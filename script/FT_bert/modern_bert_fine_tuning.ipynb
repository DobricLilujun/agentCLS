{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snt/miniconda3/envs/env_classification/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Filter: 100%|██████████| 27/27 [00:00<00:00, 4362.17 examples/s]\n",
      "Filter: 100%|██████████| 27/27 [00:00<00:00, 5813.16 examples/s]\n",
      "Map: 100%|██████████| 23/23 [00:00<00:00, 3456.43 examples/s]\n",
      "Map: 100%|██████████| 4/4 [00:00<00:00, 1071.48 examples/s]\n",
      "Casting the dataset: 100%|██████████| 23/23 [00:00<00:00, 5717.36 examples/s]\n",
      "Casting the dataset: 100%|██████████| 4/4 [00:00<00:00, 1394.96 examples/s]\n",
      "Map: 100%|██████████| 23/23 [00:00<00:00, 48.99 examples/s]\n",
      "Map: 100%|██████████| 4/4 [00:00<00:00, 16.69 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['index', 'labels', 'description', 'file_id', 'content', 'split', 'content_length'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from datasets.dataset_dict import DatasetDict, IterableDatasetDict\n",
    "from datasets.iterable_dataset import IterableDataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from datasets import ClassLabel\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from transformers import logging as transformers_logging\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from huggingface_hub import HfFolder\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import os\n",
    "import torch\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "transformers_logging.set_verbosity_error()\n",
    "\n",
    "# ========================== CMD Argument Parser ==========================\n",
    "# def parse_args():\n",
    "#     parser = argparse.ArgumentParser(description=\"Train a model using CPT (Continual Pretraining Training)\")\n",
    "#     parser.add_argument(\"--per_device_train_batch_size\", type=int, default=8, help=\"Batch size per device during training\")\n",
    "#     parser.add_argument(\"--per_device_eval_batch_size\", type=int, default=8, help=\"Batch size per device during evaluation\")\n",
    "#     parser.add_argument(\"--num_train_epochs\", type=int, default=1, help=\"Number of training epochs\")\n",
    "#     parser.add_argument(\"--learning_rate\", type=float, default=1e-6, help=\"Learning rate for training\")\n",
    "#     parser.add_argument(\"--project_root\", type=str, default=\"/Users/lujun.li/projects/mt_luxembourgish\", help=\"Path to project root\")\n",
    "#     parser.add_argument(\"--training_dataset_path\", type=str, default=\"data/processed/dataset_merged_llama_fake_targets.jsonl\", help=\"Path to training dataset\")\n",
    "#     parser.add_argument(\"--model_path\", type=str, default=\"/home/llama/Personal_Directories/srb/binary_classfication/Llama-3.2-3B-Instruct\", help=\"Path to model\")\n",
    "#     parser.add_argument(\"--resume_from_checkpoint\", type=bool, default=False, help=\"Resume training from checkpoint\")\n",
    "#     parser.add_argument(\"--resume_checkpoint_path\", type=str, default=None, help=\"Path to checkpoint to resume training from\")\n",
    "#     return parser.parse_args()\n",
    "\n",
    "# args = parse_args()\n",
    "\n",
    "# print(\"Arguments passed:\")\n",
    "# print(f\"Train Batch Size: {args.per_device_train_batch_size}\")\n",
    "# print(f\"Eval Batch Size: {args.per_device_eval_batch_size}\")\n",
    "# print(f\"Number of Epochs: {args.num_train_epochs}\")\n",
    "# print(f\"Learning Rate: {args.learning_rate}\")\n",
    "# print(f\"Project Root: {args.project_root}\")\n",
    "# print(f\"Training Dataset Path: {args.training_dataset_path}\")\n",
    "# print(f\"Model path: {args.model_path}\")\n",
    "# print(f\"Resume from checkpoint: {args.resume_from_checkpoint}\")\n",
    "# print(f\"Resume checkpoint path: {args.resume_checkpoint_path}\")\n",
    "\n",
    "\n",
    "# per_device_train_batch_size = args.per_device_train_batch_size  # Batch size for training per device\n",
    "# per_device_eval_batch_size = args.per_device_eval_batch_size  # Batch size for evaluation per device\n",
    "# num_train_epochs = args.num_train_epochs  # Number of epochs for training\n",
    "# learning_rate = args.learning_rate # Learning rate for the optimizer\n",
    "# project_root = args.project_root\n",
    "# training_dataset_path = args.training_dataset_path\n",
    "# model_path = args.model_path\n",
    "# resume_from_checkpoint = args.resume_from_checkpoint\n",
    "# resume_checkpoint_path = args.resume_checkpoint_path\n",
    "\n",
    "# Data preparation\n",
    "per_device_train_batch_size = 8\n",
    "per_device_eval_batch_size = 8\n",
    "num_train_epochs = 5\n",
    "learning_rate = 5e-5\n",
    "project_root = \"/home/snt/projects_lujun/agentCLS\"\n",
    "training_dataset_path = \"assets/LDD_split.json\"\n",
    "model_path = \"answerdotai/ModernBERT-base\"\n",
    "resume_from_checkpoint = False\n",
    "resume_checkpoint_path = None\n",
    "\n",
    "train_dataset_path = os.path.abspath(os.path.join(project_root, training_dataset_path))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "train_seed = 3407\n",
    "train_ratio = 0.001\n",
    "logging_steps = 10\n",
    "eval_steps = 10\n",
    "eval_strategy = \"steps\"\n",
    "save_strategy = \"epoch\"\n",
    "save_total_limit = 2\n",
    "logging_strategy = \"steps\"\n",
    "max_grad_norm = 0.3\n",
    "input_dataset_name = train_dataset_path.split(\"/\")[-1].split(\".\")[0]\n",
    "model_name = model_path.split(\"/\")[-1]\n",
    "\n",
    "\n",
    "if resume_from_checkpoint and resume_checkpoint_path is None:\n",
    "    raise ValueError(\"Please provide a checkpoint path to resume training from\")\n",
    "\n",
    "if resume_from_checkpoint:\n",
    "    output_dir = resume_checkpoint_path\n",
    "else:\n",
    "    current_time = datetime.now().strftime(\"%m_%d_%H_%M_%S\")\n",
    "    output_dir = f\"{project_root}/assets/logs/{input_dataset_name}_{train_ratio}_{model_name}_output_{current_time}\"\n",
    "\n",
    "dataset = pd.read_json(train_dataset_path, lines=True)\n",
    "dataset.rename(columns={\"cls_label\": \"labels\"}, inplace=True)\n",
    "# if \"EURLEX57K_split\" in train_dataset_path:\n",
    "#     if \"cls_label\" in dataset.columns:\n",
    "#         dataset.rename(columns={\"cls_label\": \"labels\"}, inplace=True)\n",
    "# else:\n",
    "#     if \"cls_label\" in dataset.columns:\n",
    "#         dataset.rename(columns={\"cls_label\": \"labels\"}, inplace=True)\n",
    "\n",
    "sample_counts = dataset.groupby('labels').size() * train_ratio\n",
    "filtered_data = dataset.groupby('labels', group_keys=False).apply(lambda x: x.iloc[:int(sample_counts[x.name])])\n",
    "dataset = filtered_data.reset_index(drop=True)\n",
    "dataset = Dataset.from_pandas(dataset)\n",
    "\n",
    "train_dataset = dataset.filter(lambda x: x[\"split\"] == \"train\")\n",
    "val_dataset = dataset.filter(lambda x: x[\"split\"] == \"validation\")\n",
    "\n",
    "# Prepare model labels - useful for inference\n",
    "labels =  set(train_dataset['labels'])\n",
    "num_labels = len(labels)\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x: {\"labels\": label2id[x[\"labels\"]]})\n",
    "val_dataset = val_dataset.map(lambda x: {\"labels\": label2id[x[\"labels\"]]})\n",
    "\n",
    "labels_ids = list(set(train_dataset['labels']))\n",
    "class_label = ClassLabel(num_classes=len(labels_ids), names=labels_ids)\n",
    "train_dataset = train_dataset.cast_column(\"labels\", class_label)\n",
    "val_dataset = val_dataset.cast_column(\"labels\", class_label)\n",
    "\n",
    "\n",
    "def tokenize(examples):\n",
    "    # Tokenize the content and add the corresponding labels to the output\n",
    "    tokenized_inputs = tokenizer(examples[\"content\"], padding=True, max_length=4096, truncation=True, return_tensors=\"pt\")\n",
    "    # tokenized_inputs[\"label\"] = examples[\"labels\"] \n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "keep_columns = [\"labels\", \"input_ids\", \"attention_mask\"]\n",
    "\n",
    "# Remove all other columns from the dataset\n",
    "tokenized_train_dataset = train_dataset.map(tokenize, batched=True, remove_columns=[col for col in train_dataset.column_names if col not in keep_columns])\n",
    "tokenized_val_dataset = val_dataset.map(tokenize, batched=True, remove_columns=[col for col in val_dataset.column_names if col not in keep_columns])\n",
    "train_dataset.features.keys()\n",
    "    \n",
    "\n",
    "## Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=num_labels, label2id=label2id, id2label=id2label,)\n",
    "\n",
    "# Metric helper method\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    score = f1_score(\n",
    "            labels, predictions, labels=labels, pos_label=1, average=\"weighted\"\n",
    "        )\n",
    "    \n",
    "    return {\"f1\": float(score) if score == 1 else score}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    # Define training args\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir= output_dir,\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "        learning_rate=5e-5,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        bf16=True,\n",
    "        optim=\"adamw_torch_fused\", \n",
    "        logging_strategy=logging_strategy,\n",
    "        logging_steps=logging_steps,\n",
    "        eval_strategy=eval_strategy,\n",
    "        eval_steps=eval_steps,\n",
    "        save_strategy=save_strategy,\n",
    "        save_total_limit=save_total_limit,\n",
    "        load_best_model_at_end=False,\n",
    "        max_grad_norm=max_grad_norm,\n",
    "        # group_by_length=True,\n",
    "        # use_mps_device=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        # push to hub parameters\n",
    "        # push_to_hub=True,\n",
    "        # hub_strategy=\"every_save\",\n",
    "        # hub_token=HfFolder.get_token(),\n",
    "        report_to=\"tensorboard\",\n",
    "        disable_tqdm=False,\n",
    "        seed = train_seed\n",
    "    )\n",
    "    \n",
    "    # Create a Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train_dataset,\n",
    "        eval_dataset=tokenized_val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    trainer_stats = trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
    "    print(\"Finished training SFT.\")\n",
    "    return trainer_stats\n",
    "\n",
    "\n",
    "trainer_stats = None\n",
    "\n",
    "def main():\n",
    "    trainer_stats = train()\n",
    "    return trainer_stats\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trainer_stats = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snt/miniconda3/envs/env_classification/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_949293/1957952343.py:31: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filtered_data = dataset.groupby('labels', group_keys=False).apply(lambda x: x.iloc[:int(sample_counts[x.name])])\n",
      "Filter: 100%|██████████| 315/315 [00:00<00:00, 11616.32 examples/s]\n",
      "Filter: 100%|██████████| 315/315 [00:00<00:00, 13441.78 examples/s]\n",
      "Processing validation data:   0%|          | 0/264 [00:00<?, ?sample/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Processing validation data: 100%|██████████| 264/264 [01:17<00:00,  3.42sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0833\n",
      "F1 Score: 0.0200\n",
      "AUC: 0.5349\n",
      "Average Inference Time per Sample: 0.2929 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load checkpoint\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from datasets.dataset_dict import DatasetDict, IterableDatasetDict\n",
    "from datasets.iterable_dataset import IterableDataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from datasets import ClassLabel\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "# Data preparation\n",
    "import torch\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "input_dataset_path = \"/home/snt/projects_lujun/agentCLS/assets/LDD_split.json\"\n",
    "model_path = \"answerdotai/ModernBERT-base\"\n",
    "train_ratio = 0.01\n",
    "checkpoint_dir = \"/home/snt/projects_lujun/agentCLS/assets/logs/LDD_split_0.001_ModernBERT-base_output_03_11_14_30_16\"\n",
    "\n",
    "input_dataset_name = input_dataset_path.split(\"/\")[-1].split(\".\")[0]\n",
    "model_name = model_path.split(\"/\")[-1]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "dataset = pd.read_json(input_dataset_path, lines=True)\n",
    "dataset.rename(columns={\"cls_label\": \"labels\"}, inplace=True)\n",
    "sample_counts = dataset.groupby('labels').size() * train_ratio\n",
    "filtered_data = dataset.groupby('labels', group_keys=False).apply(lambda x: x.iloc[:int(sample_counts[x.name])])\n",
    "dataset = filtered_data.reset_index(drop=True)\n",
    "dataset = Dataset.from_pandas(dataset)\n",
    "\n",
    "train_dataset = dataset.filter(lambda x: x[\"split\"] == \"train\")\n",
    "val_dataset = dataset.filter(lambda x: x[\"split\"] == \"validation\")\n",
    "\n",
    "# Prepare model labels - useful for inference\n",
    "labels =  set(train_dataset['labels'])\n",
    "num_labels = len(labels)\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "def get_last_checkpoints(output_dir):\n",
    "    checkpoints = os.listdir(output_dir)\n",
    "    checkpoints = [c for c in checkpoints if \"checkpoint\" in c]\n",
    "    checkpoints = [int(c.split(\"-\")[-1]) for c in checkpoints]\n",
    "    last_checkpoint = max(checkpoints)\n",
    "    return f\"{output_dir}/checkpoint-{last_checkpoint}\"\n",
    "\n",
    "checkpoints_path  = get_last_checkpoints(checkpoint_dir)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoints_path).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Initialize lists to store true and predicted labels\n",
    "true_label_one_hot_list = []\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "all_probs = []\n",
    "\n",
    "# Start time for measuring inference efficiency\n",
    "start_time = time.time()\n",
    "\n",
    "# Iterate through validation dataset and make predictions\n",
    "for input in tqdm(train_dataset, desc=\"Processing validation data\", unit=\"sample\"):\n",
    "    sample = input['content']\n",
    "    true_label = input['labels']\n",
    "    tokenized_input = tokenizer(sample, padding=True, max_length=4096, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    model_output = model(**tokenized_input)\n",
    "    logits = model_output.logits\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    predicted_class_idx = torch.argmax(probabilities, dim=-1).item()\n",
    "    predicted_label = id2label[str(predicted_class_idx)]\n",
    "    \n",
    "    true_label_idx = int(label2id[true_label])\n",
    "    true_label_one_hot = np.zeros(probabilities.size(-1))\n",
    "    true_label_one_hot[true_label_idx] = 1\n",
    "\n",
    "    true_labels.append(true_label)\n",
    "    true_label_one_hot_list.append(true_label_one_hot)\n",
    "    predicted_labels.append(predicted_label)\n",
    "    all_probs.append(probabilities.detach().cpu().numpy())  # Store the raw probabilities for AUC\n",
    "\n",
    "# Calculate accuracy, F1 score, and AUC\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')  # weighted F1 score\n",
    "auc = roc_auc_score(np.array(true_label_one_hot_list),  np.squeeze(np.array(all_probs)), multi_class='ovr', average='weighted')  # for multi-class AUC\n",
    "\n",
    "# Calculate inference time (average time per sample)\n",
    "end_time = time.time()\n",
    "inference_time = (end_time - start_time) / len(train_dataset)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"Average Inference Time per Sample: {inference_time:.4f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
