{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2161114/26970209.py:158: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filtered_train_data = dataset.groupby('labels', group_keys=False).apply(\n",
      "/tmp/ipykernel_2161114/26970209.py:162: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filtered_validation_data = dataset.groupby('labels', group_keys=False).apply(\n",
      "Map: 100%|██████████| 3039/3039 [00:00<00:00, 6021.36 examples/s]\n",
      "Map: 100%|██████████| 900/900 [00:00<00:00, 6272.44 examples/s]\n",
      "Casting the dataset: 100%|██████████| 3039/3039 [00:00<00:00, 75511.04 examples/s]\n",
      "Casting the dataset: 100%|██████████| 900/900 [00:00<00:00, 76052.66 examples/s]\n",
      "Map: 100%|██████████| 3039/3039 [00:08<00:00, 378.33 examples/s]\n",
      "Map: 100%|██████████| 900/900 [00:02<00:00, 359.95 examples/s]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at /home/snt/projects_lujun/base_models/Llama-3.2-1B-Instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model, LoraConfig\n",
    "import json\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from datasets.dataset_dict import DatasetDict, IterableDatasetDict\n",
    "from datasets.iterable_dataset import IterableDataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from datasets import ClassLabel\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "# Data preparation\n",
    "import torch\n",
    "from transformers import EarlyStoppingCallback\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "# \n",
    "# ========================== CMD Argument Parser ==========================\n",
    "# def parse_args():\n",
    "#     parser = argparse.ArgumentParser(description=\"Train a model using CPT (Continual Pretraining Training)\")\n",
    "#     parser.add_argument(\"--per_device_train_batch_size\", type=int, default=8, help=\"Batch size per device during training\")\n",
    "#     parser.add_argument(\"--per_device_eval_batch_size\", type=int, default=8, help=\"Batch size per device during evaluation\")\n",
    "#     parser.add_argument(\"--num_train_epochs\", type=int, default=1, help=\"Number of training epochs\")\n",
    "#     parser.add_argument(\"--learning_rate\", type=float, default=1e-6, help=\"Learning rate for training\")\n",
    "#     parser.add_argument(\"--project_root\", type=str, default=\"/Users/lujun.li/projects/mt_luxembourgish\", help=\"Path to project root\")\n",
    "#     parser.add_argument(\"--training_dataset_path\", type=str, default=\"data/processed/dataset_merged_llama_fake_targets.jsonl\", help=\"Path to training dataset\")\n",
    "#     parser.add_argument(\"--model_path\", type=str, default=\"/home/llama/Personal_Directories/srb/binary_classfication/Llama-3.2-3B-Instruct\", help=\"Path to model\")\n",
    "#     parser.add_argument(\"--resume_from_checkpoint\", type=bool, default=False, help=\"Resume training from checkpoint\")\n",
    "#     parser.add_argument(\"--resume_checkpoint_path\", type=str, default=None, help=\"Path to checkpoint to resume training from\")\n",
    "#     parser.add_argument(\"--qlora\", type=bool, default=False, help=\"Use QLoRA\")\n",
    "#     parser.add_argument(\"--r\", type=int, default=16, help=\"Rank for LoRA\")\n",
    "#     return parser.parse_args()\n",
    "\n",
    "# args = parse_args()\n",
    "\n",
    "\n",
    "# print(\"Arguments passed:\")\n",
    "# print(f\"Train Batch Size: {args.per_device_train_batch_size}\")\n",
    "# print(f\"Eval Batch Size: {args.per_device_eval_batch_size}\")\n",
    "# print(f\"Number of Epochs: {args.num_train_epochs}\")\n",
    "# print(f\"Learning Rate: {args.learning_rate}\")\n",
    "# print(f\"Project Root: {args.project_root}\")\n",
    "# print(f\"Training Dataset Path: {args.training_dataset_path}\")\n",
    "# print(f\"Model path: {args.model_path}\")\n",
    "# print(f\"Resume from checkpoint: {args.resume_from_checkpoint}\")\n",
    "# print(f\"Resume checkpoint path: {args.resume_checkpoint_path}\")\n",
    "# print(f\"Qlora: {args.qlora}\")\n",
    "# print(f\"Rank: {args.r}\")\n",
    "\n",
    "# per_device_train_batch_size = args.per_device_train_batch_size  # Batch size for training per device\n",
    "# per_device_eval_batch_size = args.per_device_eval_batch_size  # Batch size for evaluation per device\n",
    "# num_train_epochs = args.num_train_epochs  # Number of epochs for training\n",
    "# learning_rate = args.learning_rate # Learning rate for the optimizer\n",
    "# project_root = args.project_root\n",
    "# training_dataset_path = args.training_dataset_path\n",
    "# model_path = args.model_path\n",
    "# resume_from_checkpoint = args.resume_from_checkpoint\n",
    "# resume_checkpoint_path = args.resume_checkpoint_path\n",
    "# qlora = args.qlora\n",
    "# r = args.r\n",
    "\n",
    "\n",
    "## Data preparation\n",
    "per_device_train_batch_size = 8\n",
    "per_device_eval_batch_size = 8\n",
    "num_train_epochs = 10\n",
    "learning_rate = 1e-5\n",
    "project_root = \"/home/snt/projects_lujun/agentCLS\"\n",
    "training_dataset_path = \"assets/training_dataset/EURLEX57K_split_proportional_train_1500_val_300.jsonl\"\n",
    "model_path = \"/home/snt/projects_lujun/base_models/Llama-3.2-1B-Instruct\"\n",
    "resume_from_checkpoint = False\n",
    "resume_checkpoint_path = None\n",
    "qlora = False\n",
    "r = 16\n",
    "\n",
    "train_dataset_path = os.path.abspath(os.path.join(project_root, training_dataset_path))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "\n",
    "# Default Parameters\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "train_seed = 3407\n",
    "train_ratio = 1.0\n",
    "logging_steps = 10\n",
    "eval_steps = 100\n",
    "eval_strategy = \"epoch\"\n",
    "save_strategy = \"epoch\"\n",
    "save_total_limit = 2\n",
    "logging_strategy = \"steps\"\n",
    "max_grad_norm = 0.3\n",
    "input_dataset_name = train_dataset_path.split(\"/\")[-1].split(\".\")[0]\n",
    "model_name = model_path.split(\"/\")[-1]\n",
    "max_length = 4096\n",
    "load_in_4bit = True\n",
    "bnb_4bit_quant_type = 'nf4'\n",
    "quantization_config = None\n",
    "\n",
    "\n",
    "if qlora:\n",
    "# Quantization with Lora\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit = load_in_4bit, # enable 4-bit quantization\n",
    "        bnb_4bit_quant_type = bnb_4bit_quant_type, # information theoretically optimal dtype for normally distributed weights\n",
    "        bnb_4bit_use_double_quant = True, # quantize quantized weights //insert xzibit meme\n",
    "        bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n",
    "    )\n",
    "\n",
    "    # Lora\n",
    "    lora_config = LoraConfig(\n",
    "        r = r, # the dimension of the low-rank matrices\n",
    "        lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "        target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n",
    "        lora_dropout = 0.05, # dropout probability of the LoRA layers\n",
    "        bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n",
    "        task_type = 'SEQ_CLS',\n",
    "    )\n",
    "\n",
    "\n",
    "if resume_from_checkpoint and resume_checkpoint_path is None:\n",
    "    raise ValueError(\"Please provide a checkpoint path to resume training from\")\n",
    "\n",
    "if resume_from_checkpoint:\n",
    "    output_dir = resume_checkpoint_path\n",
    "else:\n",
    "    current_time = datetime.now().strftime(\"%m_%d_%H_%M_%S\")\n",
    "    output_dir = f\"{project_root}/assets/logs/SFT/{input_dataset_name}_{train_ratio}_{model_name}_output_{current_time}\"\n",
    "\n",
    "dataset = pd.read_json(train_dataset_path, lines=True)\n",
    "dataset.rename(columns={\"cls_label\": \"labels\"}, inplace=True)\n",
    "\n",
    "# Compute sample counts for each group based on 'labels' and 'split'\n",
    "sample_counts = dataset.groupby(['labels', 'split']).size() * train_ratio\n",
    "\n",
    "filtered_train_data = dataset.groupby('labels', group_keys=False).apply(\n",
    "    lambda x: x[x['split'] == 'train'].iloc[:int(sample_counts.loc[x.name, 'train'])]\n",
    ")\n",
    "\n",
    "filtered_validation_data = dataset.groupby('labels', group_keys=False).apply(\n",
    "    lambda x: x[x['split'] == 'validation'].iloc[:int(sample_counts.loc[x.name, 'validation'])]\n",
    ")\n",
    "\n",
    "filtered_train = filtered_train_data.reset_index(drop=True)\n",
    "filtered_validation = filtered_validation_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_pandas(filtered_train)\n",
    "val_dataset = Dataset.from_pandas(filtered_validation)\n",
    "\n",
    "\n",
    "# Tokenization\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"content\"], padding=\"max_length\", truncation=True, max_length=max_length)\n",
    "\n",
    "labels =  set(train_dataset['labels'])\n",
    "num_labels = len(labels)\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x: {\"labels\": label2id[x[\"labels\"]]})\n",
    "val_dataset = val_dataset.map(lambda x: {\"labels\": label2id[x[\"labels\"]]})\n",
    "\n",
    "labels_ids = list(set(train_dataset['labels']))\n",
    "class_label = ClassLabel(num_classes=len(labels_ids), names=labels_ids)\n",
    "train_dataset = train_dataset.cast_column(\"labels\", class_label)\n",
    "val_dataset = val_dataset.cast_column(\"labels\", class_label)\n",
    "\n",
    "\n",
    "keep_columns = [\"labels\", \"input_ids\", \"attention_mask\"]\n",
    "tokenized_train_dataset = train_dataset.map(tokenize, batched=True, remove_columns=[col for col in train_dataset.column_names if col not in keep_columns])\n",
    "tokenized_val_dataset = val_dataset.map(tokenize, batched=True, remove_columns=[col for col in val_dataset.column_names if col not in keep_columns])\n",
    "train_dataset.features.keys()\n",
    "\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=num_labels, label2id=label2id, id2label=id2label, quantization_config=quantization_config,)\n",
    "\n",
    "if qlora:\n",
    "    model = get_peft_model(prepare_model_for_kbit_training(model), lora_config)\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "model.gradient_checkpointing_enable()\n",
    "train_dataset.features.keys()\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    acc = accuracy_score(labels, np.argmax(predictions, axis=-1))\n",
    "    f1 = f1_score(labels, np.argmax(predictions, axis=-1), average=\"weighted\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "def train():\n",
    "    # Define training args\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir= output_dir,\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        bf16=True,\n",
    "        optim=\"adamw_torch_fused\", \n",
    "        logging_strategy=logging_strategy,\n",
    "        logging_steps=logging_steps,\n",
    "        eval_strategy=eval_strategy,\n",
    "        eval_steps=eval_steps,\n",
    "        save_strategy=save_strategy,\n",
    "        save_total_limit=save_total_limit,\n",
    "        load_best_model_at_end=True,\n",
    "        max_grad_norm=max_grad_norm,\n",
    "        # group_by_length=True,\n",
    "        # use_mps_device=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        # push to hub parameters\n",
    "        # push_to_hub=True,\n",
    "        # hub_strategy=\"every_save\",\n",
    "        # hub_token=HfFolder.get_token(),\n",
    "        report_to=\"tensorboard\",\n",
    "        disable_tqdm=False,\n",
    "        seed = train_seed,\n",
    "    )\n",
    "    \n",
    "    # Create a Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train_dataset,\n",
    "        eval_dataset=tokenized_val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "    trainer_stats = trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
    "    print(\"Finished training SFT.\")\n",
    "    return trainer_stats\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    def get_last_checkpoints(output_dir):\n",
    "        checkpoints = os.listdir(output_dir)\n",
    "        checkpoints = [c for c in checkpoints if \"checkpoint\" in c]\n",
    "        checkpoints = [int(c.split(\"-\")[-1]) for c in checkpoints]\n",
    "        last_checkpoint = max(checkpoints)\n",
    "        return f\"{output_dir}/checkpoint-{last_checkpoint}\"\n",
    "    \n",
    "    checkpoints_path  = get_last_checkpoints(output_dir)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(checkpoints_path).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    validation_results = []\n",
    "\n",
    "    # Initialize lists to store true and predicted labels\n",
    "    true_label_one_hot_list = []\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    # Start time for measuring inference efficiency\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Iterate through validation dataset and make predictions\n",
    "    for input in tqdm(val_dataset, desc=\"Processing validation data\", unit=\"sample\"):\n",
    "        sample = input['content']\n",
    "        true_label_idx = int(input['labels'])\n",
    "        tokenized_input = tokenizer(sample, padding=\"max_length\", max_length=max_length, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        model_output = model(**tokenized_input)\n",
    "        logits = model_output.logits\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        predicted_class_idx = torch.argmax(probabilities, dim=-1).item()\n",
    "        predicted_label = id2label[str(predicted_class_idx)]\n",
    "        \n",
    "        true_label = id2label[str(true_label_idx)]\n",
    "        true_label_one_hot = np.zeros(probabilities.size(-1))\n",
    "        true_label_one_hot[true_label_idx] = 1\n",
    "\n",
    "        true_labels.append(true_label)\n",
    "        true_label_one_hot_list.append(true_label_one_hot)\n",
    "        predicted_labels.append(predicted_label)\n",
    "        all_probs.append(probabilities.detach().cpu().numpy())  # Store the raw probabilities for AUC\n",
    "        result = {\n",
    "            'content': sample,\n",
    "            'true_label': true_label,\n",
    "            'predicted_label': predicted_label,\n",
    "            'true_label_one_hot': true_label_one_hot.tolist(),\n",
    "            'predicted_class_idx': predicted_class_idx,\n",
    "            'probabilities': probabilities.detach().cpu().numpy().tolist()  # Convert to list for JSON serialization\n",
    "        }\n",
    "        validation_results.append(result)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%m_%d_%H_%M_%S\")\n",
    "    df_validation_results = pd.DataFrame(validation_results)\n",
    "    jsonl_file_path = os.path.join(checkpoints_path, f'validation_results_{timestamp}.jsonl')\n",
    "    df_validation_results.to_json(jsonl_file_path, orient='records', lines=True)\n",
    "\n",
    "\n",
    "    # Calculate accuracy, F1 score, and AUC\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')  # weighted F1 score\n",
    "    auc = roc_auc_score(np.array(true_label_one_hot_list),  np.squeeze(np.array(all_probs), axis=1), multi_class='ovr', average='weighted')  # for multi-class AUC\n",
    "\n",
    "    # Calculate inference time (average time per sample)\n",
    "    end_time = time.time()\n",
    "    inference_time = (end_time - start_time) / len(train_dataset)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Average Inference Time per Sample: {inference_time:.4f} seconds\")\n",
    "    return \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# python llama3_FT.py \\\n",
    "# --per_device_train_batch_size 8 \\\n",
    "# --per_device_eval_batch_size 8 \\\n",
    "# --num_train_epochs 10 \\\n",
    "# --learning_rate 1e-6 \\\n",
    "# --project_root /home/llama/Personal_Directories/srb/agentCLS \\\n",
    "# --training_dataset_path assets/training_dataset/LDD_split_equal_train_1000_val_300.jsonl \\\n",
    "# --model_path /home/llama/Personal_Directories/srb/binary_classfication/Llama-3.2-3B-Instruct \\\n",
    "# --resume_from_checkpoint \"False\" \\\n",
    "# --resume_checkpoint_path \"\" \\\n",
    "# --qlora False \\\n",
    "# --r 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = None\n",
    "\n",
    "def main():\n",
    "    trainer_stats = train()\n",
    "    return trainer_stats\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trainer_stats = main()\n",
    "    eval_results = evaluate()\n",
    "\n",
    "    print(\"Finished training and evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    def get_last_checkpoints(output_dir):\n",
    "        checkpoints = os.listdir(output_dir)\n",
    "        checkpoints = [c for c in checkpoints if \"checkpoint\" in c]\n",
    "        checkpoints = [int(c.split(\"-\")[-1]) for c in checkpoints]\n",
    "        last_checkpoint = max(checkpoints)\n",
    "        return f\"{output_dir}/checkpoint-{last_checkpoint}\"\n",
    "    \n",
    "    def get_all_checkpoints(output_dir):\n",
    "        checkpoints = os.listdir(output_dir)\n",
    "        checkpoints = [c for c in checkpoints if c.startswith(\"checkpoint-\") and c.split(\"-\")[-1].isdigit()]\n",
    "        checkpoints = sorted(checkpoints, key=lambda x: int(x.split(\"-\")[-1]))\n",
    "        return [os.path.join(output_dir, c) for c in checkpoints]\n",
    "\n",
    "    \n",
    "    \n",
    "    checkpoints_path  = get_last_checkpoints(output_dir)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=num_labels, label2id=label2id, id2label=id2label, quantization_config=quantization_config,).to(device)\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.config.use_cache = False\n",
    "    model.config.pretraining_tp = 1\n",
    "    model.gradient_checkpointing_enable()\n",
    "    validation_results = []\n",
    "\n",
    "    # Initialize lists to store true and predicted labels\n",
    "    true_label_one_hot_list = []\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    # Start time for measuring inference efficiency\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Iterate through validation dataset and make predictions\n",
    "    for input in tqdm(val_dataset, desc=\"Processing validation data\", unit=\"sample\"):\n",
    "        sample = input['content']\n",
    "        true_label_idx = int(input['labels'])\n",
    "        tokenized_input = tokenizer(sample, padding=True, max_length=max_length, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        model_output = model(**tokenized_input)\n",
    "        logits = model_output.logits\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        predicted_class_idx = torch.argmax(probabilities, dim=-1).item()\n",
    "        predicted_label = id2label[str(predicted_class_idx)]\n",
    "        \n",
    "        true_label = id2label[str(true_label_idx)]\n",
    "        true_label_one_hot = np.zeros(probabilities.size(-1))\n",
    "        true_label_one_hot[true_label_idx] = 1\n",
    "\n",
    "        true_labels.append(true_label)\n",
    "        true_label_one_hot_list.append(true_label_one_hot)\n",
    "        predicted_labels.append(predicted_label)\n",
    "        all_probs.append(probabilities.detach().cpu().numpy())  # Store the raw probabilities for AUC\n",
    "        result = {\n",
    "            'content': sample,\n",
    "            'true_label': true_label,\n",
    "            'predicted_label': predicted_label,\n",
    "            'true_label_one_hot': true_label_one_hot.tolist(),\n",
    "            'predicted_class_idx': predicted_class_idx,\n",
    "            'probabilities': probabilities.detach().cpu().numpy().tolist()  # Convert to list for JSON serialization\n",
    "        }\n",
    "        validation_results.append(result)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%m_%d_%H_%M_%S\")\n",
    "    df_validation_results = pd.DataFrame(validation_results)\n",
    "    jsonl_file_path = os.path.join(checkpoints_path, f'validation_results_{timestamp}.jsonl')\n",
    "    df_validation_results.to_json(jsonl_file_path, orient='records', lines=True)\n",
    "\n",
    "    # Calculate accuracy, F1 score, and AUC\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')  # weighted F1 score\n",
    "    auc = roc_auc_score(np.array(true_label_one_hot_list),  np.squeeze(np.array(all_probs), axis=1), multi_class='ovr', average='weighted')  # for multi-class AUC\n",
    "\n",
    "    # Calculate inference time (average time per sample)\n",
    "    end_time = time.time()\n",
    "    inference_time = (end_time - start_time) / len(train_dataset)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Average Inference Time per Sample: {inference_time:.4f} seconds\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model, LoraConfig\n",
    "import json\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from datasets.dataset_dict import DatasetDict, IterableDatasetDict\n",
    "from datasets.iterable_dataset import IterableDataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from datasets import ClassLabel\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "# Data preparation\n",
    "import torch\n",
    "from transformers import EarlyStoppingCallback\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "training_dataset_path = \"/home/snt/projects_lujun/agentCLS/assets/training_dataset/EURLEX57K_split_proportional_train_1500_val_300.jsonl\"\n",
    "output_dir = \"/home/snt/projects_lujun/agentCLS/assets/logs/SFT/EURLEX57K_split_proportional_train_1500_val_300_0.01_Llama-3.2-1B-Instruct_output_03_16_17_12_51\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2178372/2214299606.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filtered_train_data = dataset.groupby('labels', group_keys=False).apply(\n",
      "/tmp/ipykernel_2178372/2214299606.py:71: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filtered_validation_data = dataset.groupby('labels', group_keys=False).apply(\n",
      "Map: 100%|██████████| 3039/3039 [00:00<00:00, 5733.99 examples/s]\n",
      "Map: 100%|██████████| 900/900 [00:00<00:00, 9780.58 examples/s]\n",
      "Casting the dataset: 100%|██████████| 3039/3039 [00:00<00:00, 96578.22 examples/s]\n",
      "Casting the dataset: 100%|██████████| 900/900 [00:00<00:00, 118419.98 examples/s]\n"
     ]
    }
   ],
   "source": [
    "per_device_train_batch_size = 8\n",
    "per_device_eval_batch_size = 8\n",
    "num_train_epochs = 10\n",
    "learning_rate = 1e-5\n",
    "project_root = \"/home/snt/projects_lujun/agentCLS\"\n",
    "model_path = \"/home/snt/projects_lujun/base_models/Llama-3.2-1B-Instruct\"\n",
    "resume_from_checkpoint = False\n",
    "resume_checkpoint_path = None\n",
    "qlora = False\n",
    "r = 16\n",
    "\n",
    "train_dataset_path = os.path.abspath(os.path.join(project_root, training_dataset_path))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "\n",
    "# Default Parameters\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "train_seed = 3407\n",
    "train_ratio = 1.0\n",
    "logging_steps = 10\n",
    "eval_steps = 100\n",
    "eval_strategy = \"epoch\"\n",
    "save_strategy = \"epoch\"\n",
    "save_total_limit = 2\n",
    "logging_strategy = \"steps\"\n",
    "max_grad_norm = 0.3\n",
    "input_dataset_name = train_dataset_path.split(\"/\")[-1].split(\".\")[0]\n",
    "model_name = model_path.split(\"/\")[-1]\n",
    "max_length = 4096\n",
    "load_in_4bit = True\n",
    "bnb_4bit_quant_type = 'nf4'\n",
    "quantization_config = None\n",
    "\n",
    "\n",
    "if qlora:\n",
    "# Quantization with Lora\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit = load_in_4bit, # enable 4-bit quantization\n",
    "        bnb_4bit_quant_type = bnb_4bit_quant_type, # information theoretically optimal dtype for normally distributed weights\n",
    "        bnb_4bit_use_double_quant = True, # quantize quantized weights //insert xzibit meme\n",
    "        bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n",
    "    )\n",
    "\n",
    "    # Lora\n",
    "    lora_config = LoraConfig(\n",
    "        r = r, # the dimension of the low-rank matrices\n",
    "        lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "        target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n",
    "        lora_dropout = 0.05, # dropout probability of the LoRA layers\n",
    "        bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n",
    "        task_type = 'SEQ_CLS',\n",
    "    )\n",
    "\n",
    "\n",
    "if resume_from_checkpoint and resume_checkpoint_path is None:\n",
    "    raise ValueError(\"Please provide a checkpoint path to resume training from\")\n",
    "\n",
    "dataset = pd.read_json(train_dataset_path, lines=True)\n",
    "dataset.rename(columns={\"cls_label\": \"labels\"}, inplace=True)\n",
    "\n",
    "# Compute sample counts for each group based on 'labels' and 'split'\n",
    "sample_counts = dataset.groupby(['labels', 'split']).size() * train_ratio\n",
    "\n",
    "filtered_train_data = dataset.groupby('labels', group_keys=False).apply(\n",
    "    lambda x: x[x['split'] == 'train'].iloc[:int(sample_counts.loc[x.name, 'train'])]\n",
    ")\n",
    "\n",
    "filtered_validation_data = dataset.groupby('labels', group_keys=False).apply(\n",
    "    lambda x: x[x['split'] == 'validation'].iloc[:int(sample_counts.loc[x.name, 'validation'])]\n",
    ")\n",
    "\n",
    "filtered_train = filtered_train_data.reset_index(drop=True)\n",
    "filtered_validation = filtered_validation_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_pandas(filtered_train)\n",
    "val_dataset = Dataset.from_pandas(filtered_validation)\n",
    "\n",
    "\n",
    "# Tokenization\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"content\"], padding=\"max_length\", truncation=True, max_length=max_length)\n",
    "\n",
    "labels =  set(train_dataset['labels'])\n",
    "num_labels = len(labels)\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x: {\"labels\": label2id[x[\"labels\"]]})\n",
    "val_dataset = val_dataset.map(lambda x: {\"labels\": label2id[x[\"labels\"]]})\n",
    "\n",
    "labels_ids = list(set(train_dataset['labels']))\n",
    "class_label = ClassLabel(num_classes=len(labels_ids), names=labels_ids)\n",
    "train_dataset = train_dataset.cast_column(\"labels\", class_label)\n",
    "val_dataset = val_dataset.cast_column(\"labels\", class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import os\n",
    "\n",
    "gpu_per_hours_dict = {\n",
    "    \"Llama-3.2-1B-Instruct\":{\n",
    "        \"train\": 27.360,\n",
    "        \"inference\": 25.782\n",
    "    },\n",
    "    \"gemma-2-2b-it\":{\n",
    "        \"train\": 51.496,\n",
    "        \"inference\": 32.664\n",
    "    },\n",
    "    \"Llama-3.2-3B-Instruct\":{\n",
    "        \"train\": 65.522,\n",
    "        \"inference\": 39.556\n",
    "    },\n",
    "    \"ModernBERT-base\":{\n",
    "        \"train\": 27.006,\n",
    "        \"inference\": 1.528\n",
    "    }\n",
    "}\n",
    "\n",
    "alpha = 0.5\n",
    "beta = 0.5\n",
    "\n",
    "def extract_training_time(log_dir, scalar_name=\"train/loss\"):\n",
    "\n",
    "    event_files = [\n",
    "        os.path.join(root, file)\n",
    "        for root, _, files in os.walk(log_dir)\n",
    "        for file in files\n",
    "        if \"events\" in file\n",
    "    ]\n",
    "\n",
    "    if not event_files:\n",
    "        raise FileNotFoundError(\"Directory does not contain any event files.\")\n",
    "    \n",
    "    event_file = event_files[0] \n",
    "\n",
    "    ea = event_accumulator.EventAccumulator(event_file)\n",
    "    ea.Reload() \n",
    "\n",
    "    available_keys = ea.scalars.Keys()\n",
    "    if scalar_name not in available_keys:\n",
    "        raise ValueError(f\"Scalar '{scalar_name}' doesn't exist: {available_keys}\")\n",
    "    \n",
    "\n",
    "    wall_times = ea.Scalars(scalar_name)\n",
    "    start_time = wall_times[0].wall_time\n",
    "    end_time = wall_times[-1].wall_time \n",
    "\n",
    "    training_duration = end_time - start_time\n",
    "    return start_time, end_time, training_duration\n",
    "\n",
    "def evaluate_multiple(output_dir, val_dataset):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    def get_last_checkpoints(output_dir):\n",
    "        checkpoints = os.listdir(output_dir)\n",
    "        checkpoints = [c for c in checkpoints if \"checkpoint\" in c]\n",
    "        checkpoints = [int(c.split(\"-\")[-1]) for c in checkpoints]\n",
    "        last_checkpoint = max(checkpoints)\n",
    "        return f\"{output_dir}/checkpoint-{last_checkpoint}\"\n",
    "    \n",
    "    def get_all_checkpoints(output_dir):\n",
    "        checkpoints = os.listdir(output_dir)\n",
    "        checkpoints = [c for c in checkpoints if c.startswith(\"checkpoint-\") and c.split(\"-\")[-1].isdigit()]\n",
    "        checkpoints = sorted(checkpoints, key=lambda x: int(x.split(\"-\")[-1]))\n",
    "        return [os.path.join(output_dir, c) for c in checkpoints]\n",
    "\n",
    "    checkpoints_paths= get_all_checkpoints(output_dir)\n",
    "    for checkpoints_path in checkpoints_paths:\n",
    "        checkpoints_path  = get_last_checkpoints(output_dir)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=num_labels, label2id=label2id, id2label=id2label, quantization_config=quantization_config,).to(device)\n",
    "        model.config.pad_token_id = tokenizer.pad_token_id\n",
    "        model.config.use_cache = False\n",
    "        model.config.pretraining_tp = 1\n",
    "        model.gradient_checkpointing_enable()\n",
    "        validation_results = []\n",
    "\n",
    "        # Initialize lists to store true and predicted labels\n",
    "        true_label_one_hot_list = []\n",
    "        true_labels = []\n",
    "        predicted_labels = []\n",
    "        all_probs = []\n",
    "\n",
    "        # Start time for measuring inference efficiency\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Iterate through validation dataset and make predictions\n",
    "        for input in tqdm(val_dataset, desc=\"Processing validation data\", unit=\"sample\"):\n",
    "            sample = input['content']\n",
    "            true_label_idx = int(input['labels'])\n",
    "            tokenized_input = tokenizer(sample, padding=True, max_length=max_length, truncation=True, return_tensors=\"pt\").to(device)\n",
    "            model_output = model(**tokenized_input)\n",
    "            logits = model_output.logits\n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            predicted_class_idx = torch.argmax(probabilities, dim=-1).item()\n",
    "            predicted_label = id2label[str(predicted_class_idx)]\n",
    "            \n",
    "            true_label = id2label[str(true_label_idx)]\n",
    "            true_label_one_hot = np.zeros(probabilities.size(-1))\n",
    "            true_label_one_hot[true_label_idx] = 1\n",
    "\n",
    "            true_labels.append(true_label)\n",
    "            true_label_one_hot_list.append(true_label_one_hot)\n",
    "            predicted_labels.append(predicted_label)\n",
    "            all_probs.append(probabilities.detach().cpu().numpy())  # Store the raw probabilities for AUC\n",
    "            result = {\n",
    "                'content': sample,\n",
    "                'true_label': true_label,\n",
    "                'predicted_label': predicted_label,\n",
    "                'true_label_one_hot': true_label_one_hot.tolist(),\n",
    "                'predicted_class_idx': predicted_class_idx,\n",
    "                'probabilities': probabilities.detach().cpu().numpy().tolist()  # Convert to list for JSON serialization\n",
    "            }\n",
    "            validation_results.append(result)\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%m_%d_%H_%M_%S\")\n",
    "        df_validation_results = pd.DataFrame(validation_results)\n",
    "        jsonl_file_path = os.path.join(checkpoints_path, f'validation_results_{timestamp}.jsonl')\n",
    "        df_validation_results.to_json(jsonl_file_path, orient='records', lines=True)\n",
    "\n",
    "\n",
    "        # Calculate accuracy, F1 score, and AUC\n",
    "        accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "        f1 = f1_score(true_labels, predicted_labels, average='weighted')  # weighted F1 score\n",
    "        auc = roc_auc_score(np.array(true_label_one_hot_list),  np.squeeze(np.array(all_probs), axis=1), multi_class='ovr', average='weighted')  # for multi-class AUC\n",
    "\n",
    "        # Calculate inference time (average time per sample)\n",
    "        end_time = time.time()\n",
    "        inference_time = (end_time - start_time) \n",
    "        inference_time_hours = round(inference_time / 3600, 4)\n",
    "        start_time, end_time, training_duration = extract_training_time(output_dir)\n",
    "        training_time_hours = round(training_duration / 3600, 4)\n",
    "\n",
    "        for k,v in gpu_per_hours_dict.items():\n",
    "            if k in output_dir:\n",
    "                gpu_ram_train = v[\"train\"]\n",
    "                gpu_ram_inference = v[\"inference\"]\n",
    "                break\n",
    "        training_gpu_hours_ram = gpu_ram_train * training_time_hours\n",
    "        inference_gpu_hours_ram = gpu_ram_inference * inference_time_hours\n",
    "        total_gpu_hours_ram = training_gpu_hours_ram + inference_gpu_hours_ram\n",
    "        Resource_M = f1 / (alpha * training_gpu_hours_ram + beta * inference_gpu_hours_ram)\n",
    "        Time_M = f1 / (alpha * training_time_hours + beta * inference_time_hours)\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"AUC: {auc:.4f}\")\n",
    "        print(f\"Resource_M: {Resource_M:.4f}\")\n",
    "        print(f\"Time_M: {Time_M:.4f}\")\n",
    "        print(f\"total GPU hours (RAM): {total_gpu_hours_ram:.4f}\")\n",
    "        print(f\"training GPU hours (RAM): {training_gpu_hours_ram:.4f}\")\n",
    "        print(f\"inference GPU hours (RAM): {inference_gpu_hours_ram:.4f}\")\n",
    "\n",
    "\n",
    "        # print(f\"Training started at: {round(start_time / 3600, 2)} hours\")\n",
    "        # print(f\"Training ended at: {round(end_time / 3600, 2)} hours\")\n",
    "        # print(f\"Training duration: {round(training_duration / 3600, 2)} hours\")\n",
    "\n",
    "\n",
    "    return \n",
    "\n",
    "\n",
    "evaluate_multiple(output_dir=output_dir, val_dataset=val_dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
