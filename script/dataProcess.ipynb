{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess for CLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ag_news_classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset keys: dict_keys(['train', 'test'])\n",
      "Sample data: {'answer_choices': ['World politics', 'Sports', 'Business', 'Science and technology'], 'inputs': [3556, 472, 5, 9034, 7, 205, 4207, 3195, 3, 27201, 8, 1589, 41, 18844, 61, 3, 18844, 3, 18, 7110, 18, 7, 9670, 7, 6, 3556, 1887, 31, 7, 3, 26, 5165, 697, 2, 3348, 13, 6173, 18, 75, 63, 2532, 7, 6, 33, 2492, 1442, 541, 5, 363, 3783, 200, 8788, 48, 1506, 1108, 58], 'inputs_pretokenized': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again. \\nWhat label best describes this news article? \", 'targets': [1769, 1], 'targets_pretokenized': ' \\nBusiness'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bigscience/P3\", \"ag_news_classify\")\n",
    "\n",
    "print(\"Dataset keys:\", dataset.keys())\n",
    "\n",
    "print(\"Sample data:\", dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rotten_tomatoes_Movie_Expressed_Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset keys: dict_keys(['train', 'validation', 'test'])\n",
      "Sample data: {'answer_choices': ['negative', 'positive'], 'inputs': [8, 2480, 19, 3, 26677, 12, 36, 8, 1401, 7, 17, 2646, 31, 7, 126, 96, 975, 152, 96, 11, 24, 3, 88, 31, 7, 352, 12, 143, 3, 9, 16500, 237, 2123, 145, 1584, 29, 1490, 3, 12291, 35, 15, 6938, 3, 6, 3, 26459, 18, 75, 12513, 4049, 10157, 526, 42, 3, 849, 1926, 142, 6191, 3, 5, 37, 6493, 7103, 21, 8, 1974, 19], 'inputs_pretokenized': 'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . The sentiment expressed for the movie is ', 'targets': [1465, 1], 'targets_pretokenized': ' positive'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bigscience/P3\", \"rotten_tomatoes_Movie_Expressed_Sentiment\")\n",
    "\n",
    "print(\"Dataset keys:\", dataset.keys())\n",
    "\n",
    "print(\"Sample data:\", dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### qasc_is_correct_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 8134/8134 [00:00<00:00, 328557.92 examples/s]\n",
      "Generating validation split: 100%|██████████| 926/926 [00:00<00:00, 120063.23 examples/s]\n",
      "Generating test split: 100%|██████████| 920/920 [00:00<00:00, 132649.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset keys: dict_keys(['train', 'validation', 'test'])\n",
      "Sample data: {'answer_choices': ['Yes', 'No'], 'inputs': [156, 27, 817, 25, 24, 493, 9, 26, 7, 13, 387, 54, 36, 5147, 57, 15328, 6, 11, 987, 25, 8, 822, 96, 9170, 686, 13, 387, 3239, 19, 5147, 57, 15328, 4609, 6, 19, 8, 2024, 1525, 96, 855, 291, 40, 7, 121, 58], 'inputs_pretokenized': 'If I tell you that Beads of water can be formed by clouds, and ask you the question \"what type of water formation is formed by clouds?\", is the correct answer \"pearls\"? \\n\\n', 'targets': [465, 1], 'targets_pretokenized': ' \\n\\n No '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"bigscience/P3\", \"qasc_is_correct_1\")\n",
    "print(\"Dataset keys:\", dataset.keys())\n",
    "print(\"Sample data:\", dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WOS11967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_level_2\n",
      "2    2543\n",
      "4    2512\n",
      "0    2428\n",
      "3    2264\n",
      "1    2220\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('web_of_science', 'WOS11967')\n",
    "\n",
    "subcategory_counts = dataset['train'].to_pandas()['label_level_2'].value_counts()\n",
    "print(subcategory_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Parent Categories: 7\n",
      "Unique Parent-Child Category Combinations: 34\n",
      "Top 5 Parent-Child Combinations: [((4, 4), 449), ((4, 3), 441), ((1, 4), 426), ((4, 1), 423), ((3, 3), 420)]\n",
      "\n",
      "Parent-Child Count:\n",
      "(4, 4): 449\n",
      "(4, 3): 441\n",
      "(1, 4): 426\n",
      "(4, 1): 423\n",
      "(3, 3): 420\n",
      "(4, 0): 410\n",
      "(3, 1): 402\n",
      "(6, 2): 401\n",
      "(2, 1): 397\n",
      "(2, 3): 394\n",
      "(2, 2): 391\n",
      "(2, 0): 389\n",
      "(2, 4): 388\n",
      "(3, 4): 386\n",
      "(4, 2): 384\n",
      "(3, 0): 371\n",
      "(5, 2): 368\n",
      "(5, 1): 357\n",
      "(1, 2): 353\n",
      "(6, 0): 351\n",
      "(3, 2): 346\n",
      "(6, 1): 340\n",
      "(6, 3): 335\n",
      "(5, 3): 321\n",
      "(5, 0): 309\n",
      "(0, 1): 301\n",
      "(6, 4): 301\n",
      "(0, 3): 300\n",
      "(0, 2): 300\n",
      "(1, 0): 300\n",
      "(0, 4): 300\n",
      "(0, 0): 298\n",
      "(5, 4): 262\n",
      "(1, 3): 53\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the WOS-11967 dataset\n",
    "dataset = load_dataset(\"web_of_science\", \"WOS11967\")\n",
    "\n",
    "train_data = dataset[\"train\"]\n",
    "\n",
    "parent_count = defaultdict(int)\n",
    "parent_child_count = defaultdict(int)\n",
    "\n",
    "for example in train_data:\n",
    "    parent_label = example[\"label_level_1\"]\n",
    "    child_label = example[\"label_level_2\"]\n",
    "    \n",
    "    parent_count[parent_label] += 1\n",
    "    parent_child_count[(parent_label, child_label)] += 1 \n",
    "\n",
    "num_parents = len(parent_count)\n",
    "num_parent_child = len(parent_child_count)\n",
    "\n",
    "print(f\"Unique Parent Categories: {num_parents}\")\n",
    "print(f\"Unique Parent-Child Category Combinations: {num_parent_child}\")\n",
    "\n",
    "sorted_parent_child = sorted(parent_child_count.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Top 5 Parent-Child Combinations:\", sorted_parent_child[:5])\n",
    "\n",
    "print(\"\\nParent-Child Count:\")\n",
    "for (parent, child), count in sorted(parent_child_count.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"({parent}, {child}): {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAXI 1500 \n",
    "\n",
    "To be done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Spliting For Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n"
     ]
    }
   ],
   "source": [
    "unique_labels = list(set(train_data[\"label\"]))\n",
    "print(unique_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_df = pd.read_json(\"/home/snt/projects_lujun/agentCLS/assets/training_dataset/EURLEX57K_split_equal_train_1000_val_300.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cls_label\n",
       "Decision      1300\n",
       "Directive     1300\n",
       "Regulation    1300\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.cls_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "celex_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "document_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "header",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "recitals",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "main_body",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "eurovoc_concepts",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "content_length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cls_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "description",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "27333bbb-13f8-4668-922b-da9a87fb2d49",
       "rows": [
        [
         "0",
         "31983D0455",
         "Decision",
         "83/455/EEC: Commission Decision of 1 September 1983 establishing that the apparatus described as 'Plessey- Viz - Radiosonde, model 1393' may be imported free of Common Customs Tariff duties\n",
         "COMMISSION  DECISION\nof 1 September 1983\nestablishing that the apparatus described as 'Plessey-Viz - Radiosonde, model 1393' may be imported free of Common Customs Tariff duties\n(83/455/EEC)\nTHE COMMISSION OF THE EUROPEAN\nCOMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Regulation (EEC) No 1798/75 of 10 July 1975 on the importation free of Common Customs Tariff duties of educational, scientific and cultural materials (1), as last amended by Regulation (EEC) No 608/82 (2),\nHaving regard to Commission Regulation (EEC) No 2784/79 of 12 December 1979 laying down provisions for the implementation of Regulation (EEC) No 1798/75 (3), and in particular Article 7 thereof,\nWhereas, by letter dated 21 February 1983, the Federal Republic of Germany has requested the Commission to invoke the procedure provided for in Article 7 of Regulation (EEC) No 2784/79 in order to determine whether or not the apparatus described as 'Plessey-Viz - Radiosonde, model 1393', ordered on 20 January 1982 and intended to be used for the ascertainment of the altitude-related pressure, temperature and humidity profiles for the purpose of determining atmospheric transport phenomena, should be considered to be a scientific apparatus and, where the reply is in the affirmative, whether apparatus of equivalent scientific value is currently being manufactured in the Community;\nWhereas, in accordance with the provisions of Article 7 (5) of Regulation (EEC) No 2784/79, a group of experts composed of representatives of all the Member States met on 6 July 1983 within the framework of the Committee on Duty-Free Arrangements to examine the matter;\nWhereas this examination showed that the apparatus in question is a radiosonde; whereas its objective technical characteristics such as the emission frequency and the use to which it is put make it specially suited to scientific research; whereas, moreover, apparatus of the same kind are principally used for scientific activities; whereas it must therefore be considered to be a scientific apparatus;\nWhereas, on the basis of information received from Member States, apparatus of equivalent scientific value capable of use for the same purpose is not currently manufactured in the Community; whereas, therefore, duty-free admission of this apparatus is justified,",
         "[\"The apparatus described as 'Plessey-Viz - Radiosonde, model 1393', which is the subject of an application by the Federal Republic of Germany of 21 February 1983, may be imported free of Common Customs Tariff duties.\", 'This Decision is addressed to the Member States.']",
         "['1091', '2159', '3842', '4381']",
         "train",
         "83/455/EEC: Commission Decision of 1 September 1983 establishing that the apparatus described as 'Plessey- Viz - Radiosonde, model 1393' may be imported free of Common Customs Tariff duties\n\n,\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Regulation (EEC) No 1798/75 of 10 July 1975 on the importation free of Common Customs Tariff duties of educational, scientific and cultural materials (1), as last amended by Regulation (EEC) No 608/82 (2),\nHaving regard to Commission Regulation (EEC) No 2784/79 of 12 December 1979 laying down provisions for the implementation of Regulation (EEC) No 1798/75 (3), and in particular Article 7 thereof,\nWhereas, by letter dated 21 February 1983, the Federal Republic of Germany has requested the Commission to invoke the procedure provided for in Article 7 of Regulation (EEC) No 2784/79 in order to determine whether or not the apparatus described as 'Plessey-Viz - Radiosonde, model 1393', ordered on 20 January 1982 and intended to be used for the ascertainment of the altitude-related pressure, temperature and humidity profiles for the purpose of determining atmospheric transport phenomena, should be considered to be a scientific apparatus and, where the reply is in the affirmative, whether apparatus of equivalent scientific value is currently being manufactured in the Community;\nWhereas, in accordance with the provisions of Article 7 (5) of Regulation (EEC) No 2784/79, a group of experts composed of representatives of all the Member States met on 6 July 1983 within the framework of the Committee on Duty-Free Arrangements to examine the matter;\nWhereas this examination showed that the apparatus in question is a radiosonde; whereas its objective technical characteristics such as the emission frequency and the use to which it is put make it specially suited to scientific research; whereas, moreover, apparatus of the same kind are principally used for scientific activities; whereas it must therefore be considered to be a scientific apparatus;\nWhereas, on the basis of information received from Member States, apparatus of equivalent scientific value capable of use for the same purpose is not currently manufactured in the Community; whereas, therefore, duty-free admission of this apparatus is justified,\nThe apparatus described as 'Plessey-Viz - Radiosonde, model 1393', which is the subject of an application by the Federal Republic of Germany of 21 February 1983, may be imported free of Common Customs Tariff duties. This Decision is addressed to the Member States.",
         "2580",
         "Decision",
         "Decision"
        ],
        [
         "1",
         "32014D0207",
         "Decision",
         "2014/207/EU: Commission Implementing Decision of 11 April 2014 on the designation of the .eu Top Level Domain Registry  Text with EEA relevance\n",
         "12.4.2014 EN Official Journal of the European Union L 109/41\nCOMMISSION IMPLEMENTING DECISION\nof 11 April 2014\non the designation of the .eu Top Level Domain Registry\n(Text with EEA relevance)\n(2014/207/EU)\nTHE EUROPEAN COMMISSION",
         ",\nHaving regard to the Treaty on the Functioning of the European Union,\nHaving regard to Regulation (EC) No 733/2002 of the European Parliament and of the Council of 22 April 2002 on the implementation of the .eu Top Level Domain (1), and in particular Article 3(1)(b) thereof,\nWhereas:\n(1) The Commission should designate the Registry entrusted with the organisation, administration and management of the .eu Top Level Domain after publishing a call for expressions of interest in the Official Journal of the European Union.\n(2) In 2003 the Commission designated European Registry for internet Domains (EURid) as the .eu Top Level Domain Registry by its Decision 2003/375/EC (2). The Commission concluded a contract with European Registry for internet Domains (EURid) that specified the conditions according to which the Commission supervises the organisation, administration and management of the .eu Top Level Domain by the Registry. That contract was signed on 12 October 2004 for a term of five years and then renewed in 2009 for another five years. It will expire on 12 October 2014.\n(3) The Commission published a Call for expressions of interest (2013/C 134/06) in the Official Journal of the European Union on 14 May 2013 jointly with the Commission Declaration on its role as supervisor of the organisation, administration and management of the .eu TDL by the Registry (2013/C 134/05), inviting applications from organisations wishing to be selected as the Registry to be entrusted with the organisation, management and administration of the .eu Top Level Domain.\n(4) The call was closed on 20 June 2013. Only one application was received, from European Registry for internet Domains (EURid).\n(5) An evaluation based on the eligibility criteria and selection criteria provided for in the call for expressions of interest was conducted on 25 July 2013.\n(6) The evaluators examined the application and established scorecard comprising different marks (individual and collective) for the application in line with the marking system provided in Section 4 of the call, and taking into account its overall quality in view of the selection criteria. The evaluators concluded that the application from European Registry for internet Domains (EURid) met the minimum requirements for each of the selection criteria. The Commission has examined the results arrived at by the evaluators and on this basis endorses the decision.\n(7) The measures provided for in this Decision are in accordance with the opinion of the Communications Committee established by Article 22(1) of Directive 2002/21/EC of the European Parliament and of the Council (3),",
         "['European Registry for internet Domains (EURid) shall be the .eu Top Level Domain Registry entrusted with the organisation, management and administration of the .eu Top Level Domain.', 'The Commission shall enter into a contract with European Registry for internet Domains (EURid) specifying the conditions according to which the Commission supervises the organisation, administration and management of the .eu Top Level Domain by the Registry, in accordance with Article 3(1)(c) of the Regulation (EC) No 733/2002.\\nThat contract shall have an initial period of five years and may be extended two times each time for an additional period of maximum five years.', 'Decision 2003/375/EC is repealed.', 'This Decision shall enter into force on the day following that of its publication in the Official Journal of the European Union.']",
         "['6139', '6775', '773', '7950']",
         "train",
         "2014/207/EU: Commission Implementing Decision of 11 April 2014 on the designation of the .eu Top Level Domain Registry  Text with EEA relevance\n\n,\nHaving regard to the Treaty on the Functioning of the European Union,\nHaving regard to Regulation (EC) No 733/2002 of the European Parliament and of the Council of 22 April 2002 on the implementation of the .eu Top Level Domain (1), and in particular Article 3(1)(b) thereof,\nWhereas:\n(1) The Commission should designate the Registry entrusted with the organisation, administration and management of the .eu Top Level Domain after publishing a call for expressions of interest in the Official Journal of the European Union.\n(2) In 2003 the Commission designated European Registry for internet Domains (EURid) as the .eu Top Level Domain Registry by its Decision 2003/375/EC (2). The Commission concluded a contract with European Registry for internet Domains (EURid) that specified the conditions according to which the Commission supervises the organisation, administration and management of the .eu Top Level Domain by the Registry. That contract was signed on 12 October 2004 for a term of five years and then renewed in 2009 for another five years. It will expire on 12 October 2014.\n(3) The Commission published a Call for expressions of interest (2013/C 134/06) in the Official Journal of the European Union on 14 May 2013 jointly with the Commission Declaration on its role as supervisor of the organisation, administration and management of the .eu TDL by the Registry (2013/C 134/05), inviting applications from organisations wishing to be selected as the Registry to be entrusted with the organisation, management and administration of the .eu Top Level Domain.\n(4) The call was closed on 20 June 2013. Only one application was received, from European Registry for internet Domains (EURid).\n(5) An evaluation based on the eligibility criteria and selection criteria provided for in the call for expressions of interest was conducted on 25 July 2013.\n(6) The evaluators examined the application and established scorecard comprising different marks (individual and collective) for the application in line with the marking system provided in Section 4 of the call, and taking into account its overall quality in view of the selection criteria. The evaluators concluded that the application from European Registry for internet Domains (EURid) met the minimum requirements for each of the selection criteria. The Commission has examined the results arrived at by the evaluators and on this basis endorses the decision.\n(7) The measures provided for in this Decision are in accordance with the opinion of the Communications Committee established by Article 22(1) of Directive 2002/21/EC of the European Parliament and of the Council (3),\nEuropean Registry for internet Domains (EURid) shall be the .eu Top Level Domain Registry entrusted with the organisation, management and administration of the .eu Top Level Domain. The Commission shall enter into a contract with European Registry for internet Domains (EURid) specifying the conditions according to which the Commission supervises the organisation, administration and management of the .eu Top Level Domain by the Registry, in accordance with Article 3(1)(c) of the Regulation (EC) No 733/2002.\nThat contract shall have an initial period of five years and may be extended two times each time for an additional period of maximum five years. Decision 2003/375/EC is repealed. This Decision shall enter into force on the day following that of its publication in the Official Journal of the European Union.",
         "3608",
         "Decision",
         "Decision"
        ],
        [
         "2",
         "32007D0621",
         "Decision",
         "2007/621/EC,Euratom: Council Decision of 26 September 2007 appointing a Danish member of the European Economic and Social Committee\n",
         "28.9.2007 EN Official Journal of the European Union L 253/38\nCOUNCIL DECISION\nof 26 September 2007\nappointing a Danish member of the European Economic and Social Committee\n(2007/621/EC, Euratom)\nTHE COUNCIL OF THE EUROPEAN UNION",
         ",\nHaving regard to the Treaty establishing the European Community, and in particular Article 259 thereof,\nHaving regard to the Treaty establishing the European Atomic Energy Community, and in particular Article 167 thereof,\nHaving regard to Council Decision 2006/703/EC, Euratom of 16 October 2006 appointing the Danish members of the European Economic and Social Committee (1) for the period from 21 September 2006 to 20 September 2010,\nHaving regard to the nomination submitted by the Danish Government,\nHaving received the opinion of the Commission,\nWhereas a Danish member’s seat on the aforementioned Committee has fallen vacant following the resignation of Ms Randi IVERSEN,",
         "['Ms Mette KINDBERG is hereby appointed a member of the European Economic and Social Committee in place of Ms Randi IVERSEN for the remainder of her term of office, which ends on 20 September 2010.', 'This Decision shall take effect on the date of its adoption.']",
         "['336', '3559', '6054']",
         "train",
         "2007/621/EC,Euratom: Council Decision of 26 September 2007 appointing a Danish member of the European Economic and Social Committee\n\n,\nHaving regard to the Treaty establishing the European Community, and in particular Article 259 thereof,\nHaving regard to the Treaty establishing the European Atomic Energy Community, and in particular Article 167 thereof,\nHaving regard to Council Decision 2006/703/EC, Euratom of 16 October 2006 appointing the Danish members of the European Economic and Social Committee (1) for the period from 21 September 2006 to 20 September 2010,\nHaving regard to the nomination submitted by the Danish Government,\nHaving received the opinion of the Commission,\nWhereas a Danish member’s seat on the aforementioned Committee has fallen vacant following the resignation of Ms Randi IVERSEN,\nMs Mette KINDBERG is hereby appointed a member of the European Economic and Social Committee in place of Ms Randi IVERSEN for the remainder of her term of office, which ends on 20 September 2010. This Decision shall take effect on the date of its adoption.",
         "1070",
         "Decision",
         "Decision"
        ],
        [
         "3",
         "31992D0283",
         "Decision",
         "92/283/EEC: Commission Decision of 8 May 1992 approving the plan for the approval of establishments for the purposes of intra-Community trade in poultry and hatching eggs submitted by the Netherlands (Only the Dutch text is authentic)\n",
         "COMMISSION DECISION  of 8 May 1992  approving the plan for the approval of establishments for the purposes of intra-Community trade in poultry and hatching eggs submitted by the Netherlands  (Only the Dutch text is authentic)  (92/283/EEC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Directive 90/539/EEC of 15 October 1990 on animal health conditions governing intra-Community trade in, and imports from third countries of, poultry and hatching eggs (1), as last amended by Directive 91/496/EEC (2), and in  particular Article 3 (2) thereof,\nWhereas by letter dated 11 November 1991 the Netherlands transmitted a plan to the Commission;\nWhereas the plan has been examined and found to meet the requirements of Directive 90/539/EEC, and in particular Annex II thereof;\nWhereas the measures provided for in this Decision are in accordance with the opinion of the Standing Veterinary Committee,",
         "['The plan submitted by the Netherlands for the approval of establishments for the purposes of intra-Community trade in poultry and hatching eggs is hereby approved.', 'The Netherlands shall bring into force by 1 May 1992 the laws, regulations and administrative provisions for implementation of the plan referred to in Article 1.', 'This Decision is addressed to the Netherlands.']",
         "['152', '192', '2121', '2286', '4747', '619']",
         "train",
         "92/283/EEC: Commission Decision of 8 May 1992 approving the plan for the approval of establishments for the purposes of intra-Community trade in poultry and hatching eggs submitted by the Netherlands (Only the Dutch text is authentic)\n\n,\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Directive 90/539/EEC of 15 October 1990 on animal health conditions governing intra-Community trade in, and imports from third countries of, poultry and hatching eggs (1), as last amended by Directive 91/496/EEC (2), and in  particular Article 3 (2) thereof,\nWhereas by letter dated 11 November 1991 the Netherlands transmitted a plan to the Commission;\nWhereas the plan has been examined and found to meet the requirements of Directive 90/539/EEC, and in particular Annex II thereof;\nWhereas the measures provided for in this Decision are in accordance with the opinion of the Standing Veterinary Committee,\nThe plan submitted by the Netherlands for the approval of establishments for the purposes of intra-Community trade in poultry and hatching eggs is hereby approved. The Netherlands shall bring into force by 1 May 1992 the laws, regulations and administrative provisions for implementation of the plan referred to in Article 1. This Decision is addressed to the Netherlands.",
         "1318",
         "Decision",
         "Decision"
        ],
        [
         "4",
         "31994D1032",
         "Decision",
         "94/1032/EC: Commission Decision of 16 December 1994 on the approval of the Single Programming Document for Community structural assistance in the region of West Cumbria and Furness concerned by Objective 2 in the United Kingdom (Only the English text is authentic)\n",
         "COMMISSION  DECISION of 16 December 1994 on the approval of the Single Programming Document for Community  structural assistance in the region of West Cumbria and Furness concerned by Objective 2 in the  United Kingdom (Only the English text is authentic) (94/1032/EC)\nTHE COMMISSION OF  THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Regulation (EEC) No 4253/88 of 19 December 1988 laying down provisions for  implementing Regulation (EEC) No 2052/88 as regards coordination of activities of the different  Structural Funds between themselves and with the operations of the European Investment Bank and the  other existing financial instruments (1), as amended by Regulation (EEC) No 2082/93 (2), and in  particular Article 10 (1) last subparagraph thereof,\nAfter consultation of the Advisory Committee on the Development and Conversion of Regions and the  Committee pursuant to Article 124 of the Treaty,\nWhereas the programming procedure for structural assistance under Objective 2 is defined in Article  9 (8) to (10) of Council Regulation (EEC) No 2052/88 of 24 June 1988 on the tasks of the Structural  Funds and their effectiveness and on coordination of their activities between themselves and with  the operations of the European Investment Bank and the other existing financial instruments (3), as  amended by Regulation (EEC) No 2081/93 (4); whereas, however, the last subparagraph of Article 5  (2) of Regulation (EEC) No 4253/88 foresees that in order to simplify and to speed up programming  procedures, Member States may submit in a Single Programming Document the information required for  the regional and social conversion plan referred to in Article 9 (8) of Regulation (EEC) No 2052/88  and the information required at Article 14 (2) of Regulation (EEC) No 4253/88; whereas Article 10  (1) last subparagraph of Regulation (EEC) No 4253/88 foresees that in that case the Commission  adopts a single decision in a Single Document covering the points referred to in Article 8 (3) and  the assistance from the Funds referred to in the last subparagraph of Article 14 (3);\nWhereas the Commission has established, by Decision 94/169/EC (5), an initial list of declining  industrial areas concerned by Objective 2 for the period 1994 to 1996;\nWhereas the United Kingdom Government has submitted to the Commission on 18 April 1994 the Single  Programming Document referred to in Article 5 (2) of Regulation (EEC) No 4253/88 for the region of  West Cumbria and Furness; whereas this document contains the elements referred to in Article 9 (8)  of Regulation (EEC) No 2052/88 and in Article 14 (2) of Regulation (EEC) No 4253/88; whereas  expenditure under this Single Programming Document is eligible pursuant to Article 33 (2) of  Regulation (EEC) No 4253/88, from 1 January 1994;\nWhereas the Single Programming Document submitted by this Member State includes a description of  the conversion priorities selected and the applications for assistance from the European Regional  Development Fund (ERDF) and the European Social Fund (ESF) as well as an indication of the planned  use of the assistance available from the European Investment Bank (EIB) and the other financial  instruments in implementing the Single Programming Document;\nWhereas, in accordance with Article 3 of Regulation (EEC) No 4253/88, the Commission is charged  with ensuring, within the framework of the partnership, coordination and consistency between  assistance from the Funds and assistance provided by the EIB and the other financial instruments,  including the ECSC and the other actions for structural purposes;\nWhereas the EIB has been involved in the drawing up of the Single Programming Document in  accordance with the provisions of Article 8 (1) of Regulation (EEC) No 4253/88, applicable by  analogy in the establishment of the Single Programming Document; whereas it has declared itself  prepared to contribute to the implementation of this document in conformity with its statutory  provisions; whereas, however, it has not yet been possible to evaluate precisely the amounts of  Community loans corresponding to the financial needs;\nWhereas Article 2 second subparagraph of Commission Regulation (EEC) No 1866/90 of 2 July 1990 on  arrangements for using the ecu for the purpose of the budgetary management of the Structural Funds  (1), as last amended by Regulation (EC) No 2745/94 (2), stipulates that in the Commission Decisions  approving a Single Programming Document, the Community assistance available for the entire period  and the annual breakdown thereof shall be set out in ecus at prices for the year in which each  Decision is taken and shall be subject to indexation; whereas this annual breakdown must be  compatible with the progressive increase in the commitment appropriations shown in Annex II to  Regulation (EEC) No 2052/88; whereas indexation is based on a single rate per year, corresponding  to the rates applied annually to budget appropriations on the basis of the mechanism for the  technical adjustment of the financial perspectives;\nWhereas Article 1 of Council Regulation (EEC) No 4254/88 of 19 December 1988 laying down provisions  for implementing Regulation (EEC) No 2052/88 as regards the European Regional Development Fund (3),  as amended by Regulation (EEC) No 2083/93 (4), defines the measures for which the ERDF may provide  financial support;\nWhereas Article 1 of Council Regulation (EEC) No 4255/88 of 19 December 1988 laying down provisions  for implementing Regulation (EEC) No 2052/88 as regards the European Social Fund (5), as amended by  Regulation (EEC) No 2084/93 (6), defines the measures for which the ESF may provide financial  support;\nWhereas the Single Programming Document has been established in agreement with the Member State  concerned through the partnership defined in Article 4 of Regulation (EEC) No 2052/88;\nWhereas the Single Programming Document satisfies the conditions and includes the information  required by Article 14 of Regulation (EEC) No 4253/88;\nWhereas the present assistance satisfies the conditions laid down in Article 13 of Regulation (EEC)  No 4253/88, and so should be implemented by means of an integrated approach involving finance from  more than one Fund;\nWhereas Article 1 of the Financial Regulation of 21 December 1977 applicable to the general budget  of the European Communities (7), as last amended by Regulation (ECSC, EC, Euratom) No 2730/94 (8),  states that the legal commitments entered into for measures extending over more than one financial  year must contain a time limit for implementation which must be specified to the recipient in due  form when the aid is granted;\nWhereas Article 20 (3) of Regulation (EEC) No 4253/88 provides, subject to available funding, for a  single commitment where the Community assistance granted is less than ECU 40 million for the whole  programmation period;\nWhereas all the other conditions laid down for the grant of aid from the ERDF and the ESF have been  complied with,",
         "['The Single Programming Document for Community structural assistance  in the region of West Cumbria and Furness concerned by Objective 2 in the United Kingdom, covering  the period 1 January 1994 to 31 December 1996, is hereby approved.', 'The Single Programming Document includes the following essential elements:\\n(a) a statement of the main priorities for joint action, their specific quantified objectives, an  appraisal of their expected impact and their consistency with economic, social and regional  policies in the United Kingdom;\\nthe main priorities are:\\n1. industrial and business development;\\n2. development of knowledge-based industries;\\n3. tourism development;\\n4. community economic development;\\n(b) the assistance from the Structural Funds as referred to in Article 4;\\n(c) the detailed provisions for implementing the Single Programming Document comprising:\\n- the procedures for monitoring and evaluation,\\n- the financial implementation provisions,\\n- the rules for compliance with Community policies;\\n(d) the procedures for verifying additionality and an initial evaluation of the latter;\\n(e) the arrangements for associating the environmental authorities with the implementation of the  Single Programming Document;\\n(f) the means available for technical assistance necessary for the preparation, implementation or  adaptation of the measures concerned.', 'For the purpose of indexation, the annual breakdown of the global maximal allocation  foreseen for the assistance from the Structural Funds is as follows:\\n>TABLE>', 'The assistance from the Structural Funds granted to the Single  Programming Document amounts to a maximum of ECU 25,0 million.\\nThe procedure for granting the financial assistance, including the financial contribution from the  Funds to the various priorities and measures, is set out in the financing plan and the detailed  implementing provisions which form an integral part of the Single Programming Document.\\nThe national financial contribution envisaged, which is approximately ECU 26,50 million for the  public sector and ECU 13,75 million for the private sector, may be met in part by Community loans,  in particular from the ECSC and EIB.', '1.  The breakdown among the Structural Funds of the total Community assistance  available is as follows:\\n- ERDF:ECU 18,82 million,\\n- ESF:ECU  6,18 million.\\n2.  The budgetary commitments at the moment of approval of the Single Programming Document refer to  the total Community assistance.', 'The breakdown among the Structural Funds and the procedure for the grant of the  assistance may be altered subsequently, subject to the availability of funds and the budgetary  rules, in the light of adjustments decided according to the procedure laid down in Article 25 (5)  of Regulation (EEC) No 4253/88.', 'The Community aid concerns expenditure on operations under the Single Programming  Document which, in the Member State concerned, are the subject of legally binding commitments and  for which the requisite finance has been specifically allocated no later than 31 December 1996. The  final date for taking account of expenditure on these measures is 31 December 1998.', 'The Single Programming Document shall be implemented in accordance with Community law,  and in particular Articles 6, 30, 48, 52 and 59 of the EC Treaty and the Community Directives on  the coordination of procedures for the award of contracts.', 'This Decision is addressed to the United Kingdom of Great Britain and Northern  Ireland.']",
         "['1460', '231', '2407', '3067', '3396', '431']",
         "train",
         "94/1032/EC: Commission Decision of 16 December 1994 on the approval of the Single Programming Document for Community structural assistance in the region of West Cumbria and Furness concerned by Objective 2 in the United Kingdom (Only the English text is authentic)\n\n,\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Regulation (EEC) No 4253/88 of 19 December 1988 laying down provisions for  implementing Regulation (EEC) No 2052/88 as regards coordination of activities of the different  Structural Funds between themselves and with the operations of the European Investment Bank and the  other existing financial instruments (1), as amended by Regulation (EEC) No 2082/93 (2), and in  particular Article 10 (1) last subparagraph thereof,\nAfter consultation of the Advisory Committee on the Development and Conversion of Regions and the  Committee pursuant to Article 124 of the Treaty,\nWhereas the programming procedure for structural assistance under Objective 2 is defined in Article  9 (8) to (10) of Council Regulation (EEC) No 2052/88 of 24 June 1988 on the tasks of the Structural  Funds and their effectiveness and on coordination of their activities between themselves and with  the operations of the European Investment Bank and the other existing financial instruments (3), as  amended by Regulation (EEC) No 2081/93 (4); whereas, however, the last subparagraph of Article 5  (2) of Regulation (EEC) No 4253/88 foresees that in order to simplify and to speed up programming  procedures, Member States may submit in a Single Programming Document the information required for  the regional and social conversion plan referred to in Article 9 (8) of Regulation (EEC) No 2052/88  and the information required at Article 14 (2) of Regulation (EEC) No 4253/88; whereas Article 10  (1) last subparagraph of Regulation (EEC) No 4253/88 foresees that in that case the Commission  adopts a single decision in a Single Document covering the points referred to in Article 8 (3) and  the assistance from the Funds referred to in the last subparagraph of Article 14 (3);\nWhereas the Commission has established, by Decision 94/169/EC (5), an initial list of declining  industrial areas concerned by Objective 2 for the period 1994 to 1996;\nWhereas the United Kingdom Government has submitted to the Commission on 18 April 1994 the Single  Programming Document referred to in Article 5 (2) of Regulation (EEC) No 4253/88 for the region of  West Cumbria and Furness; whereas this document contains the elements referred to in Article 9 (8)  of Regulation (EEC) No 2052/88 and in Article 14 (2) of Regulation (EEC) No 4253/88; whereas  expenditure under this Single Programming Document is eligible pursuant to Article 33 (2) of  Regulation (EEC) No 4253/88, from 1 January 1994;\nWhereas the Single Programming Document submitted by this Member State includes a description of  the conversion priorities selected and the applications for assistance from the European Regional  Development Fund (ERDF) and the European Social Fund (ESF) as well as an indication of the planned  use of the assistance available from the European Investment Bank (EIB) and the other financial  instruments in implementing the Single Programming Document;\nWhereas, in accordance with Article 3 of Regulation (EEC) No 4253/88, the Commission is charged  with ensuring, within the framework of the partnership, coordination and consistency between  assistance from the Funds and assistance provided by the EIB and the other financial instruments,  including the ECSC and the other actions for structural purposes;\nWhereas the EIB has been involved in the drawing up of the Single Programming Document in  accordance with the provisions of Article 8 (1) of Regulation (EEC) No 4253/88, applicable by  analogy in the establishment of the Single Programming Document; whereas it has declared itself  prepared to contribute to the implementation of this document in conformity with its statutory  provisions; whereas, however, it has not yet been possible to evaluate precisely the amounts of  Community loans corresponding to the financial needs;\nWhereas Article 2 second subparagraph of Commission Regulation (EEC) No 1866/90 of 2 July 1990 on  arrangements for using the ecu for the purpose of the budgetary management of the Structural Funds  (1), as last amended by Regulation (EC) No 2745/94 (2), stipulates that in the Commission Decisions  approving a Single Programming Document, the Community assistance available for the entire period  and the annual breakdown thereof shall be set out in ecus at prices for the year in which each  Decision is taken and shall be subject to indexation; whereas this annual breakdown must be  compatible with the progressive increase in the commitment appropriations shown in Annex II to  Regulation (EEC) No 2052/88; whereas indexation is based on a single rate per year, corresponding  to the rates applied annually to budget appropriations on the basis of the mechanism for the  technical adjustment of the financial perspectives;\nWhereas Article 1 of Council Regulation (EEC) No 4254/88 of 19 December 1988 laying down provisions  for implementing Regulation (EEC) No 2052/88 as regards the European Regional Development Fund (3),  as amended by Regulation (EEC) No 2083/93 (4), defines the measures for which the ERDF may provide  financial support;\nWhereas Article 1 of Council Regulation (EEC) No 4255/88 of 19 December 1988 laying down provisions  for implementing Regulation (EEC) No 2052/88 as regards the European Social Fund (5), as amended by  Regulation (EEC) No 2084/93 (6), defines the measures for which the ESF may provide financial  support;\nWhereas the Single Programming Document has been established in agreement with the Member State  concerned through the partnership defined in Article 4 of Regulation (EEC) No 2052/88;\nWhereas the Single Programming Document satisfies the conditions and includes the information  required by Article 14 of Regulation (EEC) No 4253/88;\nWhereas the present assistance satisfies the conditions laid down in Article 13 of Regulation (EEC)  No 4253/88, and so should be implemented by means of an integrated approach involving finance from  more than one Fund;\nWhereas Article 1 of the Financial Regulation of 21 December 1977 applicable to the general budget  of the European Communities (7), as last amended by Regulation (ECSC, EC, Euratom) No 2730/94 (8),  states that the legal commitments entered into for measures extending over more than one financial  year must contain a time limit for implementation which must be specified to the recipient in due  form when the aid is granted;\nWhereas Article 20 (3) of Regulation (EEC) No 4253/88 provides, subject to available funding, for a  single commitment where the Community assistance granted is less than ECU 40 million for the whole  programmation period;\nWhereas all the other conditions laid down for the grant of aid from the ERDF and the ESF have been  complied with,\nThe Single Programming Document for Community structural assistance  in the region of West Cumbria and Furness concerned by Objective 2 in the United Kingdom, covering  the period 1 January 1994 to 31 December 1996, is hereby approved. The Single Programming Document includes the following essential elements:\n(a) a statement of the main priorities for joint action, their specific quantified objectives, an  appraisal of their expected impact and their consistency with economic, social and regional  policies in the United Kingdom;\nthe main priorities are:\n1. industrial and business development;\n2. development of knowledge-based industries;\n3. tourism development;\n4. community economic development;\n(b) the assistance from the Structural Funds as referred to in Article 4;\n(c) the detailed provisions for implementing the Single Programming Document comprising:\n- the procedures for monitoring and evaluation,\n- the financial implementation provisions,\n- the rules for compliance with Community policies;\n(d) the procedures for verifying additionality and an initial evaluation of the latter;\n(e) the arrangements for associating the environmental authorities with the implementation of the  Single Programming Document;\n(f) the means available for technical assistance necessary for the preparation, implementation or  adaptation of the measures concerned. For the purpose of indexation, the annual breakdown of the global maximal allocation  foreseen for the assistance from the Structural Funds is as follows:\n>TABLE> The assistance from the Structural Funds granted to the Single  Programming Document amounts to a maximum of ECU 25,0 million.\nThe procedure for granting the financial assistance, including the financial contribution from the  Funds to the various priorities and measures, is set out in the financing plan and the detailed  implementing provisions which form an integral part of the Single Programming Document.\nThe national financial contribution envisaged, which is approximately ECU 26,50 million for the  public sector and ECU 13,75 million for the private sector, may be met in part by Community loans,  in particular from the ECSC and EIB. 1.  The breakdown among the Structural Funds of the total Community assistance  available is as follows:\n- ERDF:ECU 18,82 million,\n- ESF:ECU  6,18 million.\n2.  The budgetary commitments at the moment of approval of the Single Programming Document refer to  the total Community assistance. The breakdown among the Structural Funds and the procedure for the grant of the  assistance may be altered subsequently, subject to the availability of funds and the budgetary  rules, in the light of adjustments decided according to the procedure laid down in Article 25 (5)  of Regulation (EEC) No 4253/88. The Community aid concerns expenditure on operations under the Single Programming  Document which, in the Member State concerned, are the subject of legally binding commitments and  for which the requisite finance has been specifically allocated no later than 31 December 1996. The  final date for taking account of expenditure on these measures is 31 December 1998. The Single Programming Document shall be implemented in accordance with Community law,  and in particular Articles 6, 30, 48, 52 and 59 of the EC Treaty and the Community Directives on  the coordination of procedures for the award of contracts. This Decision is addressed to the United Kingdom of Great Britain and Northern  Ireland.",
         "10506",
         "Decision",
         "Decision"
        ],
        [
         "5",
         "32014D0819",
         "Decision",
         "2014/819/EU: Commission Implementing Decision of 17 November 2014 concerning the rejection of a request to cancel a name entered in the register of protected designations of origin and protected geographical indications provided for in Regulation (EU) No 1151/2012 of the European Parliament and of the Council [Jihočeská Niva (PGI)] (notified under document C(2014) 8391)\n",
         "20.11.2014 EN Official Journal of the European Union L 333/24\nCOMMISSION IMPLEMENTING DECISION\nof 17 November 2014\nconcerning the rejection of a request to cancel a name entered in the register of protected designations of origin and protected geographical indications provided for in Regulation (EU) No 1151/2012 of the European Parliament and of the Council [Jihočeská Niva (PGI)]\n(notified under document C(2014) 8391)\n(Only the Slovak text is authentic)\n(2014/819/EU)\nTHE EUROPEAN COMMISSION",
         ",\nHaving regard to the Treaty on the Functioning of the European Union,\nHaving regard to Regulation (EU) No 1151/2012 of the European Parliament and of the Council of 21 November 2012 on quality schemes for agricultural products and foodstuffs (1), and in particular Article 54(1) thereof,\nWhereas:\n(1) The first subparagraph of Article 54(1) of Regulation (EU) No 1151/2012 provides that, apart from in the case of requests from the producers of the product sold under the registered name, the Commission may cancel the registration of a protected geographical indication where compliance with the conditions of the specification is not ensured or where no product has been placed on the market under the protected geographical indication for at least seven years.\n(2) The Commission has examined the request to cancel the registration of the protected geographical indication ‘Jihočeská Niva’ submitted by Slovakia on 20 September 2013 and received on 27 September 2013.\n(3) This cancellation request does not fall within either of the two cases specified in the first subparagraph of Article 54(1) of Regulation (EU) No 1151/2012 and does not therefore meet the conditions laid down in that Article.\n(4) In view of the foregoing, the request to cancel the protected geographical indication ‘Jihočeská Niva’ submitted by Slovakia must be rejected.\n(5) The measure provided for in this Decision is in accordance with the opinion of the Committee for agricultural product quality policy,",
         "['The request to cancel the protected geographical indication ‘Jihočeská Niva’ is rejected.', 'This Decision is addressed to the Slovak Republic.']",
         "['1110', '3173', '5573', '5859', '893']",
         "train",
         "2014/819/EU: Commission Implementing Decision of 17 November 2014 concerning the rejection of a request to cancel a name entered in the register of protected designations of origin and protected geographical indications provided for in Regulation (EU) No 1151/2012 of the European Parliament and of the Council [Jihočeská Niva (PGI)] (notified under document C(2014) 8391)\n\n,\nHaving regard to the Treaty on the Functioning of the European Union,\nHaving regard to Regulation (EU) No 1151/2012 of the European Parliament and of the Council of 21 November 2012 on quality schemes for agricultural products and foodstuffs (1), and in particular Article 54(1) thereof,\nWhereas:\n(1) The first subparagraph of Article 54(1) of Regulation (EU) No 1151/2012 provides that, apart from in the case of requests from the producers of the product sold under the registered name, the Commission may cancel the registration of a protected geographical indication where compliance with the conditions of the specification is not ensured or where no product has been placed on the market under the protected geographical indication for at least seven years.\n(2) The Commission has examined the request to cancel the registration of the protected geographical indication ‘Jihočeská Niva’ submitted by Slovakia on 20 September 2013 and received on 27 September 2013.\n(3) This cancellation request does not fall within either of the two cases specified in the first subparagraph of Article 54(1) of Regulation (EU) No 1151/2012 and does not therefore meet the conditions laid down in that Article.\n(4) In view of the foregoing, the request to cancel the protected geographical indication ‘Jihočeská Niva’ submitted by Slovakia must be rejected.\n(5) The measure provided for in this Decision is in accordance with the opinion of the Committee for agricultural product quality policy,\nThe request to cancel the protected geographical indication ‘Jihočeská Niva’ is rejected. This Decision is addressed to the Slovak Republic.",
         "2002",
         "Decision",
         "Decision"
        ],
        [
         "6",
         "32007D0861",
         "Decision",
         "2007/861/EC: Council Decision of 10 December 2007 on the signing and provisional application of an Agreement in the form of an Exchange of Letters between the European Community and the Republic of Belarus amending the Agreement between the European Community and the Republic of Belarus on trade in textile products\n",
         "21.12.2007 EN Official Journal of the European Union L 337/113\nCOUNCIL DECISION\nof 10 December 2007\non the signing and provisional application of an Agreement in the form of an Exchange of Letters between the European Community and the Republic of Belarus amending the Agreement between the European Community and the Republic of Belarus on trade in textile products\n(2007/861/EC)\nTHE COUNCIL OF THE EUROPEAN UNION",
         ",\nHaving regard to the Treaty establishing the European Community, and in particular Article 133 in conjunction with Article 300(2), first sentence thereof,\nHaving regard to the proposal from the Commission,\nWhereas:\n(1) The Commission has negotiated on behalf of the Community an Agreement in the form of an Exchange of Letters to extend for one year the existing Agreement and Protocols on trade in textile products with the Republic of Belarus, with some adjustments of the quantitative limits.\n(2) The Agreement in the form of an Exchange of Letters should be applied on a provisional basis as of 1 January 2008, pending the completion of procedures required for its conclusion, subject to reciprocal provisional application by the Republic of Belarus.\n(3) The Agreement in the form of an Exchange of Letters should be signed on behalf of the Community,",
         "['Subject to its possible conclusion at a later date, the President of the Council is hereby authorised to designate the person(s) empowered to sign on behalf of the Community the Agreement in the form of an Exchange of Letters between the European Community and the Republic of Belarus amending the Agreement between the European Community and the Republic of Belarus on trade in textile products.', 'Subject to reciprocity, the Agreement in the form of an Exchange of Letters shall be applied on a provisional basis from 1 January 2008, pending its formal conclusion.\\nThe text of the Agreement in the form of an Exchange of Letters is attached to this Decision.', '1.\\xa0\\xa0\\xa0If the Republic of Belarus fails to respect paragraph 2.4 of the Agreement in the form of an Exchange of Letters, the quota for 2008 will be reduced to the levels applicable in 2007.\\n2.\\xa0\\xa0\\xa0The decision to implement paragraph 1 shall be taken in accordance with the procedures referred to in Article 17 of Council Regulation (EEC) No 3030/93 of 12 October 1993 on common rules for imports of certain textile products from third countries\\xa0(1).', 'This Decision shall be published in the Official Journal of the European Union.\\nIt shall enter into force on the day following its publication in the Official Journal of the European Union.']",
         "['2783', '3466', '3591', '5403', '5458']",
         "train",
         "2007/861/EC: Council Decision of 10 December 2007 on the signing and provisional application of an Agreement in the form of an Exchange of Letters between the European Community and the Republic of Belarus amending the Agreement between the European Community and the Republic of Belarus on trade in textile products\n\n,\nHaving regard to the Treaty establishing the European Community, and in particular Article 133 in conjunction with Article 300(2), first sentence thereof,\nHaving regard to the proposal from the Commission,\nWhereas:\n(1) The Commission has negotiated on behalf of the Community an Agreement in the form of an Exchange of Letters to extend for one year the existing Agreement and Protocols on trade in textile products with the Republic of Belarus, with some adjustments of the quantitative limits.\n(2) The Agreement in the form of an Exchange of Letters should be applied on a provisional basis as of 1 January 2008, pending the completion of procedures required for its conclusion, subject to reciprocal provisional application by the Republic of Belarus.\n(3) The Agreement in the form of an Exchange of Letters should be signed on behalf of the Community,\nSubject to its possible conclusion at a later date, the President of the Council is hereby authorised to designate the person(s) empowered to sign on behalf of the Community the Agreement in the form of an Exchange of Letters between the European Community and the Republic of Belarus amending the Agreement between the European Community and the Republic of Belarus on trade in textile products. Subject to reciprocity, the Agreement in the form of an Exchange of Letters shall be applied on a provisional basis from 1 January 2008, pending its formal conclusion.\nThe text of the Agreement in the form of an Exchange of Letters is attached to this Decision. 1.   If the Republic of Belarus fails to respect paragraph 2.4 of the Agreement in the form of an Exchange of Letters, the quota for 2008 will be reduced to the levels applicable in 2007.\n2.   The decision to implement paragraph 1 shall be taken in accordance with the procedures referred to in Article 17 of Council Regulation (EEC) No 3030/93 of 12 October 1993 on common rules for imports of certain textile products from third countries (1). This Decision shall be published in the Official Journal of the European Union.\nIt shall enter into force on the day following its publication in the Official Journal of the European Union.",
         "2470",
         "Decision",
         "Decision"
        ],
        [
         "7",
         "31988D0382",
         "Decision",
         "88/382/EEC: Council Decision of 24 June 1988 concerning a supplement, in respect of mercury originating in sectors other than the chlor-alkali electrolysis industry, to Annex IV to the Convention for the Protection of the Rhine against Chemical Pollution\n",
         "14.7.1988 EN Official Journal of the European Communities L 183/30\nCOUNCIL DECISION\nof 24 June 1988\nconcerning a supplement, in respect of mercury originating in sectors other than the chlor-alkali electrolysis industry, to Annex IV to the Convention for the Protection of the Rhine against Chemical Pollution\n(88/382/EEC)\nTHE COUNCIL OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Economic Community, and in particular Article 130 S thereof,\nHaving regard to the proposal from the Commission,\nHaving regard to the opinion of the European Parliament (1),\nHaving regard to the opinion of the Economic and Social Committee (2),\nWhereas, by Decision 77/586/EEC (3), the Community concluded the Convention for the Protection of the Rhine against Chemical Pollution, hereinafter referred to as the ‘Chemical Convention’, and the Additional Agreement to the Agreement signed in Berne on 29 April 1963 concerning the International Commission for the protection of the Rhine against Pollution, hereinafter referred to as the ‘International Commission’;\nWhereas, under Article 5 of the Convention, the International Commission proposes limit values for the discharge of certain substances into the surface waters of the Rhine basin by way of amendments to Annex IV to the Chemical Convention; whereas, under Article 14 of the Chemical Convention, unanimous acceptance by the Contracting Parties to the Convention is necessary for those amendments to enter into force;\nWhereas, in the form of a proposal designed to supplement Annex IV to the Chemical Convention, the International Commission has established limit values for mercury discharged by industries other than the chlor-alkali electrolysis industry;\nWhereas Directive 84/156/EEC (4) lays down limit values for mercury discharges by sectors other than the chlor-alkali electrolysis industry into the aquatic environment of the Community; whereas these limit values are identical to those set out in the proposal of the International Commission;\nWhereas Article 4 of that Directive requires Member States to draw up specific programmes for reduction of mercury discharges by multiple sources which are not industrial plants; whereas there are no such provisions in the proposal of the International Commission;\nWhereas it is desirable that the Community, as a Contracting Party to the Convention, adopt, the abovementioned proposal,",
         "['The proposal by the International Commission for the Protection of the Rhine against Pollution, intended to supplement, in respect of mercury originating in sectors other than the chlor-alkali electrolysis industry, Annex IV to the Convention for the Protection of the Rhine against Chemical Pollution, is hereby adopted on behalf of the European Economic Community.\\nThe text of the proposal is attached to this Decision.', 'This Decision shall be applicable without prejudice to the specific provisions in other Community rules, particularly Article 4 of Directive 84/156/EEC.', 'The President of the Council shall notify the Government of the Swiss Confederation, in accordance with the procedures laid down by the Chemical Convention, of the adoption of the proposal referred to in Article 1.']",
         "['177', '1880', '2528', '2533', '3468', '5457']",
         "train",
         "88/382/EEC: Council Decision of 24 June 1988 concerning a supplement, in respect of mercury originating in sectors other than the chlor-alkali electrolysis industry, to Annex IV to the Convention for the Protection of the Rhine against Chemical Pollution\n\n,\nHaving regard to the Treaty establishing the European Economic Community, and in particular Article 130 S thereof,\nHaving regard to the proposal from the Commission,\nHaving regard to the opinion of the European Parliament (1),\nHaving regard to the opinion of the Economic and Social Committee (2),\nWhereas, by Decision 77/586/EEC (3), the Community concluded the Convention for the Protection of the Rhine against Chemical Pollution, hereinafter referred to as the ‘Chemical Convention’, and the Additional Agreement to the Agreement signed in Berne on 29 April 1963 concerning the International Commission for the protection of the Rhine against Pollution, hereinafter referred to as the ‘International Commission’;\nWhereas, under Article 5 of the Convention, the International Commission proposes limit values for the discharge of certain substances into the surface waters of the Rhine basin by way of amendments to Annex IV to the Chemical Convention; whereas, under Article 14 of the Chemical Convention, unanimous acceptance by the Contracting Parties to the Convention is necessary for those amendments to enter into force;\nWhereas, in the form of a proposal designed to supplement Annex IV to the Chemical Convention, the International Commission has established limit values for mercury discharged by industries other than the chlor-alkali electrolysis industry;\nWhereas Directive 84/156/EEC (4) lays down limit values for mercury discharges by sectors other than the chlor-alkali electrolysis industry into the aquatic environment of the Community; whereas these limit values are identical to those set out in the proposal of the International Commission;\nWhereas Article 4 of that Directive requires Member States to draw up specific programmes for reduction of mercury discharges by multiple sources which are not industrial plants; whereas there are no such provisions in the proposal of the International Commission;\nWhereas it is desirable that the Community, as a Contracting Party to the Convention, adopt, the abovementioned proposal,\nThe proposal by the International Commission for the Protection of the Rhine against Pollution, intended to supplement, in respect of mercury originating in sectors other than the chlor-alkali electrolysis industry, Annex IV to the Convention for the Protection of the Rhine against Chemical Pollution, is hereby adopted on behalf of the European Economic Community.\nThe text of the proposal is attached to this Decision. This Decision shall be applicable without prejudice to the specific provisions in other Community rules, particularly Article 4 of Directive 84/156/EEC. The President of the Council shall notify the Government of the Swiss Confederation, in accordance with the procedures laid down by the Chemical Convention, of the adoption of the proposal referred to in Article 1.",
         "3100",
         "Decision",
         "Decision"
        ],
        [
         "8",
         "32014D0796",
         "Decision",
         "2014/796/EU: Council Implementing Decision of 7 November 2014 authorising the Republic of Latvia to apply a measure derogating from Article 287 of Directive 2006/112/EC on the common system of value added tax\n",
         "15.11.2014 EN Official Journal of the European Union L 330/46\nCOUNCIL IMPLEMENTING DECISION\nof 7 November 2014\nauthorising the Republic of Latvia to apply a measure derogating from Article 287 of Directive 2006/112/EC on the common system of value added tax\n(2014/796/EU)\nTHE COUNCIL OF THE EUROPEAN UNION",
         ",\nHaving regard to the Treaty on the Functioning of the European Union,\nHaving regard to Council Directive 2006/112/EC of 28 November 2006 on the common system of value added tax (1) (the VAT Directive), and in particular Article 395(1) thereof,\nHaving regard to the proposal from the European Commission,\nWhereas:\n(1) By letter registered with the Secretariat-General of the Commission on 1 July 2014, Latvia requested authorisation for a measure derogating from Article 287(10) of the VAT Directive in order to exempt certain taxable persons whose annual turnover is no higher than EUR 50 000 (‘the measure’). The measure would release those taxable persons from certain or all of the obligations in relation to value added tax (VAT) referred to in Chapters 2 to 6 of Title XI of the VAT Directive. Such measure had already been granted to Latvia by Council Implementing Decision 2010/584/EU (2) which expired on 31 December 2013.\n(2) By letter dated 7 August 2014, the Commission informed the other Member States of the request made by Latvia. By letter dated 11 August 2014, the Commission notified Latvia that it had all the information necessary to consider the request.\n(3) A special scheme for small enterprises is already available to Member States under Title XII of the VAT Directive. The measure derogates from Title XII of the VAT Directive only in so far as the taxable person's annual turnover threshold for the special scheme is higher than that allowed for Latvia under Article 287(10) of the VAT Directive, which is EUR 17 200.\n(4) A higher threshold for the special scheme is a simplification measure as it may significantly reduce the VAT obligations of the smallest businesses, whilst that special scheme is optional for taxable persons and allows businesses to opt for the normal VAT arrangements.\n(5) From information provided by Latvia, the derogation will only have a negligible impact on the overall amount of tax revenue collected at the final stage of consumption.\n(6) The derogation has no impact on the Union's own resources accruing from VAT,",
         "['By way of derogation from Article 287(10) of Directive 2006/112/EC, the Republic of Latvia is authorised to exempt from VAT taxable persons whose annual turnover is no higher than EUR 50\\xa0000.', 'This Decision shall take effect on the day of its notification.\\nIt shall apply until 31 December 2017.', 'This Decision is addressed to the Republic of Latvia.']",
         "['2358', '4585', '5581', '5706', '6029', '935']",
         "train",
         "2014/796/EU: Council Implementing Decision of 7 November 2014 authorising the Republic of Latvia to apply a measure derogating from Article 287 of Directive 2006/112/EC on the common system of value added tax\n\n,\nHaving regard to the Treaty on the Functioning of the European Union,\nHaving regard to Council Directive 2006/112/EC of 28 November 2006 on the common system of value added tax (1) (the VAT Directive), and in particular Article 395(1) thereof,\nHaving regard to the proposal from the European Commission,\nWhereas:\n(1) By letter registered with the Secretariat-General of the Commission on 1 July 2014, Latvia requested authorisation for a measure derogating from Article 287(10) of the VAT Directive in order to exempt certain taxable persons whose annual turnover is no higher than EUR 50 000 (‘the measure’). The measure would release those taxable persons from certain or all of the obligations in relation to value added tax (VAT) referred to in Chapters 2 to 6 of Title XI of the VAT Directive. Such measure had already been granted to Latvia by Council Implementing Decision 2010/584/EU (2) which expired on 31 December 2013.\n(2) By letter dated 7 August 2014, the Commission informed the other Member States of the request made by Latvia. By letter dated 11 August 2014, the Commission notified Latvia that it had all the information necessary to consider the request.\n(3) A special scheme for small enterprises is already available to Member States under Title XII of the VAT Directive. The measure derogates from Title XII of the VAT Directive only in so far as the taxable person's annual turnover threshold for the special scheme is higher than that allowed for Latvia under Article 287(10) of the VAT Directive, which is EUR 17 200.\n(4) A higher threshold for the special scheme is a simplification measure as it may significantly reduce the VAT obligations of the smallest businesses, whilst that special scheme is optional for taxable persons and allows businesses to opt for the normal VAT arrangements.\n(5) From information provided by Latvia, the derogation will only have a negligible impact on the overall amount of tax revenue collected at the final stage of consumption.\n(6) The derogation has no impact on the Union's own resources accruing from VAT,\nBy way of derogation from Article 287(10) of Directive 2006/112/EC, the Republic of Latvia is authorised to exempt from VAT taxable persons whose annual turnover is no higher than EUR 50 000. This Decision shall take effect on the day of its notification.\nIt shall apply until 31 December 2017. This Decision is addressed to the Republic of Latvia.",
         "2632",
         "Decision",
         "Decision"
        ],
        [
         "9",
         "32008D0973",
         "Decision",
         "2008/973/EC: Commission Decision of 15 December 2008 amending Council Directive 2002/56/EC as regards the date laid down in Article 21(3) until which Member States are authorised to extend the validity of decisions concerning equivalence of seed potatoes from third countries (notified under document number C(2008) 8135) (Text with EEA relevance)\n",
         "23.12.2008 EN Official Journal of the European Union L 345/90\nCOMMISSION DECISION\nof 15 December 2008\namending Council Directive 2002/56/EC as regards the date laid down in Article 21(3) until which Member States are authorised to extend the validity of decisions concerning equivalence of seed potatoes from third countries\n(notified under document number C(2008) 8135)\n(Text with EEA relevance)\n(2008/973/EC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Directive 2002/56/EC of 13 June 2002 on the marketing of seed potatoes (1), and in particular the second subparagraph of Article 21(3) thereof,\nWhereas:\n(1) Directive 2002/56/EC provides that, with effect from certain dates, Member States may no longer determine for themselves the equivalence of seed potatoes harvested in third countries with seed potatoes harvested within the Community and complying with that Directive.\n(2) However, as work to establish a Community equivalence for seed potatoes from all the third countries concerned had not been completed, Directive 2002/56/EC permitted Member States to extend until 31 March 2008 the validity of equivalence decisions which they had already taken for seed potatoes from certain third countries not covered by a Community equivalence. This date was chosen by reference to the end of the period where seed potatoes are placed on the market.\n(3) Since this work still has not been completed and as a new marketing season will start by the end of the year 2008, it is necessary to authorise Member States to extend the validity of their national equivalence decisions.\n(4) Directive 2002/56/EC should therefore be amended accordingly.\n(5) The measures provided for in this Decision are in accordance with the opinion of the Standing Committee on Seeds and Propagating Material for Agriculture, Horticulture and Forestry,",
         "['In the first subparagraph of Article 21(3) of Directive 2002/56/EC, ‘31 March 2008’ is replaced by ‘31 March 2011’.', 'This Decision is addressed to the Member States.']",
         "['13', '2300', '2409', '2548', '2771']",
         "train",
         "2008/973/EC: Commission Decision of 15 December 2008 amending Council Directive 2002/56/EC as regards the date laid down in Article 21(3) until which Member States are authorised to extend the validity of decisions concerning equivalence of seed potatoes from third countries (notified under document number C(2008) 8135) (Text with EEA relevance)\n\n,\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Directive 2002/56/EC of 13 June 2002 on the marketing of seed potatoes (1), and in particular the second subparagraph of Article 21(3) thereof,\nWhereas:\n(1) Directive 2002/56/EC provides that, with effect from certain dates, Member States may no longer determine for themselves the equivalence of seed potatoes harvested in third countries with seed potatoes harvested within the Community and complying with that Directive.\n(2) However, as work to establish a Community equivalence for seed potatoes from all the third countries concerned had not been completed, Directive 2002/56/EC permitted Member States to extend until 31 March 2008 the validity of equivalence decisions which they had already taken for seed potatoes from certain third countries not covered by a Community equivalence. This date was chosen by reference to the end of the period where seed potatoes are placed on the market.\n(3) Since this work still has not been completed and as a new marketing season will start by the end of the year 2008, it is necessary to authorise Member States to extend the validity of their national equivalence decisions.\n(4) Directive 2002/56/EC should therefore be amended accordingly.\n(5) The measures provided for in this Decision are in accordance with the opinion of the Standing Committee on Seeds and Propagating Material for Agriculture, Horticulture and Forestry,\nIn the first subparagraph of Article 21(3) of Directive 2002/56/EC, ‘31 March 2008’ is replaced by ‘31 March 2011’. This Decision is addressed to the Member States.",
         "1981",
         "Decision",
         "Decision"
        ],
        [
         "10",
         "31990D0294",
         "Decision",
         "90/294/EEC: Commission Decision of 20 December 1989 on the establishment of the Community support framework for Community structural assistance in the self-governing town of Emden (Federal Republic of Germany), which is eligible under Objective 2 (Only the German text is authentic)\n",
         "COMMISSION  DECISION\nof 20 December 1989\non the establishment of the Community support framework for Community structural assistance in the self-governing town of Emden (Federal Republic of Germany), which is eligible under Objective 2\n(Only the German text is authentic)\n(90/294/EEC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Regulation (EEC) No 2052/88 of 24 June 1988 on the tasks of the Structural Funds and their effectiveness and on coordination of their activities between themselves and with the operations of the European Investment Bank and the other existing financial instruments (1), and in particular Article 9 (9) thereof,\nWhereas, in accordance with Article 9 (9) of Regulation (EEC) No 2052/88, the Commission, on the basis of the regional and social conversion plans submitted by the Member States, shall establish, through partnership and in agreement with the Membe State concerned, the Community support frameworks for Community structural operations;\nWhereas, in accordance with the second subparagraph of that provision, Community support frameworks shall cover in particular the priorities, the forms of assistance, the indicative financing plan, with details of the amount of assistance and its source, and the duration of the assistance;\nWhereas Title III, Articles 8 et seq. of Council Regulation (EEC) No 4253/88 (2) of 19 December 1988 laying down provisions for implementing Regulation (EEC) No 2052/88 as regards coordination of the activities of the different Structural Funds between themselves and with the operations of the European Investment Bank and the other existing financial instruments (2) sets out the conditions for the preparation and implementation of Community support frameworks;\nWhereas the Government of the Federal Republic of Germany submitted to the Commission on 31 March 1989, pursuant to Article 9 (8) of Regulation (EEC) No 2052/88, the regional and social conversion plan for the self-governing town of Emden (Federal Republic of Germany) which, as decided by the Commission under Decision 89/288/EEC (3) in accordance with the procedure referred to in Article 9 (2) and (3) of the said Regulation, is eligible under Objective 2;\nWhereas the plan submitted by the Member State includes a description of the priorities selected and an indication of the use to be made of assistance from the European Regional Development Fund (ERDF), the European Social Fund (ESF) and the European Investment Bank (EIB) and the other financial instruments in implementing the plan;\nWhereas this Community support framework has been established in agreement with the Member State concerned through the partnership defined in Article 4 of Regulation (EEC) No 2052/88;\nWhereas the EIB has also been involved in the preparation of the Community support framework in accordance with Article 8 of Regulation (EEC) No 4253/88; whereas it has declared its readiness to help implement the frame\nwork on the basis of the estimated loan arrangements indicated in this Decision and in accordance with the provisions of its Statute;\nWhereas the Commission is prepared to examine the possibility of the other Community lending instruments contributing to the financing of this framework in accordance with the specific provisions governing them;\nWhereas this Decision is consistent with the opinion of the Advisory Committee on the Development and Conversion of Regions and of the European Social Fund Committee;\nWhereas, in accordance with Article 10 (2) of Regulation (EEC) No 4253/88, this Decision is to be sent as a declaration of intent to the Member State;\nWhereas, in accordance with Article 20 (1) and (2) of Regulation (EEC) No 4253/88, the budgetary commitments relating to the contribution from the Structural Funds to the financing of the operations covered by the Community support framework will be made on the basis of subsequent Commission Decisions approving the operations concerned,",
         "['The Support Framework for the self-governing town of Emden (Federal Republic of Germany), which is eligible under Objective 2, covering the period from 1 January 1989 to 31 December 1991, is hereby approved.\\nThe Commission declares that it intends to contribute to the implementation of this Community Support Framework in accordance with the detailed provisions thereof and in compliance with the rules and guidelines for each Community source of financing.', 'The Community support framework shall include the following essential information:\\n(a) a statement of the priorities for joint action:\\n- development and for rehabilitation of industrial estates,\\n- diversification of the industrial structure;\\n(b) an outline of the forms of assistance to be provided, in the form of operational programmes;\\n(c) an indicative financing plan specifying, at constant 1989 prices, the total cost of the priorities adopted for joint action by the Community and the Member State concerned and, in addition, of existing multiannual national initiatives, that is ECU 6,2 million for the whole period, and the financial arrangements envisaged for budgetary assistance from the Community, broken down as follows:\\n(in ECU million)\\n1.2 //  //  // ERDF   // 1,6   // ESF   // 0,7   //    //  // Total for Structural Funds  // 2,3   // Other grant instruments   // -   //    //   // Total grants  // 2,3   //  //\\nThe resultant national financing requirement, that is approximately ECU 3,9 million for the public sector and ECU - million for the private sector, may be partially covered by Community loans from the European Investment Bank and the other lending instruments.', 'This declaration of intent is addressed to the Federal Republic of Germany.']",
         "['1052', '1329', '2518', '4825']",
         "train",
         "90/294/EEC: Commission Decision of 20 December 1989 on the establishment of the Community support framework for Community structural assistance in the self-governing town of Emden (Federal Republic of Germany), which is eligible under Objective 2 (Only the German text is authentic)\n\n,\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Regulation (EEC) No 2052/88 of 24 June 1988 on the tasks of the Structural Funds and their effectiveness and on coordination of their activities between themselves and with the operations of the European Investment Bank and the other existing financial instruments (1), and in particular Article 9 (9) thereof,\nWhereas, in accordance with Article 9 (9) of Regulation (EEC) No 2052/88, the Commission, on the basis of the regional and social conversion plans submitted by the Member States, shall establish, through partnership and in agreement with the Membe State concerned, the Community support frameworks for Community structural operations;\nWhereas, in accordance with the second subparagraph of that provision, Community support frameworks shall cover in particular the priorities, the forms of assistance, the indicative financing plan, with details of the amount of assistance and its source, and the duration of the assistance;\nWhereas Title III, Articles 8 et seq. of Council Regulation (EEC) No 4253/88 (2) of 19 December 1988 laying down provisions for implementing Regulation (EEC) No 2052/88 as regards coordination of the activities of the different Structural Funds between themselves and with the operations of the European Investment Bank and the other existing financial instruments (2) sets out the conditions for the preparation and implementation of Community support frameworks;\nWhereas the Government of the Federal Republic of Germany submitted to the Commission on 31 March 1989, pursuant to Article 9 (8) of Regulation (EEC) No 2052/88, the regional and social conversion plan for the self-governing town of Emden (Federal Republic of Germany) which, as decided by the Commission under Decision 89/288/EEC (3) in accordance with the procedure referred to in Article 9 (2) and (3) of the said Regulation, is eligible under Objective 2;\nWhereas the plan submitted by the Member State includes a description of the priorities selected and an indication of the use to be made of assistance from the European Regional Development Fund (ERDF), the European Social Fund (ESF) and the European Investment Bank (EIB) and the other financial instruments in implementing the plan;\nWhereas this Community support framework has been established in agreement with the Member State concerned through the partnership defined in Article 4 of Regulation (EEC) No 2052/88;\nWhereas the EIB has also been involved in the preparation of the Community support framework in accordance with Article 8 of Regulation (EEC) No 4253/88; whereas it has declared its readiness to help implement the frame\nwork on the basis of the estimated loan arrangements indicated in this Decision and in accordance with the provisions of its Statute;\nWhereas the Commission is prepared to examine the possibility of the other Community lending instruments contributing to the financing of this framework in accordance with the specific provisions governing them;\nWhereas this Decision is consistent with the opinion of the Advisory Committee on the Development and Conversion of Regions and of the European Social Fund Committee;\nWhereas, in accordance with Article 10 (2) of Regulation (EEC) No 4253/88, this Decision is to be sent as a declaration of intent to the Member State;\nWhereas, in accordance with Article 20 (1) and (2) of Regulation (EEC) No 4253/88, the budgetary commitments relating to the contribution from the Structural Funds to the financing of the operations covered by the Community support framework will be made on the basis of subsequent Commission Decisions approving the operations concerned,\nThe Support Framework for the self-governing town of Emden (Federal Republic of Germany), which is eligible under Objective 2, covering the period from 1 January 1989 to 31 December 1991, is hereby approved.\nThe Commission declares that it intends to contribute to the implementation of this Community Support Framework in accordance with the detailed provisions thereof and in compliance with the rules and guidelines for each Community source of financing. The Community support framework shall include the following essential information:\n(a) a statement of the priorities for joint action:\n- development and for rehabilitation of industrial estates,\n- diversification of the industrial structure;\n(b) an outline of the forms of assistance to be provided, in the form of operational programmes;\n(c) an indicative financing plan specifying, at constant 1989 prices, the total cost of the priorities adopted for joint action by the Community and the Member State concerned and, in addition, of existing multiannual national initiatives, that is ECU 6,2 million for the whole period, and the financial arrangements envisaged for budgetary assistance from the Community, broken down as follows:\n(in ECU million)\n1.2 //  //  // ERDF   // 1,6   // ESF   // 0,7   //    //  // Total for Structural Funds  // 2,3   // Other grant instruments   // -   //    //   // Total grants  // 2,3   //  //\nThe resultant national financing requirement, that is approximately ECU 3,9 million for the public sector and ECU - million for the private sector, may be partially covered by Community loans from the European Investment Bank and the other lending instruments. This declaration of intent is addressed to the Federal Republic of Germany.",
         "5715",
         "Decision",
         "Decision"
        ],
        [
         "11",
         "31987D0122",
         "Decision",
         "87/122/EEC: Council Decision of 9 February 1987 on the conclusion of the second Exchange of Letters complementing the Agreement between the European Economic Community and New Zealand on trade in mutton, lamb and goatmeat and comprising an understanding relevant to the first subparagraph of clause 2 of that Agreement\n",
         "COUNCIL  DECISION\nof 9 February 1987\non the conclusion of the second Exchange of Letters complementing the Agreement between the European Economic Community and New Zealand on trade in mutton, lamb and goatmeat and comprising an understanding relevant to the first subparagraph of clause 2 of that Agreement\n(87/122/EEC)\nTHE COUNCIL OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Economic Community, and in particular Article 113 thereof,\nHaving regard to the recommendation from the Commission,\nWhereas, under the voluntary restraint Agreement concluded with the European Economic Community on mutton, lamb and goatmeat (1). New Zealand undertook, in an Exchange of Letters (2), to limit the amount of its exports to certain Community markets considered to be sensitive areas; whereas, however, this undertaking provides that the quantities for 1987 and 1988 be fixed by 1 August 1986;\nWhereas the Commission has conducted negotiations to that end with New Zealand and whereas these negotiations resulted in the initialling of an Exchange of Letters with that country,",
         "['1. The second Exchange of Letters complementing the Agreement between the European Economic Community and New Zealand on trade in mutton, lamb and goatmeat and comprising an understanding relevant to the first subparagraph of clause 2 of that Agreement is hereby approved on behalf of the Community.\\n2. The text of the Exchange of Letters is attached to this Decision.', 'The President of the Council is hereby authorized to designate the person empowered to sign the Exchange of Letters referred to in Article 1 in order to bind the Community.']",
         "['2089', '4683', '4691']",
         "train",
         "87/122/EEC: Council Decision of 9 February 1987 on the conclusion of the second Exchange of Letters complementing the Agreement between the European Economic Community and New Zealand on trade in mutton, lamb and goatmeat and comprising an understanding relevant to the first subparagraph of clause 2 of that Agreement\n\n,\nHaving regard to the Treaty establishing the European Economic Community, and in particular Article 113 thereof,\nHaving regard to the recommendation from the Commission,\nWhereas, under the voluntary restraint Agreement concluded with the European Economic Community on mutton, lamb and goatmeat (1). New Zealand undertook, in an Exchange of Letters (2), to limit the amount of its exports to certain Community markets considered to be sensitive areas; whereas, however, this undertaking provides that the quantities for 1987 and 1988 be fixed by 1 August 1986;\nWhereas the Commission has conducted negotiations to that end with New Zealand and whereas these negotiations resulted in the initialling of an Exchange of Letters with that country,\n1. The second Exchange of Letters complementing the Agreement between the European Economic Community and New Zealand on trade in mutton, lamb and goatmeat and comprising an understanding relevant to the first subparagraph of clause 2 of that Agreement is hereby approved on behalf of the Community.\n2. The text of the Exchange of Letters is attached to this Decision. The President of the Council is hereby authorized to designate the person empowered to sign the Exchange of Letters referred to in Article 1 in order to bind the Community.",
         "1607",
         "Decision",
         "Decision"
        ],
        [
         "12",
         "32008D0326",
         "Decision",
         "2008/326/EC: Commission Decision of 11 April 2008 adjusting the weightings applicable from 1 February 2007 , 1 March 2007 , 1 April 2007 , 1 May 2007 and 1 June 2007 to the remuneration of officials, temporary staff and contract staff of the European Communities serving in third countries\n",
         "24.4.2008 EN Official Journal of the European Union L 112/26\nCOMMISSION DECISION\nof 11 April 2008\nadjusting the weightings applicable from 1 February 2007, 1 March 2007, 1 April 2007, 1 May 2007 and 1 June 2007 to the remuneration of officials, temporary staff and contract staff of the European Communities serving in third countries\n(2008/326/EC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Community,\nHaving regard to the Staff Regulations of officials of the European Communities and the conditions of employment of other servants of the Communities laid down by Regulation (EEC, Euratom, ECSC) No 259/68 (1), and in particular the second paragraph of Article 13 of Annex X thereto,\nWhereas:\n(1) Pursuant to the first paragraph of Article 13 of Annex X to the Staff Regulations, the weightings to be applied from 1 July 2006 to the remuneration of officials, temporary staff and contract staff of the European Communities serving in third countries payable in the currency of their country of employment were laid down by Council Regulation (EC) No 453/2007 (2).\n(2) Some of these weightings need to be adjusted in accordance with the second paragraph of Article 13 of Annex X to the Staff Regulations, with effect from 1 February, 1 March, 1 April, 1 May and 1 June 2007, since the statistics available to the Commission show that in certain third countries the variation in the cost of living measured on the basis of the weighting and the corresponding exchange rate has exceeded 5 % since weightings were last laid down or adjusted,",
         "['With effect from 1 February, 1 March, 1 April, 1 May and 1 June 2007 the weightings applied to the remuneration of officials, temporary staff and contract staff of the European Communities serving in third countries, payable in the currency of the country of employment, shall be those set out in the Annex hereto.\\nThe exchange rates for the calculation of such remuneration shall be established in accordance with the rules for the implementation of the Financial Regulation and shall correspond to the date referred to in the first paragraph.']",
         "['1026', '1048', '2300', '4271', '5251']",
         "train",
         "2008/326/EC: Commission Decision of 11 April 2008 adjusting the weightings applicable from 1 February 2007 , 1 March 2007 , 1 April 2007 , 1 May 2007 and 1 June 2007 to the remuneration of officials, temporary staff and contract staff of the European Communities serving in third countries\n\n,\nHaving regard to the Treaty establishing the European Community,\nHaving regard to the Staff Regulations of officials of the European Communities and the conditions of employment of other servants of the Communities laid down by Regulation (EEC, Euratom, ECSC) No 259/68 (1), and in particular the second paragraph of Article 13 of Annex X thereto,\nWhereas:\n(1) Pursuant to the first paragraph of Article 13 of Annex X to the Staff Regulations, the weightings to be applied from 1 July 2006 to the remuneration of officials, temporary staff and contract staff of the European Communities serving in third countries payable in the currency of their country of employment were laid down by Council Regulation (EC) No 453/2007 (2).\n(2) Some of these weightings need to be adjusted in accordance with the second paragraph of Article 13 of Annex X to the Staff Regulations, with effect from 1 February, 1 March, 1 April, 1 May and 1 June 2007, since the statistics available to the Commission show that in certain third countries the variation in the cost of living measured on the basis of the weighting and the corresponding exchange rate has exceeded 5 % since weightings were last laid down or adjusted,\nWith effect from 1 February, 1 March, 1 April, 1 May and 1 June 2007 the weightings applied to the remuneration of officials, temporary staff and contract staff of the European Communities serving in third countries, payable in the currency of the country of employment, shall be those set out in the Annex hereto.\nThe exchange rates for the calculation of such remuneration shall be established in accordance with the rules for the implementation of the Financial Regulation and shall correspond to the date referred to in the first paragraph.",
         "2039",
         "Decision",
         "Decision"
        ],
        [
         "13",
         "32005D0735",
         "Decision",
         "2005/735/EC: Council Decision of 20 September 2005 concerning the conclusion of a Protocol to the Euro-Mediterranean Agreement establishing an Association between the European Communities and their Member States, of the one part, and the Hashemite Kingdom of Jordan, of the other part, to take account of the accession of the Czech Republic, the Republic of Estonia, the Republic of Cyprus, the Republic of Latvia, the Republic of Lithuania, the Republic of Hungary, the Republic of Malta, the Republic of Poland, the Republic of Slovenia, and the Slovak Republic to the European Union\n",
         "26.10.2005 EN Official Journal of the European Union L 283/1\nCOUNCIL DECISION\nof 20 September 2005\nconcerning the conclusion of a Protocol to the Euro-Mediterranean Agreement establishing an Association between the European Communities and their Member States, of the one part, and the Hashemite Kingdom of Jordan, of the other part, to take account of the accession of the Czech Republic, the Republic of Estonia, the Republic of Cyprus, the Republic of Latvia, the Republic of Lithuania, the Republic of Hungary, the Republic of Malta, the Republic of Poland, the Republic of Slovenia, and the Slovak Republic to the European Union\n(2005/735/EC)\nTHE COUNCIL OF THE EUROPEAN UNION",
         ",\nHaving regard to the Treaty establishing the European Community, and in particular Article 310 in conjunction with the second sentence of Article 300(2), first subparagraph, and the second subparagraph of Article 300(3) thereof,\nHaving regard to the 2003 Act of Accession, and in particular Article 6(2) thereof,\nHaving regard to the proposal from the Commission,\nHaving regard to the assent of the European Parliament (1),\nWhereas:\n(1) The Protocol to the Euro-Mediterranean Agreement establishing an Association between the European Communities and their Member States, of the one part, and the Hashemite Kingdom of Jordan, of the other part, was signed on behalf of the European Community and its Member States on 31 May 2005.\n(2) The Protocol should be approved,",
         "['The Protocol to the Euro-Mediterranean Agreement establishing an Association between the European Communities and their Member States, of the one part, and the Hashemite Kingdom of Jordan, of the other part, to take account of the accession of the Czech Republic, the Republic of Estonia, the Republic of Cyprus, the Republic of Latvia, the Republic of Lithuania, the Republic of Hungary, the Republic of Malta, the Republic of Poland, the Republic of Slovenia, and the Slovak Republic to the European Union, is hereby approved on behalf of the European Community and\\xa0its Member States.\\nThe text of the Protocol is attached to this Decision\\xa0(2).']",
         "['12', '1532', '2850', '2901', '4048']",
         "train",
         "2005/735/EC: Council Decision of 20 September 2005 concerning the conclusion of a Protocol to the Euro-Mediterranean Agreement establishing an Association between the European Communities and their Member States, of the one part, and the Hashemite Kingdom of Jordan, of the other part, to take account of the accession of the Czech Republic, the Republic of Estonia, the Republic of Cyprus, the Republic of Latvia, the Republic of Lithuania, the Republic of Hungary, the Republic of Malta, the Republic of Poland, the Republic of Slovenia, and the Slovak Republic to the European Union\n\n,\nHaving regard to the Treaty establishing the European Community, and in particular Article 310 in conjunction with the second sentence of Article 300(2), first subparagraph, and the second subparagraph of Article 300(3) thereof,\nHaving regard to the 2003 Act of Accession, and in particular Article 6(2) thereof,\nHaving regard to the proposal from the Commission,\nHaving regard to the assent of the European Parliament (1),\nWhereas:\n(1) The Protocol to the Euro-Mediterranean Agreement establishing an Association between the European Communities and their Member States, of the one part, and the Hashemite Kingdom of Jordan, of the other part, was signed on behalf of the European Community and its Member States on 31 May 2005.\n(2) The Protocol should be approved,\nThe Protocol to the Euro-Mediterranean Agreement establishing an Association between the European Communities and their Member States, of the one part, and the Hashemite Kingdom of Jordan, of the other part, to take account of the accession of the Czech Republic, the Republic of Estonia, the Republic of Cyprus, the Republic of Latvia, the Republic of Lithuania, the Republic of Hungary, the Republic of Malta, the Republic of Poland, the Republic of Slovenia, and the Slovak Republic to the European Union, is hereby approved on behalf of the European Community and its Member States.\nThe text of the Protocol is attached to this Decision (2).",
         "2001",
         "Decision",
         "Decision"
        ],
        [
         "14",
         "31975D0156",
         "Decision",
         "75/156/ECSC: Commission Decision of 16 December 1974 on the acquisition by the Federal Republic of Germany of a majority shareholding in Gelsenberg AG, Essen (Only the German text is authentic)\n",
         "COMMISSION DECISION  of 16 December 1974  on the acquisition by the Federal Republic of Germany of a majority shareholding in Gelsenberg AG, Essen  (Only the German text is authentic)  (75/156/ECSC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Coal and Steel Community, and in particular Articles 66 and 80 thereof;\nHaving regard to Decision No 24/54 of 6 May 1954 laying down in implementation of Article 66 (1) of the Treaty a Regulation on what constitutes control of an undertaking;\nHaving regard to the communication from the Government of the Federal Republic of Germany of 13 March 1974 concerning its intention to acquire a majority shareholding in Gelsenberg AG, Essen;\nWhereas:    1. Through a number of State-controlled undertakings the Federal Republic of Germany engages in the production and distribution of coal. It owns:      - a controlling 40 % holding in Vereinigte Elektrizitäts- und Bergwerks-Aktiengesellschaft (VEBA), Bonn and Berlin ; the remainder of VEBA's shares is dispersed over a large number of holdings. VEBA holds 99.1 % of the share capital of Hugo Stinnes AG, Mülheim, an undertaking engaged in the wholesale coal trade, which itself holds controlling interests in this field. VEBA also has a 14.1 % share in the capital of the coalproducing undertaking Ruhrkohle AG;\n- about 83 % of the share capital of Vereinigte Industrie-Unternehmungen Aktiengesellschaft (VIAG), Berlin.\nTogether with VIAG, VEBA controls Braunschweigische Kohlenbergwerke (BKB), Helmstedt. BKB stopped production of brown coal briquettes on 1 April 1974, but it controls other smaller distribution undertakings within the meaning of Article 80 of the Treaty.\nBKB, together with VEBA, also controls BKB/Stinnes-Stromeyer GmbH, which is also a coal wholesaler.\nThe Federal Republic of Germany also owns:      - 76 % of the shares of Saarbergwerke AG, Saarbrücken, which is a coal-producing undertaking within the meaning of Article 80 of the Treaty. Saarbergwerke has a majority holding in several coal distribution undertakings within the meaning of Article 80;\n- 100 % of the share capital of Salzgitter AG, which has a 10.8 % holding in Ruhrkohle AG.\n2. Gelsenberg AG is a group with activities in the fields of hydrocarbons, chemicals, nuclear processing/electricity generation, inland waterways, transport and distribution ; 48.3 % of its shares are held by Rheinisch-Westfälische Elektrizitätswerk-Aktiengesellschaft (RWE), Essen. The remainder of the shares is dispersed over a number of holdings. Its whollyowned subsidiary Raab Karcher GmbH is a coal distri-  bution undertaking within the meaning of Article 80 of the Treaty. Raab Karcher GmbH has links with Bayerische Brennstoffhandel GmbH KG and Hansen Neuerburg Export-Import GmbH OHG : these last two undertakings are controlled jointly by Raab Karcher and other firms. Gelsenberg AG also has a 13.55 % holding in Ruhrkohle AG.\n3. The Federal Government proposes to acquire 51.3 % of the share capital of Gelsenberg AG. The combination of Gelsenberg AG and VEBA is designed to produce a viable large-scale group whose activities would centre on oil and electricity production. Since a merger of the two undertakings means the combination of their coal production and distribution businesses too, this constitutes a concentration within the meaning of Article 66 (1).\nThe Federal Government controls, directly or indirectly, other undertakings within the meaning of Article 80. With regard however to these holdings of the Federal Government it should be noted that the undertakings controlled by the Government are not subject to any central planning or decision-making authority but are operated as economically independent undertakings. Although therefore VEBA, Vereinigte Industrie-Unternehmungen AG, Saarbergwerke AG and Salzgitter AG are effectively linked to each other, nevertheless the connection does not bring about any restrictive effect on competition. Consequently, assessment of the concentration can be confined to the integration of Gelsenberg AG into VEBA.\n4. VEBA and Gelsenberg AG, like all shareholders of Ruhrkohle AG, were formerly mining companies and transferred their mining holdings to Ruhrkohle AG in 1969. Like the many other shareholders, they do not have a large enough shareholding to control Ruhrkohle AG. Acquisition of holdings in Gelsenberg AG will, however, give the Federal Government a further 13.55 % of the shares of Ruhrkohle AG. The undertakings controlled by the Federal Government will then hold approximately 39 % of the capital of Ruhrkohle and will undoubtedly have a considerable influence on its business policy. However, there are no indications that the Government of the Federal Republic of Germany could use its strengthened position to modify the supply conditions of Ruhrkohle AG so as to favour the merchants controlled by it. In addition the terms of business of Ruhrkohle AG as authorized by the Commission (1) ensure equal treatment for all wholesalers in terms of direct purchasing from Ruhrkohle AG.\nThe change in the pattern of ownership of Ruhrkohle AG will thus not give the VEBA/Gelsenberg AG Group any advantage as regards access to production.\n5. To judge by 1973 figures, annual sales of solid fuels on the relevant market (the Federal Republic of Germany) can be expected to be as follows: >PIC FILE= \"T0004905\">\nThe total sales of approximately ... metric tons per annum by the two undertakings to be merged represent some 33 % of total sales by coal wholesalers on the relevant market. This share of the wholesale market will be the largest in the Federal Republic. However there are seven other coal wholesalers in the Federal Republic with market shares of between 5 and 10 %. And there are about 150 smaller undertakings. Consequently, and because these wholesalers are widely scattered throughout the Federal Republic of Germany consumers still have a wide choice in covering their requirements for solid fuels despite the concentration amounting to 33 % of the market.\nVEBA/Gelsenberg AG are not in a position to fix prices for solid fuels. Of the approximately... metric tons of solid fuels sold in 1973, about... metric tons were produced in the Community. Since the trade margin allowed for this coal by the main supplier fields is only about 4 % of the list price, the two undertakings cannot sell at much below list price. On the other hand, VEBA/Gelsenberg AG can only raise prices as far as the competition from fuel oil allows, because for many years the price of fuel oil has been well below that of Community coal. This applies also, though to a lesser extent, to the approximately ... metric tons of coal imported in 1973. VEBA/Gelsenberg AG account for approximately ... % of the market in coal imports from non-Community countries - a market position of much the same strength as their position in the wholesale coal business as a whole. However, prices for imported coal from the duty-free import quota have invariably been above the price for fuel oil. The only exception is coal from state-trading countries, some of which has been imported at the same price as fuel oil.\nThis price situation has changed substantially the wholesale fuel trade in two ways : most consumers have converted their installations to use fuel-oil or modified them to use either solid or liquid fuels. As a result the coal wholesalers in Germany sold about 49 000 000 metric tons of fuel oil in 1973 in addition to solid fuels. This means that currently only about 30  (1)OJ No L 120, 7.5.1973, p. 14.\nto 32 % of sales by coal wholesalers (ton for ton) is accounted for by solid fuels : by far the greater part of their business is in fuel oil. The oil companies, however, also sold about 33 000 000 metric tons direct rather than through coal wholesalers. As a result there is less opportunity today for a wholesaler to exploit a strong market position. The possibility of substituting fuel oil for solid fuel and the appearance of new competitors in the market ensure a sufficently competitive situation. This competition among wholesalers is primarily in terms of the variety of their supplies, their reputation for delivery on time, quality, delivery arrangements and their treatment of complaints.\nIn determining whether the merger of the two undertakings might afford them other exceptional competitive advantage, consideration should be given to the fact that they have their own inland waterway vessels. VEBA and Gelsenberg AG have a carrying capacity of their own which enabled them in 1971 to transport about ... % and ... % respectively of total shipments by German firms within the Federal Republic of Germany and to and from foreign ports. However, less than 20 % of the solid fuels sold in the Federal Republic of Germany is shipped by water, and VEBA and Gelsenberg AG each carried less than ... % of their solid fuels sales in their own vessels. Another pointer indicating that the two undertakings will not gain a privileged position through the use of their own vessels is the fact that on inland waterways the supply of cargo space exceeds demand and VEBA/Gelsenberg AG have no direct influence on transport charges since waterway freight charges, where not fixed at set rates (as in German domestic traffic), are determined freely on the freight market. Given this market structure and this relationship between supply and demand, the two undertakings have virtually no scope for granting special terms to buyers to make use of their transport facilities.\n6. Consequently, the merger will not enable the undertakings involved to determine prices or to control or restrict distribution in a substantial part of the solid fuel market or to evade the rules of competition instituted under the Treaty. Also, it will not give them an artificially privileged position affording a substantial advantage in access to supplies or markets,",
         "['The Federal Republic of Germany is authorized to acquire a majority of the shares of Gelsenberg AG, Essen.', 'This Decision is addressed to the Federal Republic of Germany.']",
         "['1318', '1414', '2264', '3783', '830']",
         "train",
         "75/156/ECSC: Commission Decision of 16 December 1974 on the acquisition by the Federal Republic of Germany of a majority shareholding in Gelsenberg AG, Essen (Only the German text is authentic)\n\n,\nHaving regard to the Treaty establishing the European Coal and Steel Community, and in particular Articles 66 and 80 thereof;\nHaving regard to Decision No 24/54 of 6 May 1954 laying down in implementation of Article 66 (1) of the Treaty a Regulation on what constitutes control of an undertaking;\nHaving regard to the communication from the Government of the Federal Republic of Germany of 13 March 1974 concerning its intention to acquire a majority shareholding in Gelsenberg AG, Essen;\nWhereas:    1. Through a number of State-controlled undertakings the Federal Republic of Germany engages in the production and distribution of coal. It owns:      - a controlling 40 % holding in Vereinigte Elektrizitäts- und Bergwerks-Aktiengesellschaft (VEBA), Bonn and Berlin ; the remainder of VEBA's shares is dispersed over a large number of holdings. VEBA holds 99.1 % of the share capital of Hugo Stinnes AG, Mülheim, an undertaking engaged in the wholesale coal trade, which itself holds controlling interests in this field. VEBA also has a 14.1 % share in the capital of the coalproducing undertaking Ruhrkohle AG;\n- about 83 % of the share capital of Vereinigte Industrie-Unternehmungen Aktiengesellschaft (VIAG), Berlin.\nTogether with VIAG, VEBA controls Braunschweigische Kohlenbergwerke (BKB), Helmstedt. BKB stopped production of brown coal briquettes on 1 April 1974, but it controls other smaller distribution undertakings within the meaning of Article 80 of the Treaty.\nBKB, together with VEBA, also controls BKB/Stinnes-Stromeyer GmbH, which is also a coal wholesaler.\nThe Federal Republic of Germany also owns:      - 76 % of the shares of Saarbergwerke AG, Saarbrücken, which is a coal-producing undertaking within the meaning of Article 80 of the Treaty. Saarbergwerke has a majority holding in several coal distribution undertakings within the meaning of Article 80;\n- 100 % of the share capital of Salzgitter AG, which has a 10.8 % holding in Ruhrkohle AG.\n2. Gelsenberg AG is a group with activities in the fields of hydrocarbons, chemicals, nuclear processing/electricity generation, inland waterways, transport and distribution ; 48.3 % of its shares are held by Rheinisch-Westfälische Elektrizitätswerk-Aktiengesellschaft (RWE), Essen. The remainder of the shares is dispersed over a number of holdings. Its whollyowned subsidiary Raab Karcher GmbH is a coal distri-  bution undertaking within the meaning of Article 80 of the Treaty. Raab Karcher GmbH has links with Bayerische Brennstoffhandel GmbH KG and Hansen Neuerburg Export-Import GmbH OHG : these last two undertakings are controlled jointly by Raab Karcher and other firms. Gelsenberg AG also has a 13.55 % holding in Ruhrkohle AG.\n3. The Federal Government proposes to acquire 51.3 % of the share capital of Gelsenberg AG. The combination of Gelsenberg AG and VEBA is designed to produce a viable large-scale group whose activities would centre on oil and electricity production. Since a merger of the two undertakings means the combination of their coal production and distribution businesses too, this constitutes a concentration within the meaning of Article 66 (1).\nThe Federal Government controls, directly or indirectly, other undertakings within the meaning of Article 80. With regard however to these holdings of the Federal Government it should be noted that the undertakings controlled by the Government are not subject to any central planning or decision-making authority but are operated as economically independent undertakings. Although therefore VEBA, Vereinigte Industrie-Unternehmungen AG, Saarbergwerke AG and Salzgitter AG are effectively linked to each other, nevertheless the connection does not bring about any restrictive effect on competition. Consequently, assessment of the concentration can be confined to the integration of Gelsenberg AG into VEBA.\n4. VEBA and Gelsenberg AG, like all shareholders of Ruhrkohle AG, were formerly mining companies and transferred their mining holdings to Ruhrkohle AG in 1969. Like the many other shareholders, they do not have a large enough shareholding to control Ruhrkohle AG. Acquisition of holdings in Gelsenberg AG will, however, give the Federal Government a further 13.55 % of the shares of Ruhrkohle AG. The undertakings controlled by the Federal Government will then hold approximately 39 % of the capital of Ruhrkohle and will undoubtedly have a considerable influence on its business policy. However, there are no indications that the Government of the Federal Republic of Germany could use its strengthened position to modify the supply conditions of Ruhrkohle AG so as to favour the merchants controlled by it. In addition the terms of business of Ruhrkohle AG as authorized by the Commission (1) ensure equal treatment for all wholesalers in terms of direct purchasing from Ruhrkohle AG.\nThe change in the pattern of ownership of Ruhrkohle AG will thus not give the VEBA/Gelsenberg AG Group any advantage as regards access to production.\n5. To judge by 1973 figures, annual sales of solid fuels on the relevant market (the Federal Republic of Germany) can be expected to be as follows: >PIC FILE= \"T0004905\">\nThe total sales of approximately ... metric tons per annum by the two undertakings to be merged represent some 33 % of total sales by coal wholesalers on the relevant market. This share of the wholesale market will be the largest in the Federal Republic. However there are seven other coal wholesalers in the Federal Republic with market shares of between 5 and 10 %. And there are about 150 smaller undertakings. Consequently, and because these wholesalers are widely scattered throughout the Federal Republic of Germany consumers still have a wide choice in covering their requirements for solid fuels despite the concentration amounting to 33 % of the market.\nVEBA/Gelsenberg AG are not in a position to fix prices for solid fuels. Of the approximately... metric tons of solid fuels sold in 1973, about... metric tons were produced in the Community. Since the trade margin allowed for this coal by the main supplier fields is only about 4 % of the list price, the two undertakings cannot sell at much below list price. On the other hand, VEBA/Gelsenberg AG can only raise prices as far as the competition from fuel oil allows, because for many years the price of fuel oil has been well below that of Community coal. This applies also, though to a lesser extent, to the approximately ... metric tons of coal imported in 1973. VEBA/Gelsenberg AG account for approximately ... % of the market in coal imports from non-Community countries - a market position of much the same strength as their position in the wholesale coal business as a whole. However, prices for imported coal from the duty-free import quota have invariably been above the price for fuel oil. The only exception is coal from state-trading countries, some of which has been imported at the same price as fuel oil.\nThis price situation has changed substantially the wholesale fuel trade in two ways : most consumers have converted their installations to use fuel-oil or modified them to use either solid or liquid fuels. As a result the coal wholesalers in Germany sold about 49 000 000 metric tons of fuel oil in 1973 in addition to solid fuels. This means that currently only about 30  (1)OJ No L 120, 7.5.1973, p. 14.\nto 32 % of sales by coal wholesalers (ton for ton) is accounted for by solid fuels : by far the greater part of their business is in fuel oil. The oil companies, however, also sold about 33 000 000 metric tons direct rather than through coal wholesalers. As a result there is less opportunity today for a wholesaler to exploit a strong market position. The possibility of substituting fuel oil for solid fuel and the appearance of new competitors in the market ensure a sufficently competitive situation. This competition among wholesalers is primarily in terms of the variety of their supplies, their reputation for delivery on time, quality, delivery arrangements and their treatment of complaints.\nIn determining whether the merger of the two undertakings might afford them other exceptional competitive advantage, consideration should be given to the fact that they have their own inland waterway vessels. VEBA and Gelsenberg AG have a carrying capacity of their own which enabled them in 1971 to transport about ... % and ... % respectively of total shipments by German firms within the Federal Republic of Germany and to and from foreign ports. However, less than 20 % of the solid fuels sold in the Federal Republic of Germany is shipped by water, and VEBA and Gelsenberg AG each carried less than ... % of their solid fuels sales in their own vessels. Another pointer indicating that the two undertakings will not gain a privileged position through the use of their own vessels is the fact that on inland waterways the supply of cargo space exceeds demand and VEBA/Gelsenberg AG have no direct influence on transport charges since waterway freight charges, where not fixed at set rates (as in German domestic traffic), are determined freely on the freight market. Given this market structure and this relationship between supply and demand, the two undertakings have virtually no scope for granting special terms to buyers to make use of their transport facilities.\n6. Consequently, the merger will not enable the undertakings involved to determine prices or to control or restrict distribution in a substantial part of the solid fuel market or to evade the rules of competition instituted under the Treaty. Also, it will not give them an artificially privileged position affording a substantial advantage in access to supplies or markets,\nThe Federal Republic of Germany is authorized to acquire a majority of the shares of Gelsenberg AG, Essen. This Decision is addressed to the Federal Republic of Germany.",
         "10064",
         "Decision",
         "Decision"
        ],
        [
         "15",
         "32001D0742",
         "Decision",
         "2001/742/EC: Council Decision of 16 October 2001 authorising the Federal Republic of Germany to conclude with the Czech Republic an agreement containing measures derogating from Articles 2 and 3 of the Sixth Directive 77/388/EEC on the harmonisation of the laws of the Member States relating to turnover taxes\n",
         "Council Decision\nof 16 October 2001\nauthorising the Federal Republic of Germany to conclude with the Czech Republic an agreement containing measures derogating from Articles 2 and 3 of the Sixth Directive 77/388/EEC on the harmonisation of the laws of the Member States relating to turnover taxes\n(2001/742/EC)\nTHE COUNCIL OF THE EUROPEAN UNION",
         ",\nHaving regard to the Treaty establishing the European Community,\nHaving regard to the Sixth Council Directive 77/388/EEC of 17 May 1977 on the harmonisation of the laws of the Member States relating to turnover taxes - Common system of value added tax: uniform basis of assessment(1) (hereinafter referred to as the \"Sixth VAT Directive\"), and in particular Article 30 thereof,\nHaving regard to the proposal from the Commission,\nWhereas:\n(1) Under Article 30 of the Sixth VAT Directive, the Council, acting unanimously on a proposal from the Commission, may authorise any Member State to conclude with a non-member country or an international organisation an agreement which may contain derogations from the said Directive.\n(2) By letter registered at the Secretariat-General of the Commission on 18 October 2000, the German Government requested authorisation to conclude an agreement with the Czech Republic relating to the construction of a frontier bridge between the States in question.\n(3) The agreement contains provisions in the field of value added tax (VAT) which derogate from Articles 2 and 3 of the Sixth VAT Directive as regards, on the one hand, the supplies of goods and services in connection with the construction, repair and renewal of the frontier bridge and, on the other hand, importation of goods used for the construction work or the maintenance of this bridge.\n(4) The other Member States were informed of the German request on 2 February 2001.\n(5) In the absence of derogations, the construction, repair and renewal work carried out on German territory would be subject to VAT in Germany while that carried out on Czech territory would lie outside the scope of the Sixth VAT Directive. Further, each importation from the Czech Republic into Germany of goods used for the construction and the maintenance of the frontier bridge would be subject to VAT in Germany.\n(6) The purpose of these derogations is to simplify the rules of taxation for the contractors carrying out the work in question.\n(7) The derogations will have only a negligible effect on the own resources of the European Communities accruing from value added tax,",
         "['The Federal Republic of Germany is hereby authorised to conclude an agreement, containing measures derogating from the Sixth VAT Directive, with the Czech Republic concerning the construction of a frontier bridge at Furth im Wald-Schafberg/Folmava/Vollmau, which is partly on the territory of the Federal Republic of Germany and partly on the territory of the Czech Republic, linking the German Federal B20 road heading east with the Czech national I/26 road heading west.\\nThe tax derogations provided for by the agreement are set out in Articles 2 and 3.', 'By way of derogation from Article 3 of the Sixth VAT Directive, insofar as it extends on to the territory of the Federal Republic of Germany, the area of the construction site for the frontier bridge referred to in Article 1 of this Decision and, after its completion, the frontier bridge itself, shall be treated as forming part of the territory of the Czech Republic as regards supplies of goods or services intended for the construction of the frontier bridge or for its repair and renewal.', 'By way of derogation from Article 2(2) of the Sixth VAT Directive, the importation of goods into Germany from the Czech Republic shall not be subject to VAT insofar as those goods are used for the construction or maintenance of the bridge referred to in Article 1 of this Decision. However, this derogation shall not apply to any goods imported for the same purpose by a public authority.', 'This Decision is addressed to the Federal Republic of Germany.']",
         "['1234', '1318', '2206', '4585', '5581', '5860']",
         "train",
         "2001/742/EC: Council Decision of 16 October 2001 authorising the Federal Republic of Germany to conclude with the Czech Republic an agreement containing measures derogating from Articles 2 and 3 of the Sixth Directive 77/388/EEC on the harmonisation of the laws of the Member States relating to turnover taxes\n\n,\nHaving regard to the Treaty establishing the European Community,\nHaving regard to the Sixth Council Directive 77/388/EEC of 17 May 1977 on the harmonisation of the laws of the Member States relating to turnover taxes - Common system of value added tax: uniform basis of assessment(1) (hereinafter referred to as the \"Sixth VAT Directive\"), and in particular Article 30 thereof,\nHaving regard to the proposal from the Commission,\nWhereas:\n(1) Under Article 30 of the Sixth VAT Directive, the Council, acting unanimously on a proposal from the Commission, may authorise any Member State to conclude with a non-member country or an international organisation an agreement which may contain derogations from the said Directive.\n(2) By letter registered at the Secretariat-General of the Commission on 18 October 2000, the German Government requested authorisation to conclude an agreement with the Czech Republic relating to the construction of a frontier bridge between the States in question.\n(3) The agreement contains provisions in the field of value added tax (VAT) which derogate from Articles 2 and 3 of the Sixth VAT Directive as regards, on the one hand, the supplies of goods and services in connection with the construction, repair and renewal of the frontier bridge and, on the other hand, importation of goods used for the construction work or the maintenance of this bridge.\n(4) The other Member States were informed of the German request on 2 February 2001.\n(5) In the absence of derogations, the construction, repair and renewal work carried out on German territory would be subject to VAT in Germany while that carried out on Czech territory would lie outside the scope of the Sixth VAT Directive. Further, each importation from the Czech Republic into Germany of goods used for the construction and the maintenance of the frontier bridge would be subject to VAT in Germany.\n(6) The purpose of these derogations is to simplify the rules of taxation for the contractors carrying out the work in question.\n(7) The derogations will have only a negligible effect on the own resources of the European Communities accruing from value added tax,\nThe Federal Republic of Germany is hereby authorised to conclude an agreement, containing measures derogating from the Sixth VAT Directive, with the Czech Republic concerning the construction of a frontier bridge at Furth im Wald-Schafberg/Folmava/Vollmau, which is partly on the territory of the Federal Republic of Germany and partly on the territory of the Czech Republic, linking the German Federal B20 road heading east with the Czech national I/26 road heading west.\nThe tax derogations provided for by the agreement are set out in Articles 2 and 3. By way of derogation from Article 3 of the Sixth VAT Directive, insofar as it extends on to the territory of the Federal Republic of Germany, the area of the construction site for the frontier bridge referred to in Article 1 of this Decision and, after its completion, the frontier bridge itself, shall be treated as forming part of the territory of the Czech Republic as regards supplies of goods or services intended for the construction of the frontier bridge or for its repair and renewal. By way of derogation from Article 2(2) of the Sixth VAT Directive, the importation of goods into Germany from the Czech Republic shall not be subject to VAT insofar as those goods are used for the construction or maintenance of the bridge referred to in Article 1 of this Decision. However, this derogation shall not apply to any goods imported for the same purpose by a public authority. This Decision is addressed to the Federal Republic of Germany.",
         "3966",
         "Decision",
         "Decision"
        ],
        [
         "16",
         "32015D0006",
         "Decision",
         "Decision (EU) 2015/300 of the European Central Bank of 10 February 2015 on the eligibility of marketable debt instruments issued or fully guaranteed by the Hellenic Republic (ECB/2015/6)\n",
         "25.2.2015 EN Official Journal of the European Union L 53/29\nDECISION (EU) 2015/300 OF THE EUROPEAN CENTRAL BANK\nof 10 February 2015\non the eligibility of marketable debt instruments issued or fully guaranteed by the Hellenic Republic (ECB/2015/6)\nTHE GOVERNING COUNCIL OF THE EUROPEAN CENTRAL BANK",
         ",\nHaving regard to the Treaty on the Functioning of the European Union, and in particular the first indent of Article 127(2) thereof,\nHaving regard to the Statute of the European System of Central Banks and of the European Central Bank, and in particular the first indent of Article 3.1, Article 12.1, Article 18 and the second indent of Article 34.1 thereof,\nHaving regard to Guideline ECB/2011/14 of 20 September 2011 on monetary policy instruments and procedures of the Eurosystem (1), and in particular Section 1.6 and Sections 6.3.1, 6.3.2 and 6.4.2 of Annex I thereto,\nHaving regard to Guideline ECB/2014/31 of 9 July 2014 on additional temporary measures relating to Eurosystem refinancing operations and eligibility of collateral and amending Guideline ECB/2007/9 (2), and in particular Article 1(3) and Articles 6 and 8 thereof,\nWhereas:\n(1) Pursuant to Article 18.1 of the Statute of the European System of Central Banks and of the European Central Bank, the European Central Bank (ECB) and the national central banks of Member States whose currency is the euro (hereinafter the ‘NCBs’) may conduct credit operations with credit institutions and other market participants, with lending being based on adequate collateral. The standard criteria determining the eligibility of collateral for the purposes of Eurosystem monetary policy operations are laid down in Annex I to Guideline ECB/2011/14.\n(2) Pursuant to Section 1.6 of Annex I to Guideline ECB/2011/14, the Governing Council may, at any time, change the instruments, conditions, criteria and procedures for the execution of Eurosystem monetary policy operations. Pursuant to Section 6.3.1 of Annex I to Guideline ECB/2011/14, the Eurosystem reserves the right to determine whether an issue, issuer, debtor or guarantor fulfils its requirements for high credit standards on the basis of any information it may consider relevant. Further, the Eurosystem's minimum requirements for credit quality thresholds are specified in the Eurosystem credit assessment framework rules for marketable assets, as laid down in Section 6.3.2 of Annex I to Guideline ECB/2011/14.\n(3) The suspension of the Eurosystem's minimum requirements for credit quality thresholds applicable to marketable debt instruments issued or fully guaranteed by the Hellenic Republic, initially decided by the Governing Council on 6 May 2010, was an exceptional and temporary measure which was based on the positive assessment by the Governing Council of compliance with a European Union/International Monetary Fund programme. At the time, the Governing Council took into consideration the fact that the Hellenic Republic had approved a programme which the Governing Council considered to be appropriate so that, from a credit risk management perspective, the marketable debt instruments issued or guaranteed by the Hellenic Republic retained a quality standard sufficient for their continued eligibility as collateral for Eurosystem monetary policy operations, irrespective of any external credit assessment. Moreover, the Governing Council took into consideration the strong commitment of the Greek Government to fully implement that programme (3).\n(4) Under Article 8 of Guideline ECB/2014/31, the Eurosystem's credit quality thresholds do not apply to marketable debt instruments issued or fully guaranteed by the central governments of euro area Member States under a European Union/International Monetary Fund programme, unless the Governing Council decides that the respective Member State no longer complies with the conditionality of its financial support and/or macroeconomic programme. Under Article 1(3) of the same Guideline, the Hellenic Republic is, for the purposes of Article 6(1) and Article 8 of that Guideline, considered a euro area Member State compliant with a European Union/International Monetary Fund programme.\n(5) On the basis of the information available, the Governing Council has made an assessment, according to which it is not currently possible to assume a successful conclusion of the review of the European Union/International Monetary Fund programme for the Hellenic Republic. Consequently, the Hellenic Republic is no longer deemed to be in compliance with the conditionality of the programme and, as a result, the conditions for the temporary suspension of the Eurosystem's credit quality thresholds in respect of such instruments, as set out in Article 8(2) of Guideline ECB/2014/31, are no longer fulfilled. As a consequence, the Governing Council has decided that the Eurosystem's credit quality thresholds shall apply in respect of marketable debt instruments issued or fully guaranteed by the Hellenic Republic,",
         "[\"Eligibility of marketable debt instruments issued or fully guaranteed by the Hellenic Republic\\n1.\\xa0\\xa0\\xa0For the purposes of Article 6(1) and Article 8 of Guideline ECB/2014/31, the Hellenic Republic shall no longer be considered to be in compliance with a European Union/International Monetary Fund programme.\\n2.\\xa0\\xa0\\xa0The Eurosystem's minimum requirements for credit quality thresholds, as set out in the Eurosystem credit assessment framework rules for certain marketable assets in Section 6.3.2 of Annex I to Guideline ECB/2011/14, shall apply in the case of marketable debt instruments issued or fully guaranteed by the Hellenic Republic.\\n3.\\xa0\\xa0\\xa0In the event of any discrepancy between this Decision, Guideline ECB/2011/14 and Guideline ECB/2014/31, as implemented at national level by the NCBs, this Decision shall prevail.\", 'Entry into force\\nThis Decision shall enter into force on 11 February 2015.']",
         "['1130', '1182', '2098', '2510', '424', '6151']",
         "train",
         "Decision (EU) 2015/300 of the European Central Bank of 10 February 2015 on the eligibility of marketable debt instruments issued or fully guaranteed by the Hellenic Republic (ECB/2015/6)\n\n,\nHaving regard to the Treaty on the Functioning of the European Union, and in particular the first indent of Article 127(2) thereof,\nHaving regard to the Statute of the European System of Central Banks and of the European Central Bank, and in particular the first indent of Article 3.1, Article 12.1, Article 18 and the second indent of Article 34.1 thereof,\nHaving regard to Guideline ECB/2011/14 of 20 September 2011 on monetary policy instruments and procedures of the Eurosystem (1), and in particular Section 1.6 and Sections 6.3.1, 6.3.2 and 6.4.2 of Annex I thereto,\nHaving regard to Guideline ECB/2014/31 of 9 July 2014 on additional temporary measures relating to Eurosystem refinancing operations and eligibility of collateral and amending Guideline ECB/2007/9 (2), and in particular Article 1(3) and Articles 6 and 8 thereof,\nWhereas:\n(1) Pursuant to Article 18.1 of the Statute of the European System of Central Banks and of the European Central Bank, the European Central Bank (ECB) and the national central banks of Member States whose currency is the euro (hereinafter the ‘NCBs’) may conduct credit operations with credit institutions and other market participants, with lending being based on adequate collateral. The standard criteria determining the eligibility of collateral for the purposes of Eurosystem monetary policy operations are laid down in Annex I to Guideline ECB/2011/14.\n(2) Pursuant to Section 1.6 of Annex I to Guideline ECB/2011/14, the Governing Council may, at any time, change the instruments, conditions, criteria and procedures for the execution of Eurosystem monetary policy operations. Pursuant to Section 6.3.1 of Annex I to Guideline ECB/2011/14, the Eurosystem reserves the right to determine whether an issue, issuer, debtor or guarantor fulfils its requirements for high credit standards on the basis of any information it may consider relevant. Further, the Eurosystem's minimum requirements for credit quality thresholds are specified in the Eurosystem credit assessment framework rules for marketable assets, as laid down in Section 6.3.2 of Annex I to Guideline ECB/2011/14.\n(3) The suspension of the Eurosystem's minimum requirements for credit quality thresholds applicable to marketable debt instruments issued or fully guaranteed by the Hellenic Republic, initially decided by the Governing Council on 6 May 2010, was an exceptional and temporary measure which was based on the positive assessment by the Governing Council of compliance with a European Union/International Monetary Fund programme. At the time, the Governing Council took into consideration the fact that the Hellenic Republic had approved a programme which the Governing Council considered to be appropriate so that, from a credit risk management perspective, the marketable debt instruments issued or guaranteed by the Hellenic Republic retained a quality standard sufficient for their continued eligibility as collateral for Eurosystem monetary policy operations, irrespective of any external credit assessment. Moreover, the Governing Council took into consideration the strong commitment of the Greek Government to fully implement that programme (3).\n(4) Under Article 8 of Guideline ECB/2014/31, the Eurosystem's credit quality thresholds do not apply to marketable debt instruments issued or fully guaranteed by the central governments of euro area Member States under a European Union/International Monetary Fund programme, unless the Governing Council decides that the respective Member State no longer complies with the conditionality of its financial support and/or macroeconomic programme. Under Article 1(3) of the same Guideline, the Hellenic Republic is, for the purposes of Article 6(1) and Article 8 of that Guideline, considered a euro area Member State compliant with a European Union/International Monetary Fund programme.\n(5) On the basis of the information available, the Governing Council has made an assessment, according to which it is not currently possible to assume a successful conclusion of the review of the European Union/International Monetary Fund programme for the Hellenic Republic. Consequently, the Hellenic Republic is no longer deemed to be in compliance with the conditionality of the programme and, as a result, the conditions for the temporary suspension of the Eurosystem's credit quality thresholds in respect of such instruments, as set out in Article 8(2) of Guideline ECB/2014/31, are no longer fulfilled. As a consequence, the Governing Council has decided that the Eurosystem's credit quality thresholds shall apply in respect of marketable debt instruments issued or fully guaranteed by the Hellenic Republic,\nEligibility of marketable debt instruments issued or fully guaranteed by the Hellenic Republic\n1.   For the purposes of Article 6(1) and Article 8 of Guideline ECB/2014/31, the Hellenic Republic shall no longer be considered to be in compliance with a European Union/International Monetary Fund programme.\n2.   The Eurosystem's minimum requirements for credit quality thresholds, as set out in the Eurosystem credit assessment framework rules for certain marketable assets in Section 6.3.2 of Annex I to Guideline ECB/2011/14, shall apply in the case of marketable debt instruments issued or fully guaranteed by the Hellenic Republic.\n3.   In the event of any discrepancy between this Decision, Guideline ECB/2011/14 and Guideline ECB/2014/31, as implemented at national level by the NCBs, this Decision shall prevail. Entry into force\nThis Decision shall enter into force on 11 February 2015.",
         "5765",
         "Decision",
         "Decision"
        ],
        [
         "17",
         "31992D0209",
         "Decision",
         "92/209/EEC: Council Decision of 16 March 1992 on the conclusion of a Protocol on financial and technical cooperation between the European Economic Community and the Lebanese Republic\n",
         "COUNCIL DECISION  of 16 March 1992  on the conclusion of a Protocol on financial and technical cooperation between the European Economic Community and the Lebanese Republic  (92/209/EEC)\nTHE COUNCIL OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Economic Community, and in particular Article 238 thereof,\nHaving regard to the recommendation from the Commission,\nHaving regard to the assent of the European Parliament (1),\nWhereas the Protocol on financial and technical cooperation between the European Economic Community and the Lebanese Republic should be approved,",
         "['The Protocol on financial and technical cooperation between the European Economic Community and the Lebanese Republic is hereby approved on behalf of the Community.\\nThe text of the Protocol is attached to this Decision.', 'The President of the Council shall give the notification provided for in Article 22 (1) of the Protocol (2).', 'This Decision shall take effect on the day following its publication in the Official Journal of the European Communities.']",
         "['1613', '211', '225', '2850']",
         "train",
         "92/209/EEC: Council Decision of 16 March 1992 on the conclusion of a Protocol on financial and technical cooperation between the European Economic Community and the Lebanese Republic\n\n,\nHaving regard to the Treaty establishing the European Economic Community, and in particular Article 238 thereof,\nHaving regard to the recommendation from the Commission,\nHaving regard to the assent of the European Parliament (1),\nWhereas the Protocol on financial and technical cooperation between the European Economic Community and the Lebanese Republic should be approved,\nThe Protocol on financial and technical cooperation between the European Economic Community and the Lebanese Republic is hereby approved on behalf of the Community.\nThe text of the Protocol is attached to this Decision. The President of the Council shall give the notification provided for in Article 22 (1) of the Protocol (2). This Decision shall take effect on the day following its publication in the Official Journal of the European Communities.",
         "1012",
         "Decision",
         "Decision"
        ],
        [
         "18",
         "31997D0717",
         "Decision",
         "97/717/EC: Commission Decision of 12 June 1997 on the approval of the single programming document for Community structural assistance in the region of Plymouth concerned by Objective 2 in the United Kingdom (Only the English text is authentic)\n",
         "COMMISSION DECISION of 12 June 1997 on the approval of the single programming document for Community structural assistance in the region of Plymouth concerned by Objective 2 in the United Kingdom (Only the English text is authentic) (97/717/EC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Regulation (EEC) No 4253/88 of 19 December 1988 laying down provisions for implementing Regulation (EEC) No 2052/88 as regards coordination of activities of the different Structural Funds between themselves and with the operations of the European Investment Bank and the other existing financial instruments (1), as last amended by Regulation (EC) No 3193/94 (2), and in particular Article 10 (1) last subparagraph thereof,\nAfter consultation of the Advisory Committee on the Development and Conversion of Regions and the Committee pursuant to Article 124 of the Treaty,\nWhereas the programming procedure for structural assistance under Objective 2 is defined in Article 9 (6) to 9 (10) of Council Regulation (EEC) No 2052/88 of 24 June 1988 on the tasks of the Structural Funds and their effectiveness and on coordination of their activities between themselves and with the operations of the European Investment Bank and the other existing financial instruments (3), as last amended by Regulation (EC) No 3193/94; whereas however the last subparagraph of Article 5 (2) of Regulation (EEC) No 4253/88 foresees that in order to simplify and to speed up programming procedures, Member States may submit in a single programming document the information required for the regional and social conversion plan referred to in Article 9 (8) of Regulation (EEC) No 2052/88 and the information required at Article 14 (2) of Regulation (EEC) No 4253/88; whereas Article 10 (1) last subparagraph of Regulation (EEC) No 4253/88 foresees that in that case the Commission adopt a single decision in a single document covering the points referred to in Article 8 (3) and the assistance from the Funds referred to in the last subparagraph of Article 14 (3);\nWhereas the Commission has established, by Decision 96/472/EC (4), the list of declining industrial areas concerned by Objective 2 for the programming period from 1997 to 1999;\nWhereas the global maximum allocation foreseen for the assistance of the Structural Funds for the present single programming document is composed of resources coming from the indicative allocation of Structural Fund commitment appropriations for the period 1997 to 1999 under Objective 2 resulting from Commission Decision 96/468/EC (5) and from unused appropriations of ECU 2,293 million of the corresponding single programming document covering the period 1994 to 1996, pursuant to Commission Decision C(96) 3679 of 17 December 1996;\nWhereas the United Kingdom Government has submitted to the Commission on 2 August 1996 the single programming document as referred to in Article 5 (2) of Regulation (EEC) No 4253/88 for the region of Plymouth; whereas this document contains the elements referred to in Article 9 (8) of Regulation (EEC) No 2052/88 and in Article 14 (2) of Regulation (EEC) No 4253/88; whereas expenditure under this single programming document is eligible as from that date;\nWhereas the single programming document submitted by this Member State includes a description of the conversion priorities selected and the applications for assistance from the European Regional Development Fund (ERDF) and the European Social Fund (ESF) as well as an indication of the planned use of the assistance available from the European Investment Bank (EIB) and the other financial instruments in implementing the single programming document;\nWhereas, in accordance with Article 3 of Regulation (EEC) No 4253/88, the Commission is charged with ensuring, within the framework of the partnership, coordination and consistency between assistance from the Funds and assistance provided by the EIB and the other financial instruments;\nWhereas the EIB has been involved in the drawing up of the single programming document in accordance with the provisions of Article 8 (1) of Regulation (EEC) No 4253/88, applicable by analogy in the establishment of the single programming document; whereas it has declared itself prepared to contribute to the implementation of this document in conformity with its statutory provisions; whereas, however, it has not yet been possible to evaluate precisely the amounts of Community loans corresponding to the financial needs;\nWhereas Article 2 second subparagraph of Commission Regulation (EEC) No 1866/90 of 2 July 1990 on arrangements for using the ecu for the purpose of the budgetary management of the Structural Funds (6), as last amended by Regulation (EC) No 2745/94 (7), stipulates that in the Commission decisions approving a single programming document, the Community assistance available for the entire period and the annual breakdown thereof shall be set out in ecus at prices for the year in which each decision is taken and shall be subject to indexation; whereas this annual breakdown must be compatible with the progressive increase in the commitment appropriations shown in Annex II to Regulation (EEC) No 2052/88; whereas indexation is based on a single rate per year, corresponding to the rates applied annually to budget appropriations on the basis of the mechanism for the technical adjustment of the financial perspectives;\nWhereas Article 1 of Council Regulation (EEC) No 4254/88 of 19 December 1988 laying down provisions for implementing Regulation (EEC) No 2052/88 as regards the European Regional Development Fund (8), as amended by Regulation (EEC) No 2083/93 (9), defines the measures for which the ERDF may provide financial support;\nWhereas Article 1 of Council Regulation (EEC) No 4255/88 of 19 December 1988 laying down provisions for implementing Regulation (EEC) No 2052/88 as regards the European Social Fund (10), as amended by Regulation (EEC) No 2084/93 (11), defines the measures for which the ESF may provide financial support;\nWhereas the single programming document has been established in agreement with the Member State concerned through the partnership defined in Article 4 of Regulation (EEC) No 2052/88;\nWhereas the single programming document satisfies the conditions and includes the information required by Article 14 of Regulation (EEC) No 4253/88;\nWhereas the present assistance satisfies the conditions laid down in Article 13 of Regulation (EEC) No 4253/88, and so should be implemented by means of an integrated approach involving finance from more than one Fund;\nWhereas Article 1 of the Financial Regulation of 21 December 1977 applicable to the general budget of the European Communities (12), as last amended by Regulation (EC, Euratom, ECSC) No 2335/95 (13), states that the legal commitments entered into for measures extending over more than one financial year must contain a time limit for implementation which must be specified to the recipient in due form when the aid is granted;\nWhereas Article 20 (3) of Regulation (EEC) No 4253/88 provides, subject to available funding, for a single commitment where the Community assistance granted is less than ECU 40 million for the whole programming period;\nWhereas it is appropriate to mention that this Decision is ruled by the provisions on the eligibility of expenditure laid down in the Annex to Commission Decision C(97) 1035/7 of 23 April 1997 modifying the decisions approving the Community support frameworks, the single programming documents and the Community initiative programmes in respect of the United Kingdom;\nWhereas all the other conditions laid down for the grant of aid from the ERDF and the ESF have been complied with,",
         "['The single programming document for Community structural assistance in the region of Plymouth concerned by Objective 2 in the United Kingdom, covering the period 1 January 1997 to 31 December 1999, is hereby approved.', 'The single programming document includes the following essential elements:\\n(a) a statement of the main priorities for joint action, their specific quantified objectives, an appraisal of their expected impact and their consistency with economic, social and regional policies in the United Kingdom;\\nthe main priorities are:\\n1. industry and business development,\\n2. technology based industries,\\n3. tourism development,\\n4. community economic development;\\n(b) the assistance from the Structural Funds as referred to in Article 4;\\n(c) the detailed provisions for implementing the single programming document comprising:\\n- the procedures for monitoring and evaluation,\\n- the provisions on financial implementation,\\n- the rules for compliance with Community policies;\\n(d) the procedures for verifying additionality and an initial evaluation of the latter;\\n(e) the arrangements for associating the environmental authorities with the implementation of the single programming document;\\n(f) the means available for technical assistance necessary for the preparation, implementation or adaptation of the measures concerned.', '1. For the purpose of indexation, the annual breakdown of the global maximum allocation foreseen for the assistance from the Structural Funds is as follows:\\n>TABLE>\\n2. To this global maximum allocation is added an amount of ECU 2,293 million not subject to indexation, resulting from unused appropriations of the corresponding single programming document covering the period 1994 to 1996.', 'The assistance from the Structural Funds granted to the single programming document amounts to a maximum of ECU 38,590 million.\\nThe procedure for granting the financial assistance, including the financial contribution from the Funds to the various priorities and measures, is set out in the financing plan and the detailed implementing provisions which form an integral part of the single programming document.\\nThe national financial contribution envisaged, which is approximately ECU 40,202 million for the public sector and ECU 8,719 million for the private sector, may be met in part by Community loans, in particular from the EIB.', '1. The breakdown among the Structural Funds of the total Community assistance available is as follows:\\n- ERDF: ECU 31,341 million,\\n- ESF: ECU 7,249 million.\\n2. The budgetary commitments at the moment of approval of the single programming document refer to the total Community assistance.', 'The breakdown among the Structural Funds and the procedure for the grant of the assistance may be altered subsequently, subject to the availability of funds and the budgetary rules, in the light of adjustments decided according to the procedure laid down in Article 25 (5) of Regulation (EEC) No 4253/88.', 'The Community aid concerns expenditure on operations under the single programming document which, in the Member State concerned, are the subject of legally binding commitments and for which the requisite finance has been specifically allocated no later than 31 December 1999. The final date for taking account of expenditure on these measures is 31 December 2001.', 'The single programming document shall be implemented in accordance with Community law, and in particular Articles 6, 30, 48, 52 and 59 of the Treaty and the Community Directives on the coordination of procedures for the award of contracts.', 'This Decision is ruled by the provisions laid down in the Annex to Decision C(97) 1035/7.', '0\\nThis Decision is addressed to the United Kingdom.']",
         "['1460', '3003', '3067', '3399', '4838', '5138']",
         "train",
         "97/717/EC: Commission Decision of 12 June 1997 on the approval of the single programming document for Community structural assistance in the region of Plymouth concerned by Objective 2 in the United Kingdom (Only the English text is authentic)\n\n,\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Regulation (EEC) No 4253/88 of 19 December 1988 laying down provisions for implementing Regulation (EEC) No 2052/88 as regards coordination of activities of the different Structural Funds between themselves and with the operations of the European Investment Bank and the other existing financial instruments (1), as last amended by Regulation (EC) No 3193/94 (2), and in particular Article 10 (1) last subparagraph thereof,\nAfter consultation of the Advisory Committee on the Development and Conversion of Regions and the Committee pursuant to Article 124 of the Treaty,\nWhereas the programming procedure for structural assistance under Objective 2 is defined in Article 9 (6) to 9 (10) of Council Regulation (EEC) No 2052/88 of 24 June 1988 on the tasks of the Structural Funds and their effectiveness and on coordination of their activities between themselves and with the operations of the European Investment Bank and the other existing financial instruments (3), as last amended by Regulation (EC) No 3193/94; whereas however the last subparagraph of Article 5 (2) of Regulation (EEC) No 4253/88 foresees that in order to simplify and to speed up programming procedures, Member States may submit in a single programming document the information required for the regional and social conversion plan referred to in Article 9 (8) of Regulation (EEC) No 2052/88 and the information required at Article 14 (2) of Regulation (EEC) No 4253/88; whereas Article 10 (1) last subparagraph of Regulation (EEC) No 4253/88 foresees that in that case the Commission adopt a single decision in a single document covering the points referred to in Article 8 (3) and the assistance from the Funds referred to in the last subparagraph of Article 14 (3);\nWhereas the Commission has established, by Decision 96/472/EC (4), the list of declining industrial areas concerned by Objective 2 for the programming period from 1997 to 1999;\nWhereas the global maximum allocation foreseen for the assistance of the Structural Funds for the present single programming document is composed of resources coming from the indicative allocation of Structural Fund commitment appropriations for the period 1997 to 1999 under Objective 2 resulting from Commission Decision 96/468/EC (5) and from unused appropriations of ECU 2,293 million of the corresponding single programming document covering the period 1994 to 1996, pursuant to Commission Decision C(96) 3679 of 17 December 1996;\nWhereas the United Kingdom Government has submitted to the Commission on 2 August 1996 the single programming document as referred to in Article 5 (2) of Regulation (EEC) No 4253/88 for the region of Plymouth; whereas this document contains the elements referred to in Article 9 (8) of Regulation (EEC) No 2052/88 and in Article 14 (2) of Regulation (EEC) No 4253/88; whereas expenditure under this single programming document is eligible as from that date;\nWhereas the single programming document submitted by this Member State includes a description of the conversion priorities selected and the applications for assistance from the European Regional Development Fund (ERDF) and the European Social Fund (ESF) as well as an indication of the planned use of the assistance available from the European Investment Bank (EIB) and the other financial instruments in implementing the single programming document;\nWhereas, in accordance with Article 3 of Regulation (EEC) No 4253/88, the Commission is charged with ensuring, within the framework of the partnership, coordination and consistency between assistance from the Funds and assistance provided by the EIB and the other financial instruments;\nWhereas the EIB has been involved in the drawing up of the single programming document in accordance with the provisions of Article 8 (1) of Regulation (EEC) No 4253/88, applicable by analogy in the establishment of the single programming document; whereas it has declared itself prepared to contribute to the implementation of this document in conformity with its statutory provisions; whereas, however, it has not yet been possible to evaluate precisely the amounts of Community loans corresponding to the financial needs;\nWhereas Article 2 second subparagraph of Commission Regulation (EEC) No 1866/90 of 2 July 1990 on arrangements for using the ecu for the purpose of the budgetary management of the Structural Funds (6), as last amended by Regulation (EC) No 2745/94 (7), stipulates that in the Commission decisions approving a single programming document, the Community assistance available for the entire period and the annual breakdown thereof shall be set out in ecus at prices for the year in which each decision is taken and shall be subject to indexation; whereas this annual breakdown must be compatible with the progressive increase in the commitment appropriations shown in Annex II to Regulation (EEC) No 2052/88; whereas indexation is based on a single rate per year, corresponding to the rates applied annually to budget appropriations on the basis of the mechanism for the technical adjustment of the financial perspectives;\nWhereas Article 1 of Council Regulation (EEC) No 4254/88 of 19 December 1988 laying down provisions for implementing Regulation (EEC) No 2052/88 as regards the European Regional Development Fund (8), as amended by Regulation (EEC) No 2083/93 (9), defines the measures for which the ERDF may provide financial support;\nWhereas Article 1 of Council Regulation (EEC) No 4255/88 of 19 December 1988 laying down provisions for implementing Regulation (EEC) No 2052/88 as regards the European Social Fund (10), as amended by Regulation (EEC) No 2084/93 (11), defines the measures for which the ESF may provide financial support;\nWhereas the single programming document has been established in agreement with the Member State concerned through the partnership defined in Article 4 of Regulation (EEC) No 2052/88;\nWhereas the single programming document satisfies the conditions and includes the information required by Article 14 of Regulation (EEC) No 4253/88;\nWhereas the present assistance satisfies the conditions laid down in Article 13 of Regulation (EEC) No 4253/88, and so should be implemented by means of an integrated approach involving finance from more than one Fund;\nWhereas Article 1 of the Financial Regulation of 21 December 1977 applicable to the general budget of the European Communities (12), as last amended by Regulation (EC, Euratom, ECSC) No 2335/95 (13), states that the legal commitments entered into for measures extending over more than one financial year must contain a time limit for implementation which must be specified to the recipient in due form when the aid is granted;\nWhereas Article 20 (3) of Regulation (EEC) No 4253/88 provides, subject to available funding, for a single commitment where the Community assistance granted is less than ECU 40 million for the whole programming period;\nWhereas it is appropriate to mention that this Decision is ruled by the provisions on the eligibility of expenditure laid down in the Annex to Commission Decision C(97) 1035/7 of 23 April 1997 modifying the decisions approving the Community support frameworks, the single programming documents and the Community initiative programmes in respect of the United Kingdom;\nWhereas all the other conditions laid down for the grant of aid from the ERDF and the ESF have been complied with,\nThe single programming document for Community structural assistance in the region of Plymouth concerned by Objective 2 in the United Kingdom, covering the period 1 January 1997 to 31 December 1999, is hereby approved. The single programming document includes the following essential elements:\n(a) a statement of the main priorities for joint action, their specific quantified objectives, an appraisal of their expected impact and their consistency with economic, social and regional policies in the United Kingdom;\nthe main priorities are:\n1. industry and business development,\n2. technology based industries,\n3. tourism development,\n4. community economic development;\n(b) the assistance from the Structural Funds as referred to in Article 4;\n(c) the detailed provisions for implementing the single programming document comprising:\n- the procedures for monitoring and evaluation,\n- the provisions on financial implementation,\n- the rules for compliance with Community policies;\n(d) the procedures for verifying additionality and an initial evaluation of the latter;\n(e) the arrangements for associating the environmental authorities with the implementation of the single programming document;\n(f) the means available for technical assistance necessary for the preparation, implementation or adaptation of the measures concerned. 1. For the purpose of indexation, the annual breakdown of the global maximum allocation foreseen for the assistance from the Structural Funds is as follows:\n>TABLE>\n2. To this global maximum allocation is added an amount of ECU 2,293 million not subject to indexation, resulting from unused appropriations of the corresponding single programming document covering the period 1994 to 1996. The assistance from the Structural Funds granted to the single programming document amounts to a maximum of ECU 38,590 million.\nThe procedure for granting the financial assistance, including the financial contribution from the Funds to the various priorities and measures, is set out in the financing plan and the detailed implementing provisions which form an integral part of the single programming document.\nThe national financial contribution envisaged, which is approximately ECU 40,202 million for the public sector and ECU 8,719 million for the private sector, may be met in part by Community loans, in particular from the EIB. 1. The breakdown among the Structural Funds of the total Community assistance available is as follows:\n- ERDF: ECU 31,341 million,\n- ESF: ECU 7,249 million.\n2. The budgetary commitments at the moment of approval of the single programming document refer to the total Community assistance. The breakdown among the Structural Funds and the procedure for the grant of the assistance may be altered subsequently, subject to the availability of funds and the budgetary rules, in the light of adjustments decided according to the procedure laid down in Article 25 (5) of Regulation (EEC) No 4253/88. The Community aid concerns expenditure on operations under the single programming document which, in the Member State concerned, are the subject of legally binding commitments and for which the requisite finance has been specifically allocated no later than 31 December 1999. The final date for taking account of expenditure on these measures is 31 December 2001. The single programming document shall be implemented in accordance with Community law, and in particular Articles 6, 30, 48, 52 and 59 of the Treaty and the Community Directives on the coordination of procedures for the award of contracts. This Decision is ruled by the provisions laid down in the Annex to Decision C(97) 1035/7. 0\nThis Decision is addressed to the United Kingdom.",
         "11425",
         "Decision",
         "Decision"
        ],
        [
         "19",
         "31986D0331",
         "Decision",
         "86/331/EEC: Commission Decision of 23 June 1986 approving an addendum to the programme relating to potato marketing in the land of North Rhine Westphalia pursuant to Council Regulation (EEC) No 355/77 (Only the German text is authentic)\n",
         "COMMISSION  DECISION\nof 23 June 1986\napproving an addendum to the programme relating to potato marketing in the land of North Rhine Westphalia pursuant to Council Regulation (EEC) No 355/77\n(Only the German text is authentic)\n(86/331/EEC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Regulation (EEC) No 355/77 of 15 February 1977 on common measures to improve the conditions under which agricultural and fishery products are processed and marketed (1), as last amended by Regulation (EEC) No 3827/85 (2), and in particular Article 5 thereof,\nWhereas on 25 October 1985 the Government of the Federal Republic of Germany forwarded an addendum to the programme approved by Commission Decision 81/323/EEC (3) relating to the promotion of potato marketing in the land of North Rhine Westphalia and on 24 April 1986 submitted supplementary information;\nWhereas the purpose of this addendum is to permit the expansion and improvement of facilities for the treatment, reception, grading, storage and marketing of potatoes, so as to ensure satisfactory storage conditions for this fragile product and thereby help to improve the situation in the sector and upgrade the products; whereas it therefore constitutes a programme within the meaning of Article 2 of Regulation (EEC) No 355/77;\nWhereas the addendum contains sufficient information, as required in Article 3 of Regulation (EEC) No 355/77, to show that the objectives of Article 1 of the Regulation can be achieved in respect of potato marketing in the land of North Rhine Westphalia; whereas the estimated time required for execution of the addendum does not exceed the limits laid down in Article 3 (1) (g) of the Regulation;\nWhereas the measures provided for in this Decision are in accordance with the opinion of the Standing Committee on Agricultural Structure,",
         "['The addendum to the programme relating to potato marketing in the land of North Rhine Westphalia forwarded by the Government of the Federal Republic of Germany pursuant to Regulation (EEC) No 355/77 on 25 October 1985 concerning which supplementary information was submitted on 24 April 1986 is hereby approved.', 'This Decision is addressed to the Federal Republic of Germany.']",
         "['2548', '2792', '4663']",
         "train",
         "86/331/EEC: Commission Decision of 23 June 1986 approving an addendum to the programme relating to potato marketing in the land of North Rhine Westphalia pursuant to Council Regulation (EEC) No 355/77 (Only the German text is authentic)\n\n,\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Regulation (EEC) No 355/77 of 15 February 1977 on common measures to improve the conditions under which agricultural and fishery products are processed and marketed (1), as last amended by Regulation (EEC) No 3827/85 (2), and in particular Article 5 thereof,\nWhereas on 25 October 1985 the Government of the Federal Republic of Germany forwarded an addendum to the programme approved by Commission Decision 81/323/EEC (3) relating to the promotion of potato marketing in the land of North Rhine Westphalia and on 24 April 1986 submitted supplementary information;\nWhereas the purpose of this addendum is to permit the expansion and improvement of facilities for the treatment, reception, grading, storage and marketing of potatoes, so as to ensure satisfactory storage conditions for this fragile product and thereby help to improve the situation in the sector and upgrade the products; whereas it therefore constitutes a programme within the meaning of Article 2 of Regulation (EEC) No 355/77;\nWhereas the addendum contains sufficient information, as required in Article 3 of Regulation (EEC) No 355/77, to show that the objectives of Article 1 of the Regulation can be achieved in respect of potato marketing in the land of North Rhine Westphalia; whereas the estimated time required for execution of the addendum does not exceed the limits laid down in Article 3 (1) (g) of the Regulation;\nWhereas the measures provided for in this Decision are in accordance with the opinion of the Standing Committee on Agricultural Structure,\nThe addendum to the programme relating to potato marketing in the land of North Rhine Westphalia forwarded by the Government of the Federal Republic of Germany pursuant to Regulation (EEC) No 355/77 on 25 October 1985 concerning which supplementary information was submitted on 24 April 1986 is hereby approved. This Decision is addressed to the Federal Republic of Germany.",
         "2245",
         "Decision",
         "Decision"
        ],
        [
         "20",
         "32007D0123",
         "Decision",
         "2007/123/EC: Commission Decision of 20 February 2007 granting an exemption to Italy under Council Directive 92/119/EEC for the transport of pigs for slaughter on public and private roads to a slaughterhouse within a protection zone (notified under document number C(2007) 499)\n",
         "21.2.2007 EN Official Journal of the European Union L 52/10\nCOMMISSION DECISION\nof 20 February 2007\ngranting an exemption to Italy under Council Directive 92/119/EEC for the transport of pigs for slaughter on public and private roads to a slaughterhouse within a protection zone\n(notified under document number C(2007) 499)\n(Only the Italian text is authentic)\n(2007/123/EC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Directive 92/119/EEC of 17 December 1992 introducing general Community measures for the control of certain animal diseases and specific measures relating to swine vesicular disease (1) and in particular point 7(2)(d) of Annex II thereof,\nWhereas:\n(1) On 15 November 2006 a protection zone was established by the competent authority in Italy around an outbreak of swine vesicular disease in the municipality of Romano di Lombardia, Province of Bergamo, in accordance with Article 10 of Directive 92/119/EEC.\n(2) Accordingly, the movement and transport of pigs on public and private roads within that protection zone have been prohibited.\n(3) However, Italy has submitted a request for an exemption from that prohibition for the transport of pigs for slaughter coming from outside that protection zone, on public and private roads within the protection zone, in order to transport them to a slaughterhouse situated in the protection zone.\n(4) It is appropriate to provide for that exemption, subject to the condition that Italy takes strict control and precaution measures that guarantee that there is no risk of the spread of the disease.\n(5) The measures provided for in this Decision are in accordance with the opinion of the Standing Committee on the Food Chain and Animal Health,",
         "['1.\\xa0\\xa0\\xa0Italy may authorise the transport of pigs for slaughter coming from outside the protection zone established on 15 November 2006 around the outbreak of swine vesicular disease that occurred in the municipality of Romano di Lombardia, Province of Bergamo (the pigs), on public and private roads within that protection zone, to slaughterhouse IMC No 825 M (the slaughterhouse), under the following conditions:\\n(a) the dispatch of the pigs must be notified at least 24 hours in advance by the official veterinarian for the holding of origin to the official veterinarian for the slaughterhouse;\\n(b) the transport of the pigs to the slaughterhouse must be via a corridor; details of that corridor must be laid down in advance by Italy;\\n(c) vehicles carrying the pigs must be sealed by the competent authority before or on entry to the corridor; at the time of sealing, the competent authority must record the registration number of the vehicle and the number of pigs transported therein;\\n(d) on arrival at the slaughterhouse, the competent authority shall:\\n(i) inspect and remove the seal on the vehicle;\\n(ii) be present at the unloading of the pigs;\\n(iii) record the registration number of the vehicle and the number of pigs therein.\\n2.\\xa0\\xa0\\xa0Any vehicle carrying pigs to the slaughterhouse shall undergo, immediately following unloading, cleaning and disinfection under official control and in accordance with the instructions of the competent authority.', 'This Decision is addressed to the Republic of Italy.']",
         "['1445', '1519', '1755', '1857', '192', '2560', '4152', '5581']",
         "train",
         "2007/123/EC: Commission Decision of 20 February 2007 granting an exemption to Italy under Council Directive 92/119/EEC for the transport of pigs for slaughter on public and private roads to a slaughterhouse within a protection zone (notified under document number C(2007) 499)\n\n,\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Directive 92/119/EEC of 17 December 1992 introducing general Community measures for the control of certain animal diseases and specific measures relating to swine vesicular disease (1) and in particular point 7(2)(d) of Annex II thereof,\nWhereas:\n(1) On 15 November 2006 a protection zone was established by the competent authority in Italy around an outbreak of swine vesicular disease in the municipality of Romano di Lombardia, Province of Bergamo, in accordance with Article 10 of Directive 92/119/EEC.\n(2) Accordingly, the movement and transport of pigs on public and private roads within that protection zone have been prohibited.\n(3) However, Italy has submitted a request for an exemption from that prohibition for the transport of pigs for slaughter coming from outside that protection zone, on public and private roads within the protection zone, in order to transport them to a slaughterhouse situated in the protection zone.\n(4) It is appropriate to provide for that exemption, subject to the condition that Italy takes strict control and precaution measures that guarantee that there is no risk of the spread of the disease.\n(5) The measures provided for in this Decision are in accordance with the opinion of the Standing Committee on the Food Chain and Animal Health,\n1.   Italy may authorise the transport of pigs for slaughter coming from outside the protection zone established on 15 November 2006 around the outbreak of swine vesicular disease that occurred in the municipality of Romano di Lombardia, Province of Bergamo (the pigs), on public and private roads within that protection zone, to slaughterhouse IMC No 825 M (the slaughterhouse), under the following conditions:\n(a) the dispatch of the pigs must be notified at least 24 hours in advance by the official veterinarian for the holding of origin to the official veterinarian for the slaughterhouse;\n(b) the transport of the pigs to the slaughterhouse must be via a corridor; details of that corridor must be laid down in advance by Italy;\n(c) vehicles carrying the pigs must be sealed by the competent authority before or on entry to the corridor; at the time of sealing, the competent authority must record the registration number of the vehicle and the number of pigs transported therein;\n(d) on arrival at the slaughterhouse, the competent authority shall:\n(i) inspect and remove the seal on the vehicle;\n(ii) be present at the unloading of the pigs;\n(iii) record the registration number of the vehicle and the number of pigs therein.\n2.   Any vehicle carrying pigs to the slaughterhouse shall undergo, immediately following unloading, cleaning and disinfection under official control and in accordance with the instructions of the competent authority. This Decision is addressed to the Republic of Italy.",
         "3157",
         "Decision",
         "Decision"
        ],
        [
         "21",
         "31997D0642",
         "Decision",
         "97/642/EC, Euratom: Council Decision of 22 September 1997 appointing a member of the Economic and Social Committee\n",
         "COUNCIL DECISION of 22 September 1997 appointing a member of the Economic and Social Committee (97/642/EC, Euratom)\nTHE COUNCIL OF THE EUROPEAN UNION",
         ",\nHaving regard to the Treaty establishing the European Community, and in particular Article 194 thereof,\nHaving regard to the Treaty establishing the European Atomic Energy Community, and in particular Article 166 thereof,\nHaving regard to Council Decision 94/660/EC, Euratom of 26 September 1994 appointing the members of the Economic and Social Committee for the period up to 20 September 1998 (1),\nWhereas a seat as a member of that Committee has fallen vacant following the death of Mr JosĂŠ Luis Mayayo Bello, of which the Council was notified on 28 January 1997;\nHaving regard to the nominations submitted by the Spanish Government,\nHaving obtained the opinion of the Commission of the European Communities,",
         "[\"Mr D. Pedro Barato Triguero is hereby appointed a member of the Economic and Social Committee in place of Mr JosĂŠ Luis Mayayo Bello for the remainder of the latter's term of office, which runs until 20 September 1998.\"]",
         "['3559', '6054']",
         "train",
         "97/642/EC, Euratom: Council Decision of 22 September 1997 appointing a member of the Economic and Social Committee\n\n,\nHaving regard to the Treaty establishing the European Community, and in particular Article 194 thereof,\nHaving regard to the Treaty establishing the European Atomic Energy Community, and in particular Article 166 thereof,\nHaving regard to Council Decision 94/660/EC, Euratom of 26 September 1994 appointing the members of the Economic and Social Committee for the period up to 20 September 1998 (1),\nWhereas a seat as a member of that Committee has fallen vacant following the death of Mr JosĂŠ Luis Mayayo Bello, of which the Council was notified on 28 January 1997;\nHaving regard to the nominations submitted by the Spanish Government,\nHaving obtained the opinion of the Commission of the European Communities,\nMr D. Pedro Barato Triguero is hereby appointed a member of the Economic and Social Committee in place of Mr JosĂŠ Luis Mayayo Bello for the remainder of the latter's term of office, which runs until 20 September 1998.",
         "1049",
         "Decision",
         "Decision"
        ],
        [
         "22",
         "32004D0121",
         "Decision",
         "2004/121/EC: Commission Decision of 6 February 2004 adjusting the thresholds referred to in Article 157(b) and Article 158(1)(a) and (c) of Regulation (EC, Euratom) No 2342/2002 laying down detailed rules for the implementation of the Financial Regulation\n",
         "Commission Decision\nof 6 February 2004\nadjusting the thresholds referred to in Article 157(b) and Article 158(1)(a) and (c) of Regulation (EC, Euratom) No 2342/2002 laying down detailed rules for the implementation of the Financial Regulation\n(2004/121/EC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to Commission Regulation (EC, Euratom) No 2342/2002 of 23 December 2002 laying down detailed rules for the implementation of Council Regulation (EC, Euratom) No 1605/2002 on the Financial Regulation applicable to the general budget of the European Communities(1), and in particular Article 271 thereof,\nWhereas:\n(1) Article 271(2) stipulates that the thresholds applicable to public procurement contracts are to be adjusted every two years pursuant to the provisions of the directives on the coordination of public procurement procedures.\n(2) The euro equivalents of the thresholds, fixed in SDR(2) in the directives, which are to be applied from 1 January 2004 have been published in the Official Journal(3),",
         "['The euro equivalents of the thresholds applicable to public procurement contracts shall be adjusted as set out below, with effect from 1 January 2004:\\n>TABLE>', \"This Decision shall enter into force on the day of its publication in the Official Journal of the European Union. It shall be notified to the other institutions and bodies by the Commission's accounting officer.\"]",
         "['1810', '3119', '929']",
         "train",
         "2004/121/EC: Commission Decision of 6 February 2004 adjusting the thresholds referred to in Article 157(b) and Article 158(1)(a) and (c) of Regulation (EC, Euratom) No 2342/2002 laying down detailed rules for the implementation of the Financial Regulation\n\n,\nHaving regard to Commission Regulation (EC, Euratom) No 2342/2002 of 23 December 2002 laying down detailed rules for the implementation of Council Regulation (EC, Euratom) No 1605/2002 on the Financial Regulation applicable to the general budget of the European Communities(1), and in particular Article 271 thereof,\nWhereas:\n(1) Article 271(2) stipulates that the thresholds applicable to public procurement contracts are to be adjusted every two years pursuant to the provisions of the directives on the coordination of public procurement procedures.\n(2) The euro equivalents of the thresholds, fixed in SDR(2) in the directives, which are to be applied from 1 January 2004 have been published in the Official Journal(3),\nThe euro equivalents of the thresholds applicable to public procurement contracts shall be adjusted as set out below, with effect from 1 January 2004:\n>TABLE> This Decision shall enter into force on the day of its publication in the Official Journal of the European Union. It shall be notified to the other institutions and bodies by the Commission's accounting officer.",
         "1353",
         "Decision",
         "Decision"
        ],
        [
         "23",
         "31999D0040",
         "Decision",
         "1999/40/EC: Commission Decision of 21 December 1998 repealing Decision 96/276/EC on certain protective measures in respect of bivalve molluscs from Tunisia (notified under document number C(1998) 4340) (Text with EEA relevance)\n",
         "COMMISSION DECISION of 21 December 1998 repealing Decision 96/276/EC on certain protective measures in respect of bivalve molluscs from Tunisia (notified under document number C(1998) 4340) (Text with EEA relevance) (1999/40/EC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Directive 90/675/EEC of 10 December 1990 laying down the principles governing the organisation of veterinary checks on products entering the Community from third countries (1), as last amended by the Directive 96/43/EC (2), and in particular Article 19 thereof,\nWhereas, following the detection of diarrhoeic toxin in bivalve molluscs imported into the Community from Tunisia, the Commission adopted Decision 96/276/EC on certain protective measures in respect of bivalve molluscs from Tunisia (3);\nWhereas a team of Commission experts visited Tunisia to assess the protective measures implemented by the Tunisian authorities;\nWhereas the protective measures and the health guarantees provided by the Tunisian authorities are sufficient to permit the resumption of imports of bivalve molluscs from Tunisia;\nWhereas Commission Decision 98/569/EC (4) lays down special conditions governing imports of live bivalve molluscs, echinoderms, tunicates and marine gastropods originating in Tunisia;\nWhereas, therefore, Decision 96/276/EC should be repealed;\nWhereas the measures provided for in this Decision are in accordance with the opinion of the Standing Veterinary Committee,",
         "['Decision 96/276/EC is repealed.', 'Member States shall amend the measures they apply to imports to make them conform with this Decision. They shall inform the Commission of the steps taken.', 'This Decision is addressed to the Member States.']",
         "['1445', '1961', '3135', '3579', '3730', '4578']",
         "train",
         "1999/40/EC: Commission Decision of 21 December 1998 repealing Decision 96/276/EC on certain protective measures in respect of bivalve molluscs from Tunisia (notified under document number C(1998) 4340) (Text with EEA relevance)\n\n,\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Directive 90/675/EEC of 10 December 1990 laying down the principles governing the organisation of veterinary checks on products entering the Community from third countries (1), as last amended by the Directive 96/43/EC (2), and in particular Article 19 thereof,\nWhereas, following the detection of diarrhoeic toxin in bivalve molluscs imported into the Community from Tunisia, the Commission adopted Decision 96/276/EC on certain protective measures in respect of bivalve molluscs from Tunisia (3);\nWhereas a team of Commission experts visited Tunisia to assess the protective measures implemented by the Tunisian authorities;\nWhereas the protective measures and the health guarantees provided by the Tunisian authorities are sufficient to permit the resumption of imports of bivalve molluscs from Tunisia;\nWhereas Commission Decision 98/569/EC (4) lays down special conditions governing imports of live bivalve molluscs, echinoderms, tunicates and marine gastropods originating in Tunisia;\nWhereas, therefore, Decision 96/276/EC should be repealed;\nWhereas the measures provided for in this Decision are in accordance with the opinion of the Standing Veterinary Committee,\nDecision 96/276/EC is repealed. Member States shall amend the measures they apply to imports to make them conform with this Decision. They shall inform the Commission of the steps taken. This Decision is addressed to the Member States.",
         "1730",
         "Decision",
         "Decision"
        ],
        [
         "24",
         "31995D0523",
         "Decision",
         "95/523/EC: Council Decision of 27 November 1995 concerning the conclusion of an Agreement between the European Community and Canada establishing a cooperation programme in higher education and training\n",
         "COUNCIL DECISION of 27 November 1995 concerning the conclusion of an Agreement between the European Community and Canada establishing a cooperation programme in higher education and training (95/523/EC)\nTHE COUNCIL OF THE EUROPEAN UNION",
         ",\nHaving regard to the Treaty establishing the European Community, and in particular Articles 126 and 127 in conjunction with Article 228 (2) first sentence and (3) first subparagraph thereof,\nHaving regard to the proposal from the Commission,\nHaving regard to the opinion of the European Parliament, (1),\nWhereas by its Decision of 21 November 1994 the Council authorized the Commission to negotiate agreements for cooperation in higher education and vocational training between the European Community, Canada and the United States of America;\nWhereas the Community and Canada expect to obtain mutual benefit from such operation, which must, on the Community's side, be complementary to bilateral programmes between the Member States and Canada and provide a European added value;\nWhereas the Agreement between the European Community and Canada establishing a cooperation programme in higher education and training should be approved,",
         "['The Agreement between the European Community and Canada establishing a cooperation programme in higher education and training is hereby approved on behalf of the Community.\\nThe text of the Agreement is attached to this Decision.', \"The financial reference amount to fulfil the Community's financial obligations mentioned in Article 7 of the Agreement shall be ECU 3,24 million for the five-year period provided for in Article 11 (2) thereof.\\nThe annual appropriations shall be authorized by the budget authority within the limit of the financial perspective.\", 'The delegation of the European Community to the Joint Committee referred to in Article 5 of the Agreement shall consist of a representative from the Commission assisted by a representative from each Member State.', 'The President of the Council is hereby authorized to designate the person or persons empowered to sign the Agreement on behalf of the Council of the European Union and to carry out the notifications provided for in Article 11 of the Agreement.']",
         "['1074', '3060', '5100', '5176', '5404', '800']",
         "train",
         "95/523/EC: Council Decision of 27 November 1995 concerning the conclusion of an Agreement between the European Community and Canada establishing a cooperation programme in higher education and training\n\n,\nHaving regard to the Treaty establishing the European Community, and in particular Articles 126 and 127 in conjunction with Article 228 (2) first sentence and (3) first subparagraph thereof,\nHaving regard to the proposal from the Commission,\nHaving regard to the opinion of the European Parliament, (1),\nWhereas by its Decision of 21 November 1994 the Council authorized the Commission to negotiate agreements for cooperation in higher education and vocational training between the European Community, Canada and the United States of America;\nWhereas the Community and Canada expect to obtain mutual benefit from such operation, which must, on the Community's side, be complementary to bilateral programmes between the Member States and Canada and provide a European added value;\nWhereas the Agreement between the European Community and Canada establishing a cooperation programme in higher education and training should be approved,\nThe Agreement between the European Community and Canada establishing a cooperation programme in higher education and training is hereby approved on behalf of the Community.\nThe text of the Agreement is attached to this Decision. The financial reference amount to fulfil the Community's financial obligations mentioned in Article 7 of the Agreement shall be ECU 3,24 million for the five-year period provided for in Article 11 (2) thereof.\nThe annual appropriations shall be authorized by the budget authority within the limit of the financial perspective. The delegation of the European Community to the Joint Committee referred to in Article 5 of the Agreement shall consist of a representative from the Commission assisted by a representative from each Member State. The President of the Council is hereby authorized to designate the person or persons empowered to sign the Agreement on behalf of the Council of the European Union and to carry out the notifications provided for in Article 11 of the Agreement.",
         "2151",
         "Decision",
         "Decision"
        ],
        [
         "25",
         "32003D0339",
         "Decision",
         "2003/339/EC: Council Decision of 6 May 2003 appointing an alternate member of the Committee of the Regions\n",
         "Council Decision\nof 6 May 2003\nappointing an alternate member of the Committee of the Regions\n(2003/339/EC)\nTHE COUNCIL OF THE EUROPEAN UNION",
         ",\nHaving regard to the Treaty establishing the European Community, and in particular Article 263 thereof,\nHaving regard to the proposal from the German Government,\nWhereas:\n(1) On 22 January 2002 the Council adopted Decision 2002/60/EC appointing the members and alternate members of the Committee of the Regions(1).\n(2) The seat of an alternate member of the Committee of the Regions has become vacant following the resignation of Ms Ulrike RODUST, of which the Council was notified on 2 April 2003,",
         "['Ms Heide SIMONIS is hereby appointed an alternate member of the Committee of the Regions in place of Ms Ulrike RODUST for the remainder of her term of office, which ends on 25 January 2006.']",
         "['1318', '3559', '4328', '5508']",
         "train",
         "2003/339/EC: Council Decision of 6 May 2003 appointing an alternate member of the Committee of the Regions\n\n,\nHaving regard to the Treaty establishing the European Community, and in particular Article 263 thereof,\nHaving regard to the proposal from the German Government,\nWhereas:\n(1) On 22 January 2002 the Council adopted Decision 2002/60/EC appointing the members and alternate members of the Committee of the Regions(1).\n(2) The seat of an alternate member of the Committee of the Regions has become vacant following the resignation of Ms Ulrike RODUST, of which the Council was notified on 2 April 2003,\nMs Heide SIMONIS is hereby appointed an alternate member of the Committee of the Regions in place of Ms Ulrike RODUST for the remainder of her term of office, which ends on 25 January 2006.",
         "798",
         "Decision",
         "Decision"
        ],
        [
         "26",
         "31977D0449",
         "Decision",
         "77/449/EEC: Commission Decision of 27 June 1977 on the implementation of the reform of agricultural structures in France pursuant to Council Directive 72/159/EEC of 17 April 1972 (Only the French text is authentic)\n",
         "COMMISSION DECISION  of 27 June 1977  on the implementation of the reform of agricultural structures in France pursuant to Council Directive 72/159/EEC of 17 April 1972  (Only the French text is authentic)  (77/449/EEC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Directive 72/159/EEC of 17 April 1972 on the modernization of farms (1), as amended by Directive 76/837/EEC of 25 October 1976 (2), and in particular Article 18 (3) thereof,\nWhereas on 15 March 1977 the French Government forwarded, pursuant to Article 17 (4) thereof, the Decree of 7 December 1976 concerning development plans for farms;\nWhereas Article 18 (3) of Directive 72/159/EEC requires the Commission to determine whether, having regard to the abovementioned Decree, the existing provisions in France for the implementation of the said Directive, which form the subject of Commission Decision 77/207/EEC (3), continue to satisfy the conditions for financial contribution by the Community to common measures within the meaning of Article 15 thereof;\nWhereas the abovementioned Decree meets the requirements of the said Directive;\nWhereas the measures provided for in this Decision are in accordance with the opinion of the Standing Committee on Agricultural Structure,",
         "['Having regard to the Decree concerning development plans for farms, the existing provisions for the implementation of Directive 72/159/EEC in France continue to satisfy the conditions for financial contribution by the Community to common measures within the meaning of Article 15 of Directive 72/159/EEC.', 'This Decision is addressed to the French Republic.']",
         "['1085', '1958', '2970', '2971', '889', '980']",
         "train",
         "77/449/EEC: Commission Decision of 27 June 1977 on the implementation of the reform of agricultural structures in France pursuant to Council Directive 72/159/EEC of 17 April 1972 (Only the French text is authentic)\n\n,\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Directive 72/159/EEC of 17 April 1972 on the modernization of farms (1), as amended by Directive 76/837/EEC of 25 October 1976 (2), and in particular Article 18 (3) thereof,\nWhereas on 15 March 1977 the French Government forwarded, pursuant to Article 17 (4) thereof, the Decree of 7 December 1976 concerning development plans for farms;\nWhereas Article 18 (3) of Directive 72/159/EEC requires the Commission to determine whether, having regard to the abovementioned Decree, the existing provisions in France for the implementation of the said Directive, which form the subject of Commission Decision 77/207/EEC (3), continue to satisfy the conditions for financial contribution by the Community to common measures within the meaning of Article 15 thereof;\nWhereas the abovementioned Decree meets the requirements of the said Directive;\nWhereas the measures provided for in this Decision are in accordance with the opinion of the Standing Committee on Agricultural Structure,\nHaving regard to the Decree concerning development plans for farms, the existing provisions for the implementation of Directive 72/159/EEC in France continue to satisfy the conditions for financial contribution by the Community to common measures within the meaning of Article 15 of Directive 72/159/EEC. This Decision is addressed to the French Republic.",
         "1648",
         "Decision",
         "Decision"
        ],
        [
         "27",
         "31979D0576",
         "Decision",
         "79/576/EEC: Commission Decision of 13 June 1979 refusing to accept the scientific character of the apparatus described as 'JMR-1 Doppler satellite survey receiver'\n",
         "COMMISSION DECISION  of 13 June 1979  refusing to accept the scientific character of the apparatus described as \"JMR-1 Doppler satellite survey receiver\"  (79/576/EEC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Regulation (EEC) No 1798/75 of 10 July 1975 on the importation free of Common Customs Tariff duties of educational, scientific and cultural materials (1),\nHaving regard to Commission Regulation (EEC) No 3195/75 of 2 December 1975 laying down provisions for the implementation of Regulation (EEC) No 1798/75 (2), and in particular Articles 4 and 5 thereof,\nWhereas, by letter dated 4 December 1978, the United Kingdom Government requested the Commission to invoke the procedure laid down in Articles 4 and 5 of Regulation (EEC) No 3195/75 in order to determine whether or not the apparatus described as \"JMR-1 Doppler satellite survey receiver\", intended for measuring the total electron content of the ionosphere, should be considered as a scientific apparatus and, where the reply is in the affirmative, whether apparatus of equivalent scientific value is currently being manufactured in the Community;\nWhereas, in accordance with the provisions of Article 4 (5) of Regulation (EEC) No 3195/75, a group of experts composed of representatives of all the Member States met on 27 April 1979 within the Committee on Duty-Free Arrangements to examine this particular case;\nWhereas this examination showed that the apparatus in question is a portable receiving and data recording system, which does not have the requisite objective technical characteristics making it specifically suited to scientific research ; whereas this apparatus constitutes a special application of an instrument with normal technical characteristics ; whereas moreover it is an apparatus in current use in particular for locating mineral oil deposits under the sea bed ; whereas its use in the case in question could not alone confer upon it the character of a scientific apparatus ; whereas it therefore cannot be regarded as a scientific apparatus,",
         "['The apparatus described as \"JMR-1 Doppler satellite survey receiver\" is not considered to be a scientific apparatus.', 'This Decision is addressed to the Member States.']",
         "['1091', '3842', '4381']",
         "train",
         "79/576/EEC: Commission Decision of 13 June 1979 refusing to accept the scientific character of the apparatus described as 'JMR-1 Doppler satellite survey receiver'\n\n,\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Regulation (EEC) No 1798/75 of 10 July 1975 on the importation free of Common Customs Tariff duties of educational, scientific and cultural materials (1),\nHaving regard to Commission Regulation (EEC) No 3195/75 of 2 December 1975 laying down provisions for the implementation of Regulation (EEC) No 1798/75 (2), and in particular Articles 4 and 5 thereof,\nWhereas, by letter dated 4 December 1978, the United Kingdom Government requested the Commission to invoke the procedure laid down in Articles 4 and 5 of Regulation (EEC) No 3195/75 in order to determine whether or not the apparatus described as \"JMR-1 Doppler satellite survey receiver\", intended for measuring the total electron content of the ionosphere, should be considered as a scientific apparatus and, where the reply is in the affirmative, whether apparatus of equivalent scientific value is currently being manufactured in the Community;\nWhereas, in accordance with the provisions of Article 4 (5) of Regulation (EEC) No 3195/75, a group of experts composed of representatives of all the Member States met on 27 April 1979 within the Committee on Duty-Free Arrangements to examine this particular case;\nWhereas this examination showed that the apparatus in question is a portable receiving and data recording system, which does not have the requisite objective technical characteristics making it specifically suited to scientific research ; whereas this apparatus constitutes a special application of an instrument with normal technical characteristics ; whereas moreover it is an apparatus in current use in particular for locating mineral oil deposits under the sea bed ; whereas its use in the case in question could not alone confer upon it the character of a scientific apparatus ; whereas it therefore cannot be regarded as a scientific apparatus,\nThe apparatus described as \"JMR-1 Doppler satellite survey receiver\" is not considered to be a scientific apparatus. This Decision is addressed to the Member States.",
         "2252",
         "Decision",
         "Decision"
        ],
        [
         "28",
         "31987D0085",
         "Decision",
         "87/85/EEC: Commission Decision of 7 January 1987 on the setting-up of an Advisory Committee on Social Questions affecting Farmers and the Members of their families\n",
         "COMMISSION DECISION of 7 January 1987 on the setting-up of an Advisory Committee on Social Questions affecting Farmers and the Members of their Families (87/85/EEC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Economic Community,\nWhereas the Advisory Committee on Social Questions affecting Farmers and the Members of their Families was set up by Commission Decision 64/18/EEC (1), replaced by Commission Decision 76/410/EEC (2), as last amended by Decision 83/77/EEC (3);\nWhereas, following the accession of new Member States to the Community, the number of seats on the Committee should be increased and they should be reallocated; whereas the procedure for the replacement of members should also be adjusted;\nWhereas the provisions concerning the Advisory Committee on Social Questions affecting Farmers and the Members of their Families have been amended several times and have therefore become difficult to apply; whereas they should therefore be consolidated;\nWhereas the Commission should seek the views of producers, traders and rural families on social questions affecting agriculture;\nWhereas representatives of the various interests directly concerned by the abovementioned questions must have an opportunity to participate in the drafting of the opinions requested by the Commission;\nWhereas the trade associations concerned and the associations of rural families in the Member States have set up organizations at Community level which are in a position to represent those concerned in all the Member States,",
         "[\"1.  There shall be attached to the Commission an Advisory Committee on Social Questions affecting Farmers and the Members of their Families (hereinafter called 'the Committee').\\n2.  The Committee shall be composed of representatives of the following interests: farmers, paid agricultural workers and rural families.\\n(4) OJ No 2, 10. 1. 1964, p. 25/64.\\n(5) OJ No L 106, 23. 4. 1976, p. 36.\\n(6) OJ No L 51, 24. 2. 1983, p. 34.\", '1.  The Committee may be consulted by the Commission on any social questions affecting farmers and members of their families working on the holding, all such questions being considered both in themselves and in relation to their repercussions  on the agricultural population as a whole.\\n2.  At the request on one of the interests referred to in Article 1 (2), the Committee may on its own initiative and in regard to a matter within its terms of reference forward opinions and reports to the Commission.', \"1.  The Committee shall consist of 32 members.\\n2.  Seats on the Committee shall be apportioned as follows:\\n- 22 to farmers' representatives, including four to representatives of young farmers,\\n- seven to representatives of paid agricultural workers,\\n- three to representatives of rural families.\", \"1.  Members of the Committee shall be appointed by the Commission on proposals from the following organizations set up at Community level: Committee of Agricultural Organizations in the EEC (COPA), European Federation of Agricultural Workers'  Unions within the Community (EFA), Committee of Family Organizations for the European Communities (COFACE).\\nFor each seat to be filled, these bodies shall put forward the names of two candidates of different nationality.\\n2.  The term of office for members of the Committee shall be three years. Their appointments may be renewed. Members shall not be remunerated for their services.\\nAfter the expiry of the three years members of the Committee shall remain in office until they are replaced or until their appointments are renewed.\\nIn the event of the resignation or decease of a member or a request from the body having proposed a member that he be replaced, he shall be replaced in accordance with the procedure laid down in paragraph 1.\\n3.  A list of the members of the Committee shall be published by the Commission, for information purposes, in the Official Journal of the European Communities.\", '1.  After consulting the Commission, the Committee shall elect a chairman for a period of three years.\\nThe chairman shall be elected, in the case of the first ballot, by a two-thirds majority of the members present and, in the case of subsequent ballots, by a simple majority of the members present. In the event of a tie, the Commission shall provide a  chairman on a temporary basis.\\n2.  The Committee shall elect two vice-chairmen for a period of three years. The vice-chairmen may not represent the same interest as the chairman.\\nThe election shall take place in accordance with the procedure laid down in paragraph 1.\\nThe officers shall prepare and organize the work of the Committee.', '1.  Only the Commission representatives, the members of the Committee, or persons replacing them in their absence, and persons invited in accordance with paragraphs 3 and 4 may participate in or attend meedings.\\n2.  Should a member be unable to attend a meeting, the organization or organizations to which a seat is allocated may appoint a person to take his place. This person shall be selected from a list drawn up by mutual agreement between the Commission and  the organization or organizations in question and containing a number of names equal to half the total number of members representing the organization or organizations in question.\\nThis number shall be not less than one and not more\\nthan 12.\\nThe secretariat of the Committee must be informed of such replacement of a member at least seven days before a meeting.\\n3.  At the request of an organization to which one or more seats are allocated, the chairman may, in agreement with the Commission staff, invite its general secretary or a member of its secretariat to attend the meetings of the Committee as an observer.  Should he be unable to attend, however, the general secretary may have his seat as an observer taken by another person designated by him.\\nObservers shall not have the right to speak. They may, however, be invited to do so by the chairman in agreement with the Commission staff.\\n4.  At the request of an organization to which one or more seats are allocated, and when the matters on the agenda are of a highly technical nature outside the normal framework of the deliberations of the Committee, the chairman may, in agreement with  the Commission staff, invite one or more experts to take part in the deliberations of the Committee.\\nThe Commission may, on its own initiative, invite any person particularly well qualified in one of the subjects on the agenda to take part in the deliberations of the Committee as an expert.\\nHowever, experts shall participate only in the discussion of the matter concerning which they were invited to attend.', 'In agreement with the Commission staff, the Committee may set up working to facilitate its work.', '1.  The Committee shall be convened by the Commission and shall meet at the Commission headquarters. Meetings of the officers shall be convened by the chairman by arrangement with the Commission.\\n2.  Representatives of the Commission departments concerned shall take part in meetings of the Committee, its officers and working parties.\\n3.  Secretarial services for the Committee and its working parties shall be provided by the Commission.', 'No vote shall be taken on the matters discussed by the Committee.\\nThe Commission may, when seeking the opinion of the Committee, set a time limit within which such opinion must be given.\\nThe views expressed by the various interests represented\\nshall be included in a summary record forwarded to the Commission.\\nIn the event of unanimous agreement being reached in the Committee on the opinion to be given, the Committee shall formulate joint conclusions and attach them to the summary record.', '0\\nWithout prejudice to the provisions of Article 214 of the\\nTreaty, where the Commission informs them that the opinions requested or the question raised is on a matter of a confidential nature, members of the Committee shall be under an obligation not to disclose information which has\\ncome to their knowledge through the work of the Committee or of its working parties.\\nIn such cases, only Committee members and representatives of the Commission departments concerned may be present at the meetings.', '1\\nCommission Decision 76/410/EEC is hereby repealed.', '2\\nThis Decision shall enter into force on 1 January 1987.']",
         "['2690', '5511', '6050', '936']",
         "train",
         "87/85/EEC: Commission Decision of 7 January 1987 on the setting-up of an Advisory Committee on Social Questions affecting Farmers and the Members of their families\n\n,\nHaving regard to the Treaty establishing the European Economic Community,\nWhereas the Advisory Committee on Social Questions affecting Farmers and the Members of their Families was set up by Commission Decision 64/18/EEC (1), replaced by Commission Decision 76/410/EEC (2), as last amended by Decision 83/77/EEC (3);\nWhereas, following the accession of new Member States to the Community, the number of seats on the Committee should be increased and they should be reallocated; whereas the procedure for the replacement of members should also be adjusted;\nWhereas the provisions concerning the Advisory Committee on Social Questions affecting Farmers and the Members of their Families have been amended several times and have therefore become difficult to apply; whereas they should therefore be consolidated;\nWhereas the Commission should seek the views of producers, traders and rural families on social questions affecting agriculture;\nWhereas representatives of the various interests directly concerned by the abovementioned questions must have an opportunity to participate in the drafting of the opinions requested by the Commission;\nWhereas the trade associations concerned and the associations of rural families in the Member States have set up organizations at Community level which are in a position to represent those concerned in all the Member States,\n1.  There shall be attached to the Commission an Advisory Committee on Social Questions affecting Farmers and the Members of their Families (hereinafter called 'the Committee').\n2.  The Committee shall be composed of representatives of the following interests: farmers, paid agricultural workers and rural families.\n(4) OJ No 2, 10. 1. 1964, p. 25/64.\n(5) OJ No L 106, 23. 4. 1976, p. 36.\n(6) OJ No L 51, 24. 2. 1983, p. 34. 1.  The Committee may be consulted by the Commission on any social questions affecting farmers and members of their families working on the holding, all such questions being considered both in themselves and in relation to their repercussions  on the agricultural population as a whole.\n2.  At the request on one of the interests referred to in Article 1 (2), the Committee may on its own initiative and in regard to a matter within its terms of reference forward opinions and reports to the Commission. 1.  The Committee shall consist of 32 members.\n2.  Seats on the Committee shall be apportioned as follows:\n- 22 to farmers' representatives, including four to representatives of young farmers,\n- seven to representatives of paid agricultural workers,\n- three to representatives of rural families. 1.  Members of the Committee shall be appointed by the Commission on proposals from the following organizations set up at Community level: Committee of Agricultural Organizations in the EEC (COPA), European Federation of Agricultural Workers'  Unions within the Community (EFA), Committee of Family Organizations for the European Communities (COFACE).\nFor each seat to be filled, these bodies shall put forward the names of two candidates of different nationality.\n2.  The term of office for members of the Committee shall be three years. Their appointments may be renewed. Members shall not be remunerated for their services.\nAfter the expiry of the three years members of the Committee shall remain in office until they are replaced or until their appointments are renewed.\nIn the event of the resignation or decease of a member or a request from the body having proposed a member that he be replaced, he shall be replaced in accordance with the procedure laid down in paragraph 1.\n3.  A list of the members of the Committee shall be published by the Commission, for information purposes, in the Official Journal of the European Communities. 1.  After consulting the Commission, the Committee shall elect a chairman for a period of three years.\nThe chairman shall be elected, in the case of the first ballot, by a two-thirds majority of the members present and, in the case of subsequent ballots, by a simple majority of the members present. In the event of a tie, the Commission shall provide a  chairman on a temporary basis.\n2.  The Committee shall elect two vice-chairmen for a period of three years. The vice-chairmen may not represent the same interest as the chairman.\nThe election shall take place in accordance with the procedure laid down in paragraph 1.\nThe officers shall prepare and organize the work of the Committee. 1.  Only the Commission representatives, the members of the Committee, or persons replacing them in their absence, and persons invited in accordance with paragraphs 3 and 4 may participate in or attend meedings.\n2.  Should a member be unable to attend a meeting, the organization or organizations to which a seat is allocated may appoint a person to take his place. This person shall be selected from a list drawn up by mutual agreement between the Commission and  the organization or organizations in question and containing a number of names equal to half the total number of members representing the organization or organizations in question.\nThis number shall be not less than one and not more\nthan 12.\nThe secretariat of the Committee must be informed of such replacement of a member at least seven days before a meeting.\n3.  At the request of an organization to which one or more seats are allocated, the chairman may, in agreement with the Commission staff, invite its general secretary or a member of its secretariat to attend the meetings of the Committee as an observer.  Should he be unable to attend, however, the general secretary may have his seat as an observer taken by another person designated by him.\nObservers shall not have the right to speak. They may, however, be invited to do so by the chairman in agreement with the Commission staff.\n4.  At the request of an organization to which one or more seats are allocated, and when the matters on the agenda are of a highly technical nature outside the normal framework of the deliberations of the Committee, the chairman may, in agreement with  the Commission staff, invite one or more experts to take part in the deliberations of the Committee.\nThe Commission may, on its own initiative, invite any person particularly well qualified in one of the subjects on the agenda to take part in the deliberations of the Committee as an expert.\nHowever, experts shall participate only in the discussion of the matter concerning which they were invited to attend. In agreement with the Commission staff, the Committee may set up working to facilitate its work. 1.  The Committee shall be convened by the Commission and shall meet at the Commission headquarters. Meetings of the officers shall be convened by the chairman by arrangement with the Commission.\n2.  Representatives of the Commission departments concerned shall take part in meetings of the Committee, its officers and working parties.\n3.  Secretarial services for the Committee and its working parties shall be provided by the Commission. No vote shall be taken on the matters discussed by the Committee.\nThe Commission may, when seeking the opinion of the Committee, set a time limit within which such opinion must be given.\nThe views expressed by the various interests represented\nshall be included in a summary record forwarded to the Commission.\nIn the event of unanimous agreement being reached in the Committee on the opinion to be given, the Committee shall formulate joint conclusions and attach them to the summary record. 0\nWithout prejudice to the provisions of Article 214 of the\nTreaty, where the Commission informs them that the opinions requested or the question raised is on a matter of a confidential nature, members of the Committee shall be under an obligation not to disclose information which has\ncome to their knowledge through the work of the Committee or of its working parties.\nIn such cases, only Committee members and representatives of the Commission departments concerned may be present at the meetings. 1\nCommission Decision 76/410/EEC is hereby repealed. 2\nThis Decision shall enter into force on 1 January 1987.",
         "8255",
         "Decision",
         "Decision"
        ],
        [
         "29",
         "31987D0159",
         "Decision",
         "87/159/EEC: Commission Decision of 19 February 1987 approving an addendum to the specific programme for the seed sector in Belgium pursuant to Council Regulation (EEC) No 355/77 (only the French and the Dutch texts are authentic)\n",
         "COMMISSION  DECISION\nof 19 February 1987\napproving an addendum to the specific programme for the seed sector in Belgium pursuant to Council Regulation (EEC) No 355/77\n(Only the French and the Dutch texts are authentic)\n(87/159/EEC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Regulation (EEC) No 355/77 of 15 February 1977 on common measures to improve the conditions under which agricultural and fishery products are processed and marketed (1), as last amended by Regulation (EEC) No 2224/86 (2), and in particular Article 5 thereof,\nWhereas on 8 January 1986 the Belgian Government notified an addendum to the programme for seed sector approved by Commission Decision 81/514/EEC (3) and completed it on 9 July 1986;\nWhereas this addendum relates only to investments for the modernization, rationalization and concentration of seed-marketing capacities and whereas all these investments are capable of contributing towards improving the situation in the said sector and towards its development; whereas it thus constitutes a programme within the meaning of Article 2 of Regulation (EEC) No 355/77;\nWhereas this adendum includes a sufficient quantity of the data referred to in Article 3 of Regulation (EEC) No 355/77 to demonstrate that the objectives of Article 1 of the said Regulation may be achieved in the abovementioned sector; whereas the time limit set for the implementation of the amendement does not exceed the period specified in Article 3 (1) (g) of said the Regulation;\nWhereas the measures provided for in this Decision are are in accordance with the opinion of the Standing Committee on Agricultural Structure,",
         "['The addeundum to the programme for the seed sector, as notified by the Belgian Government on 8 January 1986 and completed on 9 July 1986 in accordance with Regulation (EEC) No 355/77, is hereby approved.', 'This Decision is adressed to the Kingdom of Belgium.']",
         "['4081', '4298', '4839', '666']",
         "train",
         "87/159/EEC: Commission Decision of 19 February 1987 approving an addendum to the specific programme for the seed sector in Belgium pursuant to Council Regulation (EEC) No 355/77 (only the French and the Dutch texts are authentic)\n\n,\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Regulation (EEC) No 355/77 of 15 February 1977 on common measures to improve the conditions under which agricultural and fishery products are processed and marketed (1), as last amended by Regulation (EEC) No 2224/86 (2), and in particular Article 5 thereof,\nWhereas on 8 January 1986 the Belgian Government notified an addendum to the programme for seed sector approved by Commission Decision 81/514/EEC (3) and completed it on 9 July 1986;\nWhereas this addendum relates only to investments for the modernization, rationalization and concentration of seed-marketing capacities and whereas all these investments are capable of contributing towards improving the situation in the said sector and towards its development; whereas it thus constitutes a programme within the meaning of Article 2 of Regulation (EEC) No 355/77;\nWhereas this adendum includes a sufficient quantity of the data referred to in Article 3 of Regulation (EEC) No 355/77 to demonstrate that the objectives of Article 1 of the said Regulation may be achieved in the abovementioned sector; whereas the time limit set for the implementation of the amendement does not exceed the period specified in Article 3 (1) (g) of said the Regulation;\nWhereas the measures provided for in this Decision are are in accordance with the opinion of the Standing Committee on Agricultural Structure,\nThe addeundum to the programme for the seed sector, as notified by the Belgian Government on 8 January 1986 and completed on 9 July 1986 in accordance with Regulation (EEC) No 355/77, is hereby approved. This Decision is adressed to the Kingdom of Belgium.",
         "1940",
         "Decision",
         "Decision"
        ],
        [
         "30",
         "31993D0283",
         "Decision",
         "93/283/EEC: Commission Decision of 18 December 1991 on the establishment of the Community support framework for Community structural assistance in the areas eligible under Objective 2 in the region of Auvergne (France) (Only the French text is authentic)\n",
         "<{COM}>COMMISSION DECISION of 18 December 1991 on the establishment of the Community support framework for Community structural assistance in the areas eligible under Objective 2 in the region of Auvergne (France) (Only the French text is  authentic)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Regulation (EEC) No 2052/88 of 24 June 1988 on the tasks of the Structural Funds and their effectiveness and on coordination of their activities between themselves and with the operations of the European Investment Bank and the  other existing financial instruments (1), and in particular Article 9 (9) thereof,\nWhereas, in accordance with Article 9 (9) of Regulation (EEC) No 2052/88, the Commission, on the basis of the regional and social conversion plans submitted by the Member States, shall establish, through partnership and in agreement with the Member  State concerned, the Community support frameworks for Community structural operations;\nWhereas, in accordance with the second paragraph of that provision, the Community support framework shall cover in particular the priorities adopted, the forms of assistance and the indicative financing plan, with details of the amount of assistance and  its source, and the duration of the assistance;\nWhereas Title III of Council Regulation (EEC) No 4253/88 of 19 December 1988 laying down provisions for implementing Regulation (EEC) No 2052/88 as regards coordination of the activities of the different Structural Funds between themselves and with the  operations of the European Investment Bank and the other existing financial instruments (2) sets out the conditions for the preparation and implementation of Community support frameworks;\nWhereas by Decision 89/288/EEC (3) the Commission adopted an initial list of areas eligible under Objective 2;\nWhereas by Decision 90/400/EEC (4) the Commission extended that list to take account of the Decision of 17 December 1989 concerning the Rechar Community initiative (5);\nWhereas on 30 April 1991 the Commission decided to retain that list for 1992 and 1993;\nWhereas on 8 May 1989 the French Government submitted to the Commission the regional and social conversion plan referred to in Article 9 (8) of Regulation (EEC) No 2052/88 in respect of the areas eligible under Objective 2 in the region of Auvergne;\nWhereas the plan submitted by the Member State included a description of the priorities selected and an indication of the use to be made of assistance from the European Regional Development Fund (ERDF) and the European Social Fund (ESF) in implementing  it;\nWhereas, pursuant to Article 9 (9) of Regulation (EEC) No 2052/88, on 20 December 1989 the Commission adopted the Community support framework for the region of Auvergne for 1989 to 1991; whereas this Community support framework constitutes the second  phase of Community assistance to that region under Objective 2;\nWhereas this Community support framework has been established in agreement with the Member State concerned through the partnership defined in Article 4 of Regulation (EEC) No 2052/88;\nWhereas the EIB has also been involved in the preparation of the Community support framework in accordance with Article 8 of Regulation (EEC) No 4253/88; whereas it has declared its readiness to help implement this framework in accordance with its  Statute;\nWhereas the Commission is prepared to examine the possibility of the other Community lending instruments contributing to the financing of this framework in accordance with the specific provisions governing them;\nWhereas this Decision is consistent with the opinion of the Advisory Committee on the Development and Conversion of Regions and of the European Social Fund Committee;\nWhereas, in accordance with Article 10 (2) of Regulation (EEC) No 4253/88, this Decision is to be sent as a Declaration of Intent to the Member State;\nWhereas, in accordance with Article 20 (1) and (2) of Regulation (EEC) No 4253/88, the budgetary commitments relating to the contribution from the Structural Funds to the financing of the operations covered by this Community support framework will be  made on the basis of subsequent Commission decisions approving the operations concerned,",
         "['The Community support framework for Community structural assistance in the areas eligible under Objective 2 in the region of Auvergne (France), covering the period 1 January 1992 to 31 December 1993, is hereby approved.\\nThe Commission declares that it intends to contribute to the implementation of this Community support framework in accordance with the detailed provisions thereof and in compliance with the rules and guidelines governing the Structural Funds and the  other existing financial instruments.', 'The Community support framework contains the following essential information:\\n(a) the priorities for joint action:\\n- improving the attractiveness of employment areas,\\n- encouraging the competitiveness of firms and the creation of employment,\\n- development of tourist resources;\\n(b) an outline of the forms of assistance (a multifund (ERDF and ESF) operational programme) to be provided;\\n(c) an indicative financing plan specifying, at constant 1992 prices, for operations undertaken at the initiative of France the total cost and the amount of the expected contribution from the Community budget broken down as follows:\\nERDF ECU 7,08 million\\nESF ECU 1,77 million\\nTotal for Structural Funds ECU 8,85 million.\\nThe resultant national financing required may be partially covered by Community loans from the European Investment Bank and the other lending instruments.', 'This Declaration of Intent is addressed to the French Republic.']",
         "['1005', '1460', '2518', '2609', '431', '4364']",
         "train",
         "93/283/EEC: Commission Decision of 18 December 1991 on the establishment of the Community support framework for Community structural assistance in the areas eligible under Objective 2 in the region of Auvergne (France) (Only the French text is authentic)\n\n,\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Regulation (EEC) No 2052/88 of 24 June 1988 on the tasks of the Structural Funds and their effectiveness and on coordination of their activities between themselves and with the operations of the European Investment Bank and the  other existing financial instruments (1), and in particular Article 9 (9) thereof,\nWhereas, in accordance with Article 9 (9) of Regulation (EEC) No 2052/88, the Commission, on the basis of the regional and social conversion plans submitted by the Member States, shall establish, through partnership and in agreement with the Member  State concerned, the Community support frameworks for Community structural operations;\nWhereas, in accordance with the second paragraph of that provision, the Community support framework shall cover in particular the priorities adopted, the forms of assistance and the indicative financing plan, with details of the amount of assistance and  its source, and the duration of the assistance;\nWhereas Title III of Council Regulation (EEC) No 4253/88 of 19 December 1988 laying down provisions for implementing Regulation (EEC) No 2052/88 as regards coordination of the activities of the different Structural Funds between themselves and with the  operations of the European Investment Bank and the other existing financial instruments (2) sets out the conditions for the preparation and implementation of Community support frameworks;\nWhereas by Decision 89/288/EEC (3) the Commission adopted an initial list of areas eligible under Objective 2;\nWhereas by Decision 90/400/EEC (4) the Commission extended that list to take account of the Decision of 17 December 1989 concerning the Rechar Community initiative (5);\nWhereas on 30 April 1991 the Commission decided to retain that list for 1992 and 1993;\nWhereas on 8 May 1989 the French Government submitted to the Commission the regional and social conversion plan referred to in Article 9 (8) of Regulation (EEC) No 2052/88 in respect of the areas eligible under Objective 2 in the region of Auvergne;\nWhereas the plan submitted by the Member State included a description of the priorities selected and an indication of the use to be made of assistance from the European Regional Development Fund (ERDF) and the European Social Fund (ESF) in implementing  it;\nWhereas, pursuant to Article 9 (9) of Regulation (EEC) No 2052/88, on 20 December 1989 the Commission adopted the Community support framework for the region of Auvergne for 1989 to 1991; whereas this Community support framework constitutes the second  phase of Community assistance to that region under Objective 2;\nWhereas this Community support framework has been established in agreement with the Member State concerned through the partnership defined in Article 4 of Regulation (EEC) No 2052/88;\nWhereas the EIB has also been involved in the preparation of the Community support framework in accordance with Article 8 of Regulation (EEC) No 4253/88; whereas it has declared its readiness to help implement this framework in accordance with its  Statute;\nWhereas the Commission is prepared to examine the possibility of the other Community lending instruments contributing to the financing of this framework in accordance with the specific provisions governing them;\nWhereas this Decision is consistent with the opinion of the Advisory Committee on the Development and Conversion of Regions and of the European Social Fund Committee;\nWhereas, in accordance with Article 10 (2) of Regulation (EEC) No 4253/88, this Decision is to be sent as a Declaration of Intent to the Member State;\nWhereas, in accordance with Article 20 (1) and (2) of Regulation (EEC) No 4253/88, the budgetary commitments relating to the contribution from the Structural Funds to the financing of the operations covered by this Community support framework will be  made on the basis of subsequent Commission decisions approving the operations concerned,\nThe Community support framework for Community structural assistance in the areas eligible under Objective 2 in the region of Auvergne (France), covering the period 1 January 1992 to 31 December 1993, is hereby approved.\nThe Commission declares that it intends to contribute to the implementation of this Community support framework in accordance with the detailed provisions thereof and in compliance with the rules and guidelines governing the Structural Funds and the  other existing financial instruments. The Community support framework contains the following essential information:\n(a) the priorities for joint action:\n- improving the attractiveness of employment areas,\n- encouraging the competitiveness of firms and the creation of employment,\n- development of tourist resources;\n(b) an outline of the forms of assistance (a multifund (ERDF and ESF) operational programme) to be provided;\n(c) an indicative financing plan specifying, at constant 1992 prices, for operations undertaken at the initiative of France the total cost and the amount of the expected contribution from the Community budget broken down as follows:\nERDF ECU 7,08 million\nESF ECU 1,77 million\nTotal for Structural Funds ECU 8,85 million.\nThe resultant national financing required may be partially covered by Community loans from the European Investment Bank and the other lending instruments. This Declaration of Intent is addressed to the French Republic.",
         "5690",
         "Decision",
         "Decision"
        ],
        [
         "31",
         "32006D0070",
         "Decision",
         "2006/70/EC,Euratom: Commission Decision of  31 January 2006  amending Decision 2001/844/EC, ECSC, Euratom\n",
         "7.2.2006 EN Official Journal of the European Union L 34/32\nCOMMISSION DECISION\nof 31 January 2006\namending Decision 2001/844/EC, ECSC, Euratom\n(2006/70/EC, Euratom)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Community, and in particular Article 218(2) thereof,\nHaving regard to the Treaty establishing the European Atomic Energy Community, and in particular Article 131 thereof,\nHaving regard to the Treaty on European Union, and in particular Articles 21(1) and 41(1) thereof,\nWhereas:\n(1) The Commission’s provisions on security are contained in the Annex to Commission Decision 2001/844/EC, ECSC, Euratom of 29 November 2001 amending its internal Rules of Procedure (1).\n(2) The Commission has decided on a number of changes in the assignment of responsibilities and in the designation of departments and services.\n(3) Definitions in the Annex to Decision 2001/844/EC, ECSC, Euratom should be in line with the relevant provisions in the text.\n(4) The text of the rules on security should be amended accordingly,",
         "['The Rules on security as set out in the Annex to Decision 2001/844/EC, ECSC, Euratom are amended as follows:\\n1. in Section 4.2(e) ‘President of the Commission’ is replaced by ‘Director of the Commission Security Directorate’;\\n2. Section 13 is replaced by the following text:\\n3. in Appendix 2, ‘President’ is replaced by ‘Member of the Commission responsible for security matters’;\\n4. in point 10(c) of Appendix 4, ‘President’ is replaced by ‘Director of the Commission Security Directorate’;\\n5. in point 7 of Appendix 5, ‘President’ is replaced by ‘Member of the Commission responsible for security matters’;\\n6. throughout the text of the rules on security and its Appendices:\\n(a) ‘Commission Security Office’ and ‘Commission Security Service’ are replaced by: ‘Commission Security Directorate’;\\n(b) ‘Head of the Commission Security Office’ is replaced by ‘Director of the Commission Security Directorate’;\\n7. a new recital is added after recital 7 of the Annex, reading: ‘These provisions are without prejudice to Article 286 of the Treaty and to Regulation (EC) 45/2001 of the European Parliament and of the Council of 18 December 2000 on the protection of individuals with regard to the processing of personal data by the Community institutions and bodies and on the free movement of such data.’', 'This Decision shall enter into force on the day of its publication in the Official Journal of the European Union.']",
         "['3561', '4038', '4039', '5181', '5640']",
         "train",
         "2006/70/EC,Euratom: Commission Decision of  31 January 2006  amending Decision 2001/844/EC, ECSC, Euratom\n\n,\nHaving regard to the Treaty establishing the European Community, and in particular Article 218(2) thereof,\nHaving regard to the Treaty establishing the European Atomic Energy Community, and in particular Article 131 thereof,\nHaving regard to the Treaty on European Union, and in particular Articles 21(1) and 41(1) thereof,\nWhereas:\n(1) The Commission’s provisions on security are contained in the Annex to Commission Decision 2001/844/EC, ECSC, Euratom of 29 November 2001 amending its internal Rules of Procedure (1).\n(2) The Commission has decided on a number of changes in the assignment of responsibilities and in the designation of departments and services.\n(3) Definitions in the Annex to Decision 2001/844/EC, ECSC, Euratom should be in line with the relevant provisions in the text.\n(4) The text of the rules on security should be amended accordingly,\nThe Rules on security as set out in the Annex to Decision 2001/844/EC, ECSC, Euratom are amended as follows:\n1. in Section 4.2(e) ‘President of the Commission’ is replaced by ‘Director of the Commission Security Directorate’;\n2. Section 13 is replaced by the following text:\n3. in Appendix 2, ‘President’ is replaced by ‘Member of the Commission responsible for security matters’;\n4. in point 10(c) of Appendix 4, ‘President’ is replaced by ‘Director of the Commission Security Directorate’;\n5. in point 7 of Appendix 5, ‘President’ is replaced by ‘Member of the Commission responsible for security matters’;\n6. throughout the text of the rules on security and its Appendices:\n(a) ‘Commission Security Office’ and ‘Commission Security Service’ are replaced by: ‘Commission Security Directorate’;\n(b) ‘Head of the Commission Security Office’ is replaced by ‘Director of the Commission Security Directorate’;\n7. a new recital is added after recital 7 of the Annex, reading: ‘These provisions are without prejudice to Article 286 of the Treaty and to Regulation (EC) 45/2001 of the European Parliament and of the Council of 18 December 2000 on the protection of individuals with regard to the processing of personal data by the Community institutions and bodies and on the free movement of such data.’ This Decision shall enter into force on the day of its publication in the Official Journal of the European Union.",
         "2382",
         "Decision",
         "Decision"
        ],
        [
         "32",
         "31992D0392",
         "Decision",
         "92/392/EEC: Council Decision of 30 June 1992 on temporary national compensation for farmers in Germany\n",
         "COUNCIL DECISION of 30 June 1992 on temporary national compensation for farmers in Germany (92/392/EEC)\nTHE COUNCIL OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Economic Community, and in particular Articles 42 and 43 thereof,\nHaving regard to the proposal from the Commission (1),\nHaving regard to the opinion of the European Parliament (2),\nHaving regard to the opinion of the Economic and Social Committee (3),\nWhereas to compensate for the lower farm incomes resulting from reductions in prices expressed in national currency brought about in Germany by the adaptation of agricultural conversion rates, Council Regulation (EEC) No 855/84 of 21 March 1984 on the  calculation and dismantlement of the monetary compensatory amounts applying to certain agricultural products (4), provided that, subject to certain specified conditions, a special national aid granted through the value added tax (VAT) system was  compatible with the common market; whereas the aid provisions laid down in that Regulation are not limited in time; whereas Twentieth Council Directive 85/361/EEC of 16 July 1985 on the harmonization of the laws of the Member States relating to turnover  taxes - Common system of value added tax; derogations in connection with the special aids granted to certain farmers to compensate for the dismantlement of monetary compensatory amounts applying to certain agricultural products (5), laid down the  conditions under which VAT could be used for the grant of this special aid;\nWhereas the Council, when adopting Directive 85/361/EEC, noted that the consequences of the dismantlement of monetary compensatory amounts are temporary and degressive; whereas farm incomes in Germany have recently developed in an unsatisfactory manner;  whereas the said Directive expired on 31 December 1991; whereas it is therefore appropriate to provide for an income support benefit for the farm sector in Germany in 1992;\nWhereas the mechanism for granting aid as laid down in Directive 85/361/EEC is production-linked; whereas the need to support incomes for 1992 temporarily could be met more appropriately by national farm support measures; whereas due account should be  taken of the farm structure in the Laender of the former German Democratic Republic; whereas the aid provided for in Council Decision 88/402/EEC of 30 June 1988 on aid to farmers in the Federal Republic of Germany (6) should be granted notwithstanding  this Decision,",
         "['Without prejudice to Decision 88/402/EEC, Germany is hereby authorized to grant to farmers, from 1 January 1992 until 31 December 1992, special national aid which is not linked to prices or to production, under the following conditions:\\n1. Individual farmers shall qualify for aid per hectare of utilized agricultural area of their holdings; however, the aid per holding shall not be less than DM 1 500 and shall not exceed DM 16 000 per year. This aid shall be paid on a one-off basis.\\n2. Germany may lay down that farmers who cooperatively work the same holding on 1 January 1992 receive the aid specified in point 1. The ceiling on area and maximum amount shall be multiplied by the number of farmers in the cooperative.\\n3. In principle, only farmers who are members of the German farm retirement pension scheme (GAL) may qualify for this scheme;\\n4. Derogations from point 1 except as regards the one-off payment and from point 3 shall be applied to the extent necessary to take account of the farm structure in the new Laender.\\n5. Germany shall fix the unit amount referred to at point 1, the conditions of point 4, and all other implementing details in such a way as to ensure that the overall volume of the special aid does not exceed DM 2 200 million.', '1. Germany shall notify to the Commission drafts of detailed provisions and of any further amendments relating to the implementation of the aid scheme referred to in Article 1.\\nAt the request of the Commission, it shall provide further guidance information.\\n2. Germany may not implement the relevant provisions before such time as the Commission has ascertained their compatibility with the stipulations set out in Article 1.\\nThe Commission shall decide on whether to approve the draft provisions within two months from the date of receiving them.', 'This Decision is addressed to the Federal Republic of Germany.']",
         "['1318', '3679', '4585', '889']",
         "train",
         "92/392/EEC: Council Decision of 30 June 1992 on temporary national compensation for farmers in Germany\n\n,\nHaving regard to the Treaty establishing the European Economic Community, and in particular Articles 42 and 43 thereof,\nHaving regard to the proposal from the Commission (1),\nHaving regard to the opinion of the European Parliament (2),\nHaving regard to the opinion of the Economic and Social Committee (3),\nWhereas to compensate for the lower farm incomes resulting from reductions in prices expressed in national currency brought about in Germany by the adaptation of agricultural conversion rates, Council Regulation (EEC) No 855/84 of 21 March 1984 on the  calculation and dismantlement of the monetary compensatory amounts applying to certain agricultural products (4), provided that, subject to certain specified conditions, a special national aid granted through the value added tax (VAT) system was  compatible with the common market; whereas the aid provisions laid down in that Regulation are not limited in time; whereas Twentieth Council Directive 85/361/EEC of 16 July 1985 on the harmonization of the laws of the Member States relating to turnover  taxes - Common system of value added tax; derogations in connection with the special aids granted to certain farmers to compensate for the dismantlement of monetary compensatory amounts applying to certain agricultural products (5), laid down the  conditions under which VAT could be used for the grant of this special aid;\nWhereas the Council, when adopting Directive 85/361/EEC, noted that the consequences of the dismantlement of monetary compensatory amounts are temporary and degressive; whereas farm incomes in Germany have recently developed in an unsatisfactory manner;  whereas the said Directive expired on 31 December 1991; whereas it is therefore appropriate to provide for an income support benefit for the farm sector in Germany in 1992;\nWhereas the mechanism for granting aid as laid down in Directive 85/361/EEC is production-linked; whereas the need to support incomes for 1992 temporarily could be met more appropriately by national farm support measures; whereas due account should be  taken of the farm structure in the Laender of the former German Democratic Republic; whereas the aid provided for in Council Decision 88/402/EEC of 30 June 1988 on aid to farmers in the Federal Republic of Germany (6) should be granted notwithstanding  this Decision,\nWithout prejudice to Decision 88/402/EEC, Germany is hereby authorized to grant to farmers, from 1 January 1992 until 31 December 1992, special national aid which is not linked to prices or to production, under the following conditions:\n1. Individual farmers shall qualify for aid per hectare of utilized agricultural area of their holdings; however, the aid per holding shall not be less than DM 1 500 and shall not exceed DM 16 000 per year. This aid shall be paid on a one-off basis.\n2. Germany may lay down that farmers who cooperatively work the same holding on 1 January 1992 receive the aid specified in point 1. The ceiling on area and maximum amount shall be multiplied by the number of farmers in the cooperative.\n3. In principle, only farmers who are members of the German farm retirement pension scheme (GAL) may qualify for this scheme;\n4. Derogations from point 1 except as regards the one-off payment and from point 3 shall be applied to the extent necessary to take account of the farm structure in the new Laender.\n5. Germany shall fix the unit amount referred to at point 1, the conditions of point 4, and all other implementing details in such a way as to ensure that the overall volume of the special aid does not exceed DM 2 200 million. 1. Germany shall notify to the Commission drafts of detailed provisions and of any further amendments relating to the implementation of the aid scheme referred to in Article 1.\nAt the request of the Commission, it shall provide further guidance information.\n2. Germany may not implement the relevant provisions before such time as the Commission has ascertained their compatibility with the stipulations set out in Article 1.\nThe Commission shall decide on whether to approve the draft provisions within two months from the date of receiving them. This Decision is addressed to the Federal Republic of Germany.",
         "4310",
         "Decision",
         "Decision"
        ],
        [
         "33",
         "32000D0641",
         "Decision",
         "Council Decision of 17 October 2000 establishing a secretariat for the joint supervisory data-protection bodies set up by the Convention on the Establishment of a European Police Office (Europol Convention), the Convention on the Use of Information Technology for Customs Purposes and the Convention implementing the Schengen Agreement on the gradual abolition of checks at the common borders (Schengen Convention)\n",
         "Council Decision\nof 17 October 2000\nestablishing a secretariat for the joint supervisory data-protection bodies set up by the Convention on the Establishment of a European Police Office (Europol Convention), the Convention on the Use of Information Technology for Customs Purposes and the Convention implementing the Schengen Agreement on the gradual abolition of checks at the common borders (Schengen Convention)\n(2000/641/JHA)\nTHE COUNCIL OF THE EUROPEAN UNION",
         ",\nHaving regard to Articles 30 and 34(2)(c) of the Treaty on the European Union,\nHaving regard to Article 2 of the Protocol integrating the Schengen acquis into the framework of the European Union,\nHaving regard to the initiative of the Portuguese Republic(1),\nHaving considered the opinion of the European Parliament(2),\nWhereas:\n(1) The Convention on the Establishment of a European Police Office (Europol Convention)(3), the Convention on the Use of Information Technology for Customs Purposes(4) and the Convention implementing the Schengen Agreement on the gradual abolition of checks at the common borders (Schengen Convention)(5) have created joint supervisory bodies in order to monitor the correct application of data protection provisions in those instruments.\n(2) In order for those joint supervisory bodies to function effectively and to reduce costs, they should be supported by one single, independent data-protection secretariat which, in the exercise of its tasks, is bound only by instructions of those bodies.\n(3) For practical reasons the administration of the data-protection secretariat should be closely linked to the General Secretariat of the Council, while safeguarding its independence in the exercise of its tasks.\n(4) In order to ensure this independence, decisions on the appointment and removal from office of the head of the data-protection secretariat should be taken by the Deputy Secretary-General of the Council, acting on a proposal of the joint supervisory bodies, and the other officials assigned to the data-protection secretariat should be placed exclusively under the instructions of the head of the data-protection secretariat.\n(5) The administrative expenses of the data-protection secretariat should be charged to the general budget of the European Union. Europol should contribute to the financing of certain expenses in respect of meetings relating to matters of implementation of the Europol Convention.\n(6) Since Council Decision 1999/438/EC of 20 May 1999 concerning the joint supervisory authority set up under Article 115 of the Convention applying the Schengen Agreement of 14 June 1985, on the gradual abolition of checks at common borders, signed on 19 June 1990(6), is superseded by this Decision, it should be repealed as from the date on which this Decision becomes applicable.\n(7) The existing joint supervisory bodies have expressed their approval for the principles set out in this Decision,",
         "['Establishment and tasks of the data-protection secretariat\\n1. A secretariat (hereinafter referred to as the \"data-protection secretariat\") is hereby established for the joint supervisory bodies set up by the Convention on the Establishment of a European Police Office (Europol Convention), the Convention on the Use of Information Technology for Customs Purposes and the Convention implementing the Schengen Agreement on the gradual abolition of checks at the common borders (Schengen Convention).\\n2. The data-protection secretariat shall fulfil the tasks provided for the secretariats of the joint supervisory bodies as laid down in the respective Rules of Procedure of those bodies.', 'Data-protection Secretary\\n1. The data-protection secretariat shall be headed by a data-protection secretary whose independence in the performance of his tasks shall be safeguarded, subject only to instructions from the joint supervisory bodies and their chairmen. The Deputy Secretary-General of the Council, acting on a proposal by the joint supervisory bodies, shall appoint the data-protection secretary for a period of three years. The data-protection secretary may be reappointed.\\n2. The data-protection secretary shall be chosen from among the persons who are European Union citizens, have full civil and political rights, can bring to bear appropriate experience and expertise in the performance of the duties concerned, and offer every guarantee of independence. He shall refrain from any action incompatible with his duties and, during his term of office, not engage in any other occupation, whether gainful or not. He shall, after his term of office, behave with integrity and discretion as regards the acceptance of appointments and benefits.\\n3. The data-protection secretary shall be removed from office by the Deputy Secretary-General of the Council, acting on a proposal from the joint supervisory bodies, if he no longer fulfils the conditions required for the performance of his duties or if he has been guilty of serious misconduct.\\n4. Apart from normal replacement on expiry of his term of office or in the event of his death and removal from office in accordance with paragraph 3, the office of the data-protection secretary shall end when his resignation takes effect. In the case of the expiration of his term of office and in the case of his resignation, he shall at the request of the joint supervisory bodies remain in office until he has been replaced.\\n5. The data-protection secretary shall, both during and after termination of his term of office, be subject to a duty of professional secrecy with regard to the confidential information which has come to his knowledge in the course of the performance of his duties.\\n6. During his term of office, the data-protection secretary shall, except where otherwise stated in this Decision, be subject to the rules applicable to persons having the status of a temporary agent within the meaning of Article 2(a) of the Conditions of employment of other servants of the European Communities(7), including Articles 12 to 15 and 18 of the Protocol on Privileges and Immunities of the European Communities. The data-protection secretary shall be in grade A, the level and step at which he is employed shall be determined by the criteria applicable to the officials and other agents of the Communities. If the person appointed is already an official of the Communities, he shall be seconded for the term of his office in the interest of the service by virtue of Article 37(a), first indent, of the Staff Regulations of officials of the European Communities (Staff Regulations)(8). The first sentence of the last paragraph of Article 37 of the Staff Regulations shall apply without prejudice to paragraph 1 of this Article.', 'Staff\\n1. The data-protection secretariat shall be provided with the staff necessary for the performance of its tasks. The staff members assigned to the data-protection secretariat shall fill posts included in the list of posts appended to the section of the general budget of the European Union relating to the Council.\\n2. In the exercise of their duties the staff members referred to in paragraph 1 shall be subject exclusively to the instructions of the data-protection secretary and the joint supervisory bodies and their chairmen. In that context, they may neither seek nor accept instructions from any government, authority, organisation or person apart from the data-protection secretary and the joint supervisory bodies and their chairmen.\\n3. Notwithstanding paragraph 2, the staff assigned to the data-protection secretariat shall be subject to the regulations and rules applicable to officials and other servants of the European Communities. As regards the exercise of the powers conferred by the Staff Regulations on the appointing authority and the powers under the Conditions of employment of other servants of the European Communities, the staff shall be subject to the same rules as the officials and other agents of the European Communities.', 'Administrative support\\n1. The General Secretariat of the Council shall provide the office space and equipment necessary for the performance of the duties of the data-protection secretariat. It shall provide facilities for meetings of the joint supervisory bodies within the premises of the Council, including interpretation facilities.\\n2. As fas as meetings to be convened in the premises of the Council are concerned, the chairmanship of the joint supervisory bodies shall set these dates subject to prior agreement of the Presidency of the Council.', 'Financing\\n1. The administrative overhead expenses of the data-protection secretariat (in particular equipment, remuneration, allowances and other personnel expenses) shall be charged to the section of the general budget of the European Union relating to the Council.\\n2. Costs related directly to meetings shall be borne\\n- by the Council, for meetings on the premises of the Council relating to matters of implementation of the provisions of the Schengen Convention as well as travelling expenses for carrying out controls at the C.SIS and for meetings relating to matters of implementation of the Convention on the Use of Information Technology for Customs Purposes,\\n- by Europol, for meetings relating to matters of implementation of the Europol Convention.', 'Final provisions\\n1. This Decision shall enter into force the day following its adoption by the Council.\\nIt shall apply from 1 September 2001.\\n2. As from the date of entry into force of this Decision, the decisions and acts necessary to implement this Decision can be adopted. They shall not take effect before the date on which this Decision becomes applicable.\\n3. At the date on which this Decision becomes applicable, Decision 1999/438/EC shall be repealed. It shall, however, continue to apply to expenses caused by events preceding that date.']",
         "['4079', '5181', '5405', '5441', '5540', '5630']",
         "train",
         "Council Decision of 17 October 2000 establishing a secretariat for the joint supervisory data-protection bodies set up by the Convention on the Establishment of a European Police Office (Europol Convention), the Convention on the Use of Information Technology for Customs Purposes and the Convention implementing the Schengen Agreement on the gradual abolition of checks at the common borders (Schengen Convention)\n\n,\nHaving regard to Articles 30 and 34(2)(c) of the Treaty on the European Union,\nHaving regard to Article 2 of the Protocol integrating the Schengen acquis into the framework of the European Union,\nHaving regard to the initiative of the Portuguese Republic(1),\nHaving considered the opinion of the European Parliament(2),\nWhereas:\n(1) The Convention on the Establishment of a European Police Office (Europol Convention)(3), the Convention on the Use of Information Technology for Customs Purposes(4) and the Convention implementing the Schengen Agreement on the gradual abolition of checks at the common borders (Schengen Convention)(5) have created joint supervisory bodies in order to monitor the correct application of data protection provisions in those instruments.\n(2) In order for those joint supervisory bodies to function effectively and to reduce costs, they should be supported by one single, independent data-protection secretariat which, in the exercise of its tasks, is bound only by instructions of those bodies.\n(3) For practical reasons the administration of the data-protection secretariat should be closely linked to the General Secretariat of the Council, while safeguarding its independence in the exercise of its tasks.\n(4) In order to ensure this independence, decisions on the appointment and removal from office of the head of the data-protection secretariat should be taken by the Deputy Secretary-General of the Council, acting on a proposal of the joint supervisory bodies, and the other officials assigned to the data-protection secretariat should be placed exclusively under the instructions of the head of the data-protection secretariat.\n(5) The administrative expenses of the data-protection secretariat should be charged to the general budget of the European Union. Europol should contribute to the financing of certain expenses in respect of meetings relating to matters of implementation of the Europol Convention.\n(6) Since Council Decision 1999/438/EC of 20 May 1999 concerning the joint supervisory authority set up under Article 115 of the Convention applying the Schengen Agreement of 14 June 1985, on the gradual abolition of checks at common borders, signed on 19 June 1990(6), is superseded by this Decision, it should be repealed as from the date on which this Decision becomes applicable.\n(7) The existing joint supervisory bodies have expressed their approval for the principles set out in this Decision,\nEstablishment and tasks of the data-protection secretariat\n1. A secretariat (hereinafter referred to as the \"data-protection secretariat\") is hereby established for the joint supervisory bodies set up by the Convention on the Establishment of a European Police Office (Europol Convention), the Convention on the Use of Information Technology for Customs Purposes and the Convention implementing the Schengen Agreement on the gradual abolition of checks at the common borders (Schengen Convention).\n2. The data-protection secretariat shall fulfil the tasks provided for the secretariats of the joint supervisory bodies as laid down in the respective Rules of Procedure of those bodies. Data-protection Secretary\n1. The data-protection secretariat shall be headed by a data-protection secretary whose independence in the performance of his tasks shall be safeguarded, subject only to instructions from the joint supervisory bodies and their chairmen. The Deputy Secretary-General of the Council, acting on a proposal by the joint supervisory bodies, shall appoint the data-protection secretary for a period of three years. The data-protection secretary may be reappointed.\n2. The data-protection secretary shall be chosen from among the persons who are European Union citizens, have full civil and political rights, can bring to bear appropriate experience and expertise in the performance of the duties concerned, and offer every guarantee of independence. He shall refrain from any action incompatible with his duties and, during his term of office, not engage in any other occupation, whether gainful or not. He shall, after his term of office, behave with integrity and discretion as regards the acceptance of appointments and benefits.\n3. The data-protection secretary shall be removed from office by the Deputy Secretary-General of the Council, acting on a proposal from the joint supervisory bodies, if he no longer fulfils the conditions required for the performance of his duties or if he has been guilty of serious misconduct.\n4. Apart from normal replacement on expiry of his term of office or in the event of his death and removal from office in accordance with paragraph 3, the office of the data-protection secretary shall end when his resignation takes effect. In the case of the expiration of his term of office and in the case of his resignation, he shall at the request of the joint supervisory bodies remain in office until he has been replaced.\n5. The data-protection secretary shall, both during and after termination of his term of office, be subject to a duty of professional secrecy with regard to the confidential information which has come to his knowledge in the course of the performance of his duties.\n6. During his term of office, the data-protection secretary shall, except where otherwise stated in this Decision, be subject to the rules applicable to persons having the status of a temporary agent within the meaning of Article 2(a) of the Conditions of employment of other servants of the European Communities(7), including Articles 12 to 15 and 18 of the Protocol on Privileges and Immunities of the European Communities. The data-protection secretary shall be in grade A, the level and step at which he is employed shall be determined by the criteria applicable to the officials and other agents of the Communities. If the person appointed is already an official of the Communities, he shall be seconded for the term of his office in the interest of the service by virtue of Article 37(a), first indent, of the Staff Regulations of officials of the European Communities (Staff Regulations)(8). The first sentence of the last paragraph of Article 37 of the Staff Regulations shall apply without prejudice to paragraph 1 of this Article. Staff\n1. The data-protection secretariat shall be provided with the staff necessary for the performance of its tasks. The staff members assigned to the data-protection secretariat shall fill posts included in the list of posts appended to the section of the general budget of the European Union relating to the Council.\n2. In the exercise of their duties the staff members referred to in paragraph 1 shall be subject exclusively to the instructions of the data-protection secretary and the joint supervisory bodies and their chairmen. In that context, they may neither seek nor accept instructions from any government, authority, organisation or person apart from the data-protection secretary and the joint supervisory bodies and their chairmen.\n3. Notwithstanding paragraph 2, the staff assigned to the data-protection secretariat shall be subject to the regulations and rules applicable to officials and other servants of the European Communities. As regards the exercise of the powers conferred by the Staff Regulations on the appointing authority and the powers under the Conditions of employment of other servants of the European Communities, the staff shall be subject to the same rules as the officials and other agents of the European Communities. Administrative support\n1. The General Secretariat of the Council shall provide the office space and equipment necessary for the performance of the duties of the data-protection secretariat. It shall provide facilities for meetings of the joint supervisory bodies within the premises of the Council, including interpretation facilities.\n2. As fas as meetings to be convened in the premises of the Council are concerned, the chairmanship of the joint supervisory bodies shall set these dates subject to prior agreement of the Presidency of the Council. Financing\n1. The administrative overhead expenses of the data-protection secretariat (in particular equipment, remuneration, allowances and other personnel expenses) shall be charged to the section of the general budget of the European Union relating to the Council.\n2. Costs related directly to meetings shall be borne\n- by the Council, for meetings on the premises of the Council relating to matters of implementation of the provisions of the Schengen Convention as well as travelling expenses for carrying out controls at the C.SIS and for meetings relating to matters of implementation of the Convention on the Use of Information Technology for Customs Purposes,\n- by Europol, for meetings relating to matters of implementation of the Europol Convention. Final provisions\n1. This Decision shall enter into force the day following its adoption by the Council.\nIt shall apply from 1 September 2001.\n2. As from the date of entry into force of this Decision, the decisions and acts necessary to implement this Decision can be adopted. They shall not take effect before the date on which this Decision becomes applicable.\n3. At the date on which this Decision becomes applicable, Decision 1999/438/EC shall be repealed. It shall, however, continue to apply to expenses caused by events preceding that date.",
         "9751",
         "Decision",
         "Decision"
        ],
        [
         "34",
         "32003D0093",
         "Decision",
         "2003/93/EC: Council Decision of 19 December 2002 authorising the Member States, in the interest of the Community, to sign the 1996 Hague Convention on jurisdiction, applicable law, recognition, enforcement and cooperation in respect of parental responsibility andmeasures for the protection of children\n",
         "Council decision\nof 19 December 2002\nauthorising the Member States, in the interest of the Community, to sign the 1996 Hague Convention on Jurisdiction, Applicable Law, Recognition, Enforcement and Cooperation in respect of Parental Responsibility and Measures for the Protection of Children\n(2003/93/CE)\nTHE COUNCIL OF THE EUROPEAN UNION",
         ",\nHaving regard to the Treaty establishing the European Community, and in particular Article 61(c) and Article 300 thereof,\nHaving regard to the proposal from the Commission,\nWhereas:\n(1) The Community is working towards the establishment of a common judicial area based on the principle of mutual recognition of judicial decisions.\n(2) The Convention on Jurisdiction, Applicable Law, Recognition, Enforcement and Cooperation in respect of Parental Responsibility and Measures for the Protection of Children concluded on 19 October 1996 in the framework of The Hague Conference on Private International Law, (hereinafter referred to as the Convention) makes a valuable contribution to the protection of children at international level, and it is therefore desirable that its provisions be applied as soon as possible.\n(3) Certain articles of the Convention affect Community secondary legislation on jurisdiction and the recognition and enforcement of judgments, in particular Council Regulation (EC) No 1347/2000 of 29 May 2000 on jurisdiction and the recognition and enforcement of judgments in matrimonial matters and in matters of parental responsibility for children of both spouses(1).\n(4) The Community has exclusive competence for the relevant provisions of the Convention insofar as those articles affect Community rules adopted in this area. The Member States should retain their competence in the areas covered by the Convention which do not affect Community law.\n(5) Pursuant to the Convention, only sovereign States may be party to it. For that reason, the Community may not at present sign, ratify or accede to it.\n(6) The Council should therefore authorise the Member States, by way of exception, to sign the Convention in the interest of the Community, under the conditions set out in this Decision.\n(7) Taking account of Articles 23, 26 and 52 of the Convention, a Decision taken by a Member State on matters governed by the Convention may be recognised and enforced in another Member State in accordance with the relevant internal rules of Community law.\n(8) The United Kingdom and Ireland are taking part in the adoption and application of this Decision.\n(9) Denmark, in accordance with Articles 1 and 2 of the Protocol on the position of Denmark annexed to the Treaty on European Union and the Treaty establishing the European Community, is not taking part in the adoption of this Decision and is therefore not bound by it nor subject to its application,",
         "['1. The Council hereby authorises the Member States to sign the Convention on Jurisdiction, Applicable Law, Recognition, Enforcement and Cooperation in respect of Parental Responsibility and Measures for the Protection of Children, concluded on 19 October 1996, in the interest of the Community, subject to the conditions set out in the following articles.\\n2. The text of the Convention is attached to this Decision(2).\\n3. In this Decision, the term \"Member State\" shall mean all Member States with the exception of Denmark.', 'When signing the Convention, Member States shall make the following declaration:\\n\"Articles 23, 26 and 52 of the Convention allow Contracting Parties a degree of flexibility in order to apply a simple and rapid regime for the recognition and enforcement of judgments. The Community rules provide for a system of recognition and enforcement which is at least as favourable as the rules laid down in the Convention. Accordingly, a judgment given in a Court of a Member State of the European Union, in respect of a matter relating to the Convention, shall be recognised and enforced in(3) by application of the relevant internal rules of Community law(4).\"', 'Member States shall make the necessary arrangements for the Convention to be signed before 1 June 2003.', 'When signing the Convention, Member States shall inform the Ministry of Foreign Affairs of the Kingdom of the Netherlands in writing that the signing has taken place in accordance with this Decision.\\nThis Decision is addressed to the Member States in accordance with the Treaty establishing the European Community.']",
         "['2701', '3316', '3472', '3919', '5811', '860']",
         "train",
         "2003/93/EC: Council Decision of 19 December 2002 authorising the Member States, in the interest of the Community, to sign the 1996 Hague Convention on jurisdiction, applicable law, recognition, enforcement and cooperation in respect of parental responsibility andmeasures for the protection of children\n\n,\nHaving regard to the Treaty establishing the European Community, and in particular Article 61(c) and Article 300 thereof,\nHaving regard to the proposal from the Commission,\nWhereas:\n(1) The Community is working towards the establishment of a common judicial area based on the principle of mutual recognition of judicial decisions.\n(2) The Convention on Jurisdiction, Applicable Law, Recognition, Enforcement and Cooperation in respect of Parental Responsibility and Measures for the Protection of Children concluded on 19 October 1996 in the framework of The Hague Conference on Private International Law, (hereinafter referred to as the Convention) makes a valuable contribution to the protection of children at international level, and it is therefore desirable that its provisions be applied as soon as possible.\n(3) Certain articles of the Convention affect Community secondary legislation on jurisdiction and the recognition and enforcement of judgments, in particular Council Regulation (EC) No 1347/2000 of 29 May 2000 on jurisdiction and the recognition and enforcement of judgments in matrimonial matters and in matters of parental responsibility for children of both spouses(1).\n(4) The Community has exclusive competence for the relevant provisions of the Convention insofar as those articles affect Community rules adopted in this area. The Member States should retain their competence in the areas covered by the Convention which do not affect Community law.\n(5) Pursuant to the Convention, only sovereign States may be party to it. For that reason, the Community may not at present sign, ratify or accede to it.\n(6) The Council should therefore authorise the Member States, by way of exception, to sign the Convention in the interest of the Community, under the conditions set out in this Decision.\n(7) Taking account of Articles 23, 26 and 52 of the Convention, a Decision taken by a Member State on matters governed by the Convention may be recognised and enforced in another Member State in accordance with the relevant internal rules of Community law.\n(8) The United Kingdom and Ireland are taking part in the adoption and application of this Decision.\n(9) Denmark, in accordance with Articles 1 and 2 of the Protocol on the position of Denmark annexed to the Treaty on European Union and the Treaty establishing the European Community, is not taking part in the adoption of this Decision and is therefore not bound by it nor subject to its application,\n1. The Council hereby authorises the Member States to sign the Convention on Jurisdiction, Applicable Law, Recognition, Enforcement and Cooperation in respect of Parental Responsibility and Measures for the Protection of Children, concluded on 19 October 1996, in the interest of the Community, subject to the conditions set out in the following articles.\n2. The text of the Convention is attached to this Decision(2).\n3. In this Decision, the term \"Member State\" shall mean all Member States with the exception of Denmark. When signing the Convention, Member States shall make the following declaration:\n\"Articles 23, 26 and 52 of the Convention allow Contracting Parties a degree of flexibility in order to apply a simple and rapid regime for the recognition and enforcement of judgments. The Community rules provide for a system of recognition and enforcement which is at least as favourable as the rules laid down in the Convention. Accordingly, a judgment given in a Court of a Member State of the European Union, in respect of a matter relating to the Convention, shall be recognised and enforced in(3) by application of the relevant internal rules of Community law(4).\" Member States shall make the necessary arrangements for the Convention to be signed before 1 June 2003. When signing the Convention, Member States shall inform the Ministry of Foreign Affairs of the Kingdom of the Netherlands in writing that the signing has taken place in accordance with this Decision.\nThis Decision is addressed to the Member States in accordance with the Treaty establishing the European Community.",
         "4373",
         "Decision",
         "Decision"
        ],
        [
         "35",
         "32007D0789",
         "Decision",
         "2007/789/EC: Commission Decision of 4 December 2007 suspending the definitive anti-dumping duty imposed by Regulation (EC) No 1420/2007 on imports of silico-manganese originating in the People’s Republic of China and Kazakhstan\n",
         "5.12.2007 EN Official Journal of the European Union L 317/79\nCOMMISSION DECISION\nof 4 December 2007\nsuspending the definitive anti-dumping duty imposed by Regulation (EC) No 1420/2007 on imports of silico-manganese originating in the People’s Republic of China and Kazakhstan\n(2007/789/EC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Regulation (EC) No 384/96 of 22 December 1995 on protection against dumped imports from countries not members of the European Community (1) (the basic Regulation), and in particular Article 14(4) thereof,\nAfter consulting the Advisory Committee,\nWhereas:\nA.   PROCEDURE\n(1) The Council, by Regulation (EC) No 1420/2007 (2), imposed a definitive anti-dumping duty on imports of silico-manganese (including ferro-silico-manganese) (SiMn) originating in the People’s Republic of China (PRC) and Kazakhstan, falling within CN codes 7202 30 00 and ex 8111 00 11 (TARIC code 8111001110) (the product concerned). The rate of the anti-dumping duty is 8,2 % and 6,5 % for the product originating in the PRC and Kazakhstan respectively.\n(2) Information on a change of market conditions, which occurred after the original investigation period, indicated in Regulation (EC) No 1420/2007, and which might justify the suspension of the measures imposed, in accordance with Article 14(4) of the basic Regulation, was obtained by the Commission. Consequently, the Commission examined whether such suspension was warranted.\nB.   GROUNDS\n(3) Article 14(4) of the basic Regulation provides that, in the Community interest, anti-dumping measures may be suspended on the grounds that market conditions have temporarily changed to an extent that injury would be unlikely to resume as a result of such suspension, provided that the Community industry has been given an opportunity to comment and these comments have been taken into account. Article 14(4) further specifies that the anti-dumping measures concerned may be reinstated at any time if the reason for suspension is no longer applicable.\n(4) Since the original investigation period, an increase in world prices for SiMn was observed, indicating a change of the market situation and conditions. In view of this, the Commission has carried out a further investigation to assess the recent evolution of volumes and prices of the product concerned for the period between 1 July 2006 and 30 September 2007 and their impact on the injury suffered by the Community industry as well as the overall Community interest.\n(5) On the basis of the information gathered, it was established that market prices of SiMn on the Community market have increased after the original investigation period until the third quarter of year 2007 by around 69 %, i.e. from an average EUR 622/MT in the third quarter of year 2006 to an average EUR 1 051/MT in the third quarter of year 2007. In particular, a significant increase of around 42 % was to be observed between the second and the third quarter of year 2007. These trends can also be found in other major markets across the world as well as for imports of SiMn into the Community.\n(6) SiMn is a key raw material used for the production of steel. The price increase described above can be attributed to the temporary supply shortages combined with a higher demand for SiMn due to increased demand for steel worldwide. Evidence from previous sudden price increases such as the one that occurred in year 2004 shows that such demand-supply imbalances in this market are of temporary nature. Prices tend to return to their long-term levels once the spare capacities for SiMn are fully utilised.\n(7) Between the original investigation period and the period from 1 October 2006 to 30 September 2007 the market share of imports of SiMn originating in the PRC and Kazakhstan decreased by 0,6 percentage points to 9,8 % of the overall Community consumption. EC consumption has increased by 20 %.\n(8) With regard to the Community industry, it is to be noted that since the original investigation period, the situation of the Community industry has improved. Between the original investigation period and the period from 1 October 2006 to 30 September 2007, the sales and production volumes have increased by 15 % and 19 % respectively. However, the market share of the Community industry decreased by 1,1 percentage points to 23,8 %. The profit situation improved significantly and the profitability of the Community industry reached 42 % in the third quarter of year 2007, thus substantially surpassing even the 5 % profit level established as appropriate by the original investigation.\n(9) As indicated in recitals 157 to 163 of Regulation (EC) No 1420/2007, the imposition of measures in question was expected to have some negative, although limited, effects for users in the form of cost increases arising out of the possible need to arrange new or alternative supplies. Considering the temporary change in market conditions and that consequently the Community industry is currently not suffering injury, any negative effect on users could be removed by suspending the measures. Consequently, it can be concluded that the suspension is in the overall Community interest.\n(10) Given the temporary change in market conditions, and in particular the high level of prices of SiMn existing on the Community market, which is far higher than the injurious price level found in the original investigation, together with the alleged demand-supply imbalance of the product concerned, it is considered that the injury linked to the imports of the product concerned originating in the PRC and Kazakhstan is unlikely to resume as a result of the suspension. It is therefore proposed to suspend for nine months the measures in force in accordance with Article 14(4) of the basic Regulation.\nC.   CONSULTATION OF COMMUNITY INDUSTRY\n(11) Pursuant to Article 14(4) of the basic Regulation, the Commission has informed the Community industry of its intention to suspend the anti-dumping measures in question. The Community industry has been given an opportunity to comment and did not oppose the suspension of the anti-dumping measures.\nD.   CONCLUSION\n(12) The Commission therefore considers that all requirements for suspending the anti-dumping duty imposed on the product concerned are met, in accordance with Article 14(4) of the basic Regulation. Consequently, the anti-dumping duty imposed by Regulation (EC) No 1420/2007 should be suspended for a period of nine months.\n(13) The Commission will monitor the development of imports and the prices of the product concerned. Should a situation arise at any time in which increased volumes at dumped prices of the product concerned from the PRC and Kazakhstan resume and consequently cause injury to the Community industry, the Commission will take the necessary steps to reinstate the anti-dumping duty, taking into account the substantive rules that govern an injury assessment. An interim review pursuant to Article 11(3) of the basic Regulation might be initiated, if appropriate,",
         "['The definitive anti-dumping duty imposed by Regulation (EC) No 1420/2007 on imports of silico-manganese (including ferro-silico-manganese), originating in the People’s Republic of China and Kazakhstan, falling within CN codes 7202\\xa030\\xa000 and ex\\xa08111\\xa000\\xa011 (TARIC code 8111001110) is hereby suspended for a period of nine months.', 'This Decision shall enter into force on the day following its publication in the Official Journal of the European Union.']",
         "['1309', '1591', '1779', '2771', '3837', '4084', '519', '5693', '5969']",
         "train",
         "2007/789/EC: Commission Decision of 4 December 2007 suspending the definitive anti-dumping duty imposed by Regulation (EC) No 1420/2007 on imports of silico-manganese originating in the People’s Republic of China and Kazakhstan\n\n,\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Regulation (EC) No 384/96 of 22 December 1995 on protection against dumped imports from countries not members of the European Community (1) (the basic Regulation), and in particular Article 14(4) thereof,\nAfter consulting the Advisory Committee,\nWhereas:\nA.   PROCEDURE\n(1) The Council, by Regulation (EC) No 1420/2007 (2), imposed a definitive anti-dumping duty on imports of silico-manganese (including ferro-silico-manganese) (SiMn) originating in the People’s Republic of China (PRC) and Kazakhstan, falling within CN codes 7202 30 00 and ex 8111 00 11 (TARIC code 8111001110) (the product concerned). The rate of the anti-dumping duty is 8,2 % and 6,5 % for the product originating in the PRC and Kazakhstan respectively.\n(2) Information on a change of market conditions, which occurred after the original investigation period, indicated in Regulation (EC) No 1420/2007, and which might justify the suspension of the measures imposed, in accordance with Article 14(4) of the basic Regulation, was obtained by the Commission. Consequently, the Commission examined whether such suspension was warranted.\nB.   GROUNDS\n(3) Article 14(4) of the basic Regulation provides that, in the Community interest, anti-dumping measures may be suspended on the grounds that market conditions have temporarily changed to an extent that injury would be unlikely to resume as a result of such suspension, provided that the Community industry has been given an opportunity to comment and these comments have been taken into account. Article 14(4) further specifies that the anti-dumping measures concerned may be reinstated at any time if the reason for suspension is no longer applicable.\n(4) Since the original investigation period, an increase in world prices for SiMn was observed, indicating a change of the market situation and conditions. In view of this, the Commission has carried out a further investigation to assess the recent evolution of volumes and prices of the product concerned for the period between 1 July 2006 and 30 September 2007 and their impact on the injury suffered by the Community industry as well as the overall Community interest.\n(5) On the basis of the information gathered, it was established that market prices of SiMn on the Community market have increased after the original investigation period until the third quarter of year 2007 by around 69 %, i.e. from an average EUR 622/MT in the third quarter of year 2006 to an average EUR 1 051/MT in the third quarter of year 2007. In particular, a significant increase of around 42 % was to be observed between the second and the third quarter of year 2007. These trends can also be found in other major markets across the world as well as for imports of SiMn into the Community.\n(6) SiMn is a key raw material used for the production of steel. The price increase described above can be attributed to the temporary supply shortages combined with a higher demand for SiMn due to increased demand for steel worldwide. Evidence from previous sudden price increases such as the one that occurred in year 2004 shows that such demand-supply imbalances in this market are of temporary nature. Prices tend to return to their long-term levels once the spare capacities for SiMn are fully utilised.\n(7) Between the original investigation period and the period from 1 October 2006 to 30 September 2007 the market share of imports of SiMn originating in the PRC and Kazakhstan decreased by 0,6 percentage points to 9,8 % of the overall Community consumption. EC consumption has increased by 20 %.\n(8) With regard to the Community industry, it is to be noted that since the original investigation period, the situation of the Community industry has improved. Between the original investigation period and the period from 1 October 2006 to 30 September 2007, the sales and production volumes have increased by 15 % and 19 % respectively. However, the market share of the Community industry decreased by 1,1 percentage points to 23,8 %. The profit situation improved significantly and the profitability of the Community industry reached 42 % in the third quarter of year 2007, thus substantially surpassing even the 5 % profit level established as appropriate by the original investigation.\n(9) As indicated in recitals 157 to 163 of Regulation (EC) No 1420/2007, the imposition of measures in question was expected to have some negative, although limited, effects for users in the form of cost increases arising out of the possible need to arrange new or alternative supplies. Considering the temporary change in market conditions and that consequently the Community industry is currently not suffering injury, any negative effect on users could be removed by suspending the measures. Consequently, it can be concluded that the suspension is in the overall Community interest.\n(10) Given the temporary change in market conditions, and in particular the high level of prices of SiMn existing on the Community market, which is far higher than the injurious price level found in the original investigation, together with the alleged demand-supply imbalance of the product concerned, it is considered that the injury linked to the imports of the product concerned originating in the PRC and Kazakhstan is unlikely to resume as a result of the suspension. It is therefore proposed to suspend for nine months the measures in force in accordance with Article 14(4) of the basic Regulation.\nC.   CONSULTATION OF COMMUNITY INDUSTRY\n(11) Pursuant to Article 14(4) of the basic Regulation, the Commission has informed the Community industry of its intention to suspend the anti-dumping measures in question. The Community industry has been given an opportunity to comment and did not oppose the suspension of the anti-dumping measures.\nD.   CONCLUSION\n(12) The Commission therefore considers that all requirements for suspending the anti-dumping duty imposed on the product concerned are met, in accordance with Article 14(4) of the basic Regulation. Consequently, the anti-dumping duty imposed by Regulation (EC) No 1420/2007 should be suspended for a period of nine months.\n(13) The Commission will monitor the development of imports and the prices of the product concerned. Should a situation arise at any time in which increased volumes at dumped prices of the product concerned from the PRC and Kazakhstan resume and consequently cause injury to the Community industry, the Commission will take the necessary steps to reinstate the anti-dumping duty, taking into account the substantive rules that govern an injury assessment. An interim review pursuant to Article 11(3) of the basic Regulation might be initiated, if appropriate,\nThe definitive anti-dumping duty imposed by Regulation (EC) No 1420/2007 on imports of silico-manganese (including ferro-silico-manganese), originating in the People’s Republic of China and Kazakhstan, falling within CN codes 7202 30 00 and ex 8111 00 11 (TARIC code 8111001110) is hereby suspended for a period of nine months. This Decision shall enter into force on the day following its publication in the Official Journal of the European Union.",
         "7448",
         "Decision",
         "Decision"
        ],
        [
         "36",
         "32014D0162",
         "Decision",
         "Council Decision 2014/162/EU of 11 March 2014 amending Decision 2004/162/EC with regard to its implementation in Mayotte from 1 January 2014\n",
         "25.3.2014 EN Official Journal of the European Union L 89/3\nCOUNCIL DECISION 2014/162/EU\nof 11 March 2014\namending Decision 2004/162/EC with regard to its implementation in Mayotte from 1 January 2014\nTHE COUNCIL OF THE EUROPEAN UNION",
         ",\nHaving regard to the Treaty on the Functioning of the European Union, and in particular Article 349 thereof,\nHaving regard to the proposal from the European Commission,\nAfter transmission of the draft legislative act to the national parliaments,\nHaving regard to the opinion of the European Parliament (1),\nActing in accordance with a special legislative procedure,\nWhereas:\n(1) Council Decision 2004/162/EC (2) authorises the French authorities to apply exemptions or reductions to dock dues in respect of products produced locally in the French outermost regions and listed in the Annex to that Decision. Those exemptions or reductions constitute specific measures designed to offset the specific constraints faced by the outermost regions which increase production costs for local companies and make it difficult for their products to compete with the same products imported from metropolitan France and other Member States. Mayotte’s situation is the same as that of the other French outermost regions.\n(2) In accordance with European Council Decision 2012/419/EU (3), with effect from 1 January 2014 Mayotte became an outermost region within the meaning of Article 349 of the Treaty on the Functioning of the European Union (TFEU). Union law should therefore be applicable to Mayotte from that date.\n(3) The French authorities have requested that Decision 2004/162/EC be applicable to Mayotte with effect from 1 January 2014, and have submitted a list of the products to which they wish to apply differentiated taxation, on the basis of whether the products are produced locally or not.\n(4) This Decision should authorise the French authorities to apply differentiated taxation to the products for which they have proven: firstly, that local production exists; secondly, that a significant importation of goods (including from metropolitan France and other Member States) could jeopardise the continuation of local production; and thirdly, that additional costs exist which increase the cost price of local production in comparison to products produced elsewhere, compromising the competitiveness of products produced locally. The authorised tax differential should not exceed the proven additional costs. Applying those principles and taking into account the specific structural social and economic situation of Mayotte as a new outermost region, which is compounded by exactly the same special constraints which justified the derogation in Decision 2004/162/EC for the other French outermost regions in accordance with Article 349 TFEU, the proposed specific measures for Mayotte are justified, without going beyond what is necessary and without creating an unjustified advantage for local production in this new outermost region.\n(5) The products in respect of which the French authorities have provided those three types of proof are listed in Parts A, B and C of the Annex to Decision 2004/162/EC. The products concerned listed in Part A of that Annex (authorised tax differential of 10 percentage points) are pepper (products 0904 11 and 0904 12 (4)), vanilla (0905), chocolate (1806), certain plastic products (3925 10 10, 3925 90 80, 3926 90 90 and 3926 90 97), bricks (6901 and 6902) and dental prostheses (9021 21 90).\n(6) The products concerned listed in Part B of the Annex to Decision 2004/162/EC (authorised tax differential of 20 percentage points) are fish (products 0301, 0302, 0303, 0304 and 0305), certain wood articles (4407, 4409, 4414, 4418, 4419, 4420 and 4421), certain paperboard and paper articles (4819 and 4821), certain products from the press and publishing sector (4902, 4909, 4910 and 4911), certain flat glass products (7003 and 7005), certain iron articles (7210, 7301, 7312, 7314, 9406 00 31 and 9406 00 38), certain aluminium articles (7606, 7610 10 and 8310) and certain seats (9401 69, 9401 90 30 and 9403 40).\n(7) The products concerned listed in Part C of the Annex to Decision 2004/162/EC (authorised tax differential of 30 percentage points) are milk and dairy products (0401, 0403 and 0406), certain meat-based processed products (1601 and 1602), certain bakery products (1901 and 1905), ice-creams (2105), mineral water and sodas (2201 and 2202), beer (2203), ylang-ylang (3301 29 11 and 3301 29 31), soaps and detergents (3401 and 3402) and foam mattresses (9404 29 90).\n(8) Decision 2004/162/EC should therefore be amended accordingly.\n(9) In light of the urgent need for Mayotte to be able, as a new outermost region, to benefit from the derogations introduced by this Decision as early as possible, an exception should be made to the eight-week period laid down by Article 4 of Protocol No 1 on the role of national parliaments in the European Union, annexed to the Treaty on the European Union and the TFEU.\n(10) Since Mayotte became an outermost region on 1 January 2014, and in order to avoid any legal uncertainty, it is necessary that this Decision applies from 1 January 2014,",
         "['Decision 2004/162/EC is amended as follows:\\n(1) the first subparagraph of Article 1(1) is replaced by the following:\\n(2) the Annex is amended as follows:\\n(a) the following point is added to Part A:\\n‘5. - Mayotte as outermost region\\n(b) the following point is added to Part B:\\n‘5. - Mayotte as outermost region\\n(c) the following point is added to Part C:\\n‘5. - Mayotte as outermost region', 'This Decision shall enter into force on the date of its adoption.\\nIt shall apply from 1 January 2014.', 'This Decision is addressed to the FrenchRepublic.']",
         "['1085', '1086', '1317', '1843', '2247', '365', '4128', '6926', '935']",
         "train",
         "Council Decision 2014/162/EU of 11 March 2014 amending Decision 2004/162/EC with regard to its implementation in Mayotte from 1 January 2014\n\n,\nHaving regard to the Treaty on the Functioning of the European Union, and in particular Article 349 thereof,\nHaving regard to the proposal from the European Commission,\nAfter transmission of the draft legislative act to the national parliaments,\nHaving regard to the opinion of the European Parliament (1),\nActing in accordance with a special legislative procedure,\nWhereas:\n(1) Council Decision 2004/162/EC (2) authorises the French authorities to apply exemptions or reductions to dock dues in respect of products produced locally in the French outermost regions and listed in the Annex to that Decision. Those exemptions or reductions constitute specific measures designed to offset the specific constraints faced by the outermost regions which increase production costs for local companies and make it difficult for their products to compete with the same products imported from metropolitan France and other Member States. Mayotte’s situation is the same as that of the other French outermost regions.\n(2) In accordance with European Council Decision 2012/419/EU (3), with effect from 1 January 2014 Mayotte became an outermost region within the meaning of Article 349 of the Treaty on the Functioning of the European Union (TFEU). Union law should therefore be applicable to Mayotte from that date.\n(3) The French authorities have requested that Decision 2004/162/EC be applicable to Mayotte with effect from 1 January 2014, and have submitted a list of the products to which they wish to apply differentiated taxation, on the basis of whether the products are produced locally or not.\n(4) This Decision should authorise the French authorities to apply differentiated taxation to the products for which they have proven: firstly, that local production exists; secondly, that a significant importation of goods (including from metropolitan France and other Member States) could jeopardise the continuation of local production; and thirdly, that additional costs exist which increase the cost price of local production in comparison to products produced elsewhere, compromising the competitiveness of products produced locally. The authorised tax differential should not exceed the proven additional costs. Applying those principles and taking into account the specific structural social and economic situation of Mayotte as a new outermost region, which is compounded by exactly the same special constraints which justified the derogation in Decision 2004/162/EC for the other French outermost regions in accordance with Article 349 TFEU, the proposed specific measures for Mayotte are justified, without going beyond what is necessary and without creating an unjustified advantage for local production in this new outermost region.\n(5) The products in respect of which the French authorities have provided those three types of proof are listed in Parts A, B and C of the Annex to Decision 2004/162/EC. The products concerned listed in Part A of that Annex (authorised tax differential of 10 percentage points) are pepper (products 0904 11 and 0904 12 (4)), vanilla (0905), chocolate (1806), certain plastic products (3925 10 10, 3925 90 80, 3926 90 90 and 3926 90 97), bricks (6901 and 6902) and dental prostheses (9021 21 90).\n(6) The products concerned listed in Part B of the Annex to Decision 2004/162/EC (authorised tax differential of 20 percentage points) are fish (products 0301, 0302, 0303, 0304 and 0305), certain wood articles (4407, 4409, 4414, 4418, 4419, 4420 and 4421), certain paperboard and paper articles (4819 and 4821), certain products from the press and publishing sector (4902, 4909, 4910 and 4911), certain flat glass products (7003 and 7005), certain iron articles (7210, 7301, 7312, 7314, 9406 00 31 and 9406 00 38), certain aluminium articles (7606, 7610 10 and 8310) and certain seats (9401 69, 9401 90 30 and 9403 40).\n(7) The products concerned listed in Part C of the Annex to Decision 2004/162/EC (authorised tax differential of 30 percentage points) are milk and dairy products (0401, 0403 and 0406), certain meat-based processed products (1601 and 1602), certain bakery products (1901 and 1905), ice-creams (2105), mineral water and sodas (2201 and 2202), beer (2203), ylang-ylang (3301 29 11 and 3301 29 31), soaps and detergents (3401 and 3402) and foam mattresses (9404 29 90).\n(8) Decision 2004/162/EC should therefore be amended accordingly.\n(9) In light of the urgent need for Mayotte to be able, as a new outermost region, to benefit from the derogations introduced by this Decision as early as possible, an exception should be made to the eight-week period laid down by Article 4 of Protocol No 1 on the role of national parliaments in the European Union, annexed to the Treaty on the European Union and the TFEU.\n(10) Since Mayotte became an outermost region on 1 January 2014, and in order to avoid any legal uncertainty, it is necessary that this Decision applies from 1 January 2014,\nDecision 2004/162/EC is amended as follows:\n(1) the first subparagraph of Article 1(1) is replaced by the following:\n(2) the Annex is amended as follows:\n(a) the following point is added to Part A:\n‘5. - Mayotte as outermost region\n(b) the following point is added to Part B:\n‘5. - Mayotte as outermost region\n(c) the following point is added to Part C:\n‘5. - Mayotte as outermost region This Decision shall enter into force on the date of its adoption.\nIt shall apply from 1 January 2014. This Decision is addressed to the FrenchRepublic.",
         "5619",
         "Decision",
         "Decision"
        ],
        [
         "37",
         "32010D0414",
         "Decision",
         "2010/414/CFSP: Council Decision 2010/414/CFSP of 26 July 2010 amending Decision 2010/127/CFSP concerning restrictive measures against Eritrea\n",
         "27.7.2010 EN Official Journal of the European Union L 195/74\nCOUNCIL DECISION 2010/414/CFSP\nof 26 July 2010\namending Decision 2010/127/CFSP concerning restrictive measures against Eritrea\nTHE COUNCIL OF THE EUROPEAN UNION",
         ",\nHaving regard to the Treaty on European Union, and in particular Article 29 thereof,\nWhereas:\n(1) On 1 March 2010, the Council adopted Decision 2010/127/CFSP concerning restrictive measures against Eritrea (1) and implementing United Nations Security Council Resolution (UNSCR) 1907 (2009).\n(2) Decision 2010/127/CFSP provides for restrictions on the admission of, and financial restrictive measures against persons and entities designated by the United Nations Security Council or by the competent Sanctions Committee, as well as prohibitions on the supply, sale or transfer of weapons and military equipment to those designated persons and entities and on the provision of related assistance and services.\n(3) The procedure for amending the Annex to Decision 2010/127/CFSP should include a requirement to communicate to the designated persons and entities the grounds for listing as provided by the Sanctions Committee, so as to give them an opportunity to present observations. Where observations are submitted or where substantial new evidence is presented, the Council should review its decision in the light of those observations and inform the person or entity concerned accordingly.\n(4) This Decision respects the fundamental rights and observes the principles recognised in particular by the Charter of Fundamental Rights of the European Union and notably the right to an effective remedy and to a fair trial, the right to property and the right to the protection of personal data. This Decision should be applied in accordance with those rights and principles.\n(5) This Decision also fully respects the obligations of Member States under the United Nations Charter and the legally binding nature of United Nations Security Council Resolutions.\n(6) Further action by the Union is needed in order to implement certain measures,",
         "['Decision 2010/127/CFSP is hereby amended as follows:\\n(1) Article 7 is replaced by the following:\\n(2) The following Articles are inserted:', 'This Decision shall enter into force on the date of its adoption.']",
         "['2647', '3483', '3584', '3870', '5617', '5788', '7']",
         "train",
         "2010/414/CFSP: Council Decision 2010/414/CFSP of 26 July 2010 amending Decision 2010/127/CFSP concerning restrictive measures against Eritrea\n\n,\nHaving regard to the Treaty on European Union, and in particular Article 29 thereof,\nWhereas:\n(1) On 1 March 2010, the Council adopted Decision 2010/127/CFSP concerning restrictive measures against Eritrea (1) and implementing United Nations Security Council Resolution (UNSCR) 1907 (2009).\n(2) Decision 2010/127/CFSP provides for restrictions on the admission of, and financial restrictive measures against persons and entities designated by the United Nations Security Council or by the competent Sanctions Committee, as well as prohibitions on the supply, sale or transfer of weapons and military equipment to those designated persons and entities and on the provision of related assistance and services.\n(3) The procedure for amending the Annex to Decision 2010/127/CFSP should include a requirement to communicate to the designated persons and entities the grounds for listing as provided by the Sanctions Committee, so as to give them an opportunity to present observations. Where observations are submitted or where substantial new evidence is presented, the Council should review its decision in the light of those observations and inform the person or entity concerned accordingly.\n(4) This Decision respects the fundamental rights and observes the principles recognised in particular by the Charter of Fundamental Rights of the European Union and notably the right to an effective remedy and to a fair trial, the right to property and the right to the protection of personal data. This Decision should be applied in accordance with those rights and principles.\n(5) This Decision also fully respects the obligations of Member States under the United Nations Charter and the legally binding nature of United Nations Security Council Resolutions.\n(6) Further action by the Union is needed in order to implement certain measures,\nDecision 2010/127/CFSP is hereby amended as follows:\n(1) Article 7 is replaced by the following:\n(2) The following Articles are inserted: This Decision shall enter into force on the date of its adoption.",
         "2184",
         "Decision",
         "Decision"
        ],
        [
         "38",
         "32001D0141",
         "Decision",
         "2001/141/EC: Commission Decision of 20 February 2001 for the implementation of a bluetongue vaccination programme in certain parts of the protection zone in Italy and the purchase by the Community of vaccine for this purpose (notified under document number C(2001) 424)\n",
         "Commission Decision\nof 20 February 2001\nfor the implementation of a bluetongue vaccination programme in certain parts of the protection zone in Italy and the purchase by the Community of vaccine for this purpose\n(notified under document number C(2001) 424)\n(Only the Italian text is authentic)\n(2001/141/EC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Directive 2000/75/EC of 20 November 2000(1) laying down specific provisions for the control and eradiction of bluetongue, and in particular Article 9(2),\nHaving regard to Council Decision 90/424/EEC of 26 June 1990 on expenditure in the veterinary field(2), as last amended by Council Decision 2000/12/EC(3), and in particular Article 3(3) and (5),\nWhereas:\n(1) During the year 2000 bluetongue outbreaks were notified in different Italian regions: Sardinia, Sicily and Calabria.\n(2) Italian authorities informed the Commission on the 19 December 2000 that they intended to perform in 2001 a vaccination campaign in Calabria and Basilicate regions and in the province of Salerno.\n(3) The objective of this campaign is to prevent a spread of the discase on the rest of the territory of the Community by interrupting the virus circulation in the protection zone demarcated around the outbreaks in Calabria.\n(4) The amount of vaccine necessary to carry on this campaign is of 1700000 doses of monovalent bluetongue vaccine serotype 2.\n(5) No bluetongue vaccine is produced by the pharmaceutical industry based in the Member States.\n(6) The Onderstepoort Laboratory in South Africa is the only laboratory which may produce that type of monovalent vaccine (attenuated vaccine) with the serotype 2.\n(7) Pursuant to Article 3(2) of Council Regulation (EC) No 1258/1999(4), veterinary and plant health measures undertaken in accordance with Community rules shall be financed under the Guarantee Section of the European Agricultural Guidance and Guaranteee Fund. For financial control purposes, Articles 8 and 9 of Council Regulation (CE) No 1258/1999 apply.\n(8) The financial contribution from the Community shall be granted provided that the actions planned are efficiently carried out and that the authorities supply all the necessary information within the time limits laid down.\n(9) The measures provided for in this Decision are in accordance with the opinion of the Standing Veterinary Committee,",
         "['Italy will implement in spring 2001 a vaccination programme against bluetonge in Calabria and Basilicate regions and in the Salerno province.', 'For the implementation of the programme referred to in Article 1 the financial assistance from the Community will cover the supply to Italy of 1700000 doses of monovalent vaccine serotype 2.', 'The maximum cost of the measures referred to in Article 2 shall be up to EUR 140000.', '1. For the vaccination programme referred to in Article 1 the Director-General of the Directorate-General for Health and Consumer Protection shall be authorised to make arrangements with Onderstepoort Laboratory in South Africa for the purchase of 1700000 doses of monovalent bluetongue vaccine (serotype 2).\\n2. The arrangements referred to in paragraph 1 shall include the airfreight to Italy.', 'The Commission may carry out on-the-spot checks in collaboration with the competent national authorities to ensure that the programme has been implemented.\\nThe Commission shall inform the Member States of the outcome of these checks.', 'The financial contribution of the Community for the programme referred to under Article 1 shall be granted subjet to:\\n(a) bringing into force by 1 April 2001 the laws, regulations and administrative provisions by the Member State concerned for implementing the programme,\\n(b) forwarding a final report by 1 July 2001 at the latest on the technical execution of the programme accompanied by justifying evidence as to the costs incurred and the results attained,\\n(c) implementing the programme efficiently, and provided that Community veterinary legislation has been respected.', 'This Decisione is addressed to the Italian Republic.']",
         "['1520', '1598', '1755', '2211', '4636', '862', '922']",
         "train",
         "2001/141/EC: Commission Decision of 20 February 2001 for the implementation of a bluetongue vaccination programme in certain parts of the protection zone in Italy and the purchase by the Community of vaccine for this purpose (notified under document number C(2001) 424)\n\n,\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Directive 2000/75/EC of 20 November 2000(1) laying down specific provisions for the control and eradiction of bluetongue, and in particular Article 9(2),\nHaving regard to Council Decision 90/424/EEC of 26 June 1990 on expenditure in the veterinary field(2), as last amended by Council Decision 2000/12/EC(3), and in particular Article 3(3) and (5),\nWhereas:\n(1) During the year 2000 bluetongue outbreaks were notified in different Italian regions: Sardinia, Sicily and Calabria.\n(2) Italian authorities informed the Commission on the 19 December 2000 that they intended to perform in 2001 a vaccination campaign in Calabria and Basilicate regions and in the province of Salerno.\n(3) The objective of this campaign is to prevent a spread of the discase on the rest of the territory of the Community by interrupting the virus circulation in the protection zone demarcated around the outbreaks in Calabria.\n(4) The amount of vaccine necessary to carry on this campaign is of 1700000 doses of monovalent bluetongue vaccine serotype 2.\n(5) No bluetongue vaccine is produced by the pharmaceutical industry based in the Member States.\n(6) The Onderstepoort Laboratory in South Africa is the only laboratory which may produce that type of monovalent vaccine (attenuated vaccine) with the serotype 2.\n(7) Pursuant to Article 3(2) of Council Regulation (EC) No 1258/1999(4), veterinary and plant health measures undertaken in accordance with Community rules shall be financed under the Guarantee Section of the European Agricultural Guidance and Guaranteee Fund. For financial control purposes, Articles 8 and 9 of Council Regulation (CE) No 1258/1999 apply.\n(8) The financial contribution from the Community shall be granted provided that the actions planned are efficiently carried out and that the authorities supply all the necessary information within the time limits laid down.\n(9) The measures provided for in this Decision are in accordance with the opinion of the Standing Veterinary Committee,\nItaly will implement in spring 2001 a vaccination programme against bluetonge in Calabria and Basilicate regions and in the Salerno province. For the implementation of the programme referred to in Article 1 the financial assistance from the Community will cover the supply to Italy of 1700000 doses of monovalent vaccine serotype 2. The maximum cost of the measures referred to in Article 2 shall be up to EUR 140000. 1. For the vaccination programme referred to in Article 1 the Director-General of the Directorate-General for Health and Consumer Protection shall be authorised to make arrangements with Onderstepoort Laboratory in South Africa for the purchase of 1700000 doses of monovalent bluetongue vaccine (serotype 2).\n2. The arrangements referred to in paragraph 1 shall include the airfreight to Italy. The Commission may carry out on-the-spot checks in collaboration with the competent national authorities to ensure that the programme has been implemented.\nThe Commission shall inform the Member States of the outcome of these checks. The financial contribution of the Community for the programme referred to under Article 1 shall be granted subjet to:\n(a) bringing into force by 1 April 2001 the laws, regulations and administrative provisions by the Member State concerned for implementing the programme,\n(b) forwarding a final report by 1 July 2001 at the latest on the technical execution of the programme accompanied by justifying evidence as to the costs incurred and the results attained,\n(c) implementing the programme efficiently, and provided that Community veterinary legislation has been respected. This Decisione is addressed to the Italian Republic.",
         "4032",
         "Decision",
         "Decision"
        ],
        [
         "39",
         "31984D0465",
         "Decision",
         "84/465/EEC: Commission Decision of 26 September 1984 accepting undertakings given in connection with the anti-dumping proceeding concerning imports of asbestos-cement corrugated sheets originating in Czechoslovakia and the German Democratic Republic and terminating that proceeding\n",
         "COMMISSION  DECISION\nof 26 September 1984\naccepting undertakings given in connection with the anti-dumping proceeding concerning imports of asbestos-cement corrugated sheets originating in Czechoslovakia and the German Democratic Republic and terminating that proceeding\n(84/465/EEC)\nTHE COMMISSION OF THE EUROPEAN\nCOMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Regulation (EEC) No 2176/84 of 23 July 1984 on protection against dumped or subsidized imports from countries not members of the European Economic Community (1), and in particular Article 10 thereof,\nAfter consultation within the Advisory Committee as provided for under the abovementioned Regulation,\nWhereas:\nA. Procedure\n(1) In January 1984 the Commission received a complaint lodged by the 'Union professionnelle des usines belges d'asbeste ciment' on behalf of producers representing the majority of Community production of asbestos-cement corrugated sheets. The complaint contained evidence of dumping and of material injury resulting therefrom, which was considered sufficient to justify the initiation of a proceeding. The Commission accordingly announced, by a notice published in the Official Journal of the European Communities (2), the initiation of an anti-dumping proceeding concerning imports into the Community of asbestos-cement corrugated sheets falling within subheading ex 68.12 A of the Common Customs Tariff, corresponding to NIMEXE code ex 68.12-11, originating in Czechoslovakia and the German Democratic Republic and commenced an investigation.\n(2) The Commission officially so advised the exporters and importers known to be concerned and the representatives of the exporting countries and the complainants and gave the parties directly concerned the opportunity to make known their views in writing and to request a hearing.\n(3) The known exporter and importers of the product concerned originating in Czechoslovakia requested and were granted a hearing.\n(4) The exporter and importers of the product concerned originating in Czechoslovakia requested and were granted the opportunity to meet the complainants for the purpose of presenting their opposing views.\n(5) The Commission sought and verified all information it deemed to be necessary for the purposes of a preliminary determination and carried out investigations at the premises of the following:\n(i) EEC producers\n(a) Belgium\n- Eternit NV, Kapelle-op-den-Bos,\n- S. A. Fabrecim, Harmignies,\n- J. M. Balmatt NV, Mol,\n- NV Scheerders van Kerhove's Ver. Fabrieken, St. Niklaas;\n(b) The Netherlands\n- Eternit BV, Amsterdam;\n(c) France\n- Eternit Industries SA, Vernouillet,\n- Everitube SA, Paris;\n(d) Federal Republic of Germany\nEternit AG, Berlin;\n(ii) Producer in Finland\n(for the purpose of determining the normal value):\nOy Partek AB, Muijala;\n(iii) Importers\n(a) Belgium\nEts. D. Van Riet, Temse, for the product originating in the German Democratic Republic;\n(b) The Netherlands\n- A. de Boo Delft BV, Delft (assisted by a representative of P. N. M. Hooge-ChemicaliĂŤn BV, Vught, acting as the agent of the exporter of the German Democratic Republic),\n- Austria BV, Lisse, for the product originating in Czechoslovakia.\n(6) The investigation of dumping covered the period 1 January to 31 December 1983.\nB. Normal value\n(7) In order to establish whether the imports from Czechoslovakia and the German Democratic Republic were dumped, the Commission had to take account of the fact that these countries do not have market economies. The Commission therefore based its determination of the normal value in a market-economy country.\n(8) In this connection, the complainants had suggested the Finnish market. However, most of the exporters and importers contested the use of Finnish domestic prices, mainly because these parties considered that these prices do not result from a normal supply and demand situation. Therefore, it was suggested by these parties to use Spanish prices for sales on the domestic market or for export to the EEC.\n(9) Although the arguments presented by the exporters and importers were not considered by the Commission to constitute by themselves sufficient reasons for rejecting Finland as the market-economy third country for the determination of the normal value, the Commission, nevertheless, examined the possibility of establishing normal value on the basis of the prices of the Spanish product. However, the Commission was informed that its representatives could not be received at the premises of the individual producers in Spain, but that an investigation could take place at the office of the Spanish association of asbestos-cement producers. This proposal was not considered acceptable by the Commission, since there were not sufficient guarantees offered that would enable the Commission's representatives to carry out a thorough investigation covering all information necessary to determine the normal value in accordance with the provisions of Article 3 of Council Regulation (EEC) No 2176/84, particularly concerning the profitability relating to the sales made by each of the Spanish producers of the product concerned.\n(10) Taking into account the fact that no other alternatives had been put forward by the interested parties, except for Austria, with regard to which no evidence or arguments had been submitted, and in order to avoid further delays at this stage of the proceeding, it was provisionally decided that the constructed value calculated for the manufacturer of the product concerned in Finland is to be considered as the most appropriate and reasonable basis for the determination of the normal value, since by taking the constructed value as the basis for this calculation, the main objection raised by the exporters and importers (see point 8) does not apply. The constructed value was computed by taking the company's total cost of materials and manufacture, including overheads and a modest profit margin, considered reasonable in this case.\nC. Export price\n(11) Export prices were determined on the basis of the prices actually paid for the product sold for export to the Community.\nD. Comparison\n(12) In comparing normal value with export prices, the Commission took account, where appropriate, of differences affecting price comparability. This was the case for differences in conditions and terms of sale in so far as a direct relationship could be satisfactorily demonstrated. These differences concerned in particular credit terms, transport, insurance, handling, loading and ancillary costs. All comparisons were made at ex-works level.\nE. Margins\n(13) The above preliminary examination of the facts shows the existence of dumping in respect of all the exporters concerned, the margin of dumping being equal to the amount by which the normal value as established exceeds the prices for export to the Community.\n(14) These margins vary according to the exporter concerned and the importing Member State, the weighted average dumping margin with regard to each of the exporting countries being as follows:\n- Czechoslovakia: 82 %\n- the German Democratic Republic: 77 %\nF. Injury\n(15) With regard to the injury caused by the dumped imports the evidence available to the Commission shows that imports into the Community from Czechoslovakia and the German Democratic Republic of asbestos-cement corrugated sheets increased from 26 780 tonnes in 1980 to 30 947 tonnes in 1983, which represents an increase of 15,5 %. In the Benelux countries these imports increased from 9 188 tonnes in 1980 to 21 161 tonnes in 1983, which represents an increase of 130 %.\n(16) With regard to the combined market share held by the dumped imports the evidence available to the Commission shows that it increased from 1,4 % in 1980 to 2,3 % in 1983 in the Community, which represents an increase of 64 %. Furthermore, in the Benelux countries, where these imports were concentrated, this market share increased from 5,8 to 20,4 % between 1980 and 1983, which represents an increase of 250 %.\n(17) The resale prices of these imports undercut the prices of the Community producers concerned in this proceeding during the investigation period by 15 %.\n(18) These imports have been a main cause of the increasing difficulties encountered in a declining market by the Community producers concerned in this proceeding. As such, these dumped imports contributed to the reduction of their production, which dropped by 21,4 % between 1980 and 1983, to the reduction of their capacity utilization, which dropped from 72 % in 1980 to 64 % in 1983 despite the lowering of their capacity by 12 % during the same period, and to the reduction of their sales, which dropped by 15,5 % between 1980 and 1983.\n(19) With regard to the development of the profitability of the Community producers concerned in this proceeding, it has been established that between 1980 and 1983 profits either dropped significantly or considerable losses were made.\n(20) Between 1980 and 1983 the number of employees of these Community producers was significantly reduced.\n(21) It has been argued by some exporters and importers that injury has been caused not by the dumped imports, but by sales of the product concerned originating in Italy. Although it appears on the basis of the evidence available to the Commission that sales of the product concerned originating in Italy increased significantly between 1980 and 1983, the prices at which this product was sold were, on average, 15 % above the prices of the dumped products. The substantial increase of the dumped products, particularly in the Benelux countries, and the prices at which they are offered for sale in these Member States, led the Commission to determine that the effects of the dumped imports of asbestos-cement corrugated sheets originating both in Czechoslovakia and in the German Democratic Republic taken in isolation, have to be considered as constituting material injury to the Community producers concerned in this proceeding.\nG. Community interest\n(22) In view of the particularly serious difficulties facing the Community producers concerned in this proceeding and particularly the negative development of their profitability, the Commission has come to the conclusion that it is in the Community's interest that action be taken.\nH. Undertakings\n(23) The exporters concerned were informed of the main findings of the preliminary investigation and commented on them. Undertakings were subsequently offered by the exporters established in Czechoslovakia and the German Democratic Republic concerning their exports of asbestos-cement corrugated sheets to the Community. (24) The effect of the said undertakings will be to increase their export prices to the Community to the level which the Commission, having taken into account, on the one hand, the selling price necessary to provide an adequate return to Community producers and, on the other hand, the purchase price of the Community importers and their costs and profit margin, considered necessary to eliminate injury. These increases in no case exceed the dumping margins found in the investigation.\n(25) In these circumstances, the undertakings offered are considered acceptable and the proceeding may, therefore, be terminated without imposition of anti-dumping duties.\n(26) No objection to this course was raised in the Advisory Committee,",
         "['The undertakings given by the following companies:\\n- Czechoslovak Ceramics Foreign Trade Corporation, Prague (Czechoslovakia),\\n- Limex GmbH, Bau-Export-Import, Berlin (German Democratic Republic),\\nin connection with the anti-dumping proceeding concerning imports of asbestos-cement corrugated sheets falling within subheading ex 68.12 A of the Common Customs Tariff, corresponding to NIMEXE code ex 68.12-11, originating in Czechoslovakia and the German Democratic Republic, are hereby accepted.', 'The anti-dumping proceeding referred to in Article 1 is hereby terminated.']",
         "['1308', '1826', '4411', '588']",
         "train",
         "84/465/EEC: Commission Decision of 26 September 1984 accepting undertakings given in connection with the anti-dumping proceeding concerning imports of asbestos-cement corrugated sheets originating in Czechoslovakia and the German Democratic Republic and terminating that proceeding\n\n,\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Regulation (EEC) No 2176/84 of 23 July 1984 on protection against dumped or subsidized imports from countries not members of the European Economic Community (1), and in particular Article 10 thereof,\nAfter consultation within the Advisory Committee as provided for under the abovementioned Regulation,\nWhereas:\nA. Procedure\n(1) In January 1984 the Commission received a complaint lodged by the 'Union professionnelle des usines belges d'asbeste ciment' on behalf of producers representing the majority of Community production of asbestos-cement corrugated sheets. The complaint contained evidence of dumping and of material injury resulting therefrom, which was considered sufficient to justify the initiation of a proceeding. The Commission accordingly announced, by a notice published in the Official Journal of the European Communities (2), the initiation of an anti-dumping proceeding concerning imports into the Community of asbestos-cement corrugated sheets falling within subheading ex 68.12 A of the Common Customs Tariff, corresponding to NIMEXE code ex 68.12-11, originating in Czechoslovakia and the German Democratic Republic and commenced an investigation.\n(2) The Commission officially so advised the exporters and importers known to be concerned and the representatives of the exporting countries and the complainants and gave the parties directly concerned the opportunity to make known their views in writing and to request a hearing.\n(3) The known exporter and importers of the product concerned originating in Czechoslovakia requested and were granted a hearing.\n(4) The exporter and importers of the product concerned originating in Czechoslovakia requested and were granted the opportunity to meet the complainants for the purpose of presenting their opposing views.\n(5) The Commission sought and verified all information it deemed to be necessary for the purposes of a preliminary determination and carried out investigations at the premises of the following:\n(i) EEC producers\n(a) Belgium\n- Eternit NV, Kapelle-op-den-Bos,\n- S. A. Fabrecim, Harmignies,\n- J. M. Balmatt NV, Mol,\n- NV Scheerders van Kerhove's Ver. Fabrieken, St. Niklaas;\n(b) The Netherlands\n- Eternit BV, Amsterdam;\n(c) France\n- Eternit Industries SA, Vernouillet,\n- Everitube SA, Paris;\n(d) Federal Republic of Germany\nEternit AG, Berlin;\n(ii) Producer in Finland\n(for the purpose of determining the normal value):\nOy Partek AB, Muijala;\n(iii) Importers\n(a) Belgium\nEts. D. Van Riet, Temse, for the product originating in the German Democratic Republic;\n(b) The Netherlands\n- A. de Boo Delft BV, Delft (assisted by a representative of P. N. M. Hooge-ChemicaliĂŤn BV, Vught, acting as the agent of the exporter of the German Democratic Republic),\n- Austria BV, Lisse, for the product originating in Czechoslovakia.\n(6) The investigation of dumping covered the period 1 January to 31 December 1983.\nB. Normal value\n(7) In order to establish whether the imports from Czechoslovakia and the German Democratic Republic were dumped, the Commission had to take account of the fact that these countries do not have market economies. The Commission therefore based its determination of the normal value in a market-economy country.\n(8) In this connection, the complainants had suggested the Finnish market. However, most of the exporters and importers contested the use of Finnish domestic prices, mainly because these parties considered that these prices do not result from a normal supply and demand situation. Therefore, it was suggested by these parties to use Spanish prices for sales on the domestic market or for export to the EEC.\n(9) Although the arguments presented by the exporters and importers were not considered by the Commission to constitute by themselves sufficient reasons for rejecting Finland as the market-economy third country for the determination of the normal value, the Commission, nevertheless, examined the possibility of establishing normal value on the basis of the prices of the Spanish product. However, the Commission was informed that its representatives could not be received at the premises of the individual producers in Spain, but that an investigation could take place at the office of the Spanish association of asbestos-cement producers. This proposal was not considered acceptable by the Commission, since there were not sufficient guarantees offered that would enable the Commission's representatives to carry out a thorough investigation covering all information necessary to determine the normal value in accordance with the provisions of Article 3 of Council Regulation (EEC) No 2176/84, particularly concerning the profitability relating to the sales made by each of the Spanish producers of the product concerned.\n(10) Taking into account the fact that no other alternatives had been put forward by the interested parties, except for Austria, with regard to which no evidence or arguments had been submitted, and in order to avoid further delays at this stage of the proceeding, it was provisionally decided that the constructed value calculated for the manufacturer of the product concerned in Finland is to be considered as the most appropriate and reasonable basis for the determination of the normal value, since by taking the constructed value as the basis for this calculation, the main objection raised by the exporters and importers (see point 8) does not apply. The constructed value was computed by taking the company's total cost of materials and manufacture, including overheads and a modest profit margin, considered reasonable in this case.\nC. Export price\n(11) Export prices were determined on the basis of the prices actually paid for the product sold for export to the Community.\nD. Comparison\n(12) In comparing normal value with export prices, the Commission took account, where appropriate, of differences affecting price comparability. This was the case for differences in conditions and terms of sale in so far as a direct relationship could be satisfactorily demonstrated. These differences concerned in particular credit terms, transport, insurance, handling, loading and ancillary costs. All comparisons were made at ex-works level.\nE. Margins\n(13) The above preliminary examination of the facts shows the existence of dumping in respect of all the exporters concerned, the margin of dumping being equal to the amount by which the normal value as established exceeds the prices for export to the Community.\n(14) These margins vary according to the exporter concerned and the importing Member State, the weighted average dumping margin with regard to each of the exporting countries being as follows:\n- Czechoslovakia: 82 %\n- the German Democratic Republic: 77 %\nF. Injury\n(15) With regard to the injury caused by the dumped imports the evidence available to the Commission shows that imports into the Community from Czechoslovakia and the German Democratic Republic of asbestos-cement corrugated sheets increased from 26 780 tonnes in 1980 to 30 947 tonnes in 1983, which represents an increase of 15,5 %. In the Benelux countries these imports increased from 9 188 tonnes in 1980 to 21 161 tonnes in 1983, which represents an increase of 130 %.\n(16) With regard to the combined market share held by the dumped imports the evidence available to the Commission shows that it increased from 1,4 % in 1980 to 2,3 % in 1983 in the Community, which represents an increase of 64 %. Furthermore, in the Benelux countries, where these imports were concentrated, this market share increased from 5,8 to 20,4 % between 1980 and 1983, which represents an increase of 250 %.\n(17) The resale prices of these imports undercut the prices of the Community producers concerned in this proceeding during the investigation period by 15 %.\n(18) These imports have been a main cause of the increasing difficulties encountered in a declining market by the Community producers concerned in this proceeding. As such, these dumped imports contributed to the reduction of their production, which dropped by 21,4 % between 1980 and 1983, to the reduction of their capacity utilization, which dropped from 72 % in 1980 to 64 % in 1983 despite the lowering of their capacity by 12 % during the same period, and to the reduction of their sales, which dropped by 15,5 % between 1980 and 1983.\n(19) With regard to the development of the profitability of the Community producers concerned in this proceeding, it has been established that between 1980 and 1983 profits either dropped significantly or considerable losses were made.\n(20) Between 1980 and 1983 the number of employees of these Community producers was significantly reduced.\n(21) It has been argued by some exporters and importers that injury has been caused not by the dumped imports, but by sales of the product concerned originating in Italy. Although it appears on the basis of the evidence available to the Commission that sales of the product concerned originating in Italy increased significantly between 1980 and 1983, the prices at which this product was sold were, on average, 15 % above the prices of the dumped products. The substantial increase of the dumped products, particularly in the Benelux countries, and the prices at which they are offered for sale in these Member States, led the Commission to determine that the effects of the dumped imports of asbestos-cement corrugated sheets originating both in Czechoslovakia and in the German Democratic Republic taken in isolation, have to be considered as constituting material injury to the Community producers concerned in this proceeding.\nG. Community interest\n(22) In view of the particularly serious difficulties facing the Community producers concerned in this proceeding and particularly the negative development of their profitability, the Commission has come to the conclusion that it is in the Community's interest that action be taken.\nH. Undertakings\n(23) The exporters concerned were informed of the main findings of the preliminary investigation and commented on them. Undertakings were subsequently offered by the exporters established in Czechoslovakia and the German Democratic Republic concerning their exports of asbestos-cement corrugated sheets to the Community. (24) The effect of the said undertakings will be to increase their export prices to the Community to the level which the Commission, having taken into account, on the one hand, the selling price necessary to provide an adequate return to Community producers and, on the other hand, the purchase price of the Community importers and their costs and profit margin, considered necessary to eliminate injury. These increases in no case exceed the dumping margins found in the investigation.\n(25) In these circumstances, the undertakings offered are considered acceptable and the proceeding may, therefore, be terminated without imposition of anti-dumping duties.\n(26) No objection to this course was raised in the Advisory Committee,\nThe undertakings given by the following companies:\n- Czechoslovak Ceramics Foreign Trade Corporation, Prague (Czechoslovakia),\n- Limex GmbH, Bau-Export-Import, Berlin (German Democratic Republic),\nin connection with the anti-dumping proceeding concerning imports of asbestos-cement corrugated sheets falling within subheading ex 68.12 A of the Common Customs Tariff, corresponding to NIMEXE code ex 68.12-11, originating in Czechoslovakia and the German Democratic Republic, are hereby accepted. The anti-dumping proceeding referred to in Article 1 is hereby terminated.",
         "11917",
         "Decision",
         "Decision"
        ],
        [
         "40",
         "32004D0791(01)",
         "Decision",
         "Council Decision 2004/791/CFSP of 22 November 2004 extending and amending Decision 2002/842/CFSP implementing Joint Action 2002/589/CFSP with a view to a European Union's contribution to combating the destabilising accumulation and spread of small arms and light weapons in South East Europe\n",
         "24.11.2004 EN Official Journal of the European Union L 348/46\nCOUNCIL DECISION 2004/791/CFSP\nof 22 November 2004\nextending and amending Decision 2002/842/CFSP implementing Joint Action 2002/589/CFSP with a view to a European Union's contribution to combating the destabilising accumulation and spread of small arms and light weapons in South East Europe\nTHE COUNCIL OF THE EUROPEAN UNION",
         ",\nHaving regard to Joint Action 2002/589/CFSP (1) and in particular Article 6 thereof, in conjunction with the second indent of Article 23(2) of the Treaty on European Union,\nWhereas:\n(1) On 21 October 2002 the Council adopted Decision 2002/842/CFSP (2) concerning a European Union contribution to combating the destabilising accumulation and spread of small arms and light weapons in South East Europe, which was aimed at implementing Joint Action 2002/589/CFSP and which made available EUR 200 000 for this purpose.\n(2) Some objectives could not be fulfilled by 31 December 2004, the date on which Decision 2002/842/CFSP expires, and others should be consolidated and expanded after that date. The project in question is a multi-annual project.\n(3) Decision 2002/842/CFSP should therefore be extended and amended,",
         "['Decision 2002/842/CFSP is hereby amended as follows:\\n1. In Article 2(1), the financial reference amount ‘EUR 300\\xa0000’ shall be replaced by ‘EUR 330\\xa0000’;\\n2. In Article 4(1), the second sentence shall be replaced by the sentence ‘It shall expire on 31 December 2005’.', 'This Decision shall take effect on the day of its adoption.', 'This Decision shall be published in the Official Journal of the European Union.']",
         "['3434', '3450', '3506', '5413', '862', '914', '922']",
         "train",
         "Council Decision 2004/791/CFSP of 22 November 2004 extending and amending Decision 2002/842/CFSP implementing Joint Action 2002/589/CFSP with a view to a European Union's contribution to combating the destabilising accumulation and spread of small arms and light weapons in South East Europe\n\n,\nHaving regard to Joint Action 2002/589/CFSP (1) and in particular Article 6 thereof, in conjunction with the second indent of Article 23(2) of the Treaty on European Union,\nWhereas:\n(1) On 21 October 2002 the Council adopted Decision 2002/842/CFSP (2) concerning a European Union contribution to combating the destabilising accumulation and spread of small arms and light weapons in South East Europe, which was aimed at implementing Joint Action 2002/589/CFSP and which made available EUR 200 000 for this purpose.\n(2) Some objectives could not be fulfilled by 31 December 2004, the date on which Decision 2002/842/CFSP expires, and others should be consolidated and expanded after that date. The project in question is a multi-annual project.\n(3) Decision 2002/842/CFSP should therefore be extended and amended,\nDecision 2002/842/CFSP is hereby amended as follows:\n1. In Article 2(1), the financial reference amount ‘EUR 300 000’ shall be replaced by ‘EUR 330 000’;\n2. In Article 4(1), the second sentence shall be replaced by the sentence ‘It shall expire on 31 December 2005’. This Decision shall take effect on the day of its adoption. This Decision shall be published in the Official Journal of the European Union.",
         "1515",
         "Decision",
         "Decision"
        ],
        [
         "41",
         "32007D0815",
         "Decision",
         "2007/815/EC: Commission Decision of 29 November 2007 implementing Decision No 573/2007/EC of the European Parliament and of the Council as regards the adoption of the strategic guidelines 2008 to 2013 (notified under document number C(2007) 5738)\n",
         "12.12.2007 EN Official Journal of the European Union L 326/29\nCOMMISSION DECISION\nof 29 November 2007\nimplementing Decision No 573/2007/EC of the European Parliament and of the Council as regards the adoption of the strategic guidelines 2008 to 2013\n(notified under document number C(2007) 5738)\n(Only the Bulgarian, Czech, Dutch, English, Estonian, Finnish, French, German, Greek, Hungarian, Italian, Latvian, Lithuanian, Maltese, Polish, Portuguese, Romanian, Slovak, Slovenian, Spanish and Swedish texts are authentic)\n(2007/815/EC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Decision No 573/2007/EC of the European Parliament and the Council of 23 May 2007 establishing a European Refugee Fund for the period 2008 to 2013 as part of the General programme ‘Solidarity and Management of Migration Flows’ and repealing Council Decision 2004/904/EC (1), and in particular Article 17 thereof,\nWhereas:\n(1) The Commission should lay down strategic guidelines setting out a framework for the intervention of the Fund relating to the multi-annual programming period 2008 to 2013.\n(2) The guidelines should define the priorities and, in accordance with Article 14(4) of the Decision No 573/2007/EC, the specific priorities which allow the Member States not covered by the Cohesion Fund to have the co-financing of the Community contribution increased to 75 % for projects co-financed by the Fund.\n(3) In accordance with Article 2 of the Protocol on the position of Denmark, annexed to the Treaty on European Union and to the Treaty establishing the European Community, Denmark is not bound by this Decision or subject to its application.\n(4) In accordance with Article 3 of the Protocol on the position of the United Kingdom and Ireland, annexed to the Treaty on European Union and to the Treaty establishing the European Community, Ireland has notified, by letter of 6 September 2005, its wish to take part in the adoption and application of Decision No 573/2007/EC.\n(5) In accordance with Article 3 of the Protocol on the position of the United Kingdom and Ireland, annexed to the Treaty on European Union and to the Treaty establishing the European Community, the United Kingdom has notified, by letter of 27 October 2005, its wish to take part in the adoption and application of Decision No 573/2007/EC.\n(6) The measures provided for in this Decision are in accordance with the opinion of the common Committee ‘Solidarity and Management of Migration Flows’ established by Article 56 of Decision No 574/2007/EC of the European Parliament and of the Council establishing the External Borders Fund for the period 2007 to 2013 as part of the General programme ‘Solidarity and Management of Migration Flows’ (2),",
         "['The guidelines setting out the priorities and specific priorities for the multi-annual programming for the period 2008 to 2013 shall be as defined in the Annex.', 'This Decision is addressed to the Kingdom of Belgium, the Republic of Bulgaria, the Czech Republic, the Federal Republic of Germany, the Republic of Estonia, the Hellenic Republic, the Kingdom of Spain, the French Republic, Ireland, the Italian Republic, the Republic of Cyprus, the Republic of Latvia, the Republic of Lithuania, the Grand-Duchy of Luxembourg, the Republic of Hungary, the Republic of Malta, the Kingdom of the Netherlands, the Republic of Austria, the Republic of Poland, the Portuguese Republic, Romania, the Republic of Slovenia, the Slovak Republic, the Republic of Finland, the Kingdom of Sweden, the United Kingdom of Great Britain and Northern Ireland.']",
         "['1000', '1052', '1462', '2986', '3075', '4005', '5315']",
         "train",
         "2007/815/EC: Commission Decision of 29 November 2007 implementing Decision No 573/2007/EC of the European Parliament and of the Council as regards the adoption of the strategic guidelines 2008 to 2013 (notified under document number C(2007) 5738)\n\n,\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Decision No 573/2007/EC of the European Parliament and the Council of 23 May 2007 establishing a European Refugee Fund for the period 2008 to 2013 as part of the General programme ‘Solidarity and Management of Migration Flows’ and repealing Council Decision 2004/904/EC (1), and in particular Article 17 thereof,\nWhereas:\n(1) The Commission should lay down strategic guidelines setting out a framework for the intervention of the Fund relating to the multi-annual programming period 2008 to 2013.\n(2) The guidelines should define the priorities and, in accordance with Article 14(4) of the Decision No 573/2007/EC, the specific priorities which allow the Member States not covered by the Cohesion Fund to have the co-financing of the Community contribution increased to 75 % for projects co-financed by the Fund.\n(3) In accordance with Article 2 of the Protocol on the position of Denmark, annexed to the Treaty on European Union and to the Treaty establishing the European Community, Denmark is not bound by this Decision or subject to its application.\n(4) In accordance with Article 3 of the Protocol on the position of the United Kingdom and Ireland, annexed to the Treaty on European Union and to the Treaty establishing the European Community, Ireland has notified, by letter of 6 September 2005, its wish to take part in the adoption and application of Decision No 573/2007/EC.\n(5) In accordance with Article 3 of the Protocol on the position of the United Kingdom and Ireland, annexed to the Treaty on European Union and to the Treaty establishing the European Community, the United Kingdom has notified, by letter of 27 October 2005, its wish to take part in the adoption and application of Decision No 573/2007/EC.\n(6) The measures provided for in this Decision are in accordance with the opinion of the common Committee ‘Solidarity and Management of Migration Flows’ established by Article 56 of Decision No 574/2007/EC of the European Parliament and of the Council establishing the External Borders Fund for the period 2007 to 2013 as part of the General programme ‘Solidarity and Management of Migration Flows’ (2),\nThe guidelines setting out the priorities and specific priorities for the multi-annual programming for the period 2008 to 2013 shall be as defined in the Annex. This Decision is addressed to the Kingdom of Belgium, the Republic of Bulgaria, the Czech Republic, the Federal Republic of Germany, the Republic of Estonia, the Hellenic Republic, the Kingdom of Spain, the French Republic, Ireland, the Italian Republic, the Republic of Cyprus, the Republic of Latvia, the Republic of Lithuania, the Grand-Duchy of Luxembourg, the Republic of Hungary, the Republic of Malta, the Kingdom of the Netherlands, the Republic of Austria, the Republic of Poland, the Portuguese Republic, Romania, the Republic of Slovenia, the Slovak Republic, the Republic of Finland, the Kingdom of Sweden, the United Kingdom of Great Britain and Northern Ireland.",
         "3297",
         "Decision",
         "Decision"
        ],
        [
         "42",
         "31997D0204",
         "Decision",
         "97/204/EC: Council Decision of 17 March 1997 authorizing the Kingdom of Spain to apply a measure derogating from Article 9 of the Sixth Directive 77/388/EEC on the harmonization of the laws of the Member States relating to turnover taxes\n",
         "COUNCIL DECISION of 17 March 1997 authorizing the Kingdom of Spain to apply a measure derogating from Article 9 of the Sixth Directive 77/388/EEC on the harmonization of the laws of the Member States relating to turnover taxes (97/204/EC)\nTHE COUNCIL OF THE EUROPEAN UNION",
         ",\nHaving regard to the Treaty establishing the European Community,\nHaving regard to the Sixth Council Directive 77/388/EEC of 17 May 1977 on the harmonization of the laws of the Member States relating to turnover taxes - Common system of value added tax: uniform basis of assessment (1), and in particular Article 27 thereof,\nHaving regard to the proposal from the Commission,\nWhereas, pursuant to Article 27 (1) of Directive 77/388/EEC, the Council, acting unanimously on a proposal from the Commission, may authorize any Member State to introduce special measures for derogation from that Directive in order to simplify the procedure for charging the tax or to prevent certain types of tax evasion or avoidance;\nWhereas, by letter to the Commission registered on 6 December 1996, the Kingdom of Spain requested authorization to introduce a measure derogating from Article 9 of Directive 77/388/EEC;\nWhereas the other Member States were informed on 20 December 1996 of the request made by the Kingdom of Spain;\nWhereas the measure is necessary to counter the tax avoidance effects that have led a growing number of Community taxable and non-taxable persons to purchase telecommunications services outside the Community in order to avoid payment of VAT; whereas the measure is furthermore necessary to discourage suppliers of telecommunications services established in a Member State from establishing themselves outside the Community;\nWhereas the measure is also necessary to simplify the procedure for charging the tax insofar as it provides the same tax obligations for customers of telecommunications services regardless of whether these services are performed by suppliers established inside or outside the Community;\nWhereas the derogations will not affect, except to a negligible extent, the amount of tax due at the final consumption stage and will not therefore have an adverse effect on the European Communities' own resources arising from value-added tax;\nWhereas it is necessary to grant this measure from 1 January 1997 in order to remedy as quickly as possible a situation undermining the competitiveness of European telecommunications companies; whereas from 1 January 1997 the customers and the suppliers of telecommunications services had no longer a legitimate confidence in the continuation of the legislation in force at that date;\nWhereas it is desirable that the derogation should be granted until 31 December 1999, or, if a Directive altering the place of taxation of telecommunications services enters into force at an earlier date, until that date, in order to allow the Council to adopt a general Community solution based on the Commission proposal,",
         "['By way of derogation from Article 9 (1) of Directive 77/388/EEC, the Kingdom of Spain is authorized to include, within Article 9 (2) (e) of the Directive, telecommunications services. In the case of a Member State making use of this facility, the provisions of Article 9 (3) (b) of the Directive shall also apply to these services.\\nTelecommunications services shall be deemed to be services relating to the transmission, emission or reception of signals, writing, images and sounds or information of any nature by wire, radio, optical or other electromagnetic systems, including the transfer or assignment of the right to use capacity for such transmission, emission or reception.', 'This Decision may be applied to telecommunications services in respect of which the chargeable event took place from 1 January 1997. It will also apply to prepayments made in respect of telecommunications services paid for before the date of implementation of this Decision by the Member State insofar as these prepayments cover supplies of telecommunications services which are performed after the date of implementation.', 'The authorization specified in this Decision shall apply until 31 December 1999, or, if a Directive altering the place of taxation of telecommunications services enters into force at an earlier date, until that date.', 'This Decision is addressed to the Kingdom of Spain.']",
         "['2897', '3017', '4424', '4585', '5581', '863']",
         "train",
         "97/204/EC: Council Decision of 17 March 1997 authorizing the Kingdom of Spain to apply a measure derogating from Article 9 of the Sixth Directive 77/388/EEC on the harmonization of the laws of the Member States relating to turnover taxes\n\n,\nHaving regard to the Treaty establishing the European Community,\nHaving regard to the Sixth Council Directive 77/388/EEC of 17 May 1977 on the harmonization of the laws of the Member States relating to turnover taxes - Common system of value added tax: uniform basis of assessment (1), and in particular Article 27 thereof,\nHaving regard to the proposal from the Commission,\nWhereas, pursuant to Article 27 (1) of Directive 77/388/EEC, the Council, acting unanimously on a proposal from the Commission, may authorize any Member State to introduce special measures for derogation from that Directive in order to simplify the procedure for charging the tax or to prevent certain types of tax evasion or avoidance;\nWhereas, by letter to the Commission registered on 6 December 1996, the Kingdom of Spain requested authorization to introduce a measure derogating from Article 9 of Directive 77/388/EEC;\nWhereas the other Member States were informed on 20 December 1996 of the request made by the Kingdom of Spain;\nWhereas the measure is necessary to counter the tax avoidance effects that have led a growing number of Community taxable and non-taxable persons to purchase telecommunications services outside the Community in order to avoid payment of VAT; whereas the measure is furthermore necessary to discourage suppliers of telecommunications services established in a Member State from establishing themselves outside the Community;\nWhereas the measure is also necessary to simplify the procedure for charging the tax insofar as it provides the same tax obligations for customers of telecommunications services regardless of whether these services are performed by suppliers established inside or outside the Community;\nWhereas the derogations will not affect, except to a negligible extent, the amount of tax due at the final consumption stage and will not therefore have an adverse effect on the European Communities' own resources arising from value-added tax;\nWhereas it is necessary to grant this measure from 1 January 1997 in order to remedy as quickly as possible a situation undermining the competitiveness of European telecommunications companies; whereas from 1 January 1997 the customers and the suppliers of telecommunications services had no longer a legitimate confidence in the continuation of the legislation in force at that date;\nWhereas it is desirable that the derogation should be granted until 31 December 1999, or, if a Directive altering the place of taxation of telecommunications services enters into force at an earlier date, until that date, in order to allow the Council to adopt a general Community solution based on the Commission proposal,\nBy way of derogation from Article 9 (1) of Directive 77/388/EEC, the Kingdom of Spain is authorized to include, within Article 9 (2) (e) of the Directive, telecommunications services. In the case of a Member State making use of this facility, the provisions of Article 9 (3) (b) of the Directive shall also apply to these services.\nTelecommunications services shall be deemed to be services relating to the transmission, emission or reception of signals, writing, images and sounds or information of any nature by wire, radio, optical or other electromagnetic systems, including the transfer or assignment of the right to use capacity for such transmission, emission or reception. This Decision may be applied to telecommunications services in respect of which the chargeable event took place from 1 January 1997. It will also apply to prepayments made in respect of telecommunications services paid for before the date of implementation of this Decision by the Member State insofar as these prepayments cover supplies of telecommunications services which are performed after the date of implementation. The authorization specified in this Decision shall apply until 31 December 1999, or, if a Directive altering the place of taxation of telecommunications services enters into force at an earlier date, until that date. This Decision is addressed to the Kingdom of Spain.",
         "4287",
         "Decision",
         "Decision"
        ],
        [
         "43",
         "32001D0736",
         "Decision",
         "2001/736/EC: Commission Decision of 17 October 2001 amending Decision 1999/283/EC laying down the animal health conditions and veterinary certification for imports of fresh meat from certain African countries and amending Decision 2000/585/EC laying down animal health conditions and veterinary certification for imports of wild and farmed game meat and rabbit meat from third countries, as regards Zimbabwe (Text with EEA relevance) (notified under document number C(2001) 3109)\n",
         "Commission Decision\nof 17 October 2001\namending Decision 1999/283/EC laying down the animal health conditions and veterinary certification for imports of fresh meat from certain African countries and amending Decision 2000/585/EC laying down animal health conditions and veterinary certification for imports of wild and farmed game meat and rabbit meat from third countries, as regards Zimbabwe\n(notified under document number C(2001) 3109)\n(Text with EEA relevance)\n(2001/736/EC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Directive 72/462/EEC of 12 December 1972 on health and veterinary inspection problems upon importation of bovine, ovine and caprine animals and swine, fresh meat or meat products from third countries(1), as last amended by Regulation (EC) No 1452/2001(2), and in particular Article 14(3) thereof,\nHaving regard to Council Directive 92/45/EEC of 16 June 1992 concerning public health and animal health problems relating to the killing of wild game and the placing on the market of wild game meat(3), as last amended by Directive 97/79/EC(4), and in particular Article 16(3) thereof,\nHaving regard to Council Directive 92/118/EEC of 17 December 1992 laying down animal health and public health requirements governing trade in and imports into the Community of products not subject to the said requirements laid down in specific Community rules referred to in Annex A(I) to Directive 89/662/EEC and, as regards pathogens, to Directive 90/425/EEC(5), as last amended by Commission Decision 1999/724/EC(6), and in particular Article 10(3) thereof,\nWhereas:\n(1) The animal health conditions and veterinary certificates for imports of fresh meat from certain Africain countries are laid down by Commission Decision 1999/283/EC(7), as last amended by Decision 2001/601/EC(8).\n(2) The animal health conditions and veterinary certificates for imports of game meat are laid down by Commission Decision 2000/585/EC(9), as last amended by Decision 2001/640/EC(10).\n(3) An outbreak of foot-and-mouth disease has been reported in the EC approved free area in Zimbabwe on 17 August 2001.\n(4) Until such time as it can be guaranteed that the veterinary situation is fully under control and in order to safeguard the animal health situation of the Community, it is necessary, to suspend the approval of imports into the Community of fresh meat including game meat from Zimbabwe.\n(5) Member States shall authorise imports from Zimbabwe of de-boned fresh meat, excluding game meat, produced before 17 August 2001 and certified in accordance with the conditions laid down in Decision 1999/283/EC.\n(6) Decisions 1999/283/EC and 2000/585/EC must be amended accordingly.\n(7) The measures provided for in this Decision are in accordance with the opinion of the Standing Veterinary Committee,",
         "['1. Annex II to Decision 1999/283/EC is replaced by Annex I to this Decision.\\n2. Annex II to Decision 2000/585/EC is replaced by Annex II to this Decision.', 'This Decision shall apply from 11 September 2001.', 'This Decision is addressed to the Member States.']",
         "['1309', '2954', '2955', '4692', '4782', '5369']",
         "train",
         "2001/736/EC: Commission Decision of 17 October 2001 amending Decision 1999/283/EC laying down the animal health conditions and veterinary certification for imports of fresh meat from certain African countries and amending Decision 2000/585/EC laying down animal health conditions and veterinary certification for imports of wild and farmed game meat and rabbit meat from third countries, as regards Zimbabwe (Text with EEA relevance) (notified under document number C(2001) 3109)\n\n,\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Directive 72/462/EEC of 12 December 1972 on health and veterinary inspection problems upon importation of bovine, ovine and caprine animals and swine, fresh meat or meat products from third countries(1), as last amended by Regulation (EC) No 1452/2001(2), and in particular Article 14(3) thereof,\nHaving regard to Council Directive 92/45/EEC of 16 June 1992 concerning public health and animal health problems relating to the killing of wild game and the placing on the market of wild game meat(3), as last amended by Directive 97/79/EC(4), and in particular Article 16(3) thereof,\nHaving regard to Council Directive 92/118/EEC of 17 December 1992 laying down animal health and public health requirements governing trade in and imports into the Community of products not subject to the said requirements laid down in specific Community rules referred to in Annex A(I) to Directive 89/662/EEC and, as regards pathogens, to Directive 90/425/EEC(5), as last amended by Commission Decision 1999/724/EC(6), and in particular Article 10(3) thereof,\nWhereas:\n(1) The animal health conditions and veterinary certificates for imports of fresh meat from certain Africain countries are laid down by Commission Decision 1999/283/EC(7), as last amended by Decision 2001/601/EC(8).\n(2) The animal health conditions and veterinary certificates for imports of game meat are laid down by Commission Decision 2000/585/EC(9), as last amended by Decision 2001/640/EC(10).\n(3) An outbreak of foot-and-mouth disease has been reported in the EC approved free area in Zimbabwe on 17 August 2001.\n(4) Until such time as it can be guaranteed that the veterinary situation is fully under control and in order to safeguard the animal health situation of the Community, it is necessary, to suspend the approval of imports into the Community of fresh meat including game meat from Zimbabwe.\n(5) Member States shall authorise imports from Zimbabwe of de-boned fresh meat, excluding game meat, produced before 17 August 2001 and certified in accordance with the conditions laid down in Decision 1999/283/EC.\n(6) Decisions 1999/283/EC and 2000/585/EC must be amended accordingly.\n(7) The measures provided for in this Decision are in accordance with the opinion of the Standing Veterinary Committee,\n1. Annex II to Decision 1999/283/EC is replaced by Annex I to this Decision.\n2. Annex II to Decision 2000/585/EC is replaced by Annex II to this Decision. This Decision shall apply from 11 September 2001. This Decision is addressed to the Member States.",
         "3093",
         "Decision",
         "Decision"
        ],
        [
         "44",
         "31992D0520",
         "Decision",
         "92/520/EEC: Commission Decision of 3 November 1992 amending Decision 89/374/EEC of 2 June 1989 on the organization of a temporary experiment under Council Directive 66/402/EEC on the marketing of cereal seed, in order to establish the conditions to be satisfied by the crop and the seed of hybrids of rye\n",
         "COMMISSION DECISION\nof 3 November 1992\namending  Decision 89/374/EEC of 2 June 1989 on the organization of a temporary experiment under Council  Directive 66/402/EEC on the marketing of cereal seed, in order to establish the conditions to be  satisfied by the crop and the seed of hybrids of rye\n(92/520/EEC)\nTHE COMMISSION  OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Directive 66/402/EEC of 14 June 1966 on the marketing of cereal seed  (1),  as last amended by Directive 90/654/EEC  (2), and in particular Article 13a thereof,\nWhereas pursuant to Commission Decision 89/374/EEC  (3) a temporary experiment was organized, at  Community level, in order to establish the conditions to be satisfied by the crop and the seed of  hybrids of rye; whereas according to the abovementioned Decision the experiment should end on 30  June 1992; whereas further data are needed; whereas it is therefore appropriate to extend the  experiment until 30 June 1994;\nWhereas the measures provided for in this Decision are in accordance with the opinion of the  Standing Committee on Seeds and Propagating Material for Agriculture, Horticulture and Forestry,",
         "[\"In Article 3 of Decision 89/374/EEC, '30  June 1992` is replaced by '30 June 1994`.\", 'This Decision is addressed to the Member  States.']",
         "['2081', '2915', '3409', '4059', '4081', '5360']",
         "train",
         "92/520/EEC: Commission Decision of 3 November 1992 amending Decision 89/374/EEC of 2 June 1989 on the organization of a temporary experiment under Council Directive 66/402/EEC on the marketing of cereal seed, in order to establish the conditions to be satisfied by the crop and the seed of hybrids of rye\n\n,\nHaving regard to the Treaty establishing the European Economic Community,\nHaving regard to Council Directive 66/402/EEC of 14 June 1966 on the marketing of cereal seed  (1),  as last amended by Directive 90/654/EEC  (2), and in particular Article 13a thereof,\nWhereas pursuant to Commission Decision 89/374/EEC  (3) a temporary experiment was organized, at  Community level, in order to establish the conditions to be satisfied by the crop and the seed of  hybrids of rye; whereas according to the abovementioned Decision the experiment should end on 30  June 1992; whereas further data are needed; whereas it is therefore appropriate to extend the  experiment until 30 June 1994;\nWhereas the measures provided for in this Decision are in accordance with the opinion of the  Standing Committee on Seeds and Propagating Material for Agriculture, Horticulture and Forestry,\nIn Article 3 of Decision 89/374/EEC, '30  June 1992` is replaced by '30 June 1994`. This Decision is addressed to the Member  States.",
         "1313",
         "Decision",
         "Decision"
        ],
        [
         "45",
         "31994D0122",
         "Decision",
         "Commission Decision of 28 February 1994 amending for the second time Decision 93/602/EC concerning certain protection measures relating to African swine fever in Portugal\n",
         "COMMISSION DECISION of 28 February 1994 amending for the second time Decision 93/602/EC concerning certain protection measures relating to African swine fever in Portugal (94/122/EC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Directive 90/425/EEC of 26 June 1990 concerning veterinary and zootechnical checks applicable in intra-Community trade in certain live animals and products with a view to the completion of the internal market (1), as last  amended by Directive 92/118/EEC (2), and in particular Article 10 (4) thereof,\nHaving regard to Council Directive 89/662/EEC of 11 December 1989 concerning veterinary checks in intra-Community trade with a view to the completion of the internal market (3), as last amended by Directive 92/118/EEC, and in particular Article 9 (4)  thereof,\nWhereas as a result of outbreaks of African swine fever in the Alentejo region of Portugal, the Commission adopted Decision 93/602/EC of 19 November 1993 concerning certain protection measures relating to African swine fever in Portugal (4), as amended  by Decision 94/35/EC (5);\nWhereas the occurrence of African swine fever is liable to present a serious threat to the herds of other Member States in view of the trade in live pigs, fresh pigmeat and certain meat-based products;\nWhereas information provided by Portugal on the African swine fever situation makes it possible to reduce the protection measures established by Decision 93/602/EC;\nWhereas in the light of the new situation it is necessary to adjust the measures adopted by Decision 93/602/EC;\nWhereas the measures provided for in this Decision are in accordance with the opinion of the Standing Veterinary Committee,",
         "[\"Decision 93/602/EC is hereby amended as follows:\\n1. In Article 3, paragraphs 1, 2 and 3, '94/35/EC' is replaced by '94/122/EC'.\\n2. In Article 4, paragraph 3 is replaced by the following:\\n'3. In derogation to the provisions of paragraph 1, pigs for breeding and production may be sent from holdings situated in the area described in Annex I to a designated holding situated outside this area on the following conditions:\\n- the pigs have remained on the holding of origin for at least 30 days prior to consignment and no other pigs have been introduced during the same period,\\n- all pigs to be consigned have been subjected to an individual serological test for African swine fever with negative results within 10 days prio to consignment, or\\nthe herd has been sampled in accordance with the provisions of Annex II within 14 days prior to consignment,\\n- all the pigs to be consigned have been identified with an eartag or tattoo prior to sampling,\\n- all pigs in the holding of origin are subjected to a clinical examination by an authorized veterinarian within 24 hours prior to consignment,\\n- the pigs shall be transported in a sealed means of transport from the holding of origin to the designated holding situated in Portugal; the means of transport utilized shall be cleaned and disinfected before and after each journey,\\n- the pigs must be accompanied during transport to the holding of destination by a health document (Guia Sanitária de Trânsito de Suínos) issued by an official veterinarian,\\n- upon arrival at the holding of destination, all the pigs on the holding must remain at the said holding for at least 60 days. The holding shall be kept under the supervision of an official veterinarian and pigs kept on the holding cannot enter into  intra-Community trade.'\", 'Member States shall amend the measures which they apply to trade so as to bring them into compliance with this Decision. They shall immediately inform the Commission thereof.', 'This Decision is addressed to the Member States.']",
         "['2356', '2560', '2563', '5369', '619']",
         "train",
         "Commission Decision of 28 February 1994 amending for the second time Decision 93/602/EC concerning certain protection measures relating to African swine fever in Portugal\n\n,\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Directive 90/425/EEC of 26 June 1990 concerning veterinary and zootechnical checks applicable in intra-Community trade in certain live animals and products with a view to the completion of the internal market (1), as last  amended by Directive 92/118/EEC (2), and in particular Article 10 (4) thereof,\nHaving regard to Council Directive 89/662/EEC of 11 December 1989 concerning veterinary checks in intra-Community trade with a view to the completion of the internal market (3), as last amended by Directive 92/118/EEC, and in particular Article 9 (4)  thereof,\nWhereas as a result of outbreaks of African swine fever in the Alentejo region of Portugal, the Commission adopted Decision 93/602/EC of 19 November 1993 concerning certain protection measures relating to African swine fever in Portugal (4), as amended  by Decision 94/35/EC (5);\nWhereas the occurrence of African swine fever is liable to present a serious threat to the herds of other Member States in view of the trade in live pigs, fresh pigmeat and certain meat-based products;\nWhereas information provided by Portugal on the African swine fever situation makes it possible to reduce the protection measures established by Decision 93/602/EC;\nWhereas in the light of the new situation it is necessary to adjust the measures adopted by Decision 93/602/EC;\nWhereas the measures provided for in this Decision are in accordance with the opinion of the Standing Veterinary Committee,\nDecision 93/602/EC is hereby amended as follows:\n1. In Article 3, paragraphs 1, 2 and 3, '94/35/EC' is replaced by '94/122/EC'.\n2. In Article 4, paragraph 3 is replaced by the following:\n'3. In derogation to the provisions of paragraph 1, pigs for breeding and production may be sent from holdings situated in the area described in Annex I to a designated holding situated outside this area on the following conditions:\n- the pigs have remained on the holding of origin for at least 30 days prior to consignment and no other pigs have been introduced during the same period,\n- all pigs to be consigned have been subjected to an individual serological test for African swine fever with negative results within 10 days prio to consignment, or\nthe herd has been sampled in accordance with the provisions of Annex II within 14 days prior to consignment,\n- all the pigs to be consigned have been identified with an eartag or tattoo prior to sampling,\n- all pigs in the holding of origin are subjected to a clinical examination by an authorized veterinarian within 24 hours prior to consignment,\n- the pigs shall be transported in a sealed means of transport from the holding of origin to the designated holding situated in Portugal; the means of transport utilized shall be cleaned and disinfected before and after each journey,\n- the pigs must be accompanied during transport to the holding of destination by a health document (Guia Sanitária de Trânsito de Suínos) issued by an official veterinarian,\n- upon arrival at the holding of destination, all the pigs on the holding must remain at the said holding for at least 60 days. The holding shall be kept under the supervision of an official veterinarian and pigs kept on the holding cannot enter into  intra-Community trade.' Member States shall amend the measures which they apply to trade so as to bring them into compliance with this Decision. They shall immediately inform the Commission thereof. This Decision is addressed to the Member States.",
         "3707",
         "Decision",
         "Decision"
        ],
        [
         "46",
         "32000D0817",
         "Decision",
         "2000/817/EC: Commission Decision of 27 December 2000 concerning the non-inclusion of permethrin in Annex I to Council Directive 91/414/EEC and the withdrawal of authorisations for plant protection products containing this active substance (notified under document number C(2000) 4140) (Text with EEA relevance)\n",
         "Commission Decision\nof 27 December 2000\nconcerning the non-inclusion of permethrin in Annex I to Council Directive 91/414/EEC and the withdrawal of authorisations for plant protection products containing this active substance\n(notified under document number C(2000) 4140)\n(Text with EEA relevance)\n(2000/817/EC)\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES",
         ",\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Directive 91/414/EEC of 15 July 1991 concerning the placing of plant-protection products on the market(1), as last amended by Commission Directive 2000/68/EC(2), and in particular the fourth subparagraph of Article 8(2) thereof,\nHaving regard to Commission Regulation (EEC) No 3600/92 of 11 December 1992 laying down the detailed rules for the implementation of the first stage of the programme of work referred to in Article 8(2) of Council Directive 91/414/EEC concerning the placing of plant protection products on the market(3), as last amended by Commission Regulation (EC) No 2266/2000(4) and in particular Article 7(3a)b) thereof,\nWhereas:\n(1) Article 8(2) of Directive 91/414/EEC provided for the Commission to carry out a programme of work for the examination of the active substances used in plant-protection products which were already on the market on 15 July 1993. Detailed rules for the carrying out of this programme were established in Commission Regulation (EEC) No 3600/92.\n(2) Commission Regulation (EC) No 933/94(5) of 27 April 1994, as last amended by Regulation (EC) No 2230/95(6) has designated the active substances which should be assessed in the framework of Regulation (EEC) No 3600/92, designated a Member State to act as rapporteur in respect of the assessment of each substance and identified the producers of each active substance who submitted a notification in due time in accordance with Article 4(2) of Regulation (EEC) No 3600/92.\n(3) Permethrin is one of the 90 active substances designated in Regulation (EC) No 933/94.\n(4) In accordance with Article 7(1)(c) of Regulation (EEC) No 3600/92, Ireland, being the designated rapporteur Member State, submitted on 10 June 1998 to the Commission the report of its assessment of the information submitted by the notifiers in accordance with the provisions of Article 6(1) of this Regulation.\n(5) The assessment report prepared by Ireland was reviewed by the Member States and the Commission within the Standing Committee on Plant Health. This review was finalised on 13 July 2000 in the format of the Commission review report for permethin, in accordance with Article 7(6) of Regulation (EEC) No 3600/92.\n(6) It has appeared from the assessments made that the submitted information is not sufficient to demonstrate that, under the proposed conditions of use, plant-protection products containing the active substance concerned satisfy the requirements laid down in Articles 5(1)(a) and (b) and 5(2)(b) of Directive 91/414/EEC.\n(7) All notifiers informed the Commission and the rapporteur Member State that they no longer wished to participate in the programme of work for this active substance. Therefore, the further information which would be required to demonstrate that permethrin fully complies with the requirements of Directive 91/414/EEC will not be submitted.\n(8) Therefore, it is not possible to include this active substance in Annex I to Directive 91/414/EEC.\n(9) Technical evidence has been provided indicating that limited further use of permethrin in forestry could be allowed whilst research is ongoing in order to find efficient alternatives providing that appropriate risk mitigation measures are taken.\n(10) Any period of grace for disposal, storage, placing on the market and use of existing stocks of plant-protection products containing permethrin allowed by Member States, in accordance with the provisions of Article 4(6) of Directive 91/414/EEC should be limited to a period no longer than 18 months to allow existing stocks to be used in no more than one further growing season.\n(11) This Decision does not prejudice any action the Commission may undertake at a later stage for this active substance within the framework of Council Directive 79/117/EEC(7).\n(12) The measures provided for in this Decision are in accordance with the opinion of the Standing Committee on Plant Health,",
         "['Permethrin is not included as an active substance in Annex I to Directive 91/414/EEC.', 'The Member States shall ensure:\\n1. that authorisations for all uses of plant-protection products containing permethrin are withdrawn within a period of six months from the date of adoption of the present Decision except for the uses referred to in paragraph 2;\\n2. that the authorisations for uses of plant-protection products containing permethrin in young plants for forestry are withdrawn not later than on 25 July 2003;\\n3. that from the date of the present Decision no authorisations for plant-protection products containing permethrin will be granted or renewed under the derogation provided for in Article 8(2) of Directive 91/414/EEC, except for the uses referred to in paragraph 2.', 'Any period of grace granted by a Member State in accordance with the provisions of Article 4(6) of Directive 91/414/EEC, shall be as short as possible and not longer than 18 months from the date of adoption of the present Decision. For the uses referred to in Article 2(2) the period of grace shall expire not later than on 31 December 2003.', 'This Decision is addressed to the Member States.']",
         "['13', '2081', '2773', '2985', '3618', '4308']",
         "train",
         "2000/817/EC: Commission Decision of 27 December 2000 concerning the non-inclusion of permethrin in Annex I to Council Directive 91/414/EEC and the withdrawal of authorisations for plant protection products containing this active substance (notified under document number C(2000) 4140) (Text with EEA relevance)\n\n,\nHaving regard to the Treaty establishing the European Community,\nHaving regard to Council Directive 91/414/EEC of 15 July 1991 concerning the placing of plant-protection products on the market(1), as last amended by Commission Directive 2000/68/EC(2), and in particular the fourth subparagraph of Article 8(2) thereof,\nHaving regard to Commission Regulation (EEC) No 3600/92 of 11 December 1992 laying down the detailed rules for the implementation of the first stage of the programme of work referred to in Article 8(2) of Council Directive 91/414/EEC concerning the placing of plant protection products on the market(3), as last amended by Commission Regulation (EC) No 2266/2000(4) and in particular Article 7(3a)b) thereof,\nWhereas:\n(1) Article 8(2) of Directive 91/414/EEC provided for the Commission to carry out a programme of work for the examination of the active substances used in plant-protection products which were already on the market on 15 July 1993. Detailed rules for the carrying out of this programme were established in Commission Regulation (EEC) No 3600/92.\n(2) Commission Regulation (EC) No 933/94(5) of 27 April 1994, as last amended by Regulation (EC) No 2230/95(6) has designated the active substances which should be assessed in the framework of Regulation (EEC) No 3600/92, designated a Member State to act as rapporteur in respect of the assessment of each substance and identified the producers of each active substance who submitted a notification in due time in accordance with Article 4(2) of Regulation (EEC) No 3600/92.\n(3) Permethrin is one of the 90 active substances designated in Regulation (EC) No 933/94.\n(4) In accordance with Article 7(1)(c) of Regulation (EEC) No 3600/92, Ireland, being the designated rapporteur Member State, submitted on 10 June 1998 to the Commission the report of its assessment of the information submitted by the notifiers in accordance with the provisions of Article 6(1) of this Regulation.\n(5) The assessment report prepared by Ireland was reviewed by the Member States and the Commission within the Standing Committee on Plant Health. This review was finalised on 13 July 2000 in the format of the Commission review report for permethin, in accordance with Article 7(6) of Regulation (EEC) No 3600/92.\n(6) It has appeared from the assessments made that the submitted information is not sufficient to demonstrate that, under the proposed conditions of use, plant-protection products containing the active substance concerned satisfy the requirements laid down in Articles 5(1)(a) and (b) and 5(2)(b) of Directive 91/414/EEC.\n(7) All notifiers informed the Commission and the rapporteur Member State that they no longer wished to participate in the programme of work for this active substance. Therefore, the further information which would be required to demonstrate that permethrin fully complies with the requirements of Directive 91/414/EEC will not be submitted.\n(8) Therefore, it is not possible to include this active substance in Annex I to Directive 91/414/EEC.\n(9) Technical evidence has been provided indicating that limited further use of permethrin in forestry could be allowed whilst research is ongoing in order to find efficient alternatives providing that appropriate risk mitigation measures are taken.\n(10) Any period of grace for disposal, storage, placing on the market and use of existing stocks of plant-protection products containing permethrin allowed by Member States, in accordance with the provisions of Article 4(6) of Directive 91/414/EEC should be limited to a period no longer than 18 months to allow existing stocks to be used in no more than one further growing season.\n(11) This Decision does not prejudice any action the Commission may undertake at a later stage for this active substance within the framework of Council Directive 79/117/EEC(7).\n(12) The measures provided for in this Decision are in accordance with the opinion of the Standing Committee on Plant Health,\nPermethrin is not included as an active substance in Annex I to Directive 91/414/EEC. The Member States shall ensure:\n1. that authorisations for all uses of plant-protection products containing permethrin are withdrawn within a period of six months from the date of adoption of the present Decision except for the uses referred to in paragraph 2;\n2. that the authorisations for uses of plant-protection products containing permethrin in young plants for forestry are withdrawn not later than on 25 July 2003;\n3. that from the date of the present Decision no authorisations for plant-protection products containing permethrin will be granted or renewed under the derogation provided for in Article 8(2) of Directive 91/414/EEC, except for the uses referred to in paragraph 2. Any period of grace granted by a Member State in accordance with the provisions of Article 4(6) of Directive 91/414/EEC, shall be as short as possible and not longer than 18 months from the date of adoption of the present Decision. For the uses referred to in Article 2(2) the period of grace shall expire not later than on 31 December 2003. This Decision is addressed to the Member States.",
         "5459",
         "Decision",
         "Decision"
        ],
        [
         "47",
         "32012D0250",
         "Decision",
         "2012/250/EU: Commission Implementing Decision of 8 May 2012 amending Decision 2008/855/EC as regards animal health control measures relating to classical swine fever in Germany (notified under document C(2012) 2992)  Text with EEA relevance\n",
         "11.5.2012 EN Official Journal of the European Union L 124/39\nCOMMISSION IMPLEMENTING DECISION\nof 8 May 2012\namending Decision 2008/855/EC as regards animal health control measures relating to classical swine fever in Germany\n(notified under document C(2012) 2992)\n(Text with EEA relevance)\n(2012/250/EU)\nTHE EUROPEAN COMMISSION",
         ",\nHaving regard to the Treaty on the Functioning of the European Union,\nHaving regard to Council Directive 89/662/EEC of 11 December 1989 concerning veterinary checks in intra-Community trade with a view to the completion of the internal market (1), and in particular Article 9(4) thereof,\nHaving regard to Council Directive 90/425/EEC of 26 June 1990 concerning veterinary and zootechnical checks applicable in intra-Community trade in certain live animals and products with a view to the completion of the internal market (2), and in particular Article 10(4) thereof,\nWhereas:\n(1) Commission Decision 2008/855/EC of 3 November 2008 concerning animal health control measures relating to classical swine fever in certain Member States (3) lays down certain control measures in relation to classical swine fever in the Member States or regions thereof listed in the Annex thereto. That list includes parts of the territory of the federal States Rhineland-Palatinate and North Rhine-Westfalia in Germany.\n(2) Germany has informed the Commission about recent developments with regard to classical swine fever in feral pigs in the regions of the federal States Rhineland-Palatinate and North Rhine-Westfalia listed in the Annex to Decision 2008/855/EC.\n(3) That information indicates that classical swine fever in feral pigs has been eradicated in the federal States Rhineland-Palatinate and North Rhine-Westfalia. Accordingly, the measures provided for in Decision 2008/855/EC should no longer apply to those regions and the entry for Germany in the list set out in Part I of the Annex thereto should be deleted.\n(4) Decision 2008/855/EC should therefore be amended accordingly.\n(5) The measures provided for in this Decision are in accordance with the opinion of the Standing Committee on the Food Chain and Animal Health,",
         "['In the Annex to Decision 2008/855/EC, point 1 of Part I is deleted.', 'This Decision is addressed to the Member States.']",
         "['1318', '1445', '2356', '2560', '3711', '3713', '5722']",
         "train",
         "2012/250/EU: Commission Implementing Decision of 8 May 2012 amending Decision 2008/855/EC as regards animal health control measures relating to classical swine fever in Germany (notified under document C(2012) 2992)  Text with EEA relevance\n\n,\nHaving regard to the Treaty on the Functioning of the European Union,\nHaving regard to Council Directive 89/662/EEC of 11 December 1989 concerning veterinary checks in intra-Community trade with a view to the completion of the internal market (1), and in particular Article 9(4) thereof,\nHaving regard to Council Directive 90/425/EEC of 26 June 1990 concerning veterinary and zootechnical checks applicable in intra-Community trade in certain live animals and products with a view to the completion of the internal market (2), and in particular Article 10(4) thereof,\nWhereas:\n(1) Commission Decision 2008/855/EC of 3 November 2008 concerning animal health control measures relating to classical swine fever in certain Member States (3) lays down certain control measures in relation to classical swine fever in the Member States or regions thereof listed in the Annex thereto. That list includes parts of the territory of the federal States Rhineland-Palatinate and North Rhine-Westfalia in Germany.\n(2) Germany has informed the Commission about recent developments with regard to classical swine fever in feral pigs in the regions of the federal States Rhineland-Palatinate and North Rhine-Westfalia listed in the Annex to Decision 2008/855/EC.\n(3) That information indicates that classical swine fever in feral pigs has been eradicated in the federal States Rhineland-Palatinate and North Rhine-Westfalia. Accordingly, the measures provided for in Decision 2008/855/EC should no longer apply to those regions and the entry for Germany in the list set out in Part I of the Annex thereto should be deleted.\n(4) Decision 2008/855/EC should therefore be amended accordingly.\n(5) The measures provided for in this Decision are in accordance with the opinion of the Standing Committee on the Food Chain and Animal Health,\nIn the Annex to Decision 2008/855/EC, point 1 of Part I is deleted. This Decision is addressed to the Member States.",
         "2179",
         "Decision",
         "Decision"
        ],
        [
         "48",
         "32013D0475",
         "Decision",
         "2013/475/EU: Council Decision of 23 September 2013 on the position to be taken on behalf of the European Union within the Bilateral Oversight Board under the Agreement between the United States of America and the European Community on cooperation in the regulation of civil aviation safety, concerning Decision No 0004 amending Annex 1 to the Agreement\n",
         "28.9.2013 EN Official Journal of the European Union L 257/2\nCOUNCIL DECISION\nof 23 September 2013\non the position to be taken on behalf of the European Union within the Bilateral Oversight Board under the Agreement between the United States of America and the European Community on cooperation in the regulation of civil aviation safety, concerning Decision No 0004 amending Annex 1 to the Agreement\n(2013/475/EU)\nTHE COUNCIL OF THE EUROPEAN UNION",
         ",\nHaving regard to the Treaty on the Functioning of the European Union, and in particular Article 100(2) in conjunction with Article 218(9) thereof,\nHaving regard to the proposal from the European Commission,\nWhereas:\n(1) Council Decision 2011/719/EU of 7 March 2011 concerning the conclusion of the Agreement between the United States of America and the European Community on cooperation in the regulation of civil aviation safety (1) entered into force on 1 May 2011.\n(2) Pursuant to Article 3.C.2 of the Agreement between the United States of America and the European Community on cooperation in the regulation of civil aviation safety (2) (‘the Agreement’), the Bilateral Oversight Board established by Article 3.A of the Agreement may amend the annexes to the Agreement in accordance with Article 19.B thereof.\n(3) It is appropriate to establish the position to be be adopted on the Union’s behalf within the Bilateral Oversight Board in accordance with Article 4(4) of Decision 2011/719/EU with regard to Decision No 0004 of the Bilateral Oversight Board amending Annex 1 to the Agreement,",
         "['The position to be adopted on behalf of the European Union within the Bilateral Oversight Board, as referred to in Article 3.A of the Agreement between the United States of America and the European Community on cooperation in the regulation of civil aviation safety, with regard to the adoption of a Decision amending Annex 1 to the Agreement, shall be based on the draft Decision No 0004 of the Bilateral Oversight Board, attached to this Decision.', 'This Decision shall enter into force on the day of its adoption.']",
         "['1252', '4408', '5404', '5870', '5887', '888']",
         "train",
         "2013/475/EU: Council Decision of 23 September 2013 on the position to be taken on behalf of the European Union within the Bilateral Oversight Board under the Agreement between the United States of America and the European Community on cooperation in the regulation of civil aviation safety, concerning Decision No 0004 amending Annex 1 to the Agreement\n\n,\nHaving regard to the Treaty on the Functioning of the European Union, and in particular Article 100(2) in conjunction with Article 218(9) thereof,\nHaving regard to the proposal from the European Commission,\nWhereas:\n(1) Council Decision 2011/719/EU of 7 March 2011 concerning the conclusion of the Agreement between the United States of America and the European Community on cooperation in the regulation of civil aviation safety (1) entered into force on 1 May 2011.\n(2) Pursuant to Article 3.C.2 of the Agreement between the United States of America and the European Community on cooperation in the regulation of civil aviation safety (2) (‘the Agreement’), the Bilateral Oversight Board established by Article 3.A of the Agreement may amend the annexes to the Agreement in accordance with Article 19.B thereof.\n(3) It is appropriate to establish the position to be be adopted on the Union’s behalf within the Bilateral Oversight Board in accordance with Article 4(4) of Decision 2011/719/EU with regard to Decision No 0004 of the Bilateral Oversight Board amending Annex 1 to the Agreement,\nThe position to be adopted on behalf of the European Union within the Bilateral Oversight Board, as referred to in Article 3.A of the Agreement between the United States of America and the European Community on cooperation in the regulation of civil aviation safety, with regard to the adoption of a Decision amending Annex 1 to the Agreement, shall be based on the draft Decision No 0004 of the Bilateral Oversight Board, attached to this Decision. This Decision shall enter into force on the day of its adoption.",
         "1964",
         "Decision",
         "Decision"
        ],
        [
         "49",
         "31999D0662",
         "Decision",
         "99/662/EC: Council Decision of 19 July 1999 concerning the conclusion of the Agreement on mutual recognition of OECD principles of good laboratory practice (GLP) and compliance monitoring programmes between the European Community and the State of Israel\n",
         "COUNCIL DECISION\nof 19 July 1999\nconcerning the conclusion of the Agreement on mutual recognition of OECD principles of good laboratory practice (GLP) and compliance monitoring programmes between the European Community and the State of Israel\n(1999/662/EC)\nTHE COUNCIL OF THE EUROPEAN UNION",
         ",\nHaving regard to the Treaty establishing the European Community, and in particular Article 133 thereof, in conjunction with the first sentence of Article 300(2) and the first subparagraph of Article 300(3) and Article 300(4),\nHaving regard to the proposal from the Commission,\nWhereas:\n(1) the Agreement on mutual Recognition of OECD principles of good laboratory practice (GLP) and compliance monitoring programmes, initialled in Brussels on 16 January 1997, was negotiated by the Commission in accordance with its negotiating guidelines and should be approved;\n(2) certain aspects of implementation have been assigned to the Joint Committee established by the Agreement, and in particular the power to amend certain parts of the two Annexes;\n(3) it is necessary to lay down the internal procedures required for the proper functioning of the Agreement; the Commission should be empowered to make certain technical changes to the Agreement and to take certain decisions concerning its implementation,",
         "['The Agreement on mutual recognition of OECD principles of good laboratory practice (GLP) and compliance monitoring programmes between the European Community and the State of Israel is hereby approved on behalf of the Community.\\nThe text of the Agreement and the Agreed Minutes are attached to this Decision.', 'The President of the Council shall, on behalf of the Community, transmit the note provided for in Article 16 of the Agreement(1).', '1. The Commission, assisted by the Special Committee appointed by the Council, shall represent the Community in the Joint Committee provided for in Article 10 of the Agreement. After consulting the Special Committee, the Commission shall carry out the notifications, consultations and exchanges of information, shall make the requests for inspections and for participation in inspections, and, if need be, shall reply to requests, in accordance with Articles 3(2), 5(2), 6, 7, 9 and 12 of the Agreement and in Annex II thereto, and adopt the Decision provided for in Article 11(2) and (3) and the second sentence of Article 12.\\n2. The position of the Community within the Joint Committee, with regard to amendments to Annex I decided on in accordance with the second sentence of Article 4 of the Agreement and to amendments to Annex II decided on in accordance with Article 5 of the Agreement, shall be adopted by the Commission after it has consulted the Special Committee referred to in paragraph 1 of this Article.\\n3. All other decisions shall be taken by the Council, acting by a qualified majority on a proposal from the Commission.']",
         "['1474', '1518', '2739', '3482', '3660', '5811']",
         "train",
         "99/662/EC: Council Decision of 19 July 1999 concerning the conclusion of the Agreement on mutual recognition of OECD principles of good laboratory practice (GLP) and compliance monitoring programmes between the European Community and the State of Israel\n\n,\nHaving regard to the Treaty establishing the European Community, and in particular Article 133 thereof, in conjunction with the first sentence of Article 300(2) and the first subparagraph of Article 300(3) and Article 300(4),\nHaving regard to the proposal from the Commission,\nWhereas:\n(1) the Agreement on mutual Recognition of OECD principles of good laboratory practice (GLP) and compliance monitoring programmes, initialled in Brussels on 16 January 1997, was negotiated by the Commission in accordance with its negotiating guidelines and should be approved;\n(2) certain aspects of implementation have been assigned to the Joint Committee established by the Agreement, and in particular the power to amend certain parts of the two Annexes;\n(3) it is necessary to lay down the internal procedures required for the proper functioning of the Agreement; the Commission should be empowered to make certain technical changes to the Agreement and to take certain decisions concerning its implementation,\nThe Agreement on mutual recognition of OECD principles of good laboratory practice (GLP) and compliance monitoring programmes between the European Community and the State of Israel is hereby approved on behalf of the Community.\nThe text of the Agreement and the Agreed Minutes are attached to this Decision. The President of the Council shall, on behalf of the Community, transmit the note provided for in Article 16 of the Agreement(1). 1. The Commission, assisted by the Special Committee appointed by the Council, shall represent the Community in the Joint Committee provided for in Article 10 of the Agreement. After consulting the Special Committee, the Commission shall carry out the notifications, consultations and exchanges of information, shall make the requests for inspections and for participation in inspections, and, if need be, shall reply to requests, in accordance with Articles 3(2), 5(2), 6, 7, 9 and 12 of the Agreement and in Annex II thereto, and adopt the Decision provided for in Article 11(2) and (3) and the second sentence of Article 12.\n2. The position of the Community within the Joint Committee, with regard to amendments to Annex I decided on in accordance with the second sentence of Article 4 of the Agreement and to amendments to Annex II decided on in accordance with Article 5 of the Agreement, shall be adopted by the Commission after it has consulted the Special Committee referred to in paragraph 1 of this Article.\n3. All other decisions shall be taken by the Council, acting by a qualified majority on a proposal from the Commission.",
         "2833",
         "Decision",
         "Decision"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 3900
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>celex_id</th>\n",
       "      <th>document_type</th>\n",
       "      <th>title</th>\n",
       "      <th>header</th>\n",
       "      <th>recitals</th>\n",
       "      <th>main_body</th>\n",
       "      <th>eurovoc_concepts</th>\n",
       "      <th>split</th>\n",
       "      <th>content</th>\n",
       "      <th>content_length</th>\n",
       "      <th>cls_label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31983D0455</td>\n",
       "      <td>Decision</td>\n",
       "      <td>83/455/EEC: Commission Decision of 1 September...</td>\n",
       "      <td>COMMISSION  DECISION\\nof 1 September 1983\\nest...</td>\n",
       "      <td>,\\nHaving regard to the Treaty establishing th...</td>\n",
       "      <td>[The apparatus described as 'Plessey-Viz - Rad...</td>\n",
       "      <td>[1091, 2159, 3842, 4381]</td>\n",
       "      <td>train</td>\n",
       "      <td>83/455/EEC: Commission Decision of 1 September...</td>\n",
       "      <td>2580</td>\n",
       "      <td>Decision</td>\n",
       "      <td>Decision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32014D0207</td>\n",
       "      <td>Decision</td>\n",
       "      <td>2014/207/EU: Commission Implementing Decision ...</td>\n",
       "      <td>12.4.2014 EN Official Journal of the European ...</td>\n",
       "      <td>,\\nHaving regard to the Treaty on the Function...</td>\n",
       "      <td>[European Registry for internet Domains (EURid...</td>\n",
       "      <td>[6139, 6775, 773, 7950]</td>\n",
       "      <td>train</td>\n",
       "      <td>2014/207/EU: Commission Implementing Decision ...</td>\n",
       "      <td>3608</td>\n",
       "      <td>Decision</td>\n",
       "      <td>Decision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32007D0621</td>\n",
       "      <td>Decision</td>\n",
       "      <td>2007/621/EC,Euratom: Council Decision of 26 Se...</td>\n",
       "      <td>28.9.2007 EN Official Journal of the European ...</td>\n",
       "      <td>,\\nHaving regard to the Treaty establishing th...</td>\n",
       "      <td>[Ms Mette KINDBERG is hereby appointed a membe...</td>\n",
       "      <td>[336, 3559, 6054]</td>\n",
       "      <td>train</td>\n",
       "      <td>2007/621/EC,Euratom: Council Decision of 26 Se...</td>\n",
       "      <td>1070</td>\n",
       "      <td>Decision</td>\n",
       "      <td>Decision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31992D0283</td>\n",
       "      <td>Decision</td>\n",
       "      <td>92/283/EEC: Commission Decision of 8 May 1992 ...</td>\n",
       "      <td>COMMISSION DECISION  of 8 May 1992  approving ...</td>\n",
       "      <td>,\\nHaving regard to the Treaty establishing th...</td>\n",
       "      <td>[The plan submitted by the Netherlands for the...</td>\n",
       "      <td>[152, 192, 2121, 2286, 4747, 619]</td>\n",
       "      <td>train</td>\n",
       "      <td>92/283/EEC: Commission Decision of 8 May 1992 ...</td>\n",
       "      <td>1318</td>\n",
       "      <td>Decision</td>\n",
       "      <td>Decision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31994D1032</td>\n",
       "      <td>Decision</td>\n",
       "      <td>94/1032/EC: Commission Decision of 16 December...</td>\n",
       "      <td>COMMISSION  DECISION of 16 December 1994 on th...</td>\n",
       "      <td>,\\nHaving regard to the Treaty establishing th...</td>\n",
       "      <td>[The Single Programming Document for Community...</td>\n",
       "      <td>[1460, 231, 2407, 3067, 3396, 431]</td>\n",
       "      <td>train</td>\n",
       "      <td>94/1032/EC: Commission Decision of 16 December...</td>\n",
       "      <td>10506</td>\n",
       "      <td>Decision</td>\n",
       "      <td>Decision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>32006R1817</td>\n",
       "      <td>Regulation</td>\n",
       "      <td>Commission Regulation (EC) No 1817/2006 of 11 ...</td>\n",
       "      <td>12.12.2006 EN Official Journal of the European...</td>\n",
       "      <td>,\\nHaving regard to the Treaty establishing th...</td>\n",
       "      <td>[The standard import values referred to in Art...</td>\n",
       "      <td>[1118, 1605, 2511, 2635, 693]</td>\n",
       "      <td>validation</td>\n",
       "      <td>Commission Regulation (EC) No 1817/2006 of 11 ...</td>\n",
       "      <td>1163</td>\n",
       "      <td>Regulation</td>\n",
       "      <td>Regulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>31998R1627</td>\n",
       "      <td>Regulation</td>\n",
       "      <td>Council Regulation (EC) No 1627/98 of 20 July ...</td>\n",
       "      <td>COUNCIL REGULATION (EC) No 1627/98 of 20 July ...</td>\n",
       "      <td>,\\nHaving regard to the Treaty establishing th...</td>\n",
       "      <td>[Regulation (EEC) No 822/87 is amended as foll...</td>\n",
       "      <td>[2173, 2410, 4708, 4713, 4734]</td>\n",
       "      <td>validation</td>\n",
       "      <td>Council Regulation (EC) No 1627/98 of 20 July ...</td>\n",
       "      <td>5498</td>\n",
       "      <td>Regulation</td>\n",
       "      <td>Regulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>32007R0522</td>\n",
       "      <td>Regulation</td>\n",
       "      <td>Commission Regulation (EC) No 522/2007 of 11 M...</td>\n",
       "      <td>12.5.2007 EN Official Journal of the European ...</td>\n",
       "      <td>,\\nHaving regard to the Treaty establishing th...</td>\n",
       "      <td>[For the 31st individual invitation to tender ...</td>\n",
       "      <td>[20, 2644, 2664, 2681, 3070, 4860]</td>\n",
       "      <td>validation</td>\n",
       "      <td>Commission Regulation (EC) No 522/2007 of 11 M...</td>\n",
       "      <td>2137</td>\n",
       "      <td>Regulation</td>\n",
       "      <td>Regulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>32011R0962</td>\n",
       "      <td>Regulation</td>\n",
       "      <td>Commission Implementing Regulation (EU) No 962...</td>\n",
       "      <td>28.9.2011 EN Official Journal of the European ...</td>\n",
       "      <td>,\\nHaving regard to the Treaty on the Function...</td>\n",
       "      <td>[The standard import values referred to in Art...</td>\n",
       "      <td>[1115, 1602, 2173, 2635, 3191]</td>\n",
       "      <td>validation</td>\n",
       "      <td>Commission Implementing Regulation (EU) No 962...</td>\n",
       "      <td>1371</td>\n",
       "      <td>Regulation</td>\n",
       "      <td>Regulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>31987R3316</td>\n",
       "      <td>Regulation</td>\n",
       "      <td>Commission Regulation (EEC) No 3316/87 of 4 No...</td>\n",
       "      <td>COMMISSION  REGULATION (EEC) No 3316/87\\nof 4 ...</td>\n",
       "      <td>,\\nHaving regard to the Treaty establishing th...</td>\n",
       "      <td>[The following paragraph is added to Article 1...</td>\n",
       "      <td>[1570, 4227, 4498]</td>\n",
       "      <td>validation</td>\n",
       "      <td>Commission Regulation (EEC) No 3316/87 of 4 No...</td>\n",
       "      <td>2207</td>\n",
       "      <td>Regulation</td>\n",
       "      <td>Regulation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3900 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        celex_id document_type  \\\n",
       "0     31983D0455      Decision   \n",
       "1     32014D0207      Decision   \n",
       "2     32007D0621      Decision   \n",
       "3     31992D0283      Decision   \n",
       "4     31994D1032      Decision   \n",
       "...          ...           ...   \n",
       "3895  32006R1817    Regulation   \n",
       "3896  31998R1627    Regulation   \n",
       "3897  32007R0522    Regulation   \n",
       "3898  32011R0962    Regulation   \n",
       "3899  31987R3316    Regulation   \n",
       "\n",
       "                                                  title  \\\n",
       "0     83/455/EEC: Commission Decision of 1 September...   \n",
       "1     2014/207/EU: Commission Implementing Decision ...   \n",
       "2     2007/621/EC,Euratom: Council Decision of 26 Se...   \n",
       "3     92/283/EEC: Commission Decision of 8 May 1992 ...   \n",
       "4     94/1032/EC: Commission Decision of 16 December...   \n",
       "...                                                 ...   \n",
       "3895  Commission Regulation (EC) No 1817/2006 of 11 ...   \n",
       "3896  Council Regulation (EC) No 1627/98 of 20 July ...   \n",
       "3897  Commission Regulation (EC) No 522/2007 of 11 M...   \n",
       "3898  Commission Implementing Regulation (EU) No 962...   \n",
       "3899  Commission Regulation (EEC) No 3316/87 of 4 No...   \n",
       "\n",
       "                                                 header  \\\n",
       "0     COMMISSION  DECISION\\nof 1 September 1983\\nest...   \n",
       "1     12.4.2014 EN Official Journal of the European ...   \n",
       "2     28.9.2007 EN Official Journal of the European ...   \n",
       "3     COMMISSION DECISION  of 8 May 1992  approving ...   \n",
       "4     COMMISSION  DECISION of 16 December 1994 on th...   \n",
       "...                                                 ...   \n",
       "3895  12.12.2006 EN Official Journal of the European...   \n",
       "3896  COUNCIL REGULATION (EC) No 1627/98 of 20 July ...   \n",
       "3897  12.5.2007 EN Official Journal of the European ...   \n",
       "3898  28.9.2011 EN Official Journal of the European ...   \n",
       "3899  COMMISSION  REGULATION (EEC) No 3316/87\\nof 4 ...   \n",
       "\n",
       "                                               recitals  \\\n",
       "0     ,\\nHaving regard to the Treaty establishing th...   \n",
       "1     ,\\nHaving regard to the Treaty on the Function...   \n",
       "2     ,\\nHaving regard to the Treaty establishing th...   \n",
       "3     ,\\nHaving regard to the Treaty establishing th...   \n",
       "4     ,\\nHaving regard to the Treaty establishing th...   \n",
       "...                                                 ...   \n",
       "3895  ,\\nHaving regard to the Treaty establishing th...   \n",
       "3896  ,\\nHaving regard to the Treaty establishing th...   \n",
       "3897  ,\\nHaving regard to the Treaty establishing th...   \n",
       "3898  ,\\nHaving regard to the Treaty on the Function...   \n",
       "3899  ,\\nHaving regard to the Treaty establishing th...   \n",
       "\n",
       "                                              main_body  \\\n",
       "0     [The apparatus described as 'Plessey-Viz - Rad...   \n",
       "1     [European Registry for internet Domains (EURid...   \n",
       "2     [Ms Mette KINDBERG is hereby appointed a membe...   \n",
       "3     [The plan submitted by the Netherlands for the...   \n",
       "4     [The Single Programming Document for Community...   \n",
       "...                                                 ...   \n",
       "3895  [The standard import values referred to in Art...   \n",
       "3896  [Regulation (EEC) No 822/87 is amended as foll...   \n",
       "3897  [For the 31st individual invitation to tender ...   \n",
       "3898  [The standard import values referred to in Art...   \n",
       "3899  [The following paragraph is added to Article 1...   \n",
       "\n",
       "                        eurovoc_concepts       split  \\\n",
       "0               [1091, 2159, 3842, 4381]       train   \n",
       "1                [6139, 6775, 773, 7950]       train   \n",
       "2                      [336, 3559, 6054]       train   \n",
       "3      [152, 192, 2121, 2286, 4747, 619]       train   \n",
       "4     [1460, 231, 2407, 3067, 3396, 431]       train   \n",
       "...                                  ...         ...   \n",
       "3895       [1118, 1605, 2511, 2635, 693]  validation   \n",
       "3896      [2173, 2410, 4708, 4713, 4734]  validation   \n",
       "3897  [20, 2644, 2664, 2681, 3070, 4860]  validation   \n",
       "3898      [1115, 1602, 2173, 2635, 3191]  validation   \n",
       "3899                  [1570, 4227, 4498]  validation   \n",
       "\n",
       "                                                content  content_length  \\\n",
       "0     83/455/EEC: Commission Decision of 1 September...            2580   \n",
       "1     2014/207/EU: Commission Implementing Decision ...            3608   \n",
       "2     2007/621/EC,Euratom: Council Decision of 26 Se...            1070   \n",
       "3     92/283/EEC: Commission Decision of 8 May 1992 ...            1318   \n",
       "4     94/1032/EC: Commission Decision of 16 December...           10506   \n",
       "...                                                 ...             ...   \n",
       "3895  Commission Regulation (EC) No 1817/2006 of 11 ...            1163   \n",
       "3896  Council Regulation (EC) No 1627/98 of 20 July ...            5498   \n",
       "3897  Commission Regulation (EC) No 522/2007 of 11 M...            2137   \n",
       "3898  Commission Implementing Regulation (EU) No 962...            1371   \n",
       "3899  Commission Regulation (EEC) No 3316/87 of 4 No...            2207   \n",
       "\n",
       "       cls_label description  \n",
       "0       Decision    Decision  \n",
       "1       Decision    Decision  \n",
       "2       Decision    Decision  \n",
       "3       Decision    Decision  \n",
       "4       Decision    Decision  \n",
       "...          ...         ...  \n",
       "3895  Regulation  Regulation  \n",
       "3896  Regulation  Regulation  \n",
       "3897  Regulation  Regulation  \n",
       "3898  Regulation  Regulation  \n",
       "3899  Regulation  Regulation  \n",
       "\n",
       "[3900 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_json(\"/home/snt/projects_lujun/agentCLS/assets/training_dataset/LDD_split_proportional_train_1500_val_300.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cls_label  split     \n",
       "cs.AI      train         1423\n",
       "           validation     300\n",
       "cs.CE      train         1293\n",
       "           validation     300\n",
       "cs.CV      train         1303\n",
       "           validation     300\n",
       "cs.DS      train         1500\n",
       "           validation     300\n",
       "cs.IT      train         1500\n",
       "           validation     300\n",
       "cs.NE      train         1355\n",
       "           validation     300\n",
       "cs.PL      train         1334\n",
       "           validation     300\n",
       "cs.SY      train         1500\n",
       "           validation     300\n",
       "math.AC    train         1474\n",
       "           validation     300\n",
       "math.GR    train         1500\n",
       "           validation     300\n",
       "math.ST    train         1500\n",
       "           validation     300\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby([\"cls_label\",\"split\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10378.622484458961\n"
     ]
    }
   ],
   "source": [
    "data[\"len\"] = data[\"content\"].apply(lambda x: len(x.split()))\n",
    "average_length = data[\"len\"].mean()\n",
    "print(average_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cls_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "file_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "content_length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "len",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "50f04598-77f1-4473-88df-1f0303322fa6",
       "rows": [
        [
         "0",
         "18843",
         "cs.AI",
         "Artificial Intelligence",
         "1711.04569v2.pdf",
         "MULTILINGUAL ADAPTATION OF RNN BASED ASR SYSTEMS\nMarkus Müller, Sebastian Stüker, Alex Waibel\n\narXiv:1711.04569v2 [eess.AS] 27 Feb 2018\n\nInstitute for Anthropomatics and Robotics\nKarlsruhe Institute of Technology, Karlsruhe, Germany\n{m.mueller, sebastian.stueker, alexander.waibel}@kit.edu\n\nABSTRACT\nIn this work, we focus on multilingual systems based on recurrent neural networks (RNNs), trained using the Connectionist Temporal Classification (CTC) loss function. Using a\nmultilingual set of acoustic units poses difficulties. To address\nthis issue, we proposed Language Feature Vectors (LFVs)\nto train language adaptive multilingual systems. Language\nadaptation, in contrast to speaker adaptation, needs to be applied not only on the feature level, but also to deeper layers\nof the network. In this work, we therefore extended our previous approach by introducing a novel technique which we\ncall “modulation”. Based on this method, we modulated the\nhidden layers of RNNs using LFVs. We evaluated this approach in both full and low resource conditions, as well as\nfor grapheme and phone based systems. Lower error rates\nthroughout the different conditions could be achieved by the\nuse of the modulation.\nIndex Terms— Multilingual, automatic speech recognition, connectionist temporal classification, language feature\nvectors, low-resource\n1. INTRODUCTION\nTraining multilingual speech recognition systems requires\nspecial methods. In low-resource conditions, training systems\non data from multiple languages improves the performance.\nIn a resource rich environment, using data from multiple languages often does not improve the performance, but might\nevent affect it negatively. In both cases, adaptation techniques\nare required to improve the recognition accuracy and neural\nnetworks adapted to language characteristics have proven to\nperform better. This is similar to speaker adaptation, where\nadapted networks outperform unadapted ones.\nHowever, language adaptation is more challenging than\nspeaker adaptation: Collecting training data from several hundred speakers is possible. This amount of speakers enables\nnetworks to generalize upon speaker properties. For language\nadaptation, there are an order of magnitude less languages\navailable than there are speakers. This renders generalization\nThis work was realized in the framework of the ANR-DFG project\nBULB (ANR-14-CE35-002).\n\nacross languages more difficult. Another factor is the task itself. When trained on data from multiple speakers of the same\nlanguage, the same targets, e.g., phone states, are used. Different languages feature different, but sometimes overlapping,\nsets of targets. Although speech recognition for different languages are different tasks, they are related since all languages\nare being spoken by humans. This limits the sound inventory\nto the sounds that can be produced by the human vocal tract.\nAlso, languages (from the same language family) potentially\nshare sound inventories, as well as the set of targets the network is trained on.\nApplying language adaptation techniques should therefore enable the networks to generalize better. Encoding language properties using, e.g., LFVs, like we showed in the\npast, allow networks to be trained language adaptive in such a\nway that they can exploit similarities and differences between\nlanguages. Unlike traditional GMM/HMM or DNN/HMM\nbased systems, RNN/CTC based setups do not require explicit modelling of context dependent states which would then\nneed to be adapted. Based on RNNs, these systems should\nbe trained towards learning features based on language properties in order to be able to better perform in a multilingual\nscenario.\nAs we outlined in the related works section, several techniques for language adaptation have been proposed for traditional systems in the past. We proposed to use LFVs as additional input features for language adaptation. In this paper, we\nintroduce a novel approach of integrating LFVs into recurrent\nnetwork architectures based on the idea of Meta-PI networks.\nThe effectiveness of our approach is demonstrated in a series\nof experiments, showing that the method presented here can\nbe applied to both full- and low-resource conditions. In addition, we also omitted the pronunciation dictionary and built\nsystems using graphemes only. In a multilingual scenario,\nthis is particularly challenging as the network is required to\nlearn pronunciations from multiple languages in parallel. To\nevaluate our systems, we use the token error rate (TER) as\nprimary measure of the trained networks. But we also incorporated a RNN based language model (LM) for decoding to\nthe determine the word error rate (WER).\nThis paper is organized as follows: In the next Section\n2, we outlined related work in the field, followed by a de-\n\nTo appear in Proc. ICASSP 2018, April 15-20, 2018, Calgary, Canada\n\nc IEEE 2018\n\n\ftailed description of the method proposed in Section 3. We\ndescribed the experimental setup in Section 4, followed by\nthe results of our experiments (Section 5). This paper concludes with Section 6, where we also outline possible future\nwork.\n\nporal classification (CTC) loss function [12], which does not\nrequire frame-level labels. It aligns a sequence of tokens automatically. As in traditional systems, phones, graphemes or\nboth combined can be used as acoustic modeling units [13].\nGiven enough training data, even whole words can be used\n[14].\n\n2. RELATED WORK\n3. LANGUAGE ADAPTATION\n\n2.1. Multi- and Crosslingual Speech Recognition Systems\nPrior to the emergence of neural networks, ASR systems were\ntypically built using a GMM/HMM based approach. Methods for training/adapting such systems cross- and multilingually were proposed to handle data sparsity [1, 2]. The process of clustering context-independent phones into contextdependent ones can also be adapted to account for cross- and\nmultilinguality [3]. Due to their recurrent nature, RNNs are\na powerful tool to model sequential dependencies, rendering\nthe need for context-dependent targets superfluous. Using\nonly context-independent targets has the advantage that no\nclustering is required.\n\nIn the past, we proposed methods for adapting multilingual\nneural network based ASR systems to languages using LFVs.\nLanguage Feature Vectors are a low-dimensional representation of language properties, extracted via a neural network.\nThis network was trained to discriminate languages, based on\nlog Mel and tonal features (FFV [15] and pitch [16]) typically\nused by ASR systems. A similar architecture as for extraction\nof BNFs was used. This architecture featured a bottleneck\nas second last layer. After training, the output activations of\nthis layer were used as LFVs. To perform the adaptation, we\nappended LFVs to the acoustic features, similar to appending i-Vectors for speaker adaptation. In the results section,\nwe included error rates using this method as contrastive experiments, denoted as “LFV app”. This method has shown to\nreduce error rates for multilingual GMM/HMM, DNN/HMM\nas well as RNN/CTC based systems.\n\n2.2. Multilingual Bottleneck Features\nIn a resource constraint scenario, data from additional source\nlanguages are used to improve the performance. DNNs are\ntypically trained in two steps: Pre-training and fine-tuning. It\nhas been shown that the pre-training step is language independent [4]. The fine-tuning can be modified in multiple ways to\naccount for additional languages. One approach includes the\nuse of shared hidden layers, with language dependent output\nlayers [5]. Combining multiple output layers into one is also\npossible [6].\n\n3.1. Neural Modulation\nAppending features for speaker adaptation to acoustic features is fitting, as changes in speaker characteristics are reflected within the signal. Multiple adaptation methods like\nVTLN or fMLLR which directly operate on the acoustic features were proposed. The same holds true for i-Vector based\nadaptation, where speaker adaptive systems can be trained to\ndirectly shift input features based on speaker properties [8].\nBut language properties are a higher order concept in contrast\nto speaker variations. Some aspects are based on acoustics,\ne.g. having the same phone in multiple languages, where\na language specific coloring can be observed to some degree. But aspects like phonotactics or different sets of acoustic units require adaptation methods beyond the transformation of acoustic features. Here, adding features at deeper layers potentially enables better adaptation.\nOne possibility is a method first introduced as part of\nMeta-PI [17] networks. The key aspect is the use of Meta-PI\nconnections, which allow to modulate the output of units\nby multiplication with a coefficient. Applied to language\nadaptation, we modulated the outputs of hidden layers with\nLFVs. Based on language features, the output of LSTM cells\nare attenuated or emphasized. This forces the cells in the\nhidden layer to learn or adapt to features based on language\nproperties. Modulation can be considered related to dropout\ntraining [18], where connections are dropped on a random\n\n2.3. Neural Network Adaptation\nFeeding additional input features into a neural network is a\ncommon way for adaptation. A popular approach for speaker\nadaptation is to supply i-Vectors [7], which encode speaker\ncharacteristics in a low-dimensional representation. Speaker\nadaptive neural networks can be trained this way [8]. Such\nlow dimensional codes can also be extracted using neural networks, called Bottleneck Speaker Vectors (BSVs) [9]. In the\npast, we proposed similar methods to adapt DNNs to multiple languages. We first introduced a method encoding the\nlanguage identity using one-hot encoding [10]. We enhanced\nthis method in a similar way to BSVs, by extracting Language\nFeature Vectors (LFVs) [11]. These vectors have shown to\nencode language properties instead of the language identity\nalone, even for languages not seen during training.\n2.4. RNN Based ASR Systems\nRNN based ASR systems are becoming increasingly popular.\nOne method to train them is the use of the Connectionist tem2\n\n\fbasis. In the results section, we refer to this method as “LFV\nmod”.\nWe used a network configuration as shown in Figure 1.\nThe basic architecture is inspired by Baidu’s Deepspeech 2.\nIt combines two TDNN/CNN layers with 4 bi-directional\nLSTM layers. The output layer is a feed-forward layer which\nmaps the output of the last LSTM layer to the targets. We\nchose the number of LSTM cells in each layer to be a multiple of the dimensionality of the LFVs. This way, we could\nstructure the hidden layer into groups of LSTM cells containing an equal amount of units. The output of each group is\nthen modulated with one dimension of the LFVs. The figure\nshows both configurations, “LFV app” and “LFV mod”, but\nonly one method was applied at a time. In preliminary experiments, we determined modulating the output of the second\nLSTM layer to result in the best performance.\n\nadditional subset containing only 8h out of the 45h training\nset to evaluate our approach in a low-resource condition.\n\n4.1. Acoustic Units\nAs acoustic units, we used both phones and graphemes. The\npronunciation dictionaries were created using MaryTTS [20].\nFor merging the monolingual dictionaries, we mapped the\nphone-symbols to a multilingual phone set using the definition of articulatory features in MaryTTS’ language description files. In addition to systems based on phones, we also\ntrained networks using graphemes as acoustic units. To indicate word boundaries, an additional token was used.\n\n4.2. RNN/CTC Network Training\nLFV app\n\nLFV mod\n\n2D TDNN / CNN\nBi-directional LSTM Layers\nLayers\n\nMultilingual Bottleneck Features (ML-BNFs) were used as\ninput features. The ML-BNFs network was trained using data\nfrom 5 languages (French, German, Italian, Russian, Turkish). Input features to the network were log Mel and tonal\nfeatures (FFV [15] and pitch [16]), extracted using a 32ms\nwindow with a 10ms frame-shift. The RNN network was\ntrained using stochastic gradient descent (SGD) and Nesterov\nmomentum [21] with a factor of 0.9. Mini-batch updates with\na batch size of 15 were applied together with batch normalization. The utterances were sorted ascending by length to\nstabilize the training, as shorter utterances are easier to align.\nOutput\nLayer\n\n4.3. Grapheme Based RNN LM\nFig. 1. Network architecture showing “LFV app”, as well as\nthe proposed adaptation method “LFV mod”.\n\nWe used a RNN based LM, trained on graphemes as described\nin [22]. It featured 1 hidden layer with 1024 LSTM cells.\nThe model was trained on only a very limited set of sentences, consisting of the training utterances of the acoustic\nmodel only. As language models are typically trained on\nseveral millions of sentences, this is not much training data.\nBut the model should provide an indication whether the improvements observed as TER also result in a better word level\nspeech recognition system.\n\n4. EXPERIMENTAL SETUP\nWe based our experiments on the Euronews corpus [19],\nwhich contains data from 10 languages. For each language,\n70h of TV broadcast news recordings are available. For our\nexperiments, we used a combination of 4 languages (English, French, German, Turkish), based on the availability of\npronunciation dictionaries. We filtered utterances based on\nlength, omitting very short ones (< 1s), and also removed\nones having a transcript of more than 639 characters1 . Noises\nwere only annotated in a very basic way with a single noise\nmarker covering all different noise types, ranging from music,\nbackground and human noises. We therefore omitted utterances marked as noise. After applying all filtering, approx.\n50h of data remained per language and was split into 45h\nof training and 5h of test data. For training, we created an\n\n4.4. Evaluation\nWe evaluated our proposed method varying two conditions:\nThe availability of a pronunciation dictionary and the amount\nof data. An ASR system without language adaptation is used\nas baseline. First, we used the token error rate (TER) as primary measure to determine the performance without the use\nof external (language) models. For decoding, we use the same\nprocedure as in [12] and greedily search for the best path. In\naddition to the TER, we also determined the word error rate\n(WER) using an RNN LM.\n\n1 Internal limitation within the implementation of CUDA/warp-ctc, see:\nhttps://github.com/baidu-research/warp-ctc, accessed 2018-02-12\n\n3\n\n\f5. RESULTS\n5.1. Grapheme Based Systems\nFirst, we evaluated the use of graphemes as acoustic modeling\nunits. We started using a network configuration with the RNN\npart having 420 LSTM cells per layer, trained using only 8h\nof data per language (see Table 1). Adding LFVs after the\nTDNN / CNN layers (“LFV app”) does lower the TER, but\napplying the method presented here (“LFV mod”) lowers the\nTER even more. Similar gains can be observed using the full\nCondition\n\nDE\n\nEN\n\nFR\n\nTR\n\nML Baseline\nLFV app\nLFV mod\n\n30.8\n22.9\n20.7\n\n38.0\n33.3\n32.7\n\n29.4\n27.3\n25.4\n\n30.9\n21.3\n19.6\n\nEN\n\nFR\n\nTR\n\nBaseline\nLFV app\nLFV mod\n\n10.6\n9.5\n9.1\n\n18.2\n16.1\n15.5\n\n15.9\n14.3\n13.6\n\n9.1\n8.1\n8.0\n\nEN\n\nFR\n\nTR\n\nBaseline\nLFV app\nLFV mod\n\n8.9\n7.9\n7.7\n\n15.0\n13.6\n13.3\n\n13.5\n11.8\n11.7\n\n7.9\n7.1\n7.1\n\nTR\n\nBaseline\nLFV app\nLFV mod\n\n21.7\n20.9\n19.0\n\n27.2\n26.4\n25.6\n\n23.9\n21.3\n19.8\n\n21.6\n19.5\n17.6\n\nCondition\n\nDE\n\nEN\n\nFR\n\nTR\n\nBaseline\nLFV app\nLFV mod\n\n9.6\n9.3\n8.6\n\n14.6\n13.2\n12.5\n\n12.1\n10.8\n10.2\n\n8.5\n7.7\n7.3\n\n5.3. Decoding with RNN LM\nTo determine the WER, we ran a greedy decoding using a\nchar based RNN LM on the English subset of the test data.\nThe results shown in Table 6 indicate that the improvements\nof TER are also observable w. r. t. WER after decoding with\na language model.\n\nworks. In an additional experiment, we increased the number\nof LSTM cells per layer to 840. As shown in Table 3, the\nTER decreases in absolute terms, but the difference between\naddition and modulation becomes smaller.\nDE\n\nFR\n\nTable 5. TER of phoneme based system trained on 45h per\nlanguage, 840 LSTM cells per layer\n\nTable 2. TER of grapheme based system trained on 45h per\nlanguage, 420 LSTM cells per layer\n\nCondition\n\nEN\n\nof LSTM cells per layer to 840, similar improvements could\nbe achieved (Table 5). In contrast to the grapheme based\nsetup (Table 3), modulating the layers (“LFV mod”) improves\nthe performance over the simple addition (“LFV app”). The\nTERs of the grapheme based systems for German and Turkish\nare lower compared to their phone based counterparts. One\nreason for this is the quality of the pronunciation dictionary,\nwhich was created fully automatically based on a TTS system.\n\ntraining set (Table 2). The use of more data lowered the TER,\nwhereas the relative improvements were in the same order of\nmagnitude. Training on more data also allowed for larger netDE\n\nDE\n\nTable 4. TER of phoneme based system trained on 8h per\nlanguage, 420 LSTM cells per layer\n\nTable 1. TER of grapheme based system trained on 8h per\nlanguage, 420 LSTM cells per layer\n\nCondition\n\nCondition\n\nSetup\n\nBaseline\n\nLFV app\n\nLFV mod\n\n8h-420\n45h-840\n\n32.4%\n29.2%\n\n30.6%\n27.7%\n\n29.9%\n27.3%\n\nTable 6. WERs for English grapheme based systems.\n\nTable 3. TER of grapheme based system trained on 45h per\nlanguage, 840 LSTM cells per layer\n\n6. CONCLUSION\nUnlike speaker adaptation, where the collection of data covering hundreds of speakers is feasible, collecting data from that\nmany languages is next to impossible. Optimizing the adaptation method is therefore key to maximize the performance\nin a multilingual scenario. We presented an improved method\nfor language adaptation of RNNs in a multilingual setting.\nModulating the outputs of a layer showed improvements over\nappending LFVs to input features.\n\n5.2. Phoneme Based Systems\nIn the same notion as graphemes, we evaluated systems based\non phonemes as acoustic modelling units. Starting with the\nlimited data set (Table 4), improvements by the modulation\n(“LFV mod”) over the addition (“LFV app”) can be observed.\nUsing all available training data and increasing the number\n4\n\n\f7. REFERENCES\n\n[13] Dongpeng Chen, Brian Mak, Cheung-Chi Leung, and\nSunil Sivadas, “Joint acoustic modeling of triphones\nand trigraphemes by multi-task learning deep neural networks for low-resource speech recognition,” in Acoustics, Speech, and Signal Processing (ICASSP). IEEE,\n2014, pp. 5592–5596.\n\n[1] Tanja Schultz and Alex Waibel, “Fast bootstrapping of\nLVCSR systems with multilingual phoneme sets,” in\nEurospeech, 1997.\n[2] Sebastian Stüker,\nAcoustic modelling for underresourced languages, Ph.D. thesis, Karlsruhe, Univ.,\nDiss., 2009, 2009.\n\n[14] Hagen Soltau, Hank Liao, and Hasim Sak, “Neural\nspeech recognizer: acoustic-to-word LSTM Model for\nlarge vocabulary speech recognition,” arXiv preprint\narXiv:1610.09975, 2016.\n\n[3] Tanja Schultz and Alex Waibel, “Polyphone decision\ntree specialization for language adaptation,” in Acoustics, Speech, and Signal Processing (ICASSP). IEEE,\n2000, vol. 3, pp. 1707–1710.\n\n[15] Kornel Laskowski, Mattias Heldner, and Jens Edlund,\n“The fundamental frequency variation spectrum,” in\nProceedings of the 21st Swedish Phonetics Conference\n(Fonetik 2008), Gothenburg, Sweden, June 2008, pp.\n29–32.\n\n[4] Pawel Swietojanski, Arnab Ghoshal, and Steve Renals, “Unsupervised cross-lingual knowledge transfer\nin DNN-based LVCSR,” in SLT. IEEE, 2012, pp. 246–\n251, IEEE.\n\n[16] Kjell Schubert, “Grundfrequenzverfolgung und deren\nanwendung in der spracherkennung,” M.S. thesis, Universität Karlsruhe (TH), Germany, 1999, In German.\n\n[5] Karel Vesely, Martin Karafiat, Frantisek Grezl, Milos Janda, and Ekaterina Egorova, “The languageindependent bottleneck features,” in Proceedings of\nthe Spoken Language Technology Workshop (SLT), 2012\nIEEE. 2012, pp. 336–341, IEEE.\n\n[17] John B Hampshire and Alex Waibel, “The Meta-Pi network: Building distributed knowledge representations\nfor robust multisource pattern recognitio,” IEEE Transactions on Pattern Analysis and Machine Intelligence,\nvol. 14, no. 7, pp. 751–769, 1992.\n\n[6] Frantisek Grézl, Martin Karafiát, and Karel Vesely,\n“Adaptation of multilingual stacked bottle-neck neural\nnetwork structure for new language,” in Acoustics,\nSpeech, and Signal Processing (ICASSP). IEEE, 2014,\npp. 7654–7658.\n\n[18] Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky,\nIlya Sutskever, and Ruslan R Salakhutdinov, “Improving neural networks by preventing co-adaptation of feature detectors,” arXiv preprint arXiv:1207.0580, 2012.\n\n[7] George Saon, Hagen Soltau, David Nahamoo, and\nMichael Picheny, “Speaker adaptation of neural network\nacoustic models using i-Vectors,” in ASRU. IEEE, 2013,\npp. 55–59.\n\n[19] Roberto Gretter, “Euronews: A multilingual benchmark\nfor ASR and LID,” in Fifteenth Annual Conference of\nthe International Speech Communication Association,\n2014.\n\n[8] Yajie Miao, Hao Zhang, and Florian Metze, “Towards\nspeaker adaptive training of deep neural network acoustic models,” 2014.\n\n[20] Marc Schröder and Jürgen Trouvain, “The German textto-speech synthesis system MARY: A tool for research,\ndevelopment and teaching,” International Journal of\nSpeech Technology, vol. 6, no. 4, pp. 365–377, 2003.\n\n[9] Hengguan Huang and Khe Chai Sim, “An investigation of augmenting speaker representations to improve\nspeaker normalisation for dnn-based speech recognition,” in ICASSP. IEEE, 2015, pp. 4610–4613.\n\n[21] Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton, “On the importance of initialization and\nmomentum in deep learning,” in Proceedings of the 30th\nInternational Conference on Machine Learning (ICML13), 2013, pp. 1139–1147.\n\n[10] Markus Müller and Alex Waibel, “Using language adaptive deep neural networks for improved multilingual\nspeech recognition,” IWSLT, 2015.\n[11] Markus Müller, Sebastian Stüker, and Alex Waibel,\n“Language adaptive DNNs for improved low resource\nspeech recognition,” in Interspeech, 2016.\n\n[22] Thomas Zenkel, Ramon Sanabria, Florian Metze, Jan\nNiehues, Matthias Sperber, Sebastian Stüker, and Alex\nWaibel, “Comparison of decoding strategies for CTC\nacoustic models,” arXiv preprint arXiv:1708.04469,\n2017.\n\n[12] Alex Graves, Santiago Fernández, Faustino Gomez, and\nJürgen Schmidhuber, “Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks,” in Proceedings of the 23rd international conference on Machine learning. ACM, 2006,\npp. 369–376.\n5\n\n\f",
         "train",
         "22376",
         "3393"
        ],
        [
         "1",
         "19680",
         "cs.AI",
         "Artificial Intelligence",
         "0311016v1.pdf",
         "Generic Program Monitoring\nby Trace Analysis⋆\nErwan Jahier1 and Mireille Ducassé2\n\narXiv:cs/0311016v1 [cs.PL] 14 Nov 2003\n\n1\n2\n\nVérimag, Centre Equation - 2 avenue de Vignate 38610 Gières\nIRISA/INSA, Campus Universitaire de Beaulieu, F-35042 Rennes cedex, France\n\nSummary. Program execution monitoring consists of checking whole executions\nfor given properties, and collecting global run-time information. Monitoring helps\nprogrammers maintain their programs. However, application developers face the\nfollowing dilemma: either they use existing monitoring tools which never exactly\nfit their needs, or they invest a lot of effort to implement relevant monitoring code.\nIn this article we argue that, when an event-oriented tracer exists, the compiler\ndevelopers can enable the application developers to easily code their own monitors.\nWe propose a high-level primitive, called foldt, which operates on execution traces.\nOne of the key advantages of our approach is that it allows a clean separation of\nconcerns; the definition of monitors is totally distinct from both the user source code\nand the language compiler. We give a number of applications of the use of foldt\nto define monitors for Mercury program executions: execution profiles, graphical\nabstract views, and test coverage measurements. Each example is implemented by\na few lines of Mercury.\n\nkeywords: monitoring, automated debugging, trace analysis, test coverage,\nMercury.\n\n1\n\nIntroduction\n\nProgram maintenance and trace analysis. Several experimental studies\n(e.g., [Hatton, 1997]) show that maintenance is the most expensive phase\nof software development: the initial development represents only 20 % of\nthe cost, whereas error fixing and addition of new features after the first\nrelease represent, each, 40 % of the cost. Thus, 80 % of the cost is due to the\nmaintenance phase.\nA key issue of maintenance is program understanding. In order to fix\nlogical errors, programmers have to analyze their program symptoms and\nunderstand how these symptoms have been produced. In order to fix performance errors, programmers have to understand where the time is spent\nin the programs. In order to add new functionality, programmers have to\nunderstand how the new parts will interact with the existing ones.\n⋆\n\nThis work has been partially sponsored by the Esprit project ARGO, Industrial\nRTD Project no 25503\n\n\f2\n\nErwan Jahier and Mireille Ducassé\n\nProgram analysis tools help programmers understand programs. For example, type checkers [Pfenning, 1992] help understand data inconsistencies.\nSlicing tools [Gallagher & Lyle, 1991,Tip, 1995] help understand dependencies among parts of a program. Tracers give insights into program executions\n[Eisenstadt & Brayshaw, 1988].\nSome program analysis tools automatically analyze program execution\ntraces. They can give very precise insights of program (mis)behavior. We\nhave shown how such trace analyzers can help users debug their programs.\nIn our automated debuggers, a trace query mechanism helps users check\nproperties of parts of traced executions in order to understand misbehavior\n[Ducassé, 1999a,Ducassé, 1999b,Jahier & Ducassé, 1999a].\nIn this article, we show that trace analysis can be pushed toward monitoring to further help understand program behavior. Whereas debuggers are\ntools that retrieve run-time information at specific program points, monitors\ncollect information relative to the whole program executions. For example,\nsome monitors gather statistics which help detect heavily used parts that\nneed to be optimized; other monitors build graphs (e.g., control flow graphs,\ndynamic call graphs, proof trees) that give a global understanding of the\nexecution.\nExecution monitoring. Monitors are trace analyzers which differ from debuggers. Monitoring is mostly a “batch” activity whereas debugging is mostly\nan interactive activity. In monitoring, a set of properties is specified beforehand; the whole execution is checked; and the global collected information is\ndisplayed. In debugging, the end-user is central to the process; he specifies\non the fly the very next property to be checked; each query is induced by\nthe user’s current understanding of the situation at the very moment it is\ntyped in. Monitoring is therefore less versatile than debugging. The properties specified for monitoring have a much longer lifetime, they are meant to\nbe used over several executions.\nIt is, nevertheless, impossible to foresee all the properties that programmers may want to check on executions. One intrinsic reason is that these\nproperties are often driven by the application domain. Therefore monitoring\nsystems must provide some genericity.\nExisting approaches to implement monitors. Unfortunately, monitors\nare generally implemented by ad hoc instrumentation. This instrumentation\nrequires a significant programming effort. When done at a low level, for example by modifying the compiler and the runtime system, it requires deep\nknowledge that mostly only the language compiler implementors have. However, the monitored information is often application-dependent, and application programmers or end-users know better what has to be monitored. But\ninstrumenting compilers is almost impossible for them.\nAn alternative to low-level instrumentation is source-level instrumentation; run-time behavior information can be extracted by source-to-source\n\n\fGeneric Program Monitoring by Trace Analysis\n\n3\n\ntransformation, as done for ML [Tolmach & Appel, 1995,Kishon et al., 1991]\nand Prolog [Ducassé & Noyé, 2000] for instance . Such instrumentation, although simpler than low-level compiler instrumentation, can still be too\ncomplex for most programmers. Furthermore, for certain new declarative\nprogramming languages like Mercury [Somogyi et al., 1996], instrumentation\nmay even be impossible. Indeed, in Mercury, the declarative semantics is simple and well defined, but the operational semantics is complex. For example,\nthe compiler reorders goals according to its needs. Furthermore, input and\noutput can be made only in deterministic predicates. This complicates code\ninstrumentation.\nThus, ad hoc instrumentation is tedious at a low level and it may be\nimpossible at a high level. On the other hand, the difficult task of instrumenting the code to extract run-time information has, in general, already\nbeen achieved to provide a debugger. Debuggers, which help users locate\nfaults in programs are based on tracers. These tracers generate execution\ntraces which provide a precise and faithful image of the operational semantics of the traced language. These traces often contain sufficient information\nto base monitors upon them.\nOur Proposal. In this article, we propose a high-level primitive built on\ntop of an event oriented execution tracer. The proposed monitoring primitive,\ncalled foldt, is a fold which operates on a list of events.\nAn event oriented trace is a sequence of events. An event is a tuple of\nevent attributes. An event attribute is an elementary piece of information\nthat can be extracted from the current state of the program execution. Thus,\na trace can be seen as a sequence of tuples of a database ordered by time.\nMany tracers are event-oriented: for example, Prolog tracers based on Byrd\nbox model [Byrd, 1980], tracers for C such as Dalek [Olsson et al., 1990] and\nCoca [Ducassé, 1999a], the Egadt tracer for Pascal [Fritzson et al., 1994], the\nEsa tracer for Ada [Howden & Shi, 1996], and the Ebba tracer for distributed\nsystems [Bates, 1995].\nOne of the key advantages of our approach is that it allows a clean separation of concerns; the definition of the monitors is totally distinct from both\nthe user source code and the language compiler.\nWe have implemented foldt on top of the Mercury trace. We give a\nnumber of applications of the foldt operator to compute various monitors:\nexecution profiles, graphical abstract views, and test coverage measurements.\nEach example is implemented by a few lines of Mercury which can be written by any Mercury programmer. These applications show that the Mercury\ntrace, indeed, contains enough information to build a wide variety of interesting monitors. Detailed measurements show that, under some requirements,\nfoldt can have acceptable performance for executions of several millions of\nexecution events. Therefore our operator lays the foundation for a generic\nand powerful monitoring environment. The proposed scheme has been inte-\n\n\f4\n\nErwan Jahier and Mireille Ducassé\n\ngrated into the Mercury environment. It is fully operational and part of the\nMercury distribution.\nNote that we have implemented the foldt operator on top of Mercury\nmostly for historical reasons. We acknowledge that some of the monitors\nwere particularly easy to write thanks to the neatness of Mercury libraries,\nin particular the set library (e.g., Figure 10). Nevertheless, foldt could be\nimplemented for any system with an event-oriented tracer.\nPlan. In Section 2, we introduce the foldt operator and describe its current\nimplementation on top of the Mercury tracer. In Section 3, we illustrate the\ngenericity of foldt with various kinds of monitors. All the examples are\npresented at a level of detail that does not presuppose any knowledge of\nMercury. Section 4 discusses performance issues of foldt. Section 5 compares\nour contribution with related work. A thorough description of the Mercury\ntrace can be found in Appendix A. Appendix B lists a Mercury program\nsolving the n queens problem, which is used at various places in the article\nas an input for our monitors.\n\n2\n\nA high-level trace processing operator: foldt\n\nIn this section, we first define the foldt operator over a general trace in\na language-independent manner. We describe an implementation of this operator for Mercury program executions, and then present its current user\ninterface.\n2.1\n\nLanguage independent foldt definition\n\nA trace is a list of events; analyzing a trace therefore requires to process such\na list. The standard functional programming operator fold encapsulates a\nsimple pattern of recursion for processing lists. It takes as input arguments\na function, a list, and an initial value of an accumulator; it outputs the final\nvalue of the accumulator; this final value is obtained by successively applying\nthe function to the current value of the accumulator and each element of the\nlist. As demonstrated by Hutton [Hutton, 1999], fold has a great expressive\npower for processing lists. Therefore, we propose a fold-like operator to\nprocess execution traces; we call this operator foldt.\nBefore defining foldt, we define the notions of event and trace for sequential executions.\nDefinition 1. (Execution event, Event attributes, Execution trace)\nAn execution event is an element of the Cartesian product E = A1 × ... × An ,\nwhere Ai for i ∈ {1, ..., n} are arbitrary sets called event attributes. An execution trace is a (finite or infinite) sequence of execution events; the set of all\nexecution traces is denoted by T. We note |t| the size (its number of events)\nof a finite trace t ∈ T and |t| = ∞ the size of infinite traces.\n\n\fGeneric Program Monitoring by Trace Analysis\n\n5\n\nThe following definition of foldt is a predicative definition of a fold\noperating on a finite number of events of a (possibly infinite) trace. The set\nof predicates over τ1 × ... × τn is denoted by pred(τ1 , ..., τn ).\nDefinition 2. (foldt)\nA foldt monitor of type τ ×τ ′ is a 3-tuple : (init, collect, post process) ∈\npred(τ ) × pred(E, τ, τ ) × pred(τ, τ ′ ) such that: ∀t = (ei )i>0 ∈ T, either\nn+1\n(1) |t| < ∞ ∧ (∃!(V\n.\nV0n, ..., Vn ) ∈ τ\n(init(V0 ) i=1 collect(ei , Vi−1 , Vi ) ∧ post process(Vn , Res)))\nn+1\n(2) ∃!n < |t|, ∃!(V0 , ...,\n, ∀x ∈ τ.\nVnVn ) ∈ τ\n(init(V0 ) ∧ i=1 collect(ei , Vi−1 , Vi ) ∧ post process(Vn , Res)\n∧ ¬collect(en+1 , Vn , x))\nRes is called the result of the monitor (init, collect, post process) on trace\nt. We use the notation ∃!n to mean that there exists a unique n, and (ei )i>0\nfor the sequence (in the mathematical sense) e1 , e2 , e3 , ....\n\nOperationally, an accumulator of type τ is used to gather the collected\ninformation. It is first initialized (V0 ). The predicate collect is then applied to each event of the trace in turn, updating the accumulator along\nthe way (Vi ). There are two ways to stop this process: (1) the folding process stops when the end of the execution is reached if the trace is finite\n(|t| < ∞); (2) if collect fails before the end of the execution is reached\n(∀x ∈ τ. (¬collect(en+1 , Vn , x))). In both cases, the last value of the accumulator (Vn ) is processed by post process, which returns a value (Res) of\ntype τ ′ (post process(Vn , Res)).\nNote that this definition holds for finite and infinite traces (thanks to the\nsecond case of Definition 2). This is convenient to analyze programs that run\npermanently. The ability to end the foldt process before the end of the execution is also convenient to analyze executions part by part as explained in\nSection 2.3. A further interesting property, which is useful to execute several\nmonitors in a single program execution, is the possibility to simultaneously\napply several fold on the same list using a tuple of fold [Bird, 1987]; in\nother words:\nfoldt(i1 , c1 , p1 ) × ... × foldt(in , cn , pn ) =\nfoldt(i1 × ... × in , c1 × ... × cn , p1 × ... × pn )\nwhere:\n∀a1 , ..., an ∈ τ1 × ... × τn ,\ni1 × ... × in (a1 , ..., an ) ⇔ i1 (a1 ) ∧ ... ∧ in (an ),\n∀e ∈ E, ∀a1 , ..., an ∈ τ1 × ... × τn , ∀a′1 , ..., a′n ∈ τ1′ × ... × τn′ ,\nc1 × ... × cn (e, a1 , ..., an , a′1 , ..., a′n ) ⇔ c1 (e, a1 , a′1 ) ∧ ... ∧ cn (e, an , a′n ),\n∀a1 , ..., an ∈ τ1 × ... × τn ,\np1 × ... × pn (a1 , ..., an , a′1 , ..., a′n ) ⇔ p1 (a1 , a′1 ) ∧ ... ∧ pn (an , a′n ).\n\n\f6\n\nErwan Jahier and Mireille Ducassé\n\n2.2\n\nAn implementation of foldt for Mercury\n\nWe prototyped an implementation of foldt for the Mercury programming\nlanguage. After a brief presentation of Mercury and its trace system, we\ndescribe our foldt implementation.\nMercury and its trace Mercury [Somogyi et al., 1996] is a logic and functional programming language. The principal differences with Prolog are as\nfollows. Mercury supports functions and higher-order terms. Mercury programs are free from side-effects; even input and output are managed in a\ndeclarative way. Mercury strong type, mode and determinism system allows\na lot of errors to be caught at compile time, and a lot of optimizations to be\ndone.\nThe trace generated by the Mercury tracer [Somogyi & Henderson, 1999]\nis adapted from Byrd box model [Byrd, 1980]. Its attributes are the event\nnumber, the call number, the execution depth, the event type (or port), the\ndeterminism, the procedure (defined by a module name, a name, an arity\nand a mode number), the live arguments, the live non-argument variables,\nand the goal path. A detailed description of these attributes together with\nan example of event is given in appendix A.\nThe foldt implementation An obvious and simple way to implement\nfoldt would be to store the whole trace into a single list, and then to apply a\nfold to it. This naive implementation is highly inefficient, both in time and in\nspace. It requires creating and processing a list of possibly millions of events.\nMost of the time, creating such a list is simply not feasible because of memory\nlimitations. With the current Mercury trace system, several millions of events\nare generated each second, each event requiring several bytes. To implement\nrealistic monitors, run-time information needs to be collected and analyzed\nsimultaneously (on the fly), without explicitly creating the trace.\nIn order to achieve analysis on the fly, we have implemented foldt by\nmodifying the Mercury trace system, which works as follows: when a program\nis compiled with tracing switched on, the generated C code1 is instrumented\nwith calls to the tracer (via the C function trace). Before the first event\n(resp. after the last one), a call to an initialization C function trace init\n(resp. to a finalization C function trace final) is inserted.\nWhen the trace system is entered through either one of the functions\ntrace, trace init, or trace final, the very first thing it does is to look at\nan environment variable that tells whether the Mercury program has been\ninvoked from a shell, from the standard Mercury debugger (mdb), or from another debugger (e.g., Morphine [Jahier & Ducassé, 1999a]). We have added a\nnew possible value for that environment variable which indicates whether the\n1\n\nCurrently, the only Mercury back-end that has a tracer is one that relies on a C\ncompiler to produce its executable code.\n\n\fGeneric Program Monitoring by Trace Analysis\n\n7\n\nprogram has been invoked by foldt. In that case, the trace init function\ndynamically links the Mercury program under execution with the object file\nthat contains the object code of collect, initialize, and post process.\nDynamically linking the program to its monitor is very convenient because\nneither the program nor the monitor need to be recompiled.\nOnce the monitor object file has been linked with the program, the C\nfunction trace init can call the procedure initialize to set the value of a\nglobal variable accumulator variable (of type τ ). At each event, the C function trace calls the procedure collect which updates accumulator variable.\nIf collect fails or if the last event is reached, the C function trace final\ncalls the procedure post process with accumulator variable and returns\nthe new value of this accumulator (now of type τ ′ ).\n2.3\n\nThe current user interface of foldt for Mercury\n\nIn this Section, we first describe what the user needs to do in order to define\na monitor with foldt. Then, we show how this monitor can be invoked.\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n% 1 - Define the type of the accumulator:\n:- type accumulator_type == < A Mercury type >.\n% 2 - Initialize the accumulator:\ninitialize(Accumulator) :< Mercury goals which initialize the accumulator >.\n% 3 - Update the accumulator:\ncollect(Event, AccumulatorIn, AccumulatorOut) :< Mercury goals which update the accumulator >.\n% 4 - Optionally, post-process the last value of the accumulator:\n:- type collected_type == < A Mercury type >.\npost_process(Accumulator, FoldtResult) :< Mercury goals which post-process the accumulator >.\nFig. 1. What the user needs to define to use foldt\n\nDefining monitors We chose Mercury to be the language in which users\ndefine the foldt monitors to monitor Mercury programs. As a matter of fact,\nit could have been any other language that has an interface with C, since the\ntrace system of Mercury is written in C. The choice of Mercury, however, is\nquite natural; people who want to monitor Mercury programs are likely to\nbe Mercury programmers.\n\n\f8\n\nErwan Jahier and Mireille Ducassé\n\nThe items users need to implement in order to define a foldt monitor are\ngiven in Figure 1. Lines preceded by ‘%’ are comments. First of all, since Mercury is a typed language, one first needs to define the type of the accumulator\nvariable accumulator type (line 2). Then, one needs to define initialize\nwhich gives the initial value of the accumulator, and collect which updates\nthe accumulator at each event(line 9). Optionally, one can also define the\npost process predicate which processes the last value of the accumulator.\npost process takes as input a variable of type accumulator type (τ ) and\noutputs a variable of type collected type (τ ′ ). If collected type is not\nthe same type as accumulator type, then one needs to provide its definition too (line 13). Types and modes of predicates initialize, collect and\npost process should be consistent with the following Mercury declarations:\n:- pred initialize(accumulator type::out) is det.\n:- pred collect(event::in, accumulator type::in,\naccumulator type::out) is semidet.\n:- pred post process(accumulator type::in, collected type::out)\nis det.\nThese declarations state that initialize is a deterministic predicate (is\ndet), namely it succeeds exactly once, and it outputs a variable of type\naccumulator type; collect is a semi-deterministic predicate, namely it succeeds at most once, and it takes as input an event and an accumulator. If\ncollect fails, the monitoring process stops at the current event. This can be\nvery useful, for example to stop the monitoring process before the end of the\nexecution if the collecting data is too large, or to collect data part by part\n(e.g., collecting the information by slices of 10000 events). This also allows\nfoldt to operate over non-terminating executions.\nThe type event is a structure made of all the event attributes. To access\nthese attributes, we provide specific functions which types and modes are:\n“:- func <attribute_name>(event::in) = <attribute_type>::out.”,\nwhich takes an event and returns the event attribute corresponding to its\nname. For example, the function call depth(Event) returns the depth of\nEvent. The complete list of attribute names is given in Appendix A.\nFigure 2 shows an example of monitor that counts the number of predicate invocations (calls) that occur during a program execution. We first\nimport library module int (line 1) to be able to manipulate integers. Predicate initialize initializes the accumulator to ‘0’ (line 3). Then, for every\nexecution event, collect increments the counter if the event port is call,\nand leaves it unchanged otherwise (line 5). Since collect can never fail here,\nthe calls to collect proceed until the last event of the execution is reached.\nNote that those five lines of code constitute all the necessary lines for\nthis monitor to be run. For the sake of conciseness, in the following figures\ncontaining monitors, we sometimes omit the module importation directives\nas well as the type of the accumulator when the context makes them clear.\n\n\fGeneric Program Monitoring by Trace Analysis\n1\n2\n3\n4\n5\n\n9\n\n:- import_module int.\n:- type accumulator_type == int.\ninitialize(0).\ncollect(Event, C0, C) :if port(Event) = call then C = C0+1 else C = C0.\nFig. 2. count call, a monitor that counts the number of calls using foldt\n\nInvoking foldt Currently, foldt can be invoked from a Prolog query loop\ninterpreter. We could not use Mercury for that purpose because there is no\nMercury interpreter yet.\nWe have implemented a Prolog predicate named run mercury, which\ntakes a Mercury program call as argument, and which forks a process in\nwhich this Mercury program runs in coroutining with the Prolog process.\nThe two processes communicate via sockets. When the first event of the Mercury program is reached, the hand is given to the Prolog process which waits\nfor a foldt query.\nThe command foldt has two arguments; the first one should contain\nthe name of the file defining the monitor to be run; the second one is a\nvariable that will be unified with the result of the monitor. When foldt is\ninvoked, (1) the file containing the monitor is used to automatically produce a\nMercury module named foldt.m (by adding the declarations of initialize,\ncollect, and post process, as well as the definitions of the event type\nand the attribute accessing functions); (2) foldt.m is compiled, producing\nthe object file foldt.o; (3) foldt.o is dynamically linked with the Mercury\nprogram under coroutining. Of course, steps (1) and (2) are only performed\nif the file containing the monitor is newer than the object file foldt.o.\nA monitor stops either because the end of the execution is reached, or\nbecause the collect predicate failed; in the latter case, the current event\n(i.e., the event the next query will start at) is the one occurring immediately\nafter the event where collect failed.\n\n[morphine]: run_mercury(queens), foldt(count_call, Result).\nA 5 queens solution is [1, 3, 5, 2, 4]\nLast event of queens is reached\nResult = 146\nMore? (;)\n[morphine]:\n\nFig. 3. Invoking foldt monitor of Figure 2 from an interpreter\n\nA possible session for invoking the monitor of Figure 2 is given in Figure 3.\nAt the right-hand side of the ‘[morphine]:’ prompt, there are the characters\n\n\f10\n\nErwan Jahier and Mireille Ducassé\n\ntyped in by a user. The line in italic is output by the Mercury program; all\nthe other lines are output by the Prolog process. We can therefore see that\nthe program queens (which solves the 5 queens problem, cf Appendix B)\nproduces 146 procedure calls.\n\nIllustration of the advantage of calling foldt from a Prolog query\nloop Being able to call foldt from a Prolog interpreter loop enables users to\nwrite scripts that control several foldt invocations. Figures 4 and 5 illustrate\nthis. The monitor of Figure 4 computes the maximal depth for the next 500\nevents. In the session of Figure 5, a user (via the [user]. directive) defines\nthe predicate print max depth that calls the monitor of Figure 4 and prints\nits result in loop until the end of the execution is reached. This is useful for\nexample for a program that runs out of stack space to check whether this is\ndue to a very deep execution and to know at which events this occurs.\nNote that the fact that the monitor is dynamically linked with the monitored program has an interesting side-effect here: one can change the monitor\nduring the foldt query resolution (by modifying the file where this monitor is defined). Indeed, in our example, one could change the interval within\nwhich the maximal depth is searched from 500 to 100. The monitor would\nbe (automatically) recompiled, but the foldt query would not need to be\nkilled and rerun. This can be very helpful to monitor a program that runs\npermanently; the monitored program is simply suspended while the monitor\nis recompiled.\n\n1\n2\n3\n4\n\ninitialize(acc(0, 0)).\ncollect(Event, acc(N0, D0), acc(N0+1, max(D0, depth(Event)))) :N0 < 500. % stops after 500 events\n\nFig. 4. Monitor that computes the maximal execution depth by interval of 500\nevents\n\nAs a matter of fact (as the prompt suggests), the Prolog query loop that\nwe use is Morphine [Jahier & Ducassé, 1999a], an extensible debugger for\nMercury “à la Opium” [Ducassé, 1999b]. The basic idea of Morphine is to\nbuild on top of a Prolog query loop a few coroutining primitives connected to\nthe trace system (like foldt). Those primitives let one implement all classical\ndebugger commands as efficiently as their hand-written counter-parts; the\nadvantage is, of course, that they let users implement more commands than\nthe usual hard-coded ones, fitting their own needs.\nInvoking foldt from a debugger has a further advantage; it makes it very\neasy to call a monitor during a debugging session, and vice versa. Indeed,\n\n\fGeneric Program Monitoring by Trace Analysis\n\n11\n\n[morphine]: [user].\nprint_max_depth :foldt(max_depth, acc(_, MaxDepth)),\nprint(\"The maximal depth is \"), print(MaxDepth), nl,\nprint_max_depth.\n^D\n[morphine]: run_mercury(qsort), print_max_depth.\nThe maximal depth is 54\nThe maximal depth is 28\nThe maximal depth is 50\n[0, 2, 4, 6, 7, 8, ..., 94, 95, 99, 99]\nLast event of qsort is reached\nThe maximal depth is 53\n[morphine]:\nFig. 5. A possible session using the monitor of Figure 4\n\nsome monitors are very useful for understanding program runtime behavior,\nand therefore can be seen as debugging tools.\n\n3\n\nApplications\n\nIn this section, we describe various execution monitors that can be implemented with foldt. We first give monitors which compute three different\nexecution profiles: number of events at each port, number of goal invocations\nat each depth, and sets of solutions. Then, we describe monitors that produce\ntwo types of execution graphs: dynamic control flow graph and dynamic call\ngraph. Finally, we introduce two test coverage criteria for logic programs, and\nwe give the monitors that measure them.\n3.1\n\nExecution profiles\n\nCounting the number of events at each port In Figure 2, we have\ngiven a monitor that counts the number of goal invocations. Figure 6 shows\nhow to extend this monitor to count the number of events at each port.\nWe need 5 counters that we store in an array. In the current implementation of foldt, the default mode of the second and third argument of\ncollect, respectively equal to in and out, can be overridden; here, we override them with array di and array uo (lines 4 and 5). Modes array di and\narray uo are special modes that allow arrays to be destructively updated.\nPredicate initialize creates an array Array of size 5 with each element\ninitialized to 0 (line 8). Predicate collect extracts the port from the cur-\n\n\f12\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\nErwan Jahier and Mireille Ducassé\n:- import_module int, array.\n:- type accumulator_type == array(int).\n:- mode acc_in :: array_di.\n:- mode acc_out :: array_uo.\ninitialize(Array) :init(5, 0, Array).\ncollect(Event, Array0, Array) :Port = port(Event),\nport_to_int(Port, IntPort),\nlookup(Array0, IntPort, N),\nset(Array0, IntPort, N+1, Array).\n:- pred port_to_int(port::in, int::out) is det.\nport_to_int(Port, Number) :( if\nPort = call then Number = 0\nelse if Port = exit then Number = 1\nelse if Port = redo then Number = 2\nelse if Port = fail then Number = 3\nelse Number = 4 ).\nFig. 6. A monitor that counts the number of events at each port\n\nrent event (line 11) and converts it to an integer (line 12)2 . This integer\nis used as an index to get (lookup/3) and set (set/4) array values. The\ngoal lookup(Array0, IntPort, N) returns in N the IntPortth element of\nArray0. The goal set(Array0, IntPort, N+1, Array) sets the value N+1\nin the IntPortth element of Array0 and returns the resulting array in Array.\nCounting the number of calls at each depth Figure 7 implements a\nmonitor that counts the number of calls at each depth. Predicate initialize\ncreates an array of size 32 with each element initialized to 0 (line 4). At call\nevents (line 7), predicate collect extracts the depth from the current event\n(line 8) and increments the corresponding counter (lines 10 and 14). Whenever the upper bound of the array is reached, i.e., whenever semidet lookup/4\nfails (line 9), the size of the array is doubled (lines 13).\nCollecting solutions The monitor of Figure 8 collects the solutions produced during the execution. We define the type solution as a pair containing\na procedure and a list of arguments (line 1). The collected variable is a list\n2\n\nAs a matter of fact, there are more ports than the ones handled by port to int/2\nin Figure 6 (cf Appendix A); we ignore them here for the sake of conciseness.\n\n\fGeneric Program Monitoring by Trace Analysis\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n% Module importation and accumulator type (array of int) omitted\ninitialize(Acc) :init(32, 0, Acc).\ncollect(Event, Acc0, Acc) :( if port(Event) = call then\nDepth = depth(Event),\n( if semidet_lookup(Acc0, Depth, N) then\nset(Acc0, Depth, N+1, Acc)\nelse\nsize(Acc0, Size),\nresize(Acc0, Size*2, 0, Acc1),\nset(Acc1, Depth, 1, Acc)\n)\nelse\nAcc = Acc0\n).\nFig. 7. A monitor that counts the number of calls at each depth\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n:- type solution ---> proc_name/arguments.\n:- type accumulator_type == list(solution).\ninitialize([]).\ncollect(Event, AccIn, AccOut) :( if\nport(Event) = exit,\nSolution = proc_name(Event)/arguments(Event),\nnot(member(Solution, AccIn))\nthen\nAccOut = [Solution | AccIn]\nelse\nAccOut = AccIn\n).\nFig. 8. A monitor that collects all the solutions\n\n13\n\n\f14\n\nErwan Jahier and Mireille Ducassé\n\nof solutions (line 2), which is initialized to the empty list (line 4). If the\ncurrent port is exit (line 8) and if the current solution has not been already\nproduced (lines 9,10), then the current solution is added to the list of already\ncollected solutions (line 12).\nNote that for large programs, it would be better to use a table from\npredicate names to set of solutions instead of lists.\n3.2\n\nGraphical abstract views\n\nOther execution abstract views that are widely used and very useful in\nterms of program understanding are given in terms of graphs. In the following, we show how to implement monitors that generate graphical abstractions of program executions such as control flow graphs and dynamic call\ngraphs. We illustrate the use of these monitors by applying them to the 5\nqueens program given in Appendix B. This 100 line program generates 698\nevents for a board of 5 × 5. In this article, we use the graph drawing tool\ndot [Koutsofios & North, 1991]. More elaborated visualization tools such as\nin [Stasko et al., 1998] would be desirable, especially for large executions.\nThis is, however, beyond the scope of this article.\n\nuser/0\n\nmain/2\n\ndata/1\n\nqueen/2\n\nprint_list/3\n\nprint_list_2/3\n\nqperm/2\n\nsafe/1\n\nqdelete/3\n\nnodiag/3\n\nFig. 9. The dynamic control flow graph of 5 queens\n\nDynamic control flow graphs We define the dynamic control flow graph\nof a logic program execution as the directed graph where nodes are predicates\n\n\fGeneric Program Monitoring by Trace Analysis\n\n15\n\nof the program, and arcs indicate that the program control flow went from\nthe origin to the destination node. The dynamic control flow graph of the\n5 queens program is given in Figure 9. We can see, for example, that, during\nthe program execution, the control moves from predicate main/2 to predicate\ndata/1, from predicate data/1 to predicate data/1 and predicate queen/2.\nNote that such a graph (or variants of it) is primarily useful for tools and\nonly secondarily for humans.\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n::::-\n\ntype\ntype\ntype\ntype\n\npredicate ---> proc_name/arity.\narc ---> arc(predicate, predicate).\ngraph == set(arc).\naccumulator_type ---> collected_type(predicate, graph).\n\ninitialize(collected_type(\"user\"/0, set__init)).\ncollect(Event, Acc0, Acc) :Port = port(Event),\n( if (Port = call ; Port = exit ; Port = fail ; Port = redo) then\nAcc0 = collected_type(PreviousPred, Graph0),\nCurrentPred = proc_name(Event) / proc_arity(Event),\nArc = arc(PreviousPred, CurrentPred),\nset__insert(Graph0, Arc, Graph),\nAcc = collected_type(CurrentPred, Graph)\nelse\n% other events\nAcc = Acc0\n).\nFig. 10. A monitor that calculates dynamic control flow graphs\n\nAn implementation of a monitor that produces such a graph is given in\nFigure 10. Graphs are encoded by a set of arcs, and arcs are terms composed of\ntwo predicates (lines 1 to 3). The collecting variable is composed of a predicate\nand a graph (line 4); the predicate is used to remember the previous node.\nThe collecting variable is initialized with the fake predicate user/0, and the\nempty graph (line 6). At call, exit, redo, and fail events (line 10), we\ninsert in the graph an arc from the previous predicate to the current one\n(lines 11 to 14).\nNote that in our definition of dynamic control flow graph, the number\nof times each arc is traversed is not given. Even if the control goes between\ntwo nodes several times, only one arc is represented. One can imagine a\nvariant where, for example, arcs are labeled by a counter; one just needs to\nuse multi-sets instead of sets. The result of such a variant applied to the 5\nqueens program is displayed Figure 11. Note that here, the queens program\nwas linked with a version of the library that has been compiled without trace\n\n\f16\n\nErwan Jahier and Mireille Ducassé\n\nuser/0\n1\nmain/2\n1\ndata/1\n1\n\n1\n1\n\nqueen/2\n1\nprint_list/3\n1\n\n1\n1\n\n1\n\nprint_list_2/3\n\n11\n9\n\nsafe/1\n17\n\nqperm/2\n\n126\n\n10\n\n47\n\n8\n\n47\n\nqdelete/3\n\n117\n\n17\n\nnodiag/3\n\n63\n\nFig. 11. The dynamic control flow graph of 5 queens annotated with counters\n\ninformation. This is the reason why one should not be surprised not to see\nany call to, e.g, io write string/3 in this figure.\nDynamic call graphs A static call graph of a program is a graph where the\nnodes are labeled by the predicates of the program, and where arcs between\nnodes indicate potential predicate calls. We define the dynamic call graph of a\nlogic program execution as the sub-graph of the (static) call graph composed\nof the arcs and nodes that have actually been traversed during the execution.\nFor example, in Figure 12, we can see that predicate main/2 calls predicates\ndata/1, queen/2, and print list/2. In this particular example, the static\nand dynamic call graphs are identical.\nAn implementation of a monitor that builds the dynamic call graphs is\ngiven in Figure 13. In order to define this monitor, we use the same data\nstructures as for the previous one, except that we replace the last traversed\npredicate by the whole call stack in the collected variable type (line 2). This\nstack is necessary in order to be able to get the direct ancestor of the current\npredicate. The set of arcs is initialized to the empty set (lines 4) and the stack\nis initialized to a stack that contains a fake node user/0 (line 5). In order\n\n\fGeneric Program Monitoring by Trace Analysis\n\n17\n\nuser / 0\n\nmain / 2\n\nqueen / 2\n\nsafe / 1\n\nqperm / 2\n\nnodiag / 3\n\nqdelete / 3\n\nprint_list / 3\n\ndata / 1\n\nprint_list_2 / 3\n\nFig. 12. The dynamic call graph of 5 queens\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n% Definition of pred, arc, and graph types omitted (cf previous monitor)\n:- type accumulator_type ---> ct(stack(predicate), graph).\ninitialize(ct(Stack, set__init)) :stack__push(stack__init, \"user\"/0, Stack).\ncollect(Event, ct(Stack0, Graph0), Acc) :Port = port(Event),\nCurrentPred = proc_name(Event) / proc_arity(Event),\nupdate_call_stack(Port, CurrentPred, Stack0, Stack),\n( if Port = call then\nPreviousPred = stack__top_det(Stack0),\nset__insert(Graph0, arc(PreviousPred, CurrentPred), Graph),\nAcc = ct(Stack, Graph)\nelse\nAcc = ct(Stack, Graph0) ).\n:- pred update_call_stack(trace_port_type::in, predicate::in,\nstack(predicate)::in, stack(predicate)::out) is det.\nupdate_call_stack(Port, CurrentPred, Stack0, Stack) :( if ( Port = call ; Port = redo ) then\nstack__push(Stack0, CurrentPred, Stack)\nelse if ( Port = fail ; Port = exit ; Port = exception ) then\nstack__pop_det(Stack0, _, Stack)\nelse % other events\nStack = Stack0 ).\nFig. 13. A monitor that computes dynamic call graphs\n\n\f18\n\nErwan Jahier and Mireille Ducassé\n\nto construct the set of arcs, we insert at call events an arc from the previous\npredicate to the current one (line 12). The call stack is maintained on the\nfly by the update call stack/4 predicate; the current predicate is pushed\nonto the stack at call and redo events (line 22), and popped at exit, fail,\nand exception events (line 24). The result of the execution of this monitor\napplied to the 5 queens program is displayed in Figure 12.\nNote that the call stack is actually available in the Mercury trace. We have\nintentionally not use it here for didactical purpose in order to demonstrate\nhow this information can easily (but not cheaply!) be reconstructed on the\nfly.\n3.3\n\nTest coverage\n\nIn this section, we define two notions of test coverage for logic programs,\nand we show how to measure the corresponding coverage rate of Mercury\nprogram executions using the foldt primitive. The aim here is not to provide the ultimate definition of test coverage for logic programs, but rather\nto propose two possible definitions, and to show how the corresponding coverage rate measurements can be quickly prototyped. As a consequence, the\nproposed monitors cannot pretend to be optimal either in functionality, or in\nimplementation.\nTest coverage and logic programs The aim of test coverage is to assess\nthe quality of a test suite. In particular, it helps to decide whether it is necessary to generate more test cases or not. For a given coverage criterion, one\ncan decide to stop testing when a certain percentage of coverage is reached.\nThe usual criterion used for imperative languages are instruction and\nbranch criteria [Beizer, 1990]. The instruction coverage rate achieved by a\ntest suite is the percentage of instructions that have been executed. The\nbranch coverage rate achieved by a test suite is the percentage of branches\nthat have been traversed during its execution.\nOne of the weaknesses of instruction and branch coverages is due to\nBoolean expressions. The problem occurs when a Boolean expression is composed by more than one atomic instruction: it may be that a test suite covers\neach value of the whole condition without covering all values of each atomic\npart of the condition. For example, consider the condition ‘A or B’ and a test\nsuite where the two cases ‘A = true, B = f alse’ and ‘A = f alse, B = f alse’\nare covered. In that case, every branch and every instruction is exercised,\nand nevertheless, B never succeeded. If B is erroneous, even 100% instruction and branch coverage will miss it. Whereas in imperative programs, you\nget conditional branches only in the conditions of if-then-else and loops, in\nlogic programs you get them at every unification and call (whose determinism\nallows failure); therefore this issue is crucial for logic programs.\n\n\fGeneric Program Monitoring by Trace Analysis\n\n19\n\nPredicate coverage In order to address the above problem, we need a coverage criterion that checks that each single predicate defined in the tested\nprogram succeeds and fails a given number of times. But we do not want\nto expect every predicate to fail because some, like printing predicates, are\nintrinsically deterministic. Therefore, we want a criterion that allows the\ntest designer to specify how many times a predicate should succeed and fail.\nTherefore we define a predicate criterion as a pair composed of a predicate\nand a list of exit and fail. In the case of Mercury, we can take advantage of\nthe determinism declaration to automatically determine if a predicate should\nsucceed and fail. Here is an example of predicate criterion that can be automatically defined according to the determinism declaration of each predicate:\n‘det’ predicates:\n1\n‘semidet’ predicates: 1\n‘multi’ predicates: 2\n‘nondet’ predicates: 2\n\nsuccess\nsuccess, 1 failure\nsuccesses\nsuccesses, 1 failure\n\nThen, we define the predicate coverage rate of a logic program test suite\nas the percentage of program predicate criteria that are covered during the\nexecution of the suite. To compute that rate, one just needs to look at exit\nand fail events to see which criterion is covered.\nFigure 14 shows a foldt monitor that measures the predicate coverage\nrate of the queens program. The accumulator variable is a table (map) from\nprocedure name to predicate criterion (line 2). A predicate criterion is represented by a list of exit and fail events; the type pred crit also contains\na list of call numbers (line 1), initially empty (lines 6 to 14). They are used\nto remember encountered exits (lines 37 to 43). Indeed, if an execution produces two exit events for a predicate, it does not mean that a given call of\nthis predicate has succeeded twice; it can be due to another call, for example\nrecursive. Hence, we can remove an exit atom from the list of ports to be\ncovered only if, either it is the first time the predicate exits (line 24), or if the\ncurrent call number has been encountered before (line 28). Symmetrically,\nsince all multi and nondet predicates that are called end up with a fail\nevent, a failure can be considered as covered only if no exit events occurred\nfor the current call number before (lines 24 and 30).\nThe current distribution of Morphine3 have support to automatically generate such monitors, run them, and compute the coverage percentage. Monitors are generated by parsing the source files in order to get the procedure\ndeterminisms that are necessary to be able to produce the right number of\nexit and fail atoms.\n3\n\ncf the file extras/morphine/source/generate pred cov.m and the pred cov\nMorphine command (both in extras.tgz available on the Mercury ftp and web\nsites).\n\n\f20\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n\nErwan Jahier and Mireille Ducassé\n\n:- type pred_crit ---> pc(list(call_number), list(port)).\n:- type accumulator_type == map(proc_name, pred_crit).\ninitialize(Map) :map__init(Map0),\nmap__det_insert(Map0,\nmap__det_insert(Map1,\nmap__det_insert(Map2,\nmap__det_insert(Map3,\nmap__det_insert(Map4,\nmap__det_insert(Map5,\nmap__det_insert(Map6,\nmap__det_insert(Map7,\nmap__det_insert(Map8,\n\n\"main\",\npc([], [exit]), Map1),\n\"data\",\npc([], [exit]), Map2),\n\"print_list\", pc([], [exit]), Map3),\n\"print_list_2\",pc([], [exit]), Map4),\n\"safe\",\npc([], [exit,fail]), Map5),\n\"nodiag\", pc([], [exit,fail]), Map6),\n\"qperm\", pc([], [exit,exit,fail]), Map7),\n\"qdelete\",pc([], [exit,exit,fail]), Map8),\n\"queen\", pc([], [exit,exit,fail]), Map).\n\ncollect(Event, Map0, Map) :Port = port(Event), Proc = proc_name(Event), CallN = call(Event),\n( if\n(Port = exit ; Port = fail), pc(CNL0, PL0) = map__search(Map0, Proc)\nthen\n( if\nCNL0 = []\nthen\nremove_port(Port, PL0, PL)\nelse if\nmember(CallN, CNL0)\nthen\n(if Port = exit then remove_port(exit, PL0, PL) else PL = PL0)\nelse % not member(CallN, CNL0) and not (CNL0 = [])\n(if Port = exit then PL = PL0 else remove_port(fail, PL0, PL))\n),\n( if\nPL = []\nthen\nmap__delete(Map0, Proc, Map)\nelse\n( if\nPort = exit, not member(CallN, CNL0)\nthen\nCNL = [CallN | CNL0]\nelse\nCNL = CNL0\n),\nmap__update(Map0, Proc, pc(CNL, PL), Map))\nelse\nMap = Map0 ).\n:- pred remove_port(port::in, list(port)::in, list(port)::out) is det.\nremove_port(Port, L0, L) :if list__delete_first(L0, Port, L1) then L = L1 else L = L0.\n:- type collected_type == assoc_list(proc_name, pred_crit).\npost_process(Map, AssocList) :- map__to_assoc_list(Map, AssocList).\n\nFig. 14. A monitor that measures the predicate coverage rate of the n queens\nprogram\n\n\fGeneric Program Monitoring by Trace Analysis\n\n21\n\nCall site coverage The previous coverage criterion only checks that at least\none exit for each predicate is covered. The problem is that 100% predicate\ncoverage does not imply 100% instruction nor branch coverage. To ensure\n100% instruction and branch coverage, we need a criterion that ensures that\nevery predicate invocation in the program succeeds and fails. Hence we need\na definition attached to call sites (or goals) and not only to predicates. To\nachieve that, we just need, for example, to take advantage of line numbers\nand having a table from procedure names and line numbers to list of ports\nas accumulator. The monitor that measures call site coverage rate of Mercury program executions is therefore roughly the same as the one given in\nFigure 14, where the accumulator type becomes:\n:- type proc ---> p(declared_module_name, proc_name, line_number).\n:- type call_site_crit ---> csc(list(call_number), list(port)).\n:- type accumulator_type == map(proc, call_site_crit).\nHere again, such monitors are generated automatically parsing the source\nfiles4 .\n\n4\n\nExperimental Evaluation\n\nIn the previous section we have shown the flexibility and power of the foldt\nprimitive. The aim of this section is to assess the performance of the current\nfoldt implementation. When executing a monitor, some time is spent in\nthe normal program execution (Tprog ); and some extra time is spent in the\ntrace system of Mercury (∆trace ), in the interface between the tracer and the\nfoldt mechanism 5 (∆inte ), in the basic foldt mechanism (∆f oldt ), and also\nin the monitor itself (∆<monitor> ). Hence, if we call T the execution time of\na monitored program, we have:\nT = Tprog + ∆trace + ∆inte + ∆f oldt + ∆<monitor>\nIn the following, we measure: Tprog , Ttrace = Tprog + ∆trace , Tinte =\nTprog + ∆trace + ∆inte , and Tf oldt = Tprog + ∆trace + ∆inte + ∆f oldt .\nWe compare Ttrace , Tinte , and Tf oldt against Tprog . We will therefore compute the following ratios:\nRt = Ttrace /Tprog ,\n4\n\n5\n\nRi = Tinte /Tprog\n\nand Rf = Tf oldt /Tprog\n\ncf the file extras/morphine/source/generate call site cov.m and the\ncall site cov Morphine command.\nThe Mercury predicate collect is called from the Mercury tracer which is written\nin C.\n\n\f22\n\nErwan Jahier and Mireille Ducassé\n\n4.1\n\nMethodology\n\nHardware and software. The measurements given in the following show\nthe results of experiments run on a DELL inspiron 7500, with a 433 MHz\nCeleron, 192 Mb of RAM, running under the Linux 2.2.14 operating system.\nThe machine was very lightly loaded; no X server, no network, simply the\nbasic operating system and a Prolog process in a console to run the measurement scripts. The Prolog system is Eclipse 4.1 [Eclipse, 1999]. The Mercury\ncompiler is a stable snapshot of 14 June 20016. The results are consistent\nwith experiments run on a SUN Sparc Enterprise 250 (2 x UltraSPARC-II,\n296MHz, 512 Mb of RAM) running Solaris 2.7 (figures not given here).\nTime measuring command. In order to measure the program execution\ntimes, we use the benchmark det predicate of the benchmarking.m Mercury\nstandard library. This predicate repeats the body of a program any given\nnumber of times. This is very important for small programs, as the startup\ncost very often dominates the execution cost. In the following experiments,\neach program is re-executed until it runs at least for 20 seconds. Each experiment has been done five times, and the deviation was smaller than 1\n%.\nMonitored programs. The monitored programs are the Mercury benchmark suite7 , composed of programs adapted from the Prolog benchmark suite\nof [Van Roy & Despain, 1992]. In order to have a wider range of execution\nsizes, we also measure n queens for n=10,11, as well as mastermind, a 1100\nlines Mercury program which solves a mastermind game8 .\nMercury compilation grades. In the following, the compilation grade\ngnt refers to Mercury modules compiled with the command mmc --grade\nasm fast.gc.picreg, which means that no trace event is generated. It is the\ngrade used to measure the plain execution time of programs (Tprog ).\nThe compilation grade gt refers to Mercury modules compiled with mmc\n--grade asm fast.gc.picreg --trace deep --trace-optimized, which\nmeans that all events related to all the predicates of the module, except\nlibrary predicates, are generated. This grade is used in the following to measure the time spent in the basic trace system (Ttrace ), the time spent in\nthe interface between the basic tracer and the foldt mechanism (Tinte ), the\ntime spent in the basic foldt mechanism (Tf oldt ) and the time spent in the\nmonitors (T<monitor> ).\n6\n7\n\n8\n\nThe last official release is numbered 0.10.1\nThe source code of this benchmark suite can be found on the Mercury ftp site\nftp://www.mercury.cs.mu.oz.au/pub/mercury/mercury-tests-*.tar.gz\nThe full source code of the Mercury mastermind program can be found at first\nauthor web site\n\n\fGeneric Program Monitoring by Trace Analysis\n\n23\n\nMeasuring Tprog . If the programs are compiled in grade gnt , then their\nexecution does not produce any trace and their measured execution duration\n(Tmeasured ) is exactly Tprog .\nTprog = Tmeasured\n\nif compilation grade is gnt\n\nMeasuring Ttrace . If the programs are compiled in grade gt , then their\nexecution calls the Mercury tracer. In order to measure the cost of the basic\ntracer, we have to ensure that the tracer is systematically called at each event,\nbut that it does not do anything else than entering and exiting the top-level\nswitch of the trace system.\nTtrace = Tmeasured if compilation grade is gt and\n∆inte = 0, ∆f oldt = 0, and ∆<monitor> = 0\nIn order to ensure that ∆inte = 0, ∆f oldt = 0 and ∆<monitor> = 0, we\nuse the continue command of the Mercury tracer without specifying any\nbreak-point. Indeed, with that command, at each event, the trace system is\nentered; if the event does not correspond to one of the specified breakpoints,\nthe normal execution is resumed. In our measurements, as no break-point is\nspecified, the whole execution is traversed, and nothing is executed but the\nbasic tracing mechanism.\nMeasuring Tinte . In order to measure the cost of the interface between the\nbasic tracer and the foldt mechanism, we have to ensure that the tracer\nis systematically called at each event, that it enters and exits the top-level\nswitch of the trace system, that it prepares the context to call the collect\npredicate defined for the monitor, but that it does not compute anything else,\nin particular it should not retrieve any event attribute.\nTinte = Tmeasured if compilation grade is gt and\n∆f oldt = 0, and ∆<monitor> = 0\nIn order to ensure that ∆f oldt = 0, we have implemented a degenerate foldt\nsuch that no event attribute is computed (we have replaced these computations by void values). In order to ensure that ∆<monitor> = 0, we use a\nmonitor that does not compute anything (collect( E, A, A).).\nMeasuring Tf oldt . In order to measure the cost of the basic foldt mechanism, we have to ensure that collect is called at each event for a monitor\nthat computes nothing.\nTf oldt = Tmeasured\n\nif compilation grade is gt and ∆<monitor> = 0\n\nIn order to make sure that ∆<monitor> = 0, we call foldt with a trivial\nmonitor, that does not compute anything (collect( E, A, A).).\n\n\f24\n\nErwan Jahier and Mireille Ducassé\n\nTwo of the current attributes are very costly to retrieve: the live arguments and the line number. The live arguments can be very large data\nstructures. The line number corresponds to the line where the goal is called\nand not where the predicate is defined. It is dynamically retrieved. Many\ninteresting monitors can be run without these attributes. Indeed, for the\nmonitors we propose in this article, only one monitor uses the live arguments\nand one monitor uses the line number. Monitors that do not use these costly\nattributes can disable them. As a consequence, the measurements of Tf oldt\nare made with these two attributes disabled.\n4.2\n\nResulting table\n\nTable 1. Cost of the foldt mechanisms on benchmarks. Ttrace = Tprog + ∆trace ,\nTinte = Tprog + ∆trace + ∆inte , Tf oldt = Tprog + ∆trace + ∆inte + ∆f oldt ,\nRt = Ttrace /Tprog , Ri = Tinte /Tprog , Rf = Tf oldt /Tprog , Rf∗ = (Tf oldt −\n∆inte )/Tprog\nprogram\n\nevents\n\nTprog\n\nTtrace Rt\n\nin ms in ms\n\nTinte\n\nRi\n\nin ms\n\nTf oldt\n\nRf\n\nRf∗\n\nin ms\n\nqueens-5\n\n698\n\n0.03\n\n0.24\n\n7.5\n\n2\n\n61.5\n\n2.07\n\n63\n\n9.5\n\nquery\n\n935\n\n0.09\n\n0.28\n\n3\n\n1.53\n\n16.5\n\n1.58\n\n17\n\n3.5\n\nderiv\n\n1,540\n\n0.05\n\n0.11\n\n2.5\n\n0.64\n\n14\n\n0.66\n\n14.5\n\n3\n\nqsort\n\n1,564\n\n0.1\n\n0.48\n\n5\n\n4.03\n\n42\n\n4.16\n\n43.5\n\n6.5\n\nnrev\n\n1,619\n\n0.14\n\n0.54\n\n4\n\n4.44\n\n32.5\n\n4.58\n\n33.5\n\n5\n\nprimes\n\n2,192\n\n0.21\n\n0.8\n\n4\n\n6.23\n\n30\n\n6.51\n\n31\n\n5.5\n\ncqueens\n\n3,789\n\n0.14\n\n1.26\n\n9.5\n\n11.11\n\n81\n\n11.39\n\n82\n\n11.5\n\ncrypt\n\n4,602\n\n0.72\n\n1.8\n\n3\n\n11.16\n\n16\n\n11.54\n\n16.5\n\n3.5\n\npoly\n\n79,070\n\n6.44\n\n29\n\n4.5\n\n226.2\n\n35.5\n\n233.4\n\n36.5\n\n6\n\ntak\n\n190,831\n\n3.88\n\n57.1\n\n15\n\n553.7\n\n142\n\n572.4\n\n148\n\n20\n\nqueens-10\n\n4,289,986\n\n257\n\n1530\n\n6\n\n12760 50.5\n\n13200\n\n51.5\n\n8\n\nmastermind\n\n9,106,510\n\n3630\n\n6500\n\n2\n\n30490\n\n31520\n\n9\n\n2.5\n\n32,384,320\n\n2103\n\n12030\n\n6\n\n97010 46.5 100190\n\n48\n\n7.5\n\nqueens-11\n\n8.5\n\nTable 1 illustrates the cost of the basic tracer, the cost of the interface\nbetween the tracer and foldt, as well as the cost of foldt on the benchmark\nprograms described in the previous sections. The first column contains the\nnames of the monitored programs. The second column contains the numbers\n\n\fGeneric Program Monitoring by Trace Analysis\n\n25\n\nof execution events generated by the program executions compiled in grade\ngt (all events are generated, except events relative to library predicates). The\nprograms are sorted wrt this number of events, from queens-5, 698 events,\nto queens-11, more than 32 millions of events. The third column contains\nthe execution times of the programs compiled without any trace information\n(Tprog ). The fourth column contains the execution times of the programs\ncompiled in grade gt and run under the control of the tracer without tracing\nanything (Ttrace = Tprog + ∆trace ). The fifth column contains the overhead\nfactor of the basic trace mechanism (Rt = Ttrace /Tprog ). The sixth column\ncontains the execution times of the programs compiled in grade gt and run\nunder the control of the tracer, and where the degenerate foldt is called\nwith an empty monitor (Tinte = Tprog + ∆trace + ∆inte ). The seventh column\ncontains the overhead factor of the trace and the interface between the tracer\nand foldt (Ri = Tinte /Tprog ). The eighth column contains the execution time\nof the programs compiled in grade gt and run under the control of foldt with\nan empty monitor (Tf oldt = Tprog +∆trace +∆inte +∆f oldt ). The ninth column\ncontains the overhead factor of the trace, the interface and the basic foldt\nmechanism (Rf = Tf oldt /Tprog ). The tenth column contains the overhead\nfactor of the trace and the basic foldt mechanism, with the interface cost\ndivided (Rf∗ oldt = (Tf oldt − ∆inte )/Tprog ). The time measurements have been\nrounded off two digits after the dot. The ratios have been rounded up to the\nnearest half.\n4.3\n\nDiscussion\n\nIn this section, we discuss the resulting ratios of Table 1.\nTwo extremes: tak and mastermind. The tak program has ratios much\nhigher than the other programs. The tracer overhead is already 15, the interface overhead is 142 and the foldt overheads are 148 and 20. This program\nis actually a single predicate four times recursive. It already broke the stacks\nof the reference tracer used in [Ducassé & Noyé, 2000]. This code is an extreme case to test compiler optimization capabilities. As many optimizations,\nsuch as last call optimization, cannot be applied to traced code, the better\nthe compiler is, the worse debugger and monitor ratios look. Program Tak is\nvery untypical of real life programs. The ratios related to tak are not taken\ninto account in the averages given below.\nOn the other hand mastermind has very low ratios. The tracer overhead\nis 2, the interface overhead is 8.5 and the foldt overheads are 9 and 2.5. The\nmastermind program uses a lot of library predicates which are not traced9\nand monitored in detail. This is typical of real life programs. It is encouraging\nthat the more realistic program has the best ratios. However, the other benchmarks do not use untraced libraries, in order to be fair, the ratios related to\nmastermind are not taken into account in the averages given below.\n9\n\ntheir calls and exits are traced, but not what happens inside these calls\n\n\f26\n\nErwan Jahier and Mireille Ducassé\n\nIn the following, averages are, thus, computed without the figures related\nto tak and mastermind.\nThe ratios are not correlated with the number of events. Program\nqueens-5, which has only 698 events, has very bad ratios, whereas crypt,\nalmost five thousand events, and poly, almost eighty thousand events, have\nbetter ratios than the average. The same program, n queens, run for n=\n5,10 and 11, always has comparable ratios. This seems to indicate that the\noverheads depend mostly of the monitored program and is somewhat constant\nfor a given program.\nOverhead of the tracer. The average of the tracer overhead is 5. It\nis a very good ratio. Prolog tracers can easily have an overhead over 20\n[Ducassé & Noyé, 2000]. A low ratio for the tracer is, of course, a good starting point to build efficient generic monitors.\nOverhead of the interface between the tracer and foldt. The average\nof the interface overhead is 39. This is very high and it is the main source\nof inefficiency of our current implementation. It illustrates how crucial the\nimplementation of this interface is for efficient generic monitoring.\nThe problems comes from the fact that the monitor programs have to\nbe integrated in the tracer. In our particular case, the Mercury predicate\ncollect is called from the Mercury tracer which is written in C. In order\nto call Mercury code from C with the current (low-level back-end of the)\nMercury compiler, machine registers need to be saved and restored. Since\nthe collect predicate is called several million times, this has a noticeable\ninfluence on the performance. A way to remove this overhead could be to use\nthe new MLDS back-end of the Mercury compiler, which generates high-level\nC code that does not use machine registers; unfortunately, the trace system\nis not supported for the MLDS back-end at the time of this writing. Once\nthe MLDS Mercury back-end is available, calling the collect predicate will\nactually be compiled as a simple C procedure call from within C code. The\noverhead of the interface between the tracer and foldt should thus become\nsmaller.\nOne important lesson learned from these measurements is as follows.\nWhether the monitors and the tracer are implemented in the same programming language or not, the integration of the compiled monitors should not\ncost more than a procedure call. The monitors must therefore be compiled\ninto the same target language as the tracer. Furthermore, no run-time verifications should be made. The monitors should therefore have no side-effect\non the traced execution. It should thus be statically checked that monitors\nonly update their own (fresh) variables.\nOverhead of foldt. The average of the foldt overhead is 40. Most of it is\ndue to the overhead of the interface discussed above. Assuming that the above\n\n\fGeneric Program Monitoring by Trace Analysis\n\n27\n\nfix could be done and that the interface overhead indeed becomes negligible,\nwe have computed an ideal ratio: Rf∗ = (Tf oldt − ∆inte )/Tprog . The average\nof the overhead of foldt without the interface cost is 6.5. As the average of\nthe tracer overhead is 5, we can say that the foldt overhead is acceptable.\nIn the context of Mercury, this is especially true because the developers\nof Mercury claim that Mercury programs executed in trace mode are faster\nthan the equivalent Prolog programs executed in optimized mode in the faster\nProlog systems [Somogyi & Henderson, 1999].\nUnused event attributes. As already mentioned, some attributes can be\nvery costly to compute. When they are not needed it should be possible to\ndisable them. In the current implementation of foldt, this is already the case\nfor the list of live arguments and the line numbers. The foldt overhead has\nbeen measured without the cost of the live arguments and the line numbers.\nSome measurements, not reported here, showed that this has an impact on\nthe performance.\nGranularity of the instrumentation. In order to measure the worst case,\nwe have made the Mercury tracer systematically generate all the possible\nevents. Not all monitors need such a fine-grained instrumentation. For example, for the monitor that counts the number of events at each depth, only\ncall events are necessary. When one (hard-)codes a specific monitor, one\nonly instruments the code where it is necessary. As a matter of fact, the\nMercury tracer enables users to specify what type of events, if any, should be\ngenerated for a given module (the only restriction is that, if some events are\ngenerated for a predicate, call events must be present). Hence, programmers\ncan already take advantage of this possibility to optimize their monitor. As\nfurther work, we plan to automate this optimization, namely, to automatically generate the appropriate compiling option for a given monitor.\nConclusion on performance. The cost of monitors is generally superseded\nby the cost of the foldt mechanism, except for time demanding monitors such\nas the one that computes dynamic call graphs and coverage rates for which\nwe have yet another slowdown of a factor ranging from 1.5 to 5. Hence, our\nconclusion is that with a fast tracer, an interface between the tracer and foldt\nreduced to procedure calls, and the possibility to disable the computation of\nheavy non-necessary attributes, generic monitoring can be efficient enough.\n\n5\n\nRelated work\n\nProgrammable debuggers. We designed 3 programmable debuggers, Opium\nfor Prolog [Ducassé, 1999b], Coca for C [Ducassé, 1999a] and Morphine for\nMercury [Jahier & Ducassé, 1999a]. They are based on a Prolog query loop\nplus a handful of coroutining primitives connected to the trace system. Those\n\n\f28\n\nErwan Jahier and Mireille Ducassé\n\nprimitives allow a Prolog system to communicate with the debugged program. Opium, Coca and Morphine are full debugging programming languages\nin which all classical debuggers commands can be implemented straightforwardly and efficiently. However, their set of primitives are not well suited for\nmonitoring. All the monitors implemented with foldt can easily be implemented with the debugger set of primitives [Jahier & Ducassé, 1999b], but\nresulting monitors require too many context switches and too much socket\ntraffic between the program and the monitor. With programs of several million execution events, such monitors can be four orders of magnitude slower\nthan their counterparts that use foldt [Jahier, 2000a].\nAutomated development of monitors. Jeffery et al. designed the Alamo system [Templer & Jeffery, 1998,Jeffery et al., 1998,Jeffery, 1999], that aims at\neasing the development of monitors for C programs. As in our approach,\ntheir monitoring architecture is based on event filtering, and monitors can be\nprogrammed. Their system performs trace extraction whereas we rely on an\nalready available tracer; this saves us a tedious task which has already been\ndone and optimized. On the other hand, we do not have the full control of\nthe information available in the trace. Note however that, so far, we have be\nable to reconstruct missing information, for example the call stack of Figure 13. Moreover, to avoid code explosion, Jeffery et al. perform part of the\nevent filtering at compilation time. This means that they need to recompile\nthe program each time they want to execute another monitor, whereas we\nonly need to dynamically link the monitor to the monitored program. Alamo\nand the monitored program are running in coroutining, but within the same\naddress space.\nEustace and Srivastava developed Atom [Eustace & Srivastava, 1995], a\nsystem that also aims at easing the implementation of monitors. The difference with Alamo is that monitors are implemented with procedure calls and\nglobal variables which is much more efficient than coroutining. However, the\nlanguage provided by Atom is less expressive than the Alamo’s. Alamo and\nAtom have influenced the design of foldt and we tried to take the best of\nboth: a full and high-level programming language implemented by procedure\ncalls. The advantages of our architecture over [Eustace & Srivastava, 1995]\nand [Jeffery et al., 1998] are the following:\n• A higher level interface makes the code of our monitors compact, easy to\nwrite and read, and therefore to maintain. Of course, this point is difficult to assess. We hope that the numerous and various examples given\nin Section 3 convince the reader that it is indeed the case. Nonetheless, we see three conjectures explaining why the code is more compact\nand more elegant. Firstly, users do not have to deal with code instrumentation directives; the instrumentation has already been done. Secondly, we take advantage of the expressive power of fold; using high\norder predicates such as fold for processing lists has proven to be con-\n\n\fGeneric Program Monitoring by Trace Analysis\n\n29\n\ncise and far less prone to error than processing lists manually. A third\nreason is that our monitors are written in Mercury, which is a considerably higher level language than C or C-like languages which are used\nin [Eustace & Srivastava, 1995,Jeffery et al., 1998].\n• Provided that an event-oriented tracer exists, the foldt operator is easy\nto implement. To implement it, the work done inside the Mercury runtime\nsystem, which corresponds to the really technical part, amounts to only\n61 modified lines and 292 new lines of (C) code.\nKishon and al. [Kishon & Hudak, 1995] use a denotational and operational\ncontinuation semantics to formally define monitors for a simple functional\nprogramming language. The kind of monitors they define are profilers, debuggers, and statistic collectors. From the operational semantics, a formal\ndescription of the monitor, and a program, they derive an instrumented executable file that performs the specified monitoring activity. The semantics of\nthe original programs is preserved. They use partial evaluation to make their\nmonitors reasonably efficient. The main disadvantage with this approach is\nthat they are rebuilding a whole execution system from scratch, without taking advantage of existing compilers. We strongly believe that it is important\nto have the same execution system for debugging, monitoring and producing\nthe final executable program. As noted by [Brooks et al., 1992], some errors\nonly occur in presence of optimizations, and vice versa; some programs can\nonly be executed in their optimized form because of time and memory constraints; when searching for “hot spots”, it is better to do it as much as\npossible with the optimized program as many things can be optimized away;\nand finally, sometimes, the error comes from the optimizations themselves.\nIn our setting we can easily mix traced and non-traced code.\nEfficient monitoring. Patil and Fisher [Patil & Fischer, 1997] address the\nproblem of performance monitoring by delegating the monitoring activities\nto a second processor that they call a shadow processor. Their approach is\nvery efficient; the monitored program is practically not slowed down, but the\nset of monitoring commands they propose cannot be extended. We mentioned\nin the previous section that we could reduce the number of events generated\nby the tracer. For example, in [Ball & Larus, 1992], given a static control\nflow graph, algorithms can place tracing instructions in optimal ways for\ncomputing statistics on imperative program executions.\n\n6\n\nConclusion\n\nIn this article we have proposed a generic monitoring framework based on\nfoldt10, a high-level primitive that allows users to easily specify what they\n10\n\nAvailable in Morphine, which can be downloaded from the Mercury ftp and web\nsites.\n\n\f30\n\nErwan Jahier and Mireille Ducassé\n\nwant to monitor. We illustrated it on various examples that demonstrate its\ngenericity and its simplicity of use. We defined two preliminary notions of\ntest coverage for logic programs and showed how to prototype coverage rates\nmeasurements with our primitive. Testing and monitoring tools are missing\nfrom many declarative systems: foldt allows some of these tools to be easily\ndefined and implemented. Measurements showed that the performance of the\nprimitive on the above examples can be acceptable for executions of several\nmillion trace events.\nTo sum up the advantages of our framework, we can say that it is:\n• Easy to implement: because it is based on an existing tracer (292 new,\nand 61 modified lines of codes in our current implementation).\n• Efficient: because the trace is not stored.\n• Flexible and easy to use: as illustrated by the given applications about\nexecution profiles, graphical abstract displays and test coverage.\n\nAcknowledgments\nWe would like to thank Fergus Henderson for his technical support and his\nmany contributing ideas; Pierre Deransart, Baudouin Le Charlier and Olivier\nRidoux for fruitful discussions; Jean-Philippe Pouzol for his comments on earlier versions of this article. Finally, we are grateful to the thorough anonymous\nreviews which have helped us a lot improve the article.\n\nReferences\nBall & Larus, 1992. Ball, T., & Larus, J.R. (1992). Optimally profiling and tracing\nprograms. Pages 59–70 of: 19th ACM Symposium on Principles of Programming\nLanguages.\nBates, 1995. Bates, Peter C. (1995). Debugging heterogeneous distributed systems\nusing event-based models of behavior. ACM Transactions on Computer Systems,\n13(1), 1–31.\nBeizer, 1990. Beizer, B. (1990). Software testing techniques. Vol. 2nd ed. Int.\nThomson Computer Press.\nBird, 1987. Bird, R. S. (1987). An introduction to the theory of lists. Pages 3–\n42 of: Broy, M. (ed), Logic of Programming and Calculi of Discrete Design.\nSpringer-Verlag.\nBrooks et al., 1992. Brooks, G., Hansen, G.J., & Simmons, S. (1992). A new approach to debugging optimized code. Pages 1–11 of: SIGPLAN’92 Conference\non Programming Language Design and Implementation.\nByrd, 1980. Byrd, L. (1980). Understanding the control flow of Prolog programs.\nPages 127–138 of: Tränlund, S.-A. (ed), Logic Programming Workshop.\nDucassé, 1999a. Ducassé, M. (1999a). Coca: An automated debugger for C. Pages\n504–513 of: Proceedings of the 21st Int. Conference on Software Engineering.\nACM Press.\n\n\fGeneric Program Monitoring by Trace Analysis\n\n31\n\nDucassé, 1999b. Ducassé, M. (1999b). Opium: An extendable trace analyser for\nProlog. Journal of Logic Programming, 39, 177–223. Special issue on Synthesis,\nTransformation and Analysis of Logic Programs, A. Bossi and Y. Deville (eds).\nDucassé & Noyé, 2000. Ducassé, M., & Noyé, J. (2000). Tracing Prolog programs\nby source instrumentation is efficient enough. Journal of Logic Programming,\n43(2), 157–172.\nEclipse, 1999. Eclipse. (1999).\nThe ECLiPSe Constraint Logic Programming System, ECLiPSe 4.1 - User Manual.\nIC.Parc.\nhttp://www-icparc.doc.ic.ac.uk/eclipse/.\nEisenstadt & Brayshaw, 1988. Eisenstadt, M., & Brayshaw, M. (1988). The Transparent Prolog Machine TPM: an execution model and graphical debugger for\nLogic Programming. Journal of Logic Programming, 5(4), 277–342.\nEustace & Srivastava, 1995. Eustace, A., & Srivastava, A. (1995). ATOM: A flexible interface for building high performance program analysis tools. Winter 1995\nUSENIX Conference.\nFritzson et al., 1994. Fritzson, P., Auguston, M., & Shahmehri, N. (1994). Using\nassertions in declarative and operational models for automated debugging. Journal of Systems Software, 25, 223–239.\nGallagher & Lyle, 1991. Gallagher, K.B., & Lyle, J.R. (1991). Using program slicing in software maintenance. IEEE Transactions on Software Engineering, 17(8),\n751–761.\nHatton, 1997. Hatton, L. (1997). Does OO sync with the way we think? IEEE\nSoftware, 15(3), 46–54.\nHowden & Shi, 1996. Howden, W.E., & Shi, G.M. (1996). Linear and structural\nevent sequence analysis. Pages 98–106 of: Zeil, Steven J. (ed), Proceedings of\nthe 1996 Int. Symposium on Software Testing and Analysis. ACM Press.\nHutton, 1999. Hutton, G. (1999). A tutorial on the universality and expressiveness\nof fold. Journal of Functional Programming, 355–372.\nJahier, 2000a. Jahier, E. (2000a). Analyse dynamique de programmes : mise\nen oeuvre automatisée d’analyseurs performants et spécification de modèles\nd’exécution. Ph.D. thesis, INSA de Rennes. Partly in English.\nJahier, 2000b. Jahier, E. (2000b). Collecting graphical abstract views of Mercury\nprogram executions. Pages 100–115 of: Proceedings of the 4th Int. Workshop on\nAutomated Debugging.\nJahier & Ducassé, 1999. Jahier, E., & Ducassé, M. (1999). A generic approach\nto monitor program executions. Pages 139–153 of: Schreye, D. De (ed), Int.\nConference on logic programming. MIT Press.\nJahier & Ducassé, 1999a. Jahier, E., & Ducassé, M. (1999a). Morphine 0.2 User\nand Reference Manuals.\nJahier & Ducassé, 1999b. Jahier, E., & Ducassé, M. (1999b).\nUn traceur\nd’exécutions de programmes ne sert pas qu’au débogage. Pages 297–311 of:\nFages, F. (ed), Actes des Journées Francophones de Programmation Logique et\npar Contraintes. Hermès.\nJeffery, 1999. Jeffery, C. (1999). Program monitoring and visualization. Springer.\nISBN 0-387-98644-8.\nJeffery et al., 1998. Jeffery, C., Zhou, W., Templer, K., & Brazell, M. (1998). A\nlightweight architecture for program execution monitoring. ACM SIGPLAN\nNotices, 33(7), 67–74.\nKishon & Hudak, 1995. Kishon, A., & Hudak, P. (1995). Semantics directed program execution monitoring. Journal of Functional Programming, 5(4), 501–547.\n\n\f32\n\nErwan Jahier and Mireille Ducassé\n\nKishon et al., 1991. Kishon, A., Hudak, P., & Consel, C. (1991). Monitoring semantics: a formal framework for specifying, implementing and reasoning about\nexecution monitors. ACM SIGPLAN Notices, 26(6), 338–352.\nKoutsofios & North, 1991. Koutsofios, E., & North, S. (1991). Drawing graphs with\ndot. TR 910904-59113-08TM. AT&T Bell Laboratories.\nOlsson et al., 1990. Olsson, R.A., Crawford, R.H., & Ho, W.W. (1990). Dalek: A\nGNU, improved programmable debugger. Pages 221–232 of: USENIX Association (ed), Summer 1990 USENIX Conference. USENIX Association.\nPatil & Fischer, 1997. Patil, H., & Fischer, C. (1997). Low-cost, concurrent checking of pointer and array accesses in C programs. Software Practice and Experience, 27(1), 87–110.\nPfenning, 1992. Pfenning, F. (ed). (1992). Types in Logic Programming. MIT Press.\nISBN 0-262-16131-1.\nSomogyi & Henderson, 1999. Somogyi, Z., & Henderson, F. (1999). The implementation technology of the Mercury debugger. Pages 35–49 of: Proceedings of\nthe 10th Workshop on Logic Programming Environments, vol. 30(4). Elsevier,\nElectronic Notes in Theoretical Computer Science.\nSomogyi et al., 1996. Somogyi, Z., Henderson, F., & Conway, T. (1996). The execution algorithm of Mercury, an efficient purely declarative logic programming\nlanguage. Journal of Logic Programming, 29, 17–64.\nStasko et al., 1998. Stasko, J., Domingue, J., Brown, M. H., & Price, B. A. (eds).\n(1998). Software visualization: Programming as a multimedia experience. MIT\nPress.\nTempler & Jeffery, 1998. Templer, K.S., & Jeffery, C.L. (1998). A configurable\nautomatic instrumentation tool for ANSI C. Pages 249–259 of: Proceedings of\nthe Automated Software Engineering Conference. IEEE Computer Society.\nTip, 1995. Tip, F. (1995). Generic techniques for source-level debugging and dynamic program slicing. Pages 516–530 of: Mosses, Peter D., Nielsen, Mogens, &\nSchwartzbach, Michael I. (eds), TAPSOFT ’95: Theory and Practice of Software\nDevelopment. LNCS, vol. 915. Springer-Verlag.\nTolmach & Appel, 1995. Tolmach, A., & Appel, A.W. (1995). A debugger for Standard ML. Journal of Functional Programming, 5(2), 155–200.\nVan Roy & Despain, 1992. Van Roy, P., & Despain, A. M. (1992).\nHighperformance logic programming with the Aquarius Prolog compiler. Computer,\n25(1), 54–68.\n\n\fGeneric Program Monitoring by Trace Analysis\n\nA\n\n33\n\nMercury execution events\n\nThe Mercury trace is an adaptation of Byrd’s box model [Byrd, 1980]. In\nthis section, we describe the Mercury execution events that constitute the\nMercury execution trace. More information about the Mercury tracer can be\nfound in [Somogyi & Henderson, 1999]. The different attributes provided by\nthe Mercury tracer are:\n1. Chronological event number (chrono11). Each event has a unique event\nnumber according to its rank in the trace. It is a counter of events.\n2. Goal invocation number or call number (call). Unlike chronological event\nnumber, several events have the same goal invocation number. All events\nrelated to a given goal have a unique goal number given at invocation\ntime.\n3. Execution depth (depth). It is the depth of the goal in the proof tree,\nnamely the number of its ancestor goals + 1.\n4. Event type or port (port). We distinguish between external events that\noccur at procedure entries and exits, which are the traditional ports introduced by Byrd [Byrd, 1980], and the internal events which refers to\nwhat is occurring inside a procedure. External events are:\n• call a new goal is invoked\n• exit the current goal succeeds\n• fail the current goal fails\n• redo another solution for the current goal is asked for on backtracking.\n• exception the execution raises an exception\nInternal events are:\n• disj the execution is entering a branch of a disjunction\n• switch the execution is entering a branch of a switch (a switch is\na disjunction in which each branch unifies a ground variable with\na different function symbol. In that case, at most one disjunction\nprovides a solution).\n• if the execution is entering the condition branch of an if-then-else\n• then the execution is entering the “then” branch of an if-then-else\n• else the execution is entering the “else” branch of an if-then-else\n• first the execution enters a C code fragment for the first time\n• later the execution re-enters a C code fragment\n5. Determinism (det). It characterizes the number of potential solutions\nfor a given goal. The determinism markers of Mercury are: det for procedures which have exactly 1 solution, semidet for those which have 0 or\n1 solution, nondet for those which have any number of solutions, multi\nfor those which have at least 1 solution, failure for those that have no\nsolution, and erroneous for those which lead to a runtime error.\n11\n\nThe names of the attribute accessing functions are in bold in between parentheses.\n\n\f34\n\nErwan Jahier and Mireille Ducassé\n\n6. Procedure (proc). It is defined by:\n• a flag telling if the procedure is a function or a predicate (proc type)\n• a definition module (def module)\n• a declaration module (decl module) The declaration module is the\nmodule where the user has declared the procedure. The defining module is the module where the procedure is effectively defined from the\ncompiler point of view. They may be different if the procedure has\nbeen inlined.\n• a name (name)\n• an arity (arity)\n• a mode number (mode number).\nThe mode number is an integer coding the mode of the procedure.\nWhen a predicate has only one mode, the mode number of its corresponding procedure is 0. Otherwise, the mode number is the rank in\nthe order of appearance of the mode declaration.\n7. List of live arguments (args). A variable is live at a given point of the\nexecution if it has been instantiated and if the result of that instantiation\nis still available in the runtime system. Destructive input (di mode), for\nexample, are not kept until the procedure exits.\n8. List of live Argument types (arg types).\n9. List of local live variables (local vars). Some live variables are not arguments of the current procedure.\n10. Goal path (goal path). The goal path indicates in which part of the code\nthe current internal event occurs. if, then and else branches of an ifthen-else are denoted by ?, e and t respectively; conjuncts, disjuncts and\nswitches are denoted by ci, di and si, where i is the conjunct (resp.\ndisjunct, switch) number. For example, if an event with goal path [c3,\ne, d1] is generated, it means that the event occurred in the first branch\nof a disjunction, which is in the else branch of an if-then-else, which is in\nthe third conjunction of the current goal. External events have an empty\ngoal path.\nThe event structure is illustrated by Figure 15. The displayed structure\nis related to an event of the execution of a qsort program which sorts\nthe list of integers [3, 1, 2] using a quick sort algorithm. The information contained in that structure indicates that qsort:partition/4-012\nis currently invoked, it is the tenth trace event being generated, the sixth\ngoal being invoked, and it has four ancestors (depth is 5). At this point,\nonly the first two arguments of partition/4 are instantiated: the first\none is bound to the list of integers [1, 2] and the second one to the\ninteger 3 ; the third and fourth arguments are not live, which is indicated\nby the atom ‘-’. There are two live local variables: H, which is bound to\n12\n\n‘-0’ denotes the mode number; here, ‘0’ means that qsort was declared with\nonly one mode (namely, :- mode qsort(in, in, out, out) is det). If more\nthan one mode is declared, ‘0’ denotes the first mode, ‘1’ the second one, etc.\n\n\fGeneric Program Monitoring by Trace Analysis\nchrono\ncall\ndepth\nport\ndet\nproc_type\ndef_module\ndecl_module\nname\narity\nmode_number\narg\narg_types\nlocal_vars\ngoal_path\n\n35\n\n10\n6\n5\nthen\ndet\npredicate\nqsort\nqsort\npartition\n4\n0\n[ [1, 2], 3, -, - ]\n[list(int), int, -, - ]\n[ live_var(\"H\", 1, int), live_var(\"T\", [2], list(int)) ]\n[s1, c2, t]\nFig. 15. A Mercury trace event\n\nthe integer 1, and T, which is bound to the list of integers [2]. The goal\npath tells that this event occurred in the then branch (t) of the second\nconjunction (c2) of the first switch (s1) of partition/4.\n\nB\n\nThe Mercury queens program\n\n:- module queens.\n:- interface.\n:- import_module io.\n:- pred main(io__state, io__state).\n:- mode main(di, uo) is cc_multi.\n:- implementation.\n:- import_module list, int.\nmain -->\n( { data(Data), queen(Data, Out) } ->\nio__write_string(\"A 5 queens solution is \"), print_list(Out)\n;\nio__write_string(\"No solution\\n\")\n).\n:- pred data(list(int)).\n:- mode data(out) is det.\n\n\f36\n\nErwan Jahier and Mireille Ducassé\n\n:- pred queen(list(int), list(int)).\n:- mode queen(in, out) is nondet.\n:- pred qperm(list(T), list(T)).\n:- mode qperm(in, out) is nondet.\n:- pred qdelete(T, list(T), list(T)).\n:- mode qdelete(out, in, out) is nondet.\n:- pred safe(list(int)).\n:- mode safe(in) is semidet.\n:- pred nodiag(int, int, list(int)).\n:- mode nodiag(in, in, in) is semidet.\ndata([1,2,3,4,5]).\nqueen(Data, Out) :qperm(Data, Out),\nsafe(Out).\nqperm([], []).\nqperm([X|Y], K) :qdelete(U, [X|Y], Z),\nK = [U|V],\nqperm(Z, V).\nqdelete(A, [A|L], L).\nqdelete(X, [A|Z], [A|R]) :qdelete(X, Z, R).\nsafe([]).\nsafe([N|L]) :nodiag(N, 1, L),\nsafe(L).\nnodiag(_, _, []).\nnodiag(B, D, [N|L]) :NmB is N - B,\nBmN is B - N,\n( D = NmB ->\nfail\n; D = BmN ->\nfail\n;\ntrue\n),\nD1 is D + 1,\n\n\fGeneric Program Monitoring by Trace Analysis\nnodiag(B, D1, L).\n:- pred print_list(list(int), io__state, io__state).\n:- mode print_list(in, di, uo) is det.\nprint_list(Xs) -->\n( { Xs = [] } ->\nio__write_string(\"[]\\n\")\n;\nio__write_string(\"[\"),\nprint_list_2(Xs),\nio__write_string(\"]\\n\")\n).\n:- pred print_list_2(list(int), io__state, io__state).\n:- mode print_list_2(in, di, uo) is det.\nprint_list_2([]) --> [].\nprint_list_2([X|Xs]) -->\nio__write_int(X),\n( { Xs = [] } ->\n[]\n;\nio__write_string(\", \"),\nprint_list_2(Xs)\n).\n\n37\n\n\fdata([1, 2, 3, 4, 5])\n\nqperm([1, 2, 3, 4, 5], [1, 3, 5, 2, 4])\n\nqdelete(1, [1, 2, 3, 4, 5], [2, 3, 4, 5])\n\nqdelete(3, [2, 3, 4, 5], [2, 4, 5])\n\nqdelete(3, [3, 4, 5], [4, 5])\n\nqdelete(5, [5], [])\n\ns\n\nqperm([2, 3, 4, 5], [3, 5, 2, 4])\n\nnodiag(\n\nqperm([2, 4, 5], [5, 2, 4])\n\nnodiag(\n\nqdelete(5, [2, 4, 5], [2, 4])\n\nqdelete(5, [4, 5], [4])\n\nqueen([1\n\nqperm([2, 4], [2, 4])\n\nqdelete(2, [2, 4], [4])\n\nqdelete(4, [4], [])\n\nnodia\n\nqperm([4], [4])\n\nnod\n\nqperm([], [])\n\nno\n\n\f",
         "train",
         "85521",
         "14093"
        ],
        [
         "2",
         "20001",
         "cs.AI",
         "Artificial Intelligence",
         "1801.00388v1.pdf",
         "Beyond Word Embeddings: Learning Entity and Concept\nRepresentations from Large Scale Knowledge BasesI\nWalid Shalaby, Wlodek Zadrozny\nDepartment of Computer Science\nUniversity of North Carolina at Charlotte\n{wshalaby, wzadrozn}@uncc.edu\n\narXiv:1801.00388v1 [cs.CL] 1 Jan 2018\n\nHongxia Jin\nSamsung Research America\nhongxia.jin@samsung.com\n\nAbstract\nText representation using neural word embeddings has proven efficacy in many NLP applications.\nRecently, a lot of research interest goes beyond word embeddings by adapting the traditional word\nembedding models to learn vectors of multiword expressions (concepts/entities). However, current\nmethods are limited to textual knowledge bases only (e.g., Wikipedia). In this paper, we propose a\nnovel approach for learning concept vectors from two large scale knowledge bases (Wikipedia, and\nProbase). We adapt the skip-gram model to seamlessly learn from the knowledge in Wikipedia text\nand Probase concept graph. We evaluate our concept embedding models intrinsically on two tasks:\n1) analogical reasoning where we achieve a state-of-the-art performance of 91% on semantic analogies, 2) concept categorization where we achieve a state-of-the-art performance on two benchmark\ndatasets achieving categorization accuracy of 100% on one and 98% on the other. Additionally, we\npresent a case study to extrinsically evaluate our model on unsupervised argument type identification for neural semantic parsing. We demonstrate the competitive accuracy of our unsupervised\nmethod and its ability to better generalize to out of vocabulary entity mentions compared to the\ntedious and error prone methods which depend on gazetteers and regular expressions.\n\n1. Introduction\nVector-based semantic representation models are used to represent textual structures (words,\nphrases, and documents) as multidimensional vectors. Typically, These models utilize textual\ncorpora and/or Knowledge Bases (KBs) in order to extract and model real-world knowledge. Once\nacquired, any given text structure is represented as a real-valued vector in the semantic space. The\ngoal is thus to accurately place semantically similar structures close to each other in that semantic\nspace, while placing dissimilar structures far apart.\nI In\n\nthis paper, we use the terms ”concept” and ”entity” interchangeably.\n\nPreprint under review\n\nJanuary 3, 2018\n\n\fFigure 1: Integrating knowledge from Wikipedia text (left) and Propase concept graph (right). Local conceptconcept, concept-word, and word-word contexts are generated from both KBs and used for training the skip-gram\nmodel.\n\nRecent neural-based methods for learning word vectors (embeddings) have even succeeded in\ncapturing both syntactic and semantic regularities using simple vector arithmetic [1, 2, 3]. For example, inferring analogical relationships between words: vec(king)-vec(man)+vec(woman)=vec(queen).\nThis indicates that the learned vector dimensions encode meaningful multi-clustering for each word.\nWord vectors suffer significant limitations. First, each word is assumed to have a single meaning\nregardless of its context and thus is represented by a single vector in the semantic space (e.g.,\ncharlotte (city) vs. charlotte (given name)). Second, the space contains vectors of single words\nonly. Vectors of multiword expressions (MWEs) are typically obtained by averaging the vectors of\nindividual words. However, this would often produce inaccurate representations especially if the\nmeaning of the MWE is different from the composition of meanings of its individual words (e.g.,\nvec(north carolina) vs. vec(north)+vec(carolina). Additionally, mentions that are used to refer to\nthe same concept would have different embeddings (e.g., u.s., america, usa), and the model might\nnot be able to place those individual vectors in the same sub-cluster especially the rare surface\nforms.\nFor addressing these limitations, a lot of research interest has been focusing on learning distributed representations of concepts1 and entities. Such models utilize text KBs (e.g., Wikipedia)\nor a triple-based KBs (e.g., DBpedia and Freebase) in order to learn entity vectors. Broadly speak1 concepts are lexical expressions (single or multiwords) that denote an idea, event, or an object and typically have\na set of properties.\n\n2\n\n\fing, existing methods can be divided into two categories. First, methods that learn embeddings of\nKB concepts only [4, 5, 6]. Second, methods that jointly learn embeddings of words and concepts\nin the same semantic space [7, 8, 9, 10].\nIn this paper, we introduce an effective approach for jointly learning word and concept vectors\nfrom two large scale KBs of different modalities; a text KB (Wikipedia) and a graph-based concept\nKB (Probase2 ). We adapt skip-gram, the popular local context window method [2], to integrate the\nknowledge from both KBs. As shown in Figure 1, three key properties differentiate our approach\nfrom existing methods. First, we generate word and concept contexts from their raw mentions\nin the Wikipedia text. This makes our model extensible to other text corpora with annotated\nconcept mentions. Second, we model Probase as a weighted undirected KB graph exploiting the\nco-occurrence counts between pairs of concepts. This allows us to generate more concept-concept\ncontexts during training, and subsequently learn better concept vectors for rare and infrequent\nconcepts in Wikipedia. Third, to our knowledge, this work is the first to combine knowledge from\ntwo KBs of different modalities (Wikipedia and Probase) into a unified representation.\nWe evaluate the generated concept vectors intrinsically on two tasks: 1) analogical reasoning\nwhere we achieve a state-of-the-art accuracy of 91% on semantic analogies, 2) concept categorization\non two datasets where we achieve 100% accuracy on one dataset and 98% accuracy on the other. We\nalso present a case study to analyze the impact of using our concept vectors for unsupervised argument type identification with semantic parsing as an end-to-end task. The results show competitive\nperformance of our unsupervised method compared to the tedious and error prone argument type\nidentification methods which depend on gazetteers and regular expressions. The analysis also shows\nsuperior generalization performance with utterances containing out of vocabulary (OOV) mentions.\nWe make our concept vectors and source code publicly available3 for the research community\nfor further experimentation and replication.\n2. Learning Concept Embeddings\n2.1. Skip-gram\nWe learn continuous vectors of words and entities by building upon the skip-gram model [2]. In\nthe conventional skip-gram model, a set of contexts are generated by sliding a context window of\npredefined size over sentences of a given text corpus. The vector representation of a target word is\nlearned with the objective to maximize the ability of predicting surrounding words of that target\nword.\nFormally, given a training corpus of V words w1 , w2 , ..., wV . The skip-gram model aims to\nmaximize the average log likelihood probability:\nV\n1 X\nV i=1\n\nX\n\nlog p(wi+j |wi )\n\n(1)\n\n−s≤j≤s,j6=0\n\nwhere s is the context window size, wi is the target word, and wi+j is a surrounding context word.\nThe softmax function is used to estimate the probability p(wO |wI ) as follows:\n|\nexp(vw\nuwI )\nO\np(wO |wI ) = PV\n|\nw=1 exp(vw uwI )\n\n2 https://concept.research.microsoft.com\n3 https://sites.google.com/site/conceptembeddings/\n\n3\n\n(2)\n\n\fwhere uw and vw are the input and output vectors respectively, and V is the vocabulary size.\nMikolov et al. [2] proposed hierarchical softmax and negative sampling as efficient alternatives to\napproximate the softmax function which becomes computationally intractable when V becomes\nhuge.\n2.2. Learning from Text\nOur approach genuinely learns distributed concept representations by generating concept contexts from mentions of those concepts in large encyclopedic text KBs such as Wikipedia. Utilizing\nsuch annotated KBs eliminates the need to manually annotate concept mentions and thus comes\nat no cost.\nHere we propose learning the embeddings of both words and concepts jointly. First, all concept\nmentions are identified in the given corpus. Second, contexts are generated for both words and\nconcepts from other surrounding words and other surrounding concepts as well. After generating\nall the contexts, we use the skip-gram model to jointly learn embeddings of words and concepts.\nFormally, given a training corpus of V words w1 , w2 , ..., wV . We iterate over the corpus identifying\nwords and concept mentions and thus generating a sequence of T tokens t1 , t2 , ...tT where T < V\n(as multiword concepts will be counted as one token). Afterwards we train the a skip-gram model\naiming to maximize:\nT\nX\n1X\nlog p(ti+j |ti )\n(3)\nLt =\nT i=1\n−s≤j≤s,j6=0\n\nwhere as in the conventional skip-gram model, s is the context window size. Here, ti is the target\ntoken which would be either a word or a concept mention, and ti+j is a surrounding context word\nor concept mention.\n2.3. Learning from Concept Graph\nWe employ Probase, a large scale probabilistic KB of millions of concepts and their relationships\n(basically is-a). Probase was created by mining billions of Web pages and search logs of Microsoft’s\nBing4 repository using syntactic patterns. The concept KB was then leveraged for text conceptualization to support text understanding tasks such as clustering of Twitter messages and News titles\n[11, 12], search query understanding [13], short text segmentation [14], and term similarity [15].\nProbase has a different modality than Wikipedia because the knowledge is organized as a graph\nwhose nodes are concepts and edges represent weighted is-a relationship between pairs of concepts.\nFormally, We model Probase as a 4-tuple graph G = (C, E, TC , TE ) such that:\n• C is a set of vertices representing concepts.\n• E is a set of edges (arcs) connecting pairs of concepts.\n• TC is a finite set of tuples representing global statistics of each concept (i.e. its total occurrences).\n• TE is a finite set of tuples representing co-statistics of each edge connecting pairs of concepts\n(i.e. their co-occurrence count).\n4 https://www.bing.com/\n\n4\n\n\fUnder this representation, location information is lost. Therefore the context of each concept\ncan be defined by the set of its neighbors in the graph. Formally, the skip-gram optimization\nfunction would be maximizing:\nLp =\n\n|C|\n1 X X\nlog p(cj |ci )\n|C| i=1\n\n(4)\n\n(i,j)∈E\n\n2.4. Data and Model Training\n2.4.1. Wikipedia\nWe utilize a recent Wikipedia dump of August 20165 , which has ∼7 million articles. We extract\narticles plain text discarding images and tables. We also discard References and External links\nsections (if any). We prune both articles not under the main namespace. Eventually, our corpus\ncontained ∼5 million articles in total. We preprocess each article replacing all its references to other\nWikipedia articles with the their corresponding article IDs. In case any of the references is a title\nof a redirect page, we use the page ID of the original page to ensure that all concept mentions are\nnormalized to their article IDs.\n2.4.2. Probase\nWe use Probase data repository6 which contains ∼5 million unique concepts, ∼12 million unique\ninstances, and ∼85 million is-a relationships. We follow a simple exact string matching between\nWikipedia article titles and Probase concept names in order to align the concepts in both KBs and\ngenerate the final concepts set.\n2.4.3. Training\nWe call our model Concept Multimodal Embedding (CME). During training, we jointly train\nour model to maximize L = Lt + Lp which as mentioned before is estimated using the softmax\nfunction. Following Mikolov et al. [2], we utilize negative sampling to efficiently approximate the\nsoftmax function by replacing every log p(wO |wI ) term in the softmax function (equation 2) with:\n|\nlog σ(vw\nuwI ) +\nO\n\nk\nX\n\n|\nEws ∼Pn (w) [log σ(−vw\nu )]\ns wI\n\n(5)\n\ns=1\n\nwhere k is the number of negative samples drawn for each term, and σ(x) is the sigmoid function\n( 1+e1−x ). For text learning, we use a context window of size 9. We set the vector size to 500\ndimensions and train the model for 10 iterations using 12 cores machine with 64GB of RAM. Our\nmodel takes ∼15 hours to train. The total vocabulary size is ∼12.7 million including words and\nconcepts.\n5 http://dumps.wikimedia.org/enwiki/\n6 https://concept.research.microsoft.com/Home/Download\n\n5\n\n\fDataset/Questions\nMethod\nWord2Vecsg\nWord2Vecsg b\nGlove\nMPME\nCME\n\nSemantic\n(8,869)\n58\n78.1\n80.8\n71.6\n91.4\n\nSyntactic\n(10,675)\n61\n62.8\n61.5\n54.6\n61.7\n\nAll\n(19,544)\n59.5\n69.8\n70.3\n63.1\n75.2\n\nTable 1: Results of analogical reasoning, given as percent accuracy. Our CME model gives the best result on semantic\nanalogies and higher overall accuracy than all other models.\n\n3. Evaluation\n3.1. Analogical Reasoning\nMikolov et al. [16] introduced this intrinsic evaluation scheme to assess the capacity of the\nembedding model to learn a vector space with meaningful substructure. Typically, analogies take\nthe form ”a to b is same as c to ?” where a, b, and c are elements of the vocabulary V . Using\nvector arithmetic, this can be answered by identifying d such that d = arg max Sim(vec(d), vec(b)−\nvec(a) + vec(c)), ∀d ∈ V − {a, b, c} where Sim is a similarity function7 . A good performance on this\ntask indicates the model’s ability to learn semantic and syntactic patterns as linear relationships\nbetween vectors in the embedding space [3].\n3.1.1. Dataset\nWe use the word analogies dataset [1]. The dataset contains 19,544 questions divided into\nsemantic analogies (8,869), and syntactic analogies (10,675). The semantic analogies are questions\nabout country capitals, state cities, country currencies...etc. For example, ”cairo to egypt is same as\nparis to france”. The syntactic analogies are questions about verb tenses, opposites, and adjective\nforms. For example, ”big to biggest is same as great to greatest”. In order to leverage the concept\nvectors, we first identify the corresponding entity of each analogy word and use its vector. If the\nword has no corresponding entity or corresponds to a disambiguation page under Wikipedia we use\nits word vector instead.\n3.1.2. Compared Systems\nWe compare our model to various word and entity embedding methods including:\n1. Word embeddings: a) Word2Vecsg , word embedding model trained on Wikipedia using\nskip-gram [1], b) Word2Vecsg b , a baseline model we created by training the skip-gram model\non the same Wikipedia dump we used for our CME model, and c) GloVe, word embedding\nmodel trained on Wikipedia [3].\n2. Entity mention embeddings: MPME, a recent model proposed by Cao et al. [7]. The\nmodel jointly learn embeddings of words and entity mentions by training the skip-gram on\nWikipedia and utilizing anchor texts to generate multi-prototype entity mention embeddings.\n7 Cosine\n\nsimilarity or dot product if vectors are normalized.\n\n6\n\n\f3.1.3. Results\nWe report the accuracy scores of analogical reasoning in Table 1. As we see, our CME model\noutperforms all other models by significant percentages on the semantic analogies. The closest\nperforming model (Glove) is ∼10% less accurate. Performance on syntactic analogies is still very\ncompetitive to Word2Vecsg b and GloVe. Overall, our model is ∼ 5% better than the closest\nperforming model.\n3.1.4. Error Analysis\nLocal context window models like ours generally perform better on semantic analogies than\nsyntactic ones. This indicates that syntactic regularities in most textual corpora are more difficult\nto capture than semantic regularities. A possible reason could be the more morphological variations\nof verbs and adjectives than nouns. Our model training is even more biased toward capturing\nsemantic relationships between concepts by incorporating knowledge from Probase concept graph.\nThis bias caused our model to produce more semantic predictions on the syntactic analogies than the\nWord2Vecsg b baseline, returning a semantically related word to the answer. For instance, our model\npredicted ”fast” rather than ”slows” 9 times compared to 2 times by Word2Vecsg b . And ”large”\nrather than ”smaller” 14 times compared to 1 time by Word2Vecsg b , Another set of errors were\npredicting the correct word but with wrong ending especially ”ing”. For instance, ”implementing”\nrather than ”implements” 27 times compared to 19 time by Word2Vecsg b . We argue that, despite\nthis bias, our CME model still produces very competitive performance compared to other models on\nsyntactic analogies. And more importantly, emphasizing the semantic relatedness between concepts\nduring training contributes to the significant accuracy gains on the semantic analogies.\n3.2. Concept Learning\nConcept learning is a cognitive process which involves classifying a given concept/entity to one\nor more candidate categories (e.g., ”milk” as beverage, dairy product, liquid...etc). This process is\nalso known as concept categorization8 [5].\nAutomated concept categorization can be viewed as both intrinsic and extrinsic evaluation. It\nis intrinsic because a ”good” embedding model would generate clusters of concepts belonging to\nthe same category. And optimally place the category vector at the center of its instances cluster.\nOn another hand, it is extrinsic as the embedding model could be leveraged in many knowledge\nmodeling tasks such as KB construction (promoting new concepts), KB completion (inferring new\nrelationships between concepts), and KB curation (removing noisy or assessing weak relationships).\nSimilar to Li et al. [5], we assign a given concept to a target category using Rocchio classification\n[17], where the centroid of each category is set to the category’s corresponding embedding vector.\nFormally, given a set of n candidate concept categories G = {g1 , ..., gn }, an instance concept c, an\nembedding function f , and a similarity function Sim, then c is assigned to the ith category gi such\nthat gi = arg maxi Sim(f (gi ), f (c)). Under our CME model, the embedding function f would\nalways map the given concept to its vector.\n3.2.1. Bootstrapping\nWe leverage bootstrapping in order to improve the categorization accuracy without the need\nfor labeled data. In the context of concept learning, we start with the vectors of target category\n8 In\n\nthis paper, we use concept learning and concept categorization interchangeably\n\n7\n\n\fAlgorithm 1: Classification + Bootstrapping\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\nInput: U = {(l1 , ul1 ), ..., (ln , uln )}: labels + embeddings\nD = {(d1 , vd1 ), ..., (dm , vdm )}: instances + embeddings\nN: number of bootstrap instances\nResult: L = {..., (di , lj ), ...}: label assignment for each instance\nrepeat\ncandidates ← {l1 : φ, ..., ln : φ}\nforeach (d, vd ) ∈ D do\ndmax sim = 0\ndmax label = null\nforeach (l, ul ) ∈ U do\nsiml = Sim(vd , ul )\nif siml > dmax sim then\ndmax sim = siml\ndmax lebel = l\nend\nend\nadd (d, dmax sim ) to candidates[l]\nend\nforeach (l, candidatesl ) ∈ candidates.items do\nrepeat\nscoremax = 0\ndmax = null\nforeach (d, scored ) ∈ candidatesl do\nif scored > scoremax then\nscoremax = scored\ndmax = d\nend\nend\nadd (dmax , l) to L\nul ← ul + vd\nremove d from candidatesl\nremove d from D\nuntil N highest scored instances added\nend\nuntil D = φ\n\n. most similar instance so far\n\n. assign class label\n. bootstrap label embedding\n\n. no more instances to classify\n\nconcepts as a prototype view upon which categorization assignments are made (e.g., vec(bird),\nvec(mammal)...etc). We leverage bootstrapping by iteratively updating this prototype view with the\nvectors of concept instances we are most confident. For example, if ”deer” is closest to ”mammal”\nthan any other instance in the dataset, then we update the definition of ”mammal” by performing\nvec(mammal)+=vec(deer), and repeat the same operation for other categories as well. This way, we\nadapt the initial prototype view to better match the specifics of the given data. Algorithm 1 presents\nthe pseudocode for performing concept categorization with bootstrapping. In our implementation,\nwe bootstrap the category vector with vectors of the most similar N instances at a time. Another\nimplementation option might be defining a threshold and bootstrapping using vectors of N instances\nif their similarity scores exceed that threshold.\n3.2.2. Datasets\nAs in Li et al. [5], we utilize two benchmark datasets: 1) Battig test [18], which contains 83\nsingle word concepts (e.g., cat, tuna, spoon..etc) belonging to 10 categories (e.g., mammal, fish,\nkitchenware..etc), and 2) DOTA which was created by Li et al. [5] from Wikipedia article titles\n(entities) and category names (categories). DOTA contains 300 single-word concepts (DOTAsingle) (e.g., coffee, football, semantics..etc), and (150) multiword concepts (DOTA-mult) (e.g.,\nmasala chai, table tennis, noun phrase..etc). Both belong to 15 categories (e.g., beverage, sport,\n\n8\n\n\fDataset/Instances\nMethod\nWESenna\nWEM ikolov\nTransE1\nTransE2\nTransE3\nCE\nHCE\nWEb\n+bootstrap\nCME\n+bootstrap\n\nBattig\n(83)\n44\n74\n66\n75\n46\n79\n87\n77\n88\n94\n100\n\nDOTA-single\n(300)\n52\n72\n72\n80\n55\n89\n93\n93\n97\n91\n99\n\nDOTA-mult\n(150)\n32\n67\n69\n77\n52\n85\n91\n86\n86\n88\n95\n\nDOTA-all\n(450)\n45\n72\n71\n79\n54\n88\n92\n91\n90\n90\n98\n\nTable 2: Results of the concept categorization task, given as percent accuracy. Our CME model with bootstrapping\ngives the best results outperforming all other models and baselines.\n\nlinguistics..etc). Performance is measured in terms of the ability of the system to assign concept\ninstances to their correct categories.\n3.2.3. Compared Systems\nWe compare our model to various word, entity, and category embedding methods including:\n1. Word embeddings: Collobert et al. [19] model (WESenna ) trained on Wikipedia. Here\nvectors of multiword concepts are obtained by averaging their individual word vectors. We\nalso create a baseline model (WEb ) by training the skip-gram model on the same Wikipedia\ndump we used for our CME model.\n2. MWEs embeddings: Mikolov et al. [2] model (WEM ikolov ) trained on Wikipedia. This\nmodel jointly learns single and multiword embeddings where MWEs are identified using corpus\nstatistics.\n3. Entity-category embeddings: which include Bordes et al. [20] embedding model (TransE).\nThis model utilizes relational data between entities in a KB as triplets in the form (entity,relation,entity) to generate representations of both entities and relationships. Li et al. [5]\nimplemented three variants of this model (TransE1 , TransE2 , TransE3 ) to generate representations for entities and categories jointly. Two other models introduced by Li et al. [5] are CE\nand HCE. CE generates embeddings for concepts and categories using category information of\nWikipedia articles. HCE extends CE by incorporating Wikipedia’s category hierarchy while\ntraining the model to generate concept and category vectors.\n3.2.4. Results\nWe report the accuracy scores of concept categorization in Table 2. Accuracy is calculated by\ndividing the number of correctly classified concepts by the total number of concepts in the given\ndataset. Scores of all other methods except WEb are obtained from Li et al. [5]. As we can see\nin Table 2, our CME+bootstrap model outperforms all other models by significant percentages.\nAnd even achieves 100% accuracy on the Battig dataset. With single word concepts, CME achieves\n9\n\n\fNo\n1\n2\n\nUtterance\nwhere is new orleans\nwhere is ci0\nwhat states border the mississippi river\nhow many states border ri0\n\n3\n\nlist flights from philadelphia to san francisco via dallas\nlist flight from ci0 to ci1 via ci2\n\n4\n\nflights from jfk or la guardia to cleveland\nflight from ap0 or ap1 to ci0\n\nLogical form\n( lambda $0 e ( loc:t new orleans la:ci $0 ) )\n( lambda $0 e ( loc:t ci0 $0 ) )\n( lambda $0 e ( and ( state:t $0 )\n( next to:t $0 mississippi river:r ) ) )\n( count $0 ( and ( state:t $0 ) ( next to:t $0 ri0 ) ) )\n( lambda $0 e ( and ( flight $0 )\n( from $0 philadelphia:ci ) ( to $0 san francisco:ci )\n( stop $0 dallas:ci ) ) )\n( lambda $0 e ( and ( flight $0 ) ( from $0 ci0 )\n( to $0 ci1 ) ( stop $0 ci2 ) ) )\n( lambda $0 e ( and ( flight $0 ) ( or ( from $0 jfk:ap )\n( from $0 lga:ap ) ) ( to $0 cleveland:ci ) ) )\n( lambda $0 e ( and ( flight $0 ) ( or ( from $0 ap0 )\n( from $0 ap1 ) ) ( to $0 ci0 ) ) )\n\nTable 3: Example utterances and their corresponding logical forms from the geography and flights domains. Left,\nutterances before and after argument type identification. Right, logical forms before and after argument type\nidentification. City is mapped to ci, Airport to ap, and River to ri.\n\nthe best performance on Battig and competitive performance on DOTA-single. When it comes to\nmultiword concepts, our CME model comes second after HCE.\n3.2.5. Analysis\nIs bootstrapping a magic bullet?. A first look at the results of CME+bootstrap vs. CME might\nindicate that if bootstrapping is applied to HCE or WEb which perform better than CME on\nsome datasets, their performance would still be superior. However, the results of WEb +bootstrap\nshow that the margin of performance gains of bootstrapping is not necessarily proportional to\nthe performance of the model without it. For example, WEb +bootstrap performs worse than\nCMEb +bootstrap on DOTA-single though WEb was initially better than CME. This means that\nbootstrapping other better performing models such as HCE might not be as beneficial as it is to\nCME. The bottom line here that: the model should learn a semantic space with optimal substructures which clusters instances of the same category together and keep them far from instances of\nother categories. This is clearly the case with our CME model which ends up having (near-)optimal\ncategory vectors with bootstrapping.\n3.3. Argument Type Identification: A Case Study\nIn this section, we present a case study to analyze the impact of using our concept vectors\nfor unsupervised argument type identification with semantic parsing as an end-to-end task. In a\nnutshell, semantic parsing is concerned with mapping natural language utterances into executable\nlogical forms [21]. The logical form is subsequently executed on a knowledge base to answer the\nuser question. Table 3 shows some example utterances and their corresponding logical forms from\nthe geography and flights domains.\n3.3.1. Argument Identification\nAs we can notice from the examples in Table 3, user utterances usually contain mentions of\nentities of various types (e.g., city, state, and airport names). These mentions are typically parsed\nas arguments in the resulting logical form. Some of these mentions could be rare or even missing in\nthe training data. As noted by Dong and Lapata [22], this problem reduces the model’s capacity\nto learn reliable parameters for such mentions.\n\n10\n\n\fOne possible solution is to preprocess the training data replacing all entity mentions with their\ntype names (e.g., san francisco to city, california to state...etc). This step allows the model to see\nmore identical input/output patterns during training and thus better learn the parameters of such\npatterns. The model would also generalize better to out of vocabulary mentions because the same\npreprocessing could be done at test time.\nDong and Lapata [22] proposed using gazetteers and regular expressions for argument identification. The authors also demonstrated increased accuracy when employing such approach. However,\nusing regular expressions is error prone as the same utterance could be paraphrased in many different ways. In addition, gazetteers usually have low recall and will not cover many surface forms\nof the same entity mention.\nIn this paper, we embrace argument type identification in a totally unsupervised fashion. The\nidea is to build upon the promising performance we achieved in concept categorization and apply\nthe same scheme to map entity mentions to their corresponding type names. Our unsupervised\nargument type identification is a four step process: 1) we predefine target entity types and retrieve\ntheir corresponding vectors from our CME model, 2) we identify entity mentions in user utterances\n(e.g., mississippi river), 3) we lookup the mention vector in our CME model, and 4) we compute the\nsimilarity between the mention vector and each of the predefined target entity types and choose the\nmost similar type if it exceeds a predefined threshold. This scheme is efficient and doesn’t require\nany manually crafted rules or heuristics. The only needed parameter is the similarity threshold\nwhich we fix to 0.5 during experiments.\nNote that, standard off-the-shelf entity recognition systems could help in identifying the entity\nmentions but not their type names. In domains like flights, we are interested in non standard\ntypes such as airports and airlines. It is also important to distinguish between city, state, and\ncountry mentions in the geography domain and not classifying all instances of these categories as\nthe standard location type.\n3.3.2. Datasets\nWe analyze our unsupervised scheme on two datasets9 : 1) GEO which contains a total of 880\nutterances about U.S. geography [23]. The dataset is split into 680 training instances and 200 test\ninstances. Here we target identifying five entity types: city, state, river, mountain, and country, and\n2) ATIS which contains 5,410 utterances about flight bookings split into 4,480 training instances,\n480 development instances, and 450 test instances. Here we target identifying six entity types: city,\nstate, airline, airport, day name, and month.\n3.3.3. Model & Training\nWe assess the performance of argument type identification by training Dong and Lapata [22]\nneural semantic parsing model10 . The model utilizes sequence-to-sequence learning with neural\nattention (see [22] for more details). We use the Seq2Seq variant of the model and do not perform\nany parameter tuning as our purpose is to analyze the performance before and after argument type\nidentification not to get a state-of-the-art performance on these datasets.\n9 We\n\nobtained the raw dataset files by contacting the authors of Dong and Lapata [22]\n\n10 https://github.com/donglixp/lang2logic\n\n11\n\n\fDataset\nw/o Identification\nw/ Identification\n\nGEO\n68.6\n77.1\n\nATIS\n73.2\n83.7\n\nTable 4: Results of semantic parsing before and after argument type identification, given as percent accuracy. Using\nCME to identify argument types resulted in improved accuracy on both datasets.\n\n3.3.4. Results\nWe report parsing accuracy in Table 4. Accuracy is defined as the proportion of the input\nutterances whose logical form is identical to the gold standard. As we can see, our argument type\nidentification scheme resulted in significant accuracy improvements of ∼10% on both datasets.\n3.3.5. Error Analysis\nTraining the Seq2Seq semantic parsing model on preprocessed data is clearly beneficial and\nmotivating as the results in Table 4 show. Without argument identification, the model is prone to\nthe out of vocabulary problem. For example, on GEO we spotted 24 test instances with entities\nnot mentioned in the training data (e.g., new jersey, chattahoochee river). The same on ATIS with\n23 instances. Another source of errors was due to rare mentions. For example, ”portland” appeared\nonce in GEO training data.\nAlthough our scheme demonstrated good ability to capture most entity mentions and map them\nto their correct type names. There was some subtle failure cases. For example, in ”what length is\nthe mississippi”, our scheme mapped ”mississippi” to the state, while it was mapped to the river\nin the gold standard logical form. Another example was mapping ”new york” to the city in ”what\nis the density of the new york”, while it was mapped to the state in the gold standard.\nOverall, the results show competitive performance of our unsupervised method compared to the\ntedious and error prone argument type identification methods. The analysis also shows superior\ngeneralization performance using unsupervised argument identification with utterances containing\nout of vocabulary and rare mentions.\n4. Related Work\nNeural embedding models have been proposed to learn distributed representations of concepts\nand entities. Song and Roth [24] proposed using the popular Word2Vec model [1] to obtain the\nembeddings of each concept by averaging the vectors of the concept’s individual words. For example, the embeddings of ”Microsoft Office” would be obtained by averaging the embeddings of\n”Microsoft” and ”Office” obtained from the Word2Vec model. Clearly, this scheme fails when the\nsemantics of multiword concepts is different from the compositional meaning of their individual\nwords.\nMore robust entity embeddings can be learned from the entity’s corresponding article and/or\nfrom the structure of the employed KB (e.g., its link graph) as in [4, 5, 8, 10] who all utilize the\nskip-gram model, but differ in how they define the context of the target concept. However, all these\nmethods utilize one KB only (Wikipedia), to learn entity representations. Our approach, on the\nother hand, besides Wikipedia, learns better entity representations by exploiting the conceptual\nknowledge in a weighted KB graph (Probase).\nUnlike Hu et al. [4] and Li et al. [5] who learn entity embeddings only, our proposed CME model\nmaps both words and concepts into the same semantic space. In addition, compared to Yamada\n12\n\n\fet al. [8] model which also learns words and entity embeddings jointly, we better model the local\ncontextual information of entities and words in Wikipedia as a textual KB. During training, we\ngenerate word-word, word-concept, concept-word, and concept-concept contexts (cf. equation 3).\nIn Yamada et al. [8] model, concept-concept contexts are generated from Wikipedia link graph not\nfrom their raw mentions in Wikipedia text.\nExploiting all surrounding concept tokens to a target concept allows us, given another corpus\nwith annotated concept mentions, to easily harness concept-concept contexts from this corpus even\nif the corpus has no link structure (e.g., news stories, scientific publications, medical guidelines...etc).\nOur proposed model is computationally less costly than Hu et al. [4] and Yamada et al. [8]\nmodels as it requires few hours rather than days to train on similar computing resources.\n5. Conclusion & Discussion\nConcepts are lexical expressions (single or multiwords) that denote an idea, event, or an object\nand typically have a set of properties associated with it. In this paper we introduced a neural-based\napproach for learning embeddings of explicit concepts based on the skip-gram model. Our approach\nlearns concept representations from mentions in free text corpora with annotated concept mentions\nwhich even if not available could be obtained through state-of-the-art entity linking systems. We\nalso proposed an effective and seamless adaption to the skip-gram learning scheme in order to\nlearn concept vectors from two large scale knowledge bases of different modalities (Wikipedia, and\nProbase).\nWe presented thorough evaluation of the learned concept embeddings intrinsically and extrinsically. Our performance on the analogical reasoning produced a new state-of-the-art performance\nof 91% on semantic analogies.\nEmpirical results on two datasets for performing concept categorization show superior performance of our approach over other word and entity embedding models.\nWe also presented a case study to analyze the feasibility of using the learned vectors for argument\nidentification with neural semantic parsing. The analysis shows significant performance gains using\nour unsupervised argument type identification scheme and better handling of out of vocabulary\nentity mentions.\nTo our knowledge, this work is the first to combine knowledge from both Wikipedia and Probase\ninto a unified representation. Our concept space is all Wikipedia article titles (∼5 million). We\nuse Probase as another source of conceptual knowledge to generate more concept-concept contexts\nand subsequently learn better concept vectors. In this spirit, we first filter Probase graph keeping\nonly edges whose both vertices are Wikipedia concepts. Using string matching, ∼1 million unique\nProbase concepts were mapped to Wikipedia articles. Note that, we still use the contexts generated\nfrom the 5 million Wikipedia concepts and add to them those contexts obtained from the filtered\nProbase graph. Out of the ∼12.7 million vectors in our model, we have ∼5 million concept vectors\nand ∼7.7 million word vectors.\nOne important future improvement is to better match entities from both Wikipedia and Probase.\nFor example, using string edits to increase recall or graph matching techniques to increase precision.\nDespite using the string matching, the performance of our method is superior compared to other\nmethods utilizing Wikipedia only. It is expected that string matching might produce incorrect\nmappings. However, it is important to mention that our string matching exploits the redirect pages\ntitles as well as the canonical titles of Wikipedia articles which increases the recall. For example,\n\n13\n\n\fin Probase, nyc, city of new york, new york city are all matched with same Wikipedia article New\nYork City.\nOur initial qualitative analysis shows that it is common to match single-sense Wikipedia concepts\n(ss-Wiki) with multi-sense Probase concepts (ms-Pro) (e.g., Tiger and Rose). However, in many\nof these cases, the ms-Pro is dominated by the ss-Wiki. For example, Wikipedia’s page for Tiger\ndescribes the animal. In Probase, Tiger is-a Animal and Tiger is-a Big cat has more co-occurrences\n(917 & 315 respectively) compared to Tiger is-a Dance (1 co-occurrence). Same for Rose which\nis described in Wikipedia as flowering plant. In Probase, Rose is-a Flower has (906) and Rose\nis-a Plant has (487) co-occurrences compared to Rose is-a Garden (10) and Rose is-a Odor (5) cooccurrences. We believe this would help generating more consistent contexts from Wikipedia and\nProbase. On the other hand, such multiple sense concepts in Probase could be leveraged for tasks\nlike sense disambiguation and multi-prototype embeddings along the lines of Camacho-Collados\net al. [9], Iacobacci et al. [25], and Mancini et al. [26].\nOne important aspect of our CME model is its ability to better model the long tail entities\nwith few mentions. Existing approaches that utilize Wikipedia’s link graph treat Wikipedia as\nunweighted directed KB graph. During training, a context is generated for entities e1 and e2 if\ne1 has incoming/outgoing link from/to e2 . This mechanism would poorly model rare/infrequent\nWikipedia concepts which have few incoming links (i.e. few mentions). We, alternatively, exploit\nProbase link structure modeling it as a weighted undirected KB graph. We also utilize the cooccurrence counts between pairs of concepts (cf. Figure 1). Therefore, we generate more conceptconcept contexts resulting in better representations of the long-tail concepts. Consider for example\nNightstand which has in Wikipedia 17 incoming links. In Probase, Nightstand is-a Furniture, is-a\nCasegoods, and is-a Bedroom furniture with co-occurrences 47, 47, and 32 respectively. This is a\n100+ more contexts than we can generate from Wikipedia. Even for frequent Wikipedia concepts,\nour model by exploiting the co-occurrence counts will reinforce concept-concept relatedness from\nthe many contexts obtained from Probase.\nAcknowledgment\nThis work was partially supported by the National Science Foundation under grant number\n1624035. Any opinions, findings, and conclusions or recommendations expressed in this material\nare those of the author(s) and do not necessarily reflect the views of the National Science Foundation.\nReferences\n[1] Mikolov T., Chen K., Corrado G., Dean J. Efficient estimation of word representations in\nvector space. arXiv preprint arXiv:130137812013;.\n[2] Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J. Distributed representations of\nwords and phrases and their compositionality. In: Advances in neural information processing\nsystems. 2013, p. 3111–9.\n[3] Pennington J., Socher R., Manning C.D. Glove: Global vectors for word representation. Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP\n2014)2014;12:1532–43.\n\n14\n\n\f[4] Hu Z., Huang P., Deng Y., Gao Y., Xing E.P. Entity hierarchy embedding. In: Proceedings\nof The 53rd Annual Meeting of the Association for Computational Linguistics. 2015,.\n[5] Li Y., Zheng R., Tian T., Hu Z., Iyer R., Sycara K. Joint embedding of hierarchical\ncategories and entities for concept categorization and dataless classification. arXiv preprint\narXiv:1607079562016;.\n[6] Ristoski P., Paulheim H. Rdf2vec: Rdf graph embeddings for data mining. In: International\nSemantic Web Conference. Springer; 2016, p. 498–514.\n[7] Cao Y., Huang L., Ji H., Chen X., Li J. Bridge text and knowledge by learning multiprototype entity mention embedding. In: Proceedings of the 55th Annual Meeting of the\nAssociation for Computational Linguistics (Volume 1: Long Papers); vol. 1. 2017, p. 1623–33.\n[8] Yamada I., Shindo H., Takeda H., Takefuji Y. Joint learning of the embedding of words\nand entities for named entity disambiguation. arXiv preprint arXiv:1601013432016;.\n[9] Camacho-Collados J., Pilehvar M.T., Navigli R. Nasari: Integrating explicit knowledge\nand corpus statistics for a multilingual representation of concepts and entities. Artificial\nIntelligence2016;240:36–64.\n[10] Shalaby W., Zadrozny W. Learning concept embeddings for efficient bag-of-concepts densification. arXiv preprint arXiv:1702033422017;.\n[11] Song Y., Wang H., Wang Z., Li H., Chen W. Short text conceptualization using a probabilistic knowledgebase. In: Proceedings of the Twenty-Second international joint conference\non Artificial Intelligence-Volume Volume Three. AAAI Press; 2011, p. 2330–6.\n[12] Song Y., Wang S., Wang H. Open domain short text conceptualization: A generative+\ndescriptive modeling approach. In: IJCAI. 2015, p. 3820–6.\n[13] Wang Z., Zhao K., Wang H., Meng X., Wen J.R. Query understanding through knowledgebased conceptualization2015;.\n[14] Hua W., Wang Z., Wang H., Zheng K., Zhou X. Short text understanding through lexicalsemantic analysis. In: Data Engineering (ICDE), 2015 IEEE 31st International Conference on.\nIEEE; 2015, p. 495–506.\n[15] Kim D., Wang H., Oh A.H. Context-dependent conceptualization. In: IJCAI. 2013, p.\n2330–6.\n[16] Mikolov T., Yih W.t., Zweig G. Linguistic regularities in continuous space word representations. In: hlt-Naacl; vol. 13. 2013, p. 746–51.\n[17] Rocchio J.J. Relevance feedback in information retrieval1971;.\n[18] Baroni M., Lenci A. Distributional memory: A general framework for corpus-based semantics.\nComputational Linguistics2010;36(4):673–721.\n[19] Collobert R., Weston J., Bottou L., Karlen M., Kavukcuoglu K., Kuksa P. Natural language\nprocessing (almost) from scratch. Journal of Machine Learning Research2011;12(Aug):2493–\n537.\n15\n\n\f[20] Bordes A., Usunier N., Garcia-Duran A., Weston J., Yakhnenko O. Translating embeddings\nfor modeling multi-relational data. In: Advances in neural information processing systems.\n2013, p. 2787–95.\n[21] Wang Y., Berant J., Liang P., et al. Building a semantic parser overnight.In: ACL (1). 2015,\np. 1332–42.\n[22] Dong L., Lapata M.\narXiv:1601012802016;.\n\nLanguage to logical form with neural attention.\n\narXiv preprint\n\n[23] Zettlemoyer L.S., Collins M. Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars. arXiv preprint arXiv:120714202012;.\n[24] Song Y., Roth D. Unsupervised sparse vector densification for short text similarity. In:\nProceedings of NAACL. 2015,.\n[25] Iacobacci I., Pilehvar M.T., Navigli R. Sensembed: Learning sense embeddings for word and\nrelational similarity. In: ACL (1). 2015, p. 95–105.\n[26] Mancini M., Camacho-Collados J., Iacobacci I., Navigli R. Embedding words and senses\ntogether via joint knowledge-enhanced training. arXiv preprint arXiv:1612027032016;.\n\n16\n\n\f",
         "train",
         "43918",
         "6876"
        ],
        [
         "3",
         "18561",
         "cs.AI",
         "Artificial Intelligence",
         "1802.06821v1.pdf",
         "336\n\nInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\nКОМПЛЕКСНЫЕ ИНСТРУМЕНТАЛЬНЫЕ СРЕДСТВА ИНЖЕНЕРИИ ОНТОЛОГИЙ\nВиталий Величко, Кирилл Малахов, Виталий Семенков, Александр Стрижак\nАннотация: В статье представлен обзор актуальных специализированных инструментальных\nсредств инженерии онтологий, а также средств аннотирования текстов на основе онтологий.\nРассмотрены основные функции и возможности данных инструментальных средств, их достоинства\nи недостатки. Описываются основные компоненты системы формирования онтологий на основе\nсемантического анализа текстовых массивов. Дается системный сравнительный анализ средств\nинженерии онтологий.\nКлючевые слова: онтология, инженерия знаний, проектирование онтологии предметной области,\nинструментальный комплекс онтологического назначения.\nACM Classification Keywords: I.2 ARTIFICIAL INTELLIGENCE - I.2.4 Knowledge Representation Formalisms\nand Methods, H. Information Systems – H.2 DATABASE MANAGEMENT – H.2.4 Systems\n\nВведение\nМетодология проектирования онтологии предметной области (ПрО) [Палагин, 2012] основывается на\nконструктивном использовании следующих категорий – множества концептов, отношений, функций\nинтерпретации и аксиом. Построение указанных множеств является трудоёмким процессом, как по\nвремени, так и по количеству вовлечённых в процесс проектирования высококвалифицированных\nспециалистов. Особенно трудоемко ручное проектирование онтологий, которое мало чем отличается от\nтематического проектирования экспертных систем.\nПонимание важности решения проблемы создания эффективных инструментальных средств поддержки\nпроцессов проектирования онтологии заданной ПрО, пришло практически одновременно с осознанием\nпарадигмы компьютерных онтологий. В настоящее время известно более ста инструментальных\nпрограммных систем [Гаврилова, 2000; Палагин, 2009], но только ограниченное количество комплексных\nпрограммных систем включают редактор онтологических структур, автоматизированное построение\nонтологий ПрО, средства поверхностного семантического анализа текстовых документов, используемых\nдля построения онтологии.\n\nОсновные характеристики комплексных программных систем проектирования онтологий\nК основным характеристикам комплексных программных систем онтологического инжиниринга можно\nотнести: поддерживаемые формализмы и форматы представления онтологий, архитектура программного\nобеспечения, интерфейс пользователя, функционал редактора онтологии, средства хранения онтологий,\nдоступность, дополнительные возможности. Ниже рассмотрим более подробно некоторые из\nприведенных характеристик.\n\n\fInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\n337\n\nПоддерживаемые формализмы и форматы представления онтологий\nПод формализмом понимается некоторая формальная теория [Клини, 1957], лежащая в основе способа\nпредставления онтологических знаний (логика предикатов, фреймовые модели, дескриптивная логика,\nконцептуальные графы и др.). Выбранный формализм существенно влияет на организацию внутренних\n(компьютерных) структур данных и может определять их формат представления.\nФормат представления онтологий задаёт вид их хранения в библиотеке, способ передачи онтологических\nописаний другим потребителям и метод обработки ее концептов. В качестве форматов онтологических\nописаний разработаны определенные языки представления онтологий, наиболее известными из которых\nявляются OWL, RDFS, KIF.\nНекоторые из известных редакторов онтологий поддерживают работу с несколькими формализмами\nпредставления, однако следует учитывать тот факт, что обычно конкретный формализм является\nпредпочтительным для конкретного редактора [Палагин, 2009].\nФункциональность редактора онтологии\nФункциональность редактора онтологии является одной из самых важных характеристик, под которой\nпонимается множество предоставляемых пользователю сервисов работы с онтологическими структурами.\nБазовый набор функций редактора онтологии обычно обеспечивает:\nработу с одним или несколькими онтологическими описаниями (проектами) одновременно;\nграфический интерфейс пользователя;\nредактирование онтологии (создание, редактирование, удаление концептов, отношений, аксиом и\nпрочих структурных элементов онтологии);\nинкапсулирование онтологий в среду информационных систем.\nДополнительные возможности\nК дополнительным возможностям относят поддержку языка запросов, анализ целостности, использование\nмеханизма логического вывода, поддержку удалённого доступа через Интернет, документирование.\nИзвестны три группы инструментальных средств (ИнС) онтологического инжиниринга [Овдей, 2006]. К\nпервой группе относят инструменты создания онтологий, которые предполагают поддержку совместной\nразработки и просмотра, создание онтологии в соответствии с заданной (произвольной) методологией,\nподдержку рассуждений.\nКо второй группе относят инструменты объединения, отображения и выравнивания онтологий.\nОбъединение предполагает нахождение сходств и различий между исходными онтологиями и создание\nрезультирующей онтологии, которая содержит элементы исходных онтологий. Для этого ИнС\nавтоматически определяют соответствия между концептами или обеспечивают графическую среду, в\nкоторой пользователь сам находит эти соответствия. Процедура отображения заключается в нахождении\nсемантических связей между концептами различных онтологий. Процедура выравнивания онтологий\nустанавливает различные виды соответствия между двумя онтологиями, информация о которых\nсохраняется для дальнейшего использования в приложениях пользователя [Noy, 1999].\n\n\f338\n\nInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\nК третьей группе относят инструменты для аннотирования Web-ресурсов на основе онтологий.\nСодержательный обзор известных инструментов инженерии онтологий, в котором рассмотрены основные\nфункции и возможности ИнС, их достоинства, недостатки, сравнительный анализ и описание известных\nдоступных онторедакторов, также приведен в [Овдей, 2006; Noy, 1999; Calvanese, 2007; Филатов, 2007].\nОбщими недостатками большинства известных инструментальных средств являются:\nотсутствие процедур автоматического (автоматизированного) формирования компонент онтологии;\nанглоязычный интерфейс с пользователем, в котором (для большинства ИнС) не предусмотрено\nприсвоение имён компонентам онтологии на русском или украинском языке;\nструктуризация концептов выполняется только по одному типу отношений;\nдля большинства общедоступных ИнС не предусмотрена работа с большими по объёму\nонтологиями (например, для OntoEditFree – до 50 концептов);\nбольшинство инструментов хранит свои онтологии в текстовых файлах, что ограничивает скорость\nдоступа к онтологиям;\nзадекларированные функциональные возможности для общедоступных инструментов зачастую так\nи остаются нереализованными;\nнедостаток информации для пользователей в инструкциях.\nРассмотрим более подробно некоторые инструментальные программные системы, предназначенные для\nпостроения онтологий и их использования для решения задач. Универсальные и специализированные\nоболочки программных систем являются средством, упрощающим процесс создания интеллектуальной\nсистемы [Артемьева, 2008]. Универсальные оболочки основаны на использовании некоторого\nуниверсального языка представления знаний. В специализированных оболочках при представлении\nзнаний используется специфичная для предметной области схема, определяемая онтологией той\nобласти, для которой создается оболочка, что позволяет создавать базу знаний эксперту предметной\nобласти без участия посредника, которым является инженер знаний. В сложно-структурированных\nпредметных областях, связанных с наукой, могут изменяться не только знания, но и онтологии, и, как\nследствие, множество классов решаемых задач. Описание особенностей специализированных оболочек\nинтеллектуальных систем для сложно-структурированных предметных областей приведено на основе\nстатьи «Интеллектуальная система, основанная на многоуровневой онтологии химии» [Артемьева, 2008].\n\nСпециализированная оболочка интеллектуальной системы для сложно-структурированных предметных областей\nИнформационными компонентами специализированной оболочки для сложно-структурированной ПрО\nявляются многоуровневая модульная онтология и модульная база знаний. Создание и редактирование\nинформационных компонент осуществляется многоуровневым редактором онтологий и редактором\nзнаний, разработка которых основывается на онтологии уровня n.\nРедакторы многоуровневых онтологий и знаний должны позволять создание и редактирование\nмодульных онтологий и знаний, а также обеспечивать возможность повторного использования модулей\n\n\fInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\n339\n\nпри создании онтологий и знаний новых разделов и подразделов области, причем процесс создания и\nредактирования модуля онтологии уровня i-1 должен управляться онтологией уровня i, а процесс\nсоздания и редактирования модуля знаний – онтологией уровня 2.\nРедактор онтологии должен обеспечивать возможность выбора того из существующих модулей онтологии\nуровня i, который управляет процессом редактирования создаваемого модуля. Аналогично при\nредактировании модуля знаний должна обеспечиваться возможность выбора «управляющего» модуля\nонтологии уровня 2.\nРедакторы онтологии и знаний должны обеспечивать возможность задания структурированной и\nнеструктурированной части онтологии, а также структурированной и неструктурированной части знаний,\nт. е. программным компонентом этих редакторов должен быть специализированный редактор\nутверждений, позволяющий вводить онтологические соглашения и законы предметной области.\nРедактор знаний должен обеспечивать возможность ввода/вывода значений нестандартных величин при\nредактировании знаний. Для значений нестандартных величин в предметной области может\nсуществовать способ их графического представления. Например, для химии [Артемьева, 2008]\nграфически может быть задана краткая структурная формула или структурная формула химического\nсоединения. Поэтому редактор знаний должен обеспечивать возможность использования принятого в\nпредметной области графического способа представления значений нестандартных величин при\nсоздании и редактировании знаний. Величина, которой принадлежит значение некоторого свойства,\nзадается онтологией уровня 2. Поэтому редактор знаний должен обеспечивать автоматический выбор\n(управляемый онтологией уровня 2) средств для графического представления значений нестандартных\nвеличин при редактировании знаний.\nРедактор онтологии интерпретирует онтологию уровня i при создании модуля онтологии уровня i-1.\nРедактор знаний интерпретирует онтологию уровня 2 при создании модуля знаний. Одна и та же\nонтология может интерпретироваться разными способами в разных редакторах знаний. Редакторы знаний\nмогут отличаться не только способом интерпретации знаний, но и интерфейсом. Очевидно, что более\nудобный интерфейс и более понятный эксперту способ интерпретации можно обеспечить для редактора,\nпредназначенного\n\nдля\n\nинтерпретации\n\nодной\n\nонтологии,\n\nа\n\nне\n\nкласса\n\nонтологий.\n\nПоэтому\n\nспециализированная оболочка должна позволять использование редакторов, поддерживающих разные\nспособы интерпретации модуля онтологии уровня 2 и предоставлять возможность эксперту выбора\nтребуемого ему редактора знаний.\nЗначения нестандартных величин используются не только при редактировании знаний, но также при\nвводе исходных данных задач. Графический способ задания исходных данных задач более удобен для\nспециалиста предметной области, поскольку в этом случае отсутствует необходимость громоздкого\nвербального описания этих данных. Графическое представление результатов решения является более\nнаглядным способом представления. Поэтому оболочка должна обеспечивать возможность ввода/вывода\nзначений нестандартных величин при задании исходных данных задач, а также позволять использование\n\n\f340\n\nInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\nпринятого в предметной области графического способа представления значений нестандартных величин\nпри вводе исходных данных задач и выводе результатов их решения.\nКак уже отмечалось, величина, которой принадлежит значение некоторого свойства, задается онтологией\nуровня 2. Оболочка должна обеспечивать автоматический выбор (управляемый онтологией) средств для\nграфического представления значений нестандартных величин при задании исходных данных задач.\nКаждый раздел сложно-структурированной ПрО характеризуется своим множеством классов прикладных\nзадач, причем разные множества могут содержать как общие классы задач, так и специфичные для\nраздела. Решатель задач может быть предназначен для решения классов задач одного раздела (в этом\nслучае он использует онтологию и знания этого раздела), либо разных разделов (в этом случае он может\nиспользовать разные онтологии и знания). В первом случае используемая решателем онтология\nопределяется классом задач. Во втором случае требуется дополнительное указание, какие онтология и\nзнания должны использоваться в процессе решения. Специализированная оболочка интеллектуальных\nсистем для сложно-структурированной предметной области должна обеспечивать возможность решения\nзадач разных классов, причем пользователь должен иметь возможность указания модуля онтологии и\nмодуля знаний, которые надо использовать при решении задач.\nТаким образом, специализированная оболочка должна содержать расширяемые библиотеки систем для\nрешения задач разных классов, системы автоматического построения методов решения задач по их\nспецификации (рис. 1).\n\nРис. 1. Системы для решения задач и средства их разработки\n\n\fInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\n341\n\nМетод решения задач может быть представлен либо в виде алгоритма, либо в виде множества правил\nсистемы продукций. В первом случае для создания решателя задач используется процессор\nалгоритмического языка, во втором случае – процессор языка, основанного на правилах, который\nявляется одним из программных компонент специализированной оболочки.\n\nСпециализированная система обработки текстовых документов «ЛоТА»\nСпециализированная система обработки текстовых документов «ЛоТА» [Невзорова, 2001] является\nсистемой класса Text Mining. Система предназначена для анализа специализированных текстов «Логика\nработы», описывающих логику работы сложной технической системы в различных режимах\nфункционирования. Основной задачей анализа является извлечение из данных текстов информационной\nмодели алгоритмов, решающих определенную задачу в определенной проблемной ситуации, и контроль\nструктурной и информационной целостности выделенной схемы алгоритмов.\nИнформационная модель алгоритма включает:\nописание входного информационного потока (типы информационных сигналов или семантическое\nописание информационного потока с указанием источника информации\n\nконкретный алгоритм,\n\nконкретное измерительное устройство);\nописание процессов преобразования входных данных в выходные (допустимый способ разрешения\nпроблемы);\nописание выходного информационного потока (типы информационных сигналов или семантическое\nописание информационного потока с указанием точки приема информации).\nРешение основной задачи обеспечивается комплексом технологий обработки текстов, включающих:\nтехнологии морфосинтаксического анализа;\nтехнологии семантико-синтаксического анализа;\nтехнологии взаимодействия с прикладной онтологией.\nУказанная сумма технологий формируется на основе центрального ядра – прикладной онтологии (в\nдальнейшем, авиаонтология [Лукашевич, 2004]), обеспечивающей согласованное взаимодействие\nразличных программных модулей. Авиаонтология концептуально описывает предметную область\nинформационного\n\nобеспечения\n\nразличных\n\nполетных\n\nрежимов\n\nантропоцентрических\n\nсистем.\n\nАвиаонтология представляет собой сеть понятий предметной области. Авиаонтология относится к классу\nлингвистических (лексических) онтологий и предназначена для встраивания в различные лингвистические\nприложения.\nПрограммный комплекс состоит из трех взаимодействующих подсистем: подсистемы лингвистического\nанализа технических текстов «Анализатор», подсистемы ведения онтологии «OntoEditor+» и подсистемы\n«Интегратор». Взаимодействие подсистем реализовано на базе технологии «клиент-сервер», причем в\nразличных подзадачах подсистемы выступают в различных режимах (режим сервера или режим клиента).\nИнструментальная система визуального проектирования «OntoEditor+» является специализированной\nСУБД. Система предназначена для ручного редактирования онтологий, хранящихся в реляционной базе\n\n\f342\n\nInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\nданных в формате TPS, а также обслуживания запросов пользователей и внешних программ. Новые\nвозможности системы обеспечиваются функциональным набором «Лингвистический инструментарий»,\nпосредством которого реализуется встраивание прикладной онтологии в лингвистические приложения.\nНаиболее типичными задачами, решаемыми с помощью инструментария системы «OntoEditor+»,\nявляются: изучение структурных свойств прикладной онтологии с помощью исследовательского\nинструментария системы «OntoEditor+»; построение лингвистической оболочки прикладной онтологии;\nзадача покрытия текста онтологическими входами; построение выводов по прикладной онтологии и др.\nПодсистема\n\n«Анализатор»\n\nреализует\n\nосновные\n\nэтапы\n\nлингвистической\n\nобработки\n\nтекста\n\n(графематический, морфосинтаксический и частичный синтаксический анализ).\nПодсистема «Интегратор» исполняет внешний запрос на извлечение знаний из текста. Структура\nвнешнего запроса содержит компоненты информационной модели алгоритма. Внешний запрос\nинтерпретируется при взаимодействии с подсистемой «OntoEditor+» как структура, привязанная к\nприкладной онтологии. Выделение компонент информационной модели происходит на основе\nмеханизмов отождествления элементов дерева сегментов входного текста (взаимодействие с\nподсистемой «Анализатор») и элементов структуры запроса (взаимодействие с подсистемой\n«OntoEditor+»).\nИнструментальная система визуального проектирования онтологий «OntoEditor+» включает:\nлингвистический инструментарий (задачи корпусного исследования (загрузка корпуса; сегментация\nна предложения; автоматическое ведение статистики по различным объектам корпуса), построение\nлингвистической оболочки онтологии, задача покрытия текста онтологическими входами,\nпостроение выводов по онтологии, поддержка протоколов информационного обмена системы\n«OntoEditor+» с внешними программными модулями, в том числе с внешними информационными\nресурсами);\nисследовательский инструментарий.\nОсновные функции подсистемы «Анализатор»:\nграфематический анализ;\nморфосинтаксический анализ;\nпокрытие текста онтологическими входами (взаимодействие с системой «OntoEditor+»).\nОсновные функции подсистемы «Интегратор»:\nанализ и исполнение внешнего запроса (информационная модель алгоритма);\nинтерпретация внешнего запроса в терминах прикладной онтологии (взаимодействие с системой\n«OntoEditor+»);\nинтерпретация внешнего запроса в структурных компонентах дерева сегментов (взаимодействие с\nсистемой «Анализатор»);\nконтроль информационной целостности (анализ компонент внешнего запроса).\nМетод контекстного разрешения омонимии является базовым методом в интегральной технологии\nразрешения омонимии в системе «ЛоТА». Однако практические задачи системы выявили ряд важных\n\n\fInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\n343\n\nаспектов лингвистического анализа, которые стимулировали развитие новых методов разрешения\nмногозначности.\nИнтегральная технология разрешения многозначности, разрабатываемая в системе «ЛоТА», включает\nследующие методы:\nметод контекстного разрешения функциональной омонимии;\nметод разрешения функциональной, грамматической и лексической омонимии на основе\nиндексируемой базы устойчивых коллокаций;\nметод разрешения функциональной, грамматической и лексической омонимии на основе\nлингвистической оболочки онтологии.\nДля эффективного встраивания в лингвистические приложения система «OntoEditor+» поддерживает\nгруппу протоколов информационного обмена с внешними программными модулями системы и внешними\nсловарными базами данных, обеспечивая работу в режиме клиент-сервер. Разрешение многозначности\n(функциональной, морфологической и лексической) во входных текстах происходит на основе механизма\nраспознавания контекстов омонимов, зафиксированных в индексируемой базе контекстов.\nРазработаны три основных механизма пополнения индексируемой базы контекстов функциональных\nомонимов:\nручной ввод и редактирование данных по типовым контекстам омонимов;\nимпорт типовых контекстов омонимов из текстового файла, подготовленного в специальном\nформате представления данных;\nимпорт типовых контекстов омонимов, обнаруженных специальными механизмами поиска\nподсистемы «Анализатор».\nДанный механизм организован как запрос к подсистеме «Анализатор» с передачей ему от подсистемы\n«OntoEditor+» текстового корпуса, по которому проводится поиск. В процессе обработки подсистема\n«Анализатор» передает подсистеме «OntoEditor+» информацию об обнаруженных контекстах омонимов,\nкоторая записывается либо в индекс омонимов, либо в автоматическом режиме, либо в режиме диалога с\nоператором. Отличительной особенностью режима диалога является режим самообучения, который\nреализуется с использованием механизма журнала событий. В данном журнале в зависимости от его\nнастройки фиксируются те или иные важные события в системе, например, изменение информации в\nиндексе омонимов или операции взаимодействия с подсистемой «Анализатор». В режиме самообучения\nсохраняется и контролируется последовательность ранее сгенерированных диалогов, что обеспечивает\nгенерацию только уникальных диалогов на разрешение омонимии без повторений.\nЛингвистический инструментарий подсистемы «OntoEditor+» обеспечивает встраивание онтологии в\nразличные приложения, связанные с обработкой текстов. Лингвистический инструментарий реализует\nфункции загрузки корпуса текстов; автоматическое ведение статистики по различным объектам корпуса;\nфункции предсинтаксической обработки текста (сегментация предложений, распознавание аббревиатур,\nразрешение омонимии на основе специальных протоколов взаимодействия с внешними словарными\nресурсами); построение лингвистической оболочки онтологии; распознавание терминов прикладной\n\n\f344\n\nInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\nонтологии во входном тексте (задача покрытия). Сопряжение онтологического и лингвистического\n(грамматического) ресурсов реализуется через механизмы лингвистической оболочки онтологии.\nЛингвистическая\n\nоболочка\n\nонтологии\n\nсоздается\n\nс\n\nпомощью\n\nразработанного\n\nпрограммного\n\nинструментария, посредством которого фиксируется грамматическая информация об онтологических\nконцептах и их текстовых формах. Каждый онтологический вход (как правило, многословный термин)\nснабжается соответствующей грамматической информацией, при этом для омонима разрешается\nсоответствующая\n\n(функциональная,\n\nлексическая,\n\nморфологическая)\n\nомонимия.\n\nГрамматическая\n\nинформация передается в подсистему «OntoEditor+» от подсистемы «Анализатор» на основе\nспециальных протоколов взаимодействия. Разрешение лексической, функциональной и морфологической\nомонимии выполняется на основе специальных диалогов с экспертом-лингвистом. Отдельные процедуры\nреализуют проверки словоформ в составе терминологического входа на согласованность их\nграмматических характеристик, также осуществляется контроль достоверности словарной информации.\nКонтроль достоверности обеспечивает отслеживание изменений, как в составе грамматического словаря,\nтак и в составе онтологии. Учитывая сложность и многоступенчатость вышеперечисленных процедур, в\nподсистеме «OntoEditor+» разработан мастер построения лингвистической оболочки, который вызывается\nкомандой основного меню.\nПодсистема «Анализатор» обеспечивает реализацию метода разрешения омонимии на основе\nконтекстных правил, т. е. фактически используются лингвистические знания системы. Этот метод\nявляется универсальным, не зависит от специфики предметной области и обеспечивает в текущей версии\nточность распознавания не ниже 95 %. Однако, для данного метода существуют крайне сложные типы\nфункциональной омонимии, например, тип «частица/союз». Разрешение данной омонимии возможно во\nмногих случаях лишь после завершения полного синтаксического анализа.\nВзаимодействие подсистемы «OntoEditor+» и подсистемы «Анализатор» осуществляется на основе\nспециальных протоколов взаимодействия. При применении интегральной технологии разрешение\nмногозначности происходит в два этапа. На первом этапе подсистема «Анализатор» (клиент) передает\nзапрос на разрешение омонимии входного текста подсистеме «OntoEditor+» (сервер). Подсистема\n«OntoEditor+» возвращает подсистеме «Анализатор» информацию о разрешенных омонимах на основе\nсвоих методов. На втором этапе подсистема \"Анализатор\" разрешает омонимию оставшихся\nнеразрешенных омонимов на основе метода контекстных правил.\nИнтегральная\n\nтехнология\n\nразрешения\n\nмногозначности\n\nэффективно\n\nприменяется\n\nна\n\nэтапе\n\nпредсинтаксического анализа в системе «ЛоТА». По существу, интегральная технология представляет\nсобой сочетание инженерного и лингвистического подхода к решению поставленной задачи. В основе\nпроектирования интегральной технологии лежат процессы скоординированного взаимодействия\nразличных языковых уровней, прежде всего онтологического уровня (обеспечивающего системные\nмодели знаний о мире) и различных языковых уровней (морфологического и синтаксического). В системе\nреализован эффективный механизм взаимодействия различных подсистем, обеспечивающих реализацию\nразличных методов в составе интегральной технологии. При этом, следует признать, что сам процесс\n\n\fInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\n345\n\nсогласования языковых взаимодействий достаточно сложен и требует определения большого числа\nдефиниций-правил, описывающих условия обработки концептов онтологии.\n\nИнтеллектуальная система извлечения данных и их анализа (на основе текстов) ИСИДА-Т\nЦелью ИСИДА-Т [Кормалев, 2006]; [Киселев, 2004], является извлечение значимой информации\nопределенного типа из (больших массивов) текста для дальнейшей аналитической обработки.\nРезультатом работы систем является получение структурированных данных и отношений на них.\nОсновные компоненты ИСИДА-Т:\nИнфраструктурные службы (конфигурирование, параллельная обработка, взаимодействие\nмодулей);\nЛингвистический процессор;\nМодули работы со знаниями ПрО;\nИнтерпретатор правил извлечения информации.\nРазработанные в рамках проекта ИСИДА-Т технологии, инструменты и продукты позволяют:\nобнаруживать в электронных документах, извлекать и структурировать информацию о\nпредставляющих интерес фактах, событиях, объектах и отношениях;\nвыполнять мониторинг сайтов в сети Интернет на предмет появления там значимой для\nпользователя информации.\nОсновные рабочие характеристики технологии и продуктов:\nподдержка русского языка;\nбыстрая настройка на предметную область при помощи эффективных инструментальных средств;\nвысокая точность и полнота анализа за счет использования предметных знаний;\nналичие встроенных средств визуализации результатов анализа в виде диаграмм и схем;\nлегкая интегрируемость в другие информационные системы на любом уровне (программный или\nсетевой интерфейс, БД);\nфункционирование под управлением ОС Windows и большинства Linux-систем;\nблизкая к линейной масштабируемость при параллельной архитектуре анализа. Возможность\nработы на вычислительных машинах кластерного типа.\nНекоторые области применения технологий семантического анализа и структурирования текстовой\nинформации:\nинформационная поддержка бизнеса (business intelligence) и управление знаниями (knowledge\nmanagement);\nмаркетинговые исследования;\nфинансовая аналитика;\nвоенная и коммерческая разведка и мониторинг;\nинформационная поддержка органов государственной власти (в рамках направления «Электронное\nправительство»);\n\n\f346\n\nInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\nработа библиотек, издательств и СМИ.\nРассмотрим общую организацию инфраструктуры системы ИСИДА-Т. Краеугольным камнем системы\nИСИДА-Т является точная настройка на предметную область и конкретную задачу извлечения. С одной\nстороны, это достигается за счет редактирования лингвистических ресурсов, ресурсов знаний, правил\nизвлечения и правил трансформации. С другой стороны, настройка может потребовать включения в\nпроцесс обработки дополнительных специализированных методов обработки текста. Кроме того, для\nкаждой задачи необходимо подобрать наиболее подходящие алгоритмические средства анализа из\nнабора имеющихся. Эти аспекты требуют создания такой архитектуры, при которой легко могут\nдобавляться и замещаться алгоритмические компоненты процесса извлечения.\nПроблема конфигурирования на алгоритмическом уровне потребовала создания модульной архитектуры\nи декларативного подхода к определению процесса извлечения. Модули получили название\nобрабатывающих ресурсов в противовес лингвистическим ресурсам и ресурсам знаний. В конфигурации\nдекларируется порядок обработки документа аналитическими модулями, потоки данных между ними, а\nтакже параметры их работы.\nОбрабатывающие ресурсы можно разделить на следующие группы.\nРесурсы предобработки. Сюда относятся средства определения кодировки документа, извлечения\nтекста и стилевой разметки из документа, предварительной фильтрации.\nРесурсы лингвистического анализа. Осуществляют разбор текста на отдельные слова,\nморфологический анализ (в том числе специализированные варианты для различных категорий\nимен собственных), поверхностный синтаксический анализ и определение границ предложений.\nРесурсы извлечения. Осуществляют поиск в документе целевой лексики и синтаксических\nконструкций, а также первичное структурирование информации.\nРесурсы унификации знаний и вывода. Осуществляют унификацию и отождествление элементов\nзнаний, вывод производных знаний.\nРесурсы подготовки результата. Осуществляют приведение извлеченной информации к\nопределенному формату и передачу за пределы последовательности обработки (в БД, глобальный\nресурс знаний, файл, приложение).\nВ системе ИСИДА-Т все модули, в том числе средства общего лингвистического анализа, используют\nструктуру данных – аннотация. Аннотация – объект, который приписывается фрагменту текста (например,\nслову, словосочетанию, предложению, ссылке на сущность предметной области и т. д.) и описывает\nсвойства этого фрагмента. Аннотации разбиты на конечное множество классов. Каждый класс аннотаций\nописывает текст в определенном аспекте. Информация о фрагменте представлена значениями\nименованных атрибутов аннотации. Наборы классов и атрибутов аннотаций намеренно не\nспецифицированы, чтобы можно было использовать произвольный набор обрабатывающих модулей и\nпредставлять необходимую лингвистическую и предметную информацию. Обмен данными между\nмодулями тоже идет в терминах аннотаций: новые аннотации могут строиться на основании полученных\nна предыдущих этапах анализа [Овдей, 2006]. В реализации системы ИСИДА-Т модель аннотаций была\n\n\fInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\n347\n\nдополнена некоторыми полезными средствами. В частности, было снято ограничение на атомарность\nатрибутов и добавлена возможность устанавливать ссылки между аннотациями.\nДля распознавания текстовых ситуаций используется набор правил, описывающих характерные для\nконкретной задачи способы выражения ситуации в тексте. Эти правила задают образец для\nсопоставления и действия, которые должны быть произведены после успешного сопоставления. Ряд\nсовременных систем извлечения информации (в том числе, система ИСИДА-Т) берут за основу\nразличные диалекты языка CPSL [Noy, 1999]. Использование этого языка подразумевает разметку текста\nпри помощи аннотаций.\nЯзык правил, используемый в системе ИСИДА-Т, является расширением CPSL. Предлагаемые\nрасширения преследуют две цели: 1) обеспечить возможность описывать более сложные контексты, в\nкоторых встречается целевая информация, и 2) снизить объем рутинной работы при создании системы\nправил за счет более компактного описания контекста [Гаврилова, 2000].\nОтличия от других реализаций, например, JAPE [Calvanese, 2007] или диалекта CPSL состоят в\nследующем.\nРеализована встроенная поддержка расширенного спектра типов данных, в том числе, ссылок на\nаннотации и множественных значений. Данные этих типов могут использоваться в качестве\nзначений переменных и значений атрибутов аннотаций.\nЛогика работы интерпретатора правил приведена в максимальное соответствие поведению\nинтерпретатора обычных регулярных выражений. Отличия от современной реализации JAPE и\nMontreal transducer [Calvanese, 2007] заключаются в поддержке «жадных» и «нежадных»\nквантификаторов и опережающей проверки.\nПоддерживаются кванторы существования (по умолчанию) и всеобщности, связывающие\nэлементарные тесты. К кванторам может добавляться отрицание.\nСуществуют языковые средства, позволяющие гибко проверять взаимное расположение\nаннотаций, рассматриваемых в контексте сопоставления, и прочих аннотаций во входной\nколлекции.\nВ тестах могут использоваться функции для обращения к ресурсу знаний, например, проверки\nтаксономической принадлежности элементов. Для более сложных запросов к ресурсу знаний\nиспользуется предметно-ориентированный язык, совпадающий с языком описания левой части\nправил трансформации.\nДля передачи информации между элементарными тестами, а также в правую часть правил могут\nиспользоваться именованные переменные, значения которых присваиваются явно в ходе\nсопоставления. Множество значений переменных входит в контекст сопоставления.\n\nИнструментальное средство проектирования онтологий Protégé\nProtégé [Noy, 1999] – локальная, свободно распространяемая Java-программа, разработанная группой\nмедицинской информатики Стэндфордского университета. Программа предназначена для построения\n\n\f348\n\nInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\n(создания, редактирования и просмотра) онтологий прикладной области. Её первоначальная цель –\nпомочь разработчикам программного обеспечения в создании и поддержке явных моделей предметной\nобласти и включение этих моделей непосредственно в программный код. Protégé включает редактор\nонтологий, позволяющий проектировать онтологии, разворачивая иерархическую структуру абстрактных\nили конкретных классов и слотов. Структура онтологии сделана аналогично иерархической структуре\nкаталога. На основе сформированной онтологии, Protégé может генерировать формы получения знаний\nдля введения экземпляров классов и подклассов. Инструмент имеет графический интерфейс, удобный\nдля использования неопытными пользователями, снабжен справками и примерами.\nProtégé основан на фреймовой модели представления знания OKBC (Open Knowledge Base Connectivity)\n[Chaudhri, 1998] и снабжен рядом плагинов, что позволяет адаптировать его для редактирования моделей,\nхранимых в разных форматах (стандартный текстовый, в базе данных JDBC, UML, языков XML, XOL,\nSHOE, RDF и RDFS, DAML+OIL, OWL).\nИспользуемые формализмы и форматы\nИзначально единственной моделью знаний, поддерживаемой Protégé, была фреймовая модель. Этот\nформализм сейчас является «родным» для редактора, но не единственным.\nProtégé имеет открытую, легко расширяемую архитектуру и, помимо фреймов, поддерживает все\nнаиболее распространенные языки представления знаний (SHOE, XOL, DAML+OIL, RDF/RDFS, OWL).\nProtégé поддерживает модули расширения функциональности (plug-in). Расширять Protégé для\nиспользования нового языка проще, чем создавать редактор этого языка «с нуля».\nProtégé основан на модели представления знаний OKBC (Open Knowledge Base Connectivity). Основными\nэлементами являются классы, экземпляры, слоты (представляющие свойства классов и экземпляров) и\nфасеты (задающие дополнительную информацию о слотах).\nПользовательский интерфейс\nПользовательский интерфейс состоит из главного меню и нескольких вкладок для редактирования\nразличных частей базы знаний и ее структуры. Набор и названия вкладок зависят от типа проекта (языка\nпредставления) и могут быть настроены вручную. Обычно имеются следующие основные вкладки:\nКлассы, Слоты (или Свойства для OWL), Экземпляры, Метаданные.\n\nИнструментальный комплекс автоматизированного построения онтологий ПрО\nИнструментальный комплекс онтологического назначения (ИКОН) для автоматизированного построения\nонтологии в произвольной предметной области [Палагин, 2012] является системой, реализующей одно из\nнаправлений комплексных технологий Data & Text Mining, а именно – анализ и обработку больших\nобъёмов неструктурированных данных, в частности лингвистических корпусов текстов на украинском\nи/или русском языке, извлечение из них предметных знаний с последующим их представлением в виде\nсистемно-онтологической структуры или онтологии предметной области.\nИзвлечение информации (Information Extraction) [Палагин, 2012] –– это подход, позволяющий сузить круг\nзадач, требующих специфического предметно-ориентированного решения при анализе текста. В рамках\n\n\fInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\n349\n\nэтого подхода задача обработки текста ограничена распознаванием множества классов ключевых\nпонятий конкретной предметной области и игнорированием всякой другой информации.\nНесмотря на то, что системы извлечения информации могут строиться для выполнения различных задач,\nподчас сильно отличающихся друг от друга, существуют компоненты, которые можно выделить\nпрактически в каждой системе.\nВ состав почти каждой системы извлечения информации входят четыре основных компонента, а именно:\nкомпонент разбиения на лексемы, некоторый тип лексического или морфологического анализа,\nсинтаксический анализ (микро- и макроуровень), модуль извлечения информации и модуль для анализа\nна уровне конкретной предметной области. В зависимости от требований к конкретному программному\nпродукту в приведённую выше схему добавляют дополнительные модули анализа (специальная\nобработка составных слов; устранение омонимии; выделение составных типов, которое может также быть\nреализовано на языке правил извлечения информации; объединение частичных результатов).\nРазбиение на слова при анализе европейских языков не является проблемой, поскольку слова\nотделяются друг от друга пробелом (или знаками препинания). Тем не менее, для обработки составных\nслов, аббревиатур, буквенно-цифровых комплексов и ряда других особых случаев требуются\nспецифические алгоритмы. С границами предложений, как правило, тоже больших проблем не возникает.\nОднако при анализе таких языков как японский или китайский, определение границ слова на основе\nорфографии невозможно. По этой причине системы извлечения информации, работающие с такими\nязыками, должны быть дополнены модулем сегментирования текста на слова.\nВ некоторые системы наряду с обычными средствами лексического и морфологического анализа могут\nбыть включены модули для определения и категоризации атрибутов частей речи, смысловых нагрузок\nслов, имен или других нетривиальных лексических единиц.\nИКОН предназначен для реализации множества компонентов единой информационной технологии:\nпоиск в сети Интернет и/или в других электронных коллекциях (ЭлК) текстовых документов (ТД),\nрелевантных заданной ПрО, их индексацию и сохранение в базе данных;\nавтоматическая обработка естественно-языковых текстов;\nизвлечение из множества ТД знаний, релевантных заданной ПрО, их системно-онтологическая\nструктуризация и формально-логическое представление на одном (или нескольких) из\nобщепринятых языков описания онтологий. Кроме того, внутри этой технологии реализуется\nпроцедура построения, визуализации и проверки семантических структур синтаксических единиц\nТД и понятийных структур заданной ПрО в виде онтографа, названного начальной онтологией ПрО;\nсоздание,\n\nнакопление\n\nи\n\nиспользование\n\nбольших\n\nструктур\n\nонтологических\n\nзнаний\n\nв\n\nсоответствующих библиотеках;\nсистемная интеграция онтологических знаний как одна из основных компонент методологии\nмеждисциплинарных научных исследований;\nдругие процедуры, связанные с автоматизацией приобретения знаний из множества естественноязыковых объектов.\n\n\f350\n\nInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\nИКОН состоит из трёх подсистем и представляет собой интеграцию разного рода информационных\nресурсов (ИР), программно-аппаратных средств обработки и процедур естественного интеллекта (ЕИ),\nкоторые, взаимодействуя между собой, реализуют совокупность алгоритмов автоматизированного,\nитерационного построения понятийных структур предметных знаний, их накопления и/или системной\nинтеграции. Обобщённая блок-схема ИКОН представлена на рис. 2.\nПодсистема «Информационный ресурс» включает блоки формирования лингвистического корпуса\nтекстов, баз данных языковых структур и библиотек понятийных структур. Первый компонент\nпредставляет собой различные источники текстовой информации, поступающей на обработку в систему.\nВторой компонент представляет собой различные базы данных обработки языковых структур, часть из\nкоторых формируется (наполняется данными) в процессе обработки ТД, а другая часть формируется до\nпроцесса построения онтологии ПрО и, по сути, является ЭлК различных словарей. Третий компонент\nпредставляет собой совокупность библиотек понятийных структур разного уровня представления (от\nнаборов терминов и понятий до высокоинтегрированной онтологической структуры междисциплинарных\nзнаний) и является результатом реализации некоторого проекта (проектирования онтологии ПрО и/или\nсистемной интеграции онтологий).\n\nРис. 2. Обобщённая блок-схема ИКОН\n\nПодсистема «Программно-аппаратные средства» включает блоки обработки языковых и понятийных\nструктур и управляющую графическую оболочку, с помощью которой инженер по знаниям осуществляет\nобщее управление процессом использования связанных информационных технологий.\nПодсистема\n\n«Естественный\n\nинтеллект»\n\nосуществляет\n\nподготовку\n\nи\n\nреализацию\n\nпроцедур\n\nпредварительного этапа проектирования, а на протяжении всего процесса осуществляет контроль и\nпроверку результатов выполнения этапов проектирования, принимает решение о степени их\nзавершённости (и в случае необходимости – повторении некоторых из них).\n\n\fInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\n351\n\nТОДОС – IT-платформа онтологических информационно-аналитических экспертных\nсистем\nТОДОС – инновационный комплекс программно-информационных и методических средств управления\nзнаниями с использованием подходов онтологического управления корпоративными информационными\nресурсами, где человек рассматривается как источник определения новых знаний для передачи их в\nформе собственного знания через инструментарий [Стрижак, 2013]. ТОДОС обеспечивает для\nпользователя единую интегрированную точку доступа – «единое окно» – к информации и приложениям\nсистемы для обеспечения интерактивного взаимодействия при решении прикладных задач.\nПринцип ТОДОС – «Ситуационная осведомленность» за счет предоставления пользователям\nнеобходимой информации, касающейся направлений их деятельности и достаточной для принятия\nэффективного решения:\nУдобное, интуитивно-понятное, многоаспектное представление аналитической информации;\nОбеспечение работы с неструктурированной и слабо структурируемой информацией;\nРабота с информацией и результатами анализа из любой точки сетевого доступа;\nУдовлетворение поиска и запросов пользователей – извлечение знаний;\nОбработка и анализ контента, агрегирование и упорядочивание по заданному критерию;\nПоддержка принятия решений на основе анализа больших объемов информации;\nОт данных - к пространственно-распределённым системам управления (ГИС) - от ГИС - к\nинформации;\nОбеспечение взаимодействия и обратной связи.\nКонцепция ТОДОС:\nконсолидация и интеграция всей имеющейся корпоративной информации и предоставление ее\nчерез систему «единого окна», за счет чего повышается уровень осведомленности всех категорий\nпользователей в их деятельности;\nобеспечение «бесшовной» системной интеграции информационных технологий и инноваций с\nцелью создания информационно-аналитических ресурсов для внедрения в бизнес-процессы\nорганизации;\nсоздание условий «ситуационной осведомленности» для всех заинтересованных категорий\nпользователей с многоаспектным анализом массивов документов, их анализом, сравнением,\nрейтингованием с выводом отчетов и результатов анализа;\nобеспечение онтологического управления информационными массивами, которые объединяются в\nединое корпоративное информационное пространство – онтолого-управляемую систему\nкорпоративных знаний;\nпоиск в сети Интернет и в файловых электронных коллекциях текстовых документов, релевантных\nтематике исследований и экспертизы;\n\n\f352\n\nInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\nавтоматическая обработка естественно-языковых текстов с выделением поверхностных\nсемантических отношений для дальнейшего их анализа;\nизвлечение из множества документов знаний, релевантных выбранной предметной области, их\nсистемно-онтологическая структуризация и формально-логическое представление, а также\nпостроение, визуализация и верификация семантических структур синтаксических единиц\nтекстовых документов и категориальных знаний заданной предметной области в виде\nонтологического графа;\nавтоматизированное построение онтологий и тезаурусов предметных областей для организации\nсистемы управления знаниями;\nавтоматизированный анализ и создание системы рейтингов объектов исследования и процессов с\nними связанных с учетом всего множества факторов, влияющих на соответствующие объекты и\nпроцессы;\nобеспечение многовекторного исследования объектов и процессов с целью выявления параметров\nвлияющих на их состояние, развитие и принятия соответствующего объективного решения.\nТОДОС – это:\nМодуль КОНСПЕКТ – контекстно-семантический анализ естественно-языкового текста и\nпостроение таксономии документов;\nМодуль КОНФОР – классификация и генерация онтологий предметной области;\nМодуль ЭДИТОР – конструирование трансдисциплинарных онтологий;\nМодуль АЛЬТЕРНАТИВА – онтология задачи выбора для информационно-аналитической\nподдержки принятия решений и обеспечения процессов многофакторного анализа и рейтингования;\nПОИСКОВАЯ МАШИНА – поиск лексических структур на основе лингвистической обработки\nбольшого количества распределенных сетевых текстовых массивов;\nЛИНГВИСТИЧЕСКИЙ КОРПУС – электронная библиотека со средствами ассоциативного поиска\nсемантически связанных информационных массивов;\nМодуль КРИПТО – защита информационных массивов от несанкционированного доступа.\nМодуль КОНСПЕКТ представляет собой лингвистический процессор [Величко, 2009], который\nобеспечивает первичное формирование лингвистического корпуса [Широков, 2005] и позволяет решать\nследующие практические задачи:\n1) Выделение однословных и многословных терминов документа.\n2) Формирование списка терминов с подсчетом их количества в тексте.\n3) Навигация по списку терминов с отбором и отражением контекстов предложений из текста с\nвыделенными терминами.\n4) Автоматизированное построение тематического словаря по коллекции документов для использования в\nлокальной полнотекстовой поисковой системе с целью повышения релевантности поиска.\n\n\fInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\n5) Конспектирование текста по заданной теме. Конспект\n\n353\n\nэто краткое изложение содержания статьи или\n\nкниги. Система автоматически создает текстуальный конспект, где основные положения произведения,\nдоказательства и выводы передаются словами автора, то есть цитатами. Тема конспекта задается\nпользователем программы с помощью ключевого слова или словосочетания. Из исходного текста в\nконспект отбираются предложения, содержащие тему, и автоматически отбираются термины текста,\nассоциативно связанные с заданной темой. Пример конспекта, который автоматически построен в среде\nмодуля КОНСПЕКТ, приведен на рис. 3.\n\nРис. 3. Фрагмент среды модуля КОНСПЕКТ\n\nРезультаты, которые можно получить в ближайшее время при условии доработки разработанной\nпрограммы:\n1) Повышение качества обработки текстов на украинском и русском языках за счет увеличения объема\nсловаря системы;\n2) Автоматическое определение тематических направлений документа;\n3) Сортировка документов по тематическим направлениям;\n4) Построение семантической сети терминов документа;\n5) Объединение семантических сетей терминов для нескольких документов;\n6) Поиск информации в сети Интернет с помощью поискового модуля системы ТОДОС с дополнительной\nавтоматической семантической фильтрацией результатов поиска. Для дополнительной фильтрации\nиспользуются алгоритмы формирования семантических категорий заданной тематики, извлеченных из\n\n\f354\n\nInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\nтекста. Список документов, которые получает пользователь после дополнительной фильтрации,\nсокращается в несколько раз;\n7) Конспектирование текста по заданной теме (для украинского языка).\nМодуль КОНФОР предназначен для построения семантических связей между объектами предметной\nобласти на основе индуцированной обработки отношений между объектами тематических классов ПрО.\nДля этого тематические классы описываются пользователем в соответствии с нижеприведённой схемой:\n(имя класса объектов 1),(имя связи), (имя объекта 1),...,(имя объекта n)\n(имя класса объектов 2),(имя связи), (имя объекта 1),...,(имя объекта j)\n.......................................................................................................................\n(имя класса объектов m),(имя связи), (имя объекта 1),...,(имя объекта k)\nСогласно схемы заполняется таблица, например MS Excel, ячейки столбца А которой содержат имена\nматеринских вершин графа, ячейки столбца В – имена связей между вершинами, ячейки столбцов от С до\nZ – имена дочерних вершин. Выходной структурой модуля КОНФОР является онтограф ПрО [Палагин,\n2012], [Довгий, 2013], вершины которого носят имена объектов.\nМодуль ЭДИТОР предназначен для создания, редактирования, просмотра и анализа сетей понятий и\nформирования закономерностей, представленных в виде набора значений признаков, которыми\nописываются начальные понятия предметной области. Таким образом, описание предметной области\nявляется наглядным и легко интерпретируется пользователем.\nВыделение закономерностей происходит методом индуктивного формирования понятий на основе\nпирамидальной сети.\nПирамидальной сетью называется ациклический ориентированный граф, вершинами которого выступают\nтермины (понятия) предметной области, а ребрами (дугами)\n\nсемантические связи между терминами\n\n[Гладун, 1994].\nПредставление информации в виде графа позволяет изучать не только отдельный термин (понятие), но и\nполучать все его семантические связи с другими понятиями, тем самым осмысливая его роль в данной\nсистеме знаний или в ходе решения задачи.\nОднако сетевой граф может выступать не только средством организации знаний. Расширяя\nтрадиционные функции, граф можно превратить в среду, в которой обеспечивается активная работа со\nзнаниями, а также оригинальным образом решаются учебные задачи.\nКонцептуальная модель предметной области или онтология состоит из графа (иерархии понятий)\nпредметной области, связей между ними и законов, которые действуют в рамках этой модели.\nМодуль АЛЬТЕРНАТИВА обеспечивает упорядочивание объектов-концептов онтологии, на основе\nинтегрированной обработки характеризующих их свойств. Для этого используются весовая, бальная и\nлингвистическая шкалы. Каждая такая шкала определяет значение критериев, характеризующих свойства\nобъектов тематической онтологии ПрО. В общем случае свойства-критерии характеризуются различными\n\n\fInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\n355\n\nстепенями важности, которые при решении задачи выбора задаются некоторыми действительными\nчислами\n\nвесовыми коэффициентами. Перед решением задачи для каждого критерия необходимо\n\nсформировать его значение для каждой альтернативы [Саати, 1989].\nМодули ПОИСКОВАЯ МАШИНА и ЛИНГВИСТИЧЕСКИЙ КОРПУС, обеспечивают маркировку и\nиндексирование семантических единиц, определяющих и описывающих контексты объектов тематических\nонтологий ПрО. Контексты семантических единиц составляют электронную библиотеку.\nМодуль КРИПТО обеспечивает защиту информационных ресурсов электронной библиотеки системы.\nЗащита реализуется на основе гомоморфного кодирования. Для создания эффективных методов защиты\nсистемы реализуются механизмы инфраструктуры публичных ключей (PKI). Инфраструктура публичных\nключей позволяет объединить электронные подписи, публичные и частные ключи и пирамиду\nвиртуальных лиц или организаций, которые могут выполнять действия по управлению тематическими\nонтологиями и отображающими их документами.\nНа основе анализа сопроводительной документации, справочных материалов, доступных в открытых\nисточниках информации (интернет, научные труды), и, в отдельных случаях, практической работы с\nпрограммными системами конструирования онтологий (ИКОН, ТОДОС, Protégé), построена сводная\nтаблица, обобщающая сравнительные технические характеристики некоторых специализированных\nинструментальных средств инженерии онтологий (таблица 1).\n\nЗаключение\nВ статье представлен обзор специализированных инструментальных средств инженерии онтологий. Как\nвидно из сравнительной таблицы, в которой представлены различные системы конструирования\nонтологий, стратегическим направлением развития таких систем является интероперабельность.\nЭффективность использования онтологических описаний в основном зависит от возможностей\nприменения форматов их описаний при решении различных сложных прикладных задач. Наиболее\nконструктивным методом решения этой проблемы может быть разработка онтологий задач, которые\nсмогут\n\nобеспечить\n\nсемантическую\n\nсинхронизацию\n\nвзаимодействий\n\nразличных\n\nпо\n\nтематикам\n\nинформационных систем на основе установления отношений между свойствами их концептов.\n\nБиблиография\n[Клини, 1957] Клини С. К. Введение в метаматематику [Текст] / С. К. Клини. – М. : Иностранная литература, 1957. –\n526 с.\n[Палагин, 2012] Палагин А. В. Онтологические методы и средства обработки предметных знаний / А. В. Палагин,\nС. Л. Крывый, Н. Г. Петренко. – [монография] – Луганск : изд-во ВНУ им. В. Даля, 2012. – 323 с.\n[Гаврилова, 2000] Гаврилова Т. А., Хорошевский В. Ф. Базы знаний интеллектуальных систем / Учебник для вузов. –\nСПб, Изд-во «Питер», 2000. – 384 с.\n[Палагин, 2009] Палагин А. В., Петренко Н. Г. Системно-онтологический анализ предметной области // УСиМ. – 2009.\n– № 4. – С. 3–14.\n[Овдей, 2006] Овдей О. М. Обзор инструментов инженерии онтологий / О. М. Овдей, Г. Ю. Проскудина. – Российский\nнаучный электронный журнал «Электронные библиотеки», 2004. – т. 7. – Вып. 4, ISSN 1562-5419. – Режим\n\n\f356\n\nInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\nдоступа: http://www.elbib.ru/index.phtml?page= elbib/rus/journal/2004/part4/op. – Дата доступа: 19.10.2006. –\nНазвание с экрана.\n[Noy, 1999] Noy N. SMART: Automated Support for Ontology Merging and Alignment / N. Noy, M. Musen. – Stanford\nMedical Informatics, Stanford Univ. – 1999. – 24 p. Режим доступа: http://ais-portal.ru/2009/03. – Дата доступа:\n17.05.2010.\n[Calvanese, 2007] Software Tools for Ontology Design and Maintenance / [D. Calvanese, P. Dongilli, G. De Giacomo, A.\nKaplunova, D. Lembo, M. Lenzerini, R. Möller, R. Rosati, S. Tessaris, M. Wessel, I. Zorzi] Project Deliverable\nD21,TONES,\n2007.\nhttp://www.researchgate.net/publication/240754938_Software_Tools_for_Ontology_Design_and_Maintenance\n[Артемьева, 2008] Артемьева И. Л., Рештаненко Н. В. Интеллектуальная система, основанная на многоуровневой\nонтологии химии // Программные продукты и системы. – 2008. – № 1. – С. 84-87.\n[Филатов, 2007] Филатов В. А. Разработка высокоэффективных средств создания и обработки онтологических баз\nзнаний / Филатов В. А., Щербак С. С., Хайрова А. А. – Системи обробки інформації, випуск 8 (66), 2007. – С. 120–\n124. – Режим доступа: www.nbuv.gov.ua/portal/ natural/soi/2007_8/Filatov.pdf. – Дата доступа: 17.11.2010. –\nНазвание с экрана.\n[Невзорова, 2001] Невзорова О. А., Федунов Б. Е. Система анализа технических текстов «ЛоТА»: основные\nконцепции и проектные решения. // Изв. РАН. Теория и системы управления.– 2001. № 3. – С. 138-149.\n[Лукашевич, 2004] Лукашевич Н.В., Невзорова О. А., АвиаОнтология: анализ современного состояния ресурса //\nКомпьютерная лингвистика и интеллектуальные технологии: труды Международной конференции Диалог’2004. –\nМосква, Наука, 2004– т.2 - с. 424-430.\n[Кормалев, 2006] Кормалев Д. А., Куршев Е. П. Развитие языка правил извлечения информации в системе ИСИДА-Т\n// Труды международной конференции «Программные системы: теория и приложения». — Т. 2. — М. :\nФизматлит, 2006. — С. 365-377.\n[Киселев, 2004] Киселев С. Л., Ермаков А. Е., Плешко В. В. Поиск фактов в тексте естественного языка на основе\nсетевых описаний // Компьютерная лингвистика и интеллектуальные технологии: труды Международной\nконференции Диалог’2004. – Москва, Наука, 2004.\n[Chaudhri, 1998] OKBC: A Programmatic Foundation for Knowledge Base Interoperability. V. Chaudhri, A. Farquhar, R.\nFikes P. Karp J. Rice // Fifteenth National Conf. on Artificial Intelligence. AAAIPres/The MIT Press, Madison, P.600-607,\n1998.http://www.oracle.com/technetwork/java/javase/index.html\n[Стрижак, 2013] Стрижак О.Є. Засоби онтологічної інтеграції і супроводу розподілених просторових та семантичних\nінформаційних ресурсів [Текст] / Екологічна безпека та природокористування: 3б. наук, праць / М-во освіти і науки\nУкраїни, Київ. нац. ун-т буд-ва і архіт., НАН України, Ін-т телекомунікацій і гло-бал. інформ. простору; редкол.:\nО.С. Волошкіна, О.М. Трофимчук (голов. ред.) [та ін.]. - К., 2013. - Вип. 12. – с.166-177]\n[Величко, 2009] Величко В. Автоматизированное создание тезауруса терминов предметной области для локальных\nпоисковых систем / В. Величко, П. Волошин, С. Свитла // “Knowledge – Dialogue – Solution” International Book\nSeries “INFORMATION SCIENCE & COMPUTING”, Number 15. – FOI ITHEA Sofia, Bulgaria. - 2009. – pp.24-31.\n[Широков, 2005] Корпусна лінгвістика / В.А. Широков, О.В. Булгаков, Т.О. Грязнухіна та ін.. – К.: Довіра, 2005. – 471 с.\n[Довгий, 2013] Комп’ютерні онтології та їх використання у навчальному процесі. Теорія і практика. : Монографія / С. О.\nДовгий, В. Ю. Величко, Л. С. Глоба, О. Є. Стрижак та ін. – К. : Інститут обдарованої дитини, 2013. – 310 с.\n[Стрижак, 2014] Онтологія задачі вибору та її застосування при аналізі лімнологічних систем [Текст] / [О.Є. Стрижак,\nВ.В. Горборуков, О.В. Франчук, М.А. Попова] // Екологічна безпека та природокористування: 3б. наук, праць / М-во\nосвіти і науки України, Київ. нац. ун-т буд-ва і архіт., НАН України, Ін-т телекомунікацій і гло-бал. інформ.\nпростору; редкол.: О.С. Волошкіна, О.М. Трофимчук (голов. ред.) [та ін.]. - К., 2014. - Вип. 15. – С. – 172-183.\n[Гладун, 1994] Гладун В.П. Процессы формирования новых знаний [Текст] / В. П. Гладун. – София : СД «Педагог 6»,\n1994. – 192 с.\n[Саати, 1989] Саати Т. Принятие решений. Метод анализ иерархий: Пер. с англ. / Т. Саати.-М.: Радио и связь, 1989.316 с.\n\n\fInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\n357\n\n\f358\n\nInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\n\fInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\n359\n\n\f360\n\nInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\n\fInternational Journal \"Information Models and Analyses\" Volume 3, Number 4, 2014\n\n361\n\nИнформация об авторах\nВеличко Виталий Юрьевич – к.т.н., старший научный сотрудник, Институт\nкибернетики\n\nим. В. М. Глушкова\n\nНАН\n\nУкраины,\n\nКиев-187\n\nГСП,\n\n03680,\n\nпросп. акад. Глушкова, 40; e-mail: velychko@aduis.com.ua\nОсновные области научных исследований: индуктивный логический вывод, обработка\nестественно-языковых текстов\nМалахов Кирилл Сергеевич – младший научный сотрудник, Институт кибернетики\nим. В. М. Глушкова НАН Украины, Киев-187 ГСП, 03680, просп. акад. Глушкова, 40; email: malahov@live.com\nОсновные области научных исследований: онтологический инжиниринг\nСеменков Виталий Васильевич\n\nаспирант, Луганський национальний университет\n\nимени Тараса Шевченка\nОсновные области научных исследований: онтологический инжиниринг\nСтрижак Александр Евгеньевич\n\nк.т.н., старший научный сотрудник, Институт\n\nтелекоммуникаций и глобального информационного пространства НАН Украины,\nКиев-186, 03186, Чоколовский бульвар, 13; e-mail: sae953@gmail.com\nОсновные области научных исследований:\n\nкорпоративные интеллектуальные\n\nсистемы, поддержка принятия решений\n\nIntegrated Tools for Engineering Ontologies\nVelychko V.Yu., Malahov K.S., Semenkov V.V., Strizhak A.E.\n\nAbstract: The article presents an overview of current specialized ontology engineering tools, as well as texts’\nannotation tools based on ontologies. The main functions and features of these tools, their advantages and\ndisadvantages are discussed. A systematic comparative analysis of means for engineering ontologies is\npresented.\nACM Classification Keywords: I.2 ARTIFICIAL INTELLIGENCE - I.2.4 Knowledge Representation Formalisms\nand Methods, H. Information Systems – H.2 DATABASE MANAGEMENT – H.2.4 Systems\n\n\f",
         "train",
         "60978",
         "7055"
        ],
        [
         "4",
         "17628",
         "cs.AI",
         "Artificial Intelligence",
         "1712.04415v1.pdf",
         "Deception Detection in Videos\nZhe Wu1\n\nBharat Singh1\n1\n\nLarry S. Davis1\n\nUniversity of Maryland\n\n2\n\nDartmouth College\n\n{zhewu,bharat,lsd}@umiacs.umd.edu\n\narXiv:1712.04415v1 [cs.AI] 12 Dec 2017\n\nV. S. Subrahmanian2\n\nvs@dartmouth.edu\n\nAbstract\nWe present a system for covert automated deception detection\nin real-life courtroom trial videos. We study the importance\nof different modalities like vision, audio and text for this task.\nOn the vision side, our system uses classifiers trained on low\nlevel video features which predict human micro-expressions.\nWe show that predictions of high-level micro-expressions can\nbe used as features for deception prediction. Surprisingly,\nIDT (Improved Dense Trajectory) features which have been\nwidely used for action recognition, are also very good at predicting deception in videos. We fuse the score of classifiers\ntrained on IDT features and high-level micro-expressions to\nimprove performance. MFCC (Mel-frequency Cepstral Coefficients) features from the audio domain also provide a significant boost in performance, while information from transcripts is not very beneficial for our system. Using various\nclassifiers, our automated system obtains an AUC of 0.877\n(10-fold cross-validation) when evaluated on subjects which\nwere not part of the training set. Even though state-of-theart methods use human annotations of micro-expressions for\ndeception detection, our fully automated approach outperforms them by 5%. When combined with human annotations of micro-expressions, our AUC improves to 0.922. We\nalso present results of a user-study to analyze how well do\naverage humans perform on this task, what modalities they\nuse for deception detection and how they perform if only\none modality is accessible. Our project page can be found\nat https://doubaibai.github.io/DARE/.\n\nIntroduction\nDeception is common in our daily lives. Some lies are harmless, while others may have severe consequences and can become an existential threat to society. For example, lying in\na court may affect justice and let a guilty defendant go free.\nTherefore, accurate detection of a deception in a high stakes\nsituation is crucial for personal and public safety.\nThe ability of humans to detect deception is very limited.\nIn (Bond Jr and DePaulo 2006), it was reported that the average accuracy of detecting lies without special aids is 54%,\nwhich is only slightly better than chance. To detect deception more accurately, physiological methods have been developed. However, physiological methods such as the Polygraph, or more recent functional Magnetic Resonance ImagCopyright c 2018, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\n\nFigure 1: Micro-expression: Eyebrows Raising. The left image and rightmost image in the image sequence are the same.\nHowever, it is much easier to detect the micro-expression in\nthe image sequence when compared to the static image, as\nshown by the two green dotted lines.\ning (fMRI) based methods are not always correlated with\ndeception (Farah et al. 2014). Additionally, the cost of the\nequipment and the overt nature of the method make the utility of these devices limited for real-life deception detection.\nAnother line of work attempts to find behavioral cues\nfor deception detection (DePaulo et al. 2003). These cues\nare faint behavioral residues, which are difficult for untrained people to detect. For example, according to (Ekman\net al. 1969; Ekman 2009), facial micro-expressions reflect\nemotions that subjects might want to hide. However, because of the variablity across different subjects, these microexpressions are extremely difficult to detect using computer\nvision, especially in unconstrained settings.\nIt is usually much easier for humans to detect a subtle facial expression from videos than from static images (GrillSpector et al. 1998). For example, Fig. 1 shows a comparison of static and dynamic representations of a simple micro micro-expression: Eyebrows Raise. Given only the left\nstatic image, people have a difficult time detecting that the\neyebrows are raising. In contrast, we can clearly see from\nthe right image sequence that the eyebrows are raising, even\nthough the last image of the image flow is exactly the left\nstatic image.\nMotivated by these observations, we propose to use motion dynamics for recognizing facial micro-expressions.\nThis coincides with the psychological insights from (Duran et al. 2013), in which the authors suggest focusing on\ndynamic motion signatures which are indicative of deception. To accomplish this, we design a two-level feature rep-\n\n\fresentation for capturing dynamic motion signatures. For the\nlow-level feature representation, we use dense trajectories\nwhich represent motion and motion changes. For the highlevel representation, we train facial micro-expression detectors using low level features, and use their confidence score\nas high-level features. Experiments on 104 court room trial\nvideos demonstrate the effectiveness and the complementary\nnature of our low-level and high-level features.\nDeception is a complex human behavior where subjects\ntry to inhibit their deceptive evidence, from facial expressions to gestures, from the way they talk to what they\nsay. Thus, a reliable deception detection method should\nintegrate information from more than one modality. Taking motivation from prior work (Pérez-Rosas et al. 2015;\nJaiswal, Tabibu, and Bajpai 2016), we also include features\nfrom other modalities, specifically audio and text. These additional modalities improve AUC (Area under the precisionrecall curve) of our automated system by 5% to 0.877.\nWhen using ground truth facial micro-expression annotations, the system obtains 0.922 AUC which is 9% better than\nthe previous state-of-the-art. We also conduct user studies to\nanalyze how well do average humans perform on this task,\nwhat modalities they use and how they perform if only one\nmodality is accessible.\n\nRelated Work\nPhysiological measures have been considered to be useful in deception detection for a long time. Polygraph measures physiological indices such as blood pressure, heart\nrate, skin conductivity of the person under interrogation,\nbut their reliability is questionable. Thermal imaging can\nrecord the thermal patterns (Pavlidis, Eberhardt, and Levine\n2002) and measure the blood flow of the body (Buddharaju\net al. 2005), but the technique requires expensive thermal\ncameras. Brain-based detectors, such as functional MRI,\nhave recently been proposed to detect deception by scanning\nthe brain and finding areas that are correlated with deception. Although it achieves high accuracy (Kozel et al. 2005;\nLangleben and Moriarty 2013; Farah et al. 2014), important questions related to the working mechanism, reliability and the experimental setting are still open research problems (Langleben and Moriarty 2013; Farah et al. 2014). Furthermore, the above mentioned physiological measure based\nmethods are overt and could be disrupted by the subject’s\ncounter preparation and behavior (Ganis et al. 2011).\nAmong the covert systems, computer vision based methods play an important role. Early works (Lu et al. 2005;\nTsechpenakis et al. 2005) used blob analysis to track head\nand hand movements, which were used to classify human\nbehavior in videos in three different behavioral states. However, these methods used person specific sample images for\ntraining blob detectors, and since the database was small, the\nmethods were prone to overfitting and did not generalize to\nnew subjects. Based on Ekman’s psychology research(Ekman et al. 1969; Ekman 2009) that some facial behaviors\nare involuntary and might serve as an evidence for deceit\ndetection, several automatic vision-based systems were developed. Zhang et al. (Zhang et al. 2007) tried to detect the\n\ndifferences between simulated facial expressions and involuntary facial expressions by identifying Deceit Indicators,\nwhich were defined by a group of specific Facial Action\nUnits (Ekman and Friesen 1977). However, this method requires people to manually label facial landmarks and input\nmajor components of FAU, thus is not fully automated. Besides, this method was only tested with static images, so essential motion patterns in facial expressions were not captured. (Michael et al. 2010) proposed a new feature called\nmotion profiles to extend the head and hand blob analysis with facial micro-expressions. Although fully automatic,\nthis method relies heavily on the performance of facial landmarks localization, and the experimental setting is very constrained. For unconstrained videos, the facial landmark localization method may be unreliable.\nThese early works were mainly in low-stake situations.\nRecently, researchers focused more on high stake deception\ndetection, so that experiments are closer to real life settings.\nIn (Pérez-Rosas et al. 2015), a new dataset containing reallife trial videos was introduced. In this work, a multi-modal\napproach is presented for the high-stake deception detection\nproblem, but the method requires manual labelling of human\nmicro-expressions. Furthermore, in the dataset, the number\nof videos for different trials varies a lot, biasing the results\ntowards longer trials. In (Su and Levine 2016), the authors\nalso collected a video database of high-stakes situations, and\nmanually designed a variety of features for different facial\nparts. Again, the manually designed features require the facial landmarks to be accurately detected. Also, the method\nsegmented each video into multiple temporal volumes and\nassumes all the temporal volume labels to be the same when\nlearning the classifier. This could be incorrect for deception\ncases, because the deception evidence could be buried anywhere in the video.\nDeceptive behavior is very subtle and varies across different people. Thus, detecting these subtle micro motion\npatterns, e.g. micro facial expression, itself is a challenging problem. In addition, Duran et al. (Duran et al. 2013)\nsuggested that research should focus more on the movement dynamics and behavior structure. Motivated by this,\nwe directly describe behavioral dynamics without detecting facial landmarks, then use behavior dynamics to learn\nmicro-expressions and deceptive behavior. We also include\nsimple verbal and audio features, as other multi-modal approaches (Pérez-Rosas et al. 2015; Jaiswal, Tabibu, and Bajpai 2016), into the overall covert automated system.\n\nMethod\nOur automated deception detection framework consists of 3\nsteps: multi-modal feature extraction, feature encoding and\nclassification. The framework is shown in Figure. 2.\n\nMulti-Modal Feature Extraction\nMotion Features Our input source are videos, where a\nperson is making truthful or deceptive statements. The video\nacquisition conditions are unconstrained, so the subject’s\nface may not always be viewed frontally or centered. Here,\nwe employ IDT (Improved Dense Trajectory) (Wang et al.\n\n\fFigure 2: Our automated deception detection framework.\n2016) features due to their excellent performance in action\nrecognition, especially in unconstrained settings.\nIDT compute local feature correspondences in consecutive frames and estimate the camera motion using RANSAC.\nAfter cancelling the effect of camera motion, the method\nsamples feature points densely at multiple spatial scales,\nthen tracks them through a limited number of frames to prevent drifting. Within the space-time volume around the trajectory, the method computes HOG (histogram of oriented\ngradients), HOF (histogram of optical flow) (Laptev et al.\n2008), MBH (motion bountary histogram) (Dalal, Triggs,\nand Schmid 2006) and trajectory descriptors. We found that\nthe MBH descriptor works better than other descriptors (like\nHOG/HOF) for our task, because MBH computes optical\nflow derivatives and captures derivatives of motion rather\nthan first order motion information. Since we want to detect\nmicro-expressions, the descriptor should represent changes\nin motion rather than constant motion, which is captured in\nMBH.\n\nTranscript Features For every video, we use\nGlove(Global Vectors for Word Representation) (Pennington, Socher, and Manning 2014) for encoding the entire\nset of words in the video transcripts to one fixed-length\nvector. Glove is an unsupervised learning algorithm for\nrepresenting words using vectors. It is trained using word\nco-occurrence statistics. As a result, the word vector\nrepresentations capture meaningful semantic structure.\nCompared to other text-based deception detection methods (Porter and Brinke 2010), Glove is more widely\napplicable in unconstrained environments.\nWe use the pre-trained Wikipedia 2014+ Gigaword5 corpus which contains 6 billion tokens in total. Each word is\nembedded in a 300 dimensional vector space. Again, we use\nGMM to learn a vocabulary for the word vectors and employ\na Fisher Vector encoding, described below, to aggregate all\nthe word vectors into a fixed-length representation for the\nentire transcript.\n\nAudio Features We use MFCC (Mel-frequency Cepstral\nCoefficients) (Davis and Mermelstein 1980) features as our\naudio features. MFCC has been widely used for ASR (Automatic Speech Recognition) tasks for over 30 years. We use\nthe following MFCC extraction procedure: first estimate the\nperiodogram of the power spectrum for each short frame,\nthen warp to a Mel frequency scale, and finally compute the\nDCT of the log-Mel-spectrum. Then for each video, we have\na series of MFCC features corresponding to short intervals.\nAfter MFCC features are extracted, we use GMM (Gaussian\nMixture Model) to build an audio feature dictionary for all\ntraining videos. We treat all the audio features equally and\nuse our feature encoding method to encode the whole sequence, similar to (Campbell, Sturim, and Reynolds 2006).\nThis is because we are not interested in speech content (spoken words), but in hidden cues of deception in the audio domain.\n\nFeature Encoding\nSince the number of features is different for each video,\nwe employ a Fisher Vector encoding to aggregate a variable number of features to a fixed-length vector. Fisher Vectors were first introduced in (Jaakkola and Haussler 1999)\nto combine the advantages of generative and discriminative\nmodels, and are widely used in other computer vision tasks,\nsuch as image classification (Perronnin and Dance 2007), action recognition (Wang et al. 2016) and video retrieval (Han\net al. 2017).\nFisher Vector encoding first builds a K-component GMM\nmodel (µi , σi , wi : i = 1, 2, ..., K) from training data,\nwhere µi , σi , wi are the mean, diagonal covariance, and mixture weights for the ith component, respectively. Given a bag\nof features {x1 , x2 , ..., xT }, its Fisher Vector is computed\nas:\n\n\fFigure 3: Five most predictive micro-expressions, from left to right: Frowning, Eyebrows raising, Lip corners up, Lips protruded\nand Head Side Turn.\n\nGµi =\n\nGσi\n\n1\n√\n\nT wi\n\nT\nX\nt=1\n\n\u0012\nγt (i)\n\nxt − µi\nσi\n\n\u0013\n\n\u0013\n\u0012\nT\nX\n1\n(xt − µi )2\n= √\n−1\nγt (i)\nσi2\nT 2wi t=1\n\n(1)\n\n(2)\n\nwhere, γt (i) is the posterior probability. Then all the Gµi and\nGσi are stacked to form the 2DK-dimension Fisher Vector,\nwhere D is the dimensionality of local feature xt .\n\nFacial Micro-Expression Prediction\nThe multi-modal features discussed above are low-level features. Here, we introduce the high-level features used to\nrepresent facial micro-expressions. According to (Ekman et\nal. 1969; Ekman 2009), facial micro-expressions play an\nimportant role in predicting deceptive behavior. To investigate their effectiveness, (Pérez-Rosas et al. 2015) manually annotated facial expressions and use binary features derived from the ground truth annotations to predict deception.\nThey showed the five most predictive micro-expressions\nare: Frowning, Eyebrows raising, Lip corners up, Lips protruded and Head Side Turn. Samples of these facial microexpressions are shown in Figure. 3.\nWe use the low-level visual features to train microexpression detectors, and then use the predicted scores of\nthe micro-expression detectors as high-level features for predicting deception. We divide each video in the database into\nshort fixed-duration video clips and annotate these clips with\nmicro-expression labels. Formally, given a training video set\nV = {v1 , v2 , ..., vN }, by dividing each video into clips,\nwe obtain a training set C = {vij }. The annotation set is\nL = {lij }, i ∈ [1, N ] denotes the video id, the superscript\nj ∈ [1, ni ] denotes the clip id , ni is the number of clips\nfor video i and the duration of vij is a constant (4 seconds in\nour implementation). The dimension of lij is the number of\nmicro-expressions. Then we train a set of micro-expression\nclassifiers using the clips C, and apply the classifiers on test\nvideo clips C̃ to generate the predicted score L̃ = {˜lij }.\nThese score vectors are pooled by averaging them over all\nclips in a video to produce a video score vector.\n\nDeception Detection\nThe Fisher vector encoding of the low level features and the\nvideo level score vector are then used to train four binary deception classifiers. Three of those classifiers are based on the\n\nFigure 4: Video Samples in the Real-life Trial Deception\nDatabase depicting the variation in human face size, pose\nand illumination.\nvisual, auditory and text channels for which GMM’s were\nconstructed, and the fourth uses the pooled score vectors for\nthe micro-expression detectors. Denote the prediction score\nof the multi-modal Fisher Vector and the high-level microexpression feature as {Smi }, i ∈ [1, 3] and Shigh . The final\ndeception score S is obtained by late fusion, given by:\nX\nS=\nαi Smi + αhigh Shigh\n(3)\ni\n\nP4\nwhere αi , αhigh > 0 and i=1 αi + αhigh = 1. The values\nof αi and αhigh are obtained by cross validation.\n\nExperiments and Results\nDataset\nWe evaluate our automated deception detection approach on\na real-life deception detection database (Pérez-Rosas et al.\n2015). This database consists of 121 court room trial video\nclips. Videos in this trial database are unconstrained videos\nfrom the web. Thus, we need to handle differences in the\nviewing angle of the person, variation in video quality and\nbackground noise, as shown in Figure. 4.\nWe use a subset of 104 videos from the trial database\nof 121 videos, including 50 truthful videos and 54 deceptive videos. The pruned videos have either significant scene\nchange or human editing. In the experiments shown below,\nwe do not report the results, as described in (Pérez-Rosas\net al. 2015). Instead, we re-implement the method (referred\n\n\fMicro-Expression\nEyebrows Frown\nEyebrows Raise\nLips Up\nLips Protruded\nHead Side Turn\nMean\n\nIDT+FV\n0.6437\n0.6633\n0.4791\n0.7512\n0.7180\n0.6511\n\nTable 1: Micro-Expression Detector Performance\nto Ground Truth micro-expressions) on our training and test\nsplits to avoid over fitting to identities rather than deception\nclues.\nThe dataset contains only 58 identities, which is less than\nthe number of videos and often the same identity is either uniformly deceptive or truthful. This means a deception detection method may simply degenerate to person reidetification, if videos of the same person were included in\nboth the training and test splits. To avoid this problem, we\nperform 10-fold cross validation using identities instead of\nvideo samples for all the following experiments, i.e. no identity in the test set belongs to the training set.\n\nMicro-Expression Prediction\nWe first analyze the performance our micro-expression prediction module. We sample frames for each video clip using\na frame rate of 15 fps. The motion features are Improved\nDense Trajectories which are represented with a Fisher Vector encoding. The micro-expression detectors are trained using a linear kernel SVM using LibSVM (Chang and Lin\n2011). The results are shown in Table. 1, and we report AUC\n(Area under the precision-recall curve). We will show in the\nfollowing experiments that even though an AUC of 0.6511 is\nnot high for detecting micro-expressions, the high-level features representing the probability of micro-expressions still\nprovide good performance on the final deception detection\ntask. We believe deep learning based approaches could perform better at predicting micro-expressions; however, with\nthe limited amount of training data available in this dataset,\nit is problematic to train such techniques. We did experiment with off-the-shelf CNN features for classifying microexpressions, but their performance was significantly worse\nthan IDT.\n\nDeception Detection\nWe now evaluate our automated deception detection system.\nWe first test four individual features: IDT (Improved Debse\nTrajectory), high-level micro-expression scores, verbal features and MFCC audio features. Then we test different combinations of multi-modal features. To test the reliability and\nrobustness of the features, we use several widely used binary\nclassifiers in our experiments, which are Linear SVM, Kernel SVM, Naive Bayes, Decision Trees, Random Forests,\nLogistic Regression and Adaboost. We use a polynomial\nkernel for Kernel SVM because it performs best. For Naive\nBayes classifier, we use normal distributions and remove\nthe feature dimensions which have zero variance before fitting. For logistic regression, we use Binomial distribution.\n\nIn Random Forest, the number of trees is 50. In Adaboost,\nwe use decision trees as the weak learners. All experiments\nare conducted using 10-fold cross validation across different\nfeature sets and classifiers.\nThe results, measured by AUC, are shown in Table. 2.\nThe first 4 rows are results from one modality, while the last\n4 rows are after late fusion of multi-modal features. Each\ncolumn corresponds to one type of classifier. We can see\nthe highest AUC (0.8773) is after late fusion, which uses\nall modality features and a linear SVM classifier. This performance is much better than using Ground Truth microexpression features (0.8325).\nPerformance of Different Classifiers SVM and Random\nForest perform better compared to other classifiers like\nNaive Bayes and Logistic Regression because they are discriminative. One interesting finding is that different classifiers are good at utilizing different feature modalities. For\nexample, we observe that linear SVM works best on IDT\nfeatures, Random Forest works best on high-level microexpression features and Kernel SVM performs best on\nMFCC features. However, when we aggregate multi-modal\nfeatures using late fusion, the performance of different classifiers converges.\nPerformance of Different Modalities We observe that\nIDT features obtain an AUC of 0.7731. Although the proposed high-level micro-expression features could not accurately predict micro-expressions, they help in improving deception detection. MFCC features obtain the highest AUC\nusing a single modality, showing the importance of audio\nfeatures in the deception detection task. The transcript feature obtains the lowest performance, mainly because the pretrained word vector representation does not capture the underlying complicated verbal deception cues. Nevertheless,\nthe entire system still benefits from the transcript features\nafter late fusion.\nAnalysis of Late Fusion Although the performance of different modalities are different for each classifier, the overall\nperformance improves when we combine different modalities. Combining the scores of the classifier trained on IDT\nfeatures with the classifier trained on micro-expression predictions helps us obtain an AUC of 0.8347, which is the performance of visual modality. Thus, even though the microexpression detectors are trained using IDT features, the lowlevel and high-level classifiers are complementary. Other\nmodalities like text and audio improve performance by 4%\nfor the overall system.\n\nDeception Detection with Ground Truth\nMicro-Expressions\nSince the high-level feature is the prediction score of trained\nmicro-expression detectors, one interesting question is how\nthe performance will be affected if we use the Ground\nTruth micro-expression features, as in (Pérez-Rosas et al.\n2015). In the following experiment, we use the GT microexpression feature as the baseline, and test how the performance changes with other feature modalities. Table. 3 shows\nthe results, measured by AUC. Note that we re-ran this study\n\n\fFeatures\nIDT\nMicroExpression\nTranscript\nMFCC\nIDT+MicroExpression\nIDT+MicroExpression+Transcripts\nIDT+MicroExpression+MFCC\nAll Modalities\n\nL-SVM\n0.7731\n0.7502\n0.6457\n0.7694\n0.8347\n0.8347\n0.8596\n0.8773\n\nK-SVM\n0.6374\n0.7540\n0.4667\n0.8171\n0.7540\n0.7540\n0.8233\n0.8233\n\nNB\n0.5984\n0.7629\n0.6625\n0.6726\n0.7629\n0.7776\n0.7629\n0.7776\n\nDT\n0.5895\n0.7269\n0.5251\n0.4369\n0.7687\n0.7777\n0.7687\n0.7777\n\nRF\n0.5567\n0.8064\n0.6172\n0.7393\n0.8184\n0.8184\n0.8477\n0.8477\n\nLR\n0.6425\n0.7398\n0.5643\n0.6683\n0.7419\n0.7419\n0.7894\n0.7894\n\nAdaboost\n0.6591\n0.7507\n0.6416\n0.6900\n0.7507\n0.7507\n0.7899\n0.7899\n\nTable 2: Deception Detection results using different feature and classifier combinations. First 4 rows are results of independent\nfeatures. Last 4 rows are late fusion results of multi-modal features.\nFeatures\nGTMicroExpression\nGTMicroExpression+IDT\nGTMicroExpression+IDT+Transcript\nGTMicroExpression+IDT+MFCC\nGTMicroExpression+All Modalities\n\nL-SVM\n0.7964\n0.8456\n0.8594\n0.8969\n0.9065\n\nK-SVM\n0.8102\n0.8137\n0.8137\n0.9002\n0.9002\n\nNB\n0.8325\n0.8468\n0.8923\n0.8668\n0.8905\n\nDT\n0.7731\n0.7834\n0.8074\n0.7834\n0.8074\n\nRF\n0.8151\n0.8205\n0.8205\n0.8319\n0.8731\n\nLR\n0.8275\n0.8988\n0.8988\n0.9221\n0.9221\n\nAdaboost\n0.8270\n0.8270\n0.8270\n0.8320\n0.8321\n\nTable 3: Deception Detection results with Ground Truth micro-expression features and other feature modalities.\nbecause we do not use the same identity in the training and\ntest splits.\nFrom Table. 2, we observe that the performance of GTMicroExpression (Pérez-Rosas et al. 2015) alone is better\nthan high-level micro-expression features (which is the confidence score of the micro-expression classifier). With the\naddition of IDT features, our vision system improves by\nmore than 5% (0.8988 AUC). This proves the effectiveness\nof motion-based features. After late fusion with results of\ntranscript and MFCC features, the performance of the overall system is 0.9221 AUC, which is better than the proposed\nfully automated system. This suggests that developing more\naccurate methods for detecting micro-expressions is a potential direction for improving deception detection in the future.\n\nAnalysis of Micro-Expressions\nWe investigate the effectiveness of each individual microexpression.\nFor each micro-expression, we test the performance by\nusing the high-level micro-expression score feature, with\nlow level motion features and other modalities, shown in\nFigure. 5. The performance of using all micro-expressions\nis shown for comparison. We use linear SVM as the classifier in this study, as it was the best individual classifier. From\nFigure. 5, we observe that “Eyebrows Raise” is more effective than other micro-expressions in both predicted microexpressions and ground truth micro-expressions. “Head\nSide Turn” is also helpful when using predicted microexpressions, see Figure. 5a. This is different from results\nobtained from ground truth micro-expressions. On the other\nhand, “Frown” works better using ground truth feature than\npredicted feature, possibly because the “Frown” detector is\nnot accurate enough, as also suggested in Table. 1.\n\nUser Study\nTo test human performance on this task, we perform user\nstudies using AMT (Amazon Mechanical Turk). First, we\nask 10 different people to watch each video and decide if\nthey consider the subject in the video truthful or not. Each\nannotator is assigned 5 videos of 5 different identities to ensure no identity specific bias is used for deceit prediction.\nWe also record if image, audio or transcripts were helpful\nfor their decision. Note that here the decision is made using all modalities. The percentage of votes per video is used\nas the score for deception. The AUC for human prediction\nis 0.8102. This shows that this dataset is relatively easier\nthan previous studies where predictions of people on this\ntask were almost chance. Nevertheless, even on this dataset,\nit is not obvious if the subject is deceptive or not.\nWhen making the decision, 67.4% of the time users rely\non visual cues, 61.3% of the time on audio, and 70.7% of the\ntime on transcripts, as shown in Figure. 6. Note that for each\nvideo, people can select multiple modalities as helpful. From\nthis data, we notice that people tend to make decisions based\non spoken content, as this is a semantic-level feature. Only\nhalf of the people think that audio helps them making decision, while in our system, audio features are very effective.\nTherefore, we conducted another user study where we only\nshow one modality at a time to each individual user because\nwhen multiple sources of information are available simultaneously, it is not easy to tell which source was helpful for\nmaking the final decision.\nTo test human performance on each modality, we ask 5\npeople to watch each video without sound, 5 people to listen to the audio and 5 people to read the transcripts of the\nvideo. Therefore in each study, subjects have access to one\nmodality only. Note that the same person is not shown any\nother modality from the same video again after being shown\none modality. The results shown in Figure. 7 are of our sys-\n\n\f(a) Predicted Micro-Expressions\n\nFigure 6: The importance of modalities for humans in making decisions.\n\n(b) Ground Truth Micro-Expressions\n\nFigure 5: Analysis of predicted micro-expressions and\nGround truth micro-expressions. Each group depicts the performance with only that micro-expression. The performance\nof using all micro-expressions is shown in the rightmost\ngroup.\n\ntem using linear SVM as classifier along with human performance. We can see that with only visual modality, there\nis a huge performance gap between human performance and\nour system. This shows that although humans lack the ability\nof predicting deceptive behavior with visual cues alone, our\ncomputer vision based system is significantly better. On the\nother hand, with only audio, human performance is as good\nas when all modalities are accessible. But when only transcripts of videos are provided, the performance drops significantly both for humans and our system. This suggests\nthat audio information plays an essential role for humans\nfor predicting deceptive behavior, while transcripts are not\nthat beneficial. With all modalities, our automated system is\nabout 7% better compared to an average person, while our\nsystem with Ground Truth micro-expressions is about 11%\nbetter.\nFor future work, we believe better models for representing\naudio would be a promising direction for improving performance of our system. In addition, designing hybrid humancomputer systems might be very important for developing a\nrobust and accurate deception detection system.\n\nFigure 7: Human performance in deception detection using\ndifferent modalities is compared with our automated system\nand our system with Ground Truth micro-expressions.\n\nConclusion\nA system for covert automatic deception detection using\nmulti-modal information in a video was presented. We\ndemonstrated that deception can be predicted independent\nof the identity of the person. Our vision system, which\nuses both high-level and low level visual features, is significantly better at predicting deception compared to humans. When complementary information from audio and\ntranscripts is provided, deception prediction can be further\nimproved. These claims are true over a variety of classifiers verifying the robustness of our system. To understand\nhow humans predict deception using individual modalities,\nresults of a user study were also presented. As part of future\nwork, we believe collecting more data for this task would\nbe fruitful as more powerful deep learning techniques can\nbe employed. Predicting deception in a multi-agent setting\nusing information available in video would be a promising\nfuture direction as the system would need to understand the\nconversation between identities over time and then arrive at\na logical conclusion.\n\n\fAcknowlegement\nThis research was funded by ARO Grant W911NF1610342.\nWe would like to thank Srijan Kumar for helpful discussions\nduring this project.\n\nReferences\nBond Jr, C. F., and DePaulo, B. M. 2006. Accuracy of deception judgments. Personality and social psychology Review\n10(3):214–234.\nBuddharaju, P.; Dowdall, J.; Tsiamyrtzis, P.; Shastri, D.;\nPavlidis, I.; and Frank, M. 2005. Automatic thermal monitoring system (athemos) for deception detection. In Computer Vision and Pattern Recognition, 2005. CVPR 2005.\nIEEE Computer Society Conference on, volume 2, 1179–\nvol. IEEE.\nCampbell, W. M.; Sturim, D. E.; and Reynolds, D. A.\n2006. Support vector machines using gmm supervectors\nfor speaker verification. IEEE signal processing letters\n13(5):308–311.\nChang, C.-C., and Lin, C.-J. 2011. Libsvm: a library for\nsupport vector machines. ACM transactions on intelligent\nsystems and technology (TIST) 2(3):27.\nDalal, N.; Triggs, B.; and Schmid, C. 2006. Human\ndetection using oriented histograms of flow and appearance. In European conference on computer vision, 428–441.\nSpringer.\nDavis, S., and Mermelstein, P. 1980. Comparison of parametric representations for monosyllabic word recognition\nin continuously spoken sentences. IEEE transactions on\nacoustics, speech, and signal processing 28(4):357–366.\nDePaulo, B. M.; Lindsay, J. J.; Malone, B. E.; Muhlenbruck,\nL.; Charlton, K.; and Cooper, H. 2003. Cues to deception.\nPsychological bulletin 129(1):74.\nDuran, N. D.; Dale, R.; Kello, C. T.; Street, C. N.; and\nRichardson, D. C. 2013. Exploring the movement dynamics\nof deception. Frontiers in psychology 4.\nEkman, P., and Friesen, W. V. 1977. Facial action coding\nsystem.\nEkman, P.; Sorenson, E. R.; Friesen, W. V.; et al. 1969.\nPan-cultural elements in facial displays of emotion. Science\n164(3875):86–88.\nEkman, P. 2009. Telling lies: Clues to deceit in the marketplace, politics, and marriage (revised edition). WW Norton\n& Company.\nFarah, M. J.; Hutchinson, J. B.; Phelps, E. A.; and Wagner, A. D. 2014. Functional mri-based lie detection: scientific and societal challenges. Nature reviews. Neuroscience\n15(2):123.\nGanis, G.; Rosenfeld, J. P.; Meixner, J.; Kievit, R. A.; and\nSchendan, H. E. 2011. Lying in the scanner: covert countermeasures disrupt deception detection by functional magnetic\nresonance imaging. Neuroimage 55(1):312–319.\nGrill-Spector, K.; Kushnir, T.; Edelman, S.; Itzchak, Y.; and\nMalach, R. 1998. Cue-invariant activation in object-related\nareas of the human occipital lobe. Neuron 21(1):191–202.\n\nHan, X.; Singh, B.; Morariu, V.; and Davis, L. S. 2017. Vrfp:\nOn-the-fly video retrieval using web images and fast fisher\nvector products. IEEE Transactions on Multimedia.\nJaakkola, T., and Haussler, D. 1999. Exploiting generative\nmodels in discriminative classifiers. In Advances in neural\ninformation processing systems, 487–493.\nJaiswal, M.; Tabibu, S.; and Bajpai, R. 2016. The truth\nand nothing but the truth: Multimodal analysis for deception\ndetection. In Data Mining Workshops (ICDMW), 2016 IEEE\n16th International Conference on, 938–943. IEEE.\nKozel, F. A.; Johnson, K. A.; Mu, Q.; Grenesko, E. L.;\nLaken, S. J.; and George, M. S. 2005. Detecting deception\nusing functional magnetic resonance imaging. Biological\npsychiatry 58(8):605–613.\nLangleben, D. D., and Moriarty, J. C. 2013. Using brain\nimaging for lie detection: Where science, law, and policy\ncollide. Psychology, Public Policy, and Law 19(2):222.\nLaptev, I.; Marszalek, M.; Schmid, C.; and Rozenfeld, B.\n2008. Learning realistic human actions from movies. In\nComputer Vision and Pattern Recognition, 2008. CVPR\n2008. IEEE Conference on, 1–8. IEEE.\nLu, S.; Tsechpenakis, G.; Metaxas, D. N.; Jensen, M. L.;\nand Kruse, J. 2005. Blob analysis of the head and hands: A\nmethod for deception detection. In System Sciences, 2005.\nHICSS’05. Proceedings of the 38th Annual Hawaii International Conference on, 20c–20c. IEEE.\nMichael, N.; Dilsizian, M.; Metaxas, D.; and Burgoon, J. K.\n2010. Motion profiles for deception detection using visual\ncues. In European Conference on Computer Vision, 462–\n475. Springer.\nPavlidis, I.; Eberhardt, N. L.; and Levine, J. A. 2002. Human behaviour: Seeing through the face of deception. Nature 415(6867):35–35.\nPennington, J.; Socher, R.; and Manning, C. D. 2014. Glove:\nGlobal vectors for word representation. In EMNLP, volume 14, 1532–1543.\nPérez-Rosas, V.; Abouelenien, M.; Mihalcea, R.; and Burzo,\nM. 2015. Deception detection using real-life trial data. In\nProceedings of the 2015 ACM on International Conference\non Multimodal Interaction, 59–66. ACM.\nPerronnin, F., and Dance, C. 2007. Fisher kernels on visual\nvocabularies for image categorization. In Computer Vision\nand Pattern Recognition, 2007. CVPR’07. IEEE Conference\non, 1–8. IEEE.\nPorter, S., and Brinke, L. 2010. The truth about lies: What\nworks in detecting high-stakes deception? Legal and criminological Psychology 15(1):57–75.\nSu, L., and Levine, M. 2016. Does lie to me lie to you?\nan evaluation of facial clues to high-stakes deception. Computer Vision and Image Understanding 147:52–68.\nTsechpenakis, G.; Metaxas, D.; Adkins, M.; Kruse, J.; Burgoon, J. K.; Jensen, M. L.; Meservy, T.; Twitchell, D. P.;\nDeokar, A.; and Nunamaker, J. F. 2005. Hmm-based deception recognition from visual cues. In Multimedia and Expo,\n2005. ICME 2005. IEEE International Conference on, 824–\n827. IEEE.\n\n\fWang, H.; Oneata, D.; Verbeek, J.; and Schmid, C. 2016. A\nrobust and efficient video representation for action recognition. International Journal of Computer Vision 119(3):219–\n238.\nZhang, Z.; Singh, V.; Slowe, T. E.; Tulyakov, S.; and Govindaraju, V. 2007. Real-time automatic deceit detection from\ninvoluntary facial expressions. In Computer Vision and Pattern Recognition, 2007. CVPR’07. IEEE Conference on, 1–\n6. IEEE.\n\n\f",
         "train",
         "37887",
         "5704"
        ],
        [
         "5",
         "17843",
         "cs.AI",
         "Artificial Intelligence",
         "1609.05632v2.pdf",
         "On the adoption of abductive reasoning for time series\ninterpretation\nT. Teijeiro, P. Félix\n\narXiv:1609.05632v2 [cs.AI] 20 Dec 2017\n\nCentro Singular de Investigación en Tecnoloxı́as da Información (CITIUS), University of\nSantiago de Compostela, Santiago de Compostela, Spain\n\nAbstract\nTime series interpretation aims to provide an explanation of what is observed in\nterms of its underlying processes. The present work is based on the assumption\nthat the common classification-based approaches to time series interpretation\nsuffer from a set of inherent weaknesses, whose ultimate cause lies in the monotonic nature of the deductive reasoning paradigm. In this document we propose\na new approach to this problem, based on the initial hypothesis that abductive\nreasoning properly accounts for the human ability to identify and characterize\nthe patterns appearing in a time series. The result of this interpretation is a\nset of conjectures in the form of observations, organized into an abstraction hierarchy and explaining what has been observed. A knowledge-based framework\nand a set of algorithms for the interpretation task are provided, implementing a\nhypothesize-and-test cycle guided by an attentional mechanism. As a representative application domain, interpretation of the electrocardiogram allows us to\nhighlight the strengths of the proposed approach in comparison with traditional\nclassification-based approaches.\nKeywords: Abduction, Interpretation, Time Series, Temporal Abstraction,\nTemporal Reasoning, Non-monotonic Reasoning, Signal Abstraction\n\n1. Introduction\nThe interpretation and understanding of the behavior of a complex system\ninvolves the deployment of a cognitive apparatus aimed at guessing the processes\nand mechanisms underlying what is observed. The human ability to recognize\npatterns plays a paramount role as an instrument for highlighting evidence which\nshould require an explanation, by matching information from observations with\ninformation retrieved from memory. Classification naturally arises as a pattern\nrecognition task, defined as the assignment of observations to categories.\nLet us first state precisely at this point what is the problem under consideration: we wish to interpret the behavior of a complex system by measuring a\nphysical quantity along time. This quantity is represented as a time series.\n\nPreprint submitted to Artificial Intelligence\n\nDecember 21, 2017\n\n\fThe Artificial Intelligence community has devoted a great deal of effort on\ndifferent paradigms, strategies, methodologies and techniques for time series\nclassification. Nonetheless, in spite of the wide range of proposals for building\nclassifiers, either by eliciting domain knowledge or by induction from a set of\nobservations, the resulting classifier behaves as a deductive system. The present\nwork is premised on the assumption that some of the important weaknesses of\nthis approach lie in its deductive nature, and that an abductive approach can\naddress these shortcomings.\nLet us remember that a deduction contains in its conclusions information\nthat is already implicitly contained in the premises, and thus it is truth-preserving.\nIn this sense, a classifier ultimately assigns a label or a set of labels to observations. This label can designate a process or a mechanism of the system being\nobserved, but it is no more than a term that summarizes the premises satisfied\nby the observations. Conversely, abduction, or inference to the best explanation,\nis a form of inference that goes from data to a hypothesis that best explains\nor accounts for the data [21]. Abductive conclusions contain new information\nnot contained in the premises, and are capable of predicting new evidence, although they are fallible. Abductions are thus truth-widening, and they can\nmake the leap from the language of observations to the language of the underlying processes and mechanisms, responding to the aforementioned problem in\na natural way [24]. For example, consider a simple rule stating that if a patient\nexperiences a sudden tachycardia and a decrease in blood pressure, then we can\nconclude that is suffering from shock due to a loss of blood volume. From a deductive perspective, loss of blood volume is just a name provided by the rule for\nthe satisfaction of the two premises. However, from an abductive perspective,\nloss of blood volume is an explanatory hypothesis, a conjecture, that expands\nthe truth contained in the premises, enabling the observer to predict additional\nconsequences such as, for example, pallid skin, faintness, dizziness or thirst.\nOf course, the result of a classifier can be considered as a conjecture, but\nalways from an external agent, since a classifier is monotonic as a logical system\nand its conclusions cannot be refuted from within. Classifier ensembles aim to\novercome the errors of individual classifiers by combining different classification\ninstances to obtain a better result; thus, a classifier can be amended by others in\nthe final result of the ensemble. However, even an ensemble represents a bottomup mapping, and classification invariably fails above a certain level of distortion\nwithin the data. The interpretation and understanding of a complex system\nusually unfolds along a set of abstraction layers, where at each layer the temporal\ngranularity of the representation is reduced from below. A classification strategy\nprovides an interpretation as the result of connecting a set of classifiers along the\nabstraction structure, and the monotonicity of deduction entails a propagation\nof errors from the first abstraction layers upwards, narrowing the capability of\nmaking a proper interpretation as new abstraction layers are successively added.\nFollowing an abductive process instead, an observation is conjectured at each\nabstraction layer as the best explanatory hypothesis for the data from the layer\nor layers below, within the context of information from above, and the nonmonotonicity of abduction supports the retraction of any observation at any\n2\n\n\fabstraction layer in the search for the best global explanation. Thus, bottomup and top-down processing complement one another and provide a joint result.\nAs a consequence, abduction can guess the underlying processes from corrupted\ndata or even in the temporary absence of data.\nOn the other hand, a classifier is based on the assumption that the underlying processes or mechanisms are mutually exclusive. Superpositions of two or\nmore processes are excluded; they must be represented by a new process, corresponding to a new category which is different and usually unrelated to previous\nones. Therefore, an artificial casuistry-based heuristics is adopted, increasing\nthe complexity of the interpretation and reducing its adaptability to the variability of observations. In contrast, abduction can reach a conclusion from the\navailability of partial evidence, refining the result by the incremental addition of\nnew information. This makes it possible to discern different processes just from\ncertain distinguishable features, and at the end to infer a set of explanations as\nfar as the available evidence does not allow us to identify the best one, and they\nare not incompatible with each other.\nIn a classifier, the truth of the conclusion follows from the truth of all the\npremises, and missing data usually demand an imputation strategy that results\nin a conjecture: a sort of abducing to go on deducing. In contrast, an abductive\ninterpretation is posed as a hypothesize-and-test cycle, in which missing data\nis naturally managed, since a hypothesis can be evoked by every single piece of\nevidence in isolation and these can be incrementally added to reasoning. This\nfundamental property of abduction is well suited to the time-varying requirements of the interpretation of time series, where future data can compel changes\nto previous conclusions, and the interpretation task may be requested to provide\nthe current result as the best explanation at any given time.\nAbduction has primarily been proposed for diagnostic tasks [10, 33], but also\nfor question answering [15], language understanding [22], story comprehension\n[6], image understanding [36] or plan recognition [28], amongst others. Some\nstudies have proposed that perception might rely on some form of abduction.\nEven though abductive reasoning has been proven to be NP-complete, a compiled form of abduction based on a set of pre-stored hypotheses could narrow\nthe generation of hypotheses [24]. The present work takes this assumption as\na starting point and proposes a model-based abductive framework for time series interpretation supported on a set of temporal abstraction patterns. An\nabstraction pattern represents a set of constraints that must be satisfied by\nsome evidence in order to be interpreted as the hypothetical observation of a\ncertain process, together with an observation procedure providing a set of measurements for the features of the conjectured observation. A set of algorithms is\ndevised in order to achieve the best explanation through a process of successive\nabstraction from raw data, by means of a hypothesize-and-test strategy.\nSome previous proposals have adopted a non-monotonic schema for time\nseries interpretation. TrenDx system detects significant trends in time series\nby matching data to predefined trend patterns [19, 20]. One of these patterns\nplays the role of the expected or normal pattern, and the other patterns are\nfault patterns. A matching score of each pattern is based on the error between\n3\n\n\fthe pattern and the data. Multiple trend patterns can be maintained as competing hypotheses according to their matching score; as additional data arrive\nsome of the patterns can be discarded and new patterns can be triggered. This\nproposal has been applied to diagnose pediatric growth trends. A similar proposal can be found in [27], taking a step further by providing complex temporal\nabstractions, the result of finding out specific temporal relationships between\na set of significant trends. This proposal has been applied to the infectious\nsurveillance of heart transplanted patients. Another example is the Résumé\nsystem, a knowledge-based temporal abstraction framework [42, 39]. Its goal\nis to provide, from time-stamped input data, a set of interval-based temporal\nabstractions, distinguishing four output abstraction types: state, gradient, rate\nand pattern. It uses a truth maintenance system to retract inferred intervals\nthat are no longer true, and propagate new abstractions. Furthermore, this\nframework includes a non-monotonic interpolation mechanism for trend detection [41]. This proposal has been applied to several clinical domains (protocolbased care, monitoring of children’s growth and therapy of diabetes) and to an\nengineering domain (monitoring of traffic control).\nThe present work includes several examples and results from the domain\nof electrocardiography. The electrocardiogram (ECG) is the recording at the\nbody’s surface of the electrical activity of the heart as it changes with time,\nand is the primary method for the study and diagnosis of cardiac disease, since\nthe processes involved in cardiac physiology manifest in characteristic temporal\npatterns on the ECG trace. In other words, a correct reading of the ECG has\nthe potential to provide valuable insight into cardiac phenomena. Learning to\ninterpret the ECG involves the acquisition of perceptual skills from an extensive\nbibliography with interpretation criteria and worked examples. In particular,\npattern recognition is especially important in order to build a bottom-up representation of cardiac phenomena in multiple abstraction levels. This has encouraged extensive research on classification techniques for interpreting the ECG;\nhowever, in spite of all these efforts, this is still considered an open problem.\nWe shall try to demonstrate that the problem lies in the nature of deduction\nitself.\nThe rest of this paper is structured as follows: Section 2 introduces the main\nconcepts and terminology used in the paper in an informal and intuitive way.\nFollowing this, in Sections 3, 4 and 5 we formally describe all the components\nof the interpretation framework, including the knowledge representation model\nand the algorithms used to obtain effective interpretations within an affordable\ntime. Section 6 illustrates the capabilities of the framework in overcoming some\nof the most important shortcomings of deductive classifiers. Section 7 presents\nthe main experimental results derived from this work. Finally, in section 8 we\ndiscuss the properties of the model compared with other related approaches and\ndraw several conclusions.\n\n4\n\n\f2. Interpretation as a process-guessing task\nWe propose a knowledge-based interpretation framework upon the principles\nof abductive reasoning, on the basis of a strategy of hypothesis formation and\ntesting. Taking as a starting point a time series of physical measurements, a set\nof observations are guessed as conjectures of the underlying processes, through\nsuccessive levels of abstraction. Each new observation will be generated from\nprevious levels as the underlying processes aggregate, superimpose or concatenate to form more complex processes with greater duration and scope, and are\norganized into an abstraction hierarchy.\nThe knowledge of the domain is described as a set of abstraction patterns\nas follows:\nhψ ((Ah , Thb , The ) = Θ(A1 , T1 , ..., An , Tn )) abstracts m1 (A1 , T1 ), ..., mn (An , Tn )\n{C(Ah , Thb , The , A1 , T1 , ..., An , Tn )}\nwhere hψ (Ah , Thb , The ) is an observable of the domain playing the role of a\nhypothesis on the observation of an underlying process ψ, where Ah represents a set of attributes, and its temporal support is represented by two instants Thb and The , corresponding to the beginning and the end of the observable; m1 (A1 , T1 ), . . . , mn (An , Tn ) is a set of observables of the domain which\nplays the role of the evidence suggesting the observation of hψ , where each of\nthese has its own set of attributes Ai and temporal support Ti , represented\nhere as a single instant for the sake of simplicity, although this may also be\nan interval; C is a set of constraints among the variables involved in the abstraction pattern, which are interpreted as necessary conditions in order for\nthe evidence m1 (A1 , T1 ), . . . , mn (An , Tn ) to be abstracted into hψ (Ah , Thb , The );\nΘ(A1 , T1 , . . . , An , Tn ) is an observation procedure that gives as a result an\nobservation of hψ (Ah , Thb , The ) from a set of observations for m1 (A1 , T1 ), . . . ,\nmn (An , Tn ).\nTo illustrate this concept, consider the sequence of observations in Figure 1.\nEach of these observations is an instance of an observable we call point (p),\nrepresented as p(A = {V }, T ), where T determines the temporal location of the\nobservation and V is a value attribute.\nIf we analyze these observations visually, we may hypothesize the presence\nof an underlying sinusoidal process. Let us define an observable sinus for such\na sinusoidal process, with two attributes: the amplitude of the process (α) and\nits frequency (ω). The knowledge necessary to conjecture this hypothesis is\ncollected in the following abstraction pattern:\nhsinus ({α, ω}, Thb , The ) = Θ(V1 , T1 , ..., Vn , Tn )) abstracts p(V1 , T1 ), ..., p(Vn , Tn )\n{C(α, ω, Thb , The , V1 , T1 , ..., Vn , Tn )}\nWe can estimate the attribute values (α, ω, Thb , The ) of this process by a simple\nobservation procedure Θ that calculates α = max(|Vi |), for 1 ≤ i ≤ n, i.e., the\namplitude α is obtained as the maximum absolute value of the observations; ω =\n5\n\n\f30\n20\n\nv\n\n10\n0\n10\n\n20\n30\n0\n\n20\n\n40\n\nT\n\n60\n\n80\n\n100\n\nV 3.4 17.6 12.9 2.6 -17.5 -20 -10.5 -0.8 7.8 17.5 19.4 19.4 17.6 7.8 -14.9 -16.3 -11.6 15.6 17.1 -15.8 7.7 13.7 2.7 -19.8 -19.6 -3.1 0.2 8.1 9.6 0\nT\n1\n4\n8 10\n14 15\n19 21 22 24 26 27 28 30\n34\n35\n40 45 47\n55 64 70 73\n78\n80 83 84 85 86 94\n\nFigure 1: Initial temporal observations.\n\npeak\nπ/mean(Tjpeak −Tj−1\n), where Tjpeak are point observations representing a peak,\nsatisfying (Vjpeak = Vk , Tjpeak = Tk ) ∧ sign(Vk − Vk−1 ) 6= sign(Vk+1 − Vk ), so\nthat the frequency ω is obtained as the inverse of the mean temporal separation\nbetween consecutive peaks in the sequence of observations; and Thb = T1 , The =\nTn , i.e., the temporal support of the hypothesis is the time interval between the\nfirst and the last evidence points.\nWe can impose the following constraint C(α, ω, Thb , The , V1 , T1 , . . . , Vn , Tn ) for\nevery pair (Vi , Ti ) in the sequence:\n\nmax(|α · sin(ω · Ti ) − Vi |) ≤ \u000f,\nThis constraint provides a model of a sinusoidal process and a measure of\nhow well it fits a set of observations by means of a maximum error \u000f. Figure 2\nshows the continuous representation of the abstracted process, whose resulting\nobservation is hsinus (α = 20, ω = 0.3, Thb = 1, The = 94). A value of α/3 has\nbeen chosen for \u000f.\n30\n20\n10\n\nv\n\n0\n10\n\n20\n30\n0\n\n20\n\n40\n\nT\n\n60\n\n80\n\n100\n\nFigure 2: Abstracted sinusoidal process.\n\nOf course, various observation procedures can be devised in order to estimate the same or different characteristics of the process being guessed. These\nprocedures can provide one or several valid estimations in terms of their consistency with the abovementioned necessary constraints. In addition, different\nprocesses can be guessed from the same set of observations, all of them being\n\n6\n\n\fvalid in terms of their consistency. Hence, further criteria may be needed in\norder to rank the set of interpretations.\nThis simple example summarizes the common approach to the interpretation of experimental results in science and technology, when the knowledge is\navailable as a model or a set of models. The challenge is to assume that this\nknowledge is not available in an analytical but in a declarative form, as a pattern or a set of patterns, and that the interpretation task is expected to mimic\ncertain mechanisms of human perception.\n3. Definitions\nIn this section we formally define the main pieces of our interpretation framework: observables and observations for representing the behavior of the system\nunder study, and abstraction patterns for representing the knowledge about this\nsystem.\n3.1. Representation entities\nAn observation is the result of observing something with the quality of being\nobservable. We call Q = {q0 , q1 , ..., qn } the set of observables of a particular\ndomain.\nDefinition 1. We define an observable as a tuple q = hψ, A, T b , T e i, where ψ\nis a name representing the underlying process being observable, A = {A1 , ..., Anq }\nis a set of attributes to be valued, and T b and T e are two temporal variables\nrepresenting the beginning and the end of the observable.\nWe call Vq (Ai ) the domain of possible values for the attribute Ai . We assume a discrete representation of the time domain τ , isomorphic to the set of\nnatural numbers N. For any observable, we implicitly assume the constraint\nT b < T e . In the case of an instantaneous observable, this is represented as\nq = hψ, A, T i. Some observables can be dually represented from the temporal\nperspective, as either an observable supported by a temporal interval or as an\nobservable supported by a temporal instant, according to the task to be carried\nout. A paradigmatic example is found in representing the heart beat, since it\ncan be represented as a domain entity with a temporal extension comprising its\nconstituent waves, and it can also be represented as an instantaneous entity for\nmeasuring heart rate.\nExample 3.1. In the ECG signal, several distinctive waveforms can be identified, corresponding to the electrical activation-recovery cycle of the different\nheart chambers. The so-called P wave represents the activation of the atria,\nand is the first wave of the cardiac cycle. The next group of waves recorded is\nthe QRS complex, representing the simultaneous activation of the right and left\nventricles. Finally, the wave that represents the ventricular recovery is called\nthe T wave. Together, these waveforms devise the characteristic pattern of the\nheart cycle, which is repeated in a normal situation with every beat [46]. An\nexample of a common ECG strip is shown in Figure 3.\n7\n\n\fAccording to this description, the observable qP w = hatrial activation,\n{amplitude}, T b , T e i represents a P wave resulting from an atrial activation\nprocess with an unknown amplitude, localized in a still unknown temporal interval.\n\nP\n\nT\n\nFigure 3: Example of the ECG basic waveforms. [Source: MIT-BIH arrhythmia DB [18],\nrecording: 123, between 12:11.900 and 12:22.400]\n\nDefinition 2. We define an observation as a tuple o = hq, v, tb , te i, an instance\nof the observable q resulting from assigning a specific value to each attribute\nand to the temporal variables, where v = (v1 , . . . , vnq ) is the set of attribute\nvalues such that v ∈ Vq (A1 ) × . . . × Vq (Anq ) and tb , te ∈ τ are two precise\ninstants limiting the beginning and the end of the observation.\nWe also use the notation (A1 = v1 , . . . , Anq = vnq ) to represent the assignment of values to the attributes of the observable and T b = tb and T e = te for\nrepresenting the assignment of temporal limits to the observation.\nExample 3.2. The tuple o = hqP w , 0.17mV, 12 : 16.977, 12 : 17.094i represents\nthe particular occurrence of the P wave observable highlighted in Figure 3.\nSome notions involving observables and observations are defined below that\nwill be useful in describing certain properties and constraints of the domain\nconcepts, as well as in temporally arranging the interpretation process.\nDefinition 3. Given a set of observables Q, a generalization relation can be\ndefined between two different observables q = hψ, A, T b , T e i and q 0 = hψ 0 , A0 ,\nT 0b , T 0e i, denoted by q 0 is a q, meaning that q generalizes q 0 if and only if\nA ⊆ A0 and Vq0 (Ai ) ⊆ Vq (Ai ) ∀Ai ∈ A.\nThe generalization relation is reflexive, antisymmetric and transitive. The\ninverse of a generalization relation is a specification relation. From a logical\nperspective, a generalization relation can be read as an implication q 0 → q,\nmeaning that q 0 is more specific than q. It holds that every observation o =\nhq 0 , v, tb , te i of the observable q 0 is also an observation of q.\nExample 3.3. A common example of a generalization relation can be defined from a domain partition of an attribute. For example, the observable\nq1 = hSinus Rhythm, {RR ∈ [200ms, 4000ms]}, T b , T e i is a generalization of the\nobservables q2 = hSinus Tachycardia, {RR ∈ [200ms, 600ms]}, T b , T e i, q3 =\nhNormal Rhythm, {RR ∈ [600ms, 1000ms]}, T b , T e i and q4 = hSinus Bradycardia,\n{RR ∈ [1000ms, 4000ms]}, T b , T e i. The RR attribute represents the measure of\nthe mean time distance between consecutive beats, while q2 , q3 and q4 represent\nthe normal cardiac rhythm denominations according to the heart rate [46].\n8\n\n\fDefinition 4. Given a set of observables Q, an exclusion relation can be\ndefined between two different observables q = hψ, A, T b , T e i and q 0 = hψ 0 , A0 ,\nT 0b , T 0e i, denoted by q excludes q 0 , meaning that they are mutually exclusive\nif and only if their respective processes ψ and ψ 0 cannot concurrently occur.\nThe exclusion relation is defined extensionally from the knowledge of the\ndomain, and its rationale lies in the nature of the underlying processes and\nmechanisms. In so far as the occurrence of a process can only be hypothesized\nas long as it is observable, the exclusion relation behaves as a restriction on observations. Thus, given two observables q and q 0 , q excludes q 0 entails that they\ncannot be observed over two overlapping intervals, i.e., every two observations\no = hq, v, tb , te i and o0 = hq 0 , v0 , t0b , t0e i satisfy either te < t0b or t0e < tb . The opposite is not generally true. The exclusion relation is symmetric and transitive.\nAs an example, in the domain of electrocardiography, the knowledge about the\nphysiology of the heart precludes the observation of a P wave during an episode\nof Atrial fibrillation [46], so these two observables are mutually exclusive.\nWe call O the set of observations available for the observables in Q. In\norder to index this set of observations, they will be represented as a sequence\nby defining an order relation between them. This ordering aims to prioritize the\ninterpretation of the observations as they appear.\nDefinition 5. Let < be an order relation between two observations oi =\nhqi , vi , tbi , tei i and oj = hqj , vj , tbj , tej i such that (oi < oj ) ⇔ (tbi < tbj ) ∨ ((tbi =\ntbj ) ∧ (tei < tej )) ∨ ((tbi = tbj ) ∧ (tei = tej ) ∧ (qi < qj )), assuming a lexicographical\norder between observable names.\nA sequence of observations is an ordered set of observations O = (o1 , ..., oi , ...)\nwhere for all i < j then oi < oj . Every subset of a sequence of observations\nis also a sequence. The q-sequence of observations from O, denoted as O(q),\nis the subset of the observations for the observable q. The exclusion relation\nforces that any two observations oi = hq, vi , tbi , tei i and oj = hq, vj , tbj , tej i in O(q)\nsatisfy oi < oj ⇒ tei < tbj for the current application domain. By succ(oi )\nwe denote the successor of the observation oi in the sequence O, according to\nthe order relation <. By q-succ(oi ) we denote the successor of the observation\noi ∈ O(q) in its q-sequence O(q). Conversely to this notation, we denote by\nq(oi ) the observable corresponding to the oi observation.\n3.2. Abstraction patterns\nWe model an abstraction process as an abduction process, based on the conjectural relation m ← h [21], which can be read as ‘the observation of the\nfinding m allows us to conjecture the observation of h as a possible explanatory hypothesis’. For example, a very prominent peak in the ECG signal allows\nus to conjecture the observation of a heartbeat. A key aspect of the present\nproposal is that both the hypothesis and the finding are observables, and therefore formally identical, i.e., there exists qi , qj ∈ Q, with qi 6= qj , such that\nh ≡ qi = hψi , Ai , Tib , Tie i and m ≡ qj = hψj , Aj , Tjb , Tje i. In general, an abstraction process can involve a number of different findings, even multiple findings of\n9\n\n\fthe same observable, and a set of constraints among them; thus, for example, a\nregular sequence of normal heartbeats allows us to conjecture the observation of\na sinus rhythm. Additionally, an observation procedure is required in order to\nproduce an observation of the hypothesis from the observation of those findings\ninvolved in the abstraction process.\nWe devise an abstraction process as a knowledge-based reasoning process,\nsupported by the notion of abstraction pattern, which brings together those\nelements required to perform an abstraction. Formally:\nDefinition 6. An abstraction pattern P = hh, MP , CP , ΘP i consists of\na hypothesis h, a set of findings MP = {m1 , . . . , mn }, a set of constraints\nCP = {C1 , . . . , Ct } among the findings and the hypothesis, and an observation\nprocedure ΘP (A1 , T1b , T1e , . . . , An , Tnb , Tne ) ∈ O(h).\nEvery constraint Ci ∈ CP is a relation defined on a subset of the set of\nvariables taking part in the set of findings and the hypothesis {Ah , Thb , The , A1 ,\nT1b , T1e , . . . , An , Tnb , Tne }. Thus, a constraint is a subset of the Cartesian product of the respective domains, and represents the simultaneously valid assignments to the variables involved. We will denote each constraint by making\nreference to the set of variables being constrained, as in CP (Ah , Thb , The , A1 ,\nT1b , T1e , . . . , An , Tnb , Tne ) for the whole abstraction pattern.\nAn abstraction pattern establishes, through the set CP , the conditions for\nconjecturing the observation of h from a set of findings MP , and through the\nobservation procedure ΘP , the calculations for producing a new observation oh ∈\nO(h) from the observation of these findings. We call MSPq = {mq1 , mq2 , ..., mqs }\nthe set of findings of the observable q in P , being MP = q∈Q MPq . Thus, a set\nof findings allows the elements of a multiset of observables to be distinguished.\nThe interpretation procedure will choose, as we will see later, from the available\nobservations for every observable q satisfying the constraints CP , which are to\nbe assigned to the findings in MPq in order to calculate oh .\nThe set of findings MP is divided into two sets AP and EP , being AP ∩EP =\n∅, where AP is the set of findings that is said to be abstracted in oh , and EP is\nthe set of findings that constitute the observation environment of oh , that is, the\nset of findings needed to properly conjecture oh , but which are not synthesized\nin oh .\nA temporal covering assumption can be made as a default assumption [36] on\na hypothesis h = hψh , Ah , Thb , The i with respect to those findings m = hψm , Am ,\nb\ne\nTm\n, Tm\ni appearing in an abstraction pattern:\nDefault Assumption 1. (Temporal covering) Given an abstraction pattern P ,\nb\ne\n≤ The , for all m ∈ AP ⊆ MP .\nit holds that Thb ≤ Tm\nand Tm\nThe temporal covering assumption allows us to define the exclusiveness of\nan interpretation as the impossibility of including competing abstractions in the\nsame interpretation.\nExample 3.4. According to [11], in the electrocardiography domain a “wave” is\na discernible deviation from a horizontal reference line called baseline, where at\n10\n\n\fleast two opposite slopes can be identified. The term discernible means that both\nthe amplitude and the duration of the deviation must exceed some minimum values, agreed as 20 µV and 6 ms respectively. A wave can be completely described\nby a set of attributes: its amplitude (A), voltage polarity (V P ∈ {+, −}) and\nits main turning point T tp , resulting in the following observable:\nqwave = helectrical activity, {A, V P, T tp }, T b , T e i\nLet us consider the following abstraction pattern:\nPwave = hwave, MP = {mECG\n, . . . , mECG\n}, CPwave , wave observation()i\n0\nn\nwhere mECG\nis a finding representing an ECG sample, with a single attribute\ni\nVi representing the sample value, and a temporal variable Ti representing its\ntime point. We set the onset and end of a wave to the time of the second\nECG\nas\nmECG\nand second-to-last mECG\nand mECG\nn\n1\nn−1 samples, considering m0\nenvironmental observations which are used to check the presence of a slope\nchange just before and after the wave; thus EPwave = {mECG\n, mECG\n}, and\nn\n0\nECG\nECG\nAPwave = {m1\n, . . . , mn−1 }.\nA set of temporal constraints are established between the temporal variables:\nc1 = {T e − T b ≥ 6ms}, c2 = {T b = T1 }, c3 = {T e = Tn−1 } and c4 = {T b <\nT tp < T e }. Another set of constraints limit the amplitude and slope changes\nof the samples included in a wave: c5 = {sign(V1 − V0 ) 6= sign(V2 − V1 )},\nc6 = {sign(Vn − Vn−1 ) 6= sign(Vn−1 − Vn−2 )}, c7 = {sign(Vtp − Vtp−1 ) =\n−sign(Vtp+1 −Vtp )} and c8 = {min{|Vtp −V1 |, |Vtp −Vn−1 |} ≥ 20µV }. These two\nsets form the complete set of constraints of the pattern CPwave = {c1 , . . . , c8 }.\nOnce a set of ECG samples has satisfied these constraints, they support the\nobservation of a wave: owave = hqwave , (a, vp, ttp ), tb , te i. The values of tb and\nte are completely determined by the constraints c2 and c3 , while the observation\nprocedure wave observation() provides a value for the attributes as follows:\nvp = sign(Vtp − V1 ), a = max{|Vtp − V1 |, |Vtp − Vn−1 |}, and ttp = tb + tp, where\ntp = arg mink {Vk |1 ≤ k ≤ n − 1}, if V1 < V0 , or tp = arg maxk {Vk |1 ≤ k ≤\nn − 1}, if V1 > V0 .\n3.3. Abstraction grammars\nAccording to the definition, an abstraction pattern is defined over a fixed\nset of evidence findings MP . In general, however, an abstraction involves an\nundetermined number of pieces of evidence -in the case of an ECG wave, the\nnumber of samples-. Hence we provide a procedure for dynamically generating\nabstraction patterns, based on formal language theory. The set Q of observables\ncan be considered as an alphabet. Given an alphabet Q, the special symbols ∅\n(empty set), and λ (empty string), and the operators | (union), · (concatenation),\nand ∗ (Kleene closure), a formal grammar G denotes a pattern of symbols of\nthe alphabet, describing a language L(G) ⊆ Q∗ as a subset of the set of possible\nstrings of symbols of the alphabet.\nLet Gap be the class of formal grammars of abstraction patterns. An abstraction grammar G ∈ Gap is syntactically defined as a tuple (VN , VT , H, R).\n11\n\n\fFor the production rules in R the expressiveness of right-linear grammars is\nadopted [23]:\nH → qD\nD → qF | q | λ\nH is the initial symbol of the grammar, and this plays the role of the hypothesis guessed by the patterns generated by G. VN is the set of non-terminal\nsymbols of the grammar, satisfying H ∈ VN , although H cannot be found on the\nright-hand side of any production rule, since a hypothesis cannot be abstracted\nby itself. VT is the set of terminal symbols of the grammar, representing the set\nof observables QG ⊆ Q that can be abstracted by the hypothesis.\nGiven a grammar G ∈ Gap , we devise a constructive method for generating\na set of abstraction patterns PG = {P1 , . . . , Pi , . . .}. Since a formal grammar\nis simply a syntactic specification of a set of strings, every grammar G ∈ Gap\nis semantically extended to an attribute grammar [1], embedded with a set of\nactions to be performed in order to incrementally build an abstraction pattern by\nthe application of production rules. An abstraction grammar is represented as\nG = ((VN , VT , H, R), B, BR), where B(α) associates each grammar symbol α ∈\nVN ∪VT with a set of attributes, and BR(r) associates each rule r ∈ R with a set\nof attribute computation rules. An abstraction grammar associates the following\nattributes: i) P (attern), with each non-terminal symbol of the grammar; this\nwill be assigned an abstraction pattern; ii) A(bstracted), with each terminal\nsymbol corresponding to an observable q ∈ QG ; this allows us to assign each\nfinding either to the set AP or EP , depending on its value of true or false; iii)\nC(onstraint), with each terminal symbol corresponding to an observable; this\nwill be assigned a set of constraints. There are proposals in the bibliography\ndealing with different descriptions of Constraint Satisfaction Problems and their\nsemantic expression in different formalisms [2, 5, 12]. By explicitly specifying a\nconstraint as a relation a clear description is provided on its underlying meaning,\nbut this can lead to cumbersome knowledge representation processes. Multiple\nmathematical conventions can concisely and conveniently describe a constraint\nas a boolean-valued function over the variables of a set of observables. However,\nwe will focus on the result of applying a set of constraints among the variables\ninvolved.\nIn the following, the set of attribute computation rules associated with the\ngrammar productions is specified to provide a formal method for building abstraction patterns P ∈ PGh from a grammar Gh ∈ Gap . PGh gathers the set\nof abstraction patterns that share the same observable h as a hypothesis; thus,\nthese represent the different ways to conjecture h. Using this method, the application of every production incrementally adds a new observable as a finding\nand a set of constraints between this finding and previous entities, as follows:\n\n12\n\n\f1. The initial production H → qD entails:\nPH := hh, MH = ∅, CH = ∅, ΘH = ∅i\nCq := C(Ah , Thb , The , A1 , T1b , T1e )\nAq ∈ {true, f alse}\nPD := hh, MD = MH ∪ {mq1 }, CD = CH ∪ Cq , ΘD (A1 , T1b , T1e )i\n2. All the productions of the form D → qF entail:\nPD := hh, MD , CD , ΘD (A1 , T1b , T1e , . . . , Ak , Tkb , Tke )i\nb\ne\nCq := C(Ah , Thb , The , A1 , . . . , Ak+1 , Tk+1\n, Tk+1\n)\n\nAq ∈ {true, f alse}\nb\ne\nPF := hh, MF = MD ∪ {mqk+1 }, CF = CD ∪ Cq , ΘF (A1 , T1b , T1e , . . . , Ak+1 , Tk+1\n, Tk+1\n)i\n\n3. Productions of the form D → q conclude the generation of a pattern\nP ∈ PG h :\nPD := hh, MD , CD , ΘD (A1 , T1b , T1e , . . . , Ak , Tkb , Tke )i\nb\ne\nCq := C(Ah , Thb , The , A1 , . . . , Ak+1 , Tk+1\n, Tk+1\n)\n\nAq ∈ {true, f alse}\nb\ne\nP := hh, MP = MD ∪ {mqk+1 }, CP = CD ∪ Cq , ΘP (A1 , T1b , T1e , . . . , Ak+1 , Tk+1\n, Tk+1\n)i\n\n4. Productions of the form D → λ also conclude the generation of a pattern:\nPD := hh, MD , CD , ΘD (A1 , T1b , T1e , . . . , Ak , Tkb , Tke )i\nP := PD\nThis constructive method enables the incremental addition of new constraints as new findings are included in the representation of the abstraction\npattern, providing a dynamic mechanism for knowledge assembly by language\ngeneration. The final constraints in CP are obtained from the conjunction of the\nconstraints added at each step. Moreover, it is possible to design an adaptive\nobservation procedure as new evidence becomes available, since the observation\nprocedure may be different at each step.\nIn the case that no temporal constraints are attributed to a production, a\n’hereafter’ temporal relationship will be assumed by default to exist between\nthe new finding and the set of previous findings. For instance, a production of\nb\nthe form D → qF entails that CF = CP ∪ {Tib ≤ Tk+1\n| mi ∈ MP }.\nHence, in the absence of any temporal constraint, an increasing temporal order among consecutive findings in every abstraction pattern is assumed. Moreover, every temporal constraint must be consistent with this temporal order.\nAccording to the limitation imposed on observations of the same observable\nwhich prevents two different observations from occurring at the same time, an\nadditional constraint is added on any two findings of the same observable, and\nthus ∀mqi , mqj ∈ MPq , (Tie < Tjb ∨ Tje < Tib ).\n13\n\n\fSeveral examples of abstraction pattern grammars modeling common knowledge in electrocardiography are given below, in order to illustrate the expressiveness of the Gap grammars.\nExample 3.5. The grammar GN = (VN , VT , H, R) is designed to generate an\nabstraction pattern for a normal cardiac cycle, represented by the observable\nqN , including the descriptions of common durations and intervals [46]. In this\ngrammar, VN = {H, D, E}, VT = {qP w , qQRS , qT w }, and R is given by:\nH → qP w D\n\n{PH := hqN ,MH =∅,CH =∅,ΘH =∅i,\nb\nCP w := {TN\n=TPb w ; 50ms≤TPe w −TPb w ≤120ms},\n\nAP w := true,\nPD := hqN ,MD ={mP w },CD =CP w ,ΘD =∅i\n}\n\nD → qQRS E\n\n{PD := hqN ,MD ={mP w },CD =CP w ,ΘD =∅i,\ne\nb\nb\nCQRS := {50ms≤TQRS\n−TQRS\n≤150ms; 100ms≤TQRS\n−TPb w ≤210ms},\n\nAQRS := true,\nPE := hqN ,ME =MD ∪{mQRS },CE =CD ∪CQRS ,ΘE =∅i\n}\n\nE → qT w\n\n{PE := hqN ,ME ={mP w ,mQRS },CE ,ΘE =∅i,\ne\nb\ne\nCT w := {80ms≤TTb w −TQRS\n≤120ms; TTe w −TQRS\n≤520ms; TN\n=TTe w },\n\nAT w := true,\nP := hqN ,MP =ME ∪{mT w },CP =CE ∪CT w ,ΘP =∅i\n}\n\nThis grammar generates a single abstraction pattern, which allows us to interpret\nthe sequence of a P wave, a QRS complex, and a T wave as the coordinated\ncontraction and relaxation of the heart muscle, from the atria to the ventricles.\nSome additional temporal constraints are required and specified in the semantic\ndescription of the production rules. In this case, an observation procedure Θ is\nnot necessary since the attributes of the hypothesis are completely determined\nby the constraints in the grammar, and do not require additional calculus.\nThe next example shows the ability of an abstraction grammar to generate\nabstraction patterns dynamically with an undefined number of findings.\nExample 3.6. A bigeminy is a heart arrhythmia in which there is a continuous\nalternation of long and short heart beats. Most often this is due to ectopic heart\nbeats occurring so frequently that there is one after each normal beat, typically\npremature ventricular contractions (PVCs) [46]. For example, a normal beat\nis followed shortly by a PVC, which is then followed by a pause. The normal\nbeat then returns, only to be followed by another PVC. The grammar GV B =\n(VN , VT , H, R) generates a set of abstraction patterns for ventricular bigeminy,\nwhere VN = {H, D, E, F }, VT = {qN , qV }, and R is given by:\n\n14\n\n\fH → qN D\n\n{PH := hqV B ,MH =∅,CH =∅,ΘH =∅i,\nCN := {TVb B =T1 },\nAN := true,\nPD := hqV B ,MD ={mN\n1 },CD =CN ,ΘD =∅i\n}\n\nD → qV E\n\n{PD := hqV B ,MD ={mN\n1 },CD =CN ,ΘD =∅i,\nCV := {200ms≤T2 −T1 ≤800ms},\nAV := true,\nPE := hqV B ,ME =MD ∪{mV\n2 },CE =CD ∪CV ,ΘE =∅i\n}\n\nE → qN F\n\nV\n{PE := hqV B ,ME ={mN\n1 ,...,mk−1 },CE ,ΘE =∅i,\n\nCN := {1.5·200ms≤Tk −Tk−1 ≤4·800ms},\nAN := true,\nPF := hqV B ,MF =ME ∪{mN\nk },CF =CE ∪CN ,ΘF =∅i\n}\n\nF → qV E\n\nV\nN\n{PF := hqV B ,MF ={mN\n1 ,m2 ,...,mk },CF ,ΘF =∅i,\n\nCV := {200ms≤Tk+1 −Tk ≤800ms},\nAV := true,\nPE := hqV B ,ME =MF ∪{mV\nk+1 },CE =CF ∪CV ,ΘF =∅i\n}\n\nF → qV\n\nV\nN\n{PF := hqV B ,MF ={mN\n1 ,m2 ,...,mn−1 },CF ,ΘF =∅i,\n\nCV := {200ms≤Tn −Tn−1 ≤800ms; TVe B =Tn },\nAV := true,\nP := hqV B ,MP =MF ∪{mV\nn },CP =CF ∪CV ,ΘP =∅i\n}\n\nFor simplicity, we have referenced each N and V heart beat with a single\ntemporal variable. Thus Ti represents the time point of the ith heart beat, and\nis a normal beat if i is odd, and a PVC if i is even. With the execution of\nthese production rules, an unbounded sequence of alternating normal and premature ventricular QRS complexes is generated, described above as ventricular\nbigeminy. Note that in terms of the {N, V } symbols the GV B grammar is syntactically equivalent to the regular expression N V (N V )+ .\nIn this example, as in 3.5, an observation procedure ΘP is not necessary,\nsince the constraints in the grammar completely determine the temporal endpoints of the hypothesis and there are no more attributes to be valued. Figure 4\nshows an example of a ventricular bigeminy pattern.\n4. An interpretation framework\nIn this section, we define and characterize an interpretation problem. Informally, an interpretation problem arises from the availability of a set of initial\n15\n\n\fN\n\nV\n\nN\n\nV\n\nN\n\nV\n\nN\n\nV\n\nN\n\nV\n\nFigure 4: Example of ventricular bigeminy. [Source: MIT-BIH arrhythmia DB, recording:\n106, between 25:06.350 and 25:16.850]\n\nobservations from a given system, and of domain knowledge formalized as a\nset G = {Gq1 , . . . , Gqn } of Gap grammars. Every abstraction grammar Gh ∈ G\ngenerates a set of abstraction patterns that share the same hypothesis h. The\nwhole set of abstraction patterns that can be generated by G is denoted by P.\nDefinition 7. Let Q be a set of observables and G a set of abstraction grammars. We say G induces an abstraction relation in Q × Q, denoted by qi qj\nif and only if there exists an abstraction pattern P generated by some Gh ∈ G\nsuch that:\n1. qj = h\n2. MPqi ∩ AP 6= ∅\n3. qi + qi , where\n\n+\n\nis the transitive closure of\n\nThe relation qi qj is a sort of conjectural relation that allows us to conjecture the presence of qj from the observation of qi . The transitive closure of\nthe abstraction relation is a strict partial order relation between the domain\nobservables, such that qi < qj ⇔ qi +qj ; that is, if and only if ∃qk0 , . . . , qkn ∈ Q\nsuch that qk0 = qi , qkn = qj and for all m, with 0 ≤ m < n, it holds that\n...\nqkn = qj an abstraction\nqkm qkm+1 . We denote by qi = qk0 qk1\nsequence in n steps that allows the conjecture of qj from qi . This order relation\ndefines an abstraction hierarchy among the observables in Q. From the definition of a strict partial order, there must be at the base of this hierarchy at least\none observable we call q0 , corresponding in the domain of electrocardiography\nto the digital signal.\nExample 4.1. Let Q = {qP w , qQRS , qT w , qN , qV , qV B } and G = {GN , GV B },\ncontaining the knowledge represented in examples 3.5 and 3.6. The derived abstraction relation states that qP w , qQRS , qT w qN , and qN , qV qV B . Intuitively,\nwe can see that this relation splits the observables into three abstraction levels:\nthe wave level, describing the activation/recovery of the different heart chambers; the heartbeat level, describing each cardiac cycle by its origin in the muscle\ntissue; and the rhythm level, describing the dynamic behavior of the heart over\nmultiple cardiac cycles. These levels match those commonly used by experts in\nelectrocardiogram analysis [46].\nIt is worth noting that the abstraction relation is only established between\nobservables in the AP set. This provides flexibility in defining the evidence\nforming the context of a pattern, as this may belong to different abstraction\nlevels.\n16\n\n\fDefinition 8. We define an abstraction model as a tuple M = hQ, , Gi,\nwhere Q is the set of domain observables, is an abstraction relation between\nsuch observables, and G is the available knowledge as a set of abstraction grammars.\nThe successive application of the available abstraction grammars results in\na series of observations organized in a hierarchy of abstraction, according to the\norder relation between observables as described above. We are able to define an\ninterpretation problem as follows.\nDefinition 9. We define an interpretation problem as a tuple IP = hO, Mi,\nwhere O = (o1 , o2 , . . . , oi , . . .) is a sequence of observations requiring interpretation and M is an abstraction model of the domain.\nIt is worth mentioning that this definition of an abductive interpretation\nproblem differs from the common definition of an abductive diagnosis problem,\nwhere the difference between normal and faulty behaviors is explicit, leading to\nthe role of faulty manifestations. Only when a faulty manifestation is detected is\nthe abductive process of diagnosis started. In contrast, in the present framework\nall the observations have the same status, and the objective of the interpretation\nprocess is to provide an interpretation of what is observed at the highest possible\nabstraction level in terms of the underlying processes. As we will see later,\nsome observables may stand out amongst others regarding the efficiency of the\ninterpretation process, as salient features that can draw some sort of perceptual\nattention.\nAs discussed above, any observable q ∈ QP can appear multiple times as\ndifferent pieces of evidence for an abstraction pattern P , in the form of findings\ncollected in the set MP . As a consequence, P can predict multiple observations\nof the set O for a given observable q ∈ QP , each of these corresponding to\none of the findings of the set MP through a matching relation. This matching\nrelation is a matter of choice for the agent in charge of the interpretation task,\nby selecting from the evidence the observation corresponding to each finding in\na given pattern.\nDefinition 10. Given an interpretation problem IP , a matching relation for\na pattern P ∈ P is an injective relation in MP × O, defined by mq \u001b o if and\nonly if o = hq, v, tb , te i ∈ O(q) ⊆ O and mq = hψ, A, T b , T e i ∈ MP , such that\n(A1 = v1 , . . . , Anq = vnq ), T b = tb and T e = te .\nA matching relation makes an assignment of a set of observations to a set\nof findings of a certain pattern, leading us to understand the interpretation\nproblem as a search within the available evidence for a valid assignment for the\nconstraints represented in an abstraction pattern.\nFrom the notion of matching relation we can design a mechanism for abductively interpreting a subset of observations in O through the use of abstraction\npatterns. Thus, a matching relation for a given pattern allows us to hypothesize new observations from previous ones, and to iteratively incorporate new\nevidence into the interpretation by means of a hypothesize-and-test cycle. The\n17\n\n\fnotion of abstraction hypothesis defines those conditions that a subset of observations must satisfy in order to be abstracted by a new observation, and makes\nit possible to incrementally build an interpretation from the incorporation of\nnew evidence.\nDefinition 11. Given an interpretation problem IP , we define an abstraction\nhypothesis as a tuple ~ = hoh , P, \u001bi, where P = hh, MP , CP , ΘP i ∈ P, \u001b⊆\nMP × O, and we denote O~ = codomain(\u001b), satisfying:\n1. oh ∈ O(h).\n2. oh = ΘP (O~ ).\n3. CP (Ah , Thb , The , A1 , T1b , T1e , . . . , An , Tnb , Tne )|oh ,o1 ,...,on ∈O~ is satisfied.\nThese conditions entail: (1) an abstraction hypothesis guesses an observation\nof the observable hypothesized by the pattern; (2) a new observation is obtained\nfrom the application of the observation procedure to those observations being\nassigned to the set of findings MP by the matching relation; and (3) the observations taking part in an abstraction hypothesis must satisfy those constraints\nof the pattern whose variables are assigned a value by the observations.\nEven though the matching relation is a matter of choice, and therefore a\nconjecture in itself, some additional constraints may be considered as default\nassumptions. An important default assumption in the abstraction of periodic\nprocesses states that consecutive observations are related by taking part in the\nsame hypothesis, defining the basic period of the process. This assumption\nfunctions as a sort of operative hypothesis of the abstraction task:\nDefault Assumption 2. (Basic periodicity) Periodic findings in an abstraction\npattern must be assigned consecutive observations by any matching relation:\n∀mqi , mqi+1 ∈ MPq , mqi \u001b oj ∧ q−succ(oj ) ∈ O~ ⇒ mqi+1 \u001b q−succ(oj )\nThis default assumption allows us to avoid certain combinations of abstraction hypotheses that, although formally correct, are meaningless from an interpretation point of view. For example, without the assumption of basic periodicity, a normal rhythm fragment might be abstracted by two alternating\nbradycardia hypotheses, as shown in Figure 5.\nobradycardia\n1\n\nobradycardia\n2\n\nFigure 5: Motivation for the assumption of basic periodicity. [Source: MIT-BIH arrhythmia\nDB, recording: 103, between 00:40.700 and 00:51.200]\n\n18\n\n\fThe set of observations that may be abstracted in an interpretation problem\nIP is O(domain( )), that is, observations corresponding to observables involved\nin the set of findings to be abstracted by some abstraction pattern. An abstraction hypothesis defines in the set of observations O a counterpart of the subsets\nAP and EP of the set of findings MP of a pattern P , resulting from the selection of a set of observations O~ ⊆ O by means of a matching relation, satisfying\nthose requirements shown in the definition 11.\nDefinition 12. Given an interpretation problem IP and an abstraction hypothesis ~ = hoh , P, \u001bi, we define the following sets of observations:\n• abstracted by(oh ) = {o ∈ O~ | mqi \u001b o ∧ mqi ∈ AP }.\n• environment of(oh ) = {o ∈ O~ | mqi \u001b o ∧ mqi ∈ EP }.\n• evidence of(oh ) = abstracted by(oh ) ∪ environment of(oh ).\nWe denote by abstracted by(oh ) the set of observations abstracted by oh\nand which are somehow its constituents, while environment of(oh ) denotes\nthe evidential context of oh . We denote by evidence of(oh ) the set of all\nobservations supporting a specific hypothesis. Since the matching relation is\ninjective, it follows that abstracted by(oh ) ∩ environment of(oh ) = ∅.\nThe definition of these sets can be generalized to include as arguments a set of\nobservations O = {oh1 , ..., ohm } from a set of abstraction hypotheses ~1 , ..., ~m :\nS\n• abstracted by(O) = oh ∈O abstracted by(oh )\nS\n• environment of(O) = oh ∈O environment of(oh ).\nS\n• evidence of(O) = oh ∈O evidence of(oh ).\nAs a result of an abstraction hypothesis, a new observation oh is generated\nwhich can be included in the set of domain observations, so that O = O ∪ {oh }.\nIn this way, an interpretation can be incrementally built from the observations,\nby means of the aggregation of abstraction hypotheses.\nDefinition 13. Given an interpretation problem IP , an interpretation is\ndefined as a set of abstraction hypotheses I = {~1 , . . . , ~m }.\nAn interpretation can be rewritten as I = hOI , PI , \u001bI i, where OI = {oh1 , . . .\n, ohm } is the set of observations guessed by performing multiple abstraction\nhypotheses; PI = {P1 , . . . , Pm } is the set of abstraction patterns used in the\ninterpretation; and \u001bI =\u001b~1 ∪ . . . ∪ \u001b~m ⊆ (M1 ∪ . . . ∪ Mm ) × O is the global\nmatching relation. We should note that the global matching relation \u001bI is\nnot necessarily injective, since some observations may simultaneously belong to\nboth the abstracted by() and environment of() sets of different observations.\nFrom a given interpretation problem IP , multiple interpretations can be\nabductively proposed through different sets of abstraction hypotheses. Indeed,\nthe definition of interpretation is actually weak, since even an empty set I = ∅\n19\n\n\fis formally a valid interpretation. Thus, we need additional criteria in order\nto select the solution to the interpretation problem as the best choice among\ndifferent possibilities [33].\nDefinition 14. Given an interpretation problem IP , an interpretation I is a\ncover of IP if the set of observations to be interpreted O(domain( )) ⊆ O is\nincluded in the set of observations abstracted by I, that is, O(domain( )) ⊆\nabstracted by(OI ).\nDefinition 15. Given an interpretation problem IP , two different abstraction\nhypotheses ~ and ~0 of the mutually exclusive observables qh and qh0 are alternative hypotheses if and only if abstracted by(oh ) ∩ abstracted by(oh0 ) 6=\n∅.\nExample 4.2. A ventricular trigeminy is an infrequent arrhythmia very similar\nto ventricular bigeminy, except that the ectopic heart beats occur after every pair\nof normal beats instead of after each one. The grammar for hypothesizing a\nventricular trigeminy qV T would therefore be very similar to that described in\nexample 3.6, with the difference that each qV finding would appear after every\npair of qN findings. These two processes are mutually exclusive, insofar as the\nheart can develop just one of these activation patterns at a given time. For this\nreason, in the event of an observation of qV , this may be abstracted by either a\nqV B or a qV T hypothesis, but never by both simultaneously.\nDefinition 16. Given an interpretation problem IP , a cover I for IP is exclusive if and only if it contains no alternative hypotheses.\nThus, two or more different hypotheses of mutually exclusive observables\nabstracted from the same observation will be incompatible in the same interpretation, since inferring both a statement and its negation is logically prevented,\nand therefore only one of them can be selected.\nOn the other hand, a parsimony criterion is required, in order to disambiguate the possible interpretations to select as the most plausible those of\nwhich the complexity is minimum [33]. We translate this minimum complexity\nin terms of minimal cardinality.\nDefinition 17. Given an interpretation problem IP , a cover I for IP is minimal, if and only if its cardinality is the smallest among all covers for IP .\nMinimality introduces a parsimony criterion on hypothesis generation, promoting temporally maximal hypotheses, that is, those hypotheses of a larger\nscope rather than multiple equivalent hypotheses of smaller scope. For example,\nconsider an abstraction pattern that allows the conjecture of a regular cardiac\nrhythm from the presence of three or more consecutive heart beats. Without a\nparsimony criterion, a sequence of nine consecutive beats could be abstracted\nby up to three consecutive rhythm observations, even when a single rhythm\nobservation would be sufficient and better.\nDefinition 18. The solution of an interpretation problem IP is the set of all\nminimal and exclusive covers of IP .\n20\n\n\fThis definition of solution is very conservative and has limited practical\nvalue, since the usual objective is to obtain a small set of interpretations explaining what has been observed (and ideally only a single one). However, it\nallows us to characterize the problem in terms of complexity. Abduction has\nbeen formulated under different frameworks according to the task to be addressed, but has always been found an intractable problem in the general case\n[24]. The next theorem proves that an interpretation problem is also an intractable problem.\nTheorem 1. Finding the solution to an interpretation problem is NP-hard.\nProof: We will provide a polynomial-time reduction of the well-known set covering problem to an interpretation problem. Given a set of elements U =\n{u1 , . . . , um } and a set S of subsets of U , a cover is a set C ⊆ S of subsets\nof S whose union is U . In terms of complexity analysis, two different problems\nof interest are identified:\n• A set covering decision problem, stating that given a pair (U, S) and an\ninteger k the question is whether there is a set covering of size k or less.\nThis decision version of set covering is NP-complete.\n• A set covering optimization problem, stating that given a pair (U, S) the\ntask is to find a set covering that uses the fewest sets. This optimization\nversion of set covering is NP-hard.\nWe will therefore reduce the set covering problem to an interpretation problem\nby means of a polynomial-time function ϕ. Thus, we shall prove that ϕ(U, S)\nis an interpretation problem, and there is a set covering of ϕ(U, S) of size k or\nless if and only if there is a set covering of U in S of size k or less.\nGiven a pair (U, S), let ϕ(U, S) = hO, Mi where:\n1. O = U = {u1 , . . . , um }, such that ui = hq, true, ii and q = hψ, present, T i.\n2. M = hQ, , Pi, such that domain( ) = q.\n3. ∀s = {ui1 , . . . , uin } ∈ S, ∃P ∈ P, being P = hqP , MP , CP , ΘP i, where:\n• q\n\nqP and P 6= P 0 ⇒ qP 6= qP 0 .\n\n• MP = AP = MPq = {mq1 = hψ, present1 , T1 i, . . . , mqn }.\nVn\n• CP = { k=1 Tk = k; Thb = min{Tk }; The = max{Tk }}.\nVn\n• presentP = ΘP (mq1 , . . . , mqn ) = k=1 presentk .\nThus, ϕ(U, S) is an interpretation problem according to this definition. On the\nother hand, ϕ(U, S) can be built in polynomial time. In addition, for all s ∈ S\nthere exists an abstraction hypothesis ~ = hoh , P, \u001bi such that:\n1. oh = hh, true, minui ∈s {i}, maxui ∈s {i}i.\n2. ui ∈ s ⇒ ui ∈ codomain(\u001b).\n3. \u001b provides a valid assignment, since the set of observations satisfying\nΘP = true also satisfies the constraints in CP .\n21\n\n\fSince each abstraction hypothesis involves a different abstraction pattern\nthere are no alternative hypotheses in any interpretation of ϕ(U, S).\nSuppose there is a set covering C ⊆ S of U of size k or less. For all u ∈ U\nthere exists ci ∈ C − {∅} such that u ∈ ci and, by the above construction, there\n) = {u ∈ codomain(\u001b~i )} =\nexists ~i ∈ I such that abstracted by(ohS\ni\nS {u ∈\nci } = ci , and therefore, O(domain( )) ⊆ ~i ∈I abstracted by(ohi ) = i ci =\nC. That is, the set of abstraction hypotheses I is an exclusive cover of the\ninterpretation problem ϕ(U, S) of size k or less.\nFollowing the same reasoning as for the set covering optimization problem,\nfinding a minimal and a exclusive cover of an interpretation problem ϕ(U, S) is\nNP-hard, since we can use the solution of this problem to check whether there\nis an exclusive cover of the interpretation problem of size k or less, and this has\nbeen proven above to be NP-complete. \u0003\n5. Solving an interpretation problem: A heuristic search approach\nThe solution set for an interpretation problem IP consists of all exclusive\ncovers of IP having the minimum possible number of abstraction hypotheses.\nObtaining this solution set can be stated as a search on the set of interpretations of IP . The major source of complexity of searching for a solution is the\nlocal selection, from the available evidence in O, of the most appropriate matching relation for a number of abstraction hypotheses that can globally shape a\nminimal and exclusive cover of IP .\nNevertheless, the whole concept of solution must be revised in practical\nterms, due to the intractability of the task and the incompleteness of the abstraction model, that is, of the available knowledge. Indeed, we assume that\nany realistic abstraction model can hardly provide a cover for every possible\ninterpretation problem. Hence the objective should shift from searching for a\nsolution to searching for an approximate solution.\nCertain principles applicable to the interpretation problem can be exploited\nin order to approach a solution in an iterative way, bounding the combinatorial\ncomplexity of the search. These principles can be stated as a set of heuristics\nthat make it possible to evaluate and discriminate some interpretations against\nothers from the same base evidence:\n• A coverage principle, which states the preference for interpretations explaining more initial observations.\n• A simplicity principle, which states the preference for interpretations with\nfewer abstraction hypotheses.\n• An abstraction principle, which states the preference for interpretations\ninvolving higher abstraction levels.\n• A predictability principle, which states the preference for interpretations\nthat properly predict future evidence.\n\n22\n\n\fThe coverage and simplicity principles are used to define a cost measure\nfor the heuristic search process [14], while the abstraction and predictability\nprinciples are used to guide the reasoning process, in an attempt to emulate the\nsame shortcuts used by humans.\nGiven an interpretation problem IP , a heuristic vector for a certain interpretation I can be defined to guide the search, as \u000f(I) = (1 − ς(I), κ(I)), where\nς(I) = |abstracted by(OI )|/|O(domain( ))| is the covering ratio of I, and\nκ(I) = |OI | is the complexity of I. The main goal of the search strategy is to\napproach a solution with a maximum covering ratio and a minimum complexity,\nwhich is equivalent to the minimization of the heuristic vector. The covering\nratio will be considered the primary heuristic, and complexity will be considered\nfor ranking interpretations with the same covering ratio. The \u000f(I) heuristic is\nintuitive and very easy to calculate, but as a counterpart it is a non-admissible\nheuristic, since it is not monotone and may underestimate or overestimate the\ntrue goal covering. Therefore optimality cannot be guaranteed and we require\nan algorithm efficient with this type of heuristic. We propose the CONSTRUE()\nalgorithm, whose pseudocode is shown in Algorithm 1. This algorithm is a minor variation of the K-Best First Search algorithm [14], with partial expansion\nto reduce the number of explored nodes.\nAlgorithm 1 CONSTRUE search algorithm.\n1: function CONSTRUE(IP )\n2:\nvar I0 = ∅\n3:\nvar K = max(|{qj ∈ Q | qi qj , qi ∈ Q}|)\n4:\nset focus(I0 , o1 )\n5:\nvar open = sorted([h\u000f(I0 ), I0 i])\n6:\nvar closed = sorted([])\n7:\nwhile open 6= ∅ do\n8:\nfor all I ∈ open[0 . . . K] do\n9:\nI 0 = next(get descendants(I))\n10:\nif I 0 is null then\n11:\nopen = open − {h\u000f(I), Ii}\n12:\nclosed = closed ∪ {h\u000f(I), Ii}\n13:\nelse if ς(I 0 ) = 1.0 then\n14:\nreturn I 0\n15:\nelse\n16:\nopen = open ∪ {h\u000f(I 0 ), I 0 i}\n17:\nend if\n18:\nend for\n19:\nend while\n20:\nreturn min(closed)\n21: end function\n\nThe CONSTRUE() algorithm takes as its input an interpretation problem IP ,\nand returns the first interpretation found with full coverage, or the interpretation with the maximum covering ratio and minimum complexity if no covers\nare found, using the abstraction and predictability principles in the searching\n23\n\n\fprocess. To do this, it manages two ordered lists of interpretations, named open\nand closed. Each interpretation is annotated with the computed values of the\nheuristic vector. The open list contains those partial interpretations that can\nfurther evolve by (1) appending new hypotheses or (2) extending previously\nconjectured hypotheses to subsume or predict new evidence. This open list is\ninitialized with the trivial interpretation I0 = ∅. The closed list contains those\ninterpretations that cannot explain more evidence.\nAt each iteration, the algorithm selects the K most promising interpretations\naccording to the heuristic vector (line 8), and partially expands each one of them\nto obtain the next descendant node I 0 . If this node is a solution, then the process\nends by returning it (line 13), otherwise it is added to the open list. The partial\nexpansion ensures that the open list grows at each iteration by at most K new\nnodes, in order to save memory. When a node cannot expand further, it is added\nto the closed list (line 12), from which the solution is taken if no full coverages\nare found (line 20).\nThe selection of a value for the K parameter depends on the problem at\nhand. We select its value as K = max(|{qj ∈ Q | qi qj , qi ∈ Q}|), that is, as\nthe maximum number of observables that can be abstracted from any observable\nqi . The intuition behind this choice is that at any point in the interpretation\nprocess, and with the same heuristic values, the same chance is given to any\nplausible abstraction hypothesis in order to explain a certain observation.\nIn order to expand the current set of interpretations, the GET DESCENDANTS() function relies on different reasoning modes, that is, different forms of\nabduction and deduction, which are brought into play under the guidance of an\nattentional mechanism. Since searching for a solution finally involves the election of a matching relation, both observations and findings should be included\nin the scope of this mechanism. Hence, a focus of attention can be defined to\nanswer the following question: which is the next observation or finding to be\nprocessed? The answer to this question takes the form of a hypothesize-and-test\ncycle: if the attention focuses on an observation, then an abstraction hypothesis explaining this observation should be generated (hypothesize); however, if\nthe attention focuses on a finding predicted by some hypothesis, an observation\nshould be sought to match such finding (test). Thus, the interpretation problem\nis solved by a reasoning strategy that progresses incrementally over time, coping with new evidence through the dynamic generation of abstraction patterns\nfrom a finite number of abstraction grammars, and bounding the theoretical\ncomplexity by a parsimony criterion.\nTo illustrate and motivate the reasoning modes implemented in building\ninterpretations and supporting the execution of the CONSTRUE() algorithm,\nwe use a simple, but complete, interpretation problem.\nExample 5.1. Let Q = {qwave , qP w , qQRS , qT w , qN }, G = {Gw , GN , GT w }, where\nGw models the example 3.4, GN is described in example 3.5, and GT w =\n({H, D}, {qQRS , qwave }, H, R) describes the knowledge to conjecture a T wave\nwith the following rules:\n\n24\n\n\fH → qQRS D\n\n{PH := hqT w ,MH =∅,CH =∅,ΘH =∅i,\ne\nb\nCQRS := {80ms≤TTb w −TQRS\n≤120ms; TTe w −TQRS\n≤520ms},\n\nAQRS := f alse,\nPD := hqT w ,MD ={mQRS },CD =CQRS ,ΘD =∅i\n}\n\nD → qwave\n\n{PD := hqT w ,MD ={mQRS },CD =CQRS ,ΘD =∅i,\nb\ne\nCwave := {TTb w =Twave\n; TTe w =Twave\n; max(diff(sig[mwave ])≤0.7·max(diff(sig[mQRS ]))},\n\nAwave := true,\nb\ne\nb\ne\n,TQRS\n,Twave\n,Twave\n)i\nP := hqT w ,MP =MD ∪{mwave },CP =CD ∪Cwave ,ΘP =Tw delin(TQRS\n}\n\nThis grammar hypothesizes the observation of a T wave from a wave appearing shortly after the observation of a QRS complex, requiring a significant\ndecrease in the maximum slope of the signal (in the constraint definition Cwave ,\nthe expression “max(diff(sig[m])” stands for the maximum absolute value of the\ne\nb\n). The observation procedure of\nand Tm\nderivative of the ECG signal between Tm\nthe generated pattern is denoted as Tw delin(), and may be any of the methods\ndescribed in the literature for the delineation of T waves, such as in [26].\nIn addition to the Pwave pattern generated by Gw and detailed in example 3.4,\nGN and GT w generate the following abstraction patterns:\nPN = hqN , APN = {mP w , mQRS , mT w } ∪ EPN = ∅, CPN , ΘPN = ∅i\nPT w = hqT w , APT w = {mwave } ∪ EPT w = {mQRS }, CQRS ∪ Cwave , Tw delin()i\nFinally, let O = {owave\n= hqwave , ∅, 0.300, 0.403i, owave\n= hqwave , ∅, 0.463,\n1\n2\nPw\n0.549i, o\n= hqP w , ∅, 0.300, 0.403i, oQRS = hqQRS , ∅, 0.463, 0.549i} be a set of\ninitial observations including a P wave and a QRS complex abstracting two wave\nobservations located at specific time points.\nGiven this interpretation problem, Figure 6 shows the starting point for the\ninterpretation, where the root of the interpretation process is the trivial interpretation I0 , and the attention is focused on the first observation. The sequence\nof reasoning steps towards the resolution of this interpretation problem will be\nexplained in the following subsections.\n5.1. Focus of attention\nThe focus of attention is modeled as a stack; thus, once the focus is set\non a particular observation (or finding), any observation that was previously\nunder focus will not return to be focused on until the reasoning process on the\ncurrent observation is finished. Algorithm 2 shows how the different reasoning\nmodes are invoked based on the content of the focus of attention, resulting in a\nhypothesize-and-test cycle.\nLines 4-8 generate the descendants of an interpretation I when there is an\nobservation at the top of the stack. These descendants are the result of two\npossible reasoning modes: the deduction of new findings, performed by the\n\n25\n\n\fAlgorithm 2 Method for obtaining the descendants of an interpretation using different reasoning modes based on the content of the focus of attention.\n1: function get descendants(I)\n2:\nvar f ocus = get focus(I).top()\n3:\nvar desc = ∅\n4:\nif is observation(f ocus) then\n5:\nif f ocus = oh | ~ ∈ I then\n6:\ndesc = deduce(I, f ocus)\n7:\nend if\n8:\ndesc = desc ∪ abduce(I, f ocus) ∪ advance(I, f ocus)\n9:\nelse if is finding(f ocus) then\n10:\ndesc = subsume(I, f ocus) ∪ predict(I, f ocus)\n11:\nend if\n12:\nreturn desc\n13: end function\n\nDEDUCE() function, provided that the observation being focused on is an ab-\n\nstraction hypothesis; and the abduction of a new hypothesis explaining the\nobservation being focused on, performed by the ABDUCE() function. A last\ndescendant is obtained using the ADVANCE() function, which simply restores\nthe previous focus of attention by means of a POP() operation. If the focus is\nthen empty, ADVANCE() inserts the next observation to explain, which may be\nselected by temporal order in the general case, or by some domain-dependent\nsaliency criterion to prioritize certain observations over others. By removing the\nobservation at the top of the focus of attention, the ADVANCE() function sets\naside that observation as unintelligible in the current interpretation, according\nto the available knowledge.\nIf the top of the stack contains a finding, then Algorithm 2 obtains the\ndescendants of the interpretation from the SUBSUME() and PREDICT() functions (line 10). The first of these functions looks for an existing observation\nsatisfying the constraints on the finding focused on, while the second makes\npredictions about observables that have not yet been observed. All of these reasoning modes are described separately and detailed below; we will illustrate how\nthe CONSTRUE() algorithm combines these in order to solve the interpretation\nproblem in Example 5.1.\n5.2. Building an interpretation: Abduction\nAlgorithm 3 enables the abductive generation of new abstraction hypotheses. It is applied when the attention is focused on an observation that can\nbe abstracted by some abstraction pattern, producing a new observation at a\nhigher level of abstraction.\nThe result of ABDUCE() is a set of interpretations I 0 , each one adding a new\nabstraction hypothesis with respect to the parent interpretation I. To generate\nthese hypotheses, we iterate through those grammars that can make a conjecture from the observation oi under focus (line 3). Then, for each grammar, each\nproduction including the corresponding observable q(oi ) (line 4) initializes an\n26\n\n\fAlgorithm 3 Moving forward an interpretation through abduction.\n1: function abduce(I, oi )\n2:\nvar desc = ∅\n3:\nfor all Gh = hVN , VT , H, Ri ∈ G | q(oi ) h do\n4:\nfor all (U → qV ) ∈ R | q(oi ) is a q ∧ Aq = true do\n5:\nPV = hh, MV = {mq }, CV , ΘV i\n6:\n~ = hoh , PV , \u001b~ = {mq \u001b oi }i\n7:\nL~ = [(U → qV )]; B~ = U ; E~ = V\n8:\nI 0 = hOI ∪ {oh }, PI ∪ {PV }, \u001bI ∪ \u001b~ i\n9:\nO = O ∪ {oh }\n10:\nget focus(I 0 ).pop()\n11:\nget focus(I 0 ).push(oh )\n12:\ndesc = desc ∪ {I 0 }\n13:\nend for\n14:\nend for\n15:\nreturn desc\n16: end function\n\nabstraction pattern with a single finding of this observable (line 5), and a new\nhypothesis is conjectured with a matching relation involving both the observation under focus and the finding (line 6). A list structure L~ and two additional\nvariables B~ and E~ are initialized to trace the sequence of productions used to\ngenerate the findings in the abstraction pattern; these will play an important\nrole in subsequent reasoning steps (line 7). Finally the new hypothesis opens a\nnew interpretation (lines 8-9) focused on this hypothesis (line 11).\nIn this way, the ABDUCE() function implements, from a single piece of evidence, the hypothesize step of the hypothesize-and-test cycle. Below we explain\nthe reasoning modes involved in the test step of the cycle.\nExample 5.2. Let us consider the interpretation problem set out in example 5.1\nand the interpretation I0 shown in Figure 6. According to Algorithm 2, the ABDUCE() function is used to move forward the interpretation, since the focus\nof attention points to an observation oP w . The abstraction pattern that supports this operation is PN , and a matching relation is established with the mP w\nfinding. As a result, the following hypothesis is generated:\n~1 = hoN , PN , {mP w \u001b oP w }i\nFigure 6 shows the result of this reasoning process, in a new interpretation\ncalled I1 . Note that the focus of attention has been moved to the newly created\nhypothesis (lines 10-11 of the ABDUCE() function).\n5.3. Building an interpretation: Deduction\nThis reasoning mode is applied when the attention is focused on an observation oh previously conjectured as part of an abstraction hypothesis ~ (see Algorithm 4). The DEDUCE() function takes the evidence that has led to conjecture\noh and tries to extend it with new findings which can be expected, i.e., deduced,\n27\n\n\fAlgorithm 4 Moving forward an interpretation through the deduction of new findings.\n1: function deduce(I, oh )\n2:\nvar desc = ∅\n3:\nif B~ 6= H then\n4:\nfor all (X → qB~ ) ∈ R do\n5:\nPB~ = hh, MB~ = {mq }, CB~ , ΘB~ i\n6:\nfor all (U → q 0 V ) ∈ L~ do\n0\n\n7:\nPV = hh, MU ∪ {mq }, CU ∪ CV , ΘV i\n8:\nend for\n9:\n~ = hoh , PE~ , \u001b~ i\n10:\nI 0 = hOI , PI ∪ {PE~ }, \u001bI i\n11:\ninsert(L~ , (X → qB~ ), begin); B~ = X\n12:\nget focus(I 0 ).push(mq )\n13:\ndesc = desc ∪ {I 0 }\n14:\nend for\n15:\nelse\n16:\nfor all (E~ → qX) ∈ R do\n17:\nPX = hh, ME~ ∪ {mq }, CE~ ∪ CX , ΘX i\n18:\n~ = hoh , PX , \u001b~ i\n19:\nI 0 = hOI , PI \\ {PE~ } ∪ {PX }, \u001bI i\n20:\ninsert(L~ , (E~ → qX), end); E~ = X\n21:\nget focus(I 0 ).push(mq )\n22:\ndesc = desc ∪ {I 0 }\n23:\nend for\n24:\nend if\n25:\nreturn desc\n26: end function\n\nfrom the abstraction grammar Gh used to guess the observation. The key point\nis that this deduction process follows an iterative procedure, as the corresponding abstraction pattern is dynamically generated from the grammar. Hence the\nDEDUCE() function aims to extend a partial matching relation by providing the\nnext finding to be tested, as part of the test step of the hypothesize-and-test\ncycle.\nSince the first finding leading to conjecture oh does not necessarily appear at\nthe beginning of the grammar description, the corresponding abstraction pattern\nwill not, in general, be generated incrementally from the first production of the\ngrammar. Taking as a starting point the production used to conjecture oh (line 4\nin Algorithm 3), the goal is to add a new finding by applying a new production\nat both sides, towards the beginning and the end of the grammar, using the\ninformation in the L~ list. The B~ variable represents the non-terminal at the\nleft-hand side of the first production in L~ , while E~ represents the non-terminal\nat the right-hand side of the last production in L~ . Hence, this list has the form\nL~ = [(B~ → q 0 V 0 ), (V 0 → q 00 V 00 ), . . . , (V 0n−1 → q 0n E~ )]. In case L~ is empty,\nboth variables B~ and E~ represent the H non-terminal. With this information\nthe sequence of findings supporting the hypothesis ~ can be updated in two\n\n28\n\n\fopposite directions:\n• Towards the beginning of the grammar (lines 3-14): we explore the set\nof observables that may occur before the first finding according to the\nproductions of the grammar (line 4), and a new finding is deduced for\neach of these in different descendant interpretations. A new pattern PB~\nassociated with the B~ non-terminal is initialized with the new finding\n(line 5), and by moving along the sequence of productions generating the\nprevious set of findings (lines 6-8) the pattern associated to the rightmost non-terminal PE~ is updated with a new set of findings containing\nmq . Consequently, the hypothesis and the interpretation are also updated\n(lines 9 and 10), and the applied production is inserted at the beginning\nof L~ (line 11). Finally the newly deduced finding is focused on (line 12).\n• Towards the end of the grammar (lines 15-23): for each one of the observables that may occur after the last finding, a new finding mq is deduced,\nexpanding the abstraction pattern associated with the new rightmost nonterminal X. After updating the hypothesis ~, the previous pattern PE~\nin the resulting interpretation I 0 is replaced by the new one, PX , and the\napplied production is inserted at the end of L~ . Finally, the new finding\nis focused on (line 21).\nExample 5.3. Let us consider the interpretation problem set out in example 5.1\nand the interpretation I1 shown in Figure 6. Remember that the grammar used\nto generate the hypothesis in the focus of attention, GN , has the following form:\nH → qP w D\nD → qQRS E\nE → qT w\nIn this situation, it is possible to deduce new findings from the oN hypothesis.\nFollowing Algorithm 3 we can check that B~ = H and E~ = D, since the only\nfinding in the matching relation is mP w . Deduction then has to be performed\nafter this last finding, using the production D → qQRS E. After constraint checking, the resulting finding is as follows:\nb\ne\nmqn+1 = mQRS = hqQRS , ∅, TQRS\n∈ [0.400, 0.520], TQRS\n∈ [0.450, 0.660]i\n\nFigure 6 illustrates the outcome of this reasoning process and the uncertainty\nin the temporal limits of the predicted finding, which is now focused on in the\ninterpretation I2 .\n5.4. Building an interpretation: Subsumption\nSubsumption is performed when the attention is focused on a finding previously deduced from some abstraction grammar (see Algorithm 5). This reasoning mode avoids the generation of a new hypothesis for every piece of available\nevidence if it can be explained by a previous hypothesis. The SUBSUME()\n29\n\n\ffunction explores the set of observations O and selects those consistent with\nthe constraints on the finding in the focus of attention (line 3), expanding the\nmatching relation of the corresponding hypothesis in different descendant interpretations (line 4). The focus of attention is then restored to its previous state\n(line 5), allowing the deduction of new findings from the same hypothesis. The\nSUBSUME() function clearly enforces the simplicity principle.\nAlgorithm 5 Moving forward an interpretation through subsumption.\n1: function subsume(I, mi )\n2:\nvar desc = ∅\n3:\nfor all oj ∈ O | mi \u001b oj do\n4:\nI 0 = hOI , PI , \u001bI ∪ {mi \u001b oj }i\n5:\nget focus(I 0 ).pop(mi )\n6:\ndesc = desc ∪ {I 0 }\n7:\nend for\n8:\nreturn desc\n9: end function\n\nExample 5.4. Let us consider the interpretation I2 shown in Figure 6. If we\napply the subsumption procedure, it is possible to set a matching relation between oQRS and mQRS , since this observation satisfies all the constraints on\nthe finding. The result is shown in the interpretation I3 . Note that the uncertainty in the end time of the oN hypothesis is now reduced after the matching,\nhaving TNe ∈ [0.631, 1.030]. Following this, the attention focuses once again on\nthis hypothesis, and a new deduction operation may therefore be performed.\n5.5. Building an interpretation: Prediction\nThis reasoning mode is also performed when the attention is focused on a\nfinding deduced from some abstraction grammar (see Algorithm 6). In this case,\nif a finding previously deduced has not yet been observed, it will be predicted.\nThe goal of the PREDICT() function is to conjecture a new observation to\nmatch the focused finding. For this, the abstraction model is explored and those\ngrammars whose hypothesized observable is more specific than the predicted observable are selected (line 3). Then, a new pattern is initialized with no evidence\nsupporting it, and a new abstraction hypothesis with an empty matching relation is generated (lines 4-5). Finally, the attention focuses on the observation\nbeing guessed (lines 9-10) to enable the DEDUCE() function to start a new test\nstep at a lower abstraction level. Since L~ is initialized as an empty list (line 6),\nB~ and E~ point to the initial symbol of the grammar, and the corresponding\nabstraction pattern will be generated only towards the end of the grammar.\nExample 5.5. Starting from the I3 interpretation shown in Figure 6, the next\nstep we can take to move forward the interpretation is a new deduction on the\noN hypothesis, generating a new finding mT w and leading to the I4 interpretation. Since there is no available observation of the T wave, a matching with\nthis new finding mT w cannot be made by the SUBSUME() function, thus, the\n30\n\n\fAlgorithm 6 Moving forward an interpretation through the prediction of nonavailable evidence.\n1: function predict(I, mi )\n2:\nvar desc = ∅\n3:\nfor all Gh = hVN , VT , H, Ri ∈ G | h is a q(mi ) do\n4:\nPH = hh, MH = ∅, CH = ∅, ΘH = ∅i\n5:\n~ = hoh , PH , \u001b~ = ∅i\n6:\nL~ = ∅; B~ = E~ = H\n7:\nI 0 = hOI ∪ {oh }, PI ∪ {PH }, \u001bI ∪ {mi \u001b oh }i\n8:\nO = O ∪ {oh }\n9:\nget focus(I 0 ).pop(mi )\n10:\nget focus(I 0 ).push(oh )\n11:\ndesc = desc ∪ {I 0 }\n12:\nend for\n13:\nreturn desc\n14: end function\n\nonly option for moving forward this interpretation is through prediction. Following the PREDICT() function, the GT w grammar can be selected, and a new\nobservation oT w can be conjectured, generating the I5 interpretation.\nFrom I5 we can continue the deduction on the oT w hypothesis. If we ap0\nply the DEDUCE() function we obtain the mQRS finding from the environment,\nshown in Figure 6 as I6 . To move on, we can apply the SUBSUME() function,\n0\nestablishing the matching relation {mQRS \u001b oQRS }. This leads to the I7 interpretation, in which the uncertainty on the oT w observation is reduced; however,\nthe evidence for the PT w pattern is not yet complete. A new DEDUCE() step is\nnecessary, which deduces the mwave necessary finding in the I8 interpretation.\nThis finding is also absent, so another PREDICT() step is required. In this last\nstep, the Pwave pattern can be applied to observe the deviation in the raw ECG\nsignal, generating the owave\nobservation and completing the necessary evidence\n3\nfor the oT w observation and thus also for oN . Constraint solving assigns the\nvalue of tbT w , teT w and teN , so the result is a cover of the initial interpretation\nproblem in which all the hypotheses have a necessary and sufficient set of evidence. This solution is depicted in I9 .\nIt is worth noting that in this example the global matching relation \u001bI is\n0\nnot injective, since mQRS \u001b oQRS and mQRS \u001b oQRS . Also note that each\ninterpretation only generates one descendant; in a more complex scenario, however, the possibilities are numerous, and the responsibility of finding the proper\nsequence of reasoning steps lies with the CONSTRUE() algorithm.\n5.6. Improving the efficiency of interpretation through saliency\nStarting a hypothesize-and-test cycle for every single sample is not feasible\nfor most of the time series interpretation problems. Still, many problems may\nbenefit from certain saliency features that can guide the attention focus to\nsome limited temporal fragments that can be easily interpretable. Thus, the\n\n31\n\n\foN\noPw\n\noN\n\nfocus\n\nfocus\n\noPw\n\noQRS\n\noPw\n\n(mwave) (mwave)\nowave\nowave\n1\n2\n\noQRS\n\n(m ) (mwave)\nowave\nowave\n1\n2\nwave\n\nI0 = Initial evidence\nmQRS\noN\n\n(mPw)\n\nABDUCE(I0 , oP w )\n\nI1 =\n\noN\n\noN\n\n(m ) m ?\n\n(m ) (m )\n\nPw\n\nPw\n\nQRS\n\noN\n\nfocus\n\nfocus\n\noPw\n\noQRS\n\noPw\n\n(m ) (m )\nowave\nowave\n1\n2\nwave\n\n(m ) (mwave)\nowave\nowave\n1\n2\nSUBSUME(I2 , mQRS )\n\nI3 =\n\noN\n(mPw) (mQRS)\n\noN\noTw\noN\n\nmTw?\n\nfocus\n\noQRS\n\noPw\n\n(m ) (m )\nowave\nowave\n1\n2\nwave\n\nI5 =\n\n(m ) (m )\nmQRS’ ?\nQRS\n\noQRS\n\nI6 =\n\nm ?\n\nfocus\n\nfocus\n\n(m ) (m )\n(mQRS’ )\nPw\n\noPw\n\noTw\n\nDEDUCE(I5 , oT w )\n\nI7 =\n\noQRS\n\n(m ) (m )\nowave\nowave\n1\n2\nwave\n\nI8 =\n\nwave\n\noQRS\n\nmTw?\noTw\n\nwave\n\n0\n\nSUBSUME(I6 , mQRS )\n\noN\n\noPw\n\nQRS\n\n(m ) (m )\nowave\nowave\n1\n2\nwave\n\nwave\n\n(mPw) (mQRS)\n(mQRS’ )\n\noTw\n\nwave\n\noN\noTw\noN\n\nTw\n\n(m ) (m )\nowave\nowave\n1\n2\nwave\n\noQRS\n\nPREDICT(I4 , mT w )\n\noN\nPw\n\noPw\n\nmwave\noTw\noN\n\nmTw?\n\n(m ) (m )\nowave\nowave\n1\n2\nwave\n\nwave\n\nDEDUCE(I3 , oN )\n\nI4 =\n\nfocus\n\n(mPw) (mQRS)\n\nfocus\n\noPw\n\nmQRS’\noTw\noN\n\noQRS\n\nwave\n\nwave\n\nDEDUCE(I1 , oN )\n\nI2 =\nmTw\noN\n\nQRS\n\noN\noTw\noN\n\nmTw?\n\nfocus\n\noTw\nm\n\nwave\n\n(mPw) (mQRS)\n(mQRS’ )\noPw\n\noQRS\n\n(m ) (m )\nowave\nowave\n1\n2\n\n?\n\nwave\n\nDEDUCE(I7 , oT w )\n\nI9 =\n\nwave\n\n(mTw)\noTw\n(mwave)\nowave\n3\n\nPREDICT(I8 , mwave )\n\nFigure 6: Sequence of reasoning steps for solving a simple interpretation problem.\n\n32\n\n\finterpretation of the whole time series can pivot on a reduced number of initial\nobservations, thereby speeding up the interpretation process.\nA saliency-based attentional strategy can be devised from the definition of\nabstraction patterns using a subset of their constraints as a coarse filter to\nidentify a set of plausible observations. For example, in the ECG interpretation\nproblem the most common strategy is to begin the analysis by considering a\nreduced set of time points showing a significant slope in the signal, consistent\nwith the presence of QRS complexes [47]. This small set of evidence allows us\nto focus the interpretation on the promising signal segments, in the same way\nthat a cardiologist focuses on the prominent peaks to start the analysis [46]. It\nshould be noted that this strategy is primarily concerned with the behavior of\nthe focus of attention, and that it does not discard the remaining, non-salient\nobservations, as these are included later in the interpretation by means of the\nsubsumption and prediction reasoning modes.\n6. Some strengths of the framework\nIn this section we provide several practical examples which illustrate some of\nthe strengths of the proposed interpretation framework and its ability to tackle\nwith typical weaknesses of strategies based solely on a classification approach.\n6.1. Avoiding a casuistry-based interpretation\nIn the time domain, classification-based recognition of multiple processes occurring concurrently usually leads to a casuistry-based proliferation of classes, in\nwhich a new class is usually needed for each possible superposition of processes\nin order to properly identify all situations. It is common to use a representation\nin the transform domain, where certain regular processes are easily separable,\nalthough at the expense of a cumbersome representation of the temporal information [30]. In contrast, in the present framework, the hypothesize-and-test\ncycle aims to conjecture those hypotheses that best explain the available evidence, including simultaneous hypotheses in a natural way as long as these are\nnot mutually exclusive.\nECG interpretation provides some interesting examples of this type of problem. Atrial fibrillation, a common heart arrhythmia caused by the independent\nand erratic contractions of the atrial muscle fibers, is characterized by an irregularly irregular heart rhythm [46]. Most of the classification techniques for the\nidentification of atrial fibrillation are based on the analysis of the time interval\nbetween consecutive beats, and attempt to detect this irregularity [34]. These\ntechniques offer good results in those situations in which atrial fibrillation is\nthe only anomaly, but they fail to properly identify complex scenarios which go\nbeyond the distinction between atrial fibrillation and normal rhythm. In the\nstrip shown in Figure 7, obtained during a pilot study for the home follow-up of\npatients with cardiac diseases [38], such a classifier would wrongly identify this\nsegment as an atrial fibrillation episode, since the observed rhythm variability\nis consistent with the description of this arrhythmia. In contrast, the present\n\n33\n\n\finterpretation framework properly explains the first five beats as a sinus bradycardia, compatible with the presence of a premature ectopic beat in the second\nposition, followed by a trigeminy pattern during six beats, and finally another\nectopic beat with a morphology change. The reason to choose this interpretation, despite being more complex than the atrial fibrillation explanation, is\nthat it is able to abstract some of the small P waves before the QRS complexes,\nincreasing the interpretation coverage.\n\nFigure 7: False atrial fibrillation episode. [Source: Mobiguide Project [38], private recording]\n\n6.2. Coping with ignorance\nMost of the classifiers solve a separability problem among classes, either by\nlearning from a training set or by eliciting prior knowledge, and these are implicitly based on the closed-world assumption, i.e., every new instance to be\nclassified is assigned to one of the predefined classes. Such classifiers may additionally include a ’reject’ option for all those instances that could be misclassified\nsince they appear too close to the classification boundaries [7, 17]. This reject\noption is added as another possible answer expressing doubt. However, such\nclassifiers fail to classify new instances of unknown classes, since they cannot\nexpress ignorance. An approach to this problem can be found in novelty detection proposals [35], which can detect when a new instance does not fit any of\nthe predefined classes as it substantially differs from those instances available\nduring training. Still, these are limited to a common feature representation for\nevery instance, hindering the identification of what is unintelligible from the\navailable knowledge.\nThe present framework provides an expression of ignorance as a common\nresult of the interpretation problem. As long as the abstraction model is incomplete, the non-coverage of some piece of evidence by any interpretation is\nan expression of partial ignorance. In the extreme case, the trivial interpretation I0 may be a proper solution for an interpretation problem, expressing total\nignorance. Furthermore, abduction naturally includes the notion of ignorance\nin the reasoning process, since any single piece of evidence can be sufficient to\nguess an interpretation, and the hypothesize-and-test cycle can be understood\nas a process of incremental addition of evidence against an initial state of ignorance, while being able to provide an interpretation at any time based on the\navailable evidence.\nAs an example, consider the interpretation problem illustrated in Figure 8.\nLet the initial evidence be the set of QRS annotations obtained by a state-of-the\nart detection algorithm [47]. In this short strip, the eighth and ninth annotations\n\n34\n\n\fcorrespond to false positives caused by the presence of noise. A classificationbased strategy processes these two annotations as true QRS complexes, and the\nmonotone nature of the reasoning prevents their possible refutation, probably\nleading to beat misclassification and false arrhythmia detection, with errors\npropagating onwards to the end of the processing. In contrast, the present\nframework provides a single normal rhythm as the best interpretation, which\nexplains all but the two aforementioned annotations, which are ignored and\nconsidered unintelligible in the available model. It is also worth noting the\nability of this framework to integrate the results of an available classifier as a\ntype of constraint specification in the interpretation cycle.\n\nFigure 8: Unintelligible evidence due to noise. [Source: MIT-BIH arrhythmia DB, recording:\n112, between 13:46.200 and 13:56.700]\n\n6.3. Looking for missing evidence\nThe application of the classification paradigm to pattern detection also entails the potential risk of providing false negative results. In the worst case,\na false negative result may be interpreted by a decision maker as evidence of\nabsence, leading to interpretation errors with their subsequent costs, or in the\nbest case as an absence of evidence caused by the lack of a proper detection\ninstrument.\nEven though abduction is fallible, and false negative results persist, the\nhypothesize-and-test cycle involves a prediction mechanism that points to missing evidence that is expected and, moreover, estimates when it should appear.\nBoth the bottom-up and top-down processing performed in this cycle reinforces\nconfidence in the interpretation, since the semantics of any conclusion is widened\naccording to its explanatory power.\nAs an example, consider the interpretation problem illustrated in Figure 9.\nThe initial evidence is again a set of QRS annotations obtained by a stateof-the-art detection algorithm [47]. Note that the eighth beat has not been\nannotated, due to a sudden decrease in the signal amplitude. This error can be\namended in the hypothesize-and-test cycle, since the normal rhythm hypothesis\nthat abstracts the first seven QRS annotations predicts the following QRS to\nbe in the position of the missing annotation, and the PREDICT() procedure can\nlook for this (e.g., checking an alternative set of constraints).\nThe capability of abduction to ignore or look for new evidence has been\ntested with a simplified version of the present framework in the QRS detection\nproblem [43], leading to a statistically significant improvement over a state-ofthe art algorithm.\n\n35\n\n\fFigure 9: Missing evidence that may be discovered by prediction. [Source: MIT-BIH normal\nsinus rhythm DB, recording: 18184, between 09:12:45.000 and 09:12:55.500]\n\n6.4. Interpretability of the reasoning process and the results\nThe interpretability of a reasoning formalism, defined as the ability to understand and evaluate its conclusions, is an essential feature for achieving an\nadequate confidence in decision making [31]. In this sense, there are a number\nof classification methods with good interpretability; however, the methods that\ntypically offer the best performance belong to the so-called black box approaches.\nThe present interpretation framework is able to provide a justification of any\nresult in relation to the available model. Given any solution or partial solution\nof an interpretation problem, the searching path up to I0 gives full details of all\nthe reasoning steps taken to this end, and any abstraction hypothesis can be\ntraced back to the information supporting it.\nThis interpretation framework is also able to answer the question of why a\ncertain hypothesis has been rejected or neglected at any reasoning step. This is\ndone by exploring the branches outside the path between I0 and the solution.\nSince the K exploration parameter within the CONSTRUE() algorithm has been\nchosen as the maximum number of hypotheses that may explain a given observable, it is possible to reproduce the reasoning steps taken in the conjecture of any\nabstraction hypothesis, and to check why this did not succeed (non-satisfaction\nof pattern constraints, lower coverage, etc.). This can be useful in building and\nrefining the knowledge base.\n7. Experimental evaluation: beat labeling and arrhythmia detection\nThe interpretation of the electrocardiogram has served both as a challenge\nand as an inspiration for the AI community almost since its inception, due to a\nnumber of factors that can be summarized as: (1) the complexity of the physiological processes underlying what is observed; and (2) the absence of an accurate\nmodel of the heart and the hardly formalizable knowledge that constitutes the\nexperience of the cardiologist. There are numerous problems falling within the\nscope of ECG interpretation, the most relevant being heartbeat labeling [29].\nWe have tested the present framework by abductively identifying and measuring\na set of qualitative morphological and rhythm attributes for each heartbeat, and\nusing a rule-based classifier to assign a label to clusters of similar heartbeats [44].\nIt is noteworthy that an explicit representation of knowledge has been adopted,\nnamely the kind of knowledge that can be found in an ECG handbook. Table 1\nreproduces the performance comparison between this approach and the most\n\n36\n\n\fTable 1: VEB and SVEB classification performance of the abductive approach and comparison\nwith the most relevant automatic and assisted methods of the state-of-the-art\n\nDataset\n\nMethod\n\nVEB\nSe\nP+\n\nSVEB\nSe\nP+\n\nMIT-BIH Arrhythmia\nDS1+DS2\n\nTeijeiro et al. - Automatic 92.82 92.23 85.10 84.51\nLlamedo et al. - Assisted\n90±1 97±0 89±2 88±3\nKiranyaz et al. - Assisted\n93.9\n90.6\n60.3\n63.5\nInce et al. - Assisted\n84.6\n87.4\n63.5\n53.7\nLlamedo et al. - Automatic 80±2 82±3 76±2 43±2\n\nMIT-BIH Arrhythmia\nDS2\n\nTeijeiro et al. - Automatic 94.63 96.79 87.17\nLlamedo et al. - Assisted\n93±1 97±1 92±1\nKiranyaz et al. - Assisted\n95.0\n89.5\n64.6\nChazal et al. - Assisted\n93.4\n97.0\n94.0\nZhang et al. - Automatic\n85.48 92.75 79.06\nLlamedo et al. - Automatic 89±1 87±1 79±2\nChazal et al. - Automatic\n77.7\n81.9\n75.9\n\n83.98\n90±3\n62.1\n62.5\n35.98\n46±2\n38.5\n\nrelevant automatic and assisted approaches of the state-of-the art, using sensitivity and positive predictivity of ventricular and supraventricular ectopic beat\nclasses.\nAs it can be seen, this method significantly outperforms any other automatic\napproaches in the state-of-the-art, and even improves most of the assisted approaches that require expert aid. The most remarkable improvement concerns\nthe classification of supraventricular ectopic beats, which are usually hard to\ndistinguish using only morphological features. The abductive interpretation in\nmultiple abstraction levels, including a rhythm description of signal, is what\nenables a more precise classification of each individual heartbeat.\nFurthermore, the abductive interpretation approach has been used for arrhythmia detection in short single-lead ECG records, focusing on atrial fibrillation [45]. The interpretation results are combined with machine learning\ntechniques to obtain an arrhythmia classifier, achieving the best score in the\n2017 Physionet/CinC Challenge dataset and outperforming some of the most\npopular techniques such as deep learning and random forests [8].\n8. Discussion\nA new model-based framework for time series interpretation is proposed.\nThis framework relies on some basic assumptions: (i) interpretation of the behavior of a system from the set of available observations is a sort of conjecturing,\nand as such follows the logic of abduction; (ii) the interpretation task involves\nboth bottom-up and top-down processing of information along a set of abstraction levels; (iii) at the lower levels of abstraction, the interpretation task is a\nform of precompiled knowledge-based pattern recognition; (iv) the interpretation task involves both the representation of time and reasoning about time and\nalong time.\n\n37\n\n\fModel-based representation in the present framework is based on the notion\nof abstraction pattern, which defines an abstraction relation between observables\nand provides the knowledge and methods to conjecture new observations from\nprevious ones. Let us deepen in both the backward and forward logical meaning\nof an abstraction pattern, following a reasoning similar to that of [4]:\n• Backward meaning. From the backward reading of an abstraction pattern P , a hypothesis h is a possible abstraction of m1 , . . . , mn , provided\nthat the constraints in CP hold. An abstraction pattern satisfies the compositionality principle of abductive reasoning, and hence an abstraction\nhypothesis can be conjectured from a single piece of evidence, and new\npieces of evidence can be added later [16]. On the other hand, if there\nare multiple ways of observing h by means of multiple patterns, and their\nrespective constraints are inconsistent with the evidence, we do not conclude ¬h, interpreted as failure to prove h; we will only conclude ¬h in all\nthose interpretations conjecturing an observation of a different h0 , where\nh and h0 are mutually exclusive.\n• Forward meaning. An abductive observation is built upon an archetypical\nrepresentation of a hypothesis h, creating an observation as an instance of\nh by estimating, from the available evidence, its attribute values A and\nits temporal location T b and T e by means of an observation procedure\nΘP . From a forward reading, assuming h is true, there is an observation\nfor each observable of the set m1 , . . . , mn such that the constraints in\nCP hold. However, the estimated nature of abstraction does not usually\nallow us to infer, from the observation of h, the same observations of\nm1 , . . . , mn that have been abstracted into h. We must presume instead\nthat assuming h is true entails the occurrence of an observation for each\nobservable of m1 , . . . , mn , without necessarily entailing its attribute values\nand its temporal location.\nBoth the forward and the backward meanings of an abstraction pattern support the incremental building of an interpretation in the present framework.\nThus, what initially was defined as a set covering problem of a time series fragment -a completely intractable problem as it moves away from a toy examplecan be feasibly solved if it is properly structured in a set of abstraction levels, on which four reasoning modes (abduction, deduction, subsumption and\nprediction) can make a more efficient search of the best explanation under a\nparsimony criterion. Moreover, this incremental reasoning primarily follows the\ntime direction, since the available knowledge is usually compiled in the form of\na set of processes that can be expected to be found in a certain sequence, which\nunderscores the anticipatory information contained in the evidence.\nAn abstraction model, built on a set of abstraction patterns, establishes a\ncausal responsibility for the behavior observed in a complex system [24]. This\nresponsibility is expressed in the language of processes: a process is said to be\nobservable if it is assumed that it causes a recognizable trace in the physical\nquantity to be interpreted. This notion of causality is behind perception, i.e.,\n38\n\n\fconcerned with the explanation of sensory data, in contrast with the notion of\ncausality in diagnosis, concerned with the explanation of abnormality [10].\nRepresenting and reasoning about context is a relevant issue in model-based\ndiagnosis [4, 10, 33, 40]. A contextual observation is nothing more than another observation that need not be explained by a diagnosis. In most of the\nbibliography, the distinction between these two roles must be defined beforehand. Several other works enable the same observation to play different roles\nin different causal patterns, thus providing some general operations for expressing common changes made by the context in a diagnostic pattern [25, 32]. In\nthe present interpretation framework, an observation can either be part of the\nevidence to be explained in a certain abstraction pattern, or can be part of the\nenvironment in another abstraction pattern. Both types of observation play a\npart in the hypothesize-and-test cycle, with the only difference that observations\nof the environment of an abstraction pattern are not expected to be abstracted\nby this pattern. Hence, observations of the environment are naturally included\nin the deduction, subsumption and prediction modes of reasoning.\nAn important limitation of the present framework is its knowledge-intensive\nnature, requiring a non-trivial elicitation of expert knowledge. It is worth exploring different possibilities for the inclusion of machine learning strategies,\nboth for the adaption and the definition of the knowledge base. A first approach may address the automatic adjustment of the initial constraints among\nrecurrent findings in abstraction grammars. In this manner, for example, temporal constraints between consecutive heartbeats in a normal rhythm abstraction\ngrammar could be adapted to the characteristics of the subject whose ECG is\nbeing interpreted, allowing the identification of possible deviations from normality with greater sensitivity. On the other hand, the discovery of new abstraction\npatterns and abstraction grammars by data mining methods appears as a key\nchallenge. In this regard, the CONSTRUE() algorithm should be extended by\ndesigning an INDUCE() procedure aimed at conjecturing new observables after\nan inductive process. To this end, new default assumptions should be made in\norder to define those grammar structures that should rule the inductive process.\nThese grammar structures may lead to discovery new morphologies or rhythms\nnot previously included in the knowledge base.\nThe proposed framework formulates an interpretation problem as an abduction problem with constraints, targeted at finding a set of hypotheses covering\nall the observations while satisfying a set of constraints on their attribute and\ntemporal values. Thus, consistency is the only criterion to evaluate the plausibility of a hypothesis, resulting in a true or false value, and any evoked hypothesis\n(no matter how unusual it is) for which inconsistent evidence cannot be found is\nconsidered as plausible and, consequently, it will be explored in the interpretation cycle. Even though this simple approach has provided remarkable results,\nit can be expected that the inclusion of a hypothesis evaluation scheme, typically based on probability [33, 37] or possibility [13, 32] theories, will allow us\nto better discriminate between plausible and implausible hypotheses, leading to\nbetter explanations with fewer computational requirements.\nThe expressiveness of the present framework should also be enhanced to\n39\n\n\fsupport the representation of the absence of some piece of evidence, in the form\nof negation, so that ¬q represents the absence of q. The exclusion relation is a\nfirst approach to manage with the notion of absence in the hypothesize-and-test\ncycle, since the occurrence of a process is negated by the concurrent occurrence\nof any of the processes related to it by the exclusion relation. On the other hand,\nan inhibitory relation can enable us to represent a certain process preventing\nanother from occurring under some temporal constraints, providing a method to\ninsert the prediction of the absence of some observable in the hypothesize-andtest cycle. Furthermore, other forms of interaction between processes, possibly\nmodifying the respective initial patterns of evidence, should be modeled.\nFurther efforts should be made to improve the efficiency of the interpretation\nprocess. To this end, two main strategies are currently being explored. On the\none hand, the model structure is exploited to identify necessary and sufficient\nconditions for every hypothesis to be conjectured; the necessary conditions avoid\nthe expansion of the hypotheses that can be ruled out because they are inconsistent with observations, while sufficient conditions avoid the construction of\nredundant interpretations [9]. A different strategy entails additional restrictions\nin the amount of computer memory and time needed to run the algorithm, resulting in a selective pruning of the node expansion while sacrificing optimality;\nthis strategy is similar to the one used in the K-Beam algorithm [14].\nThe CONSTRUE() algorithm is based on the assumption that all the evidence to be explained is available at the beginning of the interpretation task. A\nnew version of the algorithm should be provided to cope with a wide range of\nproblems, where the interpretation must be updated as new evidence becomes\navailable over time. Examples of such problems are continuous biosignal monitoring or plan execution monitoring [3]. At the emergence of a new piece of evidence, two reasoning modes may come into play triggered by the CONSTRUE()\nalgorithm: a new explanatory hypothesis can be conjectured by means of the\nABDUCE() procedure, or the evidence can be incorporated in an existing hypothesis by means of the SUBSUME() procedure. In this way, the incorporation\nof new evidence over time is seamlessly integrated into the hypothesize-andtest cycle. Furthermore, to properly address these interpretation scenarios, the\nheuristics used to guide the search must be updated to account for the timing\nof the interpretation process, which will lead to the definition of a covering ratio\nuntil time t, and a complexity until time t.\nImplementation\nWith the aim of supporting reproducible research, the full source code of the\nalgorithms presented in this paper has been published under an Open Source\nLicense1 , along with a knowledge base for the interpretation of the ECG signal\nstrips of all examples in this paper.\n1 https://github.com/citiususc/construe\n\n40\n\n\fAcknowledgments\nThis work was supported by the Spanish Ministry of Economy and Competitiveness under project TIN2014-55183-R. T. Teijeiro was funded by an FPU\ngrant from the Spanish Ministry of Education (MEC) (ref. AP2010-1012).\nReferences\n[1] A.V. Aho, M.S. Lam, R. Sethi, and J.D. Ullman. Compilers: Principles,\nTechniques and Tools. Pearson Education, Inc., 2006.\n[2] S. Barro, R. Marı́n, J. Mira, and A. Patón. A model and a language for\nthe fuzzy representation and handling of time. Fuzzy Sets and Systems,\n61:153–175, 1994.\n[3] R. Barták, R. A. Morris, and K. B. Venable. An Introduction to ConstraintBased Temporal Reasoning. Synthesis Lectures on Artificial Intelligence\nand Machine Learning, 8(1):1–121, feb 2014.\n[4] V. Brusoni, L. Console, P. Terenziani, and D. Theseider Dupré. A spectrum\nof definitions for temporal model-based diagnosis. Artificial Intelligence,\n102(1):39–79, 1998.\n[5] S. Chakravarty and Y. Shahar. CAPSUL: A constraint-based specification\nof repeating patterns in time-oriented data. Annals of Mathematics and\nArtificial Intelligence, 30:3–22, 2000.\n[6] E. Charniak. Motivation analysis, abductive unification and nonmonotonic\nequality. Artificial Intelligence, 34(3):275–295, 1989.\n[7] C.K. Chow. On optimum recognition error and reject tradeoff. IEEE\nTransaction on Information Theory, 16(1):41–46, 1970.\n[8] G. Clifford, C. Liu, B. Moody, I. Silva, Q. Li, A. Johnson, and R. Mark.\nAF Classification from a Short Single Lead ECG Recording: the PhysioNet\nComputing in Cardiology Challenge. In Proceedings of the 2017 Computing\nin Cardiology Conference (CinC), volume 47, 2017.\n[9] L. Console, L. Portinale, and D. Theseider Dupré. Using compiled knowledge to guide and focus abductive diagnosis. IEEE Transactions on Knowledge and Data Engineering, 8(5):690–706, 1996.\n[10] L. Console and P. Torasso. A spectrum of logical definitions of model-based\ndiagnosis. Computational Intelligence, 3(7):133–141, 1991.\n[11] Working Party CSE. Recommendations for measurement standards in\nquantitative electrocardiography. European Heart Journal, 6(10):815–825,\n1985.\n[12] R. Dechter. Constraint Processing. Morgan Kaufmann Publishers, 2003.\n41\n\n\f[13] D. Dubois and H. Prade. Fuzzy relation equations and causal reasoning.\nSpecial Issue on ”Equations and Relations on Ordered Structures : Mathematical Aspects and Applications” (A. Di Nola, W. Pedrycz, S. Sessa,\neds.), Fuzzy Sets and Systems, 75:119–134, 1995.\n[14] S. Edelkamp and S. Schrödl. Heuristic Search: Theory and Applications.\nMorgan Kaufmann, 2011.\n[15] D. Ferrucci, A. Levas, S. Bagchi, D. Gondek, and E.T. Mueller. Watson:\nBeyond Jeopardy. Artificial Intelligence, 199–200:93–105, 2012.\n[16] P. Flach. Abduction and induction: Syllogistic and inferential perspectives. In Abductive and Inductive Reasoning Workshop Notes, pages 31–35.\nUniversity of Bristol, 1996.\n[17] G. Fumera, F. Roli, and G. Giacinto. Reject option with multiple thresholds. Pattern Recognition, (33):2099–2101, 2000.\n[18] A. L. Goldberger et al. PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation, 101(23):215–220, June 2000.\n[19] I.J. Haimowitz and I.S. Kohane. Automated Trend Detection with Alternate Temporal Hypotheses. In Proceedings of the 13th International Joint\nConference of Artificial Intelligence, volume 1, pages 146–151, 1993.\n[20] I.J. Haimowitz, P.P. Le, and I.S. Kohane. Clinical monitoring using\nregression-based trend templates. Artificial Intelligence in Medicine,\n7(6):473–496, 1995.\n[21] C. Hartshorn et al. Collected papers of Charles Sanders Peirce. Harvard\nUniversity Press, 1931.\n[22] J.R. Hobbs, M. Stickel, and P. Martin. Interpretation as abduction. Artificial Intelligence, 63:69–142, 1993.\n[23] J. Hopcroft, R. Motwani, and J. Ullman. Introduction to automata theory,\nlanguages and computation. Addison-Wesley, 2001.\n[24] J.R. Josephson and S.G. Josephson. Abductive inference. Computation,\nphilosophy, technology. Cambridge University Press, 1994.\n[25] J. M. Juárez, M. Campos, J. Palma, and R. Marı́n. Computing contextdependent temporal diagnosis in complex domains. Expert Systems with\nApplications, 35(3):991–1010, 2008.\n[26] P. Laguna, R. Jané, and P. Caminal. Automatic detection of wave boundaries in multilead ECG signals: validation with the CSE database. Computers and Biomedical Research, 27:45–60, 1994.\n\n42\n\n\f[27] C. Larizza, G. Bernuzzi, and M. Stefanelli. A general framework for building patient monitoring systems. In Proceedings of the 5th Conference on\nArtificial intelligence in Medicine, pages 91–102, 1995.\n[28] D. Litman and J. Allen. A plan recognition model for subdialogues in\nconversation. Cognitive Science, 11:163–200, 1987.\n[29] E. J. S. Luz, W. R. Schwartz, G. Cámara-Chávez, and D. Menotti. ECGbased Heartbeat Classification for Arrhythmia Detection: A Survey. Computer Methods and Programs in Biomedicine, 2016.\n[30] F. Mörchen. Time series feature extraction for data mining using DWT and\nDFT. Technical Report no. 33, Department of Mathematics and Computer\nScience, University of Marburg, 2003.\n[31] D. Nauck and R. Kruse. Obtaining interpretable fuzzy classification rules\nfrom medical data. Artificial Intelligence in Medicine, 16(2):149–169, 1999.\n[32] J. Palma, J. M. Juárez, M. Campos, and R. Marı́n. Fuzzy theory approach\nfor temporal model-based diagnosis: An application to medical domains.\nArtificial Intelligence in Medicine, 38(2):197, 2006.\n[33] Y. Peng and J.A. Reggia. Abductive inference models for diagnostic\nproblem-solving. Springer-Verlag, 1990.\n[34] A. Petrenas, V. Marozas, and L. Sörnmo. Low-complexity detection of\natrial fibrillation in continuous long-term monitoring. Computers in biology\nand medicine, 65:184–91, oct 2015.\n[35] M.A.F. Pimentel, D.A. Clifton, L. Clifton, and L. Tarassenko. A review of\nnovelty detection. Signal Processing, (99):215–249, 2014.\n[36] D. Poole. A methodology for using a default and abductive reasoning\nsystem. International Journal of Intelligent Systems, 5(5):521–548, 1990.\n[37] D. Poole. Learning, Bayesian Probability, Graphical Models, and Abduction. In Abduction and Induction: Essays on their Relation and Integration,\npages 153–168. Springer Netherlands, 2000.\n[38] L. Sacchi, E. Parimbelli, S. Panzarasa, N. Viani, E. Rizzo, C. Napolitano,\nR. Ioana Budasu, and S. Quaglini. Combining Decision Support SystemGenerated Recommendations with Interactive Guideline Visualization for\nBetter Informed Decisions. In Artificial Intelligence in Medicine, pages\n337–341. Springer International Publishing, 2015.\n[39] Y. Shahar. A framework for knowledge-based temporal abstraction. Artificial intelligence, 90(1–2):79–133, 1997.\n[40] Y. Shahar. Dynamic temporal interpretation contexts for temporal abstraction. Annals of Mathematics and Artificial Intelligence, 22(1–2):159–192,\n1998.\n43\n\n\f[41] Y. Shahar. Knowledge-based temporal interpolation. Journal of experimental and theoretical artificial intelligence, 11:123–144, 1999.\n[42] Y. Shahar and M.A. Musen. Knowledge-based temporal abstraction in\nclinical domains. Artificial Intelligence in Medicine, 8(3):267–298, 1996.\n[43] T. Teijeiro, P. Félix, and J. Presedo. Using Temporal Abduction for Biosignal Interpretation: A Case Study on QRS Detection. In 2014 IEEE International Conference on Healthcare Informatics, pages 334–339, 2014.\n[44] T. Teijeiro, P. Félix, J. Presedo, and D. Castro. Heartbeat classification\nusing abstract features from the abductive interpretation of the ECG. IEEE\nJournal of Biomedical and Health Informatics, 2016.\n[45] T. Teijeiro, C.A. Garcı́a, D. Castro, and P. Félix. Arrhythmia Classification\nfrom the Abductive Interpretation of Short Single-Lead ECG Records. In\nProceedings of the 2017 Computing in Cardiology Conference (CinC), volume 47, 2017.\n[46] Galen S. Wagner. Marriott’s Practical Electrocardiography. Wolters Kluwer\nHealth/Lippincott Williams & Wilkins, 11 edition, 2008.\n[47] W. Zong, G.B. Moody, and D. Jiang. A robust open-source algorithm to\ndetect onset and duration of QRS complexes. In Computers in Cardiology,\npages 737–740, 2003.\n\n44\n\n\f",
         "train",
         "116539",
         "20082"
        ],
        [
         "6",
         "19203",
         "cs.AI",
         "Artificial Intelligence",
         "1706.04052v1.pdf",
         "Beyond Monte Carlo Tree Search: Playing Go with\nDeep Alternative Neural Network and Long-Term Evaluation\nJinzhuo Wang, Wenmin Wang, Ronggang Wang, Wen Gao†\nSchool of Electronics and Computer Engineering, Peking University\nSchool of Electronics Engineering and Computer Science, Peking University\njzwang@pku.edu.cn, wangwm@ece.pku.edu.cn, rgwang@ece.pku.edu.cn, wgao@pku.edu.cn\n\narXiv:1706.04052v1 [cs.AI] 13 Jun 2017\n\n†\n\nAbstract\nMonte Carlo tree search (MCTS) is extremely popular in\ncomputer Go which determines each action by enormous simulations in a broad and deep search tree. However, human\nexperts select most actions by pattern analysis and careful\nevaluation rather than brute search of millions of future interactions. In this paper, we propose a computer Go system\nthat follows experts way of thinking and playing. Our system\nconsists of two parts. The first part is a novel deep alternative neural network (DANN) used to generate candidates of\nnext move. Compared with existing deep convolutional neural network (DCNN), DANN inserts recurrent layer after each\nconvolutional layer and stacks them in an alternative manner.\nWe show such setting can preserve more contexts of local features and its evolutions which are beneficial for move prediction. The second part is a long-term evaluation (LTE) module\nused to provide a reliable evaluation of candidates rather than\na single probability from move predictor. This is consistent\nwith human experts nature of playing since they can foresee\ntens of steps to give an accurate estimation of candidates. In\nour system, for each candidate, LTE calculates a cumulative\nreward after several future interactions when local variations\nare settled. Combining criteria from the two parts, our system\ndetermines the optimal choice of next move. For more comprehensive experiments, we introduce a new professional Go\ndataset (PGD), consisting of 253, 233 professional records.\nExperiments on GoGoD and PGD datasets show the DANN\ncan substantially improve performance of move prediction\nover pure DCNN. When combining LTE, our system outperforms most relevant approaches and open engines based on\nMCTS.\n\nIntroduction\nGo is a game of profound complexity and draws a lot attention. Although its rules are very simple (Müller 2002), it\nis difficult to construct a suitable value function of actions\nin most of situations mainly due to its high branching factors and subtle board situations that are sensitive to small\nchanges.\nPrevious solutions focus on simulating future possible interactions to evaluate candidates. In such methods, Monte\nCarlo tree search (MCTS) (Gelly and Silver 2011) is the\nmost popular one, which constructs a broad and deep search\nCopyright c 2017, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\n\ntree to simulate and evaluate each action. However, the playing strength of MCTS-based Go programs is still far from\nhuman-level due to its major limitation of uneven performance. Well known weaknesses include capturing race or\nsemeai, positions with multiple cumulative evaluation errors, ko fights, and close endgames (Rimmel et al. 2010;\nHuang and Müller 2013). We attribute it to the following reasons. First, the effectivity of truncating search tree is based\non prior knowledge and far away from perfect play (Müller\n2002). Second, when the board is spacious especially at\nopening, simulation is expensive and useless. Besides, the\noutputs of leaves in Monte Carlo tree are difficult to be precisely evaluated (Browne et al. 2012). Last but most important, MCTS does not follow professionals’ way of playing\nsince professionals hardly make brute simulation of every\npossible future positions. Instead, in most situations, they\nfirst obtain some candidates using pattern analysis and determine the optimal one by evaluating these candidates.\nRecently as deep learning revolutionizes and gradually\ndominate many tasks in computer vision community, researcher start to borrow deep learning techniques for move\nprediction and develop computer Go systems (Clark and\nStorkey 2015; Maddison et al. 2015; Tian and Zhu 2016;\nSilver et al. 2016). However, compared with visual signals\n(e.g. 224 × 224 in image domain), Go board has a much\nsmaller size (19 × 19), which poses the importance of relative position. This is consistent with playing Go as situation\ncan dramatically alter with a minor change in position. On\nthe other hand, existing DCNNs often mine such contexts\nby stacking more convolutional layers (e.g. up to 13 layers\nin (Silver et al. 2016)) to exploit high-order encodings of\nlow-level features. Simply increasing layers not only suffers\nparameter burden but also does not embed contexts of local\nfeatures and its evolutions.\nBased on the above discussions, this paper introduces a\ncomputer Go system consisting of two major parts. The first\npart is a novel deep architecture used to provide a probability distribution of legal candidates learned from professionals’ records. These candidates are further sent to a long-term\nevaluation part by considering local future impact instead of\nimmediate reward. We expect the model focus on several\nsuggested important regions rather than blind simulation of\nevery corner in the board. The primary contributions of this\nwork are summarized as follows.\n\n\f• We propose a novel deep alternative neural network\n(DANN) to learn a pattern recognizer for move prediction.\nThe proposed DANN enjoys the advantages of both CNN\nand recurrent neural network (RNN), preserving contexts\nof local features and its evolutions which we show are\nessential for playing Go. Compared with existing DCNNbased models, DANN can substantially improve the move\nprediction performance using less layers and parameters.\n\n• We introduce a new professional Go dataset (PGD) for\ncomprehensive evaluation. PGD consists of 329.4k modern professional records and considered useful for computer Go community. Thorough experiments on GoGoD\nand PGD demonstrates the advantages of our system over\nDCNNs and MCTS on both move prediction and win rate\nagainst open source engines.\n\nnition have demonstrated considerable advantages of DCNNs (Krizhevsky, Sutskever, and Hinton 2012; Simonyan\nand Zisserman 2014; Szegedy et al. 2015) and showed substantial improvement over shallow networks based on manually designed features or simple patterns extracted from\nprevious games (Silver 2009). DCNNs have yielded several\nstate-of-the-art Go playing system (Clark and Storkey 2015;\nMaddison et al. 2015; Tian and Zhu 2016; Silver et al. 2016)\nwith 8, 12 and 13 convolutional layers. Besides, these works\nhave also indicated combining DCNNs and MCTS can improve the overall playing strength. Similar conclusions are\nvalidated in state-of-the-art Go programs (Enzenberger et\nal. 2010; Baudiš and Gailly 2011). The major difference between this paper and existing combinations comes from two\nperspectives. The first one is that we use a novel architecture\nDANN to generate candidates with more consideration of\nlocal contexts and its evolutions. The proposed architecture\nshows substantial improvement with pure DCNN with fewer\nlayers and parameters. The second is that we use a long-term\nevaluation to analyze previous candidates instead of MCTS\nto assist the final choice. This strategy is faster than MCTS\nbecause the former needs to consider a large search space.\n\nRelated Work\n\nThe Proposed Computer Go System\n\nMonte Carlo tree search (MCTS). It is a best-first search\nmethod based on randomized explorations of search space,\nwhich does not require a positional evaluation function\n(Browne et al. 2012). Using the results of previous explorations, the algorithm gradually grows a game tree, and successively becomes better at accurately estimating the values of the optimal moves (Bouzy and Helmstetter 2004)\n(Coulom 2006). Such programs have led to strong amateur level performance, but a considerable gap still remains\nbetween top professionals and the strongest computer programs. The majority of recent progress is due to increased\nquantity and quality of prior knowledge, which is used to\nbias the search towards more promising states, and it is\nwidely believed that this knowledge is the major bottleneck\ntowards further progress. The first successful current Go\nprogram (Kocsis and Szepesvári 2006) was based on MCTS.\nTheir basic algorithm was augmented in MoGo (Gelly and\nSilver 2007) to leverage prior knowledge to bootstrap value\nestimates in the search tree. Training with professionals’\nmoves was enhanced in Fuego (Enzenberger et al. 2010) and\nPachi (Baudiš and Gailly 2011) and achieved strong amateur\nlevel.\nSupervised pattern-matching policy learning. Go professionals rely heavily on pattern analysis rather than brute\nsimulation in most cases (Clark and Storkey 2015; Xiao and\nMüller 2016). They can gain strong intuitions about what are\nthe best moves to consider at a glance. This is in contrast to\nMCTS which simulates enormous possible future positions.\nThe prediction functions are expected to be non-smooth\nand highly complex, since it is fair to assume professionals\nthink in complex, non-linear ways when they choose moves.\nTo this end, neural networks especially CNNs are widely\nused (Schraudolph, Dayan, and Sejnowski 1994; Enzenberger 1996; Richards, Moriarty, and Miikkulainen 1998;\nSutskever and Nair 2008). Recent works in image recog-\n\nThe proposed system is illustrated in Figure 1). Given a\nsituation, we first obtain a probability distribution of legal\npoints that are learned from a pattern-aware prediction instrument based on supervised policy learning from existing\nprofessional records. We then further analyze those candidates with high-confidence by a long-term evaluation to pursue a expectation reward after several future steps when the\nlocal situation is settled. The action with the highest score of\ncriteria combination of two criteria is our final choice.\n\n• To further enhance the candidates generated from DANN,\nwe present a novel recurrent model to make a long-term\nevaluation around each candidate for the final choice. We\nformulate the process as a partially observe Markov decision process (POMDP) problem and propose a reinforcement learning solution with careful control of variance.\n\nDeep Alternative Neural Network\nWe train a novel deep alternative neural network (DANN)\nto generate a probability distribution of legal points given\ncurrent board situation as an input. We treat the 19×19 board\nas a 19 × 19 image with multiple channels. Each channel\nencodes a different aspect of board information (see details\nin Table 1). In the following we describe the structure of\nDANN including its key component (alternative layer) and\noverall architecture. Afterwards we discuss its relations and\nadvantages over popular DCNNs.\nAlternative layer. The key component of DANN is the\nalternative layer (AL), which consists of a standard convolutional layer followed by a designed recurrent layer. Specifically, convolution operation is first performed to extract features from local neighborhoods on feature maps in the previous layers. Then a recurrent layer is applied to the output and\niteratively proceeds for T times. This procedure makes each\nunit evolve over discrete time steps and aggregate larger receptive fields (RFs). More formally, the input of a unit at\nposition (x, y, z) in the jth feature map of the ith AL at time\nt, denoted as uxyz\nij (t), is given by\nxyz\nr xyz\nuxyz\nij (t) = uij (0) + f (wij uij (t − 1)) + bij\nxyz\nc\nuxyz\nij (0) = f (w(i−1)j u(i−1)j )\n\n(1)\n\n\fFigure 1: The proposed computer Go system with deep alternative neural network (DANN) and long-term evaluation. Given\na situation the system generate several candidates by DANN that are learned from professional records. These candidates are\nfurther analyzed using a long-term evaluation with consideration of future rewards to determine a final action.\nconnections, while the shortest path goes through the feedforward connection only. The effective RF of an AL unit in\nthe feature maps of the previous layer expands when the iteration number increases. If both input and recurrent kernels\nin equation have square shapes in each feature map of size\nLfeed and Lrec , then the effective RF of an AL unit is also\nsquare, whose side length is Lfeed + Lrec × (T + 1).\n\nFigure 2: Comparison of DANN (right) and DCNN (left).\nwhere uxyz\nij (0) denotes the feed-forward output of convolutional layer, uxyz\nij (t − 1) is the recurrent input of previous\ntime, wkc and wkr are the vectorized feed-forward kernels\nand recurrent kernels, bij is the bias for jth feature map in\nith layer, uxyz\nij (0) is the output of convolutional output of\nr xyz\nprevious layer and f (wij\nuij (t − 1))) is induced by the recurrent connections. f is defined as popular rectified linear\nunit (ReLU) function f (x) = max(0, x), followed by a local response normalization (LRN)\nuxyz\nij\n\nLRN(uxyz\nij ) =\n(1 +\n\nα\nL\n\nPmin(K,k+L/2)\n\nk0 =max(0,k−L/2)\n\n2 β\n\n(uxyz\nij ) )\n\n(2)\n\nwhere K is the number of feature maps, α and β are constants controlling the amplitude of normalization. The LRN\nforces the units in the same location to compete for high activities, which mimics the lateral inhibition in the cortex. In\nour experiments, LRN is found to consistently improve the\naccuracy, though slightly. Following (Krizhevsky, Sutskever,\nand Hinton 2012), α and β are set to 0.001 and 0.75, respectively. L is set to K/8 + 1.\nEquation 1 describes the dynamic behavior of AL where\ncontexts are involved after local features are extracted. Unfolding this layer for T time steps results in a feed-forward\nsubnetwork of depth T + 1 as shown in the right of Figure 2. While the recurrent input evolves over iterations, the\nfeed-forward input remains the same in all iterations. When\nT = 0 only the feed-forward input is present. The subnetwork has several paths from the input layer to the output\nlayer. The longest path goes through all unfolded recurrent\n\nAdvantages over DCNNs. The recurrent connections in\nDANN provide three major advantages compared with popular DCNNs used for move prediction (Clark and Storkey\n2015; Maddison et al. 2015; Tian and Zhu 2016; Silver et\nal. 2016). First, they enable every unit to incorporate contexts in an arbitrarily large region in the current layer, which\nis particular suitable in the game of Go as the input signal\nis very small where the contexts are essential. As the time\nsteps increase, the state of every unit is influenced by other\nunits in a larger and larger neighborhood in the current layer.\nIn consequence, the size of regions that each unit can watch\nin the input space also increases. In standard convolutional\nlayers, the size of effective RFs of the units in the current\nlayer is fixed, and watching a larger region is only possible\nfor units in higher layers. But unfortunately the context seen\nby higher-level units cannot influence the states of the units\nin the current layer without top-down connections. Second,\nthe recurrent connections increase the network depth while\nkeeping the number of adjustable parameters constant by\nweight sharing. Specially, stacking higher layers consume\nmore parameters while AL uses only additional constant parameters compared to standard convolutional layer. This is\nconsistent with the trend of modern deep architectures, i.e.,\ngoing deeper with relatively small number of parameters (Simonyan and Zisserman 2014; Szegedy et al. 2015). Note\nthat simply increasing the depth of CNN by sharing weights\nbetween layers can result in the same depth and the same\nnumber parameters as DANN. We have tried such a model\nwhich leads to a lower performance. The third advantage is\nthe time-unfolded manner in Figure 2, which is actually a\nCNN with multiple paths between the input layer to the output layer to facilitate the learning procedure. On one hand,\nthe existence of longer paths makes it possible for the model\nto learn highly complex features. On the other hand, the existence of shorter paths may help gradient of backpropagation\nduring training. Multi-path is also used in (Lee et al. 2015;\nSzegedy et al. 2015), but extra objective functions are used\n\n\fin hidden layers to alleviate the difficulty in training deep\nnetworks, which are not used in DANN.\nOverall architecture. The overall architecture of our\nDANN has 6 ALs with 64, 128, 256, 256, 512 and 512 kernels, followed by 2 fully connected (FC) layers of size 1024\neach. We use 3 × 3 kernel for convolutional layer and recurrent layers of all 6 ALs. After each AL, the network includes\na ReLU activation. We use max pooling kernels of 2 × 2\nsize. All of these convolutional layers and recurrent layers\nare applied with appropriate padding and stride. FC layers\nare followed by a ReLU and a softmax, which outputs the\nprobabilities of Go board and illegal points are set 0.\n\nLong-Term Evaluation of Candidates\nDANN provides a probability distribution of next move\ncandidates give a situation. We further enhance this model\nby evaluating these candidates in a long-term consideration since predicting only the immediate next move limits the information received by lower layers (Tian and Zhu\n2016). Besides, many situations in intensive battle or capture chase is far beyond fair evaluation and need to be accurately judged when local variation is settled. We aim to\navoiding shortsighted moves. There are some works such as\n(Littman 1994) that consider playing games as a sequential\ndecision process of a goal-directed agent interacting with visual environment. We extend this idea to evaluate candidates\nin a similar manner. We calculate the cumulative rewards of\neach candidate with several future interactions. Combining\nprevious probabilities criterion, we obtain a final score and\ndetermine the optimal action.\nRecurrent model and internal state. Figure 3 shows our\nmodel structure, which is build a agent around a RNN. To\navoiding blind search space like MCTS, the agent observes\nthe environment only via a bandwidth-limited sensor, i.e. it\nnever senses the full board. It may extract information only\nin a local region around candidates. The goal of our model is\nto provide a reliable evaluation of each candidate and assist\nthe final choice. The agent maintains an internal state which\nsummarizes information extracted from past observations. It\nencodes the agent’s knowledge of the environment and is\ninstrumental to deciding how to act and where to deploy the\nnext action. This internal state is formed by the hidden units\nht of the recurrent neural network and updated over time by\nthe core network ht = fh (ht−1 , lt−1 ; θh ).\nAction and reward. At each step, the agent performs\ntwo actions. It decides how to deploy its sensor via the\nsensor control lt , and an action at which might affect the\nstate of the environment. The location are chosen stochastically from a distribution parameterized by the location network lt ∼ p(·|fl (ht ; θl ). The action is similarly drawn from\na distribution conditioned on a second network output at\nat ∼ p(·|fa (ht ; θa ). Finally, our model can also be augmented with an additional action that decides when it will\nstop when local fights are settled. After executing an action\nthe agent receives a new visual observation and a reward\nsignal r. The goal of the agent is to maximize the sum of\nPT\nthe reward signal R = t=1 rt . The above setup is a special instance of partially observable Markov decision pro-\n\nFigure 3: A recurrent model for long-term evaluation.\ncess (POMDP), where the true state of whole board is unobserved.\nTraining. The policy of the agent, possibly in combination with the dynamics of interactions, induces a distribution\nover possible interaction sequences and we aim to maximize\nthe reward under the distribution of\nJ (θ) = Ep(s1:T ;θ) [\n\nT\nX\n\nrt ] = Ep(s1:T ;θ) [R]\n\n(3)\n\nt=1\n\nMaximizing J exactly is difficult because it involves an\nexpectation over interaction sequences which may in turn\ninvolve unknown environment dynamics. Viewing the problem as a POMDP problem, however, allows us to bring techniques from the RL literature to bear. As shown in (Williams\n1992) a sample approximation to the gradient is given by\n∇θ J =\n\nT\nX\n\nEp (s1:T ; θ)[∇θ log π(ut |s1:t ; θ)R]\n\nt=1\nM T\n1 XX\n∇θ log π(uit |si1:t ; θ)Ri\n≈\nM i=1 t=1\n\n(4)\n\nwhere si, s are the interaction sequences obtained by running\nthe current agent πθ for i = 1 · · · M episodes. The learning rule of Equation 4 is also known as the REINFORCE\nrule, and it involves running the agent with its current policy to obtain samples of interaction sequences s1:T and then\nadjusting the parameters θ such that the log-probability of\nchosen actions that have led to high cumulative reward is increased, while that of actions having produced low reward is\ndecreased. ∇θ log π(uit |si1:t ; θ) in Equation 4 is just the gradient of the RNN and can be computed by standard backpropagation (Wierstra et al. 2007).\nVariance reduction. Equation 4 provides us with an unbiased estimate of the gradient but it may have high variance.\nIt is common to consider a gradient estimate of the form\nM T\n1 XX\n∇θ log π(uit |si1:t ; θ)(Rit − bt )\nM i=1 t=1\n\n(5)\n\n\fTable 1: Input feature channels for DANN.\nFeature\n\n# Description\n\nLadder capture\nLadder escape\nSensibleness\nLegality\nPlayer color\nZeros\nStone color\nLiberties\nLiberties∗\nTurn since\nCapture size\nSelf-atari size\n\n1\n1\n1\n1\n1\n1\n3\n4\n6\n6\n8\n8\n\nWhether point is a successful ladder capture\nWhether point is a successful ladder escape\nWhether point is legal and does not fill eyes\nWhether point is legal for current player\nWhether current player is black\nA constant plane filled with 0\nPlayer stone/opponent stone/empty\nNumber of liberties (empty adjacent points)\nNumber of liberties (after this move)\nNumber of liberties (after this move)\nHow many opponent stones would be captured\nHow many own stones would be captured\n\nPT\nwhere Rit = t0 =1 rti0 is the cumulative reward following\nthe execution of action uit , and bt is a baseline that depends\non si1:t but not on the action uit itself. This estimate is equal\nto Equation 4 in expectation but may have lower variance.\nWe select the value function of baseline following (Sutton et\nal. 1999) in the form of bt = Eπ [Rt ]. We use this type of\nbaseline and learn it by reducing the squared error between\nRi,\nt and bt .\nFinal score. We define the final score for each candidate\nusing the criteria of both DANN and long-term evaluation.\nWe select the action of the highest score of S = p × E[R]\nas the final choice of our system, where p is the probability\nproduced by the softmax layer of DANN.\n\nExperiments\nSetup\nDatasets. The first dataset we used is GoGoD (2015 winter version). The dataset consists of 82, 609 historical and\nmodern games. We limited our experiments to a subset\nof games that satisfied the following criteria: 19 × 19\nboard, modern (played after 1950), “standard” komi (komi\n∈ {5.5, 6.5, 7.5}), and no handicap stones. We did not distinguish between rulesets (most games followed Chinese\nor Japanese rules). Our criteria produced a training set of\naround 70, 000 games. We did not use popular KGS dataset\nbecause it consists of more games by lower dan players. The\naverage level is approximately 5 dan.\nBesides, we have collected a new professional Go\ndataset (PGD) consisting of 253, 233 professional records,\nwhich exceeds GoGoD and KGS in both quantity and\nplaying strength. PGD was parsed from non-profit web\nsites. All records are saved as widely used smart go file\n(SGF), named as DT EV PW WR PB BR RE.sgf, where\nDT,EV,PW,WR,PB,BR and RE represent date, tournament\ntype, black player name, black playing strength, white player\nname, white playing strength and result.\nFeature channels. The features that we used come directly from the raw representation of the game rules (stones,\nliberties, captures, legality, turns since) as in Table 1. Many\nof the features are split into multiple planes of binary values,\nfor example in the case of liberties there are separate binary\n\nfeatures representing whether each intersection has 1 liberty,\n2 liberties, 3 liberties, >= 4 liberties.\nImplementation details. The major implementations of\nDANN including convolutional layers, recurrent layers and\noptimizations are derived from Torch7 toolbox (Collobert,\nKavukcuoglu, and Farabet 2011). We use SGD applied to\nmini-batches with negative log likelihood criterion. The size\nof mini-batch is set 200. Training is performed by minimizing the cross-entropy loss function using the backpropagation through time (BPTT) algorithm (Werbos 1990). This is\nequivalent to using the standard BP algorithm on the timeunfolded network. The final gradient of a shared weight is\nthe sum of its gradients over all time steps. The initial learning rate for networks learned from scratch is 3 × 10−3 and it\nis 3×10−4 for networks fine-tuned from pre-trained models.\nThe momentum is set to 0.9 and weight decay is initialized\nwith 5 × 10−3 and reduced by 10−1 factor at every decrease\nof the learning rate.\n\nMove Prediction\nWe first evaluate different configurations of DANN. Then\nwe compare our best DANN model with DCNN-based\nmethods. Finally, we study the impact of long-term evaluation and report the overall performance on move prediction.\nModel investigation of DANN. There are two crucial\nconfigurations for DANN model. The first one is the AL setting including its order and number. The other one is the unfolding time T in recurrent layers. Comparison details are\nreported in Table 2, where B 6C 2FC is a baseline composed of similar configuration with DANN but using standard convolutional layers instead of ALs. The first column\nof left table in Table 2 has only one AL layer and the accuracy comparison demonstrates the benefits of inserting AL\nin advance. We attribute it to the context mining of lower\nfeatures. The fourth column of left table in Table 2 shows\nthe performance increases as the number of AL increases,\nwhich verifies the effectiveness of inserting recurrent layer.\nSpecifically, the order of AL can contribute a performance\ngain up to 11% which indicates that mining contexts of\nlower layer is beneficial for playing Go. Right table in Table 2 uses 5AL 2FC and 6AL 2FC to study the impact of T\nand the results prove larger T leads to better performance in\nmost cases. Given such results we use our best DANN model\n6AL 2FC in the following experiments.\nComparison with DCNN-based methods. Figure 4 reports the performance comparison of our best DANN model\nand related approaches using pure DCNN. Following (Maddison et al. 2015) we evaluate the accuracy that the correct move is within the networks n most confident predictions. As Figure 4 shows, our model consistently outperform\ntwo recent approaches (Maddison et al. 2015; Tian and Zhu\n2016) using pure DCNN on two datasets. Also, note that our\narchitecture consume less layers where the parameters are\nalso saved .\nCombining long-term evaluation. Next we examine the\ninfluence of our long-term evaluation (LTE). We focus\nmainly on the future step that is used to achieve the expectation of reward, and the episode number when solving\nEquation 4. We combine our best DANN model with LTE\n\n\fTable 2: Performance comparison (top-1) with different configurations of DANN on GoGoD and PGD datasets.\nArchitecture\nGoGoD\nB 6C 2FC\n32.2%\nAL 5C 2FC\n40.5%\nC AL 4C 2FC\n41.1%\n2C AL 3C 2FC 45.6%\n3C AL 2C 2FC 47.4%\n4C AL C 2FC\n49.4%\n5C AL 2FC\n51.9%\n\nPGD\n37.2%\n42.5%\n41.1%\n44.8%\n43.0%\n46.6%\n49.3%\n\nArchitecture GoGoD\n2AL 4C 2FC 35.0%\n3AL 3C 2FC 42.7%\n4AL 2C 2FC 47.4%\n5AL C 2FC\n47.2%\n6AL 2FC\n53.5%\n\nPGD\n39.3%\n43.1%\n42.2%\n46.4%\n51.8%\n\nArchitecture\n5AL 2FC, T\n5AL 2FC, T\n5AL 2FC, T\n5AL 2FC, T\n6AL 2FC, T\n6AL 2FC, T\n6AL 2FC, T\n6AL 2FC, T\n\n=2\n=3\n=4\n=5\n=2\n=3\n=4\n=5\n\nGoGoD\n46.9%\n48.2%\n52.3%\n55.0%\n46.4%\n51.1%\n55.3%\n57.7%\n\nPGD\n42.3%\n47.1%\n45.8%\n51.6%\n47.2%\n51.6%\n49.4%\n53.8%\n\nTable 3: Win rate comparison against open source engines between our system and previous work.\n\n8-layer-DCNN + MCTS (Clark and Storkey 2015)\n12-layer-DCNN + MCTS (Maddison et al. 2015)\n12-layer-DCNN + MCTS (Tian and Zhu 2016)\n6-layer-DANN + LTE (Ours)\n\nGnuGo\n91.0%\n97.2%\n100±0.0%\n100±0.0%\n\nFigure 4: Top-n comparison of our best DANN model and\nDCNN-based methods on GoGoD and PGD datasets.\n\non Top-1 move prediction accuracy. Table 5 demonstrates\nthe details. As can be seen, the best performance is achieved\naround 15 to 21 steps. As for the episode, LTE often converges after around 200 episodes. Using the optimal setting\nof both part, the overall top-1 accuracy can be obtained at\n61% and 56% on GoGod and PGD datasets, respectively.\n\nFigure 5: Impact of future steps and episode number in longterm evaluation on GoGoD and PGD datasets.\n\nPlaying Strength\nFinally, we evaluate the overall playing strength of our system by playing against several publicly available benchmark\nprograms. All programs were played at the strongest available settings, and a fixed number of rollouts per move. We\n\nMoGo 10k\n45.9%\n72.5±1.8%\n\nPachi 10k\n47.4%\n94.3±1.7%\n83.1±1.4%\n\nPachi 100k\n11.0%\n72.69±1.9%\n65.3±1.6%\n\nFuego 10k\n14.0%\n23.3%\n93.2±1.5%\n82.6±1.2%\n\nFuego 100k\n14.0%\n12.5%\n89.7±2.1%\n76.5±1.6%\n\nused GnuGo 3.8 level 10, MoGo (Gelly and Silver 2007),\nPachi 11.99 (Genjo-devel) with the pattern files, and Fuego\n1.1 throughout our experiments. For each setting, 3 groups\nof 100 games were played. We report the average win rate\nand standard deviation computed from group averages. All\nthe game experiments mentioned in this paper used komi 7.5\nand Chinese rules. Pondering (keep searching when the opponent is thinking) in Pachi and Fuego are on. As Table 3\nshows, our system outperform most MCTS-based Go programs. Also, the win rate of our approach is higher than that\nof previous works except (Tian and Zhu 2016).\n\nConclusion\nIn this work, we have proposed a computer Go system\nbased on a novel deep alternative neural networks (DANN)\nand long-term evaluation (LTE). We also public a new\ndataset consisting of around 25k professional records. On\ntwo datasets, we showed that DANN can predict the next\nmove made by Go professionals with an accuracy that substantially exceeds previous deep convolutional neural network (DCNN) methods. LTE strategy can further enhance\nthe quality of candidates selection, by combining the influence of future interaction instead of immediate reward.\nWithout brute simulation of possible interaction in a large\nand deep search space, our system is able to outperform most\nMCTS-based open source Go programs.\nFuture work mainly includes the improvement of DANN\nstructure for move prediction and more reliable LTE implementation. Advance techniques in computer vision community such as residual networks may help DANN obtain further improvement. As for LTE, domain knowledge of Go\nwill be attempted to provide a more reliable estimation of\nnext move candidates.\n\nAcknowledgement\nThis work was supported by Shenzhen Peacock Plan\n(20130408-183003656).\n\n\fReferences\n[Baudiš and Gailly 2011] Baudiš, P., and Gailly, J.-l. 2011.\nPachi: State of the art open source go program. In Advances\nin Computer Games. 24–38.\n[Bouzy and Helmstetter 2004] Bouzy, B., and Helmstetter,\nB. 2004. Monte-carlo go developments. In Advances in\ncomputer games. 159–174.\n[Browne et al. 2012] Browne, C. B.; Powley, E.; Whitehouse, D.; Lucas, S. M.; Cowling, P. I.; Rohlfshagen, P.;\nTavener, S.; Perez, D.; Samothrakis, S.; and Colton, S. 2012.\nA survey of monte carlo tree search methods. Computational Intelligence and AI in Games, IEEE Transactions on\n4(1):1–43.\n[Clark and Storkey 2015] Clark, C., and Storkey, A. 2015.\nTraining deep convolutional neural networks to play go. In\nProceedings of the 32nd International Conference on Machine Learning, 1766–1774.\n[Collobert, Kavukcuoglu, and Farabet 2011] Collobert,\nR.; Kavukcuoglu, K.; and Farabet, C. 2011. Torch7: A\nmatlab-like environment for machine learning. In BigLearn,\nNIPS Workshop, number EPFL-CONF-192376.\n[Coulom 2006] Coulom, R. 2006. Efficient selectivity and\nbackup operators in monte-carlo tree search. In Computers\nand games. 72–83.\n[Enzenberger et al. 2010] Enzenberger, M.; Müller, M.; Arneson, B.; and Segal, R. 2010. Fuego- an open-source\nframework for board games and go engine based on monte\ncarlo tree search. Computational Intelligence and AI in\nGames, IEEE Transactions on 2(4):259–270.\n[Enzenberger 1996] Enzenberger, M. 1996. The integration of a priori knowledge into a go playing neural network.\nURL: http://www. markus-enzenberger. de/neurogo. html.\n[Gelly and Silver 2007] Gelly, S., and Silver, D. 2007. Combining online and offline knowledge in uct. In International\nConference on Machine Learning, 273–280. ACM.\n[Gelly and Silver 2011] Gelly, S., and Silver, D. 2011.\nMonte-carlo tree search and rapid action value estimation\nin computer go. Artificial Intelligence 175(11):1856–1875.\n[Huang and Müller 2013] Huang, S.-C., and Müller, M.\n2013. Investigating the limits of monte-carlo tree search\nmethods in computer go. In Computers and Games. 39–\n48.\n[Kocsis and Szepesvári 2006] Kocsis, L., and Szepesvári, C.\n2006. Bandit based monte-carlo planning. In European Conference Machine Learning. 282–293.\n[Krizhevsky, Sutskever, and Hinton 2012] Krizhevsky, A.;\nSutskever, I.; and Hinton, G. E. 2012. Imagenet classification with deep convolutional neural networks. In Advances\nin neural information processing systems, 1097–1105.\n[Lee et al. 2015] Lee, C.-Y.; Xie, S.; Gallagher, P.; Zhang,\nZ.; and Tu, Z. 2015. Deeply-supervised nets. In International Conference on Artificial Intelligence and Statistics,\nvolume 2, 6.\n[Littman 1994] Littman, M. L. 1994. Markov games as a\nframework for multi-agent reinforcement learning. In Pro-\n\nceedings of the eleventh international conference on machine learning, volume 157, 157–163.\n[Maddison et al. 2015] Maddison, C. J.; Huang, A.;\nSutskever, I.; and Silver, D. 2015. Move evaluation in go\nusing deep convolutional neural networks. In International\nConference on Learning Representation.\n[Müller 2002] Müller, M. 2002. Computer go. Artificial\nIntelligence 134(1):145–179.\n[Richards, Moriarty, and Miikkulainen 1998] Richards, N.;\nMoriarty, D. E.; and Miikkulainen, R. 1998. Evolving neural\nnetworks to play go. Applied Intelligence 8(1):85–96.\n[Rimmel et al. 2010] Rimmel, A.; Teytaud, O.; Lee, C.-S.;\nYen, S.-J.; Wang, M.-H.; and Tsai, S.-R. 2010. Current\nfrontiers in computer go. Computational Intelligence and\nAI in Games, IEEE Transactions on 2(4):229–238.\n[Schraudolph, Dayan, and Sejnowski 1994] Schraudolph,\nN. N.; Dayan, P.; and Sejnowski, T. J. 1994. Temporal\ndifference learning of position evaluation in the game of\ngo. In Advances in Neural Information Processing Systems,\n817–817.\n[Silver et al. 2016] Silver, D.; Huang, A.; Maddison, C. J.;\nGuez, A.; Sifre, L.; Van Den Driessche, G.; Schrittwieser,\nJ.; Antonoglou, I.; Panneershelvam, V.; Lanctot, M.; et al.\n2016. Mastering the game of go with deep neural networks\nand tree search. Nature 529(7587):484–489.\n[Silver 2009] Silver, D. 2009. Reinforcement learning and\nsimulation-based search. Doctor of philosophy, University\nof Alberta.\n[Simonyan and Zisserman 2014] Simonyan, K., and Zisserman, A. 2014. Very deep convolutional networks for largescale image recognition. arXiv preprint arXiv:1409.1556.\n[Sutskever and Nair 2008] Sutskever, I., and Nair, V. 2008.\nMimicking go experts with convolutional neural networks.\nIn International Conference on Artificial Neural Networks.\n101–110.\n[Sutton et al. 1999] Sutton, R. S.; McAllester, D. A.; Singh,\nS. P.; Mansour, Y.; et al. 1999. Policy gradient methods for reinforcement learning with function approximation.\nIn Advances in neural information processing systems, volume 99, 1057–1063.\n[Szegedy et al. 2015] Szegedy, C.; Liu, W.; Jia, Y.; Sermanet,\nP.; Reed, S.; Anguelov, D.; Erhan, D.; Vanhoucke, V.; and\nRabinovich, A. 2015. Going deeper with convolutions. In\nComputer Vision and Pattern Recognition, 1–9.\n[Tian and Zhu 2016] Tian, Y., and Zhu, Y. 2016. Better computer go player with neural network and long-term prediction. In International Conference on Learning Representation.\n[Werbos 1990] Werbos, P. J. 1990. Backpropagation through\ntime: what it does and how to do it. Proceedings of the IEEE\n78(10):1550–1560.\n[Wierstra et al. 2007] Wierstra, D.; Foerster, A.; Peters, J.;\nand Schmidhuber, J. 2007. Solving deep memory pomdps\nwith recurrent policy gradients. In International Conference\non Artificial Neural Networks, 697–706.\n\n\f[Williams 1992] Williams, R. J. 1992. Simple statistical\ngradient-following algorithms for connectionist reinforcement learning. Machine learning 8(3-4):229–256.\n[Xiao and Müller 2016] Xiao, C., and Müller, M. 2016. Factorization ranking model for move prediction in the game of\ngo. In AAAI Conference on Artificial Intelligence.\n\n\f",
         "train",
         "36742",
         "5863"
        ],
        [
         "7",
         "17577",
         "cs.AI",
         "Artificial Intelligence",
         "1803.09099v1.pdf",
         "1\n\narXiv:1803.09099v1 [cs.PL] 24 Mar 2018\n\nA Resourceful Reframing of Behavior Trees\nCHRIS MARTENS, North Carolina State University\nERIC BUTLER, University of Washington\nJOSEPH C. OSBORN, University of California, Santa Cruz\nDesigners of autonomous agents, whether in physical or virtual environments, need to express nondeterminisim, failure, and parallelism in behaviors, as well as accounting for synchronous coordination between\nagents. Behavior Trees are a semi-formalism deployed widely for this purpose in the games industry, but with\nchallenges to scalability, reasoning, and reuse of common sub-behaviors.\nWe present an alternative formulation of behavior trees through a language design perspective, giving a\nformal operational semantics, type system, and corresponding implementation. We express specifications\nfor atomic behaviors as linear logic formulas describing how they transform the environment, and our type\nsystem uses linear sequent calculus to derive a compositional type assignment to behavior tree expressions.\nThese types expose the conditions required for behaviors to succeed and allow abstraction over parameters to\nbehaviors, enabling the development of behavior “building blocks” amenable to compositional reasoning and\nreuse.\nAdditional Key Words and Phrases: linear logic, behavior trees, programming languages, type systems\nACM Reference format:\nChris Martens, Eric Butler, and Joseph C. Osborn. 2016. A Resourceful Reframing of Behavior Trees. 1, 1,\nArticle 1 (January 2016), 17 pages.\nDOI: 10.1145/nnnnnnn.nnnnnnn\n\n1\n\nINTRODUCTION\n\nSpecifying the desired behaviors of agents in environments is a major theme in artificial intelligence.\nAnalysts often need to define particular policies with explicit steps, but the agents must also\nacknowledge salient changes in a potentially hostile or stochastic environment. This challenge\narises in applications including robotics, simulation, and video game development. Games in\nparticular bring challenges related to interaction with human decision-makers: even for games\nnotionally working against the objectives of the player, the activity of game design is centrally\nconcerned with helping the player learn something or have an emotional experience, and in this\nsense can be thought of as a cooperative system between agents with different knowledge states,\nnot unlike human-robot teams. The behaviors of non-player characters (NPCs) in games must be\ndesigned in support of this goal.\nGame designers must be able to specify that a given agent should patrol a hallway until it gets\nhungry (or its battery runs low) and goes home for a snack (or to recharge); but if the agent sees a\none-hundred dollar bill on the ground on the way to where it recuperates, it should force a detour.\nIn some designs, we would want an adversary (e.g., the player) to be able to trick the agent into\nrunning out of fuel by this mechanism; in other designs we would hope the agent ignores optional\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee\nprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and\nthe full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.\nAbstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires\nprior specific permission and/or a fee. Request permissions from permissions@acm.org.\n© 2016 ACM. XXXX-XXXX/2016/1-ART1 $15.00\nDOI: 10.1145/nnnnnnn.nnnnnnn\n\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\n\f1:2\n\nChris Martens, Eric Butler, and Joseph C. Osborn\n\nbut attractive diversions and prioritizes severe need. We can easily imagine two distinct agents\nwithin the same game which are differentiated only by whether they can be misled in such a way.\nGame character AI designers have somewhat contradictory goals that distinguish their project\nfrom, for example, game-playing AI whose objective is optimal play. On the one hand they want\nbelievable characters who react reasonably to player actions and to the behaviors of other nonplayer characters; but on the other hand they want to craft certain very specific experiences that\nnudge the player into trying new actions or approaching problems from a specific direction or that\nprevent the agent from performing awkward-looking sequences of 3D animations. Traditionally,\ngame character AI was implemented with explicit state machines built by hand; more recently\nbehavior trees, goal-oriented action planning, and utility-based systems have come into vogue.\n\nFig. 1. A example behavior tree for a noise-investigation behavior. The tree is evaluated in preorder traversal.\nLeaf nodes specify actions in the world (such as moving to a target), which can succeed or fail. Interior nodes\ncombine children into composite behaviors. The arrow (→) is sequencing (run each child until first failure),\nand the question (?) is selection (run each child until first success).\n\nBehavior trees are a scripting system for agents in virtual worlds, allowing designers of virtual\nagents to visually construct behavioral flowcharts based on conditions on the world around them.\nThey are widely employed in the video games industry [16] for describing the “artificial intelligence”\nbehavior of non-player characters, such as enemy units in combat simulators and members of\nvirtual populations in open world-style games. Behavior trees have also been used for robot\ncontrol [12]. They are often described as merging the utility of decision trees and state machines,\nallowing repeated or cyclic behaviors that modify and check state (internal or shared) as they\nexecute. Figure 1 shows an example behavior tree for a hypothetical security guard character. The\ntree defines how to sequence and prioritize basic behaviors of listening for noises, investigating the\nsource of the noise, or doing idle activities. During game simulation, behavior trees are typically\nre-executed with some frequency depending on the game, as often as once or more per time step.\nThe example in Figure 1, for instance, needs to be executed twice to both acquire a target and\ninvestigate it.\nSince behavior trees are often deployed in multi-agent simulations and with complex statechanging behavior, the ability for a designer to reason about the correctness of the tree quickly\nsuccumbs to its size and branching factor. Even for straightforward sequences of behaviors, the\npreconditions and postconditions are left unstated. For example, if an agent is told to move to door,\nopen door, and go through door, we might reasonably expect that in all circumstances where\nthe door is accessible, the agent will be on the opposite side of it by the time its behavior finishes.\nHowever, this is not possible to conclude unless we reason both about the conditions and effects of\nthe individual actions and how the effects of earlier actions are expected to connect to the conditions\nof later ones. Such a sequence of actions could fail, for instance, if the player were to intervene and\nclose the door immediately after the agent opened it. Furthermore, the success of behaviors may\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\n\fA Resourceful Reframing of Behavior Trees\n\n1:3\n\ndepend on external conditions on the environment: an agent may expect another agent to have\nplaced an important item that it needs, and the behavior is only correct on the condition that this\ndependency has been satisfied.\nWe describe an approach to reasoning compositionally about behavior trees in such a way that\nthey may be constructed in small units, typechecked against an expected behavioral schema, and\ncombined to form behaviors with new, compositionally-defined types. The approach requires the\nauthor to provide a linear logical specification of the atomic actions, i.e. the leaves of the tree; types\nfor complex expressions formed from these leaves are derived from a linear logical interpretation\nof the behavior tree operations (sequencing, selection, and conditions). The present work can be\nseen as a way to regain some of the guarantees given by reasoning about a behavior from start\nto finish without losing the reactivity, which is the main benefit of using behavior trees over, for\nexample, static plan generation [7].\nSince behavior trees are a relatively simple formalism repeatedly realized in different incarnations,\nand since game developers are under somewhat notorious pressure to ship products, there is no\nauthoritative, standard version of behavior trees. As alluded to above, a recurring issue with\nbehavior trees is resolving the apparent tension between reacting to unexpected changes in the\nenvironment on the one hand and to performing authored behaviors over a longer duration on\nthe other hand. The ad hoc extensions applied to behavior trees in the wild are often intended to\nresolve this tension. The approaches described in this paper could give a theoretical foundation\nfor addressing these “hacks” employed in practice—and, potentially, for more principled and\nbetter-behaved adaptations of behavior trees towards the problem of designing complex agent and\ncharacter behaviors.\nOur contributions are a formal specification and operational semantics for our formulation of\nbehavior trees, a type system and synthesis algorithm backed by an interpretation in linear logic,\nand an implementation of these systems in Standard ML. These results represent the first step of\ntoward building a toolkit for robust authoring of virtual agent behaviors, combining support for\ncorrect human authorship and certified goal-driven synthesis of behaviors.\nThe rest of the paper is organized as follows: Section 2 discusses related work; Section 3 describes further how behavior trees are used in the games industry, Section 4 explains linear logical\nspecifications and how they may be used to describe a possibility space for virtual worlds; Section 5\ndescribes the syntax and operational semantics of our behavior tree language; Section 6 describes\nthe type system and its guarantees; Section 7 describes our implementation; Section 8 discusses\nour current scope and future work; and 9 summarizes our contributions.\n2\n\nRELATED WORK\n\nFor the most part, efforts to provide robust formalisms to designers of virtual agents have been\ndisjoint from formal and language-based approaches. We identify related work in two key areas:\nprevious attempts to characterize virtual agent behaviors from a formal methods standpoint, and\nrelated models of computation that have been characterized with linear logic.\n2.1\n\nFormal accounts of behavior trees\n\nMarzinotto et al. provide an account [12] of behavior trees in the context of robot control, citing a dearth of mathematical rigor prior to their contribution. Their work contributes the first\nmathematical definition of behavior trees and accounts for their expressive capabilities.\nMore recently, there has been some very recent work in applying synthesis and verification to AI\nbehavior trees [4]. The formal basis for said work is model checking in linear temporal logic (LTL).\nOur work, by contrast, seeks a type-theoretic solution that supports modular reuse of behaviors.\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\n\f1:4\n2.2\n\nChris Martens, Eric Butler, and Joseph C. Osborn\nLinear logical accounts of agents and processes\n\nLinear Session Types [2] are an important touchstone for this work as another characterization\nof a pre-existing system, π -calculus, under a semantics derived from linear sequent calculus. Our\nwork does not identify a direct logical correspondence between logical and operational notions in\nthe same way, but similarly provides a basis for static reasoning about complex behaviors.\nThe CLF [18] logical framework and corresponding implementation Celf [17] form a basis for\ninterpreting linear logic formulas as programs under a proof-construction-as-execution paradigm\n(logic programming). While operationally, this approach diverges from the semantics of behavior\ntrees, the representation formalism informs out approach.\nFinally, linear logic has been used to account for planning in a number of interesting ways:\ndeductive planning [5] runs with the observation that, in addition to Masseron et al.’s observation\nthat linear proof search can model planning [13], linear proofs generalize plans: they can characterize\nrecursive and contingent (branching) plans, recovering some of the same expressiveness as behavior\ntrees. Dixon et al. [6] apply deductive planning to an agent-based domain for dialogue-based\nenvironments. This work encourages us to consider integrating the generative abilities of planners\nwith the reactivity of behavior trees in future work.\n3\n\nBACKGROUND: BEHAVIOR TREES IN GAMES\n\nBehavior trees are widely used to define the behavior of non-player characters in digital game\ngenres ranging from strategy and simulation to first-person shooters. The major game-making\ntools (Unreal Engine, Unity 3D, CryEngine, Amazon Lumberyard, and others) all either provide\nnatively or have third-party implementations of the technique. The canonical examples of behavior\ntrees’ use in games come from the Halo series of first-person shooter games [9]. Notable in their\nformulation is that most of the tree is shared across the different types of enemy agents that appear\nin the game, which reflects the difficulty of authoring good and reasonable behavior policies in\ngeneral. Behavior trees give authors a way to reuse some behaviors and override others from agent\nto agent.\nBehavior trees are usually characterized as a reactive AI formalism, in this context meaning that\nagents are defined in terms of their reactions to a changing environment, rather than by a top-down\nplan that tries to achieve a goal by considering contingencies in advance. Certainly, even finite\nstate machines can be made reactive by adding appropriate transitions, but scaling them to myriad\npotential game events quickly overwhelms authors. Behavior trees reduce that burden by asking a\nbehavior author to structure the reactive behaviors in a tree, implicitly defining which behaviors\nsupersede or interrupt which other behaviors by their position in a preorder traversal of that tree.\nA behavior tree is a data structure describing how an agent decides on its next actions, and at\nthe leaves some primitives for executing those actions. Behavior trees are repeatedly evaluated and\non each evaluation they process their nodes in sequence. When a node is processed, it evaluates\nwith some status: RUNNING, SUCCEEDED, or FAILED. Different sorts of nodes in the tree are specified\nin terms of the circumstances under which they evaluate to each return value.\nA key question in behavior tree semantics is whether a tree which ends an evaluation with\nthe RUNNING status should, on the next evaluation, continue from where it left off; the alternative\nis for it to begin its next evaluation from the root again. The latter approach is more reactive to\nchanges in the environment or interruptions to behaviors, but in the former it is easier to specify\nand conceptualize behaviors which take some time and should not be interrupted. It is also easier\nto avoid behavior oscillations in the former evaluation strategy. For example, with the investigation\nexample from Figure 1: with the latter approach, the agent can be interrupted by a new noise\nwhen moving to a target, while with the former approach, the agent will fully investigate a target\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\n\fA Resourceful Reframing of Behavior Trees\n\n1:5\n\nwithout distraction. Game designers have explored both semantics and even hybrids between these\napproaches; we leave our discussion of this issue until Sec. 5.\nLeaf nodes of the tree can be domain-specific conditions (which succeed if the condition is\ncurrently satisfied or fail otherwise) or domain-specific actions (for example, setting the value of a\nvariable or triggering some external action). These are the only operations which can interact with\nthe environment. The actions in Figure 1 include setting a variable representing the agent’s current\ntarget or physically navigating the agent towards said target. Failure may come from, for example,\nthere being no navigable path to the target. In video games, these are often implemented using\narbitrary program code working outside of the behavior tree formalism.\nNon-leaf nodes come in three key variants (others are usually possible to define as syntactic\nsugar). First, sequences evaluate each of their child nodes from left to right, and are RUNNING if any\nchild node is RUNNING, FAILED if any child is FAILED, or SUCCEEDED otherwise. Second, selectors\nalso evaluate their child nodes left to right, but are RUNNING if any child is RUNNING, SUCCEEDED\nif any child has SUCCEEDED, and FAILED if all the child nodes are FAILED. Third, the parallel node\nevaluates each of its children independently of each other, and has SUCCEEDED if more than a certain\nnumber of its children succeeds, FAILED if more than a certain number fail, and RUNNING otherwise.\nIt is also implicit in the definition of behavior trees that there is some external environment where\nstate can be stored and persisted from evaluation to evaluation.\nIn practice, there are many other types of nodes that can alter the semantics of the tree in\narbitrary ways, often violating the assumption of a preorder traversal: repeaters which evaluate\ntheir children over and over until they evaluate with some status, stateful versions of sequence\nand selector with memory that remember when they get stuck in RUNNING and only evaluate from\nthat stuck node forwards in their next evaluation, and so on. We ignore such extensions in this\nwork to simplify the presentation. Most of the extensions of behavior trees are meant to facilitate\nlong-running actions, to limit the reactivity of behavior trees (e.g., to allow interruptions only at\ndesigner-defined times), and to ease the sharing of behavior tree or character state across situations,\ncharacters, and actions. Actions, conditions, and decorators often themselves involve arbitrary code\nin practice, so in our presentation of the formal semantics we require a linear logic formulation of\nthe leaf nodes.\n4\n\nACTION SPECIFICATIONS IN LINEAR LOGIC\n\nAs a first step towards a type system for general behaviors, we concretize action specifications for\ndescribing the behavior of an atomic action, such as “idly smoke cigarette” in Figure 1. Although\nin reality, this behavior may simply take the form of an observable effect (e.g., some animation),\nsemantically, there are certain things we expect for it to make sense: for instance, that the agent has\na supply of cigarettes (and perhaps that this action spends one). Other actions, like passing through\na door, have more important requirements and effects, such as requiring being near the door and\nresulting in the door being open: these are aspects of the environment that may be created, or\ndepended on, by other agents (or the same agent at another time).\nThere is a long line of successful work on describing actions in a protocols and virtual worlds\nusing any of a class of related formalisms: multiset rewriting, Petri nets, vector addition systems,\nand linear logic. These systems have in common an approach to specification using rules (or\ntransitions in some systems) that describe dependencies and effects, such that the cummulative\neffects of applying those rules may be reasoned about formally.1\n\n1 Planning\n\ndomain description languages also share this approach, but most standards such as PDDL [14], do not have as\nclean of a compositional interpretation due to their allowance for the “deletion” of facts that do not appear as preconditions.\n\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\n\f1:6\n\nChris Martens, Eric Butler, and Joseph C. Osborn\n\nFig. 2. One step of multiset rewriting execution, visualized. Each color/shape (purple diamond, blue circle) represents a distinct predicate; the contents of those shapes are terms (a, b, c) or term variables\n(X). This diagram represents a transition of the state ∆ = {diamond(a), circle(a), circle(b), diamond(c)}\nalong the rule circle(X ) ⊗ diamond(X ) ( diamond(c) ⊗ diamond(d) to the new state ∆ 0 =\n{diamond(c), diamond(d), circle(b), diamond(c)}. The thick orange borders on some atoms highlight which\nones are replaced and added by the rule.\n\nThe following example uses a linear logic-based notation adapted from Ceptre [11] to describe\naction specifications for an Investigation world that could assign meaning to the actions used in\nFigure 1:\nset_target\nmove_to_target\ninvestigate\nsmoke\npace\n\n:\n:\n:\n:\n:\n\nno_target -o has_target.\nhas_target -o has_target * at_target.\nhas_target * at_target * heard_noise -o no_target.\nhas_cigarette -o 1.\n1 -o 1.\n\nThe “lolli” syntax A -o B describes the ability to transition from a world in which A obtains to\none in which A no longer obtains and has been replaced with B. The atomic propositions include\nfacts like at_door and door_open, which represent pieces of world state, the “tensor” p * q syntax\nconjoins them, and 1 is the unit of tensor. World configurations can be represented as multisets (or\nlinear contexts) ∆ specifying which facts hold, such as {no_target, heard_noise, has_cigarette,\nhas_cigarette}.\nIn general, predicates can take arguments (e.g., at(castle)) and rules can universally quantify\nover variables that stand in for term arguments, in which case states are always ground (contain no\nvariables) and the application of rules identifies appropriate substitutions for variables for which\nthe rule applies. Figure 2 visualizes a step of execution for an example.\nMultiset rewriting has been used commonly to model nondeterminism and concurrency: rulesets\ncan be nondeterministic whenever multiple rules may apply to a given state, and concurrency arises\nfrom the partial-order causal relationships between rules firing. If two rules operate on disjoint\nparts of the state, for instance, they can be considered to fire simultaneously, whereas rules that\ndepend on the effects of previous rules firing must obey sequential ordering. See Figure 3 for a\ndiagram of the causal relationships between actions for a particular program trace in which the\nagent sets a target, moves to the target, investigates a noise, and smokes a cigarette.\nFor the work described in this paper, however, we are less interested in the multiset rewriting\ninterpretation of the rules. The specification under the multiset rewriting interpretation alone does\nnot give us as authors any control over strategies for action selection or goal-driven search. Instead,\nit can be thought of as a description of the space of possible actions and a way of calculating their\ncumulative effects. Behavior trees, then, can be understood as directives for how to explore this\nspace.\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\n\fA Resourceful Reframing of Behavior Trees\n\n1:7\n\nFig. 3. A causal diagram for a possible trace of actions under the multiset rewriting interpretation of the\nInvestigate specification.\n\nFormally, we define action specifications under the following grammar:\narд\narдs\n\n::= t | x\n::=\n\n· | arд, arдs\n\nS\n\n::= p(arдs) | 1 | S ⊗ S\n\nopdecl\n\n::= name : xs. S ( S\n\nΣ\n\n::=\n\n· | Σ, opdecl\n\nΣ is a collection of specifications for operators op. Σ may also specify a collection of valid domain\ntypes over which the arguments of operators may range; for example, the operator move(Dir, N )\nmay range over directions and natural numbers, perhaps meaning to move in that direction a\ncertain number of units. The world state ∆ is represented as a linear logic context, i.e. a multiset of\natomic propositions p(arдs) representing available resources.\nIn the next section, we assume an arbitrary signature Σ for each action that computes a function\non states, which does not depend on the linear logical interpretation. However, we revisit this idea\nin Section 6 to assign types to behavior tree expressions.\n5\n\nBTL: A FORMAL SEMANTICS FOR BEHAVIOR TREES\n\nIn this section we describe BTL, a formal calculus for describing synchronous agent behaviors with\nsequencing, branching, conditions, and loops.\nThe goals of this system are similar in many ways to the BTs used in practice: we aim to provide\nsimple authoring affordances for scripting reactions to different circumstances in an implicit\nenvironment that is changing around the agent, and which the agent can change. We also adopt\nsome goals that are not currently met by industry practice:\n• Compositional reasoning. In order to be able to reason about BT nodes in terms of the\nbehaviors of their subtrees, we need to know that subtree behaviors won’t be interrupted\nin unknowable states.\n• Debugging support—specifically, the ability for authors to state what they expect a behavior\nto accomplish and have this expectation checked algorithmically. The algorithm should be\nable to identify where in the tree a stated expectation is violated.\n• Support for the expression of coordinated multi-agent behaviors. This requirement means\nthat we question the notion of an action dependency necessarily meaning failure and\ninstead (or additionally) require a blocking semantics (for instance, an agent may wait until\nanother agent joins them in the same location to hand off a needed item).\n• Support for the eventual integration of behavior synthesis, or algorithms that accept a\npropositional goal for the world state and generate BT subtrees corresponding to conditional\nplans that achieve the goal.\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\n\f1:8\n\nChris Martens, Eric Butler, and Joseph C. Osborn\n\nThese nonstandard goals entail some tradeoffs of expressiveness. While it would be ideal to\nretain, for example, the “reactive” nature of BTs that allow them to break sequential actions to\ntend to urgent interruptions, we do not adopt this form of reactivity by default because it would\npreclude the ability to reason about sequential behaviors compositionally. In Section 8 we revisit\nthese expressiveness tradeoffs and consider ways to re-incorporate additional features.\n5.1\n\nExpressions\n\nThe expressions of BTL are:\nα\n\n::= op(arдs) |?p. α | Seq{α; α } | Sel{α + α } | Seq{} | Sel{} | Repeat{α }\n\nIntuitively, op(arдs) is an atomic action, invoking a pre-defined operator on a set of ground\narguments (such as move(left)); Seq{α; α } is a sequence node; Seq{α + α } is a selector node; Seq{}\nis the unit of sequencers (does nothing); Sel{} is the unit of selectors (always fails); ?p. α checks the\ncondition p and executes α if it holds, failing otherwise; and Repeat{α } is a repeater node, running\nα until failure.\n5.2\n\nOperational Semantics\n\nWe define an operational semantics for behavior trees in terms of what they may do to an abstract\nworld state, using a big-step evaluation judgment α . ∆ ⇓ δ , where ∆ is a world state and δ is the\nresult of evaluating a BTL expression, either a new world state (on successful execution) or FAIL.\nThe evaluation judgment requires a few preliminaries to define. First, we implicitly index the\njudgment by a signature Σ, which provides a specification for a transition function t : τ → ∆ → δ\nfor each operator (atomic action) available to an agent, which takes arguments of type τ , computes\na transformation on a world state if the action can be performed, and returns FAIL otherwise.\nConcretely, our linear logical action specifications can play this role. Second, we assume a notion of\na condition “holding for” a world state, expressed by the judgment ∆ p. Again, while evaluation\ncan be defined holding this judgment abstract, in we can fulfill this definition by expressing\nconditions in terms of a (positive) subset of linear logic formulas and interpreting as affine\nprovability.\nEvaluating an operation consists of looking up its transtition function in Σ and applying that\nfunction to the current state; evaluating a condition requires that the current state satisfies the\ncondition, and otherwise fails:\nΣ(op) = t t(arдs, ∆) = δ\n∆ S α .∆⇓δ\n∆6 S\nop(arдs) . ∆ ⇓ δ\n?S. α . ∆ ⇓ δ\n?S. α . ∆ ⇓ FAIL\nA sequence evaluates by chaining the states computed by successful subtrees through successive\nsubtrees in the sequence, and fails if any subtree fails:\nα . ∆ ⇓ ∆ 0 Seq{α 0 } . ∆ 0 ⇓ δ\nα . ∆ ⇓ FAIL\n0\nSeq{} . ∆ ⇓ ∆\nSeq{α; α } . ∆ ⇓ δ\nSeq{α; α 0 } . ∆ ⇓ FAIL\nA selector succeeds with the first successful subtree and fails if no options are possible:\nα . ∆ ⇓ FAIL Sel{α 0 } . ∆ ⇓ δ\nα . ∆ ⇓ ∆0\nSel{} . ∆ ⇓ FAIL\nSel{α + α 0 } . ∆ ⇓ δ\nSel{α + α 0 } . ∆ ⇓ ∆ 0\nRepeaters continue evaluating the underlying expression until failure:\nα . ∆ ⇓ ∆ 0 Repeat{α } . ∆ 0 ⇓ δ\nRepeat{α } . ∆ ⇓ δ\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\nα . ∆ ⇓ FAIL\nRepeat{α } . ∆ ⇓ ∆\n\n\fA Resourceful Reframing of Behavior Trees\n\n1:9\n\nThis definition of BTL adopts similar conventions and semantics to process algebras, such as\nthe adoption of two key operators, sequential (conjunctive) and choice (disjunctive) composition,\nwhich have certain algebraic properties. In the case of BTL, evaluation respects the following\nstructural congruence:\nSeq{Seq{}; α }\nSeq{α; Seq{β; γ }}\nSel{Sel{} + α }\n\n≡ Seq{α } ≡ Seq{α; Seq{}}\n≡\n≡ Sel{α } ≡\n\nSeq{Seq{α; β }; γ }\nSel{α + Sel{}}\n\nSel{α + Sel{β + γ }}\n\n≡\n\nSel{Sel{α + β } + γ }\n\nSeq{α; Sel{β + γ }}\n\n≡\n\nSel{Seq{α; β } + Seq{α; γ }}\n\nSeq{Sel{α + β }; γ }\n\n≡\n\nSel{Seq{α; γ } + Seq{β; γ }}\n\nIn other words, sequences form a monoid with the unit Seq{}; selectors form a monoid with the\nunit Sel{}; and sequencing distributes over selection. We state that this equivalence is respected by\nevaluation but omit the proof for brevity:\nConjecture 5.1. BTL operational semantics respects congruence: If α . ∆ ⇓ δ and α ≡ β then\nβ . ∆ ⇓ δ.\nWhile the system bears resemblance to models of concurrency such as CSP [8] and (CCS) [15],\nit differs in that interactions between BTL expressions and their environment happen implicitly\nthrough manipulation of a shared world state, not through channel-based communication (as in\nCSP) or explicit labels for inputs and outputs (as in CCS). The lack of such machinery is what\nmakes behavior trees so attractive to authors; it reduces the burden of needing to specify how\ninformation is transmitted from one agent to another. However, it also makes the dependencies\nbetween agents tacit and therefore difficult to debug when things go wrong, which is what this\npaper aims to address.\nKleene algebra, particularly Kozen’s variant with tests (KAT) [10], offers another touchstone for\nsemantic insights; however, BTL does not quite satisfy the Kleene conditions: (1) order matters in\nselector semantics due to fallthrough, so selectors are not commutative; (2) the annihilation law\ndoes not hold; Seq{α; Sel{}} is not equivalent to Sel{} due to the state changes that α may incur.\n5.3\n\nExample\n\nBelow is BTL implementation of the behavior tree described in Figure 1. This and all future examples\nuse an n-ary form of Seq and Sel defined in the obvious way.\nSel{?heard_noise.set_target() +\nSeq{move_to_target(); investigate_target()} +\nSel{idle_smoke() + idle_pace()}}\n\nTo illustrate how an BTL expression evaluates, we consider an evaluation of this tree in an environment where the agent already has a reachable target and has not heard a noise, i.e. the situation\n{has target}. Starting evaluation at the root, the outer selector expression evaluates each child in\nsuccession until one succeeds. The first child will fail because the heard noise condition does not\nhold. The second child, a sequence, will evaluate each of its children in succession. The first action,\npredicated on having a target, evaluates by modifying the world state such that the agent is in the\nsame location as the target. Upon the movement action succeeding, the investigate target()\naction will be evaluated; however, this node fails in the absence of having heard a noise, and that\nfailure propagates to the root of the tree.\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\n\f1:10\n\nChris Martens, Eric Butler, and Joseph C. Osborn\n\nΓ; p ` p\n\ninit\n\nΓ; · ` 1\n\n1R\n\nΓ; ∆ ` M : C\n1L\nΓ; ∆, 1 ` C\n\nΓ; ∆1 ` A Γ; ∆2 ` B\n⊗R\nΓ; ∆1 , ∆2 ` A ⊗ B\nΓ; ∆, A ` B\n(R\nΓ; ∆ ` A ( B\n\n>R\n\n(no >L)\n\nΓ; ∆, A, B ` C\n⊗L\nΓ; ∆, A ⊗ B ` C\n\nΓ; ∆1 ` A Γ; ∆2 , B ` C\n(L\nΓ; ∆1 , ∆2 , A ( B ` C\n\nΓ; ∆ ` A Γ; ∆ ` B\nNR\nΓ; ∆ ` ANB\nΓ, x:τ ; ∆ ` A\n∀R\nΓ; ∆ ` ∀x:τ . A\n\nΓ; ∆ ` >\n\nΓ; ∆, Ai ` C\nNLi\nΓ; ∆, A1 NA2 ` C\n\nΓ ` t : τ Γ; ∆, N [t]:A ` C\n∀L\nΓ; ∆, ∀x:τ . A ` C\n\nFig. 4. A fragment of intuitionistic linear sequent calculus.\n\nIf instead we started in an environment {has target, heard noise}, then at the same point in\nthe tree, the investigate target action will succeed and change the world state by replacing\nhas target with no target (in practice, this might have a more interesting effect like updating\nvariables representing the agent’s knowledge of its target). Because both children of the sequence\nevaluate to success, the sequence evaluates to success. Thus, the root selector will itself evaluate\nto success without evaluating the third branch, completing the evaluation of the entire tree, and\nresulting in the state {no target}.\n6\n\nCOMPOSITIONAL REASONING\n\nCompositional reasoning for behavior trees means that understanding the effects of a whole BT can\nbe done by understanding the effects of its subtrees. The type system we describe gives a precise\naccount of the conditions under which a BT has successful execution and the consequences of that\nexecution. Accounting for the range of behaviors possible under failure is outside the scope of this\npaper (see Section 8). However, these types are richer than sets of precondtions and postcondtions:\nthey account for the “reactive” nature of BTs by requiring dependencies to be filled not prior to\nexecution but just at the node of the tree where they are needed; types also describe resources that\nare released periodically if they are not needed for later use.\nThis “open” structure of behavior types makes the account of agents’ behavior amenable to\nanalysis in the presence of multiple agent executing in parallel: BTs may both incur and use changes\nin the environment.\n6.1\n\nA linear type system, take 1\n\nOur guiding principle for assigning types to BTL expressions adopts a “formulas-as-processes”\npoint of view to imagine the proof-theoretic semantics of what the formula admits provable under\narbitrary environments. Consider linear logic formulas A ::= p | 1 | > | A ⊗ A | ANA | A ( A and\nan intuitionistic sequenct calculus defining their provability (following [3]) shown in Figure 4.\nThe following intuition guides the correspondence we seek:\n• Firing a leaf action op(arдs) of type S ( S 0 in an environment ∆ corresponds to the (-left\nrule in linear sequent calculus: to succeed, it requires that the current environment match\nthe antecedent of the action and then changes the environment to replace it with the\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\n\fA Resourceful Reframing of Behavior Trees\n\n1:11\n\nconsequent. Correspondingly, evaluating op(arдs) in an environment ∆, ∆ 0 where ∆ 0 ` S\nevaluates to ∆, S 0 in the operational semantics.\n• The unit selector Sel{} always fails, having run out of options; this corresponds to the >\nunit of N in linear logic, which has no left rule, so everything is beneath it in the preorder.\n• The unit sequence Seq{} does nothing, corresponding to the left rule of the unit 1 of ⊗.\nCorrespondingly, the operational semantics of Seq{} take the environment ∆ to itself.\n• Selectors Sel{α 1 +α 2 } nearly correspond to making a choice, as in Linear Logic’s N operator.\nThere is a difference in that N is symmetric; ANB and BNA are interprovable, whereas order\nmatters in BTL selectors. However, certain reasoning principles apply: if either α 1 . ∆ ⇓ ∆1\nor α 2 . ∆ ⇓ ∆2 , then one of ∆1 or ∆2 will be the result of evaluating Sel{α 1 + α 2 } against ∆.\nFor reasons described above, however, accounting for sequences will be more difficult. It might\nbe tempting to think that ⊗ is an appropriate interpretation, despite the relative lack of ordering\nconstraints, for reasons similar to how N can approximate selectors. A conjectured rule:\nα 1 : A1 α 2 : A2\nBAD RU LE\nSeq{α 1 ; α 2 } : A1 ⊗ A2\nAt this point we need to formulate the metatheorem we have so far been implicitly expecting to\nhold:\nConjecture 6.1. If α : A and ∆, A ` S, then α . ∆ ⇓ ∆ 0 and ∆ 0 ` S.\n(Recall that S stands for a formula with no Ns or (s, representing a successful state in the\ncourse of a BTL expression’s execution.) The proposed rule violates this conjecture; we show a\ncounterexample next.\n6.2\n\nThe trouble with sequences: an example\n\nThe following action specification describes a Doors world in which agents may pass through open\ndoors, open unlocked doors, and unlock locked doors if they have keys:\nwalk_to_door : at_elsewhere -o at_door.\npass_through : door_open * at_door -o door_open * through_door.\nopen_door : door_unlocked * at_door -o door_open * at_door.\nsmash_door : door_locked * at_door -o door_open * at_door.\nclose_door : door_open * through_door -o door_unlocked * through_door.\n\nFor a counterexample to Conjecture 6.1, let α = Seq{open door; walk to door} and let ∆ =\n{at elsewhere, door unlocked}. According to BAD RU LE, α : A = (at door⊗door unlocked (\ndoor open)⊗(at elsewhere ( at door). By straightforward rule applications, ∆, A ` door unlocked,\nbut it is not the case that Seq{open door; walk to door} . ∆ ⇓ door unlocked.\nIn addition to the clear unsoundness of describing a sequential behavior with a commutative\nconnective, there are also concerns regarding the granularity of concurrent execution. Consider a\nsimple sequential behavior for opening and going through a door:\nSeq{walk_to_door; open_door; pass_through; close_door}\n\nA type we could reasonably expect to ascribe to this behavior is:\nat elsewhere ⊗ door unlocked ( through door ⊗ door unlocked\nThis formula corresponds to the assumption that if our starting environment has at elsewhere\nand door unlocked, each element in this sequence of actions will consume the output of the\nprevious action as an input, resulting in through door. Each successive action depends on the\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\n\f1:12\n\nChris Martens, Eric Butler, and Joseph C. Osborn\n\neffects of previous actions: opening the door assumes that the previous walk action brought us to\nthe door; passing through assumes we successfully opened the door; and closing the door assumes\nwe passed through and the door is still open.\nHowever, in a general, maximally concurrent environment, we would not be allowed to make\nthese assumptions: suppose, for example, another agent interferes and closes the door just after we\nopen it. This relaxed assumption instead observes that we might forfeit all of the effects of previous\nactions, resulting in the following type:\nat elsewhere ( at door ⊗ (at door ⊗ door unlocked (\nat door ⊗ door open⊗\n(at door ⊗ door open ( through door ⊗ door open⊗\n(door open ⊗ through door ( through door ⊗ door unlocked)))\nThis formula characterizes the behavior that, at each step, a sequence releases some resources\ninto the world along with a “continuation” that could, in some cases, potentially reabsorb those\nresources, or require new ones along the way.\nThese two ascriptions correspond to different assumptions about how behaviors interact with\nother behaviors manipulating the environment. The former assumes an un-interruptable, “critical\nsection” behavior to sequences and gives a stronger guarantee, allowing us to treat the sequence\nas a black-box behavior without worrying about internal failure. On the other hand, the latter\npermits interruption and “race condition”-like scenarios that are common in games and interactive\nsimulations in practice, but offers less strict guarantees that reflect the complexity of reasoning\nabout fine-grained interaction.\nOur type system makes the latter assumption that processes may be interrupted, but we discuss\nthe potential to accommodate both in Section 8.\n6.3\n\nLinear Behavior Interfaces\n\nWe constrain linear logical formulas to the following grammar of interfaces, expressed inductively\nas nested stagings of inputs and outputs (and choice between multiple possible interfaces):\nN\n\n::= S | S ( N | S ⊗ N | N NN | >\n\nThis grammar mainly serves to prevent ( from appearing to the left of another ( while\nrepresenting staged inputs and outputs as described above.\nWe assign types as linear logic formulas N to BTL expressions α with the judgment α :Σ N .\nwhere α is an expression, N is an interface type, and Σ is a specification giving types S ( S 0 to the\nactions used at the leaves of the trees.\nThe typing rules are as follows, with Σ left implicit as an index to the judgment except when it is\nneeded. Atomic operations, conditions, the units, and selectors, are straightforward, and conditions\nmust assume, but then reproduce, the condition they depend on. Sequences are assigned a type\nbased on a computation seq of the types of their components:\n\nSeq{} : 1\nα1 : N1 α2 : N2\nSel{α 1 + α 2 } : N 1 NN 2\n\nSel{} : >\n\nΣ ` op : xs. S ( S 0\nop(arдs) :Σ [arдs/xs](S ( S 0)\n\nα :N\n?S. α : S ( S ⊗ N\n\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\nα1 : N1 α2 : N2\nSeq{α 1 ; α 2 } : seq(N 1 , N 2 )\n\n\fA Resourceful Reframing of Behavior Trees\n\n1:13\n\nThe seq operator is defined as follows:\nseq(1, N ) =\n\nN\n\nseq(S 1 , S 2 ) = S 1 ⊗ S 2\nseq(S, S 0 ⊗ N ) =\n\n(S ⊗ S 0) ⊗ N\n\nseq(S, N 1 NN 2 ) =\n\nseq(S, N 1 )Nseq(S, N 2 )\n\nseq(S 1 , S 2 ( N ) = S 1 ⊗ (S 2 ( N )\nseq(S ⊗ N 1 , N 2 ) =\n\nseq(S, seq(N 1 , N 2 ))\n\nseq(S 1 ( N 1 , N 2 ) = S 1 ( seq(N 1 , N 2 )\nseq(N 1 NN 2 , N ) =\n\n(seq(N 1 , N )Nseq(N 2 , N ))\n\nIt can be interpreted as pushing the requirements of the first formula to the outside of the\nwhole formula, then conjoining its consequences with the specification of the second formula. The\ncorrectness of this definition, and of the type system in general, with respect to the operational\nsemantics, is considered next.\n6.4\n\nMetatheory\n\nWe revisit Conjecture 6.1 and sketch a proof. First we establish a lemma about the seq operator:\nLemma 6.2. If ∆, seq(N 1 , N 2 ) ` S and ∆ is flat, i.e. consists only of propositions of the form S, then\nthere exists S 1 such that ∆, N 1 ` S 1 and ∆, S 1 ` N 2 .\nProof. By induction on the definition of seq. We show the interesting cases.\n• Case: seq(S 1 , S 2 ( N ) = S 1 ⊗ (S 2 ( N ).\nAssume ∆, S 1 , S 2 ( N ` S.Ë\nIn this case, we can\nËjust tensor together the first state and feed\nit into the second. ∆, S 1 `\n(∆) ⊗ S 1 , and ∆, (∆) ⊗ S 1 , S 2 ( N ` S by untensoring that\nproposition to get to the assumption.\n• Case: seq(S 1 ( N 1 , N 2 ) = S 1 ( seq(N 1 , N 2 ).\nAssume ∆, S 1 ( seq(N 1 , N 2 ) ` S. Because the proof of this sequent concludes with an S,\nsomewhere along the way we must discharge the (, i.e. some part of ∆ proves S 1 . Rewrite\n∆ = ∆1 , ∆ 0 where ∆1 ` S 1 . Somewhere in the proof there is an application of ( L such\nthat ∆ 0, seq(N 1 , N 2 ) ` S is a subproof, and by inductive hypothesis, there exists S 0 such that\n∆ 0, N 1 ` S 0 and S 0, N 2 ` S.\nNow it suffices to show that ∆, S 1 ( N 1 ` S 0 (since we already have S 0, N 2 ` S). This\ncan be established by reusing the part of ∆ that discharges S 1 , using ( L on ∆1 ` S 1 and\n∆ 0, N 1 ` S 0 .\n• Remaining cases are straightforward.\n\u0003\nTheorem 6.3. If α : A, ∆ is flat, and ∆, A ` S, then α . ∆ ⇓ ∆ 0 and ∆ 0 ` S.\nProof. By lexicographic induction on the typing derivation and proof. We show the sequence\ncase here.\n• Case:\nα1 : N1 α2 : N2\nSeq{α 1 ; α 2 } : seq(N 1 , N 2 )\nKnown: ∆, seq(N 1 , N 2 ) ` S. By lemma, there exists S 0 such that ∆, N 1 ` S 0 and S 0, N 2 ` S.\n\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\n\f1:14\n\nChris Martens, Eric Butler, and Joseph C. Osborn\nBy i.h., α 1 . ∆ ⇓ ∆ 0 where ∆ 0 ` S 0. By i.h., α 2 . {S 0 } ⇓ ∆ 00 where ∆ 00 ` S. By appropriate\nequivalence between the positive propostion S 0 and context ∆ 0, and by the sequence\nevaluation rule, Seq{α 1 ; α 2 } . ∆ ⇓ ∆ 00 where ∆ 00 ` S 0.\n\u0003\n\n6.5\n\nExample\n\nWe now return to the “investigating a sound” example whose evaluation was shown in Section 5.3.\nThe computed type for the example:\nSel{?heard_noise.set_target() +\nSeq{move_to_target(); investigate_target()} +\nSel{idle_smoke() + idle_pace()}}\n\nis:\n(heard noise ( (heard noise ( no target ( has target)\nN\n\n(has target ( (has target ⊗ at target ⊗\n(has target ⊗ at target ⊗ heard noise ( no target))\n\nN\n\n(has cigarette ( 1)\n\nN\n7\n\n(1 ( 1)\n\nIMPLEMENTATION\n\nWe implemented both an interpreter for BTL (with repeater nodes) and a type synthesis algorithm\nfor BTL excluding repeaters, both following the descriptions in the paper. The implementation is\nwritten in 523 lines of Standard ML, including detailed comments, and we authored an additional\n448 lines of examples, including those used in this paper.\nThe implementation is freely available on GitHub at (URL redacted for double-blind review).\n8\n\nDISCUSSION\n\nA longer-term goal for this work is to be able to account for how behavior trees are used in practice,\nto integrate the type system into the behavior authoring process (perhaps through a combination\nof checking and synthesis), and to evaluate how it may make designers (particularly without\nprogramming background) more effective. We anticipate using the implementation of BTs in the\nUnreal Engine as a benchmark. Shorter term, there are a few theoretical concerns we still need to\nconsider. We now describe a roadmap for this project.\n8.1\n\nParallel Composition\n\nCurrently, the semantics of agents operating in the world concurrently is not specified by the\nlanguage. To account for placing multiple world-manipulating agents into the environment, we\nmight consider introducing a “parallel” operator to BTL:\nα ::= . . . | Par{α 1 k α 2 }\nWe may consider a few options for an operational semantics that warrant a different typetheoretic treatment. For instance, perhaps parallel behaviors split the state and operate in isolation\nuntil complete. This behavior could be captured with the rule:\n∆ = ∆1 , ∆2 α 1 . ∆1 ⇓ ∆10 α 2 . ∆2 ⇓ ∆20\nPar{α 1 k α 2 } . ∆ ⇓ ∆10 , ∆20\n\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\n\fA Resourceful Reframing of Behavior Trees\n\n∆/skip → ∆/\n\nΣ ` op[arдs] : A ( B ∆A ` A\nstep/op\n∆, ∆A /op(arдs) → ∆, B/\n\nstep/skip\n\n∆/α 1 →∗ ∆ 0/\nstep/;\n∆/α 1 ; α 2 → ∆ 0/α 2\n\n1:15\n\n∆/α 1 + α 2 → ∆/α 1\n\n∆, p/?p. α → ∆, p/α\n\nstep/?\n\n∆1 /α 1 → ∆10 /α 10\nstep/k 1\n∆1 , ∆2 /α 1 kα 2 → ∆10 , ∆2 /α 10 kα 2\n\nstep/+1\n\n∆/α 1 9\nstep/+2\n∆/α 1 + α 2 → ∆/α 2\n\n∆/α →∗ ∆ 0/\nstep/∗\n∆/α ∗ → ∆ 0/α ∗\n∆2 /α 2 → ∆20 /α 20\nstep/k 2\n∆1 , ∆2 /α 1 kα 2 → ∆1 , ∆2 /α 1 kα 20\n\nFig. 6. A small-step semantics for BTL without failure.\n\nAdditional rules may specify that if either\nsubbehavior fails, the whole behavior fails.\nHowever, in practice, behavior trees allow for\nfiner-grained interactions between processes.\nThe above specification precludes, for example,\nthe below two behaviors succeeding:\n// Agent 1 (a1)\nSeq{move(a1,L);\ngive(a2,O)}\n\n// Agent 2 (a2)\nSeq{move(a2,L);\neat(a2,O)}\n\nThese behaviors will only succeed if they\ninteract when run; a1’s action give(a2,O) will\nonly succeed if a2’s first action, move(a2,L), is\npermitted to succeed first. Figure 5 describes\nFig. 5. Composing processes that interact.\nvisually the behavior specification we would\nlike to result in this interaction.\nTo account for such fine-grained concurrent\nbehaviors formally, we require a small-step semantics over the judgment α/∆ → α/∆ 0. A\nsketch of this semantics that includes parallel\ncomposition is in Figure 6. However, note that this semantics does not properly handle failure;\ninstead, it embodies the synchronous semantics of behaviors simply pausing (failing to evolve)\nif their conditions are not satisfied, instead permitting the possibility of a delayed transition if\ntheir conditions become satisfied as another behavior evolves. While this behavior may be useful\nin some scenarios, it is not universally desirable, so we need a way to account for this behavior,\nperhaps through a stack-based semantics with success and failure continuations. Likewise, the type\nsystem has a clear extension to count for arbitrarily “pausing” processes (⊗ is a straightforward\ninterpretation), but accounting for failure in the type system is also left to work.\n8.2\n\nTheoretical extensions\n\nIn addition to accounting for parallel execution, we also need to consider repeater nodes. The\noperational semantics are fairly easy to specify, but guaranteeing convergence of computing fixed\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\n\f1:16\n\nChris Martens, Eric Butler, and Joseph C. Osborn\n\npoints for a type-based characterization may prove difficult. Recursive types have been successfully\nintegrated into linear logic [1], and we plan to investigate their use, although readability may\nremain a challenge.\nAnother step we would like to take is to introduce additional forms of lightweight verification\non top of the type system. For instance, selectors are often designed with the intent that all possible\ncases are covered: each child of the selector is guarded by a condition, and the disjunction of the\nconditions characterizes an invariant of the state. Provided a proof that the invariant actually holds,\nit may be useful to simplify the type to omit the guards. This corresponds to provability between\ne.g. (A ⊕ B) ⊗ ((A ( C)N(B ( D)) and (C ⊕ D).\nNext, while we have established a correspondence between the type system and evaluation of\nsuccessful behaviors, we believe we can formulate a conjecture to the effect that the situations in\nwhich types fail to yield a flat context (because there is some implication that cannot be discharged\non the left, say) correspond to the failure cases of execution. We expect this proof will be more\ndifficult than the former.\n9\n\nCONCLUSION\n\nWe have presented a formal semantics and type system for a fragment of behavior trees as they are\nused to describe characters in virtual environments. Our system includes a reference implementation\nand correctness proofs. This work represents substantial new ground broken towards a longer-term\nvision of authoring robust, designer-friendly specifications for reactive agent behaviors.\nIf our long-term vision is successful, we can enable several new things for behavior authors:\nintegrating hand-authored trees with behavior synthesis algorithms through linear logic theorem\nproving (akin to planning); the development of behavior libraries consisting of reusable, parameterized behavior trees whose specification precludes examining the entire tree; and certified behaviors\nthat are guaranteed to succeed under certain environments. These features would improve the\neffectiveness of developing agents in virtual worlds with varied applications in entertainment, arts,\nsimulation modeling, research competitions and challenges, and computing education.\nREFERENCES\n[1] David Baelde. 2012. Least and greatest fixed points in linear logic. ACM Transactions on Computational Logic (TOCL)\n13, 1 (2012), 2.\n[2] Luis Caires, Frank Pfenning, and Bernardo Toninho. 2016. Linear logic propositions as session types. Mathematical\nStructures in Computer Science 26, 3 (2016), 367–423.\n[3] Bor-Yuh Evan Chang, Kaustuv Chaudhuri, and Frank Pfenning. 2003. A judgmental analysis of linear logic. Technical\nReport CMU-CS-03-131R. Department of Computer Science, Carnegie Mellon University. Revised December 2003.\n[4] Michele Colledanchise, Richard M Murray, and Petter Ogren. 2017. Synthesis of Correct-by-Construction Behavior\nTrees. (2017).\n[5] Stephen Cresswell, Alan Smaill, and Julian Richardson. 1999. Deductive synthesis of recursive plans in linear logic. In\nEuropean Conference on Planning. Springer, 252–264.\n[6] Lucas Dixon, Alan Smaill, and Alan Bundy. 2006. Planning as deductive synthesis in intuitionistic linear logic. Technical\nReport. Technical Report EDI-INF-RR-0786, School of Informatics, University of Edinburgh.\n[7] Malik Ghallab, Dana Nau, and Paolo Traverso. 2016. Automated Planning and Acting. Cambridge University Press.\n[8] Charles Antony Richard Hoare. 1978. Communicating sequential processes. Commun. ACM 21, 8 (1978), 666–677.\n[9] Damian Isla. 2005. Handling Complexity in the Halo 2 AI. In Proceedings of the 2005 Game Developers Conference.\n[10] Dexter Kozen. 1997. Kleene algebra with tests. ACM Transactions on Programming Languages and Systems (TOPLAS)\n19, 3 (1997), 427–443.\n[11] Chris Martens. 2015. Ceptre: A language for modeling generative interactive systems. In Eleventh Artificial Intelligence\nand Interactive Digital Entertainment Conference.\n¨\n[12] Alejandro Marzinotto, Michele Colledanchise, Christian Smith, and Petter Ogren.\n2014. Towards a unified behavior\ntrees framework for robot control. In Robotics and Automation (ICRA), 2014 IEEE International Conference on. IEEE,\n5420–5427.\n\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\n\fA Resourceful Reframing of Behavior Trees\n\n1:17\n\n[13] Marcel Masseron, Christophe Tollu, and Jacqueline Vauzeilles. 1993. Generating plans in linear logic: I. actions as\nproofs. Theoretical Computer Science 113, 2 (1993), 349–370.\n[14] Drew McDermott, Malik Ghallab, Adele Howe, Craig Knoblock, Ashwin Ram, Manuela Veloso, Daniel Weld, and\nDavid Wilkins. 1998. PDDL-the planning domain definition language. (1998).\n[15] Robin Milner. 1980. A calculus of communicating systems. (1980).\n[16] Steven Rabin. 2013. Game AI Pro: Collected Wisdom of Game AI Professionals. A. K. Peters, Ltd., Natick, MA, USA.\n[17] Anders Schack-Nielsen and Carsten Schürmann. 2008. Celf-A Logical Framework for Deductive and Concurrent\nSystems (System Description).. In IJCAR, Vol. 5195. Springer, 320–326.\n[18] Kevin Watkins, Iliano Cervesato, Frank Pfenning, and David Walker. 2003. A concurrent logical framework I: Judgments\nand properties. Technical Report. Technical Report CMU-CS-02-101, Department of Computer Science, Carnegie\nMellon University, 2002. Revised May.\n\n, Vol. 1, No. 1, Article 1. Publication date: January 2016.\n\n\f",
         "train",
         "54247",
         "9128"
        ],
        [
         "8",
         "18948",
         "cs.AI",
         "Artificial Intelligence",
         "1712.08296v2.pdf",
         "Intelligent Device Discovery in the Internet of\nThings – Enabling the Robot Society\nJames Sunthonlap, Phuoc Nguyen, Zilong Ye\n\narXiv:1712.08296v2 [cs.AI] 8 Jan 2018\n\nCalifornia State University Los Angeles\n5151 State University Drive, Los Angeles, CA 90032, USA\nEmail: zye5@calstatela.edu\n\nAbstract—The Internet of Things (IoT) is continuously growing\nto connect billions of smart devices anywhere and anytime in an\nInternet-like structure, which enables a variety of applications,\nservices and interactions between human and objects. In the\nfuture, the smart devices are supposed to be able to autonomously\ndiscover a target device with desired features and thus yield\nthe computing service, network service and data fusion that\nleads to the generation of a set of entirely new services and\napplications that are not supervised or even imagined by human\nbeings. The pervasiveness of smart devices, as well as the\nheterogeneity of their design and functionalities, raise a major\nconcern: How can a smart device efficiently discover a desired\ntarget device? In this paper, we propose a Social-Aware and\nDistributed (SAND) scheme that achieves a fast, scalable and\nefficient device discovery in the IoT. The proposed SAND scheme\nadopts a novel device ranking criteria that measures the device’s\ndegree, social relationship diversity, clustering coefficient and\nbetweenness. Based on the device ranking criteria, the discovery\nrequest can be guided to travel through critical devices that stand\nat the major intersections of the network, and thus quickly reach\nthe desired target device by contacting only a limited number of\nintermediate devices. We conduct comprehensive simulations on\nboth random networks and scale-free networks to evaluate the\nperformance of SAND in terms of the discovery success rate, the\nnumber of devices contacted and the number of communication\nhops. The simulation results demonstrate the effectiveness of\nSAND. With the help of such an intelligent device discovery\nas SAND, the IoT devices, as well as other computing facilities,\nsoftware and data on the Internet, can autonomously establish\nnew social connections with each other as human being do.\nThey can formulate self-organized computing groups to perform\nrequired computing tasks, facilitate a fusion of a variety of\ncomputing service, network service and data to generate novel\napplications and services, evolve from the individual aritificial\nintelligence to the collaborative intelligence, and eventually enable\nthe birth of a robot society.\nIndex Terms—Internet of Things, social-aware, distributed,\ndevice discovery, computing, network and data fusion, robot\nsociety.\n\nI. I NTRODUCTION\nThe Internet of Things (IoT) is continuously growing to connect billions of smart devices anywhere and anytime through\nan Internet-like structure. A recent forecast by International\nData Corporation (IDC) shows that the IoT will involve more\nthan 212 billion of objects by 2020, and the IoT and the\nassociated ecosystem are predicted to have a $1.7 trillion\nmarket [1]. The IoT devices are capable of sensing, analyzing\nand evaluating the surrounding objects and people. They\ncan collaborate and work together to provide a set of new\n\napplications and services, such as smart home, e-healthcare\nand intelligent transportation system. The IoT is envisioned\nto dramatically change and enhance the interactions between\nhuman and objects, bringing transformative benefits to the\nlives of human beings.\nAs the IoT evolves, it is promising that the future smart\ndevices may have the capability to discover a target device\nwith desired features, and autonomously collaborate with each\nother to accomplish certain missions or tasks. An intelligent\ndevice discovery strategy may allow the IoT devices to efficiently establish new connections with other devices based on\ntheir need. The connections can be set up to gather a certain\nnumber of computing powers, network functions, program\nsource codes, raw datasets, and etc to enable new services and\napplications. A variety of computing service, network service\nand data can be fused [2]-[4] by following the guidance of an\nintelligent device discovery strategy. For example, a glucose\nlevel monitor can send a request to find a glucose analyzer,\nand collaborate on evaluating a given patient’s glucose level.\nThe glucose analyzer may also need to search for a national\nwide database to compare the given patient’s results with\nthat of other patients, and then given the advisement or alert\nto the given patient. Here, an intelligent device discovery\nstrategy could guide the request to the appropriate destinations\nfor obtaining the required computing facilities, functions and\ndata to provide the evaluation service, natually leading to\na computing service, network service and data fusion. In\naddition, the IoT devices can also form social connections\nas human beings do, and they can collaborate to generate\nentirely new kinds of applications and services with the help of\ncollaborative intelligence of smart devices and data, rather than\nthe supervision of human beings. In the above future scenarios,\none of the key challenges is how to achieve a fast, scalable and\nefficient device discovery when there are millions or billions\nof devices in the IoT. An intelligent device discovery should\nhave a forwarding strategy that guide the discovery request\nto quickly arrive at the desired target device with minimum\ndetours. In addition, since most of the IoT devices are power\nconstrained, the device discovery should avoid involving too\nmany intermediate devices in the process of data exchange.\nThere are a few existing works on the topic of IoT device\ndiscovery. The work in [5] identified the differences between\nuser search and machine-to-machine search, and presented\nthe challenges and requirements for IoT device search. The\n\n\fauthors in [6] studied device discovery on different network\ntopologies, including a star-like centralized network, a regular\nmesh-like decentralized network and a hierarchical network.\nThey focused on analyzing the effect of the network topology\non the discovery success rate, rather than designing new device\ndiscovery strategies. The study in [7] proposed a centralized\nIoT search engine that can accurately interpret the context of\nthe discovery request and thus make a proper management of\nsearch and usage in the IoT middleware environment. However, this centralized approach may not be scalable when the\nnetwork size is large, and can be vulnerable to a single point of\nfailure. More recent work [8] investigated a distributed device\ndiscovery strategy based on Information-Centric Networking\n(ICN). However, this approach may not be applicable to the\nIoT system since it relies on the built-in features of ICN such\nas cache and broadcast capabilities, which could introduce an\nextra cost to the resource-constrained IoT devices.\nIn this work, we focus on investigating autonomous and\nintelligent device discovery in the IoT. We do not treat smart\ndevices as independent objects or limit our study on the\nartificial intelligence of a single device, but we explore humanlike social behaviors and collaborative intelligence of smart\ndevices. It is envisioned for the next episode of research in\nthe IoT and robotics. In particular, we propose a novel IoT\ndevice discovery scheme, called Social-Aware and Distributed\n(SAND), which can discover a desired target device in a fast,\nefficient and scalable manner. In SAND, IoT devices are fair\nand equal as peers, and they can interact with each other in an\nautonomous and distributed manner as human do, as each of\nthem only maintains the information of their local neighboring\npeers. Each IoT device is ranked by measuring the device’s\ndegree, social relationship diversity, clustering coefficient and\nbetweenness. Based on this, SAND opts to forward the discovery request to the neighboring device with the highest\nrank, which is likely to stand at the major intersection of the\nnetwork that can fast and efficiently lead the request to the\ndesired target device. We conduct comprehensive simulations\nto evaluate the proposed SAND scheme on both a random\nnetwork and a scale-free network. The simulation results show\nthat SAND can achieve a high discovery success rate and\na short discovery path, while contacting a small number of\nintermediate devices.\nThe rest of the paper is organized as follows. We first\nintroduce the traditional centralized and distributed device\ndiscovery schemes in Section 2. Then, we describe the design\ndetails of the proposed SAND scheme in Section 3. In Section\n4, we present the performance evaluation. In Section 5, we\ndiscuss the research challenges and opportunities related to\nthe IoT device discovery. Finally, we conclude the paper and\npropose our future work in Section 6.\nII. T RADITIONAL I OT D EVICE D ISCOVERY S CHEMES\nThere are two traditional solutions for addressing the device\ndiscovery in the IoT, which are the centralized scheme and\nthe distributed scheme. The former leverages a centralized\ncontroller to resolve the discovery request, and the latter\n\nuses a simple broadcast mechanism to discover the required\ntarget device in a breadth-first search manner. The detailed\ndescription and the comparison of these two approaches are\npresented in the following subsections.\nA. Centralized IoT Device Discovery Scheme\nTo achieve a fast and efficient IoT device discovery, a simple\nyet effective approach is to introduce a centralized controller\nwhich keeps track of the general information (e.g., the device’s\nfunctionality) of all the devices and maintains the shortest\npaths between all the device pairs. If there exists a source\ndevice which requests to discover a target device that provides\na desired function, the discovery request can be sent to the\ncentralized controller to resolve. The centralized controller can\nfind the location of the desired target device and reply to the\nsource device with the shortest path information to the target\ndevice. Such a centralized scheme is fast and accurate due\nto that the centralized controller has a global view of all the\ndevices in the network. It is also efficient since the centralized\ncontroller can provide the shortest path between the source\nand target devices, which involves the minimum number of\nintermediate devices in transmitting the discovery request.\nThe centralized scheme can be designed with robustness\nagainst dynamic changes in the network. When a new device\njoins the network, it needs to register the general information\nat the controller. A device that leaves the network also needs\nto unsubscribe at the centralized controller. In addition, the\ncentralized controller can periodically send out heartbeat messages to all the registered devices and maintain an up-to-date\nlist of the alive devices in the network. If a device fails to reply\nto the heartbeat after three attempts, it is considered as in the\nmode of lost and will be removed from the list of alive at the\ncentralized controller. We can see that the centralized scheme\nhighly relies on the centralized controller which manages the\nwhole system and the communication between the IoT devices.\nB. Distributed IoT Device Discovery Scheme\nThe centralized scheme is fast and efficient; however, it\nmay not be scalable when the number of devices is large.\nIn contrast, the distributed scheme offers a scalable device\ndiscovery in the IoT. In the distributed scheme, each device\nmaintains a local neighbor list that consists of the neighbors’\ngeneral information. When a new device joins a network, it\nonly exchanges the general information with nearby devices\nthat are within the transmission range. When a device leaves\nthe network, it needs to inform its neighbors for them to update\ntheir local neighbor list. Heartbeats can be exchanged between\nthe devices to maintain the fresh live or lost status of the\ndevices’ neighbors. The distributed discovery scheme works\nin a breadth-first search manner. When a source device makes\na request to discover a target device with desired features,\nthe distributed scheme simply broadcasts the discovery request\nto all the neighboring devices. This process iterates until the\ndesired target device is found.\nCompared to the centralized scheme, the distributed scheme\nis more resilient against possible failures since there is no\n\n\fcentralized control that is at the risk of single point of failure. It\nis also more robust when the network is dynamically changing\nsince each device only needs to maintain their local neighbor’s\ninformation. We can also infer that the distributed scheme can\nfind a cost-efficient communication path between the source\nand target devices since the breadth-first search is used. The\nonly limitation is that a large number of intermediate devices\nmay be involved in transmitting the discovery request when\nbroadcast is used, which is energy consuming. This is harmful\nto the IoT system where most of the devices are power\nconstrained.\nIII. S OCIAL -AWARE AND D ISTRIBUTED I OT D EVICE\nD ISCOVERY – SAND\nIn the famous small-world experiment [9], Travers and\nMilgram found that people are tied by a short chain of\nconnections and any two persons can be connected in six\nhops by simply exploring their social networks. A more recent\nFacebook research [10] confirmed this observation in which\nthey concluded that, among their 1.59 billion active users,\nin average a person is separated by 3.57 hops away from\nanother person. As the IoT evolves, devices could also exhibit\nhuman-like social relationships. For example, devices can be\nconsidered as family if they are from the same manufacturer,\nor can be considered as colleagues if they work together to\nprovide a service. Such social aspects can therefore be used\nto intelligently navigate device discovery requests through the\ndevice social network and connect two devices in a few hops\nas the small-world exhibited by the human social network.\nBased on this motivation, we propose the Social-Aware and\nDistributed (SAND) scheme, which can achieve a scalable,\nfast and efficient device discovery in the IoT. In SAND, IoT\ndevices can autonomously establish meaningful relationships\nwith other devices, and form an overlay device social network\nin addition to their communication network. It may be faster\nand more efficient for the devices to find their desired target\ndevice by searching among their “friends” through the overlay device social network, as oppose to simply broadcasting\nthrough the communication network as the distributed scheme\nworks. In the following subsections, we will present the details\nof the SAND architecture, the device ranking criteria and the\nforwarding strategy, respectively.\nA. The SAND Architecture\nIn SAND, the IoT devices form two layers of networks,\nwhich consists of the communication network and the overlay\ndevice social network. The communication network is at the\nbottom layer, which abstracts the data communication links\nbetween the IoT devices. As long as two IoT devices are\nwithin their transmission range, a communication link exists\nbetween them. Actually, the distributed scheme introduced\nin the previous section only considers this communication\nnetwork and performs simple broadcasting for device discovery. In SAND, in addition to the communication network, an\noverlay device social network is constructed to help achieve\nan effective IoT device discovery. When two IoT devices\n\ncan communicate with each other, they can exchange their\ndevice general information, such as the manufacturer, the\nfunctionality, the ownership and the location information. In\nthe overlay device social network, there exists a link between\ntwo IoT devices if they have a valid social relation. Similar\nas human relationships, device social relationships typically\ninclude family, friends, neighbors, colleagues, and etc. Devices\nfrom the same manufacturer can be considered as family,\ne.g., an iPhone and an Apple TV. Device friendship can be\ndescribed as objects that interact frequently with one another\nand tend to share a common theme. For example, Bob’s smartphone and his body sensors are considered as friends since\nthey interact frequently and they both serve as key components\nin providing e-healthcare services. IoT devices that locate in\nthe same room or floor can be considered as neighbors. IoT\ndevices are considered as colleagues if they work together\nto provide a specific service. For example, the temperature\nsensors, the humidity sensors and the air conditioner are\ncolleagues that work together to offer a comfortable living\nenvironment in a smart home. It is worth noting that, in our\nsimulation (to be introduced in Section IV), we abstract the\ndevice general information into a number of device features,\nand there exists a social link between two IoT devices if they\nhave a common feature.\nAn illustrative example of SAND in a smart home is shown\nin Fig. 1. Here, we only show the overlay device social\nnetwork. We assume that all the devices are connected through\nWiFi, so the communication network is a complete mesh\nnetwork, which is not shown. In the overlay social network,\nthe refrigerator (E), the TV (A) and the washing machine\n(C) are connected since they are from the same manufacturer,\ne.g., Samsung. The neighbor relationship exists between the\nvacuum (B) and the washing machine (C), both of which\nlocate in the storage room. Friendship exists between (1) the\ntelephone (D) and the TV (A), and (2) the refrigerator (E)\nand the PC (F ), which are involved in frequent interactions\nto serve the home owner. The refrigerator (E), the microwave\n(G) and the boiler (H) are considered as colleagues that work\ntogether to prepare meals.\nIn SAND, when an IoT device joins the network, it will\nexchange the general information with nearby devices that\nare within the transmission range. Consequently, social links\ncan be established if valid social relationships exist. Here, we\nassume each IoT device is social-aware and intelligent in the\nsense that they can establish social relationships autonomously\nlike human. The social aspects of IoT devices give them the\nability to form an overlay device social network automatically.\nIt is worth noting that the overlay device social network is not\nstatic but dynamically changing because of the device movements or the device relationship changes (e.g., the colleague\nrelationship may change frequently). Hence, each IoT device\nneeds to periodically update their social connections in SAND.\nIn SAND, IoT devices are supposed to act as human beings.\nThe social aspects of the devices allow them to dynamically\ncreate new social connections and form new colleagueship to\nwork together to generate new services. With the social aspects\n\n\fB\n\nA\n\nC\n\nF\n\nE\n\nD\n\nH\nG\n\nFig. 1: SAND in a Smart Home\nin SAND, devices become more visible and aware to each\nother, thus leading to a fast and effective device discovery.\nIn the process of device discovery, rather than simply\nbroadcasting the discovery message to all the neighbors as\nthe distribute schemes does, SAND will send the discovery\nmessage to each of the neighbors in a preferred order based\non the the rank of the neighboring device. The higher rank the\ndevice is, the more likely and faster it is able to forward the\ndiscovery message to the target device requested by the source\ndevice. With the social aspects in SAND, devices become more\nvisible to other devices, thus making SAND more scalable and\nefficient than the baseline distributed scheme.\nB. The Device Ranking Criteria in SAND\nIn SAND, the device discovery adopts the depth-first search\nstrategy, where the discovery request is forwarded to the neighboring devices in a preferred order based on their ranks. Here,\nthe rank of a device is determined by four factors which are the\ndevice degree, the diversity, the (local) clustering coefficient\nand the (local) betweenness of the IoT device. The first three\nfactors help SAND to select a device that may reach a broad\ncommunity, while the betweenness leads the discovery request\nto a device that stands at the major intersection of multiple\nshortest paths in the network. Thus, the device ranking criteria\nmakes SAND an intelligent, accurate and fast device discovery\nstrategy. We will present the calculation details of these four\nfactors as follows.\nDevice Degree: In the overlay social network, the degree\nof device i is denoted by ki , which is defined as the number\nof social links it has. For example, in Fig. 1, device E has a\ndegree of 5 since there are five social connections associated\nwith it. The higher the device degree is, the more likely it\nis associated with a routing path to the desired target device\nsince there are more outlets from this device.\nDiversity: In SAND, the diversity of device i is denoted by\ndi , which is defined as the number of types of social links a\ndevice is associated with. For example, in Fig. 1, device E\nhas a diversity of 3 since it has three different types of social\n\nlinks which are family (i.e., links with A and C), colleagueship\n(i.e., links with G and H) and friendship (i.e., link with F ).\nAn IoT device could have a high device degree ki , but if all\nthe connections are within the same type of social relationship,\nthe device is still assigned with a relatively low rank since it is\nnot diverse enough to reach distinct communities of devices. In\ncontrast, an IoT device that has a high diversity d is involved in\nmany different types of social relations, and may have a broad\nreachability, thus having a higher chance to connect with the\ndesired target device.\nClustering coefficient: The clustering coefficient shows how\nlikely a device and its neighbors form a clique [11]. The local\nclustering coefficient of a device is defined as the number\nof the social links in its neighborhood (including the device\nitself and its one-hop neighbors) divided by the total number\nof possible links in the neighborhood. For a given device i,\nthe local clustering coefficient ci can be calculated as:\n\b\n2| est : s, t ∈ Ni , est ∈ E |\n(1)\nci =\nki (ki − 1)\nwhere est is a social link between device s and device t, Ni\nis the set of devices in the neighborhood of device i, E is\nthe set of social links in the neighborhood of device i, and\nki is the degree of device i. The higher the local clustering\ncoefficient is, the more likely the device and its neighbors are\nforming a clique (e.g., fully mesh), thus the diameter of the\ndevice neighborhood is smaller, which can lead to a faster and\nwider dissemination for the discovery request.\nBetweenness: The betweenness reflects the probability that\na given device stands at the critical intersection of multiple\nshortest paths in the network [12]. It is defined as the number\nof shortest paths that traverse the given device divided by the\ntotal number of possible shortest paths. In SAND, the local\nbetweenness measures such a probability in the neighborhood\nthat includes the given device and its one-hop neighbors. The\nlocal betweenness of device i is calculated as:\nP\ns,t∈Ni δst (i)\nbi =\n(2)\nki (ki − 1)\nwhere Ni is the set of devices in the neighborhood of device\ni, s and t are a pair of devices in Ni , and ki is the degree\nof device i. Here, δst (i) is 1 if the shortest path between s\nand t traverses through device i; otherwise, it is 0. The higher\nthe local betweenness is, the higher chance the given device is\nlocated at the intersection that connects major shortest paths\nin the neighborhood. Discovery requests that arrive at such\nintersection can be disseminated to anyplace in the network\neasily and quickly over those shortest paths.\nIn SAND, the rank of a device Ri is defined as the\nmultiplication of the above mentioned four factors (e.g., Eq.\n(3)). The higher the rank is, the more likely the device can\nforward the discovery request to the desired target device in a\nfast and efficient manner.\nRi = ki ∗ di ∗ ci ∗ bi\n\n(3)\n\n\fC. The SAND Forwarding Strategy\nBased on the architecture and the device ranking criteria\nas described above, we propose the SAND device discovery\nscheme in this subsection. Rather than the simple broadcast\nused in the distributed scheme, SAND forwards the discovery\nrequest to a neighbor device that ranks the highest. For\nexample, in Fig. 1, the discovery request from D to C will\nbe forwarded to E, which has the highest rank (with a degree\nof 5, diversity of 3, local clustering coefficient of 0.53 and\nlocal betweenness of 0.53). The device with the highest rank is\nsupposed to be the most effective one that leads to the desired\ntarget device. In the discovery process, SAND performs a\ndepth-first search with limited search depth, where the search\nwill not exhaust to the deepest level but a depth level of n\n(which is a tunable parameter). If the desired target device\ncannot be found after searching for n levels, SAND will step\nback to examine the other unchecked neighbors in depth n−1.\nThe pseudocode of SAND discovery algorithm is shown in\nAlgorithm 1.\nAlgorithm 1 The SAND Device Discovery Algorithm\nInput: A discovery request rst from source s to target t\nOutput: The communication path pst between s and t\n1: pst .push(s);\n2: while pst is not empty do\n3:\ni ← pst .pop();\n4:\nif i is the desired target device then\n5:\nreturn the reverse path of pst ;\nelse if i has been checked before then\n6:\n7:\ncontinue;\n8:\nelse if pst .length() = depth n then\n9:\ncontinue;\n10:\nelse\n11:\nrank and sort the neighbor devices Ni ;\n12:\npst .push(Ni highest rank );\n13:\nend if\n14: end while\nSimilar as the distributed scheme, SAND is scalable since\neach IoT device only maintains information of its local connections. SAND is also resilient and robust since there is no\ncentralized controller and each IoT device is fair and equal\nas a peer. Compared to the distributed scheme, SAND is\nmore efficient because the former applies simple broadcast and\nthus a significant large number of devices are involved in the\ndiscovery process, while in the latter, SAND performs depthfirst search with limited search depth and the guidance of an\nintelligent device ranking criteria, so the number of devices\ninvolved is relatively small. Such an advantage of SAND may\nlead to a low energy consumption in the process of transmitting\nthe discovery request, which is critically beneficiary to the\nIoT system where devices are power constrained. Hence, we\ncan see that SAND inherits the advantages of the distributed\nscheme, and further improves the communication efficiency.\n\nIV. P ERFORMANCE E VALUATION\nIn this section, we focus on evaluating the performance\nof the proposed SAND scheme, compared to the distributed\nscheme that uses simple broadcast. We conduct simulations\non both a random network and a scale-free network. The\nrandom network is an irregular mesh network with social links\nrandomly generated between IoT devices, while the scale-free\nnetwork is generated by considering the power law [13] in\nwhich the fraction of devices with k connections follows a\ndistribution P (K) ∼ k −γ (γ is usually between 2 and 3). It\nis meaningful and reasonable to test SAND on a scale-free\nnetwork, since most of the social networks are scale-free and\nSAND works by considering an overlay device social network.\nIn our simulation, we generate a network that consists of\n20000 IoT devices. Each IoT device is associated with a\nnumber of connections to its neighboring devices (the number\nof connections follows uniform distribution and power law in\nthe random network and the scale-free network, respectively),\nwhich forms the communication network. Each physical link\nin the communication network has a transmission latency\nuniformly distributed within [10ms, 40ms]. The distributed\nscheme only runs on this communication network. In SAND,\nfor each IoT device, we randomly generate three features. Any\ntwo IoT devices that are physically connected and share the\nsame features will be equipped with a social link, which forms\nthe overlay device social network. The total number of features\nin the network is set to vary from 2000 to 10000. For all the\nsimulation results shown below, we generate 15000 discovery\nrequests from randomly selected source devices with randomly\nchosen desired features, and obtain the average results. Each\ndiscovery request has a time to live of 60s. With regards to\nthe evaluation, we focus on three performance metrics, which\nare the success rate, the average number of devices contacted\non success and the average number of hops of the discovery\npath on success. We will present the simulation results and\nfindings in the following parts.\nA. Success Rate\nIn the simulation, if the target device with the desired feature\ncan be found before the time to live expires, it is considered as\na successful discovery; otherwise, it is considered as a failure\nand the discovery request will be dropped. The success rate\nis defined as the number of successful discovery divided by\nthe total number of discovery requests. We show the success\nrate as a function of the number of features in Fig. 2(a)\nand Fig. 2(b). Given a fixed number of IoT devices (i.e.,\n15000 by default) in the system, as the number of features\nincreases, the system become more diverse with a variety of\ntypes of devices. From Fig. 2(a), we can see that in the random\nnetwork the success rate of both the distributed scheme and\nSAND decreases as the network becomes more diverse. The\ndistributed scheme performs better than SAND since the\ndistributed scheme uses simple broadcast while SAND uses\nthe depth-first search which may yield to a long discovery\nperiod that exceeds the required time to live.\n\n\f100.00%\n\n100.00%\n\nDistributed\nBroadcast\nSAND\n\n90.00%\n\nSuccess Rate\n\nSuccess Rate\n\n90.00%\n\n80.00%\n\n70.00%\n\n80.00%\n\n70.00%\n\n60.00%\n\n60.00%\n\n50.00%\n\n50.00%\n\nBroadcast\nDistributed\nSAND\n2000\n\n4000\n\n6000\n\n8000\n\n10000\n\nNo. of Features\n(a) Success Rate in Random Networks\n\n2000\n\n4000\n\n6000\n\n8000\n\n10000\n\nNo. of Features\n(b) Success Rate in Scale-free Networks\n\nFig. 2: Simulation Results in the Random Network and the Scale-free Network\nHowever, in the scale-free network as shown in Fig. 2(b),\nwe can see that SAND achieves a similar success rate as\nthat of the distributed scheme, which is as high as more\nthan 98%. Compared to the results in the random network,\nthe success rate experiences a significant increase. This is\nprimarily because in the scale-free network there are some\nsuperhub devices that have a large number of connections,\nwhich could help the discovery request reach the target device\nin a short time. While in the random network, each device\nhas a similar node degree and the discovery request may take\na long time to reach the target, and in some bad cases the\ntime to live requirement is violated and thus failures occur.\nAnother reason is that the device ranking criteria in SAND is\neffective and can successfully navigate the discovery request\nto the desired target device. Given that most of the real-world\nsocial networks are scale-free, we can infer that SAND is a\npractically solid solution since its success rate is above 98%.\nB. Average Number of Devices Contacted\nOne of our main interests in this research is to measure,\nduring a device discovery process, how many devices are\nbeing contacted before the desired target device is found. It is\nmore energy efficient if less number of devices are involved\nin transmitting the discovery message, which is critically\nimportant for IoT system where devices are power constrained.\nFig. 3(b) and Fig. 3(b) show the number of devices contacted\nwith different number of features in the random network and\nthe scale-free network, respectively. Here, we only count the\nmeasures on successful discovery. From the simulation results,\nwe can observe that in both random and scale-free networks, as\nthe number of features increases, SAND outperforms the distributed scheme, with an average performance improvement of\n14.6% and 13.9%, respectively. It can also be seen that as the\nnumber of features increases, the performance improvement of\nSAND over the distributed scheme becomes more significant\nin both networks. This indicates that SAND is more efficient\nwhen the IoT system is more diverse and heterogeneous.\nThanks to the adoption of depth-first search and the intelligent\ndevice ranking criteria, SAND can efficiently discover the\ndesired target device without involving too many unnecessary\n\nintermediate devices. Thus, SAND can potentially achieve a\nlow energy consumption in the process of transmitting the\ndiscovery request, which is critically beneficiary to the IoT\nwhere the devices are power constrained.\nC. Communication Hops\nAnother interest in this research is to find out how many\ncommunication hops are there to separate a source device\nfrom a desired target device. After the discovery process is\ndone, the source and target devices will communicate with\neach other over the discovery path and cooperate to perform\ncomputing tasks. The post-discovery communication can be\ncost-efficient if the number of hops of the discovery path is\nsmall. In Table I and II, we show the average number of hops\nof the discovery path in the random network and the scale-free\nnetwork, respectively. It can be seen that SAND can achieve as\nsmall communication hops as that of the distributed scheme,\nthe latter of which is supposed to be the optimal one because of\nusing the breadth-first search. This finding further validates the\neffectiveness of the device ranking criteria of SAND, which\ncan intelligently navigate the discovery to the desired target\ndevice with minimum detours. We can also see that as the\nnumber of features increases, the number of hops increases in\nboth network scenarios. This is reasonable because it becomes\nmore difficult and needs more hops of query to find the\ndesired target device when the network becomes more diverse.\nComparing the results in the two tables, we can also observe\nthat from the random network to the scale-free network, the\naverage number of hops exhibits an average increase of two\nhops. The reason behind is that the random network is a\nregular mesh network where all the devices are relatively fair\nand have similar number of connections, while the scale-free\nnetwork has some superhub devices that have huge number\nof connections. In the scale-free network, a given discovery\nrequest is usually forwarded to those superhub devices first and\nthen finds a path to the desired target device, thus resulting in\na larger number of hops than that of the random network.\nFurthermore, we evaluate the distribution of devices over the\nnumber of hops of the discovery path in the scale-free network.\nAs shown in Fig. 4, we plot the device distributions for SAND\n\n\f4,000.00\n\n3,000.00\n\n2,000.00\n\n1,000.00\n\nDistributed\nBroadcast\nSAND\n\nAvg. No. of Devices Contacted\n\nAvg. No. of Devices Contacted\n\n4,000.00\n\n3,000.00\n\n2,000.00\n\n1,000.00\nBroadcast\nDistributed\nSAND\n\n0.00\n\n0.00\n\n2000\n\n4000\n\n6000\n\n8000\n\n10000\n\nNo. of Features\n(a) Avg. No. of Devices Contacted in Random Networks\n\n2000\n\n4000\n\n6000\n\n8000\n\n10000\n\nNo. of Features\n(b) Avg. No. of Devices Contacted in Scale-free Networks\n\nFig. 3: Simulation Results in the Random Network and the Scale-free Network\nTABLE I: No. of Hops in Random Networks\n\n5000\n2000\n\n2000\n\n4000\n\n6000\n\n8000\n\n10000\n\nBroadcast\n\n3.67\n\n4.16\n\n4.43\n\n4.53\n\n4.82\n\nSAND\n\n3.66\n\n4.14\n\n4.28\n\n4.40\n\n4.69\n\nTABLE II: No. of Hops in Scale-free Networks\nNo. of Features\n\n2000\n\n4000\n\n6000\n\n8000\n\n10000\n\nBroadcast\n\n5.41\n\n6.15\n\n6.37\n\n6.47\n\n6.70\n\nSAND\n\n5.41\n\n6.14\n\n6.36\n\n6.41\n\n6.69\n\n6000\n\n4000\n\nNo. of Devices\n\nNo. of Features\n\n10000\n\n3000\n\n2000\n\n1000\n\n0\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n10\n\n11\n\n12\n\n13\n\n14\n\n15\n\nNo. of Hops\n\nusing 2000, 6000 and 10000 features. The result confirms the\npast research on social networks [9][10], and shows that in\nmost of the cases any two IoT devices are separated by 5∼7\nhops. We can also observe that the average number of hops\nis small when the network is less diverse (see the center of\nthe peak of distribution with 2000 features), and the average\nnumber of hops increases when the network becomes more\ndiverse (e.g., 6000 and 10000 features). We can also infer that\nif a device cannot be discovered in a few hops, the probability\nthat the discovery is unsuccessful increases dramatically. The\nreason behind is that the unsuccessful discovery involves\ndevices that are relatively isolated from all other devices. It\nis quite common that the discovery to those isolated devices\nwill violate the time to live requirement and get dropped. In\ncontrast, the successful discovery usually involves devices that\nare in a cluster or connected to the superhubs.\nV. R ESEARCH C HALLENGES AND O PPORTUNITIES\nAn efficient IoT device discovery may lead to the generation\nof a new set of applications and services, as well as research\nopportunities, such as self-organized computing, service and\ndata fusion, malware source traceback and the formation of a\nrobot society, etc. Meanwhile, there are many open challenges\nwith regards to these applications. In the following parts, we\npropose a few research opportunities and challenges related\nto the topic of intelligent device discovery in the IoT, and\nbeyond.\n\nFig. 4: Device Distribution v.s. No. of Hops in SAND with\n20K nodes\nA. Self-Organized Computing\nThe intelligent device discovery can enable a new format of\ncomputing services that can be self-organized by a number of\nsmart devices. A client can initiate a computing task from\nany device (e.g., a smart watch), with a set of specified\nrequirements such as computing power demand (e.g., CPU\nand memory), function or platform demand, and data demand\n(e.g., source code or raw dataset). The source IoT device is responsible for deliverying these requirements to the appropriate\ncomputing facilities in the Internet and gathering the results\nback. In this case, an intelligent device discovery strategy can\nbe used to establish connections between IoT devices and the\ncomputing facilities in the Internet. For example, a user wants\nto issue a request to check his/her glucose level from the\nsmart watch. The smart watch can use the intelligent device\ndiscovery to search for the nearest server that has enough\ncomputing and memory power to perform the computing tasks.\nThen, the server may use the intelligent device discovery\nto find the source code of glucose level analyzer, and then\ndownload and install the analyzer to perform the analysis. The\nintelligent device discovery grants IoT devices and computing\nfacilities the capability to fetch the data and functions as they\nneed for performing a given computing tasks. Thus, the IoT\ndevices and computing facilities can perform the computing\n\n\ftasks in a self-organized manner.\nIn this process, one of the open challenges is how to\nstandardize the experssion of the computing requirements so\nthat the devices and machines can initiate standard requests\nthat can be understood by other machines. Another challenge\nis how to optimize the request and reply flow routes so that\nthe network resource consumption can be minimized and the\nrequest-response latency can be minimized.\nB. Computing, Network and Data Fusion\nIn the above self-organized computing scenario, a variety\nof computing facilities, network functions/services and data\n(e.g., programming source code, patient’s raw data) can be\ninterconnected and fused by running an intelligent device\ndiscovery strategy. For a given service request, the intelligent\ndevice discovery can help with gathering the computing,\nswitching and storage hardware from a specific site, while\nfetching a pool of patients’ data from a different site and\nobtaining the source codes of particular computing functions\nor network functions from another site. Here, the computing,\nswitching and storage hardware are served as placeholders,\nwhile the source codes of the computing and network functions\nand the raw dataset can be discovered and fetched by the\nintelligent device discovery strategy and served as the input\nto those hardware placeholders. Data, software and hardware\ncan be distributed in different sites, while they are coupled by\nthe intelligent device discovery approach. Hence, an intelligent\ndevice discovery strategy is promising to enable the computing, network and data fusion, and achieve an efficient communication between the fused devices. After the computing,\nnetwork and data fusion becomes true, devices and machines\ncan easily launch new services by specifying their needs to\nthe Internet. The Internet can resolve the needs in a standard\nformat (e.g., service function chains) and efficiently connect\nthose required devices and funcitons (e.g., through intelligent\ndevice discovery strategy) to provide the required new services\nspecified by the devices and machines. With the computing,\nnetwork and data fusion, it is promising to generate novel\nmachine-initiative services that are not supervised by human\nbeings. Fusion can be considered as an intermediate phase that\nprepares and enables the formation of a robot society.\nTo achieve this, an open challenge is how to develop\na platform that can address the IoT interoperability issue\nand facilitate a computing, network service and data fusion\nplatform. Another challenge is how to efficiently discover and\ndeliver the required data and source codes to the selected\nhardware sites in a timely manner such that a seamless service\ncan be provided for the users.\nC. Traceback Cyber Attack Source\nAnother application of intelligent device discovery is in the\narea of network security. The sources of malicious attacks are\nusually spoofed to avoid being detected [14]. The intelligent\ndevice discovery can be used to traceback the actual source\nof malware attacks based on the characteristics and features\nof the malicious attacks. The security protection system can\n\nissue a traceback request for the malware source generator,\nwith certain key features of the malicious traffic. The overlay\nsocial network on top of the communication network can\nbe constructed based on the model in Section 3.1. Then,\nan enhanced model that can accurately predict the hidden\nlinks/relationships between machines can be constructed using\nthe method in [15]. Machine learning or deep learning [16]\ntechniques can also be applied here to improve the accruacy\nof the prediction. After that, the proposed intelligent device\ndiscovery strategy can run on this enhanced overlay social\nnetwork (with hidden links based on prediction) to traceback\nthe malicious source attacker. Even if the malicious source\nare spoofed and hidden behind some links or relationships,\nthe intelligent device discovery can still guide the traceback\nroute based on the pattern and features of malicious attacks.\nD. Robot Society\nThe intelligent device discovery can be used to initiate the\nconnection between a given device and its desired device for\nthe first time. After the first contact, the two devices can be\nconsidered to know each other and maintain a certain type\nof social relationship as human does. As the communications\nbetween different devices continue to grow, a variety of\ncomputing service, network service and data can be fused,\nand a robot society could be formed which consists of IoT\ndevices, servers, robots and all the machines in the Internet.\nThe device relationship in the robot society can be the same as\nthe human relationship in the human society, such as friend,\ncolleague and family relationships (which are considered in\nthis paper). There is also a high chance that some unique\nmachine type of relationships may exist in the robot society.\nOne of the challenging and meaningful work is to analyze\na large dataset of network traffic data to categorize the\nrelationships between machines/devices in the Internet. This\ncan be useful to give us an insight of the relationships and\ncommunication purpose between machines. It is also helpful\nfor us to formulate the foundamental rules of how to establish\nthe social relationship between machines/devices. Another\nopen challenge is how to ensure the security of the connection\nbefore the two machines/devices establish their social relationship. It is necessary to avoid establishing relationships with\npotential malicious devices. To achieve this, we may need\nto develop machine learning based solutions (e.g., decision\ntree classification, convolutional neural networks or recurrent\nneural networks) to train the machines/devices to identify their\nown roles and their contact’s roles in the robot society, to\nreduce the chance of establishing connections with malicious\ndevices. In general, a promising research area is to investigate\nthe social behavior and the collaborative intelligence in the\nrobot society, in addition to the artificial intelligence in a single\ndevice/machine.\nVI. C ONCLUSION AND F UTURE W ORK\nThe Internet of Things (IoT) grows continuously and connects billions of smart devices with heterogeneous functionalities, purposes and platforms. As the IoT evolves, it\n\n\fis promising that human-like social relationships could be\nautonomously established by the smart devices. With the\nhelp of an intelligent device discovery strategy, IoT devices\ncan easily discover the resources (e.g., source codes) and\ndevices (e.g., computing facilities) that meet their needs. Each\ndevice/machine is associated with one or more resources\nor capabilities of either computing power, network function,\nsource code or data. The intelligent device discovery can be\nused to glue and couple the resources from distributed sites\nto achieve the computing, network service and data fusion.\nEach device/machine acts like a robot and can establish social\nconnections with each other autonomously to collaborate and\ncreate new applications and services, which could eventually\nlead to the formation of a robot society. The goal of this\nresearch is to address the impending scalability issue in\nthe process of device discovery in IoT. In this paper, we\nhave proposed a novel approach that leverages such social\naspects of IoT devices to achieve a scalable and efficient IoT\ndevice discovery. The proposed Social-Aware and Distributed\n(SAND) scheme applies the depth-first search and forwards\nthe discovery request to neighboring devices in a preferred\norder defined by a novel social network-aware device ranking\ncriteria. More specifically, the ranking criteria takes into consideration the device’s degree, diversity and clustering coefficient, which could potentially navigate the discovery request to\nreach a broad community. Furthermore, the local betweenness\nis considered in the ranking criteria, which prioritizes the\ndevices that stands at the critical intersections of multiple\nshortest paths of the network. With the guidance of such an\nintelligent device ranking criteria, the discovery request can\nfind the desired target device in a fast and efficient manner.\nWe have conducted comprehensive simulations to validate the\neffectiveness of SAND on both a random network and a\nscale-free network. Simulation results have shown that SAND\ncan achieve the near-optimal success rate and communication\nhops as that of the distributed scheme which uses broadcast.\nIn addition, we have found that the SAND scheme contacts\na much smaller number of intermediate devices than that\nof the distributed scheme during the discovery process, thus\npotentially leading to a much less energy consumption.\nAs for future work, we plan to extend our study in the following aspects. First, we plan to extend SAND with multicast\nfeature, which allows one discovery request to fetch multiple\nreplies. This could be useful in wireless sensor network\napplications, such as in the temperature monitor system. In\naddition, rather than specifying only one feature of the desired\ntarget device, we can enhance the SAND scheme by allowing\nit to claim for multiple features to achieve a more accurate\ndiscovery. We also plan to implement SAND on a physical\ntestbed and conduct experimental studies. Secondly, we plan\nto analyze various network traffic datasets to understand the\nmeanings and purposes behind those communications, and we\ncan use machine learning techniques to categorize the social\nrelationships in the IoT. This can be used to further improve\nthe discovery speed and the discovery accuracy of SAND,\nand can also provide the basic insights for exploring the\n\nformation of the robot society. Thirdly, we plan to investigate\nthe interoperability issues in the IoT and explore a standard\nplatform that enables a variety of computing, network service\nand data fusion.\nR EFERENCES\n[1] A. Zaslavsky and P. P. Jayaraman, “Discovery in the internet of things,”\nin ACM Ubiquity Magazine, October 2015, Article No. 2.\n[2] G. Sun, V. Chang, G. Yang and D. Liao, “The cost-efficient deployment of\nreplica servers in virtual content distribution networks for data fusion,” in\nInformation Sciences (2017), http://dx.doi.org/10.1016/j.ins.2017.08.021\n[3] G. Sun, D. Liao, D. Zhao, Z. Sun, V. Chang, “Towards\nprovisioning hybrid virtual networks in federated cloud data\ncenters,” in Future Generation Computer Systems, 2017,\nhttps://doi.org/10.1016/j.future.2017.09.065\n[4] C. Li, F. Darema and V. Chang, “Distributed behavior model orchestration in cognitive internet of things solution,” in Journal of Enterprise\nInformation Systems, 2017, pp. 1-21.\n[5] P. Barnaghi and A. Sheth, “On searching the internet of things: requirements and challenges,” in IEEE Intelligent Systems, vol. 31, no. 6, 2016,\npp. 71-75.\n[6] P. C. Ccori, L. C. De Biase, M. K. Zuffo and F. S. Da Silva, “Device discovery strategies for the IoT,” in Proc. of IEEE International Symposium\non Consumer Electronics, 2016, pp. 97-98.\n[7] W. T. Lunardi, E. De Matos, R. Tiburski, et. al., “Context-based search\nengine for industrial IoT: discovery, search, selection and usage of\ndevices,” in Proc. of IEEE Conference on Emerging Technologies and\nFactory Automation, 2015, pp. 8-11.\n[8] L. Dong, R. Ravindran and G. Wang, “ICN based distributed IoT resource\ndiscovery and routing,” in Proc. of IEEE International Conference on\nTelecommunications, 2016, pp. 1-7.\n[9] J. Travers and S. Milgram, “An experimental study of the small world\nproblem,” in Sociometry, vol. 32, no. 4, 1969, pp. 425-443.\n[10] S. Edunov, C. Diuk, I. O. Filiz and S. B. Burke, “Three and a half degrees\nof separation,” 2016. [Online]. Available: https://research.fb.com/threeand-a-half-degrees-of-separation.\n[11] D. J. Watts and Steven Strogatz, “Collective dynamics of small-world\nnetworks,” in Nature, vol. 393, June 1998, pp. 440-442.\n[12] M. E. J. Newman, “Networks: an introduction,” Oxford University Press,\n2010, ISBN 978-0199206650.\n[13] A. Barabsi and R. Albert, “Emergence of scaling in random networks,”\nin Science, vol. 286, 1999, pp. 509-512.\n[14] Zhen Ling ; Junzhou Luo ; Kui Wu ; Wei Yu ; Xinwen Fu, “TorWard:\nDiscovery, Blocking, and Traceback of Malicious Traffic Over Tor,” in\nIEEE Transactions on Information Forensics and Security, vol. 10, no.\n12, pp. 2515-2530, 2015.\n[15] Berlusconi G, Calderoni F, Parolini N, Verani M, Piccardi\nC, “Link Prediction in Criminal Networks: A Tool for\nCriminal Intelligence Analysis,” in PLoS ONE 11(4): e0154244.\nhttps://doi.org/10.1371/journal.pone.0154244\n[16] R. Chauhan, H. Kaur and V. Chang, “Advancement and applicability of\nclassifiers for variant exponential model to optimize the accuracy for deep\nlearning,” in Journal of Ambient Intelligence and Humanized Computing,\n2017, pp. 1-10.\n\n\f",
         "train",
         "51381",
         "8215"
        ],
        [
         "9",
         "17861",
         "cs.AI",
         "Artificial Intelligence",
         "1709.05047v1.pdf",
         "Disentangled Variational Auto-Encoder for Semi-supervised Learning\nYang Li∗1 , Quan Pan1 , Suhang Wang3 , Haiyun Peng2 , Tao Yang 1 , and Erik Cambria2\n1\n\narXiv:1709.05047v1 [cs.LG] 15 Sep 2017\n\n2\n\nSchool of Automation, Northwestern Polytechnical University\nSchool of Computer Science and Engineering, Nanyang Technological University\n3\nDepartment of Computer Science and Engineering, Arizona State University\n\nAbstract\n\nfor semi-supervised learning, the semi-supervised VAEs are typically composed of three main components: an encoder network qφ (z|x, y), a decoder pθ (x|y, z) and a classifier qφ (y|x).\nIn the application, the encoder, decoder and classifier can be\nimplemented using various models, e.g., MLP or CNN networks [19, 34]. Though the classifier plays a vital role in achieving the semi-supervised goal, it introduces extra parameters of\nitself to learn. With the limited labeled data, it may not be an\noptimal choice to introduce more parameters to VAE for semisupervised learning because it may memorize the limited data\nwith large quantities of parameters, namely overfiting.\n\nIn this paper, we develop a novel approach for semi-supervised\nVAE without classifier. Specifically, we propose a new model\ncalled SDVAE, which encodes the input data into disentangled\nrepresentation and non-interpretable representation, then the category information is directly utilized to regularize the disentangled representation via equation constraint. To further enhance\nthe feature learning ability of the proposed VAE, we incorporate\nreinforcement learning to relieve the lack of data. The dynamic\nframework is capable of dealing with both image and text data\nwith its corresponding encoder and decoder networks. Extensive Therefore, in this paper, we investigate if we can directly incorexperiments on image and text datasets demonstrate the effective- porate the limited label information to VAE without introducing\nness of the proposed framework.\na classifier so as to achieve the goal of semi-supervised learning and at the same time to reduce the number of parameters to\nbe learned. In particular, we investigate the following two challenges: (1) Without introducing classifier, how do we incorpo1 Introduction\nrate the label information to VAE for semi-supervised learning?\nand (2) How can we effectively use the label information for representation learning of VAE? In an attempt to solve these two\nThe abundant data generated online every day has greatly ad- challenges, we propose a novel semi-supervised learning model\nvanced machine learning, data mining and computer vision com- named Semi-supervised Disentangled Variational Auto-Encoder\nmunities. However, manual labeling of large dataset is very time (SDVAE). SDVAE adopts the VAE with KKT conditions as it\nand labor consuming. Sometimes it even requires domain knowl- has better representation learning ability than VAE. Unlike exedge. All the above results the majority of the data with limited isting semi-supervised VAEs that utilize classifiers, SDVAE enlabels. Therefore, semi-supervised learning, which utilizes both codes the input data into disentangled representation and nonlabeled and unlabeled data for model training, is attracting in- interpretable representation, and the category information is dicreasing attention [4, 22, 14, 33]. Existing semi-supervised mod- rectly utilized to regularize the disentangled representation as an\nels can be generally categorized into those categories, i.e., dis- equation constraint. As the labeled data is limited, the labeled\ncriminative model, generative model, graph-based model and the information may not affects the model much. To remedy this,\ncombined model with those categories [29, 5, 9, 23, 31].\nwe further change the equation constraints into the reinforcement\nAmong various semi-supervised models proposed, the semi- learning format, which helps the objective gain the category insupervised generative models based on variational auto-encoder formation heuristics. The inverse auto-regression (IAF) is also\nhave shown strong performance in image classification [14, 19] applied to improve the latent variable learning. The proposed\nand text classification [33]. The effectiveness of VAE for semi- framework is flexible in which it can deal with both image and\nsupervised learning comes from its efficiency in posterior dis- text data by choosing corresponding encoder and decoder nettribution estimation and its powerful ability in feature extract- works. The main contributions of the paper are:\ning from text data [2] and image data [14, 19]. To adapt VAE\n\n• Propose a novel semi-supervised framework which directly\nexploits the label information to regularize disentangled rep-\n\n∗ liyangnpu@mail.nwpu.edu.cn\n\n1\n\n\fthe RCE, namely maxθ,φ Eqφ (z|x) log pθ (x|z) [6]. Then the objective function is changed with the inequation constraints:\n\nresentation with reinforcement learning;\n• Extract the disentangle variable for classification and the\nnon-interpretable variable for the reconstruction from the\ndata directly; and\n\nmax Eqφ (zi |x) log pθ (x|z)\nθ\n\n(4)\n\nsubject to KL(qφ (z|x)||pθ (z) < \u000f)\n\n• Conduct extensive experiments on image and text datasets Using KKT conditions [1], Eq.(4) can be rewritten as follows:\nto demonstrate the effectiveness of the proposed SDVAE.\nL̂(θ, φ; x, λ) = Eqφ (z|x) log pθ (x|z)\n(5)\n− λ(KL(qφ (z|x)||pθ (z)) − \u000f)\n\n2\n\nPreliminaries\n\nwhere λ > 0 is the Lagrangian multiplier, which is used to penalize the deviation of the constraint KL(qφ (z|x)||pθ (z)) ≤ \u000f.\nGiven that λ > 0 and \u000f > 0, we have\n\nIn this section, we introduce preliminaries that will be useful to\nunderstand our model.\n\nL̂(θ, φ; x, λ) ≥ Eqφ (z|x) log pθ (x|z) − λKL(qφ (z|x)||pθ (z))\n(6)\nIf λ = 1, then Eq.(6) reduces to the original variational autoencoder problems that proposed by Kingma [16]. However, if\n2.1 Variational Auto-Encoder\n0 < λ < 1, then L̂(θ, φ, λ; x) > L(θ, φ, λ; x), which is closer\nto the target log pθ (x). This is just the mathematical description\nVariational Auto-Encoders (VAEs) have emerged as one of the\nof the fact that the more information in the latent variable z, the\nmost popular deep generative models. One key step of VAE is to\ntighter of the lower bound is. Through the KKT condition, a loose\nevaluate pθ (x), which can be interpreted as\nconstraint over the decoder is introduced. Empirical results show\nlog pθ (x) = KL(qφ (z|x)||pθ (z|x)) + L(θ, φ; x)\n(1) that VAE with KKT condition performs better than original VAE.\nThus, in this paper, we use VAE with KKT condition as our basic\nwhere KL(Q||P ) is Kullback-Leibler divergence between two model.\ndistributions Q and P and L(θ, φ; x) is the evidence lower bound\n(ELBO). It is defined as\nL(θ, φ; x) = Eqφ (z|x) (− log qφ (z|x) + log pθ (x, z))\n\n2.3\n\n(2)\n\nWhen there is label information y in the observed data, it is easy\nto extend Eq.(6) to include label information as follows [14].\n\nThe term qφ (z|x) is to extract latent feature from the observed data x and it is called encoder generally. By minimizing KL divergence, we try to find qφ (z|x) that can approximate the true posterior distribution pθ (z|x). Because\nL(θ, φ; x) is non-negative and log p(x) is fixed, then minimizing KL(qφ (z|x)||pθ (z|x) is equivalent to maximizing L(θ, φ; x).\nWe can rewrite L(θ, φ; x) as\n\nL̂(θ, φ; x, y, λ) ≥ Eqφ (z|x,y) log pθ (x|z, y)\n+ λ(log p(y) + log p(z) − log qφ (z|x, y))\n\n(7)\n\nTo achieve the semi-supervised learning, [14] introduce a classifier qφ (y|x) to Eq.(7), which results in\nX\nU (θ, φ, y; x, λ) =\nqφ (y|x)(L̂(θ, φ; x, y, λ)) + H(qφ (y|x))\n\nL(θ, φ; x) = Eqφ (z|x) log pθ (x|z) − KL(qφ (z|x)||pθ (z)) (3)\n\ny\n\nwhere the first term in the RHS of Eq.(3) is the reconstruction\nerror (RCE), and the second term in the RHS is the KL divergence\nbetween the prior and the posterior (KLD). Those two values play\ndifferent roles during the approximation. We will introduce them\nin details in the next section.\n\n2.2\n\nSemi-supervised VAE\n\n(8)\nApart from the Eq.(7) and Eq.(8), the classification loss over the\nlabel information Ep(x,y) (log qφ (y|x)) is added into the objective\nfunction when facing with the labeled data. However, in this paper, the discriminative information is added from scratch and an\nequation constrained VAE is proposed, in order to highlight the\ncontribution of labeled data.\n\nVAE with KKT Conditions\n\nIn practice, we find that the RCE is usually the main error, while 3 The Proposed Framework\nthe term of KLD is regarded as the regularization to enforce\n(qφ (z|x)) to be close to pθ (z|x), which is relatively small. If\nwe constrain the KL divergence term into a small component \u000f to In this section, we introduce the details of the proposed framegain a tighter lower bound, the goal is transformed to maximize work. Instead of using a classifier to incorporate the label infor2\n\n\f3.2\n\nmation, we seek to directly use label information to regularize the\nlatent representation so as to reduce the number of parameters.\n\nSDVAE-I\n\nThe first way we consider is the cross entropy between y and v,\ni.e.,\nU = y log qφ (v|x)\n(11)\n\n3.1\n\nDisentangled Representation\n\nwhere y is the observed label information, qφ (·) is encoder for\nthe disentangle variable v. This is a popular loss function for\nsupervised learning and doesn’t introduce any new parameters.\nTherefore, we choose this as the loss function for regularizing the\ndisentangled variable v. We name this method Semi-supervised\nDisentangled VAE (SDVAE-I). By adding this loss function to\nEq.(10), the objective function of SDVAE-I is given as:\n\nIn order to incorporate the label information to the latent representation, we assume that the latent representation can be divided\ninto two parts, i.e., the disentangle variable and non-interpretable\nvariable. The disentangle variable captures the categorical information, which can be used for prediction task. Therefore, we\ncan use label information to constrain disentangled variable. The\n(12)\nL̂(θ, φ; x, λ, u) ≥ RE(z,v) − λ(KLz + KLv ) + µU\nnon-interpretable variable can be vectors comprised of any dimensions that combine other uncertain information from the data. µ is the weight parameter. When there is no labeled data, the\nFor the simplicity of notation, we use v to denote the disentan- equation condition will be U = 0.\ngled variable and z to denote the non-interpretable representation. With v and z, the encoder can be rewritten as qφ (v, z|x).\nWe further assume that the disentangled variable and the non3.3 SDVAE-II\ninterpretable variable are independent condition on x, i.e.,\n\nThe drawback of the SDVAE-I is obviously, because the training\nresults depend on the number of the labeled data heavily. However, for semi-supervised learning, there is usually a small size\nof the labeled data available. Thus, it is hard for the disentangle\nIt is a reasonable assumption, because given x, the categorical variable to capture the category information. To remedy this, we\ninformation is only dependent on x and thus v, which captures the got inspired by the idea in [33]. The equation constraints can be\ncategorical information, is independent of z given x. This means expressed by the reinforcement learning, in which ELBO can be\nthere are seldom information about the category information in seen as the reward of the equation constraint. The disentangle\nz, which is validated in the experiment part.\nvariable v acts as the agent which decides the output category\nNow qφ (z|x) is the encoder for the non-interpretable representa- information. This can be seen in Eq.(14). Finally, a constant\ntion, and qφ (v|x) is the encoder for the disentangle representa- number c is added to act as the bias. The parameter µ is changed\ninto as followed:\ntion. Based on those assumptions, Eq.(7) is written as:\nqφ (v, z|x) = qφ (v|x)qφ (z|x)\n\n(9)\n\nµ = RE(z,v) − (KLz + KLv ) + c\nL̂(θ, φ; x, λ) ≥ Eqφ (z|x),qφ (v|x) log pθ (x|z, v)\n+ λ(log p(v) + log p(z) − log qφ (z|x) − log qφ (v|x))\n\n(13)\n\nThe partial update of this part is as followed:\n\n(10)\n\n∆φ = v(L + c)∇φ log qφ (v|x)\n\n= RE(z,v) − λ(KLz + KLv )\n\n(14)\n\nWhere L denotes the RE(z,v) − (KLz + KLv ).\n\nwhere RE(z,v) = Eqφ (z|x),qφ (v|x) log pθ (x|z, v), which represents the reconstruction error given the variable (z, v). KLz and\nKLv denote the KL(qφ (z|x)||p(z)) and KL(qφ (v|x)||p(v)) respectively. From the above equation, we can see that the categorical information is extracted from the data, i.e., captured in\ndisentangled variable v. Now if we have partial labels given, we\ncan directly use the label information to regularize v.\n\nHowever, those terms only take effect over the labeled data. To\nmake up for this drawback, another term of log-likelihood expectation on disentangle variable v is added as the information entropy in Eq.(12), and this will be calculated both in labeled data\nand the unlabeled data. It helps to reduce the large variance of the\ndisentangle information. Then the objective function in Eq.(12)\nis changed into Eq.(15).\n\nWith v capturing the categorical information, there are many\nways to regularize v. Inspired by the work of [6], we add equation\nL̂(θ, φ; x, λ, c) ≥ RE(z,v) − λ(KLz + KLv )\n(15)\nconstraints on v over the ELBO, where the equation constraint is\n+ y(β1 L + c) log qφ (v|x) + β2 H(qφ (v|x))\nto enforce the disentangled representation v to be close to the label information y. In this work, we consider two ways to add the where y is the label information, β1 and β2 are the coefficient\nconstraint over the ELBO as discussed below.\nparameters, and we name this model SDVAE-II.\n3\n\n\f3.4\n\nWith Inverse Autoregressive Flow\n\nthe same time are from both the labeled data and the unlabeled\ndata. Furthermore, we assume that these two variables are independent. However, it is not the same in the previous works, they\nonly extract the latent variable z from the data. When there is\nno label information, label variable y infers from the x with the\nshared parameters from qφ (z|x) or infers from z directly.\n\nBecause the two different latent variables are extracted from\nthe data directly, to make the posterior inference more flexible\nand enhance the ability in disentangle representation in highdimension space, the inverse autoregressive flow (IAF) [35] is\napplied in SDVAE-I and SDVAE-II. The chain is initialized with\nthe output µ0 and δ0 from the encoder. Together with the random sample ε ∼ N (0, I), the latent variable z is calculated as\nz0 = µ0 + δ0 ⊗ ε. The way to update IAF chain is the same as\nthat in the LSTM shown in Eq.(16).\n\nThen, based on different assumptions, there are differences with\nthe previous works in mathematics. The ELBO with two independent latent variable inferences is written as Eq.(10), and it is\ndifferent from that in Eq.(7) who only has one latent variable z\ninference. Furthermore, if we ignore the assumption difference,\nzt = δt ⊗ zt−1 + µt\n(16) when facing with the labeled data in previous works, their objective function is a special case in Eq.(15) when β1 = β2 = 0.\nwhere (δt , µt ) are the outputs of the auto-regression neural networks, whose input is the last latent variable zt−1 , and t is the When the label is missing, previous works apply the marginal\nflow length.\nposterior inference over the label information which is shown in\n\n3.5\n\nEq.(8). In this paper, it is the inference for both latent variable\ninference over the z and v, and this is shown in Eq.(17).\n\nTraining of SDVAE\n\nU (x) = RE(z,v) − λ(KLz + KLv ) + β2 H(qφ (v|x))\n\n(17)\n\nThe models can be trained end-to-end using mini-batch with the\nADAM optimizer [13]. The training algorithm is summarized in\nAlgorithm 1. In Line 1, we initialize the parameters. From Line\n4 Experimental Results\n3 to Line 5, we sample a mini-batch to encode the input data as\nz and v. From Line 6 to Line 10, we apply IAF. We then update\nthe parameters from Line 11 to Line 13.\nIn this section, we conduct experiments to validate the effectiveness of the proposed framework. Specifically, we want to anAlgorithm 1 Training algorithm of the proposed models.\nswer the following questions: (1) Is the disentangled representa1: Initialize the parameters \u000f, φ, θ\ntion able to capture the categorical information? (2) Is the non2: repeat\ninterpretable variable helpful for the data reconstruction? (3) Is\n3:\nx ← Sample a miniBatch from the datapoints\nthe proposed framework effective for semi-supervised learning?\n4:\n\u000f ← Random sample from the noise distribution\nTo answer the above questions, we conduct experiments on im5:\nz, v ← qφ (z, v|x, \u000f)\nage and text datasets, respectively.\n6:\nif IAF then\n7:\nfor t < T do\n8:\nẑ ← iaf (z, θ)\n4.1 Experiments on Image Datasets\n9:\nend for\n10:\nend if\n4.1.1 Datasets Description\n11:\nx̂ ← pθ (x|ẑ, v)\n12:\ng ← 5θ,φ L̂(θ, φ; x, λ, c)\nCalculate the gradients of Eq.(15) for SDVAE-II, and Eq.(12) for For image domain, we choose two widely used benchSDVAE-I.\nmark datasets for evaluating the effectiveness of SDVAE, i.e.,\n13:\n(θ, φ) ←Update with gradients g\nMNIST [18] and SVHN [21]. In the MNIST, there are 55,000\n14: until model convergence\ndata samples in the train set and 10,000 data samples in the test\nset. In the SVHN, there are 73,257 data samples in the train set,\nand 26,032 data samples in the test set. Both datasets contain 10\ncategories.\n3.6 Discussion\nThe differences between the previous work [14, 33] and our work\n4.1.2\nwill be discussed in this section.\n\nModel Structure\n\nFirstly, the assumptions are different. In this work, we assume For the image data, the encoder is a deep net composed of two\nthat the disentangle variable v and non-interpretable variable z at convolutional layers followed by two fully connected layers. The\n4\n\n\fTable 1: The classification errors on the MNIST data with part of labeled data\nModels\nNN\nCNN\nTSVM\nCAE\nMTC\nAtlasRBF\nSemi-VAE(M1)+TSVM\nSemi-VAE(M2)\nSemi-VAE(M1+M2)\nSDVAE-I\nSDVAE-I&IAF\nSDVAE-II\nSDVAE-II&IAF\n\n([14])\n\n600\n11.44\n7.68\n6.16\n6.3\n5.13\n5.72(±0.05)\n4.94(±0.13)\n2.59(±0.05)\n2.75(±0.11)\n2.74(±0.06)\n2.49(±0.10)\n1.97(±0.14)\n\nECVAE-I\nconvolutional layers are used to extract features from\nthe images\nwhile the fully connected layers are used to convert the features to\nthe non-interpretable variable and the disentangle variable. The\ndecoder is a network composed of two fully connected layers to\nmap the latent features back to images. Dropout [26] is applied\nto both the encoder and decoder networks.\n\n4.1.3\n\n1000\n10.07\n6.45\n5.38\n4.77\n3.64\n3.68(±0.12)\n4.24(±0.07)\n3.60(±0.56)\n2.40(±0.02)\n2.42(±0.08)\n2.24(±0.08)\n1.96(±0.09)\n1.29(±0.11)\n\n3000\n6.04\n3.35\n3.45\n3.22\n2.57\n3.49(±0.04)\n3.92(±0.63)\n2.18(±0.04)\n1.70(±0.09)\n1.33(±0.09)\n1.58(±0.09)\n1.00(±0.05)\n\nSDVAE-I\nECVAE-I&IAF\n\nSDVAE-I&IAF\n\nSDVAE-II\nECVAE-II&IAF\n5555555555 5\n\nSDVAE-II&IAF\n3333 3\n\n00\n0\n888888888888\n000000000 00\n88888888888888888\n6\n6666 66666 00000\n666 2 2222222 2\n666666666666666666 666\n88888888888888\n6\n0\n6 2 2 22\n666 6666\n000 0\n8\n666 666666666 666666\n0 00 0\n6\n6\n8\n0000000 0 00000 6 222222 2 222222222222222\n6\n8888888\n6\n8\n4\n666666666 66666 6\n6666666666 6666 66 6\n00 00\n8 88 8 8\n2\n0\n2\n000 00 0000\n0\n2\n2\n0\n2\n6\n6\n6\n6\n2\n4\n2\n2\n0\n0\n6\n0\n2\n2 22\n8\n0 0\n6 66 66666666\n4 6 6666666 6666666\n4 4\n888888 0000000 000\n2 2222 2 2 2222\n4444444 4444444444444444\n6 666\n000 00 0\n6\n8\n4 444 44\n2222 2 2 22 2\n0\n2 2222 222 2 2 22\n44444444444444444444444 444\n4\n4\n2\n2\n4\n2\n2\n9\n4\n2\n2\n4444 444\n4\n4 44 444 44\n11111111111\n00000 00000\n2\n9\n0 00000000000000 0000 0\n4\n55 8\n1 611 1 111111\n222222222222222222\n1 111 1111\n8 88888 88 8888 888\n44 4 444\n0 0 000 00\n2 2222222 2222222221 2\n00000000000 00000000000000\n1111 1111 1\n88 888888 8 888 88 888 5 555\n4444 444444444444 44 4\n33 3333 33333\n1\n2\n7\n2\n2\n2\n2\n2\n7\n3\n0\n8 8 8888 88888888 88 8\n0\n55\n1 11 111 1\n0 0000\n32222 222222222222222\n444 444 5 3 3 3 33333333 3\n8\n88888 8888\n555 5 55\n911 1 111111111111\n2 2 27222\n3 3 333 33 3333 33 3\n8 55555555\n8\n3 33333333 3333333333 53 555 55 55 5555555\n55 555 555\n00\n30 2 7 7777\n3 33 3\n55 555 5 5\n9999 9\n7\n5\n9\n7\n7\n5\n5\n7\n3\n3\n7 777 7\n44444\n9999999 999 9\n99 9\n3\n33\n7777777777777 77\n444 44 4\n4\n4 4 4 999999999999999999999999999 9\n555555555 55555 5\n44 4 4 44\n077777777777777\n99999494 99 9 99999 9 9 99\n55 5 5 5 555\n3\n11111\n9999 9 9 9\n4\n9\n9\n55555555555555 555555555555555\n39 7777777777777 9797\n9\n9 9999 9\n1111111111111 99\n44 4 9 99 99 9999999 9 99 9\n7\n7\n5 55\n7\n7\n1\n7\n7\n7\n77\n9 9 9 99 9 9 9\n11 1 111 1 1 5\n55555 55 5\n77 27\n1 1\n999949 9999999 9999 9 9999\n7\n99 9\n1 11111111111111\n77 777 7777 797 7 7\n3\n11111 111 1 1\n3\n3\n3\n3\n3\n3\n777777 777 77777 777777777 7\n1\n3\n3\n1 111111 1\n3 3333333 333 3\n9\n5\n1 111 11 1\n77777 77777777 77777777777777777\n33333 33333333333 33333\n11111111111 11\n7 7 7 77 77 7 7 77\n333 3333 333333333 3333333\n1 111111 1\n33 3\n\nDisentangle Representation\n\nECVAE-II\n\n35 55 5 555 55\n5 3 55 5555555555555555\n5 55555555555\n9\n5 55555555\n3\n3\n3 3\n5 565\n33333333333333333 3593\n6\n6\n33333 3333333 33333333\n8\n8\n8888 8\n333 3333 33\n9\n88888888888 8888\n8\n3 333333 333333\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n88 888 88 888 89\n3 33333 3\n5 66 6\n9\n8\n8\n8\n8\n8\n8\n6\n4\n66 6\n8888888888888 8\n3\n9\n444 444\n666 666666 6\n8 88888888\n8 8\n66666 6 66 6 6\n44 44 44\n8\n44 44444444 444\n6 6666 66 6\n77\n444444444444444444 4444 6 666666666 666 66666666\n7\n7\n9\n7\n6 66666666666\n444444444 444\n77777777777 77\n4\n9 77777 7777 77777777777\n1\n6\n111\n9\n7777777777777777777777\n1\n1\n7\n1\n1\n1 11\n77777777 77 7\n3\n111111111 11111111111111\n7\n0000\n777 772\n111111111111\n00 000000000000000 00009\n8 32\n0 00000 0 000 000000\n111111\n0000006 000000\n1 111111111\n22 22\n00 0000000 00\n2\n1 11111111 1\n02000000\n2222 22222222 22 2 2\n1 11\n2222222222 2222222222222222222\n2222 222222 2 22 2\n22 4\n2 222222 2222\n22\n99999 99999\n99 9999\n99999999999999999\n9999999999999999999\n\nThe first experiment is to explore how the disentangle variable v\nand non-interpretable variable z perform in the image reconstruction. The experiment is conducted on the MNIST dataset. In the\ntraining data, we randomly select 3000 data samples as labeled\ndata and the remainings are unlabeled. The dimension of the disentangle variable v is 10 which is same as the category number,\nand the dimension of z is 50.\nWe first train the model to learn the parameters. Then we use the\ntrained model to learn latent representation on the test data. After\nlearning the representations, we mask v and z in turn to see how\nthey affect the reconstruction of the input image. Two sample\nresults are shown in Fig.1. We also use t-SNE [28] to visualize v\nof the testing data. The results from those four models (SDVAEI, SDVAE-I&IAF SDVAE-II and SDVAE-II&IAF) are shown in\nFig.2.\n\n33333333333333\n33333333333 333\n33 33333333333 33333333 3\n3 3333333\n93\n3\n\n6666 666666666666\n6 6666666666666666666666\n6 6666666666 64\n6666 66 66666\n6 66\n6\n22 2\n2 222 222222222 222\n2222222222222222222 2222222 2\n22222222 2222222 22222222\n2 22222222222 24\n2\n2222\n\n88888 8 8\n88888888 8888888\n88888888888888888888888\n88\n888888888888888\n9 99\n9 999999999\n99 9999 9999\n99 9999999999999999999999\n9 999999 99999\n\n11 11 11\n11111111111111111111111111119\n1111111111111 11111 1111111\n1111 1111111111111\n1\n\n0\n0000000000000000\n00 00000000000000000\n00000000000000000000\n0\n00 00 08\n00\n\n4 4444444 444 4\n4 44 4 444\n8 444444444444444444444444444\n44444 4\n4\n\n7\n77777777777777777777777\n7777777 77777777\n777777777777777777777777\n777\n7 777777777777\n\n5 5\n5555 55 5 55555\n555 55555555555555555555 555555555\n55555555555555\n55555\n\nFigure 2: The t-SNE distribution of the latent variable v from\nproposed models, and different categories are in different colors\nwith number.\n\nv mainly captures the categorical information, and it has little\ninfluence over the reconstruction task. More specifically, from\nFig.2, we can see that images of the same class are clustered\nMask z\nMask v\ntogether, implying that the disentangled representation captures\nthe categorical information. In addition, we find that cluster\nSDVAE-I gives the worst visualization as clusters have intersections, while SDVAE-I&IAF and SDVAE-II&IAF give better\nFigure 1: The first row in left figure and the right figure are the visualization, which suggests that SDVAE-I&IAF and SDVAEreconstruction images with the variable z and variable v masked II&IAF are better at capturing the categorical information.\nrespectively, and the images in the second row in both figures are\nFrom Fig.1, we can see that when v is masked, z still reconstructs\nthe test images original.\nthe input image well, indicating that z is appropriate for reconstruction. To explore how variable z takes effect in the image\nFrom Fig.1 and Fig.2, we can see that the disentangle variable reconstruction, we range a certain dimension of z from -2 to 2\n5\n\n\f4.2 Experiments on Text Dataset\n\non the specific labeled image, and the selected results are shown\nin Fig.3. From the image, we can see that z can control differ3\n\n4\n\n3\n\n0\n\n4.2.1\n\nDataset Description\n\nTo test the model on text data, the IMDB data [20] is used. This\ndataset contains 25,000 train samples and 25,000 test samples in\ntwo categories.\nFigure 3: The reconstruction images by varying z in a certain\ndimension.\n4.2.2 Model Structure\nent properties in image reconstruction with different dimensions,\nsuch as italic controlling, bold controlling, transform control, and\nIn the application of the text data, the encoder is also the conthe style controlling, etc. These can be seen from images in Fig.3\nvolutional neural networks, but different from the case in image\nleft to right.\ndata, there are two convolutional neural networks which are referring from [12] parallelized together. One is extracting the feature\nat the word level, and the other is extracting the feature at the\n4.1.4 Semi-Supervised Learning\ncharacter level. As to the decoder, we applied the conditioned\nLSTM [32], which is given as follows:\nFurthermore, we conduct experiments to test the proposed models in semi-supervised learning on MNIST. We randomly select\nft = σ(Wf [z; v] + Uf ht−1 + bf )\nx points from the training set as labeled data, where x is varit = σ(Wi [z; v] + Ui ht−1 + bi )\nied as {600, 1000, 3000}. The rest training data are used as unot = σ(Wo [z; v] + Uo ht−1 + bo )\nlabeled data. We compare with state-of-the-art supervised and\n(18)\nsemi-supervised classification algorithms, which are used in [14].\nIt = Wc [z; v] + Uc ht−1 + bc\nThe experiments are conducted 10 times and the average accuct = ft ⊗ ct−1 + it ⊗ σ(It )\nracy with standard deviation are showed in Table 1. Note that\nht = ot ⊗ relu(ct )\nthe performances of the compared methods are from [14] too.\nFrom this table, we can see the proposed model SDVAE-II&IAF\nperforms best in classification and makes the least classification The conditional LSTM is same as the vanilla LSTM except for\nerrors (in black bold format) with small part of the labeled data. the current variable, which is replaced by the concatenation of\nAlthough SDVAE-I performs not as good as other proposed mod- the latent variable z and v. The techniques of dropout [26] and\nbatch normalized [10] are both utilized in the encoder and deels, it still can achieve state-of-the-art results.\ncoder networks.\nTo further validate the observation, we also conduct the semisupervised learning over the SVHN, another popularly used\ndataset. SVHN has 73,257 training samples and 26032 test samples. Among the training data, we randomly select 1000 data 4.2.3 Disentangle Representation\nsamples as labeled data and the rest as unlabeled data. The results\nare shown in Table 2. Similarly, we can observe that SDVAE- We randomly select 20k samples from the training set as the laII&IAF gives the best performance.\nbeled data, and others are unlabeled during the training. Similarly, we use the t-SNE to visualize the disentangle variable\nv ∈ N 2 and the non-interpretable variable z ∈ N 50 from the\nproposed model on the test data and unlabeled data. Results are\nshowed in Fig.4,\n\nTable 2: The results on the SVHN data\nMethod\nKNN\nTSVM\nSemi-VAE(M1)+KNN\nSemi-VAE(M1)+TSVM\nSemi-VAE(M1+M2)\nSDVAE-I\nSDVAE-I&IAF\nSDVAE-II\nSDVAE-II&IAF\n\n([14])\n\nTest error rate\n77.93% (±0.08)\n66.55% (±0.10)\n65.63% (±0.15)\n54.33% (±0.11)\n36.02% (±0.10)\n47.32% (±0.13)\n46.92% (±0.12)\n44.16% (±0.14)\n34.25% (±0.13)\n\nFrom the left figure in Fig.4, we can see that the disentangle\nrepresentation v can clearly separate the positive and negative\nsamples while non-interpretable representation cannot, i.e., data\npoints from two clusters are interleaved with each other. This\nsuggests that the disentangle representation captures categorical\ninformation well, and there is seldom categorical information in\nnon-interpretable variable.\n6\n\n\fNon-interpretable\nvariable z\n1 01 0\n\n1001\n01\n\n1\n11 0\n0 1\n0\n1\n0 01\n11 0\n11001 1\n11\n1 0 010 010 1\n0 10 101000 1 0\n11111011\n0 11\n1\n1 0 1 0 10 1\n00 10\n00 1\n01 1\n1100 01\n1001\n10\n01\n0\n0 1 111 0 1000101 10\n11010100\n1 10100\n11 1 01 0\n011101\n0101 00\n0\n0\n1\n0\n101\n0 1 1101011 1100010111100 10101\n1\n1\n1111\n000 111100\n000\n1011 10\n0 110 10 0\n01 01 01001001\n0\n11 1 1 1 01 1\n0 00\n0010100 110011101\n1\n011\n001 1 11001110\n100 100\n01111\n1 1 0 1 1 0 101111\n11 001\n101\n01100\n1\n11 1 10 1001 01101001\n0 10 1 0\n10110111\n10 0\n011 1 00101101 0\n1001 1011 00011\n111\n0 110000\n1\n000001011000\n0 10 0 110110101 00\n000 00101111 011\n1\n011\n101 00 000 011 00000 1\n1 10\n00\n10 11\n000110 10100110\n0 0 1110111010 1\n1 101 1111010\n1\n1 10 10111\n11\n00001 100000\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0100 0 1 11011 0010 1 0 1101 0 10001 0\n1 11\n10 00 11\n100\n00\n0 11 0\n10 000 10 001\n01 1 011 1\n101111 1 0\n01\n0 100 0\n0\n0 01 100\n111011101010\n1100\n1 01 1\n0 0111\n0110\n1 1\n110 1110\n10 001 111 10 01011000\n0 0\n00001110 00 0 0101\n10 1\n0 1\n1 0010 0 01\n1 0010 00 1\n00\n011 0\n0 01 11 1 00 0 1011\n0\n0 0 1 11 100111000 101 101\n0 1011010111 1 101 10 101\n0 1 1 100 1\n1\n0\n1\n1\n0\n0\n00 1\n10 0 1 000100101\n1 1 00\n1 0 0 0 1011 01 1 1 1 11100 0\n11 100011\n1 0\n11 1 1 01 010 1001 1 1100 0 1001 0\n101 0\n1 101010 0\n0 1\n000 10 00 0101 110 0\n0 1\n10 0\n1\n011\n0 1\n0 1 010 1 101 00 1 1 1 01\n1\n1\n1\n1\n1\n0\n0\n1 0 00\n0\n1\n11\n0\n1\n1 01 1 0\n0\n1\n0 0\n0\n\n1\n\n4.3\n\nvd\nDisentangle variable\n0 00\n\n00\n0 000 00 0 00\n0\n00 0\n1\n1 111111\n00000 000000 0\n1111 1 11\n0 000\n000 0 000\n0\n11 1 1 11\n11 1111\n1\n00 0 0\n0\n111111111\n111 111 11 111\n00000000\n0000 00 000\n1\n0\n0\n111111 1\n0 0000 0\n111 111\n0\n0\n0\n1\n0\n1\n1\n1\n000000 0\n0\n1 1 1\n0000\n0\n0000\n000\n0\n0\n1 1 11 111\n111\n10\n00\n000 00\n0\n1\n0 0 0000 0 00\n1 11 1 1 11 1111\n000 000 000000\n00\n1 1 1111 11111\n0 0 00\n0 0 00\n00\n1111 1 11 1 11\n0\n0\n1\n0\n0\n0\n0\n0\n1\n1\n1\n1\n0\n0\n1\n00 0\n0\n1\n0 0000\n11\n11\n11\n1 1 111111 1\n00 0 000000 00\n1 11\n1\n000 0\n111\n111\n0\n1\n1\n1\n11 1111 1\n00 0 0\n00\n1\n11\n1 111 111\n1111\n00\n1111111\n1 1111 1\n1\n11\n0\n1111 1 1 11 1 111 1\n00\n11 11\n00\n11\n1 11\n00\n0\n0\n1\n00\n1 11\n0\n1 11111\n111\n1 1111\n0\n000 00 0\n1\n0 0\n111 1111\n1 11 11\n0\n11\n00 000 000\n000000\n0 00\n1111\n1\n111 11111 1111\n0\n0\n0\n0\n0\n11 1 11111 11\n0\n1\n1\n1\n0\n1\n0\n1\n0 00 00 000 0 000 0\n1 1 1111 1 1111 1 111 11\n111\n0\n0 0 0 00\n1\n1\n1\n0\n0\n1\n1\n1\n0 0 0000\n11 1 1 1 1\n0 00\n00\n1 1\n1 11\n00000 0000 00\n00000\n00\n11\n00 0 0 0\n1111 1 1 1\n00 0\n00\n0 0 0000\n1\n0\n11 11\n0\n0\n1\n1\n1\n0 0 0\n00 00 000 0 00\n111\n1 1 11 1 11\n0 0\n0\n00 0\n00 000 00\n11\n1 1 1 111111\n0000\n0\n000000 0\n111\n1111111\n1\n1111\n0\n000 0 00\n11\n0\n0\n1\n0\n0\n1\n0\n0\n1\n1\n0\n1 11\n00 00\n1 1 11 1\n0\n11 111\n11\n1111\n00 000000\n11 1 111111\n0 0000 00\n0\n0\n0 000\n1111 11 1\n0 0000\n11111\n00 0\n0\n0\n0\n0000\n0000\n1111\n000\n00 0000000\n111 11 1\n11 11 1111\n00000\n11 111\n00 000\n00\n11\n11\n000 0\n11\n1\n0 00\n\nParameters Analysis\n\nThere are several important parameters need to be tuned for the\nmodel, i.e., λ, β1 , β2 and the length of IAF. In this section, we\nconduct experiments to analyze the sensitiveness of the model to\nthe parameters.\n\n4.3.1\n\nEffects of λ and the IAF Length\n\n(a) Unlabeled Data\nNon-interpretable\nvariable z\n01\n\n0 11\n01 1\n1 11 1 0 0\n0 0 0 0 101 1\n000\n0 10 10000 1 10 011 00 00 11 11 11 1\n1 1\n1 0\n1\n1\n0 11\n10\n0 001 00101 10 0 0 0\n00001 00 1 01 1 0\n0000 0 11101 11 0 0 0 01\n01 1 01 00 0 00 1 0\n0\n1\n0\n0\n11 1 10 00\n1\n1\n0\n1110 1 10\n11\n01\n1\n0 0 010 10 0 111 0 110 1 10 1\n0 1 0011110 1110 010 1011011010001 111 0 001001 01 10 111\n0 0 0001\n1\n0\n0\n0\n1\n1\n1\n1\n0\n1\n0\n0 0\n1\n11 0\n1\n01\n1111 00 1 00 100101 00111 10100\n00 0 101 1 00 0\n01\n10 001 0\n1\n1 1\n01\n01111 10\n1101 01 0001 1 001 0\n1\n010101110\n0\n0 10000 0\n00 100100\n0\n1\n0\n0 1 1\n1\n1\n1\n1\n0\n1\n1\n1\n0 0\n1 00000 0000\n10\n11110 00 0010\n11\n101 1 00 0\n10\n0 0\n1\n1 000 0 1 001 0\n1 0 0010 1100 11111 1010000 1111\n0000 010001\n0 1 0\n0\n11 0 0\n1 0 0 0 000 1 0\n11\n1 10010 001 1101\n1\n10\n0010 1 11111\n1\n00 0 110100\n1000 1101001\n10 00 11111 01001 11 0 0\n10 1 00\n1 1 11\n0\n1\n0\n0\n1\n0\n0\n1\n1\n1 01 111 0001 1 0 1 0111 101001 1 001 1\n0 0 00 0 1 10 11001\n0\n0\n0 0\n1\n01\n0 1 11101001\n01 000 1001 10 0100\n0 0011 01 101\n00 00 0010 1\n10 001 1\n0\n0 001010110\n00 10\n110010 1011 0010 1 1 0\n0011 0\n1110 100\n011 10100101100 01 0 00100 011 011 1 1\n0 00\n1 000 10 010 1\n0\n1\n0\n1\n0 0 0\n0\n0 0 0110 1\n0\n1\n0\n1\n0 01 010 010110 01 1101 10\n10 0 11 0\n1\n00 1 110 110 00 11 0 0001\n001\n0\n101 0\n1\n0 0 00111 0 0010 0100 11 01101\n1 0111 10000 111 00 010 110 1 0\n10 0\n11\n1 0\n0 1 11\n0\n11 111 00000 0 000 1101 00 11 0 0\n1 00\n10\n1\n1\n0 1 00\n0 00\n1\n0\n1\n1\n1\n0 0 01 0 1 1 01 1 0 11\n1 1\n1 0\n0 0 1 0\n000 1 1\n01011 01 1 1 1\n1\n0\n1\n000\n1\n0\n0\n10 0 000 0 0 1\n0\n1\n\nDisentangle0 0 variable vd\n\nWe firstly evaluate λ and the length of the IAF chain which are\nproposed in the works of β-VAE [6] and IAF [15]. These experiments are conducted over the MNIST training dataset.\n\n00\n1\n1\n000\n010\n11\n1\n1\n1\n0 1101 00\n010 10001\n11 1\n0 0\n0 10\n100\n10\n110\n1\n1\n1\n00\n1010 0 00001\n0100\n11111 101111\n1\n1\n0\n00\n0 0 01\n1000\n1\n1\n1\n000000\n01011\n0 000 0\n01 1 10101\n11\n11\n1\n1100 00 00000 0\n010\n001\n1\n11111\n000\n1\n000\n1\n0\n1\n1\n1\n0\n101 1 1\n111\n0 00\n11\n1 00\n1\n00000\n1\n1\n00 1\n1 10\n00\n1111\n1111 111111\n11 1\n10010\n00 0 00000\n1\n1 0110\n1111\n1\n1\n1\n0\n0 000\n0\n1\n1\n0\n1\n1\n1\n1\n11111 111\n0\n10 1 0 01 0000 00 00001\n0 011\n1\n0\n0000 0 00\n11 11111\n110 0 0 1 0 1\n0\n1\n1\n0\n1\n0\n1\n0\n0\n000 000 00 0000\n11 1 1 1\n1 1\n10\n101 00000\n00 00000\n11 1111\n0\n10 010\n00\n000000\n000 10000\n0\n01111111\n10\n1 1 11\n0000\n0 000000\n10\n0 10\n1111 1\n11 1\n0 00000\n00000000\n000000 00000000\n0000\n00\n1111 0 00\n1 0101\n1 00\n0 000\n1\n0\n11 1111\n0\n000 000 00\n0\n1\n1\n0\n1\n0\n1\n1\n1\n0\n0\n1\n1\n1\n0\n1\n0\n0\n0\n1111111\n0 0 000 0 0000 0 000\n1 1 00\n0\n11 1 11\n1\n0\n0\n11111\n1\n11 0 0 00101 000 0000 00\n0 11111\n1\n11111\n111011\n01 1 1\n0\n0\n0\n0\n111\n111 111\n0\n0\n001\n1111\n0\n0000 0\n1\n11\n1 1\n0\n0 100\n0 0\n00\n1\n11\n1\n0\n101111111 1 0 0\n11\n1\n00\n11111011011\n00\n00\n10\n1 1 000\n010 0100\n01100\n001000\n11 1111\n11110\n0\n11 01\n00\n1 00\n0\n00 0001\n1111\n1\n0\n00 000\n10 0\n1\n00\n000\n10\n11\n1 10\n10\n0\n11\n0 00 00\n0\n00\n11010\n0 0000\n1 000\n0\n11\n1101\n110\n000000\n111\n001\n0\n1\n1\n0\n0\n1\n0\n0\n1\n11\n0\n1\n00\n0\n111\n0\n11\n10\n1\n1\n11\n11\n\nThe objective function in the proper λ finding is depicted in\nEq.(6). Results with different λ values are shown in Fig.5(a)\nFrom the results, we can see that it is better for λ to have a small\nvalue, which not only leads to a rich information in the latent\nvariable but also gets a better reconstruction error. But as de(b) Test Data\nscribed before, the large value of KL-divergence is also the cause\nFigure 4: The left figure is the t-SNE distribution of the non- of overfitting or the underfitting for the model. However, in the\ninterpretable variable z, the right figure is the t-SNE distribution case of λ = 0.1, there is a low reconstruction error, which is the\nof the disentangle variable v correspondingly. Different cate- sign of the good performance.\ngories are in different colors with number.\nThen the model structure about the IAF chain is built according\nto the Eq.(16), and the results with different length are shown in\n4.2.4 Semi-Supervised Learning\nthe right figure in Fig.5(b). From the figure, we can see that it is\nnot good to set the chain too long if it is a long IAF. The RCEs are\nWe further conduct semi-supervised classification on the text not so good together with the KLDs, and the latent variable isvery\ndataset using the representation learned from previous experi- unstable. On the contrary, there is a stable increase about the\nments and fine tuning the model. Similarly, we compare with KL divergence, and a stable decrease reconstruction error when\nstate-of-the-art semi-supervised learning algorithms. The aver- the length of the IAF chain is set to 1. This means that under\nage test error rate is reported in Table 3. From the results, we can the good reconstruction, the latent variable captures more useful\nsee that: (i) SDVAE-II&IAF outperforms the compared meth- information. This is also validated in the results of the SDVAEods, which implies the effectiveness of the proposed framework I&IAF and SDVAE-II&IAF. Thus, in the experiments about the\nfor semi-supervised learning; and (ii) As we add reinforcement IAF, its length is set to 1 by default.\nPowered by TCPDF (www.tcpdf.org)\n\nPowered by TCPDF (www.tcpdf.org)\n\nlearning and IAF, the performance increases, which suggests the\ntwo components contribute to the model.\n\n4.3.2\n\nTable 3: The results on the IMDB data\nMethod\nLSTM ([4])\nFull+Unlabeled+BoW ([20])\nWRRBM+BoW ([20])\nNBSVM-bi ([30])\nseq2-bown-CNN ([11])\nParagraph Vectors ([17])\nLM-LSTM ([4])\nSA-LSTM ([4])\nSSVAE-II&LM ([33])\nSDVAE-I\nSDVAE-I&IAF\nSDVAE-II\nSDVAE-II&IAF\n\nEffects of β1 and β2\n\nTo decide the parameter β1 and β2 that in SDVAE-II, we made\nthe grid search both on the text data and the image data. For the\nimage data, the experiment is conducted on the SVHN dataset\nwith 1000 labeled samples. Experimental result with β1 ranges\nfrom 0.1 to 1000, and β2 ranges from 0.01 to 100 are shown in\nFig.6(a). For the text data, the experiment is conducted on the\nIMDB data with 20,000 labeled samples. Experimental result\nwith β1 and β2 range from 0.1 to 1000 are shown in Fig.6(b).\n\nTest error rate\n13.50%\n11.11%\n10.77%\n8.78%\n7.67%\n7.42%\n7.64%\n7.24%\n7.23%\n12.56%\n11.60%\n7.37%\n7.18%\n\nFrom the Fig.6(a), we can see that, an acceptable range for β1 in\nthe image data is [0.1:100] and [0.01:10] for the β2 . Especially,\nwhen β1 = 0.1 and β2 = 1, it is achieving the best result.\nFor the text data, the results in the Fig.6(b) show that the accuracy\n7\n\n\fλ=0.1\nλ= 0 . 5\nλ= 1 . 0\nλ= 2 . 0\n\n1 5 0\n1 4 0\n\nλ=\nλ=\nλ=\nλ=\n\n0 .1\n0 .5\n1 .0\n2 .0\n\n5 0\n4 0\n\n1 3 0\n\nK L D\n\nR C E\n\n3 0\n1 2 0\n2 0\n1 1 0\n\n(a) The Image data\n\n1 0\n\n1 0 0\n9 0\n\nFigure 6: The grid search results for the proper β1 and β2 finding.\n0\n\n0\n\n3 0\n\n6 0\n\n9 0\n\n1 2 0\n\n1 5 0\n\nE p o c h\n\nsemi-supervised VAE all use a parametric classifier, which increases the burden to learn more parameters given the limited\nlabeled data. The proposed framework incorporates the label information directly into the disentangled representation and thus\navoids the parametric classifier.\n\n(a) Validate λ\nt=1\n\nt=1\n\n1 5 0\n\n1 3 0\n\n1 8\n\nt=1 0\nt=2 0\nt=3 0\n\nt=1 0\nt=2 0\nt=3 0\n\n1 4 0\n\n1 6\n1 4\n1 2\n\n1 1 0\n\n1 0\n\n1 0 0\n\n8\n\n9 0\n\n6\n\n8 0\n\n4\n\n7 0\n\n2\n\n6 0\n\nVariants of VAE Because of the great potential of VAE in image and text mining, various models based on VAE are proposed\nto further improve its performance [16, 6, 7, 15]. For example,\n[6] apply the KKT condition in the VAE, which gave a tighter\nlower bound. Similarly, [3] introduce importance weighting to\nVAE, which also tries to give a tighter bound. [24] consider the\nstein based sampling to minimize the KL divergence. [7] rewrite\nthe evidence lower bound objective by decomposition, and give\na clear explanation for each term. To extend the flexible of the\nposterior inference, IAF is introduced [15] which improves the\nVAE a lot.\n\nK L D\n\nR C E\n\n1 2 0\n\n0\n0\n\n2 0\n\n4 0\n\n6 0\n\n8 0\n\n1 0 0\n\n1 2 0\n\n1 4 0\n\nE p o c h\n(b) Validate Length of IAF\n\nFigure 5: The left y-axis in each figure is the reconstruction error\n(BCE) which is axis of the solid lines, and the right y-axis is the\nKL divergence (KLD) which is axis of the dash lines.\n\n6\n\nis not sensitive to β2 . However, when β1 is small, the result will\nbe more precise. In conclusion, it is better to set β1 to 0.1 and β2\ncan be set randomly.\n\n5\n\n(b) The Text data\n\nConclusions\n\nIn this work, we propose models that extract the disentangle variable v and the non-interpretable variable z from data at the same\ntime. The disentangle variable is designed to capture the category information and thus relieves the use of classifiers in semisupervised learning. The non-interpretable variable is designed to\nreconstruct the data. Experiments show that it could even reflect\ncertain textual features, such as italic, bold, transform and style\nin the hand writing digital data during the reconstruction. These\ntwo variables cooperate well and each performs its own functions\nin the SDVAE. The IAF improves the model effectively on the\nbasis of SDVAE-I and SDVAE-II. Especially in which, SDVAEII&IAF achieves the state-of-the-art results both in image data\nand the text data in the semi-supervised learning tasks.\n\nRelated Works\n\nSemi-supervised VAE Semi-supervised learning is attracting increasing attention, and lots of works are proposed [33, 8, 22, 31,\n23, 14, 27, 5]. Those works can be divided into the discriminative models [29, 4], the generative models [33, 8, 22], graph based\nmodels [27], and the combined model with those [5]. Because of\nthe effectiveness of deep generative models in capturing the data\ndistribution, semi-supervised models based on deep generative\nmodels such as generative adversarial network [25] and variational auto-encoder (VAE) [14] become popular. Semi-VAE [14]\nincorporates the learned latent variable into the classifier and improves the performance greatly. SSVAE [33] extends Semi-VAE\nfor sequence data, and also demonstrates its effectiveness in the\nsemi-supervised learning on the text data. The aforementioned\n\nReferences\n[1] Dimitri P Bertsekas. Nonlinear programming. Athena scientific Belmont, 1999.\n8\n\n\f[2] Samuel R Bowman, Luke Vilnis, Oriol Vinyals, and et al. [16] Diederik P Kingma and Max Welling. Auto-encoding variGenerating sentences from a continuous space. arXiv\national bayes. arXiv preprint arXiv:1312.6114, 2013.\npreprint arXiv:1511.06349, 2015.\n[17] Quoc Le and Tomas Mikolov. Distributed representations\n[3] Yuri Burda, Roger Grosse, and Ruslan Salakhutdiof sentences and documents. In Proceedings of the ICML,\nnov. Importance weighted autoencoders. arXiv preprint\npages 1188–1196, 2014.\narXiv:1509.00519, 2015.\n[18] Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick\n[4] Andrew M Dai and Quoc V Le. Semi-supervised sequence\nHaffner. Gradient-based learning applied to document\nlearning. In Proceedings of the NIPS, pages 3079–3087,\nrecognition. Proceedings of the IEEE, 86:2278–2324, 1998.\n2015.\n[19] Lars Maaløe, Casper Kaae Sønderby, Søren Kaae Sønderby,\n[5] Jingrui He, Jaime G Carbonell, and Yan Liu. Graph-based\nand Ole Winther. Auxiliary deep generative models. arXiv\nsemi-supervised learning as a generative model. In Propreprint arXiv:1602.05473, 2016.\nceedings of the IJCAI, volume 7, pages 2492–2497, 2007.\n[20] Andrew L Maas, Raymond E Daly, Peter T Pham, and et al.\n[6] Irina Higgins, Loic Matthey, Arka Pal, and et al. beta-vae:\nLearning word vectors for sentiment analysis. In ProceedLearning basic visual concepts with a constrained variaings of the ACL: Human Language Technologies-Volume 1,\ntional framework. In Proceedings of the ICLR, 2017.\npages 142–150, 2011.\n[7] Matthew D Hoffman and Matthew J Johnson. Elbo surgery: [21] Yuval Netzer, Tao Wang, Adam Coates, and et al. Reading\nyet another way to carve up the variational evidence lower\ndigits in natural images with unsupervised feature learning.\nbound. In Proceedings of the NIPS, Workshop in Advances\nIn Proceedings of the NIPS, Workshop on deep learning and\nin Approximate Bayesian Inference, 2016.\nunsupervised feature learning, volume 2011, page 5, 2011.\n[8] Zhiting Hu, Zichao Yang, Xiaodan Liang, and et al. Toward\n[22] Augustus Odena. Semi-supervised learning with generative\ncontrolled generation of text. In Proceedings of the ICML,\nadversarial networks. arXiv preprint arXiv:1606.01583,\npages 1587–1596, 2017.\n2016.\n[9] Gao Huang, Shiji Song, Jatinder ND Gupta, and Cheng\n[23] Yong Peng, Bao-Liang Lu, and Suhang Wang. Enhanced\nWu. Semi-supervised and unsupervised extreme learning\nlow-rank representation via sparse manifold adaption for\nmachines. IEEE transactions on cybernetics, 44(12):2405–\nsemi-supervised learning. Neural Networks, 65:1–17, 2015.\n2417, 2014.\n[10] Sergey Ioffe and Christian Szegedy. Batch normalization: [24] Yunchen Pu, Zhe Gan, Ricardo Henao, and et al. Stein\nvariational autoencoder. arXiv preprint arXiv:1704.05155,\nAccelerating deep network training by reducing internal co2017.\nvariate shift. In Proceedings of the ICML, pages 448–456,\n2015.\n[25] Jost Tobias Springenberg.\nUnsupervised and semisupervised\nlearning\nwith\ncategorical\ngenerative adversarial\n[11] Rie Johnson and Tong Zhang. Effective use of word order\nnetworks.\narXiv\npreprint\narXiv:1511.06390,\n2015.\nfor text categorization with convolutional neural networks.\narXiv preprint arXiv:1412.1058, 2014.\n\n[12]\n[13]\n\n[14]\n\n[15]\n\n[26] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, and\net al. Dropout: a simple way to prevent neural networks\nYoon Kim. Convolutional neural networks for sentence\nfrom overfitting. Journal of Machine Learning Research,\nclassification. arXiv preprint arXiv:1408.5882, 2014.\n15(1):1929–1958, 2014.\nDiederik Kingma and Jimmy Ba. Adam: A method for\nstochastic optimization. arXiv preprint arXiv:1412.6980, [27] Amarnag Subramanya and Partha Pratim Talukdar. Graphbased semi-supervised learning. Synthesis Lectures on\n2014.\nArtificial Intelligence and Machine Learning, 8(4):1–125,\nDiederik P Kingma, Shakir Mohamed, Danilo Jimenez\n2014.\nRezende, and Max Welling. Semi-supervised learning with\ndeep generative models. In Proceedings of the NIPS, pages [28] Laurens Van der Maaten and Geoffrey Hinton. Visualizing\ndata using t-sne. Journal of Machine Learning Research,\n3581–3589, 2014.\n9:2579–2605, 2008.\nDiederik P Kingma, Tim Salimans, Rafal Jozefowicz, and\net al. Improved variational inference with inverse autore- [29] V Vapnik and A Sterin. On structural risk minimization or\ngressive flow. In Proceedings of the NIPS, pages 4743–\noverall risk in a problem of pattern recognition. Automation\n4751, 2016.\nand Remote Control, 10(3):1495–1503, 1977.\n9\n\n\f[30] Sida Wang and Christopher D Manning. Baselines and bigrams: Simple, good sentiment and topic classification. In\nProceedings of the ACL: Short Papers-Volume 2, pages 90–\n94, 2012.\n[31] Suhang Wang, Jiliang Tang, Charu Aggarwal, and Huan\nLiu. Linked document embedding for classification. In Proceedings of the 25th ACM International on Conference on\nInformation and Knowledge Management, pages 115–124.\nACM, 2016.\n[32] Tsung-Hsien Wen, Milica Gasic, Nikola Mrksic, and et al.\nSemantically conditioned lstm-based natural language generation for spoken dialogue systems.\narXiv preprint\narXiv:1508.01745, 2015.\n[33] Weidi Xu, Haoze Sun, Chao Deng, and Ying Tan. Variational autoencoder for semi-supervised text classification.\nIn Proceedings of the AAAI, pages 3358–3364, 2017.\n[34] Xinchen Yan, Jimei Yang, Kihyuk Sohn, and Honglak Lee.\nAttribute2image: Conditional image generation from visual\nattributes. In Proceedings of the ECCV, pages 776–791,\n2016.\n[35] Zichao Yang, Zhiting Hu, Ruslan Salakhutdinov, and Taylor\nBerg-Kirkpatrick. Improved variational autoencoders for\ntext modeling using dilated convolutions. arXiv preprint\narXiv:1702.08139, 2017.\n\n10\n\n\f",
         "train",
         "46849",
         "8676"
        ],
        [
         "10",
         "17442",
         "cs.AI",
         "Artificial Intelligence",
         "1802.04009v2.pdf",
         "Distinguishing Question Subjectivity from Difficulty for\nImproved Crowdsourcing\nYuan Jin, Ye Zhu\n\nMark Carman, Wray Buntine\n\nSchool of Information Technology\nDeakin University, Australia\n{yuan.jin,ye.zhu}@deakin.edu.au\n\nFaculty of Information Technology\nMonash University, Australia\n{mark.carman,wray.buntine}@monash.edu\n\narXiv:1802.04009v2 [cs.AI] 14 Feb 2018\n\nABSTRACT\nThe questions in a crowdsourcing task typically exhibit varying\ndegrees of difficulty and subjectivity. Their joint effects give rise to\nthe variation in responses to the same question by different crowdworkers. This variation is low when the question is easy to answer\nand objective, and high when it is difficult and subjective. Unfortunately, current quality control methods for crowdsourcing consider\nonly the question difficulty to account for the variation. As a result,\nthese methods cannot distinguish workers’ personal preferences for\ndifferent correct answers of a partially subjective question from their\nability/expertise to avoid objectively wrong answers for that question. To address this issue, we present a probabilistic model which\n(i) explicitly encodes question difficulty as a model parameter and\n(ii) implicitly encodes question subjectivity via latent preference factors for crowd-workers. We show that question subjectivity induces\ngrouping of crowd-workers, revealed through clustering of their\nlatent preferences. Moreover, we develop a quantitative measure\nof the subjectivity of a question. Experiments show that our model\n(1) improves the performance of both quality control for crowdsourced answers and next answer prediction for crowd-workers,\nand (2) can potentially provide coherent rankings of questions in\nterms of their difficulty and subjectivity, so that task providers can\nrefine their designs of the crowdsourcing tasks, e.g. by removing\nhighly subjective questions or inappropriately difficult questions.\n\nCCS CONCEPTS\n•Information systems → Crowdsourcing; Answer ranking;\n•Computing methodologies → Learning in probabilistic graphical models;\n\nKEYWORDS\nCrowdsourcing, Subjectivity, Difficulty, Statistical modelling\n\n1\n\nINTRODUCTION\n\nOutsourcing tasks to a flexible online workforce (aka crowdsourcing) has proven a successful paradigm for data collection in numerous fields due primarily to its overall lower costs and shorter\nturnaround time as compared to in-house expert-based data collection. The downside of online crowdsourcing is that the quality of the answers collected from crowd-workers is usually not\nguaranteed, even when multiple responses are collected and aggregated for each question, and workers are trained and vetted\nusing gold-standard questions. To address this issue, many quality\ncontrol methods for the crowdsourced answers have been proposed\n[23, 24]. These methods rely on the assumptions that most crowdworkers are reliable when answering the questions and that a given\n\nworker is more likely to be reliable should she agree with the majority of her co-workers on the majority of their jointly answered\nquestions. Thus, the methods have focused on modelling the accuracy/ability/expertise of individual workers, assuming this to be\ncorrelated with the quality of the responses [5, 17]. In recent years,\nit has become popular for quality control methods to also model the\ninfluence that individual questions exert on the quality of the responses [2, 25]. Broadly speaking, the following two key properties\nof questions have drawn the modelling attention:\n• Difficulty. The modelling of question difficulty is founded on\nthe assumption that greater agreement on workers’ answers to a\nparticular question indicates less difficulty for them in determining the correct response. Quality control methods often encode\nthis assumption using a function in which worker expertise\ncounteracts question difficulty for predicting the probability of\na correct response. The probability is also known as the quality\nof the response: the more difficult the question, the lower the\nquality of a response, and vice versa. In addition, some methods\n(e.g. [9]) also consider the existence of deceptive questions which\nare so difficult that the assumption that the majority of worker\nresponses are correct no longer holds.\n• Subjectivity. In crowdsourcing, there are also many tasks that\ncontain (purely or partially) subjective questions [15]. Intuitively,\nthe degree of subjectivity of a question (or equivalently, the data\nitem described by it) depends on the number of answer options\nthat are correct. Being purely subjective means all of the options\nare correct, while being partially subjective means more than\none but not all of them are correct. Unless it is explicitly announced by the task provider that a question accepts all options\n(e.g. movie rating by workers to build a movie recommender\nsystem [12]), the number of correct answers to a question is unknown and assumed by most quality control methods to be one,\nmeaning the question is objective. However, it is widely known\nthat even expert assessors can disagree with each other on the\ncorrect answer to a question in typical crowdsourcing tasks like\nrelevance judgement which is deemed to be “quite subjective\"\n(or equivalently, at least partially subjective) [21]. In this case,\nthe objectivity assumption on the questions does not hold and\nmost of the quality control methods based on this assumption\ncannot distinguish the answering accuracy/quality of workers\nfrom their preferences for the different answers of questions.\nFor crowdsourcing tasks that contain questions whose subjectivity is either unknown or known to be at least partial, novel quality\ncontrol methods need to be developed to capture any underlying\nanswering/labelling pattern that results from the subjectivity of the\nquestions. One such pattern uncovered by collaborative filtering\n[10] is that crowd-workers who share similar preferences tend to\n\n\f(a) Product Matching task: crowd-workers asked whether\ntwo product descriptions referred to the same item or not.\n\n(b) Fashion Judgement task: crowd-workers asked whether a\npicture contains a “fashion related item” or not.\n\nFigure 1: Heatmaps showing inter-worker response similarity (% of response agreement) for two different tasks: (a) a relatively objective product matching task\nand (b) a more subjective fashion judging task, both involving binary worker responses. Hierarchical clustering was performed to order workers such that similar\nworkers are close together. The three yellow blocks in the figure for task (b) indicate three groups of response behaviour and higher subjectivity for task (b).\n\nrespond similarly towards subjective questions which share certain\n(latent) features.This pattern can also be observed in crowdsourcing where groups emerge amongst crowd-workers in terms of the\nanswers they give to partially subjective questions. Figure 1 illustrates this phenomenon by providing heat maps of pairwise worker\nsimilarity for two tasks: (a) a relatively objective task and (b) a\nmore subjective one. The objective task required workers to judge\nwhether a pair of products were the same based on their names,\ndescriptions and prices, while the subjective task asked workers to\njudge whether an image contained “fashion related items”1 . The\nsimilarity between pairs of workers is calculated as the percentage\nof agreement across the jointly answered questions2 and hierarchical clustering has been performed to group similar workers\ntogether. The three yellow boxes along the diagonal for the more\nsubjective task (b) indicates the three distinct groups of worker\nresponse behaviour for this task, which was absent in the more\nobjective task (a). Since the workers were mostly reliable on both\ntasks, we conjecture that the grouping of response behaviour for\nthe workers in the fashion judgement task reflects the underlying\nstructures in their tendencies for selecting the different correct\nanswers of the same questions (due to their subjectivity).\nTo enable the answer quality control for the above tasks and\ngenerally, any crowdsourcing task that exhibits arbitrary degrees\nof question subjectivity and difficulty, we are motivated to develop\na statistical model encoding both these properties. The resulting\nmodel is able to explain both the randomness and the correlations\nin the answering behaviour of crowd-workers. More specifically,\nwhen a task contains only purely subjective questions, groupings\nof workers start to emerge due to the subjectivity of questions. A\ngroup captures a particular correlation between the crowd-workers\nwithin it and the latent correct answers for each of the questions.\nWe model such a correlation by factorising it into the latent preferences of the workers and the latent features of the questions. The\nassumption is that the workers with similar latent preferences tend\nto have similar perceptions of what constitutes a correct answer\nfor each of the questions. For instance, asking workers “which\ncolour for this shirt do you like?” is a purely subjective question\n1 The\n\nfor which one group of workers who like blue colour in general\nwill answer “blue”, whereas another group who like green colour\nwill choose “green”. There is no reason to believe one of these two\ngroups answer the question more correctly than the other, and their\ndistinct answering patterns tend to remain consistent across similar\nquestions asking about their colour favourites for other items (e.g.\ntrousers, hats).\nIf a question is partially subjective, this means it possesses (i)\na certain degree of subjectivity which corresponds to either its\ntendency of having two or more correct answers, and (ii) a certain\nlevel of difficulty. This difficulty corrupts the crowd-workers’ perceptions as to (what tend to be) the correct answers of the question\ndetermined by its subjectivity to various extents depending on its\nlevel against the workers’ levels of expertise. We model a greater\nextent of the corruption as a lower probability that the worker’s\nanswer is equal to the subjective (worker-specific) correct answer\nto the question, thereby the lower quality of the worker’s answer.\nThis subjective correct answer characterizes the particular group\nto which the worker belongs by sharing similar preferences with\nsome other workers3 .\nIn this paper we introduce a new quality-control framework for\ncrowdsourcing that models both the subjective (i.e. worker-specific)\ntruths regarding the correct answers to individual questions and also\nthe difficulty-dependent probability that a worker’s answer to a question will equal her perceived subjective truth. We now summarise\nthe contributions of the paper as follows:\n• A novel statistical model is proposed which encodes the question difficulty explicitly and the question subjectivity implicitly\nvia latent variables for worker preferences and corresponding\nquestion features. The model accounts for both the random and\nthe systematic parts of the variance in crowdsourced answers to\nrefine the quality control over them.\n• A Monte Carlo simulation approach is provided for quantifying\nquestion subjectivity as the expected number of subjective truths\nperceived by different groupings of crowd-workers with respect\nto their preferences.\n• A meaningful ranking of questions in terms of either difficulty\nor subjectivity is derived from the model parameter estimates.\n\ndatasets for the two tasks have been listed in section 5.\nof crowd-workers not sharing any items had their similarity to be .00001.\n\n2 Pairs\n\n3 We\n\n2\n\nrefer the reader to the movie example in the previous paragraph.\n\n\fThis can bring practical benefits to crowdsourcing such as improving designs of tasks by helping requesters to detect and\nremove highly subjective questions from the tasks intended to\nbe objective.\n\nobserved features of the question. This means the model will poorly\nfit any multi-modal distribution of answers to a question.\n\n2 RELATED WORK\n2.1 Latent variable modelling in crowdsourcing\n\nIn model-based collaborative-filtering [10], matrix factorization is\ntypically applied to predicting ordinal ratings provided by users\nto items (e.g. movies, songs). Its categorical version, shown in\nFigure 2b, is less commonly applied but is important for the construction of our model for the quality control of crowdsourced\ncategorical answers. It has a generative process for the response\nr i j ∼ Discrete(ψ i j ), where ψ i j = {ψi jk }k ∈K and K is the set of\nanswer options, with its k-th component calcuated as:\n\n2.2\n\nMost state-of-the-art answer/label quality control methods in crowdsourcing have operated under the assumption that each question\nis purely objective. These methods are primarily based on statistical modelling of the interactions between crowd-workers and\nquestions which determine either the marginal probabilities of\nthe workers’ answers equal to the corresponding correct answers\n[2, 23, 25] or the conditional probabilities of the answers given the\ncorrect answers [5, 9, 20]. In comparison, the marginal probabilistic\nmodelling is simpler than the conditional modelling, and also better at mitigating answer sparsity problem in crowdsourcing [7, 8].\nThe basic marginal probabilistic modelling is GLAD [25], which\nmodels the correctness of each answer as a logistic function where\nthe question difficulty counteracts the expertise of the responding\nworker. Its graphical representation is shown by Figure 2a with the\nfollowing generative scheme for a response r i j of worker i given\nto question j: θ ∼ Dir (γ ); l j ∼ Discrete(θ ); r i j ∼ Discrete(π i j ).\nThis means a correct answer l j is drawn for question j from a discrete distribution parametrised by θ , which was previously drawn\nfrom a Dirichlet distribution parametrised by γ . Then, a response\nr i j conditioned on l j is drawn from a discrete distribution with the\nk-th component of its parameters π i j calculated as follows:\nπi jk = f (e i , d j ) if k = l j else\n\n1 − f (e i , d j )\n1\n; f (e i , d j ) =\nK −1\n1 + e −(ei /exp(d j ))\n\nLatent variable modelling in collaborative\nfiltering\n\nψ i jk = P (r i j = k |U i , V j ) = exp(u T\nik v jk )/\n\nÕ\n\nk 0 ∈K\n\nexp(u T\nv )\nik 0 jk 0\n\n(2)\n\nHere, ψ i j is also called the soft-max function, u ik and v jk are respectively the latent preferences of worker i and the latent features\nof item j in relation to the k-th answer option. The inner product\nterm uTik v jk indicates how much tendency worker i responds to\nitem j with the k-th answer option.\n\n3\n\nPROPOSED MODEL\n\nOur proposed model endeavours to combine the key characteristics\nof the latent variable models specified in section 2.1 and section\n2.2. We call it SDR model (Subjectivity-and-Difficulty Response\nmodel), which comprises an upstream module which generates a\nsubjective truth for a question based on the worker’s perception\nof the correct answer, and a downstream module which imposes a\ndifficulty-dependent corruption on the subjective truth for generating the actual response from the worker to the question. More\nspecifically, in the upstream module, the latent subjective truth\nli j of question j as perceived by crowd-worker i is drawn from a\nsoft-max function specified by Eq. (2) except that the original r i j\nin the equation is now replaced by li j . This function explains how\nthe worker’s latent preferences interact with the question’s latent\nfeatures to generate the subjective truth behind her response to the\nquestion. In the downstream, conditioned on the latent subjective\ntruth li j , the response r i j actually given by worker i to question j\nis determined by the logistic function f (ei , d j ). It encodes how the\nworker expertise ei counteracts the question difficulty d j to corrupt\nthe subjective truth into the response, which will be defined later in\nthis section. Essentially, the above perception-corruption process\nis a generalisation of the corruption process of the correct answer\nsignals from objective questions modelled in [23] by additionally\nconsidering the question subjectivity.\nUnfortunately the upstream+downstream model described above\nsuffers from an over-parameterisation issue whereby both the upstream component (which determines the worker-specific correct\nanswer) and the downstream component (which determines the\nnoise resulting from worker inaccuracy) can independently and\nadequately explain the variance observed in worker responses to\nthe same question. In other words, the varied responses from\ndifferent workers to the same question could equally be due to\ndifferent perceptions on what constitutes the correct answer to\nthe question or to difficulty of the question causing low accuracy\namongst the respondents. To remedy this situation we explicitly enforce a group structure over workers in order to limit the variation\nin the perceptions across workers. This is done by changing the\nupstream module to have sparsity-inducing priors over the latent\n\n(1)\n\nIn this case, the function takes in the expertise factor ei of worker i\nand the difficulty factor d j of question j. The output of the function\nis the probability of the response r i j being correct. When ei → +∞\nor d j → 0, this probability grows, indicating a stronger positive\ncorrelation between r i j and l j . When ei → 0 or d j → +∞ and\nthe question has binary options, the probability approaches 0.5,\nleading to no correlation between the two, which suggests r i j is a\nrandom binary pick. When ei → −∞, the probability decreases to\n0, indicating a stronger negative correlation.\nAlthough efficient in quality control of answers to objective questions, current models based on marginal probabilistic modelling\nhave hardly considered modelling the subjectivity of questions, let\nalone inferring their possible subjective truths. One of the only two\npapers that have made progress in this regard is [19]. It assumes\nthat a higher (lower) joint degree of difficulty and subjectivity for\nan entire crowdsourcing task can increase (decrease) the number\nof groups of answers given by the crowd-workers to the questions.\nThe expected size of each group becoming smaller (larger) indicates\noverall weaker (stronger) correlations of answers given to the questions. Despite attributing the variance of answers to both difficulty\nand subjectivity, the paper makes no attempt to separate the two\nwhen it is supposed to be only the difficulty accounting for the\nquality of answers. Moreover, this work requires every question\nin a task to be answered by every worker, which is unrealistic in\npractice. The other work [15] has focused on modelling partially\nsubjective questions with just ordinal answers. It assumes each\nresponse to a question is generated by a Normal distribution the\nmean and the variance of which are linearly regressed over the\n3\n\n\fµd , σd2\nµ e , σe2\n\ndj\nθ\n\numk\n\nµv , σv2\n\nri j\n\nlj\nJ\n\nei\n\nIJ\n\nri j\n\nv jk\nI\n\nγ\n\n(a) model for fully-objective items\n\nv jk\n\nµu , σu2\n\nµv , σv2\n\nJK\n\nµu , σu2\n\nzi j\n\nli j\n\nϕi\n\nα\n\nei\n\nµ e , σe2\n\nJK\n\nri j\n\ndj\n\nµd , σd2\n\nu ik\n\nIJ\n\nMK\n\nIK\n\nJ\n\n(b) model for fully-subjective items\n\nIJ\n\nI\n\n(c) model for partially-subjective items\n\nFigure 2: (a) shows GLAD with a latent variable l j for each objective truth, (b) shows a collaborative filtering model without objective truths, and (c) is the proposed\nsubjectivity-and-difficulty response (SDR) model for partially-subjective questions that is able to distinguish question difficulty from subjectivity.\n\npreferences of crowd-workers. In this paper, we use the Latent\nDirichlet Allocation (LDA) [3] as such priors. The final graphical\nrepresentation of the SDR model is shown in Figure 2c.The new\nupstream module of our model assigns a probability vector ϕ i ,\nwhich follows a Dirichlet with a concentration parameter α , to\neach worker i. Each component ϕmi of this probability vector reflects the worker’s tendency of showing a particular preference m\namong the set of preferences M she possesses when answering any\nquestion. Then, a preference assignment zi j is drawn from ϕ i for\ndetermining the specific preference worker i will show for answering question j. As for preference m, it has a weight umk for each\nanswer option k to reflect how likely each option is to be selected\ngiven the preference m showed by any worker. In this paper, we\nfix the dimension of umk to be strictly 1. This weight is multiplied\nwith the latent feature v jk of question j and the result is input to a\nsoft-max function for drawing the subjective truth li j behind the\nresponse r i j . The above generative process can be formulated as:\nϕ i ∼ Dir (α ); zi j ∼ Discrete(ϕ i ); li j ∼ Discrete(ψ zi j ) with the\nk-th component of the soft-max function ψ zi j calculated as:\nψ zi j k =\n\nexp(u zi j k v jk )\nK\nÍ\nk 0 =1\n\nanswer incorrectly due to their difficulty. Moreover, when the estimated values for this term are greater than zero for most responses,\nit means SDR deems them more likely to be correct. With more of\nthem deemed correct, the number of inferred correct answers to\nany question tends to increase. As a result, the size of latent preference set M should grow, from the perspective of SDR, to fit the\nseemingly more diverse set of correlations between latent correct\nanswers across the questions. Thus, for our model to recover the\nright number of latent preferences for crowd-workers from their\nresponses, the priors for ei and d j need to be set properly, which\nwill be elaborated more in section 5.1.\n\n4 ESTIMATION\n4.1 Model parameter estimation\nWe now provide equations used for parameter estimation, using\nthe notation ψzi j k from Eq. (3) and f (ei , d j ) = fi j from Eq. (4) to\nsimplify the equations. The conditional probability for the preference assignment zi j to worker i when answering question j given\nthe model parameters is:\n\n(3)\n\nexp(u z k 0 v jk 0 )\nij\n\nP (z i j =m |e i , d j , u m , v j , α ) ∝\n\nEmbodying the sparsity-inducing effect of LDA, the preference\nprobabilities ϕ i are dedicated to revealing the underlying groups\nof crowd-workers while the soft-max specified by Eq. (3) governs\nthe positive correlations between the latent correct answers to the\nsame questions perceived by the workers within the same group.\nWhen the number of preferences in M = 1, the probability of the\nonly preference ϕ i is 1. This has a two-fold meaning that each\nquestion has one correct answer and every worker should perceive\nthe correct answer of any question in the same way. When the size\nof M is greater than 1, this indicates certain numbers of underlying worker groups, which we can recover by applying K-means\nclustering to the estimated preference probabilities ϕ̂ i using the\nElbow method to determine the right number of the groups.\nThe downstream module corrupts the correlations between the\nsubjective truth li j and the response r i j . It draws r i j from a discrete\nprobability distribution π i j specified in Eq. (1) except the logistic\nfunction f (ei , d j ) has the following definition from [16]:\nf (e i , d j ) =\n\n1\n1 + e −(ei −d j )\n\nÕ\nk ∈K\n\nδ i jk\n\nψmk f i j\n\n\u0012\n\n\u0013\n1 − f i j 1−δi jk\nK −1\n\nN im\n¬j + αm\nÍ\n0\nN im\n¬j + αm 0\n\nm∈M\n\n(5)\n\nm\nNi¬j\n\nwhere\ndenotes the number of questions excluding question j\nanswered by worker i given her preference m. The joint probability\nof the other parameters given zi j and the hyper-parameters is:\n\u0011\n\u0010\n2\nQ = p {e i }i ∈I , {d j , v j } j ∈J , {u m }m∈M | {z i j }i ∈I, j ∈J , µ {e,d,u,v } , σ {e,d,u,v\n}\n\"\n!#\n\u0012\n\u0013\nÕÕ\nÕ\nÕ\nδ i jk 1 − f i j 1−δ i jk\n\u0001\nlog\nψ zi j k fi j\n=−\n−\nlog p(e i |µ e , σe2 ) −\nK −1\ni ∈I j ∈J\ni ∈I\nk ∈K\nÕ\n\u0001 Õ Õ\n\u0001 Õ\n\u0001\nlog p(d j |µ d , σd2 ) −\nlog p(umk |µu , σu2 ) −\nlog p(v jk |µv , σv2 )\n\nj ∈J\n\nj ∈J\n\nk ∈K m∈M\n\n(6)\n\nThe partial derivatives for Q with respect to the other parameters:\nÕÕ\nÕ δ 0 \u0012 1 − f i j \u0013 1−δi jk 0\nu\n− µu\n∂Q\ni jk\n=−\nζ i jm v jk\nfi j\nωi jk k 0 + mk 2\n∂umk\nK −1\nσu\n0\ni ∈I j ∈J\n\n(4)\n\nThe term (ei − d j ) naturally explains the type of biases induced by\ndeceptive questions when the difficulty d j is much larger than the\nexpertise ei , which is not captured in Eq. (1) as the term exp(d j )\nis never smaller than 0, meaning questions never bias workers to\n4\n\n∂Q\n∂v jk\n\n=\n\n∂Q\n∂e i\n\n=\n\n−\n\nÕ\ni ∈I\n\n−\n\n(7)\n\nk ∈K\n\nu zi j k\n\nÕ\nk 0 ∈K\n\nδ i jk 0\n\nfi j\n\n\u0012\n\n\u0013\nv jk − µv\n1 − f i j 1−δi jk 0\nωi jk k 0 +\nK −1\nσv2\n\nÕ Õ \u0012 −1 \u0013 1−δi jk\nf i j (1 − f i j )ψ zi j k\nK −1\n\nj ∈J k ∈K\n\n+\n\nei − µ e\nσe2\n\n(8)\n\n(9)\n\n\f∂Q\n∂d j\n\n= −\n\nÕ Õ\ni ∈I k ∈K\n\nδ\n(−1) i jk\n\n\u0012\n\n\u0013 1−δ\ni jk\nd j − µd\n1\nf i j (1 − f i j )ψ zi j k +\nK −1\nσd2\n\nvalue by taking its expectation with respect to the clusters of workers derived in section 4.2. More precisely, the expected number\nof correct answers to question j with respect to worker clusters\nÍ |K |\nC is: E C [|L j |] = n=1 nP C (|L j | = n). In this equation, n iterates\nover the possible number of correct answers (from 1 to the size of\nK). The probability P C (|L j | = n) denotes how likely it is that the\nnumber of correct answers to question j equals n, with respect to\nthe worker clusters C. It is, however, difficult to calculate this probability when C and K are large due to a combinatorial explosion.\nThus we apply Monte Carlo simulation to estimate (a measure of)\nthe subjectivity of question j as E C [|L j |] using Alogrithm 1.\n\n(10)\n\nHere, δi jk = 1{r i j = k}, ζi jm = 1{zi j = m} and ωi jkk 0 = ψzi j k 1−\n\u0001 1 {k=k 0 }\n\u0001 1 {k ,k 0 }\nψzi j k\n−ψzi j k 0\n. The parameter estimation involves\ntwo alternating procedures: sample zi j according to Eq. (5) and\noptimize Q in Eq. (6) using LBFGS based on Eq. (7), (8), (9) and (10).\n\n4.2\n\nTrue answer estimation\n\nA single worker-specific correct answer li j (as perceived by worker\ni) fails to provide overall information about the correct answers to\nquestion j. Thus, we should gather the li j values from all workers\nwho answer each question. However, in practice, each question\nis assigned to only a limited number (usually 3 or 5) of workers,\nmaking the estimate of the true answer distribution poor. Our solution to improving this estimate is to first find underlying clusters\nof workers (across all questions) by applying K-means with the\nElbow method based on 10-fold cross validation to the posterior\nmeans Φ̂ = {ϕ̂ i |i ∈ I} of the latent preference probabilities of all\nthe workers. With the centroid ϕ̂ c of each resulting cluster c, we\nthen calculate the probability that the true answer lc j (as perceived\nby the workers in cluster c) takes the value k as follows:\nP (lc j = k |c) =\n\nÕ\n\nP (lc j = k |m)P (m |c) =\n\nm∈M\n\nexp(ûmk v̂ jk )\n\nÕ\nm∈M\n\nÍK\n\nk 0 =1\n\nexp(ûmk 0 v̂ jk 0 )\n\nAlgorithm 1 Subjectivity estimation for question j\nInput: v̂ j ; {û m }m∈M ; Φ̂c = {ϕ̂ c }c ∈C ; T = 50, 000.\nOutput: EC [| L j |].\n1: n j ← 0. /* Initialise number of correct answers for question j to zero */\n2: for t = 1...T do /* Sample over T iterations.*/\n3:\nL̂ j ← { }. /* Initialise set of correct answers to be sampled at iteration t . */\n4:\nfor c = 1...C do\n5:\nzc j ∼ Discr et e(ϕ̂ c ). /* Sample group preference assignment zc j . */\n\nk ∈K\n\n5\n\n(12)\n\n0 v̂ jk 0 ). /* Sample\n\nEXPERIMENTS\n\nThe evaluation of our proposed model consists of four parts. The\nfirst part is its sensitivity to various degrees of subjectivity in different crowdsourcing tasks. The second and the third parts are\nits performance of predicting respectively the provided correct answers of questions and the answers to be given by crowd-workers to\nunseen questions. The last part is its consistency with human assessors in assessing the difficulty and the subjectivity of questions. We\nhave used 10 crowdsourcing datasets to evaluate the performance\nof our model in the experiments corresponding to the four parts.\nTable 1 summarises these datasets as being either (primarily) objective or partially subjective. Among them, the identification tasks\nof event time ordering, dog and duck breeds, and same products\nconcern objective factual knowledge, while the judgement tasks\nof image beauty, document relevance 1&24 , facial expression and\nadult content intrinsically contain certain degrees of subjectivity.\n\nNow we have a set of correct answer estimates L̂ j = {lˆc j |c ∈ C}\nfor question j from all the worker clusters (with C being the set\nof the clusters). For the task of true answer prediction, we can\neither arbitrarily choose one from L̂ j as the estimate of the correct\nanswer l j or choose by following certain strategies. Two simple\nstrategies are to choose lˆc j from the cluster c with the highest average expertise over its workers, or from the cluster with the largest\nproportion of workers assigned to it. The first strategy states that\nthe correct answer perceived by on average the most expert group\nof workers is the most appropriate, while the second assumes it to\nbe the one perceived by the largest group of workers which represents the mainstream school-of-thought. In this paper, we apply\nthe second strategy because most crowdsourcing datasets used in\nthe experiments correspond to relatively simple tasks, where the\nprovided correct answers we believe are more likely to be mainstream opinions. As for the first strategy, it might be more useful\nthan the second for revealing a minority group of expert workers\nwho show distinct preferences on partially or purely subjective\nquestions from the majority of less expert workers.\n\n4.3\n\ncjk\n\n7:\nL̂ j ← L̂ j ∪ lˆc j only if lˆc j < L̂ j /* Add sampled lˆc j to L̂ j when it first appears. */\n8:\nend for\n9:\nn j ← n j + | L̂ j | . /* Increase n j by number of distinct correct answers sampled at t . */\n10: end for\nn\n11: EC [| L j |] ≈ Tj . /* Divide n j by T to estimate EC [| L j |] as the question’s subjectivity. */\n\n(11)\n\nwhere ûmk and v̂ jk are the estimates of the weight umk for preference m and the latent feature v jk of question j, both specific to\noption k. The best guess regarding the correct answer lc j according\nto the workers assigned to cluster c is then:\nlˆc j = arg max P (lc j = k |c)\n\nk 0 ∈K\n\ncorrect answer lˆc j perceived by worker cluster c . */\n\n!\nϕˆmc\n\nÍ\nlˆc j ∼ ψ zc j , where ψ zc j k = exp(û zc j k v̂ jk )/\nexp(û z\n\n6:\n\n5.1\n\nSDR hyper-parameter setup\n\nAs discussed at the end of section 3, to find the right number of\nlatent preferences for crowd-workers, the hyper-parameters of\nthe expertise ei and the difficulty d j in the SDR model need to be\ncarefully set. This is achieved through held-out validation which\nleverages noise within worker responses for detecting signs that\nSDR may be overfitting the responses by introducing more latent\npreferences than necessary. More specifically, we construct a heldout validation dataset by randomly sampling a response from each\nworker. Thus, the size of such a dataset equals the number of\n\nSubjectivity estimation\n\nDespite not being directly estimated in the model, question subjectivity can still be quantified and estimated after the model has been\nestimated. This is achieved based on the reasonable assumption\nthat the subjectivity of each question is proportional to the number of correct answers it affords. Despite not knowing the actual\nnumber of correct answers |L j | to question j, we can estimate the\n\n4 The\n\nquestions of relevance judgement task 2 come from the part of TREC 2011\ncrowdsourcing track [11] that does not contain the questions of relevance judgement\ntask 1. We collected crowdsourced judgements for the task 2 from CrowdFlower.\n\n5\n\n\f• Majority Vote (MV): The predicted correct answer for each\nquestion is the one chosen by the majority of the workers.\n• Multi-dimensional Wisdom of Crowds (MdWC) [23]: This\nmodel endows both crowd-workers and questions with multidimensional latent factors, and provides the workers with additional variables to account for their answering biases.\n• Generative model of Labels, Abilities, & Difficulties (GLAD)\n[25]: This model resembles MdWC except that its latent factors (interpreted respectively as expertise and difficulty) are unidimensional, and it does not have worker-specific bias variables.\n• Dawid-Skene (DS) [5]: Unlike GLAD and MdWc which model\nthe correctness probability of each worker’s response, this model\nfocuses on the (worker-specific) conditional probability of each\nresponse option given the correct answer to each question.\n• Community Dawid-Skene (CDS) [20]: This model extends DS\nby clustering workers over some latent structures imposed on\ntheir conditional response probability matrices (given all correct\nanswer possibilities) to alleviate the response sparsity problem.\n\nTable 1: The objective and the partially subjective datasets used in this paper.\nObjective datasets\nTime [18]\nDog [26]\nDuck [23]\nProduct [22]\nPartially subjective datasets\nImage [19]\nRel1 [4]\nRel2 [11]\nFashion [13]\nFace [14]\nAdult [1]\n\n# Worker\n76\n109\n53\n176\n# Worker\n402\n642\n83\n199\n27\n269\n\n# Item\n462\n807\n240\n8,315\n# Item\n60\n1,787\n585\n3,837\n584\n333\n\n# Response\n4,620\n8,070\n9,600\n24,945\n# Response\n24,120\n13,310\n1,755\n11,511\n5,242\n3,324\n\nworkers participating in a task. Then, given a certain setting of\nthe hyper-parameters, we learn our model based on the remaining responses and use the parameter estimates from the learned\nmodel to calculate the prediction accuracy: 1−MAE (Mean Absolute Error) over the held-out dataset. We repeat the model learning\nprocess with each hyper-parameter setting over the same 100 random held-out validation data subsets. We then obtain the average\nprediction accuracy for our model across these subsets for each\nhyper-parameter setting. Finally, we choose the setting (including\nthe number for latent preferences) that yields the highest average\nprediction accuracy for use in the experiments.\n\n5.2\n\nThe performance measure: correct answer prediction accuracy, is\n1 Í\ncalculated as: | J\n1{l j = lˆj }, where lˆj is inferred from the\n| j ∈J\nÍ\nˆ\nrespective baselines. For our model, it is: 1\nj ∈ J 1 {l j = lc j },\n|J|\n\nwhere c = arg maxc ∈ C Nc with Nc the number of workers assigned\nto cluster c after Elbow K-means, and lˆc j calculated by Eq. (12). The\nhyper-parameters for each baseline except MV are optimised using\nthe held-out validation specified in section 5.1 on the exact same\nrandom held-out validation subsets of each dataset in Table 1.\n\nSensitivity analysis\n\nWe first verify whether our model is sensitive to various degrees of\nsubjectivity in different crowdsourcing tasks. If a task is (almost\nentirely) objective, the optimal size of latent preference set M\nshould be 1, meaning that every crowd-worker now perceives the\ncorrect answers in the same way. Consequently, the probabilities\nof latent preferences ϕ i for worker i collapse to ϕ i = 1, and the set\nof correct answers L j for question j collapses to a single correct\nanswer l j . In this case, we conduct the held-out validation on our\nmodel across the objective datasets each with the 100 randomly\nsampled data subsets described in section 5.1. We expect that the\naverage held-out prediction accuracy for our model across these\ndata subsets will decrease when the number of latent preferences\nit has increases from 1 to 2, since in this case the model starts to\noverfit by learning the noise in the training responses to those\nobjective tasks.\nIf a task is sufficiently subjective, our model should uncover\nthe right number of underlying groups of workers along with the\nright number of latent preferences. We conduct the experiment in\nthe same way as above to see the difference in average prediction\naccuracy on held-out unseen responses with the number of preferences increasing from 1 to 3 over the partially subjective datasets.\nWe expect the average prediction accuracy to be higher when the\nnumber of preferences is greater than 1. Moreover, since Tian and\nZhu [19] provided us with the number of worker clusters emerging\nrespectively from the five sub-tasks which constitute the image\ndata in Table 1, we thus compare the corresponding numbers of\nclusters derived from our model with theirs.\n\n5.3\n\n5.4\n\nWorker answer prediction\n\nPredicting the answers to be given by crowd-workers to unseen\nquestions is much more significant for (partially) subjective crowdsourcing tasks than it is for the objective ones as the former type\nof tasks values more about the different ways workers respond.\nFor example, it is crucial to employ worker answer prediction to\ntest a recommender system built on crowdsourced ratings. In this\nexperiment, we evaluate the performance of all the models except\nMV on predicting the next answer from each worker. We first sample one answer from each worker to create a held-out test dataset,\nand then learn all the models from the rest of the data with their\nhyper-parameters optimised as described in section 5.1 using the\nexact same random validation data subsets. Finally, we evaluate\nthe prediction performance of the models on the held-out test data\nusing (1 - MAE). Due to the limitation of our computing power,\nin this experiment, we reduce the number of held-out validation\niterations for each model to be 15 before a single iteration of heldout test is conducted. We perform 15 such random tests before the\naverage performance of each model is elicited.\n\n5.5\n\nSubjectivity and difficulty coherence\n\nIn this experiment, we investigate whether the estimates of the\ndifficulty and the subjectivity of questions derived from the SDR\nmodel are consistent with the judgements of five human assessors.\nWe focused on the object identification & image aesthetics task5\nfrom [19] as the total number of its questions is 60, a manageable\nworkload for the assessors to provide good-quality judgements with\n\nQuestion correct answer prediction\n\nTo verify the ability of the SDR model to predict the question true\nanswers, we compare it with the following state-of-the-art quality\ncontrol methods for crowdsourcing. All of these methods assume\nthat each question has a single correct answer.\n\n5 Crowd-workers\n\n6\n\nare asked whether an image is beautiful or not.\n\n\fTable 2: Average accuracy of our model with 1 and 2 latent preferences on\npredicting the held-out validation response of each worker over 4 objective\ntasks.\nDataset\nTime\nDog\nDuck\nProduct\n\n(a)\n\nTable 3: Average accuracy of our model with 1, 2 and 3 latent preferences on\npredicting the held-out validation response of each worker over 10 partially\nsubjective tasks the first 5 of which are sub-tasks of the Image task in [19].\n\n(b)\n\nFigure 3: (a) shows the 3 worker clusters on identifying sky from images and\n(b) shows the 4 worker clusters on judging beautiful images.\n\nDataset\nBeauty 1\nBeauty 2\nSky\nBuilding\nComputer\nRel1\nRel2\nFashion\nFace\nAdult\n\nsufficient levels of effort and concentration. The assessors are either\nPhD or Master students, three of whom are avid photographers\nwith adequate knowledge about what constitutes beautiful images,\nwhile the other two are novices who, during the group discussion,\nprovided suggestions as to how novices might react to different\nimages. We ask them to rank the images with respect to (i) difficulty\nand (ii) subjectivity. The respective instructions we gave to them\nare:\"rank all these images by how hard they are for crowd-workers\nto judge correctly by avoiding possible incorrect answers\" and \"rank\nthem this time by how subjective they are for crowd-workers to judge\".\nThe assessors first independently came up with their two rankings.\nIn the process, they could redo the two ranking tasks until they felt\nconfident to submit. The assessors then worked together to merge\ntheir rankings into single rankings (for both difficulty and subjectivity) through group discussion and majority vote. The resulting\nrankings were then compared with the corresponding rankings\nbased on the estimates from the learned SDR model. In addition\nto ranking the images, the assessors were also asked to categorise\neach image into one of the three levels of difficulty (namely easy,\nmedium, and hard), and into one of the three levels of subjectivity\n(namely objective, partially subjective, and purely subjective). We\ndid this to see whether there existed any correlation between the\ndifficulty or subjectivity levels to which images were categorised,\nand their corresponding estimates from the model.\n\n6\n\nThe SDR model\nm=1\nm=2\n0.8967\n0.8915\n0.6970\n0.6625\n0.8427\n0.8388\n0.8396\n0.8291\n\nThe SDR model\nm=1\nm=2\nm=3\n0.6736\n0.6944\n0.6924\n0.6914\n0.6998\n0.6937\n0.8889\n0.8962\n0.8862\n0.8997\n0.9026\n0.9007\n0.8098\n0.8117\n0.8074\n0.3956\n0.3985\n0.3983\n0.4426\n0.4481\n0.4481\n0.7517\n0.7589\n0.7522\n0.7181\n0.7203\n0.7123\n0.7469\n0.7494\n0.7446\n\nTable 4: Accuracy of all the models on predicting the true answers of the four\npartially subjective datasets (the results for the Image task are not included as\nthe number of items in this task is too small to show any significant difference\nin the performance of different models).\nDataset\nRel1\nRel2\nFashion\nFace\nAdult\n\nSDR\n0.4998\n0.4752\n0.8733\n0.6423\n0.7598\n\nQuestion correct answer prediction\nMV\nGLAD\nDS\nCDS\n0.4522\n0.4457\n0.4309\n0.4697\n0.4544\n0.4567\n0.4512\n0.4604\n0.8580\n0.8689\n0.8415\n0.8463\n0.6404\n0.6130\n0.5924\n0.5986\n0.7568\n0.7587\n0.7534\n0.7582\n\nMdWC\n0.4674\n0.4586\n0.8700\n0.6079\n0.7556\n\nemerged from these tasks. To further prove our model with 2 preferences can uncover the underlying groups of workers who have\nperceived the partially subjective tasks differently, we show the\ndensity of the workers’ latent preference probabilities ϕ̂ i estimated\nby our model from the image data [19]. Due to a space limit, we\nonly show two of them in Figure 3. According to [19], the sub-task\nof judging whether images are beautiful is more subjective than the\nsub-task of identifying skies in images. This is re-confirmed by our\nmodel with its number of worker clusters for the former sub-task\ngreater than that for the latter shown by Figures 3a and 3b.\nThe results of the question correct answer prediction described\nin section 5.3 are listed in Table 4. Across all the partially subjective datasets except the image data, the SDR model, based on\nthe largest-group strategy for choosing the best worker clusters,\nis superior than the other 5 baselines6 . Especially, for the tasks\nof relevance judgement 1&2 and fashion judgement, our model is\nable to outperform the best baselines by 3%, 1.5% and 0.3% with\nalmost 54, 9 and 13 more correctly predicted question answers\nrespectively. Since our model is reduced to being very similar to\nGLAD when dealing with the objective datasets, it has achieved\nvery similar results as GLAD did in correct answer prediction over\nall the objective datasets except for the Duck data [23]. In this task,\nour model is superior than GLAD (0.69 versus 0.62 from GLAD).\nThis suggests that our model is at least as robust as GLAD when\npredicting correct answers for objective tasks.\n\nRESULTS\n\nThe results of the sensitivity analysis described in section 5.2 are\nshown in Tables 2 and 3. We can see from Table 2 that the average\nprediction accuracy of the SDR model with 1 latent preference is\nconstantly higher than that of the model with 2 preferences over all\nthe objective datasets. According to section 5.2, this result indicates\nthere is just one underlying group of workers for each of the tasks\nwho perceive the questions’ correct answers in the same way. It also\nshows that even though the expertise-difficulty corruption introduced noises to the objective truths to form the actual responses, our\nmodel was still able to recover the number of underlying group of\nworkers to be 1. From Table 3, our model with 2 preferences clearly\noutperforms itself with 1 preference across all the partially subjective tasks. This means multiple groups of workers have emerged\ndue to the sufficient subjectivity of these tasks. Moreover, the table\nshows that further increasing the number of latent preferences to\n3 no longer improves the performance. This has most likely been\ncaused by over-fitting, and also suggests a two-dimensional latent\nspace is accurate enough to explain the worker clustering effects\n\n6 The\n\nperformance of all the models on the image data (in Table 1) has been too close\nto bear any useful information as for which of them is better since the number of the\nquestions (i.e. 60) in the data is too small.\n7\n\n\f(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\nFigure 4: (a) and (d) show the correlation of the difficulty estimates and that of the subjectivity estimates respectively with the corresponding rankings judged\nby human assessors, while (b) and (e) show the correlation of the difficulty estimates and that of the subjectivity estimates respectively with the corresponding\nlevels to which the images have been categorized by the assessors. Finally, (c) shows the images as points with coordinates being the difficulty and the subjectivity\nestimates, and has highlighted some images with noteworthy coordinates, while (d) shows these images.\nTable 5: Average Accuracy of all the models on predicting the unseen held-out\ntest response of each worker across all the partially subjective datasets.\n\nThe results of the worker answer prediction described in section\n5.4 are shown in Table 5. We can see that our model is not the best\non 3 out of the 10 partially subjective datasets, topped by different\nbaselines. Despite that, our model has still performed adequately\nwell (being second best on those datasets). We conjecture that this\nis because all these 3 datasets are with binary answer options which\nintrinsically constrain the answering behaviour of crowd-workers.\nThis results in overall weaker correlations both in the worker responses and in the underlying correct answers across the questions.\nFor the other 7 datasets, 5 of them are with more than two answer\noptions, thus containing stronger answer correlations for our model\nto exploit to achieve better performance. To examine whether the\ndifference in the worker answer prediction accuracy between any\ntwo algorithms is significant, we conducted the Nemenyi post-hoc\ntest [6] based on Table 5. The result is shown in Figure 5, according\nto which the performance difference between SDR and either CDS,\nGLAD or DS is beyond the critical difference (CD), thereby being\nstatistically significant.\nThe results of the subjectivity and difficulty coherence evaluation\nhave been summarised in Figure 4 which consists of 6 sub-figures.\nFigures 4a and 4d show overall there is a strong negative correlation\nbetween the model estimates and the rankings judged by human\nassessors. More specifically, the larger the estimate for either the\ndifficulty or the subjectivity of an image, the higher it tends to be\nranked by human assessors. Moreover, Figures 4b and 4e show\nthat there exist clear positive correlations between the levels of\ndifficulty and subjectivity into which the images get categorised\n\nDataset\nBeauty 1\nBeauty 2\nSky\nBuilding\nComputer\nRel1\nRel2\nFashion\nFace\nAdult\n\nUnseen worker answer prediction\nSDR\nGLAD\nDS\nCDS\nMdWC\n0.6974\n0.6884\n0.6256\n0.6927\n0.6912\n0.7006\n0.7011\n0.6796\n0.6842\n0.6998\n0.9014\n0.8772\n0.8801\n0.8862\n0.8903\n0.8987\n0.8912\n0.8956\n0.9006\n0.8976\n0.8284\n0.8139\n0.8115\n0.8196\n0.8336\n0.4067\n0.4035\n0.3654\n0.3972\n0.3987\n0.4386\n0.4312\n0.4257\n0.4304\n0.4340\n0.7659\n0.7593\n0.6977\n0.7621\n0.7633\n0.7224\n0.7193\n0.6625\n0.7081\n0.7148\n0.7386\n0.7347\n0.6767\n0.7312\n0.7354\n\nFigure 5: Critical difference (CD) diagram of the Nemenyi post-hoc test (α =\n0.10). The performance difference between two algorithms is significant if\nthe gap between their ranks is larger than CD. There is a horizontal line connecting the two algorithms if the rank gap between them is smaller than CD.\n\nby the human assessors, and the estimated values of these two\nproperties inferred by the SDR model.\n8\n\n\fTo support our argument about the efficacy of the SDR model\nin revealing the two key properties of images, we have selected\nfour images highlighted in different colours in Figure 4c with their\nimage ids. We can see that image 34 is inferred by our model to be\nboth easy and objective as both of its estimates shown in Figure 4c\nare the smallest. This can be re-confirmed by visual inspection of\nthe image in Figure 4f. It is very easy and clear to see that there\nis no sky in the image 34. Image 29 has been identified by our\nmodel to be hard with low subjectivity according to its estimates\nshown in Figure 4c. This is reasonable as the image indeed contains\nan extraterrestrial sky which is hard for novice workers to realise,\nwhile expert workers are able to realise and find the image objective.\nImages 2 and 23 both belong to the image beauty judgement task\nfrom [19] which requires workers to select 6 most beautiful images\nfrom 12 images. Our model has identified that image 2 is more\nsubjective and harder to judge. This is probably because image 2\ndelivers a view of scenery which is more likely to resonate with\nworkers while image 23 is merely showing an object. As a result,\nworkers tend to show more different feelings and opinions towards\nimage 2. On the other hand, image 23 does have better image quality\nand thus is easier for workers to make their decisions on whether\nit is beautiful or not.\n\n7\n\n[9] Ece Kamar, Ashish Kapoor, and Eric Horvitz. 2015. Identifying and accounting\nfor task-dependent bias in crowdsourcing. In Third AAAI Conference on Human\nComputation and Crowdsourcing.\n[10] Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization techniques for recommender systems. Computer 42, 8 (2009).\n[11] Matthew Lease and Gabriella Kazai. 2011. Overview of the trec 2011 crowdsourcing track. In Proceedings of the text retrieval conference (TREC).\n[12] Jongwuk Lee, Myungha Jang, Dongwon Lee, Won-Seok Hwang, Jiwon Hong,\nand Sang-Wook Kim. 2013. Alleviating the sparsity in collaborative filtering\nusing crowdsourcing. In Workshop on Crowdsourcing and Human Computation\nfor Recommender Systems (CrowdRec), Vol. 5.\n[13] Babak Loni, Maria Menendez, Mihai Georgescu, Luca Galli, Claudio Massari, Ismail Sengor Altingovde, Davide Martinenghi, Mark Melenhorst, Raynor\nVliegendhart, and Martha Larson. 2013. Fashion-focused Creative Commons\nSocial Dataset. In Proceedings of the 4th ACM Multimedia Systems Conference\n(MMSys ’13). ACM, New York, NY, USA, 72–77.\n[14] Barzan Mozafari, Purnamrita Sarkar, Michael J. Franklin, Michael I. Jordan, and\nSamuel Madden. 2012. Active Learning for Crowd-Sourced Databases. CoRR\nabs/1209.3686 (2012).\n[15] An Thanh Nguyen, Matthew Halpern, Byron C Wallace, and Matthew Lease.\n2016. Probabilistic modeling for crowdsourcing partially-subjective ratings.\n[16] Georg Rasch. 1993. Probabilistic models for some intelligence and attainment tests.\nERIC.\n[17] Vikas C Raykar, Shipeng Yu, Linda H Zhao, Gerardo Hermosillo Valadez, Charles\nFlorin, Luca Bogoni, and Linda Moy. 2010. Learning from crowds. Journal of\nMachine Learning Research 11, Apr (2010), 1297–1322.\n[18] Rion Snow, Brendan O’Connor, Daniel Jurafsky, and Andrew Y Ng. 2008. Cheap\nand fast—but is it good?: evaluating non-expert annotations for natural language\ntasks. In Proceedings of the conference on empirical methods in natural language\nprocessing. Association for Computational Linguistics, 254–263.\n[19] Yuandong Tian and Jun Zhu. 2012. Learning from crowds in the presence\nof schools of thought. In Proceedings of the 18th ACM SIGKDD international\nconference on Knowledge discovery and data mining. ACM, 226–234.\n[20] Matteo Venanzi, John Guiver, Gabriella Kazai, Pushmeet Kohli, and Milad Shokouhi. 2014. Community-based bayesian aggregation models for crowdsourcing.\nIn Proceedings of the 23rd international conference on World wide web. ACM,\n155–164.\n[21] Ellen M Voorhees. 2000. Variations in relevance judgments and the measurement\nof retrieval effectiveness. Information processing & management 36, 5 (2000),\n697–716.\n[22] Jiannan Wang, Tim Kraska, Michael J Franklin, and Jianhua Feng. 2012. Crowder:\nCrowdsourcing entity resolution. Proceedings of the VLDB Endowment 5, 11\n(2012), 1483–1494.\n[23] Peter Welinder, Steve Branson, Pietro Perona, and Serge J Belongie. 2010. The\nmultidimensional wisdom of crowds. In Advances in neural information processing\nsystems. 2424–2432.\n[24] Jacob Whitehill, Paul Ruvolo, Tingfan Wu, Jacob Bergsma, and Javier R. Movellan.\n2009. Whose Vote Should Count More: Optimal Integration of Labels from\nLabelers of Unknown Expertise. In 23rd Annual Conference on Neural Information\nProcessing Systems, NIPS’09. 2035–2043.\n[25] Jacob Whitehill, Ting-fan Wu, Jacob Bergsma, Javier R Movellan, and Paul L\nRuvolo. 2009. Whose vote should count more: Optimal integration of labels\nfrom labelers of unknown expertise. In Advances in neural information processing\nsystems. 2035–2043.\n[26] Denny Zhou, Sumit Basu, Yi Mao, and John C. Platt. 2012. Learning from the\nWisdom of Crowds by Minimax Entropy. In Advances in Neural Information\nProcessing Systems 25, F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger (Eds.). Curran Associates, Inc., 2195–2203. http://papers.nips.cc/paper/\n4490-learning-from-the-wisdom-of-crowds-by-minimax-entropy.pdf\n\nCONCLUSIONS\n\nIn this paper, we have proposed the SDR (Subjectivity-and-Difficulty\nResponse) model, a novel quality-control framework for crowdsourcing that is able to distinguish question subjectivity, which\ncauses worker-specific truth for individual questions, from question difficulty, which determines the probability that a worker’s\nresponse to each question equals her perceived subjective truth.\nExperiment results show that our model improves both the correct\nanswer prediction for questions and the held-out unseen response\nprediction for crowd-workers compared to five baselines across\nnumerous partially subjective crowdsourcing datasets. Moreover,\nour model shows robustness to both the objective and the partially\nsubjective datasets by discovering the right numbers of underlying\nworker groups for them. Finally, our model is able to provide estimates of the difficulty and the subjectivity of questions that are\nconsistent with the judgements from human assessors.\n\nREFERENCES\n[1] [n. d.]. Adult Datset. https://github.com/ipeirotis/Get-Another-Label/tree/\nmaster/data. ([n. d.]). Accessed: 2017-07-30.\n[2] Yoram Bachrach, Thore Graepel, Tom Minka, and John Guiver. 2012. How to\ngrade a test without knowing the answers—a Bayesian graphical model for\nadaptive crowdsourcing and aptitude testing. arXiv preprint arXiv:1206.6386\n(2012).\n[3] David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent Dirichlet\nallocation. Journal of machine Learning research 3, Jan (2003), 993–1022.\n[4] Chris Buckley, Matthew Lease, and Mark D Smucker. [n. d.]. Overview of the\ntrec 2010 relevance feedback track (notebook).\n[5] Alexander Philip Dawid and Allan M Skene. 1979. Maximum likelihood estimation of observer error-rates using the EM algorithm. Applied statistics (1979),\n20–28.\n[6] Janez Demšar. 2006. Statistical comparisons of classifiers over multiple data sets.\nJournal of Machine Learning Research 7 (2006), 1–30.\n[7] Hyun Joon Jung. 2014. Quality assurance in crowdsourcing via matrix factorization based task routing. In Proceedings of the 23rd International Conference on\nWorld Wide Web. ACM, 3–8.\n[8] Hyun Joon Jung and Matthew Lease. 2013. Crowdsourced task routing via matrix\nfactorization. arXiv preprint arXiv:1310.5142 (2013).\n9\n\n\f",
         "train",
         "54945",
         "9146"
        ],
        [
         "11",
         "19522",
         "cs.AI",
         "Artificial Intelligence",
         "1711.03539v2.pdf",
         "A Change-Detection based Framework for\nPiecewise-stationary Multi-Armed Bandit Problem\nFang Liu and Joohyun Lee and Ness Shroff\n\narXiv:1711.03539v2 [cs.LG] 20 Nov 2017\n\nThe Ohio State University\nColumbus, Ohio 43210\n{liu.3977, lee.7119, shroff.11}@osu.edu\n\nAbstract\nThe multi-armed bandit problem has been extensively studied under the stationary assumption. However in reality, this\nassumption often does not hold because the distributions of\nrewards themselves may change over time. In this paper, we\npropose a change-detection (CD) based framework for multiarmed bandit problems under the piecewise-stationary setting, and study a class of change-detection based UCB (Upper\nConfidence Bound) policies, CD-UCB, that actively detects\nchange points and restarts the UCB indices. We then develop\nCUSUM-UCB and PHT-UCB, that belong to the CD-UCB\nclass and use cumulative sum (CUSUM) and Page-Hinkley\nTest (PHT) to detect changes. We show that CUSUM-UCB\nobtains the best known regret upper bound under mild assumptions. We also demonstrate the regret reduction of the\nCD-UCB policies over arbitrary Bernoulli rewards and Yahoo! datasets of webpage click-through rates.\n\n1\n\nIntroduction\n\nThe multi-armed bandit problem, introduced by Thompson (1933), models sequential allocation in the presence of\nuncertainty and partial feedback on rewards. It has been\nextensively studied and has turned out to be fundamental\nto many problems in artificial intelligence, such as reinforcement learning (Sutton and Barto 1998), online recommendation systems (Li, Karatzoglou, and Gentile 2016) and\ncomputational advertisement (Buccapatnam et al. 2017). In\nthe classical multi-armed bandit problem (Lai and Robbins\n1985), a decision maker needs to choose one of K independent arms and obtains the associated reward in a sequence\nof time slots (rounds). Each arm is characterized by an unknown reward distribution and the rewards are independent\nand identically distributed (i.i.d.).\nThe goal of a bandit algorithm, implemented by the decision maker, is to minimize the regret over T time slots,\nwhich is defined as the expectation of the difference between the total rewards collected by playing the arm with\nthe highest expected reward and the total rewards obtained\nby the algorithm. To achieve this goal, the decision maker\nis faced with an exploration versus exploitation dilemma,\nwhich is the trade-off between exploring the environment\nCopyright c 2018, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\n\nto find the most profitable arms and exploiting the current empirically best arm as often as possible. A problemdependent regret lower bound, Ω(log T ), of any algorithm\nfor the classical bandit problem has been shown in Lai\nand Robbins (1985). Several algorithms have been proposed\nand proven to achieve O(log T ) regret, such as Thompson\nSampling (Agrawal and Goyal 2012), \u000fn -greedy and Upper Confidence Bound (UCB) (Auer, Cesa-Bianchi, and Fischer 2002). Variants of these bandit policies can be found\nin Bubeck and Cesa-Bianchi (2012).\nAlthough the stationary (classical) multi-armed bandit\nproblem is well-studied, it is unclear whether it can achieve\nO(log T ) regret in a non-stationary environment, where the\ndistributions of rewards change over time. This setting often occurs in practical problems. For example, consider the\ndynamic spectrum access problem (Alaya-Feki, Moulines,\nand LeCornec 2008) in communication systems. Here, the\ndecision maker wants to exploit the empty channel, thus improving the spectrum usage. The availability of a channel\nis dependent on the number of users in the coverage area.\nThe number of users, however can change dramatically with\ntime of day and, therefore, is itself a non-stationary stochastic process. Hence, the availability of the channel also follows a distribution that is not only unknown, but varies\nover time. To address the changing environment challenge,\na non-stationary multi-armed bandit problem has been proposed in the literature. There are two main approaches to\ndeal with the non-stationary environment: passively adaptive policies (Garivier and Moulines 2008; Besbes, Gur, and\nZeevi 2014; Wei, Hong, and Lu 2016) and actively adaptive policies (Hartland et al. 2007; Mellor and Shapiro 2013;\nAllesiardo and Féraud 2015).\nFirst, passively adaptive policies are unaware of when\nchanges happen but update their decisions based on the most\nrecent observations in order to keep track of the current\nbest arm. Discounted UCB (D-UCB), introduced by Kocsis and Szepesvári (2006), where geometric moving average over the samples is applied to the UCB index of each\narm, has\n√ been shown to achieve the regret upper-bounded\nby O( γT T log T ), where γT is the number of change\npoints up to time T (Garivier and Moulines 2008). Based\non the analysis of D-UCB, they also proposed and analyzed\nSliding-Window UCB (SW-UCB), where the algorithm updates the UCB index based on the observations within a\n\n\fmoving window\n√ of a fixed length. The regret of SW-UCB\nis at most O( γT T log T ). Exp3.S (Auer et al. 2002) also\nachieves the same regret bound, where a uniform exploration\nis mixed with the standard Exp3 (Cesa-Bianchi and Lugosi\n2006) algorithm. Similarly, Besbes, Gur, and Zeevi (2014)\nproposed a Rexp3 algorithm, which restarts the Exp3 algorithm periodically. It is shown that the regret is upper1/3\nbounded by O(VT T 2/3 ), where VT denotes the total reward variation budget up to time T .1 The increased regret of\nRexp3 comes from the adversarial nature of the algorithm,\nwhich assumes that the environment changes every time slot\nin the worst case.\nSecond, actively adaptive policies adopt a change detection algorithm to monitor the varying environment and\nrestart the bandit algorithms when there is an alarm. AdaptEvE, proposed by Hartland et al. (2007), employs a PageHinkley Test (PHT) (Hinkley 1971) to detect change points\nand restart the UCB policy. PHT has also been used to\nadapt the window length of SW-UCL (Srivastava, Reverdy,\nand Leonard 2014), which is an extension of SW-UCB in\nthe multi-armed bandit with Gaussian rewards. However,\nthe regret upper bounds of Adapt-EvE and adaptive SWUCL are still open problems. These works are closely related to our work, as one can regard them as instances of\nour change-detection based framework. We highlight that\none of our contributions is to provide an analytical result\nfor such a framework. Mellor and Shapiro (2013) took a\nBayesian view of the non-stationary bandit problem, where\na stochastic model of the dynamic environment is assumed\nand a Bayesian online change detection algorithm is applied. Similar to the work by Hartland et al. (2007), the theoretical analysis of the Change-point Thompson Sampling\n(CTS) is still open. Exp3.R (Allesiardo and Féraud 2015)\ncombines\n√ Exp3 and a drift detector, and achieves the regret\nO(γT T log T ), which is not efficient when the change rate\nγT is high.\nIn sum, for various passively adaptive policies theoretical guarantees have been obtained, as they are considered\nmore tractable to analyze. However, it has been demonstrated via extensive numerical studies that actively adaptive policies outperform passively adaptive policies (Mellor\nand Shapiro 2013). The intuition behind this is that actively\nadaptive policies can utilize the balance between exploration\nand exploitation by bandit algorithms, once a change point\nis detected and the environment stays stationary for a while,\nwhich is often true in real world applications. This observation motivates us to construct a change-detection based\nframework, where a class of actively adaptive policies can\nbe developed with both good theoretical bounds and good\nempirical performance. Our main contributions are as follows.\n1. We propose a change-detection based framework for a\npiecewise-stationary bandit problem, which consists of a\nchange detection algorithm and a bandit algorithm. We\ndevelop a class of policies, CD-UCB, that uses UCB\nas a bandit algorithm. We then design two instances\n\nof this class, CUSUM-UCB and PHT-UCB, that exploit\nCUSUM (cumulative sum) and PHT as their change detection algorithms, respectively.\n2. We provide a regret upper bound for the CD-UCB class,\nfor given change detection performance. For CUSUM, we\nobtain an upper bound on the mean detection delay and\na lower bound on the mean time between false alarms,\nandqshow that the regret of CUSUM-UCB is at most\nO( T γT log γTT ). To the best of our knowledge, this is\nthe first regret bound for actively adaptive UCB policies\nin the bandit feedback setting.\n3. The performance of the proposed and existing policies\nare validated by both synthetic and real world datasets,\nand we show that our proposed algorithms are superior to\nother existing policies in terms of regret.\n\nP −1\nVT satisfies Tt=1\nsupi∈K |µt (i) − µt+1 (i)| ≤ VT for the\nexpected reward of arm i at time t, µt (i).\n\nNote that the regret Rπ (T ) of policy π is upper-bounded\nPK\nby i=1 E[ÑT (i)] since the rewards are bounded in (1). In\n\n1\n\nWe present the problem setting in Section 2 and introduce\nour framework in Section 3. We propose our algorithms in\nSection 4. We then present performance guarantees in Section 5. In Section 6, we compare our algorithms with other\nexisting algorithms via simulation. Finally, we conclude the\npaper.\n\n2\n2.1\n\nProblem Formulation\n\nBasic Setting\n\nLet K = {1, . . . , K} be a set of arms. Let {1, 2, . . . , T }\ndenote the decision slots faced by a decision maker and T\nis the time horizon. At each time slot t, the decision maker\nchooses an arm It ∈ K and obtains a reward Xt (It ) ∈ [0, 1].\nNote that the results can be generalized to any bounded interval. The rewards {Xt (i)}t≥1 for arm i are modeled by a\nsequence of independent random variables from potentially\ndifferent distributions, which are unknown to the decision\nmaker. Let µt (i) denote the expectation of reward Xt (i) at\ntime slot t, i.e., µt (i) = E[Xt (i)]. Let i∗t be the arm with\nhighest expected reward at time slot t, denoted by µt (∗) ,\nµt (i∗t ) = maxi∈K µt (i). Let ∆µT (i) , min{µt (∗) − µt (i) :\nt ≤ T, i 6= i∗t }, be the minimum difference over all time\nslots between the expected rewards of the best arm i∗t and\nthe arm i while the arm i is not the best arm.\nA policy π is an algorithm that chooses the next arm to\nplay based on the sequence of past plays and obtained rewards. The performance of a policy π is measured in terms\nof the regret. The regret of π after T plays is defined as the\nexpected total loss of playing suboptimal arms. Let Rπ (T )\ndenote the regret of policy π after T plays and let ÑT (i) be\nthe number of times arm i has been played when it is not the\nbest arm by π during the first T plays.\n\" T\n#\nX\n∗\nRπ (T ) = E\n(Xt (it ) − Xt (It )) ,\n(1)\nt=1\n\nÑT (i) =\n\nT\nX\n\n1{It =i, µt (i)6=µt (∗)} .\n\n(2)\n\nt=1\n\n\fSection 5, we provide an upper bound on E[ÑT (i)] to obtain\na regret upper bound.\n\n2.2\n\n“alarms” to restart\t\n\n\nPiecewise-stationary Environment\n\nWe consider the notion of a piecewise-stationary environment in Yu and Mannor (2009), where the distributions of\nrewards remain constant for a certain period and abruptly\nchange at some unknown time slots, called breakpoints.\nLet γT be the number of breakpoints up to time T , γT =\nPT −1\nt=1 1{∃i∈K:µt (i)6=µt+1 (i)} . In addition, we make three\nmild assumptions for tractability.\nAssumption 1. (Piecewise Stationarity) The shortest interval between two consecutive breakpoints is greater than\nKM , for some integer M .\nAssumption 1 ensures that the shortest interval between\ntwo successive breakpoints is greater than KM , so that we\nhave enough samples to estimate the mean of each arm before the change happens. Note that this assumption is equivalent to the notions of an abruptly changing environment\nused in Garivier and Moulines (2008) and a switching environment in Mellor and Shapiro (2013). However, it is different from the adversarial environment assumption, where\nthe environment changes all the time. We make a similar assumption as Assumption 4.2 in Yu and Mannor (2009) about\nthe detectability in this paper.\nAssumption 2. (Detectability) There exists a known parameter \u000f > 0, such that ∀i ∈ K and ∀t ≤ T − 1, if\nµt (i) 6= µt+1 (i), then |µt (i) − µt+1 (i)| ≥ 3\u000f.\nAssumption 2 excludes infinitesimal mean shift, which\nis reasonable in practice when detecting abrupt changes\nbounded from below by a certain threshold.\nAssumption 3. (Bernoulli Reward) The distributions of all\nthe arms are Bernoulli distributions.\nAssumption 3 has also been used in the literature (Besbes, Gur, and Zeevi 2014; Mellor and Shapiro 2013;\nKaufmann, Korda, and Munos 2012; Agrawal and Goyal\n2012). By Assumption 3, the empirical average of M\nBernoulli random variables must be one of the grid\npoints {0, 1/M, . . . , 1}. Let λT (i) = min{(µt (i) − \u000f) −\nb(µt (i) − \u000f)M c/M, d(µt (i) + \u000f)M e/M − (µt (i) + \u000f) : t ≤\nT } \\ {0} be the minimal non-trival gap between expectation\nand closest grid point of arm i.2 We define the minimal gap\nof all arms as λ = mini∈K λT (i).\n\n3\n\nChange-Detection based Framework\n\nOur change-detection based framework consists of two components: a change detection algorithm and a bandit algorithm, as shown in Figure 1. At each time t, the bandit algorithm outputs a decision It ∈ K based on its past observations of the bandit environment. The environment generates the corresponding reward of arm It , which is observed\nby both the bandit algorithm and the change detection algorithm. The change detection algorithm monitors the distribution of each arm, and sends out a positive signal to restart\n2\n\nChange\ndetection\nalgorithm\n\nNote that b·c denotes the floor function and d·e denotes the\nceiling function.\n\nBandit\nalgorithm\narm\n\nreward\n\nXt(It)\t\n\n\nNon-stationary\nbandit\nenvironment\n\nIt\t\n\n\nFigure 1: Change-detection based framework for nonstationary bandit problems\nthe bandit algorithm once a breakpoint is detected. One can\nfind that our framework is a generalization of the existing\nactively adaptive policies.\nSince the bandit algorithms are well-studied in the bandit setting, what remains is to find a change detection algorithm, which works in the bandit environment. Change point\ndetection problems have been well studied, see, e.g., the\nbook (Basseville and Nikiforov 1993). However, the change\ndetection algorithms are applied in a context that is quite different from the bandit setting. There are two key challenges\nin adapting the existing change detection algorithms in the\nbandit setting.\n(1) Unknown priors: In the context of the change detection problem, one usually assumes that the prior distributions before and after a change point are known. However,\nsuch information is unknown to the decision maker in the\nbandit setting. Even though there are some simple methods,\nsuch as estimating the priors and then applying the change\ndetection algorithm like PHT, there are no analytical results\nin the literature.\n(2) Insufficient samples: Due to the bandit feedback setting, the decision maker can only observe one arm at each\ntime. However, there are K change detection algorithms\nrunning in parallel since each arm is associated with a\nchange detection procedure to monitor the possible mean\nshift. So the change detection algorithms in most arms are\nhungry for samples at each time. If the decision maker does\nnot feed these change detection algorithms intentionally, the\nchange detection algorithm may miss detection opportunities because they do not have enough recent samples.\n\n4\n\nApplication of the Framework\n\nIn this section, we introduce our Change-Detection based\nUCB (CD-UCB) policy, which addresses the issue of insufficient samples. Then we develop a tailored CUSUM algorithm for the bandit setting to overcome the issue of unknown priors. Finally, we combine our CUSUM algorithm\nwith the UCB algorithm as CUSUM-UCB policy, which is a\nspecific instance of our change-detection based framework.\nPerformance analysis is provided in Section 5.\n\n4.1\n\nCD-UCB policy\n\nSuppose we have a change detection algorithm, CD(·, ·),\nwhich takes arm index i and observation Xt (i) as input at\n\n\fAlgorithm 1 CD-UCB\n\nAlgorithm 2 Two-sided CUSUM\n\nRequire: T , α and an algorithm CD(·, ·)\nInitialize τi = 1, ∀i.\nfor t from 1 to T do\nUpdate according to equations (3-5).\nPlay arm It and observe Xt (It ).\nif CD(It , Xt (It )) == 1 then\nτIt = t + 1; reset CD(It , ·).\nend if\nend for\n\nRequire: parameters \u000f, M , h and {yk }k≥1\nInitialize g0+ = 0 and g0− = 0.\nfor each k do\n+\nCalculate s−\nk and sk according to (6).\n+\n−\nUpdate gk and gk according to (7).\nif gk+ ≥ h or gk− ≥ h then\nReturn 1\nend if\nend for\n\ntime t, and it returns 1 if there is an alarm for a breakpoint.\nGiven such a change detection algorithm, we can employ it\nto control the UCB algorithm, which is our CD-UCB policy\nas shown in Algorithm 1. We clarify some useful notations\nas follows. Let τi = τi (t) be the last time that the CD(i, ·)\nalarms and restarts for arm i before time t. Then the number of valid observations (after the latest detection alarm)\nfor arm i up to time t is denoted as Nt (i). Let nt be the total number of valid observations for the decision maker. For\neach arm i, let X̄t (i) be the sample average and Ct (i) be the\nconfidence padding term. In particular,\nNt (i) =\n\nt\nX\ns=τi\n\n1{Is =i} , nt =\n\nK\nX\n\nNt (i),\n\n(3)\n\ni=1\n\nt\nX\nXs (i)\nX̄t (i) =\n1{Is =i} , Ct (i) =\nNt (i)\ns=τ\ni\n\ns\n\nξ log nt\n,\nNt (i)\n\n(4)\n\nwhere ξ is some positive real number. Thus, the UCB index\nfor each arm i is X̄t (i) + Ct (i). Parameter α is a tuning\nparameter we introduce in the CD-UCB policy. At each time\nt, the policy plays the arm\n\u0001\n\u001a\narg maxi∈K X̄t (i) + Ct (i) , w.p. 1 − α\nIt =\nα . (5)\ni,\n∀i ∈ K, w.p. K\nParameter α controls the fraction of plays we exploit to\nfeed the change detection algorithm. A large α may drive\nthe algorithm to a linear regret performance while a small α\ncan limit the detectability of change detection algorithm. We\nwill discuss the choice of α in Sections 5 and 6.\n\n4.2\n\nTailored CUSUM algorithm\n\nA change detection algorithm observes a sequence of independent random variables, y1 , y2 , . . ., in an online manner,\nand outputs an alarm once a change point is detected. In the\ncontext of the traditional change detection problem, one assumes that the parameters θ0 and θ1 are known for the density function p(·|θ). In addition, yk is sampled from distribution under θ0 (θ1 ) before (after) the breakpoint. Let u0\n(u1 ) be the mean of yk before (after) the change point. The\nCUSUM algorithm, originally proposed by (Page 1954), has\nbeen proven to be optimal in detecting abrupt changes in the\nsense of worst mean detection delay (Lorden 1971). The basic idea of the CUSUM algorithm is to take a function of\n\nthe observed sample (e.g., the logarithm of likelihood ratio\nk |θ1 )\nlog p(y\np(yk |θ0 ) ) as the step of a random walk. This random walk\nis designed to have a positive mean drift after a change point\nand have a negative mean drift without a change. Hence,\nCUSUM signals a change if this random walk crosses some\npositive threshold h.\nWe propose a tailored CUSUM algorithm that works in\nthe bandit setting. To be specific, we use the first M samples\nPM\nto calculate the average, û0 , ( k=1 yk )/M. Then we construct two random walks, which have negative mean drifts\nbefore the change point and have positive mean drifts after\nthe change. In particular, we design a two-sided CUSUM algorithm, described in Algorithm 2, with an upper (lower)\nrandom walk monitoring the possible positive (negative)\n−\nmean shift. Let s+\nk (sk ) be the step of the upper (lower) ran+\ndom walk. Then sk and s−\nk are defined as\n−\n(s+\nk , sk ) = (yk − û0 − \u000f, û0 − yk − \u000f)1{k>M } .\n\n(6)\n\nLet gk+ (gk− ) track the positive drift of upper (lower) random\nwalk. In particular,\n+\n−\n−\n−\ngk+ = max(0, gk−1\n+ s+\nk ), gk = max(0, gk−1 + sk ).\n(7)\n\nThe change point is detected when either of them crosses the\nthreshold h. The parameter h is important in the detection\ndelay and false alarm trade-off. We discuss the choice of h\nin Section 5.\n\n4.3\n\nCUSUM-UCB policy\n\nNow we are ready to introduce our CUSUM-UCB policy,\nwhich is a CD-UCB policy with CUSUM as a change detection algorithm. In particular, it takes K parallel CUSUM\nalgorithms as CD(·, ·) in CD-UCB. Formal description of\nCUSUM-UCB can be found in Algorithm 3, provided in\nSection F in the supplementary material.\n\n4.4\n\nPHT-UCB policy\n\nWe introduce another instance of our CD-UCB with the\nPHT algorithm (Hinkley 1971) running as the change detection algorithm, named PHT-UCB. PHT can be viewed as\n−\na variant of Algorithm 2 by replacing (6) with (s+\nk , sk ) =\nP\nk\n(yk − ŷk − \u000f, ŷk − yk − \u000f), where ŷk = k1 s=1 ys .\n\n\f5\n\n+\n\nPerformance Analysis\n\nIn this section, we analyze the performance in each part of\nthe proposed algorithm: (a) our bandit algorithm (i.e., CDUCB), and (b) our change detection algorithm (i.e., twosided CUSUM). First, we present the regret upper bound\nresult of CD-UCB for a given change detection guarantee.\nThis is of independent interest in understanding the challenges of the non-stationary environment. Second, we provide performance guarantees of our modified CUSUM algorithm in terms of the mean detection delay, E[D], and the\nexpected number of false alarms up to time T , E[F ]. Then,\nwe combine these two results to provide the regret upper\nbound of our CUSUM-UCB. The proofs are presented in\nour supplementary material.\nTheorem 1. (CD-UCB) Let ξ = 1. Under Assumption 1, for\nany α ∈ [0, 1) and any arm i ∈ {1, . . . , K}, the CD-UCB\npolicy achieves,\n\u0010\n\u0011\nE[ÑT (i)] ≤ (γT + E[F ]) · (∆4µlog(i)T)2 + π 2 /3\n(8)\nT\n\n2\n+ π3\n\n+ γT · E[D] +\n\nαT\nK\n\n.\n\nRecall that the regret of the CD-UCB policy is upperPK\nbounded by i=1 E[ÑT (i)]. Therefore, given the parameter\nvalues (e.g., α) and the performance of a change detection\nalgorithm (i.e., E[F ] and E[D]), we can obtain the regret upper bound of that change detection based bandit algorithm.\nBy letting α = 0, we obtain the following result.\nCorollary 1. (CD-UCB|α = 0) If α = 0 and ξ = 1, then\nthe regret of CD-UCB is\nRπCD-UCB (T ) = O((γT + E[F ]) · log T + γT · E[D])). (9)\nRemark 1. If one can find an oracle algorithm that detects\nthe change point with the properties that E[F ] ≤ O(γT )\nand E[D] ≤ O(log T ), then one can achieve O(γT log T )\nregret, which recovers the regret result in Yu and Mannor (2009). We note that the WMD (Windowed Mean-shift\nDetection) change detection algorithm proposed by Yu and\nMannor (2009) achieves these properties when side observations are available.\nIn the next proposition, we introduce the result of Algorithm 2 about the conditional expected detection delay and\nthe conditional expected number of false alarms given û0 .\nNote that the expectations exclude the first M slots for initial observations.\nProposition 1. (CUSUM|û0 ) Recall that h is the tuning parameter in Algorithm 2. Under Assumptions 1 and 2, the\nconditional expected detection delay E [D||û0 − u0 | < \u000f]\nand the conditional expected number of false alarms\nE [F ||û0 − u0 | < \u000f] satisfy\nh+1\n,\n|u1 − û0 | − \u000f\n2T\nE [F ||û0 − u0 | < \u000f] ≤\n,\nexp(r(θ0 )h)\n\nE [D||û0 − u0 | < \u000f] ≤\n\n(10)\n(11)\n\nwhere r(θ0 ) = min(r− (θ0 ), r+ (θ0 )), r− (θ0 ) is the non−\nzero root of log Eθ0 [ersM +1 ] and r+ (θ0 ) is the non-zero root\n\nof log Eθ0 [ersM +1 ]. In the case of |û0 − u0 | > \u000f, the algoh+1\ntime slots.\nrithm restarts in at most |û0 −u\n0 |−\u000f\nIn the next theorem, we show the result for E[D] and E[F ]\nwhen CUSUM is used to detect the abrupt change. Note\nagain that the expectations exclude the first M time slots.\nTheorem 2. (CUSUM) Under Assumptions 1, 2 and 3, the\nexpected detection delay E[D] and the expected number of\nfalse alarms E[F ] of the Algorithm 2 satisfy\nE[D] ≤C2 (h + 1),\nE[F ] ≤\nwhere\nC1−\nlog\n\n2T\n,\n(1 − 2 exp(−2\u000f2 M )) exp(C1 h)\n\nC2\n,\n\n\u0010\n\n(12)\n\nlog\n\n\u0010,\n\nM\n4\u000f\n(1+\u000f)2 d2\u000fM e\n\n(13)\n\n2\nlog(3) + 2 exp(−2\u000f\nM )/λ,\n\u0011\n\u0001\nM\n(2\u000f) + 1 , C1+\n,\n\u0011\n+ 1 and C1 , min(C1− , C1+ ).\n\nM\n4\u000f\n(1−\u000f)2 b2\u000fM c\n\n\u0001\n\n(2\u000f)M\n\nSumming the result of Theorems 1 and 2, we obtain the\nregret upper bound of the CUSUM-UCB policy. To the best\nof our knowledge, this is the first regret bound for an actively\nadaptive UCB policy in the bandit feedback setting.\nTheorem 3. (CUSUM-UCB) Let ξ = 1. Under Assumptions 1, 2 and 3, for any α ∈ (0, 1) and any arm i ∈\n{1, . . . , K}, the CUSUM-UCB policy achieves,\nE[ÑT (i)] ≤ R1 · R2 +\n\nαT\nπ2\n+\n,\n3\nK\n\n(14)\n\n2T\n,\n(1 − 2 exp(−2\u000f2 M )) exp(C1 h)\n4 log T\nπ2\nC2 (h + 1)K\nR2 =\n+\n+M +\n.\n2\n(∆µT (i) )\n3\nα\n\nfor R1 = γT +\n\nCorollary 2. Under the Assumptions 1, 2 and 3, if horizon T and the number of breakpoints γT are known in\nadvance, then we can choose h = C11 log γTT and α =\nq\nK CC21γTT log γTT so that\ns\n!\nγT log T\nT\n+ T γT log\nRπCUSUM-UCB (T ) = O\n.\n(∆µT (i) )2\nγT\n(15)\nRemark 2. The choices of parameters depend on the knowledge of γT . This is common in the non-stationary bandit literature. For example, the discounting factor of D-UCB and\nsliding window size of SW-UCB depend on the knowledge\nof γT . The batch size of Rexp3 depends on the knowledge\nof VT , which denotes the total reward variation. It is practically viable when the reward change rate is regular such\nthat one can accurately estimate γT based on history.\nRemark 3. As shown in Garivier and\n√ Moulines (2008),\nthe lower bound of the problem is Ω( T ). Our policy approaches the optimal regret rate in an order sense.\nRemark 4. For the SW-UCB\n\u0010 √policy, the\u0011 regret analysis\nT γT log T\nresult is RπSW-UCB (T ) = O (∆\n(Garivier and\n2\nµ (i) )\nT\n\n\fTable 1: Comparison of regret bounds in various algorithms.\n\nlower bound\n\n(Kocsis and Szepesvári 2006) (Garivier and Moulines 2008) (Besbes, Gur, and Zeevi 2014) (Hartland et al. 2007)\n\n√\nO( T γT log T )\n\n√\nO( T γT log T )\n\n1/3\n\nO(VT\n\nMoulines 2008). If ∆µT (i) is a constant with respect to T ,\n√\nthen T γT log T term dominates and our policy achieves\nthe same regret rate as SW-UCB. If ∆µT (i) goes to 0 as T increases, then the regret of CUSUM-UCB grows much slower\nthan SW-UCB.\nTable 1 summarizes the regret upper bounds of the existing and proposed algorithms in the non-stationary setting\nwhen ∆µT (i) is a constant in T . Our policy has a smaller\nregret term with respect to γT compared to SW-UCB.\n\n6\n\nT 2/3 )\n\nSynthetic Datasets\n\nFlipping Environment. We consider two arms (i.e., K = 2)\nin the flipping environment, where arm 1 is stationary and\nthe expected reward of arm 2 flips between two values. All\narms are associated with Bernoulli distributions. In particular, µt (1) = 0.5 for any t ≤ T and\n\u001a\n0.5 − ∆, T3 ≤ t ≤ 2T\n3 .\n(16)\nµt (2) =\n0.8,\notherwise\nThe two change points are at T3 and 2T\n3 . Note that ∆ is\nequivalent to ∆µT (2) . We let ∆ vary within the interval\n[0.02, 0.3], and compare the regrets of D-UCB, SW-UCB\nand CUSUM-UCB to verify Remark 4. For this reason, results of other algorithms are omitted. As shown in Figure 2a,\nCUSUM-UCB outperforms D-UCB and SW-UCB. In addition, the gap between CUSUM-UCB and SW-UCB increases as ∆ decreases.\n\n(Garivier and Moulines 2008)\n\nO(\n\nUnknown\n\nq\n\nT γT log\n\nT\nγT\n\n√\nΩ( T )\n\n)\n\n4\n2.5 ×10\n\nD-UCB\nSW-UCB\nCUSUM-UCB\n\n2\n1.5\n1\n0.5\n0\n\nSimulation Results\n\nWe evaluate the existing and proposed policies in three nonstationary environments: two synthetic dataset (flipping and\nswitching scenarios) and one real-world dataset from Yahoo! (Yahoo! ). Yahoo! dataset collected user click traces\nfor news articles. Our PHT-UCB is similar to Adapt-EvE,\nbut they are different in that Adapt-EvE ignores the issue\nof insufficient samples and includes other heuristic methods\ndealing with the detection points.\nIn the simulation, the parameters\nh and α are tuned around\np\nh = log(T /γT ) and α = γTT log(T /γT ) based on the flipping environment. We suggest the practitioners to take the\nsame approach because the choices of h and α in Corollary\n2 are minimizing the regret upper bound rather than the regret. We use the same parameters h and α for CUSUM-UCB\nand PHT-UCB to compare the performances of CUSUM and\nPHT. Parameters are listed in Table 2 in Section G of the appendix. Note that \u000f and M are obtained based on the prior\nknowledge of the datasets. The baseline algorithms are tuned\nsimilarly with the knowledge of γT and T . We take the average regret over 1000 trials for the synthetic dataset.\n\n6.1\n\nActively adaptive\nAdapt-EvE\nCUSUM-UCB\n\nRexp3\n\nRegret\n\nRegret\n\nPassively adaptive\nSW-UCB\n\n0\n\n0.05\n\n0.1\n\n0.15\n\n0.2\n\n0.25\n\n0.3\n\nParameter ∆\n(a) Under the flipping environment\n5\n3.5 ×10\n\nExp3.R\nD-UCB\nRexp3\nSW-UCB\nExp3.S\nCUSUM-UCB\nPHT-UCB\n\n3\n2.5\n\nRegret\n\nPolicy\n\nD-UCB\n\n2\n1.5\n1\n0.5\n0\n\n0\n\n2\n\n4\n\n6\n\n8\n\nTime\n\n10\n×105\n\n(b) Under the switching environment\n\nFigure 2: Regret over synthetic datasets\nSwitching Environment. We consider the switching environment, introduced by Mellor and Shapiro (2013), which\nis defined by a hazard function, β(t), such that,\n\u001a\nµt−1 (i),\nwith probability 1 − β(t)\nµt (i) =\n. (17)\nµ ∼ U [0, 1], with probability β(t)\nNote that U [0, 1] denotes the uniform distribution over\nthe interval [0, 1] and µ0 (i) are independent samples from\nU [0, 1]. In the experiments, we use the constant hazard function β(t) = γT /T . All the arms are associated with a\nBernoulli distribution.\nThe regrets over the time horizon are shown in Figure 2b.\nAlthough Assumptions 1 and 2 are violated, CUSUM-UCB\nand PHT-UCB outperform the other policies. To find the\npolynomial order of the regret, we use the non-linear least\nsquares method to fit the curves to the model atb + c.\nThe resulting exponents b of Exp3.R, D-UCB, Rexp3, SWUCB, Exp3.S, CUSUM-UCB and PHT-UCB are 0.92, 0.89,\n\n\farm 1\n\n0.06\n\n2\n\n3\n\n4\n\n5\n\n0.04\n0.03\n\n1\n\n0.5\n\n0.02\n0.01\n\nD-UCB\nRexp3\nSW-UCB\nExp3.R\nExp3.S\nCUSUM-UCB\nPHT-UCB\n\n1.5\n\n0.05\n\nRegret\n\nAverage rewards of arms\n\n4\n2 ×10\n\n0.07\n\n0\n\n1\n\n2\n\n3\n\n4\n\nTime\n\n5\n×105\n\n(a) Ground truth\n\n0\n\n0\n\n0.5\n\n1\n\nTime\n\n1.5\n\n2\n×106\n\nFigure 4: Regret over the Yahoo! dataset with K = 100\n\n4000\n\nD-UCB\nRexp3\nSW-UCB\nExp3.R\nExp3.S\nCUSUM-UCB\nPHT-UCB\n\n3500\n\nRegret\n\n3000\n2500\n2000\n1500\n1000\n500\n0\n\n0\n\n1\n\n2\n\n3\n\nTime\n\n4\n\n5\n×105\n\n(b) Regret\n\nFigure 3: Rewards and regret over the Yahoo! dataset with\nK=5\n\n0.85, 0.84, 0.83, 0.72 and 0.69, respectively. The regret of\nCUSUM-UCB and PHT-UCB shows the better sublinear\nfunction of time compared to the other policies. Another observation is that PHT-UCB performs better than CUSUMUCB, although we could not find a regret upper bound for\nPHT-UCB. The reason behind is that the PHT test is more\nstable and reliable (due to the updated estimation ŷk ) in the\nswitching environment.\n\n6.2\n\nYahoo! Dataset\n\nYahoo! Experiment 1 (K = 5). Yahoo! has published\na benchmark dataset for the evaluation of bandit algorithms (Yahoo! ). The dataset is the user click log for news\narticles displayed on the Yahoo! Front Page (Li et al. 2011).\nGiven the arrival of a user, the goal is to select an article\nto present to the user, in order to maximize the expected\nclick-through rate, where the reward is a binary value for\nuser click. For the purpose of our experiment, we randomly\nselect the set of 5 articles (i.e., K = 5) from a list of 100\npermutations of possible articles which overlapped in time\nthe most. To recover the ground truth of the expected clickthrough rates of the articles, we take the same approach as\nin Mellor and Shapiro (2013), where the click-through rates\nwere estimated from the dataset by taking the mean of an\narticle’s click-through rate every 5000 time ticks (the length\nof a time tick is about one second), which is shown in Fig-\n\nure 3a.\nThe regret curves are shown in Figure 3b. We again fit\nthe curves to the model atb + c. The resulting exponents\nb of D-UCB, Rexp3, SW-UCB, Exp3.R, Exp3.S, CUSUMUCB and PHT-UCB are 1, 1, 1, 0.81, 0.85, 0.69 and 0.79,\nrespectively. The passively adaptive policies, D-UCB, SWUCB and Rexp3, receive a linear regret for most of the\ntime. CUSUM-UCB and PHT-UCB achieve much better\nperformance and show sublinear regret, because of their\nactive adaptation to changes. Another observation is that\nCUSUM-UCB outperforms PHT-UCB. The reason behind\nis that the Yahoo! dataset has more frequent breakpoints than\nthe switching environment (i.e., high γT ). Thus, the estimation ŷk in PHT test may drift away before PHT detects the\nchange, which in turn results in more detection misses and\nthe higher regret.\nYahoo! Experiment 2 (K = 100). We repeat the above experiment with K = 100. The regret curves are shown in\nFigure 4. We again fit the curves to the model atb + c. The\nresulting exponents b of D-UCB, Rexp3, SW-UCB, Exp3.R,\nExp3.S, CUSUM-UCB and PHT-UCB are 1, 1, 1, 0.88, 0.9,\n0.85 and 0.9, respectively. The passively adaptive policies,\nD-UCB, SW-UCB and Rexp3, receive a linear regret for\nmost of the time. CUSUM-UCB and PHT-UCB show robust\nperformance in this larger scale experiment.\n\n7\n\nConclusion\n\nWe propose a change-detection based framework for multiarmed bandit problems in the non-stationary setting. We\nstudy a class of change-detection based policies, CD-UCB,\nand provide a general regret upper bound given the performance of change detection algorithms. We then develop\nCUSUM-UCB and PHT-UCB, that actively react to the environment by detecting breakpoints. q\nWe analytically show\nthat the regret of CUSUM-UCB is O( T γT log γTT ), which\nis lower than the regret bound of existing policies for the\nnon-stationary setting. To the best of our knowledge, this\nis the first regret bound for actively adaptive UCB policies. Finally, we demonstrate that CUSUM-UCB outperforms existing policies via extensive experiments over arbitrary Bernoulli rewards and the real world dataset of webpage click-through rates.\n\n\fAcknowledgment\nThis work has been supported in part by grants from\nthe Army Research Office W911NF-14-1-0368 W911NF15-1-0277, and MURI W911NF-12-1-0385, DTRA grant\nHDTRA1-14-1-0058, and NSF grant CNS-1719371.\n\nReferences\nAgrawal, S., and Goyal, N. 2012. Analysis of thompson\nsampling for the multi-armed bandit problem. In COLT,\n39.1–39.26.\nAlaya-Feki, A. B. H.; Moulines, E.; and LeCornec, A. 2008.\nDynamic spectrum access with non-stationary multi-armed\nbandit. In 2008 IEEE 9th Workshop on Signal Processing\nAdvances in Wireless Communications, 416–420. IEEE.\nAllesiardo, R., and Féraud, R. 2015. Exp3 with drift detection for the switching bandit problem. In Data Science\nand Advanced Analytics (DSAA), 2015. 36678 2015. IEEE\nInternational Conference on, 1–7. IEEE.\nAuer, P.; Cesa-Bianchi, N.; Freund, Y.; and Schapire, R. E.\n2002. The nonstochastic multiarmed bandit problem. SIAM\nJournal on Computing 32(1):48–77.\nAuer, P.; Cesa-Bianchi, N.; and Fischer, P. 2002. Finitetime analysis of the multiarmed bandit problem. Machine\nlearning 47(2-3):235–256.\nBasseville, M., and Nikiforov, I. V. 1993. Detection of\nabrupt changes: theory and application, volume 104. Prentice Hall Englewood Cliffs.\nBesbes, O.; Gur, Y.; and Zeevi, A. 2014. Stochastic multiarmed-bandit problem with non-stationary rewards. In Advances in neural information processing systems, 199–207.\nBubeck, S., and Cesa-Bianchi, N. 2012. Regret analysis of\nstochastic and nonstochastic multi-armed bandit problems.\narXiv preprint arXiv:1204.5721.\nBuccapatnam, S.; Liu, F.; Eryilmaz, A.; and Shroff, N. B.\n2017. Reward maximization under uncertainty: Leveraging side-observations on networks.\narXiv preprint\narXiv:1704.07943.\nCesa-Bianchi, N., and Lugosi, G. 2006. Prediction, learning, and games. Cambridge university press.\nGallager, R. G. 2012. Discrete stochastic processes, volume\n321. Springer Science & Business Media.\nGarivier, A., and Moulines, E. 2008. On upper-confidence\nbound policies for non-stationary bandit problems. arXiv\npreprint arXiv:0805.3415.\nHartland, C.; Baskiotis, N.; Gelly, S.; Sebag, M.; and Teytaud, O. 2007. Change point detection and meta-bandits for\nonline learning in dynamic environments. CAp 237–250.\nHinkley, D. V. 1971. Inference about the change-point from\ncumulative sum tests. Biometrika 509–523.\nKaufmann, E.; Korda, N.; and Munos, R. 2012. Thompson\nsampling: An asymptotically optimal finite-time analysis. In\nInternational Conference on Algorithmic Learning Theory,\n199–213. Springer.\nKhan, R. A. 1981. A note on page’s two-sided cumulative\nsum procedure. Biometrika 717–719.\n\nKocsis, L., and Szepesvári, C. 2006. Discounted ucb. In 2nd\nPASCAL Challenges Workshop, 784–791.\nLai, T. L., and Robbins, H. 1985. Asymptotically efficient\nadaptive allocation rules. Advances in applied mathematics\n6(1):4–22.\nLi, L.; Chu, W.; Langford, J.; and Wang, X. 2011. Unbiased\noffline evaluation of contextual-bandit-based news article\nrecommendation algorithms. In Proceedings of the fourth\nACM international conference on Web search and data mining, 297–306. ACM.\nLi, S.; Karatzoglou, A.; and Gentile, C. 2016. Collaborative\nfiltering bandits. In Proceedings of the 39th International\nACM SIGIR conference on Research and Development in\nInformation Retrieval, 539–548. ACM.\nLorden, G. 1971. Procedures for reacting to a change in\ndistribution. The Annals of Mathematical Statistics 1897–\n1908.\nMellor, J., and Shapiro, J. 2013. Thompson sampling in\nswitching environments with bayesian online change detection. In Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics, 442–450.\nPage, E. S.\n1954.\nContinuous inspection schemes.\nBiometrika 41(1/2):100–115.\nPollard, D. 1984. Convergence of Stochastic Processes.\nSpringer.\nSrivastava, V.; Reverdy, P.; and Leonard, N. E. 2014.\nSurveillance in an abruptly changing world via multiarmed\nbandits. In Decision and Control (CDC), 2014 IEEE 53rd\nAnnual Conference on, 692–697. IEEE.\nSutton, R. S., and Barto, A. G. 1998. Reinforcement learning: An introduction, volume 1. MIT press Cambridge.\nThompson, W. R. 1933. On the likelihood that one unknown\nprobability exceeds another in view of the evidence of two\nsamples. Biometrika 25(3/4):285–294.\nWei, C.-Y.; Hong, Y.-T.; and Lu, C.-J. 2016. Tracking the\nbest expert in non-stationary stochastic environments. In\nAdvances In Neural Information Processing Systems, 3972–\n3980.\nYahoo!\nWebscope program.\nhttp://webscope.\nsandbox.yahoo.com/catalog.php?datatype=\nr&did=49. [Online; accessed 18-Oct-2016].\nYu, J. Y., and Mannor, S. 2009. Piecewise-stationary bandit problems with side observations. In Proceedings of the\n26th Annual International Conference on Machine Learning, 1177–1184. ACM.\n\n\fA\n\nLemma List\n\nWe will make use of the following standard facts.\nLemma 1. (Chernoff-Hoeffding bound) Let Y1 , . . . , Yn be\nrandom variables with common range [0, 1] and such that\nE[Yt |Y1 , . . . , Yt−1 ] = u. Let Sn = Y1 + · · · + Yn . Then for\nall a ≥ 0\nP{Sn ≥ nu + a} ≤ e−2a\n\n2\n\n/n\n\n,\n\n(18)\n\n2\n\n−2a /n\n\nP{Sn ≤ nu − a} ≤ e\n.\n(19)\nLemma 1 states the well known Chernoff-Hoeffding inequalities, proof of which is referred to (Pollard 1984). The\nnext two lemmas are used in the proof of Theorem 2.\nLemma 2. (Wald’s identity) Let {Yk ; k ≥ 1} be independent and identically distributed, and let Λ(r) =\nlog{E[erY1 ]}. Let J(Y ) be the interval of r over which Λ(r)\nexists. For each n ≥ 1, let Sn = Y1 + · · · + Yn . Let a < 0\nand b > 0 be arbitrary, and let L be the smallest n for which\neither Sn ≥ b or Sn ≤ a. Then for each r ∈ J(Y ),\nE [exp (rSL − LΛ(r))] = 1.\n(20)\nProof of Lemma 2 is referred to (Gallager 2012).\nLemma 3. (Two-sided CUSUM) Let η1 , η2 , . . . be independent random variables. For \u000f ≥ 0, define s+\nk = ηk − \u000f\n+\n+\n+\nand s−\n=\n−η\n−\n\u000f.\nLet\ng\n=\nmax(0,\ng\nk\nk\nk\nk−1 + sk ) and\n−\n−\n−\ngk = max(0, gk−1 + sk ). For h > 0, define H + =\ninf{k : gk+ ≥ h} and H − = inf{k : gk− ≥ h}. Let\nH = min(H + , H − ). Then, we have that\n1\n1\n1\n=\n+\n.\n(21)\nE[H]\nE[H + ] E[H − ]\nNote that the two-sided CUSUM algorithm (that signals a\nchange at H) defined in Lemma 3 is called symmetric. Proof\nof Lemma 3 is referred to (Khan 1981)\n\nB\n\nProof of Theorem 1\n\nProof. Recall that it is the arm with the best UCB\nindex at\n\u0001\ntime t, i.e., it = arg maxi∈K X̄t (i) + Ct (i) . In addition\nrt is the random arm sampled from uniform distribution. At\neach time t, if the arm i is played, then the CD-UCB algorithm is either sampling a random arm (rt = i) or playing\nthe arm with the best UCB index (it = i). So, the probability\nthat arm i is chosen at time t and arm i is not the best arm is\nP{It = i 6= i∗t } ≤ αP{rt = i} + (1 − α)P{it = i 6= i∗t }\n≤ α/K + (1 − α)P{it = i 6= i∗t }. (22)\nBy the definition of ÑT (i) in equation (1), we have that\nE[ÑT (i)] ≤\n\nT\nX\n\nP{It = i 6= i∗t }\n\n(23)\n\n(α/K + (1 − α)P{it = i 6= i∗t })\n\n(24)\n\nt=1\n\n≤\n\nT\nX\nt=1\n\n≤ αT /K +\n\nT\nX\n\nTi , {t ∈ {1, . . . , T } : µs (i) = µt (i)\nand τi (t) < s ≤ t, t ≥ τi (t) + Ai }.\n(26)\nPT\nThen, we can bound the term (b) , t=1 1{it =i6=i∗t } by\n(b) =\n\nT\nX\n\b\n\n1{it =i6=i∗t ,Nt (i)<Ai } + 1{it =i6=i∗t ,Nt (i)≥Ai }\n\nt=1\n\n≤ (γT + Fi )Ai +\n≤ (γT + Fi )Ai +\n\nP{it = i 6= i∗t } .\n{z\n\n(a)\n\n}\n\n(25)\n\nT\nX\nt=1\nγT\nX\n\n1{it =i6=i∗t ,Nt (i)≥Ai }\nDik +\n\nX\n\n(27)\n\n1{it =i6=i∗t ,Nt (i)≥Ai } .\n\nt∈Ti\n\nk=1\n\nFor each t ∈ Ti , the event {it = i 6= i∗t , Nt (i) ≥ Ai }\nimplies the following union of events\n{X̄t (i) ≥ µt (i) + Ct (i)} ∪ {X̄t (i∗t ) ≤ µt (i∗t ) − Ct (i∗t )}\n∪ {µt (i∗t ) − µt (i) < 2Ct (i), Nt (i) ≥ Ai }. (28)\nOn the event {Nt (i) ≥ Ai }, we have that\ns\nr\nξ log nt\nξ log T\n∆µT (i)\nCt (i) =\n≤\n,\n(29)\n=\nNt (i)\nAi\n2\nby the definition of Ai . Thus, 2Ct (i) ≤ µt (i∗t ) − µt (i) holds\nwhen Nt (i) ≥ Ai . This implies that the last event of (28) is\nimpossible. So we have that 1{it =i6=i∗t ,Nt (i)≥Ai } is at most\n1{X̄t (i)≥µt (i)+Ct (i)} + 1{X̄t (i∗t )≤µt (i∗t )−Ct (i∗t )} (30)\nBy the Lemma 1, we have that\nP{X̄t (i) ≥ µt (i) + Ct (i)} ≤ n−2ξ\nt\nP{X̄t (i∗t )\n\nµt (i∗t )\n\nCt (i∗t )}\n\n(31)\n\nn−2ξ\nt\n\n≤\n−\n≤\n(32)\nLet l0 , l1 , . . ., be the length of intervals between successive\nPγT +Fi\ndetection points. Then, we have that m=0\nlm = T . Let\nξ = 1, we have that\nX\nX\nP{it = i 6= i∗t , Nt (i) ≥ Ai } ≤\n2n−2\n(33)\nt\nt∈Ti\n\nt∈Ti\n\n≤\n\nt=1\n\n|\n\nNow, it remains to bound the second term of (25), denoted\n4ξ log T\nby (a). Let Ai be a constant defined as Ai , (∆\n2.\nµT (i))\nThen we can decompose the event {it = i 6= i∗t } as\n{it = i 6= i∗t , Nt (i) < Ai } ∪ {it = i 6= i∗t , Nt (i) ≥ Ai }.\nConsider an experiment of the CD-UCB over T plays. Let\nFi be the number of false alarms up to time T and Dij be the\ndetection delay of j-th breakpoint on arm i, where j ≤ γT .\nThen, the total number of detection points, when the change\ndetection algorithm CD(·, ·) signals an alarm on arm i, is\nupper-bounded by γT + Fi . Let τi (t) be the latest detection\npoints (including false arms) up to time t. For each arm i, we\ndefine Ti as the set of time slots that no breakpoint occurs\nafter Ai time slots away from the detection points.\n\nT\nX\n\n2n−2\nt ≤2\n\nt=1\n\n≤2\n\nγT\n+Fi\nX\nm=0\n\nγT\n+Fi X\nlm\nX\n\ns−2\n\n(34)\n\nm=0 s=1\n\nπ 2 /6 = (γT + Fi + 1)π 2 /3.\n\n(35)\n\n\fLet E[F ] be the expected number of false alarms in time\nhorizon T , and E[D] be the expected detection delay. Summing all the results, we have (a) = E[(b)] and\n(a) ≤(γT + E[F ])Ai + γT E[D]\n\"\n#\nX\n+E\nP{it = i 6= i∗t , Nt (i) ≥ Ai } .\n\n(36)\n\n−\nprobability that SPRT ends up with SH\n− < 0. Let G be\nthe number of SPRT tests that CUSUM runs until an alarm.\nThen G − 1 is a geometrically distributed random variable\nwith parameter Pθ {0}. Hence, we have that\n−\n− −\nL− (θ) = Eθ [H − |SH\n|SH − > h]\n− < 0]Eθ [G−1] + Eθ [H\n\n=\n\nt∈Ti\n\n≤(γT + E[F ])Ai + γT E[D] + (γT + E[F ] + 1)π 2 /3.\nCombining (36) and (25), we obtain (8).\n\nC\n\n=\n\nProof of Proposition 1\n\n−\nEθ [H − |SH\n− < 0]Pθ {0}\n−\n+ Eθ [H − |SH\n− > h]\n1 − Pθ {0}\n(41)\n\nEθ [H − ]\n.\n1 − Pθ {0}\n\n(42)\n−\n\nProof. Let y1 , y2 , . . . be a sequence of independent random variables with bounded support [0, 1]. Before (after)\nthe change, the random variable yk follows a distribution\nwith parameter θ0 (θ1 ). Let u0 (u1 ) denote the mean before\n(after) the change. Under the Assumption 2, we have that\n|u0 − u1 | ≥ 2\u000f. Note that we use the first M samples to es+\ntimate the mean before the change by û0 . Then, s−\nk and sk\nbecome a non-trivial function of observation yk . We define\nthe expected time excluding the first M time slots until the\nalarm occurs as the average run length (ARL), which is consistent with the literature in change detection problems (Basseville and Nikiforov 1993). In particular, let L(θ) be the\nARL function defined as\n\u0002\n\u0003\n+\n−\nL(θ) = Eθ inf{t : gt+M\n> h or gt+M\n> h} .\n(37)\n\nrsM +1\nLet Λ−\n]}. Then, by Lemma 2 we have\nθ (r) , log{Eθ [e\n\u0002\n\u0001\u0003\nEθ exp rSH − − H − Λ−\n= 1.\n(43)\nθ (r)\n\nIt is clear that Algorithm 2 is a symmetric version of two+\nsided CUSUM-type algorithm (Khan 1981). Let s+\nk and gk\n−\n−\n(sk and gk ) be the upper (lower) side CUSUM random\nwalk. Then, we define the ARL function for lower and upper\nside CUSUM as\n\u0002\n\u0003\n−\nL− (θ) = Eθ inf{t : gt+M\n> h} ,\n(38)\n\u0002\n\u0003\n+\n+\nL (θ) = Eθ inf{t : gt+M > h} .\n(39)\n\nBy the Assumption 1, û0 is the average of M samples\nfrom distribution under θ0 . By Lemma 1, we have that\n\nBy Lemma 3, we have that\n1\n1\n1\n= −\n+ +\nL(θ)\nL (θ) L (θ)\n\n(40)\n\nThe ARL function L(θ) characterizes the detection delay\nand false alarm performances of our CUSUM algorithm. In\nparticular, L(θ0 ) is the mean detection delay, and L(θ1 ) is\nthe mean time between false alarms. Thus, E[D] = L(θ0 )\nand E[F ] = T /L(θ1 ). By (40), it remains to calculate L− (θ)\nand L+ (θ). In the following, we show the results for L− (θ)\nand obtain the results for L+ (θ) by symmetry.\n−\nLet Sn− = s−\n1+M + . . . + sn+M be a random walk. Let\nH − be the smallest n such that Sn− crosses the bounded interval [0, h], i.e., H − = inf{Sn− < 0 or Sn− > h}. The\nprocedure that monitors the stopping time that Sn− crosses\nthe boundary is also called a sequential probability ratio test\n(SPRT). Then the lower side CUSUM can be viewed as a\nrepeated SPRT such that CUSUM restarts the SPRT once\nSn− crosses the 0 boundary (i.e., Sn− < 0) and outputs an\nalarm the first time that Sn− crosses the h boundary (i.e.,\n−\nSn− > h) (Page 1954). Let Pθ {0} , Pθ {SH\n− < 0} be the\n\nWe use the two implications from the Wald’s identity (43).\nFor simplicity, we assume that k ≥ M when we consider\n+\nthe expectation of s−\nk and sk . First, taking the derivative of\nboth sides and letting r = 0, we have that\nEθ [SH − ] = Eθ [H − ]Eθ [s−\nk ].\n\n(44)\n\n−\nSecond, letting r = r− (θ) such that Λ−\nθ (r (θ)) = 0 and\n−\nr (θ) 6= 0, we have that\n\nEθ [exp (r− (θ)SH − )] = 1.\n\nP{|û0 − u0 | > \u000f} ≤ 2e−2\u000f\n\n2\n\nM\n\n(45)\n\n.\n\n(46)\n\nNow, we classify the possible scenarios into four different\ncases depending on û0 , u0 and u1 , under which we can derive the upper bound of the mean detection delay or the mean\ntime between false alarms.\nCase 1: |û0 − u0 | < \u000f and u1 < u0\nUnder θ1 , we show the upper bound of L− (θ1 ) (mean detection delay of lower side CUSUM). Note that Eθ1 [s−\nk] =\nû0 − u1 − \u000f > 0. Then, by (42) and (44) we have that\nEθ1 [SH − ]\nEθ1 [H − ]\n=\n−\n1 − Pθ1 {0}\nEθ1 [sk ](1 − Pθ1 {0})\nEθ1 [SH − |SH − > h](1 − Pθ1 {0})\n=\nEθ1 [s−\nk ](1 − Pθ1 {0})\nEθ1 [SH − |SH − < 0]Pθ1 {0}\n+\nEθ1 [s−\nk ](1 − Pθ1 {0})\nEθ [S − |SH − > h]\n≤ 1 H\nEθ1 [s−\nk]\nh+1\n≤\n.\nEθ1 [s−\nk]\n\nL− (θ1 ) =\n\n(47)\n\n(48)\n(49)\n(50)\n\nUnder θ0 , we show the lower bound of L− (θ0 ) (mean\ntime between false alarms of lower side CUSUM). Note that\n−\nEθ0 [s−\nk ] = û0 − u0 − \u000f < 0, which implies that r (θ0 ) > 0.\n\n\fD\n\nBy (45), we have that\n1 =Eθ0 [exp (r− (θ0 )SH − )]\n\n(51)\n\n=Pθ0 {0}Eθ0 [exp (r− (θ0 )SH − )|SH − < 0]\n\n(52)\n\n−\n\n+ (1 − Pθ0 {0})Eθ0 [exp (r (θ0 )SH − )|SH − > h]\n≥(1 − Pθ0 {0})Eθ0 [exp (r− (θ0 )SH − )|SH − > h] (53)\n≥(1 − Pθ0 {0}) exp (r− (θ0 )h)\n\n(54)\n\n−\n\nNote that Eθ0 [H ] ≥ 1. Hence, we have that\nL− (θ0 ) =\n\nEθ0 [H − ]\n1\n≥\n≥ exp (r− (θ0 )h).\n1 − Pθ0 {0}\n1 − Pθ0 {0}\n(55)\n\nUnder θ0 , we obtain the lower bound of L+ (θ0 ) (mean\ntime between false alarms of upper side CUSUM) with the\nsimilar arguments. In particular, Eθ0 [s+\nk ] = u0 − û0 − \u000f < 0,\nwhich implies that r+ (θ0 ) > 0. Then we have that\nL+ (θ0 ) ≥ exp (r+ (θ0 )h).\n\n(56)\n\nLet r(θ0 ) = min(r+ (θ0 ), r− (θ0 )). By (40), we have that\nh+1\n,\nEθ1 [s−\nk]\nexp (r(θ0 )h)\n.\nL(θ0 ) ≥\n2\nL(θ1 ) ≤L− (θ1 ) ≤\n\n(57)\n(58)\n\nCase 2: |û0 − u0 | < \u000f and u1 > u0\nSimilarly, we obtain the results for upper side CUSUM as\nL+ (θ1 ) ≤\n\nh+1\nEθ1 [s+\nk]\n\n(59)\n\nL+ (θ0 ) ≥ exp (r+ (θ0 )h).\n\n(60)\n\nUnder θ0 , we check that Eθ0 [s−\nk ] = û0 − u0 − \u000f < 0. Hence,\nwe have that\nL− (θ0 ) ≥ exp (r− (θ0 )h).\n\n(61)\n\nBy (40), we have that\nh+1\n,\n(62)\nEθ1 [s+\nk]\nexp (r(θ0 )h)\n.\n(63)\nL(θ0 ) ≥\n2\nCase 3: û0 − u0 > \u000f\nWhen the estimate û0 is large (û0 − u0 > \u000f), Eθ0 [s−\nk] =\nû0 − u0 − \u000f > 0. Then we have that\nL(θ1 ) ≤L+ (θ1 ) ≤\n\nL(θ0 ) ≤ L− (θ0 ) ≤\n\nh+1\n.\nEθ0 [s−\nk]\n\n(64)\n\nCase 4: u0 − û0 > \u000f\nWhen the estimate û0 is small (u0 − û0 > \u000f), Eθ0 [s+\nk] =\nu0 − û0 − \u000f > 0. Then we have that\nL(θ0 ) ≤ L+ (θ0 ) ≤\n\nh+1\n.\nEθ0 [s+\nk]\n\n(65)\n\nProof of Theorem 2\n\nNote that the bounds for L(θ), L− (θ) and L+ (θ) in the\nProposition 1 are the conditional expectations under θ given\nû0 . By the law of total expectation, we can obtain the expected bound results by taking expectation over û0 . Let Eû0\ndenote the expectation over û0 . We classify the possible scenarios into two cases, under which we take the conditional\nexpectations and sum the total expectation finally.\nCase 1: |û0 − u0 | < \u000f\nBy the Proposition 1, given the condition û0 and |û0 −\nu0 | < \u000f, we have that\nh+1\n|u1 − û0 | − \u000f\nL− (θ0 ) ≥ exp(r− (θ0 )h)\nL(θ1 ) ≤\n\n+\n\n+\n\nL (θ0 ) ≥ exp(r (θ0 )h)\n\n(66)\n(67)\n(68)\n\nFirst, we consider the upper bound of L(θ1 ) when u1 < u0 .\nLet pZ (·) denote the probability density function (or probability mass function) of random variable Z. Then, we have\nthat\n\u0014\n\u0015\nh+1\nEû0\n|û0 − u0 | < \u000f\n(69)\n|u1 − û0 | − \u000f\n\u0015\n\u0014Z u0 +\u000f\nh+1\npû0 (u)du /P{|û0 − u0 | < \u000f}\n=\nu0 −\u000f |u1 − u| − \u000f\n(70)\n\u0015\n\u0014Z u0 +\u000f\nh+1\n=\npû (u)du /P{|û0 − u0 | < \u000f}\nu\n−\nu1 − \u000f 0\nu0 −\u000f\n(71)\nWe define δT (i) , min{|µt (i) − µt+1 (i)| − 2\u000f : µt (i) 6=\nµt+1 (i), t ≤ T }. Note that δT (i) is the minimum over a\nfinite set of positive real numbers (i.e., δT (i) > 0). Then,\nu0 − u1 − \u000f > δT (i) + \u000f. Therefore, we have\nZ u0 +\u000f\n1\npû0 (u)du\n(72)\nu0 −\u000f u − u1 − \u000f\nZ \u000f\n1\n≤\ndu\n(73)\n−\u000f u + u0 − u1 − \u000f\nZ \u000f\n1\n≤\ndu\n(74)\n−\u000f u + δT (i) + \u000f\n= log(1 + 2\u000f/δT (i)).\n(75)\nHence, we have that\n\u0014\n\u0015\nh+1\nEû0\n|û0 − u0 | < \u000f\n|u1 − û0 | − \u000f\n(h + 1) log(1 + 2\u000f/δT (i))\n≤\nP{|û0 − u0 | < \u000f}\n\n(76)\n(77)\n\nThe same result holds for u1 > u0 . Note that δT (i) ≥ \u000f by\nthe Assumption 2. Then, we have that\n\u0014\n\u0015\nh+1\n(h + 1) log(3)\nEû0\n|û0 − u0 | < \u000f ≤\n|u1 − û0 | − \u000f\nP{|û0 − u0 | < \u000f}\n(78)\n\n\fSecond, we consider the lower bound of L− (θ0 ) and\nL+ (θ0 ). By the Assumption 3, the yk is a Bernoulli random\nvariable. Then, we have that\n−r\nΛ−\nu0 + 1 − u0 ) + r(û0 − \u000f)\nθ0 (r) = log(e\n\n(79)\n\nΛ+\nθ0 (r)\n\n(80)\n\nr\n\n= log(e u0 + 1 − u0 ) − r(û0 + \u000f)\n\nd −\nΛθ0 (r) = 0\nLet r̂− (θ0 ) (r̂+ (θ0 )) be the solution of dr\n\u0001\n\u0001\n−\n+\nd +\ndr Λθ0 (r) = 0 . Then, the convexity of Λθ0 (r) Λθ0 (r)\nimplies that r− (θ0 ) > r̂− (θ0 ) (r− (θ0 ) > r̂− (θ0 )). In addition, r̂− (θ0 ) and r̂+ (θ0 ) satisfy\n\nu0 (û0 − \u000f)−1 − u0\n,\n1 − u0\n1 − u0\n.\nexp(r̂+ (θ0 )) =\nu0 (û0 + \u000f)−1 − u0\n\nexp(r̂− (θ0 )) =\n\n(81)\n(82)\n\nNote that r̂− (θ0 ) and r̂+ (θ0 ) always exist when 2\u000f < u0 <\n1 − 2\u000f. One can scale the reward linearly without changing\nthe problem by function f (x) = (1 − 4\u000f)x + 2\u000f so that the\nexpected reward is within the interval (2\u000f, 1 − 2\u000f). Hence,\nwe assume that r̂− (θ0 ) and r̂+ (θ0 ) exist without loss of generality. We first derive a lower bound for (81).\n\u0002\n\u0003\nEû0 (û0 − \u000f)−1 |û0 − u0 | < \u000f\nR u0 +\u000f 1\nu−\u000f pû0 (u)du\n= u0 −\u000f\nP{|û0 − u0 | < \u000f}\n\u0011\nR u0 +\u000f \u0010 1\n1\nu−\u000f − u0 pû0 (u)du\nu0 −\u000f\n1\n≥\n+\nP{|û0 − u0 | < \u000f}\nu0\n\u0011\nR u0 \u0010 1\n1\n− u0 pû0 (u)du\nu0 −\u000f u−\u000f\n1\n≥\n+\nP{|û0 − u0 | < \u000f}\nu0\n\u0011R\n\u0010\nu0\n1\n1\n−\np (u)du\nu0 −\u000f\nu0\nu0 −\u000f û0\n1\n+\n≥\nP{|û0 − u0 | < \u000f}\nu0\n\u0012\n\u0013\nM\n\u000f\nbu M c\nu 0 (1−u0 )M −bu0 M c +\n≥\nu0 (u0 −\u000f) bu0 M c 0\n≥\n\n\u0013\nM\n1\n(2\u000f)M + .\nu0 (u0 − \u000f) b2\u000fM c\nu0\n\u000f\n\n(83)\n(84)\n\n(85)\n\n(86)\n\n(87)\n1\nu0\n(88)\n\n\u0012\n\n(89)\n\nHence, we have that\n\u0002\n\u0003\nEû0 exp(r̂− (θ0 )) |û0 − u0 | < \u000f\n\u0012\n\u0013\n\u000f\nM\n≥\n(2\u000f)M + 1\n(u0 − \u000f)(1 − u0 ) b2\u000fM c\n\u0012\n\u0013\n4\u000f\nM\n≥\n(2\u000f)M + 1.\n(1 − \u000f)2 b2\u000fM c\n\n(90)\n(91)\n(92)\n\nNow, we derive a lower bound for (82). Similarly, we have\n\nthat\n\u0003\n\u0002\n(93)\nEû0 (û0 + \u000f)−1 |û0 − u0 | < \u000f\nR u0 +\u000f 1\nu+\u000f pû0 (u)du\n= u0 −\u000f\n(94)\nP{|û0 − u0 | < \u000f}\n\u0010\n\u0011\nR u0 +\u000f 1\n1\nu+\u000f − u0 pû0 (u)du\nu0\n1\n≤\n+\n(95)\nP{|û0 − u0 | < \u000f}\nu0\n\u0011R\n\u0010\nu0 +\u000f\n1\n1\npû0 (u)du\nu0 +\u000f − u0\nu0\n1\n≤\n+\n(96)\nP{|û0 − u0 | < \u000f}\nu0\n\u0012\n\u0013\nM\n1\n−\u000f\n(2\u000f)M + .\n(97)\n≤\nu0 (u0 + \u000f) d2\u000fM e\nu0\nHence, by the Jensen’s inequality, we have that\n\u0002\n\u0003\nEû0 exp(r̂+ (θ0 )) |û0 − u0 | < \u000f\n(98)\n\u0015\n\u0014\n1 − u0\n|û0 − u0 | < \u000f\n(99)\n= Eû0\nu0 (û0 + \u000f)−1 − u0\n1 − u0\n≥\n(100)\n−1\nEû0 [u0 (û0 + \u000f) − u0 ||û0 − u0 | < \u000f]\n1 − u0\n≥ −\u000f\n(101)\n\u0001\nM\nM +1−u\n0\n(u0 +\u000f) d2\u000fM e (2\u000f)\n\u0001\nM\nM\n\u000f d2\u000fM\ne (2\u000f)\n=\n+ 1 (102)\n\u0001\nM\nM\n(1 − u0 )(u0 + \u000f) − \u000f d2\u000fM\ne (2\u000f)\n\u0001\nM\nM\n\u000f d2\u000fM\ne (2\u000f)\n+1\n(103)\n≥\n\u0001\nM\nM\n(1 + \u000f)2 /4 − \u000f d2\u000fM\ne (2\u000f)\n\u0013\n\u0012\n4\u000f\nM\n(2\u000f)M + 1\n(104)\n≥\n(1 + \u000f)2 d2\u000fM e\n\u0011\n\u0010\n\u0001\nM\n4\u000f\nM\n+ 1 and C1+ =\nLet C1− = log (1−\u000f)\n2 b2\u000fM c (2\u000f)\n\u0011\n\u0010\n\u0001\nM\n4\u000f\nM\nlog (1+\u000f)\n+ 1 . Then, there exists a posi2 d2\u000fM e (2\u000f)\ntive number C1 , min(C1− , C1+ ), which depends on \u000f and\nM , such that\n\u0003\n\u0002\nEû0 exp(r− (θ0 )h) |û0 − u0 | < \u000f\n(105)\n\u0002\n\u0003\n−\n≥ Eû0 exp(r̂ (θ0 )h) |û0 − u0 | < \u000f\n(106)\n\b\n\u0002\n\u0003\nh\n≥ Eû0 exp(r̂− (θ0 )) |û0 − u0 | < \u000f\n(107)\n≥ exp(C1 h).\n(108)\nSimilarly, we have that\n\u0002\n\u0003\nEû0 exp(r+ (θ0 )h) |û0 − u0 | < \u000f ≥ exp(C1 h). (109)\nCase 2: |û0 − u0 | > \u000f\nBy Assumption 3, the û0 is the average of M Bernoulli\nrandom variables. In other words, û0 must be one of\nthe points {0, 1/M, . . . , 1}. Then there must be a gap\nbetween û0 and u0 . Let λT (i) = min{(µt (i) − \u000f) −\nb(µt (i) − \u000f)M c/M, d(µt (i) + \u000f)M e/M −(µt (i)+\u000f) : 1 ≤\nt ≤ T } be the minimal gap of arm i.3 We define the minimal\ngap of all arms as λ = mini∈K λT (i).\n3\nNote that b·c denotes the floor function and d·e denotes the\nceiling function.\n\n\fBy the Proposition 1, the average run length is at most\nh+1\n.\n|û0 − u0 | − \u000f\n\n(110)\n\nSuppose that û0 > u0 + \u000f, then\n\u0015\n\u0014\nh+1\n|û0 − u0 | > \u000f\n(111)\nEû0\n|û0 − u0 | − \u000f\n\u0014\n\u0015\nh+1\n=Eû0\n|û0 − u0 | > \u000f\n(112)\nû0 − u0 − \u000f\n\u0014\n\u0015\nh+1\n≤Eû0\n|û0 − u0 | > \u000f\nd(u0 + \u000f)M e/M − u0 − \u000f\n(113)\nh+1\n≤\n.\n(114)\nλ\nThe same result holds when û0 < u0 − \u000f. Summing the\nresults (78) (108) (109) (114), we derive the upper bound for\nthe mean detection delay and the lower bound for number of\nfalse alarms within the horizon T .\n\u0014\n\u0015\nh+1\nE[D] ≤ Eû0\n|û0 −u0 | < \u000f P{|û0 −u0 | < \u000f}\n|u1 − û0 |−\u000f\n(115)\n\u0015\n\u0014\nh+1\n|û0 −u0 | > \u000f P{|û0 −u0 | > \u000f}\n+ Eû0\n|û0 −u0 |−\u000f\n(116)\nh+1\n≤ (h + 1) log(3) + 2 exp(−2\u000f2 M )\n.\n(117)\nλ\nNote that the mean time between false alarm is Eû0 [L(θ0 )].\nBy the law of total expectation, we have that\nEû0 [L(θ0 )] ≥ Eû0 [L(θ0 )||û0 − u0 | < \u000f]P{|û0 − u0 | < \u000f}\n(118)\nBy the Lemma 3 and (108) (109), we have that\nEû0 [L(θ0 )||û0 − u0 | < \u000f] ≥\n\n1\nexp(C1 h)\n2\n\n(119)\n\nHence, we have that\nT\n2 exp(C1 h)P{|û0 − u0 | < \u000f}\n2T\n≤\n.\nexp(C1 h)(1 − 2 exp(−2\u000f2 M ))\n\nE[F ] ≤ 1\n\nE\n\n(120)\n(121)\n\nProof of Theorem 3\n\nThe result follows the Theorem 1 and the Theorem 2. Since\nthe results of the Theorem 2 do not include the first M time\nslots, we additionally count the regret of M for each detection point (alarm). The mean detection delay is at most\nscaled by dividing the sampling rate α/K.\n\nF\n\nCUSUM-UCB policy\n\nCUSUM-UCB policy is a CD-UCB policy with CUSUM as\na change detection algorithm. In particular, it takes K parallel CUSUM algorithms as CD(·, ·) in CD-UCB. Since our\n\nAlgorithm 3 CUSUM-UCB\nRequire: time horizon T , parameters α, \u000f, M and h\nInitialize τi = 1 and cnt(i) = M for each i ∈ K.\nfor t from 1 to T do\nUpdate according to equations (3).\nif cnt(i) > 0 for some i ∈ K then\nIt = i; cnt(i) = cnt(i) − 1.\nelse\nUpdate It according to equation (5).\nend if\nPlay arm It and observe Xt (It ).\nif CUSUM(It , Xt (It )) == 1 then\nτIt = t + 1; cnt(It ) = M ; reset CUSUM(It , ·).\nend if\nend for\n\nCUSUM algorithm needs to estimate the mean first, we let\nthe policy finish the estimation with M observations as soon\nas possible. That is why we introduce the countdown timers\ncnt(·) in Algorithm 3. The performance of CUSUM-UCB\ndepends on the parameters α and h. We discuss the joint\nchoices of α and h in Sections 5 and 6.\n\nG\n\nSimulation Parameters\n\nTable 2: Parameter setting in the simulation\nEnvironment K\nT\nγT\n\u000f\nM\nFlipping\n2\n105\n2\n0.1 100\nSwitching\n5\n106\n10\n0.1 100\nYahoo! 1\n5 5 × 105 32† 0.005 100\nYahoo! 2 100 2 × 106 216† 0.005 100\n\nh\n50\n20\n200\n200\n\nα\n0.001\n0.01\n0.024\n0.024\n\n†: We count breakpoints when the difference in mean rewards is greater than \u000f = 0.005.\n\n\f",
         "train",
         "56162",
         "10979"
        ],
        [
         "12",
         "18110",
         "cs.AI",
         "Artificial Intelligence",
         "1709.03339v3.pdf",
         "Autonomous Quadrotor Landing using Deep Reinforcement Learning\n\narXiv:1709.03339v3 [cs.AI] 27 Feb 2018\n\nSanjay\n\nSharma1 ,\n\nRiccardo Polvara1∗ , Massimiliano Patacchiola2∗\nJian Wan1 , Andrew Manning1 , Robert Sutton1 and Angelo Cangelosi2\n\nAbstract— Landing an unmanned aerial vehicle (UAV) on\na ground marker is an open problem despite the effort of\nthe research community. Previous attempts mostly focused on\nthe analysis of hand-crafted geometric features and the use\nof external sensors in order to allow the vehicle to approach\nthe land-pad. In this article, we propose a method based on\ndeep reinforcement learning that only requires low-resolution\nimages taken from a down-looking camera in order to identify\nthe position of the marker and land the UAV on it. The proposed\napproach is based on a hierarchy of Deep Q-Networks (DQNs)\nused as high-level control policy for the navigation toward the\nmarker. We implemented different technical solutions, such as\nthe combination of vanilla and double DQNs, and a partitioned\nbuffer replay. Using domain randomization we trained the\nvehicle on uniform textures and we tested it on a large\nvariety of simulated and real-world environments. The overall\nperformance is comparable with a state-of-the-art algorithm\nand human pilots.\n\nI. INTRODUCTION\nIn the upcoming years an increasing number of autonomous systems will pervade urban and domestic environments. The next generation of Unmanned Aerial Vehicles\n(UAVs) requires high-level controllers in order to move\nin unstructured environments and perform multiple tasks.\nRecently a new application has been proposed, namely the\nuse of quadrotors for the delivery of packages and goods.\nIn this scenario the most delicate part is the identification of\na ground marker and the vertical descent maneuver. Previous works used hand-crafted features analysis and external\nsensors in order to identify the land-pad. In this work we\npropose a completely different approach, based on recent\nbreakthroughs achieved with Deep Reinforcement Learning\n(DRL) [1]. Our method only requires low-resolution images\nacquired from a down-looking camera that are given as input\nto a hierarchy of Deep Q-Networks (DQNs). The output\nof the networks is a high level command that directs the\ndrone toward the marker. The most remarkable advantage\nof DRL is the absence of any human supervision, allowing\nthe quadrotor to autonomously learn how to use high-level\nactions in order to land.\nThe use of DRL in the landing problem is not straightforward. Previous applications mainly focused on deterministic\nenvironments such as the Atari game suite [1]. Using DRL\nin unstructured environments with robotic platforms has had\n*Both first and second author contributed equally and should be considered co-first authors.\n1 Autonomous Marine System Research Group, School of Engineering, Plymouth University, UK [corresponding author]\n\nriccardo.polvara@plymouth.ac.uk\n2 Centre for Robotics and Neural Systems, School of Computing, Electronics and Mathematics, Plymouth University, UK\n\nFig. 1: System overview. The navigation controller is built\non top of the flight controller. The marker detection and the\ndescent maneuver are achieved through two distinct DQNs.\n\nlimited success. In this work we tackled the landing problem\nintroducing different technical solutions. We used a divideand-conquer strategy and we split the problem in two subtasks: landmark detection and vertical descent. Two specialized DQNs take care of the two tasks and are connected\nthrough an internal trigger engaged by the networks itself.\nMoreover, we used double DQN [2] to reduce overestimation\nproblems that commonly arise when the agent moves in\ncomplex environments. To solve the issue of sparse and\ndelayed reward we implemented a new type of prioritized\nexperience replay, called partitioned buffer replay, that splits\nthe experiences in multiple containers and guarantees the\npresence of rare transitions in the training batch. As far as\nwe know, the present work is the first to use an unsupervised\nlearning approach to tackle the landing problem. We show\nan overview of the system in Figure 1 and a video in our\nrepository 1 .\nII. R ELATED WORK\nIn this section we present a brief literature review in order\nto offer an overview on the topic. This review is not meant\n1 https://github.com/pulver22/QLAB/tree/master/share/video\n\n\fto be complete, and it only aims to show how our method\ndifferentiates from previous work.\nWe can broadly group in three classes the methods used\nfor landing UAVs: sensor-fusion, device-assisted, and visionbased. The sensor-fusion methods rely on the use of multiple\nsensors, in order to gather enough data for a robust pose\nestimation. In a recent work [3] the data from a downwardlooking camera and an inertial measurement unit were combined in order to build a three-dimensional reconstruction\nof the terrain. Given the two-dimensional elevation map was\npossible to find a secure surface area for landing. In [4] the\nauthors used a particular geometric shape for the landing pad\nin conjunction with analysis of multiple sensors in order to\naccurately estimate the position of the drone with respect to\nthe marker. A ground-based multisensor fusion system has\nbeen proposed in [5]. The system included a pan-tilt unit, an\ninfrared camera and an ultra-wideband radar used to center\nthe UAV in a recovery area and guide it toward the ground.\nA similar work is presented in [6] in order to land on an\nAR-tag marker posed on a moving vessel.\nDevice-assisted methods rely on the use of ground sensors\nin order to precisely estimate the position and trajectory\nof the drone. A system based on infra-red lights has been\nused in [7]. The authors adopted a series of parallel infrared\nlamps disposed in a runway. The camera on the vehicle was\nequipped with optical filters for capturing the infrared lights\nand the images were forwarded to a control system for pose\nestimation. A Chan-Vese approach supplemented through an\nextended Kalman filter has been proposed in [8] for ground\nstereo-vision detection.\nThe vision based approaches analyse geometric features\nin order to find ground pads and land. A method based\nonly on a monocular camera has been proposed in [9]. The\nsystem used a well defined target pattern, easy to identify at\ndifferent distances. Having a series of concentric circles, it\nwas proved to be possible to find the landmark also when\npartially occluded. A modified version of the international\nlanding pattern has been used in [10]. The solution adopted\nused a seven-stages vision algorithm to identify and track the\npattern in a cluttered environment and reconstruct it when\npartially observable. The use of AR-tag fiducial marker has\nbeen taken into account in [11] and [12]. In both cases a\nprecise pose estimation has been done using only an onboard\ncamera. In [13] a vision-based visual servoing algorithm has\nbeen used to track a moving platform and to produce velocity\ncommands for an adaptive sliding controller.\nThe previous works showed different limitations that we\ndiscuss here. Sensor-fusion methods often use information\ngathered from expensive sensors that cannot be integrated\nin low-cost drones. Most of the time these methods rely\non the contribution of GPS that may be unavailable in\nreal-world scenarios. The device-assisted approaches allow\nobtaining an accurate estimation of the drone pose. However\nthe use of external devices is not always possible because\nthey are not always available. Vision-based methods have the\nadvantage of using only on-board sensors and mainly rely on\ncameras. The main limit of these methods is that low-level\n\nfeatures are often viewpoint-dependent and subject to failure\nin ambiguous cases. The present work directly deals with\nall the aforementioned problems. Our solution is based only\non a monocular onboard camera and does not use any other\nsensors or external devices. The use of DQNs significantly\nimproves the marker detection and is robust to projective\ntransformations and marker corruption.\nIII. P ROPOSED METHOD\nIn this section we describe the landing problem in reinforcement learning terms and we present the technical\nsolutions we adopted.\nA. Problem definition and notation\nHere we consider the landing problem as divided in two\nsub-problems: landmark detection and vertical descent. The\ndetection requires an exploration on the xy-plane, where the\nquadrotor has to horizontally shift in order to align its body\nframe with the marker. In the vertical descent phase the\nvehicle has to reduce the distance from the marker using\nvertical movements. Moreover, the drone has to shift on the\nxy-plane in order to keep the marker centered.\nFormally both the problems can be reduced to Markov\nDecision Processes (MDPs). At each time step t the agent\nreceives the state st , performs an action at sampled from\nthe action space A, and receives a reward rt given by\na reward function R(st , at ). The action brings the agent\nto a new state st+1 in accordance with the environmental\ntransition model T (st+1 |st , at ). In the particular case faced\nhere the transition model is not given (model free). The\ngoal of the agent is to maximize\nP∞ thekdiscounted cumulative\nreward called return R =\nk=0 γ rt+1 , where γ is the\ndiscount factor. Given the current state the agent can select\nan action from the internal policy π = P (a|s). In off-policy\nlearning the prediction of the cumulative reward can be\nobtained through an action-value function Qπ (s, a) adjusted\nduring the learning phase in order to approximate Q∗ (s, a),\nthe optimal action-value function. In this work we use a\nConvolutional Neural Network (CNN) for approximating the\nQ-function following the approach presented in [1]. The\nCNN takes as input four 84 × 84 grey scale images acquired\nby the downward looking camera mounted on the drone. The\nimages are processed by three convolutional layers and two\nfully connected layers. As activation function we used the\nrectified linear unit. The first convolution has 32 kernels of\n8 × 8 with stride of 2, the second layer has 64 kernels of\n4 × 4 with strides of 2, the third layer convolves 64 kernels\nof 3 × 3 with stride 1. The fourth layer is a fully connected\nlayer of 512 units followed by the output layer that has a\nunit for each valid action (backward, right, forward, left,\nstop, descent, land). Depending on the simulation, we used\na sub-set of the total actions available, we refer the reader to\nSection IV for additional details. A graphical representation\nof the network is presented in Figure 2.\nIt is important to focus on the two phases that characterize\nthe landing problem in order to isolate important issues. In\n\n\fFig. 2: Graphical representation of the DQN. The network\ntakes in input four 84 × 84 images, and generates in output 7\nactions: forward, right, backward, left, stop, descent, trigger.\n\nthe landmark detection phase we made the reasonable assumption of a flight at fixed-altitude. The vertical alignment\nwith the landmark is obtained through shifts in the xy-plane.\nThis expedient does not have any impact at the operational\nlevel but dramatically simplifies the task. To adjust θ, the\nparameters of the DQN, we used the following loss function:\n\u0014\nLi (θi ) = E(s,a,r,s0 )∼U (D)\n\n\u00012\nYi − Q(s, a; θi )\n\n\u0015\n(1)\n\nwith D = (e1 , ..., et ) being a dataset of experiences et =\n(st , at , rt , st+1 ) used to uniformly sample a batch at each\niteration i. The network Q(s, a; θi ) is used to estimate actions\nat runtime, whereas Yi is the target that is defined as follows:\nYi = r + γ max\nQ(s0 , a0 ; θi− )\n0\na\n\n(2)\n\nthe network Q(s0 , a0 ; θi− ) is used to generate the target and\nis constantly updated. The use of the target network is a trick\nthat improves the stability of the method. The parameters θ\nare updated every C steps and synchronized with θ− . In\nthe standard approach the experiences in the dataset D are\ncollected in a preliminary phase using a random policy. The\ndataset D is also called buffer replay and it is a way to\nrandomize the samples breaking the correlation and reducing\nthe variance [14].\nThe vertical descent phase is a form of Blind Cliffwalk\n[15] where the agent has to take the right action in order\nto progress through a sequence of N states and finally get\na positive or a negative reward. The intrinsic structure of\nthe problem makes extremely difficult to obtain a positive\nreward because the target-zone is only a small portion of the\nstate space. The consequence is that the buffer replay does\nnot contain enough positive experiences, making the policy\nunstable. To solve this issue we used a form of buffer replay,\ncalled partitioned buffer replay, that discriminates between\nrewards and guarantees a fair sampling between positive,\nnegative and neutral experiences. Another issue connected\nwith the reward sparsity is the utility overestimation [16].\nDuring a preliminary research we observed this problem\n\nin the vertical descent phase. Monitoring the Q-max value\n(the highest utility returned by the Q-network) we noticed\nthat it rapidly increased, overshooting the maximum possible\nutility of 1.0. The overestimation was associated with all the\nactions but the trigger. The trigger leads to a terminal state,\ntherefore its utility is updated without the max operator.\nThe max operator has been found to be the responsible\nof the overestimation in deep Q-learning [2]. In our case\nthe overestimated utilities of the four horizontal movements\n(grown up to 2.0 after 105 frames) were higher than the\nnon-overestimated utility associated with the trigger (stably\nconverged to 1.0). As a result the drone moved on top of the\nmarker and then shifted on the xy-plane without engaging\nthe trigger. A solution to overestimation has been recently\nproposed and has been called double DQN [2]. The target\nestimated through double DQN is defined as follows:\nYid = r + γ Q(s0 , argmax Q(s0 , a0 ; θi ); θi− )\n\n(3)\n\na0\n\nUsing this target instead of the one in Equation 2 the divergence of the DQN action distribution is mitigated resulting\nin a faster convergence and increased stability.\nB. Partitioned buffer replay\nIn a preliminary research we find out that the vertical\ndescent was affected by the sparsity of positive and negative\nrewards. The shortage of positive and negative experiences\ncaused an underestimation of the utilities associated to the\ntriggers. To deal with sparse rewards it has been proposed\nto divide the experiences in two buckets, one with high\npriority and the other with low priority [17]. Our approach\nis an extension of this method to K buckets. Another\nform of prioritized buffer replay has been proposed in [15].\nThe authors suggest to sample important transitions more\nfrequently. The prioritized replay estimates a weight for\neach experience based on the temporal difference error.\nExperiences are sampled with a probability proportional to\nthe weight. The limitation of this form of prioritization is\nthe introduction of another layer of complexity that may not\nbe justified for applications were there is a clear distinction between positive and negative rewards. Moreover this\nmethod requires O(log N ) to update the priorities. This issue\ndoes not significantly affect performances on the standard\nbenchmark but it has a relevant effect on robotics application,\nwhere there is a high cost in obtaining experiences.\nIn Section III-A we defined D = (e1 , ..., et ) being a\ndataset of experiences e = (s, a, r, s0 ) used to uniformly\nsample a batch at each iteration i. To create a partitioned\nbuffer replay we have to divide the reward space in K\npartitions:\nR = R(s, a) → Im R = R1 ∪ ... ∪ RK\n\n(4)\n\nFor any experience ei we associate its reward ri = r(ei )\nand we define the Kth buffer replay:\nDK = {(e1 , ..., eN ) : r1 , .., rN ∈ RK }\n\n(5)\n\n\fFig. 3: Finite-state machine for autonomous landing based on\nthe DQN hierarchy method. Each state has a specific trigger\nthat enables the DQN in the next stage.\n\nThe batch used for training the policy is assembled picking\nexperiences from each one of the K datasets with a certain\nfraction ρ ∈ {ρ1 , ..., ρK }.\nIn our particular case we have K = 3, meaning that we\nhave three datasets with D+ containing experiences having\npositive rewards, D− containing experiences having negative\nrewards, and D∼ for experiences having neutral rewards. The\nfraction of experiences associated to each one of the dataset\nis defined as ρ+ , ρ− , and ρ∼ .\nWhen using a partitioned buffer replay there is a substantial increase in the available number of positive and negative\nexperiences. For instance using a single buffer of size 2×104\nand accumulating 8.4 × 104 transitions, the total number\nof positive experiences is 343 and the number of negative\nexperiences is 2191. Using a partitioned buffer with size\n2×104 for the neutral partition, and size 104 for positive and\nnegative partitions, the total number of positive experiences\nis 1352 and the number of negative experiences 9270.\nC. Hierarchy of DQNs\nOur method is based on the use of a hierarchy of DQNs\nrepresenting sub-policies used to deal with different phases\nof the navigation. Similarly to a finite-state machine the\nglobal policy is divided into modules and each module is\ngoverned by a specific DQN or control loop. The DQNs are\nable to autonomously understand when it is time to call the\nnext state. The advantages of such a method are twofold. On\nthe one hand it is possible to reduce the complexity of the\ntask using a divide-and-conquer approach. On the other hand,\nthe use of a function approximator is confined in specific\nsandboxes making their use in robotic applications safer.\nA similar approach is described in hierarchical reinforcement learning [18] where a set of sub-policies, called options,\nare available to the agent in specific states. The options\ncontrol the agent in sub-regions of a core MDP called semiMDPs. In the present work we assume that the core MDP\ncan be divided into multiple isolated instances and that each\n\nFig. 4: Real environments: laboratory (a), small hall (b),\nlarge hall (c), mezzanine (d). Photo-realistic environments:\nwarehouse (e), disaster site (f), powerplant (g). Textures (h):\npavement, brick, grass, asphalt, sand, snow, soil. Marker and\ncorrupted marker (i).\n\ninstance is a proper MDP. The advantage is that we can use\nstandard Q-learning to train the agent.\nThe finite MDP describing the landing problem can be\ndivided in three main stages: landmark detection, descent\nmaneuver, touchdown. We described in Section III-A the\nfirst two phases. The touchdown consists in decreasing the\npower of the motors in the last few centimeters of the descent\nand then safely deactivate the UAV components (e.g. motors,\ncameras, boards, control unit, etc.). In this article we mainly\nfocused on the first two stages, because they represent the\nmost challenging part of the landing procedure. A graphical\nrepresentation of a hierarchical state machine is represented\nin Figure 3. We trained the first DQN (marker detection) to\nreceive a positive reward when the trigger was enabled inside\na target area. Negative reward was given if the trigger was\nenabled outside the target area. The second network (descent\nmaneuver) was trained using the same idea. In a preliminary\nphase we also trained a single network to achieve both\ndetection and descending. Given the size of the combined\nspaces the network was not able to converge to a stable\npolicy. As a baseline we also report the accumulated reward\ncurve of this network in Section IV.\nD. Training through domain randomization\nThe reality gap is the obstacles that makes it difficult\nto implement many robotic solutions in real world. This is\nespecially true for DRL where a large number of episodes\nis necessary in order to obtain stable policies. Recent research worked on bridging this gap using domain transfer\ntechniques. An example is domain randomization [19], a\nmethod for training models on simulated images that transfer\nto real images by randomizing rendering in the simulator.\nHere we adopt domain randomization in order to train the\n\n\fUAV in simple simulated environments and test it in complex\nenvironments (both simulated and real). The remarkable\nproperty of this approach is that it does not require any\npre-training on real images. If the variability is significant\nenough, models trained in simulation generalize to the real\nworld with no additional training. In the next session we\nshow how domain randomization has been included in the\ntraining phase and how the experiments have been organized.\nIV. E XPERIMENTS\nIn Section IV-A the methodology and the results obtained\nwith the DQN specialized in the landmark detection phase\nis presented, while in Section IV-B those concerning the\nvertical descent phase. In both training and testing we used\nthe same environment (Gazebo 7.7.x, ROS Kinetic) and\ndrone (Parrot BeBop 2). The simulator is a fork of the one\nused in [20] and it is freely available on our repository2 .\nThe control command sent to the vehicle is represented by\na continuous vector ∈ [−1, 1] that allows moving the drone\nwith a specific velocity on the three axes. We must point\nout that the physics of the engine has not been simplified\nin any way. There are important oscillatory effects during\naccelerations and decelerations that introduces a swinging\nbehaviour with consequent perspective distortion in the images acquired. Moreover a summation of forces effect shows\nwhen the vehicle accumulates inertia and a new velocity\ncommand is given. The DRL algorithm has to deal with this\nsource of noise.\nA. First series of simulations\nIn the first series of simulations we trained and tested the\nDQNs for the marker detection phase. We considered two\nnetworks having the same structure (Figure 2) and we trained\nthem in two different conditions. The first network was\ntrained with a uniform asphalt texture (DQN-single), whereas\nthe second network was trained with multiple textures (DQNmulti). The ability to generalize to new unseen situations is\nvery important and it should be seriously taken into account\nin the landing problem. Training the first network on a single\ntexture is a way to quantify the effect of a limited dataset on\nthe performance of the agent. In the DQN-multi condition\nthe networks were trained using seven different groups of\ntextures: asphalt, brick, grass, pavement, sand, snow, soil\n(Figure 4-h). These networks should outperform the ones\ntrained in the condition with single texture.\nAt each episode the drone started at a fixed altitude of 20\nm that was maintained for the entire flight. This expedient\nwas useful for two reasons: it significantly reduced the state\nspace to explore and it allowed visualizing the marker in\nmost of the cases giving a reference point for the navigation.\nIn a practical scenario this solution does not have any impact\non the flight, the drone is kept at a stable altitude and the\nframes are acquired regularly. To stabilize the flight we\nintroduced discrete movements, meaning that each action\nwas repeated for 2 seconds and then stopped leading to an\n2 https://github.com/pulver22/QLAB\n\n(a)\n\n(b)\n\nFig. 5: Flying-zone (red) and target-zone (green) for landmark detection (a) and vertical descent (b).\n\napproximate shift of 1 meter, similarly to the no-operation\nparameter used in [1]. The frames from the camera were\nacquired between the actions (0.5 Hz) when the vehicle was\nstationary. This expedient stabilized convergence reducing\nperspective errors.\n1) Methods: The training environment was represented by\na uniform texture of size 100 × 100 m with the landmark\npositioned in the center. The environment contained two\nbounding boxes (Figure 5a). At the beginning of each episode\nthe drone was spawned at 20 m of altitude inside the\nperimeter of the larger bounding box (15 × 15 × 20 m)\nwith a random position and orientation. A positive reward\nof 1.0 was given when the drone activated the trigger in\nthe target-zone, and a negative reward of -1.0 was given\nif the drone activated the trigger outside the target-zone.\nA negative cost of living of -0.01 was applied to all the\nother conditions. A time limit of 40 seconds (20 steps) was\nused to stop the episode and start a new one. In the DQNmulti condition the ground texture was changed every 50\nepisodes and randomly sampled between the 71 available.\nThe target and policy networks were synchronized every\nC = 10000 frames. The agent had five possible actions\navailable: forward, backward, left, right, land-trigger. The\naction was repeated for 2 seconds, then the drone was\nstopped and a new action was sampled. The buffer replay\nwas filled before the training with 4 × 105 frames using\na random policy. We trained the two DQNs for 6.5 × 105\nframes. We used an \u000f-greedy policy with \u000f decayed linearly\nfrom 1.0 to 0.1 over the first 5 × 105 frames and fixed at 0.1\nthereafter. The discount factor γ was set to 0.99. As optimizer\nwe used the RMSProp algorithm with a batch size of 32.\nThe weights were initialized using the Xavier initialization\nmethod. The DQN algorithm was implemented in Python\nusing the Tensorflow library. Simulations were performed\non a workstation with an Intel i7 (8 core) processor, 32\nGB of RAM, and the NVIDIA Quadro K2200 as graphical\nprocessing unit. On this hardware the training took 5.2 days\nto complete.\nTo test the performance of the policies we measured\nthe detection success rate of both DQN-single and DQNmulti in six tests. (i) The first test was performed on 21\n\n\funknown uniform textures belonging to the same categories\nof the training set. (ii) The second test was done on the\nsame environments but at different altitudes (20, 15, and\n10 meters). (iii) The third test was performed on the same\n21 unknown textures but using a marker corrupted through\na semi-transparent dust-like layer. (iv) The fourth test was\ndone randomly sampling 25 textures from the test set and\nmixing them in a mosaic-like composition. (v) The fifth test\nhas been done on three photo-realistic environments namely\na warehouse, a disaster site, and a power-plant (Figure 4e/g). (vi) The sixth and last test consisted in a real-world\nimplementation in the mezzanine environment (Figure 4-d).\nThe mezzanine is the only environment that allowed flying\nat an high altitude. We also measured the performances of\na random agent, an AR-tracker algorithm [6], and human\npilots in all the simulated environments. The human data has\nbeen collected using two methodologies. In the first approach\n7 volunteers used a space-navigator mouse that gave the\npossibility to move the drone in the three dimensions at\na maximum speed of 0.5 m/s. In the second methodology\n5 volunteers used a keyboard to move the drone in four\ndirections on the xy-plane through discrete steps of 1 meter.\nThe first methodology has been adopted in order to give to\nthe subjects a natural control interface, whereas the second\nmethodology gave the same control conditions of the drone.\nIn both conditions preliminary training allowed the subject\nto familiarize itself with the task. After the familiarization\nphase the real test started. In the landmark detection the\nsubjects had to align the drone with the ground marker\nand trigger the landing procedure when inside the targetzone. The subjects performed five trials for each one of the\nenvironments contained in the test set (randomly sampled).\nA time limit of 40 seconds (20 steps) was applied to each\nepisode. A landing attempt was declared as failed when the\ntime limit expired or when the subject engaged the trigger\noutside the target-zone.\n2) Results: The results for both DQN-single and DQNmulti show that the agents were able to learn an efficient\npolicy for maximizing the reward. In both conditions the\nreward increased stably without any anomaly (Figure 6\nbottom). In the same figure we also report the reward curve\nfor a baseline condition, where a single network has been\ntrained to perform both detection and descending. The reward\nof the baseline did not increase significantly and the resulting\npolicy was unable to engage the trigger inside the targetzone. The results of the test phase are summarized in Figure 6\n(top). The bar chart compares the performances of DQNsingle, DQN-multi, human pilots, AR-tracker and random\nagent. For human pilots we only report the results for the\ndiscrete control condition, since the score was higher than\nthe space-navigator condition (+6%). The average score on\nthe first test (uniform textures) for the DQN-multi is 91%.\nThe score obtained by the agent trained on a single texture\n(DQN-single) are significantly lower (39%). The human\nperformance is 90%, whereas the AR-tracker has an average\nscore of 95%. The random agent has an average reward of\n4% in this environment. Since both human pilots and DQNs\n\nFig. 6: Results of the first series of simulations. Top: detection success rate. Bottom: accumulated reward per episode\nfor DQN-single (blue line), DQN-multi (red-line), and baseline (green-line).\n\nused discrete steps to move in the environments, it is possible\nto estimate the average number of discrete steps required to\naccomplish detection. For human pilots the average number\nof steps is 12, whereas for the DQN-multi is 6, meaning\nthat humans were significantly slower. Testing the DQNmulti at different altitudes we noticed that the accuracy\nincreased at 15 (95%) and 10 (93%) meters, with respect\nto the accuracy at the training altitude of 20 meters (89%).\nThis result is explained by the fact that at lower altitudes\nthe marker is more visible. In the third test we compared\nthe DQN-multi and AR-tracker on uniform textures using\nthe corrupted marker. We observed a significant drop in the\nAR-tracker performances from 94% to 0% explained by the\nfact that the underlying template matching algorithm failed\nin identifying the corrupted marker. In the same condition\nthe DQN-multi performed well, with a drop in performance\nfrom 89% to 81%. The results in the fourth test (mixedtextures) show a lower performance for all the agents. DQNmulti has a success rate of 84% and the DQN-single of 9%.\nThe human pilots have a performance of 88% and the ARtracker of 82%. The results of the fifth test (photo-realistic\nenvironments) show a generic drop (DQN-multi=57%, DQNsingle=5%, Human=81%, Random=3%, AR-tracker=84%).\nThe overall performance on uniform textures, mixed textures\nand realistic worlds is 85% for DQN-multi, 32% for DQNsingle, 88% for human pilots, and 92% for the AR-tracker.\nFinally, the results on the sixth test (real-world environment,\nmezzanine) showed an overall accuracy of 50% on a total\nof 10 flights. We must point out that this condition was\nvery challenging because of high variability in lighting and\nattitude instability.\nB. Second series of simulations\nIn the second series of simulations we trained and tested\nthe DQNs specialized in the vertical descent. To encourage\nthe descent during the \u000f-greedy action selection we sampled\nthe action from a non-uniform distribution where the de-\n\n\fFig. 7: Snapshots representing vertical descent in the large\nhall environment. The bottom bar is the utility distribution\nof the actions. Descent has a negative utility (red bar) when\nthe drone is not centred on the marker.\n\nscending action had a probability ρ and the other N actions a\nprobability 1−ρ\nN . We used exploring-start generating the UAV\nat different altitudes and ensuring a wider exploration of the\nstate space. Instead of the standard buffer replay we used\nthe partitioned buffer replay described in Section III-B. We\ntrained two networks, the former in a single texture condition\n(DQN-single) and the latter in multi-texture condition (DQNmulti).\n1) Methods: The training environment was represented by\na flat floor of size 100 × 100 m with the landmark positioned\nin the center. The state-space in the vertical descent phase\nis significantly larger than in the marker detection and\nexploration is expensive. For this reason we reduced the\nnumber of textures used for the training, randomly sampling\n20 textures from the 71. We can hypothesize that using\nthe entire training set can lead to a better performance.\nThe action space available was represented by five actions:\nforward, backward, left, right, down. A single action was\nrepeated for 2 seconds leading to an approximate shift of\n1 meter due to a speed of 0.5 m/s. The descent action\nwas performed at a lower speed of 0.25 m/s to reduce\nundesired vertical shifts. The target and policy networks were\nsynchronized every C = 30000 frames. For the partitioned\nbuffer replay we chose ρ+ = 0.25, ρ− = 0.25, and ρ∼ = 0.5.\nA time limit of 80 seconds (40 steps) was used to stop\nthe episode and start a new one. The drone was spawned\nwith a random orientation inside a bounding box of size\n3 × 3 × 20 m at the beginning of the episode. This bounding\nbox corresponds to the target area of the landmark detection\nphase described in Section IV-A.1. A positive reward of 1.0\nwas given only when the drone entered in a target-zone of\nsize 1.5 × 1.5 × 1.5 m, centered on the marker (Figure 5b).\nIf the drone descended above 1.5 meter outside the targetzone a negative reward of -1.0 was given. A cost of living\nof -0.01 was applied at each time step. The same hyperparameters described in Section IV-A.1 were used to train the\nagent. In addition to the hardware mentioned in Section IVA.1, we also used a separate machine to collect preliminary\nexperiences. This machine is a multi-core workstation with\n32 GB of RAM and a GPU NVIDIA Tesla K-40. Before the\ntraining, the buffer replay was filled using a random policy\nwith 106 neutral experiences, 5 × 105 negative experiences\nand 6.2×104 positive experiences. We increased the number\n\nFig. 8: Results of the second series of simulations. Top:\ndescending success rate. Bottom: accumulated reward per\nepisode for DQN-single (blue line), DQN-multi (red-line),\nand baseline (green-line).\n\nof positive experiences using horizontal/vertical mirroring\nand consecutive 90 degrees rotation on all the images stored\nin the positive partition. This form of data augmentation\nincreased the total number of positive experiences to 5×105 .\nTo test the performance of the agents we measured the landing success rate of DQN-single, DQN-multi, human pilots,\nAR-tracker, and random agent in five tests. (i) In the first test\nthe agents performed landing on 21 unseen uniform textures.\n(ii) The second test consisted in landing on uniform textures\nwith a corrupted marker ( Figure 4-i). (iii) In the third test\n25 textures have been randomly sampled from the test set\nand mixed in a mosaic-like composition. (iv) In the fourth\ntest landing has been accomplished in three photo-realistic\nenvironments: warehouse, disaster site, powerplant (Figure 4e/g). (v) In the fifth and last test the UAV had to land in four\nreal-world indoor environments: laboratory, small hall, large\nhall, mezzanine (Figure 4-a/d). The performance of human\npilots has been measured in all the simulated environments\nthrough discrete and a continuous controllers using the same\nprocedure described in Section IV-A.1.\n2) Results: the accumulated reward per episode showed\nin Figure 8 (bottom), increased stably in both DQN-single\nand DQN-multi. We reported also the baseline curve of a\nnetwork trained on both detection and descent which did not\nlearn to accomplish the task.The results of the test phase are\nsummarized in Figure 8 (top). The bar chart compares the\nperformances of the DQN-single, DQN-multi, human pilots,\nAR-tracker, and random agent. For human pilots we only\nreport the score in the discrete control condition that is higher\nrespect to the space-navigator condition (+4%). The average\nscore on the first test (uniform textures) is 89% for DQNmulti, 44% for DQN-single, 91% for humans, and 98% for\nthe AR-tracker. Since both human pilots and DQNs used\ndiscrete steps to control the drone, it is possible to estimate\nthe average number of steps required to accomplish landing.\nFor human pilots the average number of steps is 23, whereas\nfor the DQN-multi is 19, meaning that human pilots were\n\n\fslower. In the second test we compared the performances\nof the DQN-multi and AR-tracker on uniform textures with\ncorrupted marker. The AR-tracker had a significant drop from\n98% to 0% due to the failure of the underlying templatematching algorithm. The DQN-multi had a drop from 89%\nto 51% showing to be more robust to marker corruption.\nThe third test (mixed textures) showed a general drop (DQNmulti= 82%, DQN-single=40%, Human=92%, Random=1%,\nAR-tracker=82%). In the fourth (realistic environments) have\nbeen observed a similar drop (DQN-multi= 81%, DQNsingle=17%, Human=88%, Random=1%, AR-tracker=91%).\nThe overall performances on uniform textures, mixed textures and realistic environments are 87% for DQN-multi,\n41% for DQN-single, 91% for human pilots, and 96% for the\nAR-tracker. In the fifth and last test (real-world) the DQNmulti has been used to control the descending phase in 40\nflights equally distributed in four environments (laboratory,\nsmall hall, large hall, mezzanine). The system obtained an\noverall success rate of 62%. Most of the missed landing have\nbeen caused by extreme light conditions (e.g. mutable natural\nlight), and by flight instability (e.g. strong drift). We can\nfurther analyze the DQN-multi policy observing the actionvalues distribution in different states (Figure 7). When the\ndrone is far from the marker the DQN penalizes the descent.\nHowever, when the drone is over the marker this utility\nsignificantly increases overcoming the others.\nV. C ONCLUSIONS AND DISCUSSION\nIn this work we used DRL to realize a system for the\nautonomous landing of a quadrotor on a static pad. The\nmain modules of the system are two DQNs that control\nthe UAV in two delicate phases: landmark detection and\nvertical descent. Using domain randomization we trained\nthe DQNs with simple uniform textures and tested them in\ncomplex environments (both simulated and real). The overall\nperformances are comparable with an AR-tracker algorithm\nand human pilots. In particular, the system is faster than\nhumans in reaching the pad and is more robust to marker\ncorruption compared to the AR-tracker. The most remarkable\noutcome is that the networks were able to generalize to\nreal environments despite training performed on a limited\nsubset of textures. In all the missed landing the flight was\ninterrupted because of the expiration time. Not even once\nthe drone landed outside of the pad. Most of the missed\nlanding have been caused by extreme conditions (mutable\nlighting and strong drift), not modeled in the simulator.\nWe hypothesize that the results can be further improved\ntaking into account these factors during the training phase.\nIn conclusion, the results obtained are promising, however\nfurther research is necessary in order to train stable policies\nthat can effectively work in a wide range of real-world\nconditions.\nAcknowledgements\nWe gratefully acknowledge the support of NVIDIA Corporation with the donation of the Tesla K40 GPU used for\nthis research.\n\nR EFERENCES\n[1] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G.\nBellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski,\net al., “Human-level control through deep reinforcement learning,”\nNature, vol. 518, no. 7540, pp. 529–533, 2015.\n[2] H. Van Hasselt, A. Guez, and D. Silver, “Deep reinforcement learning\nwith double q-learning.” in AAAI, 2016, pp. 2094–2100.\n[3] C. Forster, M. Faessler, F. Fontana, M. Werlberger, and D. Scaramuzza,\n“Continuous on-board monocular-vision-based elevation mapping applied to autonomous landing of micro aerial vehicles,” in Robotics and\nAutomation (ICRA), 2015 IEEE International Conference on. IEEE,\n2015, pp. 111–118.\n[4] S. Saripalli and G. Sukhatme, “Landing on a moving target using an\nautonomous helicopter,” in Field and service robotics. Springer, 2006,\npp. 277–286.\n[5] D. Zhou, Z. Zhong, D. Zhang, L. Shen, and C. Yan, “Autonomous\nlanding of a helicopter uav with a ground-based multisensory fusion\nsystem,” in Seventh International Conference on Machine Vision\n(ICMV 2014). International Society for Optics and Photonics, 2015,\npp. 94 451R–94 451R.\n[6] R. Polvara, S. Sharma, J. Wan, A. Manning, and R. Sutton, “Towards\nautonomous landing on a moving vessel through fiducial markers,” in\n2017 European Conference on Mobile Robots (ECMR), Sept 2017, pp.\n1–6.\n[7] Y. Gui, P. Guo, H. Zhang, Z. Lei, X. Zhou, J. Du, and Q. Yu,\n“Airborne vision-based navigation method for uav accuracy landing\nusing infrared lamps,” Journal of Intelligent & Robotic Systems,\nvol. 72, no. 2, p. 197, 2013.\n[8] D. Tang, T. Hu, L. Shen, D. Zhang, W. Kong, and K. H. Low, “Ground\nstereo vision-based navigation for autonomous take-off and landing of\nuavs: a chan-vese model approach,” International Journal of Advanced\nRobotic Systems, vol. 13, no. 2, p. 67, 2016.\n[9] S. Lange, N. Sunderhauf, and P. Protzel, “A vision based onboard\napproach for landing and position control of an autonomous multirotor\nuav in gps-denied environments,” in Advanced Robotics, 2009. ICAR\n2009. International Conference on. IEEE, 2009, pp. 1–6.\n[10] S. Lin, M. A. Garratt, and A. J. Lambert, “Monocular vision-based\nreal-time target recognition and tracking for autonomously landing\nan uav in a cluttered shipboard environment,” Autonomous Robots,\nvol. 41, no. 4, pp. 881–901, 2017.\n[11] F. Davide, Z. Alessio, S. Alessandro, D. Jeffrey, and D. Scaramuzza,\n“Vision-based autonomous quadrotor landing on a moving platform,”\nin IEEE International Symposium on Safety, Security, and Rescue\nRobotics (SSRR). IEEE, 2017.\n[12] A. R. Vetrella, I. Sa, M. Popović, R. Khanna, J. Nieto, G. Fasano,\nD. Accardo, and R. Siegwart, “Improved tau-guidance and visionaided navigation for robust autonomous landing of uavs,” in Field and\nService Robotics. Springer, 2018, pp. 115–128.\n[13] D. Lee, T. Ryan, and H. J. Kim, “Autonomous landing of a vtol\nuav on a moving platform using image-based visual servoing,” in\nRobotics and Automation (ICRA), 2012 IEEE International Conference\non. IEEE, 2012, pp. 971–976.\n[14] P. WawrzyńSki and A. K. Tanwani, “Autonomous reinforcement\nlearning with experience replay,” Neural Networks, vol. 41, pp. 156–\n167, 2013.\n[15] T. Schaul, J. Quan, I. Antonoglou, and D. Silver, “Prioritized experience replay,” arXiv preprint arXiv:1511.05952, 2015.\n[16] S. Thrun and A. Schwartz, “Issues in using function approximation\nfor reinforcement learning,” in Proceedings of the 1993 Connectionist\nModels Summer School Hillsdale, NJ. Lawrence Erlbaum, 1993.\n[17] K. Narasimhan, T. Kulkarni, and R. Barzilay, “Language understanding for text-based games using deep reinforcement learning,” arXiv\npreprint arXiv:1506.08941, 2015.\n[18] A. G. Barto and S. Mahadevan, “Recent advances in hierarchical\nreinforcement learning,” Discrete Event Dynamic Systems, vol. 13,\nno. 4, pp. 341–379, 2003.\n[19] J. Tobin, R. Fong, A. Ray, J. Schneider, W. Zaremba, and P. Abbeel,\n“Domain randomization for transferring deep neural networks from\nsimulation to the real world,” in Intelligent Robots and Systems (IROS),\n2017 IEEE/RSJ International Conference on. IEEE, 2017, pp. 23–30.\n[20] J. Engel, J. Sturm, and D. Cremers, “Camera-based navigation of\na low-cost quadrocopter,” in Intelligent Robots and Systems (IROS),\n2012 IEEE/RSJ International Conference on. IEEE, 2012, pp. 2815–\n2821.\n\n\f",
         "train",
         "43373",
         "7050"
        ],
        [
         "13",
         "17762",
         "cs.AI",
         "Artificial Intelligence",
         "1711.10123v1.pdf",
         "arXiv:1711.10123v1 [cs.DC] 28 Nov 2017\n\nHomomorphic Parameter Compression for\nDistributed Deep Learning Training\n\nJaehee Jang, Byunggook Na, Sungroh Yoon\nDepartment of Electrical Engineering\nSeoul National University\nsryoon@snu.ac.kr\n\nAbstract\nDistributed training of deep neural networks has received significant research\ninterest, and its major approaches include implementations on multiple GPUs\nand clusters. Parallelization can dramatically improve the efficiency of training\ndeep and complicated models with large-scale data. A fundamental barrier against\nthe speedup of DNN training, however, is the trade-off between computation and\ncommunication time. In other words, increasing the number of worker nodes\ndecreases the time consumed in computation while simultaneously increasing\ncommunication overhead under constrained network bandwidth, especially in\ncommodity hardware environments. To alleviate this trade-off, we suggest the idea\nof homomorphic parameter compression, which compresses parameters with the\nleast expense and trains the DNN with the compressed representation. Although\nthe specific method is yet to be discovered, we demonstrate that there is a high\nprobability that the homomorphism can reduce the communication overhead, thanks\nto little compression and decompression times. We also provide theoretical speedup\nof homomorphic compression.\n\n1\n\nIntroduction\n\nDeep learning (DL) derives structured information from raw data using deep neural networks (DNN).\nDL finds hierarchical representations of data through several non-linear layers of a DNN. When\nthe problem to be solved by using DL is challenging, we need to grasp complicated representations\nfrom the data. With the use of DNNs to solve an increasing number of high-abstraction problems\nin various fields, the size of training models and the computational load to train the models have\ncontinued to grow. Under current software and hardware constraints, DNN training demands a\nmassive amount of processing time [1], naturally leading to the need for distributed deep learning\nnaturally uprose [2, 3, 4, 5, 6]. Distributed DL divides the workload (training data or model) to\ndifferent machines and aims for faster learning while maintaining the original performance of the\nmodel.\nDNN iteratively optimizes weight parameters based on gradients computed from feedforward/backpropagation, which is highly sequential. Hence the implementation of distributed DNN\ntraining requires specific design principles and strategies as they have been suggested for years [7]. To\ngive a brief illustration on how distributed DL is implementated in general, let’s take the synchronous\nSGD update scenario as an example (Fig. 1). Synchronous SGD trains by iterating a set of processes\nto update global parameters, described by a dotted box in Fig. 1. The set of global parameter update\nconsists of the following steps. First, all the worker nodes train until the designated number of\niterations (Local Parameter/Gradient Computation in Fig. 1). Then, all the worker nodes respectively\npush their local parameters to the parameter server (Local Parameter Transfer in Fig. 1). Lastly, the\nparameter server decides global parameters by aggregating all the pushed local parameters(Global\nParameter Update in Fig. 1), and pulls them to the worker nodes(Global Parameter Broadcast in\nFig. 1).\nThe worker nodes participating in the training frequently exchange their training status with other\nnodes so that the model can reflect all the divided workloads. However, DNN models are large and so\nthe communication load. Hence they cause bottlenecks on transmission because of the contrained\n\n\fWorker\n3\n\nLocal\nParameter/\nGradient\nComputation\n\nLocal\nParameter\nTransfer\n\nLocal\nParameter/\nGradient\nComputation\n\nLocal\nParameter\nTransfer\n\nGlobal Parameter\nBroadcast\n\nWorker\n2\n\nExchange 2\nGlobal Parameter\nUpdate\n\nWorker\n1\n\nGlobal Parameter\nBroadcast\n\nExchange 1\nGlobal Parameter\nUpdate\n\nStart\n\n...\n\nComputation time Parameter transfer time\n\nFigure 1: Simplified process demonstration of distributed DL using synchronous SGD\n\ncommunication bandwidth. Especially under commodity hardware environments, the weight-transfer\ntime overwhelms even the computing time. Along with the transmission time, the time technically\nrequired for communication, that is, the time to prepare and sustain communication, is also included\nas communication overhead. The communication overhead is one of the main factors that increase\nthe parallel training time. In order to alleviate the communication overhead, attempts have been made\nto reduce the model size before communication [8, 9, 10].\nThe goal of our study is to demonstrate homomorphic parameter compression, which is a novel concept of compressed deep learning. As the term homomorphic suggests, it is a compression method that\nreduces the size of parameters and allows key operations of DL to be executed without decompression.\nSince parameters are transferred numerous times during distributed training settings, this method\ncan remarkably reduce the time consumed in communication, which is the main rate-limiting step\nof distributed training. Furthermore, homomorphism prevents the generation of additional overhead\nby repetitive compression and decompression. The main contributions of this paper include the\nfollowings: 1) To our knowledge, this is the first attempt to demonstrate homomorphic parameter\ncompression. 2) We theoretically characterize the possible factors in the parameter compression,\ne.g., the compression ratio, and provide thorough simulative analyses. 3) We provide the theoretical\nreduction in training time of the homomorphically compressed distributed training in function of the\nnumber of participating worker nodes for different values of the compression ratio.\n\n2\n\nLiterature Survey on Compressed Deep Learning\n\nNumerous studies have suggested compression in deep learning [11, 12, 13, 14]. Existing compression\nmethods aim at fitting very-large-scale models into a mobile device or single FPGA chip, at alleviating\nthe high communication overhead due to distributed training, and at improving computational\nperformance as well as storage and power efficiency.\nPost-training compression for inference. A series of studies reduced the storage and energy\nrequired to run inference on large DL models and deploy them on embedded systems or mobile\ndevices. Deep compression [11] used pruning, trained quantization, and Huffman encoding on weights\nand demonstrated a high compression ratio to fit in on-chip memory. CNNpack [15] demonstrated\nconvolutional neural network (CNN) compression in the discrete cosine transform (DCT) frequency\ndomain. These methods can effectively reduce the size of networks while retaining pre-trained\ninformation. On the other hand, since they are designed for compression after training is completed,\nthe time consumed in compression is a minor issue.\nIn-training compression for refficient deep learning. Employing compression in training enables\nefficient computation and communication under limited resources. Especially when transferring\nparameters in distributed DL, the constrained network bandwidth may consume a large amount of\ntime in communication and slow down the entire training process. The following approaches proposed\ncompression for both training and inference in order to improve computational performance as well as\nenergy and storage efficiency. We classified the approaches into two types: repetitive (de)compression\nand one-time compression. The training process of the methods is illustrated in Fig. 2.\nRepetitive (de)compression Some methods encode weights (or gradients) for every iteration We\ncall such methods repetitive (de)compression methods. Weight binarization methods [12, 13] binarize\nweights in order to train from low-power devices or specialized hardware. The binarized weights are\nused only during the forward and back propagations but not during parameter update. The authors of\n[14, 16] used gradient binarization with distributed DL training in order to reduce the communication\noverhead. They encoded gradients during global parameter update, and worker nodes have to decode\nthe gradients to update their local parameters. FreshNet [17] combined hashing [18] with DCT\n2\n\n\fParameter Decompression\n\nGlobal Parameter\nBroadcast\n\n...\n\nGlobal Parameter\nBroadcast\n\nExchange 2\nGlobal Parameter\nUpdate\n\nLocal\nParameter/\nGradient\nComputation\n\nParameter Decompression\nGlobal Parameter\nUpdate\nParameter Compression\n\nParameter Compression\n\nLocal\nParameter/\nGradient\nComputation\n\nLocal Parameter Transfer\n\nWorker\n3\n\nLocal\nParameter/\nGradient\nComputation\n\nGlobal Parameter\nUpdate\n\nWorker\n2\n\nExchange 2\n\nExchange 1\nLocal Parameter Transfer\n\n(b)\n\nParameter Compression\n\nStart\nWorker\n1\n\nParameter Decompression\n\nWorker\n3\n\nLocal\nParameter\nTransfer\n\nGlobal Parameter\nBroadcast\n\nLocal\nParameter/\nGradient\nComputation\n\nWorker\n2\n\nGlobal Parameter\nBroadcast\n\n(a)\n\nParameter Decompression\nGlobal Parameter\nUpdate\nParameter Compression\n\nExchange 1\nParameter Compression\n\nStart\nWorker\n1\n\n...\n\nFigure 2: Simplified process demonstration of mid-training compression methods, based on synchronous SGD: (a) repetitive (de)compression, and (b) one-time compression. Note that we considered\nparameter transfer time as the time in which a worker node is not training but waiting for new gradient\nupdate. (Best viewed in color)\nTable 1: Examples of Gzip compression\nSize\n\nAlexNet Caffemodel\nILSVR2012 Train Data\nCIFAR-100 Train Data\n\nCompression\nratio\n233MB\n1.079\n240GB\n1.269\n147MB\n1.097\n\nCompression\ntime\n8.079s\n10 532.177s\n660.876s\n\nDecompression\ntime\n1.898s\n3886.498s\n2.242s\n\nto compress CNN models and train in the frequency domain. Good compression performance\nand robustness in model accuracy were demonstrated . However, continuous compressions and\ndecompressions involve high risks for additional compression overhead, as shown in Fig. 2(b).\nAlthough good compression performance was demonstrated, more careful considerations are needed\nto utilize the aforementioned methods in distributed training, as is done with QSGD [16] by double\nbuffering. A quantitative analysis of compression overhead will be presented in Section 4.\nOne-time compression If DL models are compressed only once, the compression time will not significantly affect the overall training time. Compressed linear algebra (CLA) [10] exploits lightweight\ndatabase compression techniques to compress matrices and perform computations in the compressed\nrepresentation. Despite the compression ratio and the operation performance being close to that of\nuncompressed operations, it is difficult to be applied directly to distributed DL training because more\nnonlinear operations are required in DL training. Especially, operations that are frequently used in DL\ntraining, such as normalization and pooling, are not yet conducted in the compressed representation 1 .\n\n3\n\nAlgorithmic Design\n\nCommunication overhead is one of the major drawbacks of distributed DL, and compressing the\nparameters can reduce the communication workload. On the other hand, if the parameters are compressed and decompressed at every update, there are high risks for additional compression overhead.\nAs indicated in Table 1, compressing and decompressing parameters can take considerable time.\nTherefore, we need a compression approach that does not increase the computing time significantly\nwhile reducing the size of parameters properly.\nWe propose homomorphic parameter compression, inspired from homomorphic encryption [19].\nHomomorphism suggests an algebraic system that is encoded from another algebraic system and\nperforms operations equivalent to those of the encoded system. Our goal is to propose a compression\nmethod that can be trained without decompression. By referring to the early formulation of homomorphic encryption [19], the definition of homomorphic compression is as follows. Suppose we have\na system S =< W ; f1 , f2 , ... > that consists of a set of parameters W and operations fi s concerned\nwith training. The possible fi s may vary depending on the model structure. As Fig. 3 shows, linear\noperations take the majority of the operations and nonlinear operations such as pooling and relu are\n1 The\n\nconfirmed version of September 2017 can be found at https://github.com/apache/systemml\n\n3\n\n\f62.83% gemm\n17.78% img to col transformation\n6.08% normalization\n4.13% axpy\n3.88% pooling\n2.81% optimization (SGD)\n2.38% relu\n0.07% dropout\n0.04% softmax+loss\n\nFigure 3: GPU kernel analysis of AlexNet training (Caffe)\n\nincluded as well. We propose finding the encoding function φ : S → S0 , where S0 =< W 0 ; f00 , f20 , ... >,\nwhere is the compressed system.\n1. An encoded version of a weight w0i = φ (wi ) should be smaller than original weight wi .\n2. φ should be easy to compute. Conversion by φ should not take too much time. We point\nout how compression overhead can slow down the total training time in Fig. 5. We can\ncontinue training even without decompression if the compression time is long enough to\naffect the total training time, as it is difficult to expect temporal gain through homomorphic\ncompression in such a case.\n3. The operations fi0 should be efficiently computable. When training DL, varied operation\nfunctions ( fi s) are required, such as matrix multiplication and activation functions, as\nshown in Fig. 2 in Supplement. If we encode the functions to equivalent fi0 operations, the\ncomputational efficiency of fi0 operations is also required to be high.\n\n4\n4.1\n\nExperimental Study\nExperimental Settings\n\nNotations & formulated assumptions We assumed of a distributed training environment where\nthere are M worker nodes. It parallelizes a single-node training with minibatch size B on target dataset\nof size D. The single node consumes C of time when computing a minibatch, and the total size of\nweight parameters is measured as W.\nOptimization Scheme When conducting distributed training, we can define various optimization\nschemes according to when local parameters have been updated (worker nodes have been trained) with\nglobal parameters (parameters that all worker nodes share). Communication overhead is inevitable\nregardless of the strategy we shall choose. In order to emphasize the effect of communication\noverhead with different numbers of worker nodes, we assumed that we optimize the DNN training by\nsynchronous stochastic gradient descent (synchronous SGD).\nSynchronous SGD trains by iterating a set of processes to update global parameters, as described in\nFig. 1. In this paper, we defined the time required in the local parameter/gradient computation step\nuntil the designated number of iterations i as computation time, Tcmt , and the time required in the\nremaining steps as parameter transfer time, Ttn f which adds up to the time required for one set of\nglobal parameter update, Tupdate = Tcmt + Ttn f .\nMinibatch size, B → b We assumed data-parallelized training, which divides the training dataset D\ninto M worker nodes. As the dataset is divided, the ratio of the original minibatch size to training\ndata size becomes larger. If the batch size is too large, the training may be delayed [20]. Hence it is\nassumed that the minibatch size is reduced by the reduction amount of the training set. Therefore,\nB\nb= M\n.\nMinibatch computation time, C → c As the minibatch size decreases by\nC\none iteration is expected to decrease by the same ratio. Therefore, c = M\n4\n\n1\nM,\n\nthe time consumed for\n\n\fTime (sec)\n\nTime (sec)\n\n16\n120\n100\n80\n60\n40\n20\n0\n\nComputation\ntime\nParameter\ntransfer time\n\n12\n8\n4\n0\n\nSingle\n\n2\n4\n8\n16\n32\nNumber of worker nodes\n(a)\n\n64\n\nSingle\n\n2\n4\n8\n16\n32\nNumber of worker nodes\n(b)\n\n64\n\nFigure 4: Simulated analysis of Tcmt vs. Ttn f on vanilla synchronous SGD training. We conducted\nexperiments for one set of global parameter update. (a) 200-iter AlexNet training (Caffe). (b) 20-iter\nSTREET training (TensorFlow).\n\nTime (sec)\n\nTime (sec)\n\n240\n160\n80\n0\n\nSingle\n\n2\n4\n8\n16\n32\nNumber of worker nodes\n(a)\n\n64\n\n30\n25\n20\n15\n10\n5\n0\n\nComputation\ntime\nParameter\ntransfer time\nCompression/\ndecompression time\nSingle\n\n2\n4\n8\n16\n32\nNumber of worker nodes\n(b)\n\n64\n\nFigure 5: Simulated analysis of Tcmt vs. Ttn f on vanilla synchronous SGD training with a common\ncompression method. We conducted experiments for one set of global parameter update. We assumed\nGzip compression/decompresion at every parameter update. (a) 200-iter AlexNet training (Caffe). (b)\n20-iter STREET training (TensorFlow).\nComputation time per update, Tcmt Since the data and minibatch size are decreased by M1 , training\niterations are required to be tje same as single-node training in order to train the same number of\nepochs. Hence, Tcmt = i · c = i·C\nM.\nParameter transfer time, Ttn f In synchronous SGD, every local parameter of the worker node is\ncollected when updating a global parameter. If the number of participating worker nodes increases, the\nnumber of parameters to be exchanged linearly increases. That is, if we define the size of the weight\nparameter as W and train with M worker nodes, the number of parameters required to communicate\nis W · M. Letting the transmission rate of the cluster be χ, the parameter transfer time is denoted as\nTtn f = Wχ·M .\nFrom the assumptions stated in Section 3, we simulated distributed training for CNN and RNN models.\nWe trained the ImageNet dataset [21] using AlexNet [22] to simulate distributed CNN training. For\nsimulative distributed RNN training, we conducted STREET model [23] training on the French Street\nName Signs (FSNS) dataset 2 . We used Caffe [24] for the CNN model and TensorFlow [6] for the\nRNN model as computing engines. Synchronous SGD iterates the same processes of global parameter\nupdate, where the worker nodes train up to the designated iterations and communicate parameters to\napply the global training trend. Hence, Figs. 4, 5, 6, and Fig. 7(b), (c) represent only one set of global\nupdates for the total training trend in terms of time.\nThe hardware we used in the simulation is a commodity cluster. We used a homogeneous cluster\nconsisting of 25 identical machines connected via Gigabit Ethernet. Each worker node has an Intel\nCore i7-4790 processor with 16GB of main memory and an NVIDIA GTX970 GPU.\n4.2\n\nSimulated Analysis of Communication Overhead Effect and Naïve Parameter\nCompression\n\nFig. 4 shows the simulated global parameter update of vanilla synchronous SGD. As the number\nof nodes increases, the computation time decreases but the parameter transfer time increases. At\nsome points, parameter transfer takes more time than minibatch computation, which demonstrates the\nserious inefficiency of resource utility due to communication overhead in distributed training. If we\nkeep increasing the number of nodes, the parameter transfer time even exceeds the single minibatch\ncomputation time, becoming a hindrance rather than contributing to speedup.\nIf we can compress weight parameters by ρx, the parameter transfer requirement will be reduced\nby 1r . This will also reduce the time required for parameter transfer. However, the time consumed in\n2 TensorFlow\n\nimplementation at https://github.com/tensorflow/models/tree/master/street\n\n5\n\n\f(a)\nρ=0.2\n\n(b) ρ=0.2\nρ=0.5\n\n13\n\nComputation time\n50\n\nIdeal\n\n11\n\n7\nHPC\n\n5\nVanilla\nSSGD\n\n3\n1\n1\n\n2\n4\n8 16 32\nNumber of worker nodes\n\nTime (sec)\n\n40\n\n9\nSpeedup\n\n(c) ρ=0.5\nParameter transfer time\n\n30\n\nVanilla\nSync SGD\n\n20\n\nTheoretical\nlower bound\nIdeal\n\n10\n0\n\n1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0 1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0\nh (Computational overhead)\n\nFigure 6: (a) Theoretical speedup as a function of the number of worker nodes for different compression ratios when training the ImageNet with AlexNet. (b)&(c) Simulated analysis of the proposed\nmethod for 200-iter AlexNet training on 16 worker nodes, when h = 1.0, 1.1, ...2.0 and (b) ρ = 0.2.\nand (c) ρ = 0.5. We illustrated the expected Tcmt and Ttn f for one set of global parameter update.\nCompression and decompression are not shown in these graphs because they are only performed\nonce throughout the training.(Best viewed in color)\ncompressing parameters is a problem. Suppose after a worker node finished its batch, it compresses\nthe trained parameter using Gzip. Then, the parameter server aggregates the compressed parameters\nand since Gzip-compressed data are not computable, the parameter server has to decompress the\nparameters to aggregate and average. After global parameters are set, the parameter server compresses\nthe parameters again and sends them back to the worker nodes. When a worker node receives the\ncompressed parameters, it has to decompress them again to keep training.\nIf compressed training is conducted as explained above, there is a high possibility of another overhead\ncalled compression overhead. We simulated this in Fig. 4, and the results are shown in Fig. 5. If\nwe use Gzip compression, the parameter transfer time is decreased because of the reduced size of\nparameters. On the other hand, the compression and decompression time can significantly exceed the\noriginal training time, as shown in Fig. 5.\n4.3\n\nThe Expected Gain of Homomorphic Compression\n\nFrom the simulation results in Section 4, we can learn two things. First, compressing the parameter\nsize can reduce the communication workload, and second, we need a compression approach that takes\ncompression overhead into account. Therefore, we propose homomorphic parameter compression\nhere.\nFig. 6(a) shows the theoretical speedup of homomorphically compressed distributed training based\non the simulative analysis conducted in this section. It is represented as a function of the number\nof participating worker nodes for different compression ratios. The orange dotted curve in Fig. 6(a)\nshows the ideal distributed training case, where there is no communication at all so we can achieve\nlinear speedup. The yellow dashed curve is the speedup of vanilla SGD. The ideal speedup in\nhomomorphic compression occurs when there is no overhead due to the increased operation time.\nHence, the green solid and red double solid curves are the theoretical upper bounds in speedup when\nthe compression ratio is 0.2 and 0.5 respectively.\nIn actual homomorphic compression, the encoded operations are likely to require more time than the\noriginal operations. The simulated results based on this assumption are shown in Fig. 7. Note that\nthe compression time in Fig. 7 is not included in every parameter update but only in the early stage.\nWe assumed that computing in the compressed representation may take more time than the original\ncomputations. However, if we can manipulate the operation overhead and compression ratio, fast and\nlarge-scale DL training is attainable, as shown in Fig. 7.\n\n5\n\nDiscussion and Future Work\n\nWe analyzed the effect of homomorphic compression on distributed training in Section 4. In this section, we discuss the parameters required when designing a homomorphic compression method. Below,\nwe present an in-depth analysis on the computational efficiency for fi0 ’s based on the assumptions\nmade in Section 3 and Section 4:\nLet ρ be a compression ratio, ρ =\n\nφ (wi )\nwi\n\n(where 0 < ρ < 1), and T fi ) and T fi0 be the time consumed\n\nin performing fi and fi0 respectively. And we define operation overhead h as h =\n6\n\nTf 0\ni\n\nT fi\n\n. Then, the\n\n\fComputation time\n\nWith Gzip\ncompression\nVanilla\nSync SGD\n\n(De)Compression time\n24\n\n50\n\n20\nTime (sec)\n\nTime (sec)\n\nHPC\n(proposed)\n\nParameter transfer time\n\n60\n40\n30\n20\n10\n0\n\n1×10 5 2×10 5\nTime (sec)\n(a)\n\n3×105\n\n16\n12\n8\n4\n\n0\nSingle 2\n4\n8\n16\n32\n(uncompressed) Number of worker nodes\n(b)\n\n64\n\n0\nSingle 2\n4\n8\n16\n32\n(uncompressed) Number of worker nodes\n\n64\n\n(c)\n\nFigure 7: Simulated analysis of the proposed method. (a) Comparison of total Alexnet training time\namong the proposed method, synchronous SGD with Gzip compression, and vanilla synchronous\nSGD. (b)&(c) Tcmt vs. Ttn f on synchronous SGD training with proposing method. We illustrated the\nexpected result of one set of global parameter update. Compression and decompression shown in the\ngraphs are performed only once throughout the training. (b) 200-iter AlexNet training (Caffe) when\nh = 1.3, ρ = 0.2. (c) 20-iter STREET training (TensorFlow) when h = 1.5, ρ = 0.5.\n0 and parameter transfer time T 0 are expressed as\ncompressed minibatch computation time Tcmt\ntn f\nC\nMW\n0\n0\nC · Tcmt = M · h, Ttn f = BW · ρ, respectively.\nC\nBy setting the upper bound of the total training time as M\n· r (where 1 ≤ r ≤ M), the relationship\nbetween h and ρ can be obtained as expressed by Eq. ??. Therefore, we can achieve the desired\nspeedup if we can fit h and ρ under Eq. ??.\n\nC\nC\nMW\n·r ≥ ·h+\n·ρ\nM\nM\nBW\nM 2W\n∴h≤−\n·ρ +r\nCBW\nFig. 6(b) expected tendency of training time with respect to h and ρ. The most ideal training time for\nC\nM worker nodes to learn a model that takes batch computation time C is M\n(orange dotted line in\nFig. 6(b)). However, even when we train in parallel, the learning status among nodes is interchanged.\nTherefore, the realistic training time of synchronous SGD, considering communication time, is the\nsame as the red line in Fig. 6(b).\nIn addition to the upper bound the computation time for fi0 , S0 and φ are needed to be designed in\nconsideration of frequently used operations. Fig. 8 shows the GPU profiling result of AlexNet training\nwith Caffe, and it suggests that operations such as gemm take most of the computation time. It is\nexpected that, if we significantly reduce the time required for computing gemm, the operation overhead\neffect will be much weaker. Our future work is to propose a detailed homomorphic compression\nmethod.\n\nReferences\n[1] J. Keuper et al. Distributed training of deep neural networks: theoretical and practical limits of\nparallel scalability. In Proceedings of the Workshop on Machine Learning in High Performance\nComputing Environments. IEEE Press, 2016.\n[2] R. Bekkerman, et al. Scaling up machine learning: Parallel and distributed approaches.\nCambridge University Press, 2011.\n[3] J. Dean, et al. Large scale distributed deep networks. In Advances in neural information\nprocessing systems, 2012.\n[4] B. Recht, et al. Hogwild: A lock-free approach to parallelizing stochastic gradient descent. In\nAdvances in neural information processing systems, pages 693–701, 2011.\n[5] H. Kim, et al. Deepspark: Spark-based deep learning supporting asynchronous updates and\ncaffe compatibility. CoRR, vol. abs/1602.08191, 2016.\n[6] M. Abadi, et al. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015.\nSoftware available from tensorflow.org.\n[7] E. P. Xing, et al. Strategies and principles of distributed machine learning on big data. Engineering, 2(2):179–195, 2016.\n7\n\n\f[8] F. N. Iandola, et al. Squeezenet: Alexnet-level accuracy with 50x fewer parameters and< 0.5\nmb model size. arXiv preprint arXiv:1602.07360, 2016.\n[9] R. Spring et al. Scalable and sustainable deep learning via randomized hashing. arXiv preprint\narXiv:1602.08194, 2016.\n[10] A. Elgohary, et al. Compressed linear algebra for large-scale machine learning. Proceedings of\nthe VLDB Endowment, 9(12):960–971, 2016.\n[11] S. Han, et al. Deep compression: Compressing deep neural networks with pruning, trained\nquantization and huffman coding. arXiv preprint arXiv:1510.00149, 2015.\n[12] M. Courbariaux, et al. Binaryconnect: Training deep neural networks with binary weights\nduring propagations. In Advances in Neural Information Processing Systems, 2015.\n[13] M. Courbariaux, et al. Binarized neural networks: Training deep neural networks with weights\nand activations constrained to+ 1 or-1. arXiv preprint arXiv:1602.02830, 2016.\n[14] F. Seide, et al. 1-bit stochastic gradient descent and its application to data-parallel distributed\ntraining of speech dnns. In Fifteenth Annual Conference of the International Speech Communication Association, 2014.\n[15] Y. Wang, et al. Cnnpack: Packing convolutional neural networks in the frequency domain. In\nAdvances in Neural Information Processing Systems 29. 2016.\n[16] D. Alistarh, et al. Qsgd: Randomized quantization for communication-optimal stochastic\ngradient descent. arXiv preprint arXiv:1610.02132, 2016.\n[17] W. Chen, et al. Compressing convolutional neural networks in the frequency domain. In\nProceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery\nand Data Mining, KDD ’16, pages 1475–1484, New York, NY, USA, 2016. ACM.\n[18] W. Chen, et al. Compressing neural networks with the hashing trick. In Proceedings of the\n32Nd International Conference on International Conference on Machine Learning - Volume 37,\nICML’15, pages 2285–2294. JMLR.org, 2015.\n[19] R. L. Rivest, et al. On data banks and privacy homomorphisms. Foundations of secure\ncomputation, 4(11):169–180, 1978.\n[20] Y. Bengio. Practical recommendations for gradient-based training of deep architectures. In\nNeural networks: Tricks of the trade. Springer, 2012.\n[21] J. Deng, et al. Imagenet: A large-scale hierarchical image database. In Computer Vision and\nPattern Recognition, 2009. CVPR 2009. IEEE Conference on, pages 248–255. IEEE, 2009.\n[22] A. Krizhevsky, et al. Imagenet classification with deep convolutional neural networks. In\nAdvances in neural information processing systems, 2012.\n[23] R. Smith, et al. End-to-End Interpretation of the French Street Name Signs Dataset. Springer\nInternational Publishing, 2016.\n[24] Y. Jia, et al. Caffe: Convolutional architecture for fast feature embedding. arXiv preprint\narXiv:1408.5093, 2014.\n\n8\n\n\f",
         "train",
         "29476",
         "4516"
        ],
        [
         "14",
         "18871",
         "cs.AI",
         "Artificial Intelligence",
         "1803.04474v1.pdf",
         "Predicting Crime Using Spatial Features\nFateha Khanam Bappee1 , Amı́lcar Soares Júnior1 , and Stan Matwin1,2\n1\n\narXiv:1803.04474v1 [cs.AI] 12 Mar 2018\n\n2\n\nInstitute for Big Data Analytics, Dalhousie University, Halifax\nInstitute for Computer Science, Polish Academy of Sciences, Warsaw\n\nAbstract. Our study aims to build a machine learning model for crime\nprediction using geospatial features for different categories of crime. The\nreverse geocoding technique is applied to retrieve open street map (OSM)\nspatial data. This study also proposes finding hotpoints extracted from\ncrime hotspots area found by Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN). A spatial distance feature\nis then computed based on the position of different hotpoints for various\ntypes of crime and this value is used as a feature for classifiers. We test\nthe engineered features in crime data from Royal Canadian Mounted Police of Halifax, NS. We observed a significant performance improvement\nin crime prediction using the new generated spatial features.\n\n1\n\nIntroduction\n\nIn recent years, with the availability of high volume of crime data, scientists\nhave been motivated to pursue research in the field of crime and criminal investigations. Understanding the factors related to different categories of crimes and\ntheir consequences is particularly essential. The study shown in [7] applies the\nprocedure of statistical analysis on violent crime, poverty, and income inequality and outlines that homicide and assault has more connection and correlation\nwith poverty or income inequality than other crimes. The research found that\ncrime in the real-world highly correlates with time, place and population which\nmake the researcher’s task more complicated [3]. Moreover, this geographical and\ndemographic information contain many discriminatory decision pattern [10,6].\nLeveraging data mining and machine learning techniques with crime research\noffer the analysts the possibility of better analysis and crime prediction, as well\nas mining association rules for crime pattern detection.\nOur study aims to build a machine learning model to predict the relationship\nbetween criminal activity and geographical regions. We choose Nova Scotia (NS)\ncrime data as the target of our study. We focus on four different categories of\ncrime: (i) alcohol-related; (ii) assault; (iii) property crime; and (iv) motor vehicle.\nIn this work, we focus on the creation of two spatial features to predict crime:\n(i) gecoding; (ii) crime hotspots.\nThe contributions of this work include how geocoding can be used to create\nfeatures using OSM data and crime hotspots are created using a density-based\nclustering algorithm. Moreover, hotpoints are extracted from the hotspots. We\nshow using a real-world scenario that these two new features increase the performance of different classifiers for predicting four different types of crime.\n\n\f2\n\n2\n\nBappee et. al. 2018\n\nRelated Work\n\nThe existing work on crime prediction can be categorized into three different\ngroups based on the features such as temporal, spatial and demographic aspects.\nBromley and Nelson [1] reveal temporal patterns of crime to predict alcoholrelated crime in Worcester city. They also provide valuable insight into the spatial\ncharacteristics of the alcohol-related crime. The authors examine the patterns of\ncrime and disorder at street level by identifying hotspots. Ratcliffe [11] proposes\nthree types of temporal and spatial hotspots for crime pattern detection. The\nauthor also shows how the spatial and temporal characteristics combine through\nhis hotspot matrix. However, the author did not apply any machine learning\nstrategy to predict crime.\nIn [2], the authors analyze four categories of crime data which include liquor\nlaw violations, assaults and batteries, vandalism, and noise complaints. Different categories of crime show different temporal patterns. Brower and Carroll [2]\nclarify crime movement through the city of Madison using GIS mapping. The\nauthors investigate the relationships among high-density alcohol outlets and different neighborhoods. Chainey et al. [5] identify crime hotspots using Kernel\nDensity Estimation (KDE) to predict spatial crime patterns. Similarly, in another study, Nakaya and Yano [8] create crime hotspots with the help of KDE.\nHowever, they combine temporal features with crime hotspots analysis.\nNath [9] employed a semi-supervised clustering technique for detecting crime\npatterns. In [13], the authors propose a pattern detection algorithm named Series\nFinder to detect patterns of a crime automatically. In [12], the authors study\ncrime rate inference problem using Point-Of-Interest data and taxi flow data.\nPoint-Of-Interest data and taxi flow data are used to enhance the demographic\ninformation and the geographical proximity correlation respectively.\nNone of these features reported in the section were used for predicting crime\ncategories alongside crime pattern detection. In our research, we mainly focus\non the spatial aspect of crime prediction. We use geocoding technique and crime\nhotspots to generate new features.\n\n3\n\nEngineering Spatial Features\n\nGeocoding is the process of spatial representation of a location by transforming descriptive information such as coordinates, postal address, and place name.\nThe geocoding process relies on GIS and record linkage of address points, street\nnetwork and boundaries of administrative unit or region. For this work, we used\ngeocoding to extract the spatial information from the crime data. The geocoder\nlibrary written in Python, was used for geocoding services with the Open Street\nMap (OSM) provider. The output of the Geocoder package can be 108 types of\nlocation including pubs, bus stops, or hospitals from NS. According to OSM documentation, all of these types are grouped into 12 categories including amenity,\nshop, office etc. We used both types of location and category as features to\npredict crime.\n\n\fPredicting Crime Using Spatial Features\n\n3\n\nThe second type of feature used in this work was the creation of hotspots.\nHotspot analysis can emphasize the patterns of data regarding time and location\nof a geographic area. For a crime analyst, the creation of hotspots became very\npopular to identify high concentrated crime area. In this work, hotspots are\ncreated and transformed into a feature to predict different crime types. The\nidea is to cluster crime data into regions with a high rate of occurrence of the\nsame crime type. We decided to use HDBSCAN [4] because of its complexity\n(O(n logn )) and because it can handle data with variable density and eliminates\nthe \u000f (eps) parameter of DBSCAN which determines the distance threshold to\ncluster data. In this work, we used the Haversine distance in both HDBSCAN and\nshortest distance to a hotpoint. The haversine formula determines the shortest\ndistance between two points on earth located by their latitudes and longitudes.\nFigure 1 summarizes the overall process to produce the shortest distance for\nhotpoint feature. Figure 1 (a) shows crime examples (gray pins) in downtown\nHalifax area. Then, a hotspot (blue area) found by HDBSCAN is shown in Figure\n1 (b). Figure 1 (c) shows a hotpoint (red pin) extracted from a hotspot. Finally,\na new crime example (green pin) is evaluated, and the distances to hotpoints\n(yellow line) are calculated. The feature used in this work will select the shortest\ndistance to a hotpoint as a feature for classifying a crime type.\n\n4\n\nExperiments\n\nThis section outlines the experiments performed in this work and reports the experimental results obtained by the proposed classifiers trained on all raw features\nand the engineered spatial features.\nCrime data from Halifax regional police department are used in this work,\nand it covers most of the districts in Nova Scotia province in Canada. For our\nexperiments, we explore all of the offenses of 2016 which include 3726 data\nsamples. The crime attributes extracted from the source data include geographic\nlocation, incident start time, month, weekday, ucr descriptions, and whether the\nincident happened because of alcohol.\nWe also group our data using four different classes, named alcohol-related,\nassault, property damage, and motor vehicle using the ucr descriptions and alcohol incident fields. For the alcohol-related crimes, we considered all the cases\nwhere alcohol presence was reported in the UCR using the alcohol incident field\n(53% alcohol, 47% no alcohol). For all the remaining classes, the ucr description\nfield was used. The assault group (65% assault, 35% no assault) covers all levels\nof assault including sexual assault, aggravated assault, bodily harm, threat, etc.\nProperty damage group covers break, theft, robbery, etc (65% property damage,\n35% no property damage). Motor vehicle group covers all types of motor vehicle\naccident, act violation and impair driving (65% motor vehicle, 35% no motor\nvehicle).\nTo create the shortest distance to a hotpoint, we used UCR form data from\nthe year of 2015. We created hotspots for each positive class and the respective\nshortest distance to a hotpoint was used in the experiment.\n\n\f4\n\nBappee et. al. 2018\n\nFig. 1. An overview of the crime hotspots, hotpoints and distance to hotpoint feature.\n\n(a) Crime data.\n\n(b) A hotspot created by HDBSCAN.\n\n(c) A centroid computed from the\nhotspot.\n\n(d) Distance from centroid for new\ncrime data around the hotspot.\n\nThe classifiers used in this work are Logistic Regression (LR), Support Vector Machine (SVM), and Random Forest (RF) and an Ensemble with all the\nprevious classifiers. We evaluate the classifiers’ performance using the accuracy\nand Area Under the Curve (AUC) of the ROC (Receiving Operator Characteristic) analysis. The baseline used in this work to verify if the newly engineered\nfeatures help a classifier to improve the crime prediction power was the raw\ndata contained in the UCR form (incident start time, month, and weekday). A\n10-fold cross-validation was used in all phases to estimate model prediction performance correctly and paired t-tests (significance level of 0.05) were used to\ntest the statistical difference significance of raw and engineered features.\nTable 1 shows the classification accuracy for LR, SVM, RF and an ensemble of\nthese methods for all four categories of crime. For each method, the first column\ndisplays the accuracy of raw features and the second column for engineered\nspatial features. The * in Table 1 symbol indicates that the method fails for the\nstatistical hypothesis testing, i.e., the p-value is higher than 0.05.\nFor the Alcohol-related group, the results show that new spatial features\nachieve better accuracy in comparison with raw features for all four methods\nwith statistical evidence support, and the Ensemble method performs better\n\n\fPredicting Crime Using Spatial Features\n\n5\n\nthan others (75.52% of accuracy) with almost 17% accuracy improvement. The\naccuracy values of the engineered features for the Assault and Property damage groups shows that all methods, except LR, benefit from their inclusion.\nFor example, adding engineered features with raw features improves nearly 11%\n(Assault group) and 5% (Property damage group) of accuracy for RF method.\nFinally, for the Motor vehicle group, all the classifiers showed improvements,\nexcept for the Ensemble classifier.\n\nTable 1. Results for accuracy\nLR\nCrime type\n\nRF\n\nSVM\n\nEnsemble\n\nraw eng. raw eng. raw eng. raw eng.\n\nAlcohol-related\n\n59.36 65.27 57.73 73.51 59.28 71.31 58.61 75.52\n\nAssault\n\n65.35 65.03* 47.94 58.89 63.53 65.27 55.96 64.41\n\nProperty damage 88.43 88.41* 84.03 88.57 88.19 88.43 88.43 88.44*\nMotor vehicle\n\n81.59 82.31 71.82 81.45 81.11 81.45 81.56 81.80*\n\nTable 2 shows the AUC scores for LR, SVM, RF and an ensemble of LR,\nSVM & RF methods. For Alcohol-related and Motor vehicle crimes, the results\ndiscovered that spatial features give better AUC scores than raw features for\nall four methods. For instance, the Ensemble method gives 82.5% and 69.4%\nAUC score for Alcohol-related and Motor vehicle crimes respectively based on\nengineered features. Similarly, for Assault and Property damage crime, LR, RF\nand Ensemble methods perform significantly better with engineered features.\nAdding engineered features with raw features gives 56.7% and 65.7% AUC score\nfor Assault and Property damage crime respectively with the Ensemble method.\nTherefore, using spatial features, the Ensemble method performs at least 10%\nimprovement in AUC score for all four categories of crime. However, for SVM\nmethod, there is no significant evidence of improvement.\n\nTable 2. Results for AUC\nLR\nCrime type\n\nRF\n\nSVM\n\nEnsemble\n\nraw eng. raw eng. raw eng. raw eng.\n\nAlcohol-related\n\n.575 .723 .649 .818 .635 .747 .661 .825\n\nAssault\n\n.528 .613 .457 .545 .504 .533* .459 .567\n\nProperty damage .519 .651 .531 .646 .501 .505* .534 .657\nMotor vehicle\n\n.515 .686 .488 .682 .494 .536 .490 .694\n\n\f6\n\n5\n\nBappee et. al. 2018\n\nConclusions and Future Work\n\nIn this work, we explored the creation of spatial features derived from geolocated\ndata. We created two types of spatial features: (i) geocoding; and (ii) shortest\ndistance to a hotpoint. The new features were evaluated using four different\ncrime types using only the information provided in the UCR forms as features\nfor a classifier as the baseline. The results show that significant improvements in\naccuracy and AUC were found when the newly engineered features were added\nto the tested classifiers.\nWe intend to extend this work in other directions. As our study focuses on real\nworld datasets, the subject of data discrimination is another important concern.\nData discrimination refers to bias that happens because of contradistinction\namong different data sources. Another research direction we want to explore is\nthe possibility of performing transfer learning from what was learned in NS to\nother Canadian provinces.\nAcknowledgments The authors would like to thank NSERC, NS Health Authority and Injury Free Nova Scotia for financial and other supports.\n\nReferences\n1. Bromley, R.D., Nelson, A.L.: Alcohol-related crime and disorder across urban space\nand time: evidence from a british city. Geoforum 33(2), 239–254 (2002)\n2. Brower, A.M., Carroll, L.: Spatial and temporal aspects of alcohol-related crime\nin a college town. Journal of American College Health 55, 267–275 (2007)\n3. Buczak, A.L., Gifford, C.M.: Fuzzy association rule mining for community crime\npattern discovery. In: ACM SIGKDD Workshop on Intelligence and Security Informatics. pp. 2:1–2:10. ISI-KDD ’10, ACM, New York, NY, USA (2010)\n4. Campello, R.J.G.B., Moulavi, D., Sander, J.: Density-based clustering based on\nhierarchical density estimates. In: Advances in Knowledge Discovery and Data\nMining. pp. 160–172. Springer Berlin Heidelberg (2013), https://doi.org/10.\n1007/978-3-642-37456-2_14\n5. Chainey, S., Tompson, L., Uhlig, S.: The utility of hotspot mapping for predicting\nspatial patterns of crime. Security Journal 21(1), 4–28 (2008)\n6. Executive Office of the President: Big Data: A Report on Algorithmic Systems,\nOpportunity, and Civil Rights. CreateSpace Independent Publishing Platform, 2nd\nedn. (2016)\n7. Hsieh, C.C., Pugh, M.D.: Poverty, income inequality, and violent crime: A metaanalysis of recent aggregate data studies. Criminal Justice Review 18(2), 182–202\n(1993)\n8. Nakaya, T., Yano, K.: Visualising crime clusters in a space-time cube: An exploratory data-analysis approach using space-time kernel density estimation and\nscan statistics. T. GIS 14(3), 223–239 (2010)\n9. Nath, S.V.: Crime pattern detection using data mining. In: Proceedings of the 2006\nIEEE/WIC/ACM International Conference on Web Intelligence and Intelligent\nAgent Technology. pp. 41–44. WI-IATW ’06, IEEE Computer Society, Washington,\nDC, USA (2006), http://dx.doi.org/10.1109/WI-IATW.2006.55\n10. Pedreschi, D., Ruggieri, S., Turini, F.: Measuring discrimination in sociallysensitive decision records. In: Proceedings of the SIAM International Conference\non Data Mining, SDM 2009, April 30 - May 2, 2009, Sparks, Nevada, USA. pp.\n581–592 (2009)\n11. Ratcliffe, J.: The hotspot matrix: A framework for the spatio-temporal targeting\nof crime reduction. Police Practice and Research 5(1), 523 (2004)\n\n\fPredicting Crime Using Spatial Features\n\n7\n\n12. Wang, H., Kifer, D., Graif, C., Li, Z.: Crime rate inference with big data. In:\nProceedings of the 22nd ACM SIGKDD International Conference on Knowledge\nDiscovery and Data Mining, San Francisco, CA, USA, August 13-17, 2016. pp.\n635–644 (2016), http://doi.acm.org/10.1145/2939672.2939736\n13. Wang, T., Rudin, C., Wagner, D., Sevieri, R.: Learning to detect patterns of crime.\nIn: ECML/PKDD (3). Lecture Notes in Computer Science, vol. 8190, pp. 515–530.\nSpringer (2013)\n\n\f",
         "train",
         "16782",
         "2549"
        ],
        [
         "15",
         "19519",
         "cs.AI",
         "Artificial Intelligence",
         "1704.04408v1.pdf",
         "Incremental learning of high-level concepts by imitation\n\narXiv:1704.04408v1 [cs.AI] 14 Apr 2017\n\nMina Alibeigi1 , Majid Nili Ahmadabadi2 and Babak Nadjar Araabi2\n\nAbstract— Nowadays, robots become a companion in everyday life. To be well-accepted by humans, robots should\nefficiently understand meanings of their partners’ motions and\nbody language, and respond accordingly. Learning concepts by\nimitation brings them this ability in a user-friendly way.\nThis paper presents a fast and robust model for Incremental\nLearning of Concepts by Imitation (ILoCI). In ILoCI, observed\nmultimodal spatio-temporal demonstrations are incrementally\nabstracted and generalized based on both their perceptual and\nfunctional similarities during the imitation. In this method,\nperceptually similar demonstrations are abstracted by a dynamic model of mirror neuron system. An incremental method\nis proposed to learn their functional similarities through a\nlimited number of interactions with the teacher. Learning all\nconcepts together by the proposed memory rehearsal enables\nrobot to utilize the common structural relations among concepts\nwhich not only expedites the learning process especially at\nthe initial stages, but also improves the generalization ability\nand the robustness against discrepancies between observed\ndemonstrations.\nPerformance of ILoCI is assessed using standard LASA\nhandwriting benchmark data set. The results show efficiency\nof ILoCI in concept acquisition, recognition and generation in\naddition to its robustness against variability in demonstrations.\nIndex Terms— Concepts, imitation learning, humanoid\nrobots, social human-robot interaction\n\nI. INTRODUCTION\nNowadays, along with the advances in sensing and learning techniques, applications of robots have been extended\nfrom controlled to unstructured and complex environments\n[2], [3]. Company of robots in humans’ daily life have caused\nlots of difficulties in designing and programming them, since\nthey should operate in complex environments with unpredictable or time-varying dynamics and interact with humans\n[2], [3], [4]. Moreover, ordinary users generally do not have\nenough expertise to program robots for new tasks [2], [3]. In\naddition, to gain acceptance as an intelligent companion in\nour everyday life, robots should be sociable. They should\nunderstand the meanings of their partners’ motions and\nbody language, and respond accordingly. These requirements\nand limitations specify the necessity of developing socially\ninteractive learning methods for robots to enable them to\n1 Mina Alibeigi is with Cognitive Systems Lab., School of\nElectrical and Computer Engineering, College of Engineering,\nUniversity of Tehran, Tehran, Iran minaalibeigi@gmail.com;\n\nm.alibeigi@ut.ac.ir\n2 Majid Nili Ahmadabadi and Babak Nadjar Araabi are with Cognitive\nSystems Lab., Control and Intelligent Processing Center of Excellence,\nSchool of Electrical and Computer Engineering, College of Engineering,\nUniversity of Tehran, Tehran, Iran. They are also with School of Cognitive\nSciences, Institute for Research in Fundamental Sciences (IPM), Tehran,\nIran {mnili, araabi}@ut.ac.ir\n∗ The elaborate version of this paper is available at [1].\n\neffectively cope with new environments and tasks instead of\nbeing manually pre-programmed [2], [3], [4].\nInspiring by the efficient social learning methods in animals and humans (e.g. mimicry, emulation and goal emulation), researchers proposed natural and user-friendly ways\nto teach robots, which is called robot programming by\ndemonstration or imitation learning [2], [3], [4]. Although all\nthe social learning methods from the high-level knowledge\ntransfer to the low-level exact regeneration of observed\ndemonstrations are mistakenly known as imitation, but there\nare stark differences between them [3], [4], [5]. In the highlevel methods, in contrast to the low-level ones, understanding the teacher’s intentions along with regenerating actions\nare required [3], [4], [5]. In this level, also called ”true\nimitation”, skills are abstracted in a generalized symbolic\nrepresentation. Abstraction, conceptualization and symbolization are bases of true imitation. They bring decreased\nstate-space as one of the requirements of real applications\nin addition to expediting the knowledge transfer from one\nagent or situation to another [3], [6], [5], [7], [8].\nIn recent years, abstraction and symbolization have received a great deal of attention by researchers in the field of\nimitation learning [6], [7], [8], [9], [10], [11]. A considerable\nportion of the proposed methods inspired by the presumed\nrole of mirror neurons in imitative behaviors of animals and\nhumans [6], [7], [9], [10]. Tani et al. [9], [10], [12] proposed\nan offline bio-inspired method called recurrent neural networks with parametric biases (RNNPB), as a model of mirror\nneuron system. In this model, the observed spatio-temporal\ndemonstrations are learned and abstracted by the network\nbased on their perceptual properties. Moreover, Inamura et al.\n[7] proposed another bio-inspired imitation learning method\ninspiring the mirror neurons and mimesis theory [13]. In\nthis model, hidden markov models (HMMs) are used for\nabstracting and symbolizing the observed human motions\nas well as for recognizing and generating them. Demonstrations of different motion patterns are manually grouped\nand encoded into distinct HMMs in an offline manner. The\nnumber of HMMs representing different behaviors should be\nknown a priori; which is not suitable for real applications.\nMoreover, the method is not incremental, meaning that it\ndoes not give robot the ability to learn concepts gradually\nand autonomously in cooperation with the partners in order\nto keep itself socially competent.\nConsidering these shortcomings into account, some methods were proposed for incremental learning of human motions [8], [11]. One of the prominent representative algorithms is proposed by Kadone and Nakamura [8]. This\nmodel affords autonomous segmentation, abstraction, mem-\n\n\forization and recognition of demonstrated motions using\nassociative neural networks. Kulic et al. [11] proposed\nanother well-known incremental and autonomous imitation\nlearning method for acquisition, symbolization, recognition\nand hierarchical organization of whole body motion patterns\nusing Factorial HMMs.\nAlthough, in all the mentioned studies [7], [8], [9], [10],\n[11], [12], only the perceptual similarity among observed\ndemonstrations are addressed for abstraction and symbolization, but there are some perceptually different concepts that\nhave the same functional effects or semantic meanings, called\nrelational concepts [6], [14], [15], [16]. These concepts cannot be specified merely based on their perceptual properties\nand an extra information is needed to acquire them [6], [14],\n[15], [16]. They are highly prevalence in humans’ social\ninteractions and their everyday life; for instance, disparate\ngestures to convey the meaning of ”Hello” in different\ncultures. Therefore, functional categorization of observed\ndemonstrations is also indispensable for robots coexisting\nwith humans. However, despite the prevalence of relational\nconcepts, not enough researches carried out in this field.\nTo the best of our knowledge, only a limited number of\nresearches has been proposed for learning and abstracting\nconcepts based on both their perceptual and functional\nproperties [6], [14], [16], [17]. One of the basic models is\nproposed by Mobahi et al. [16]. The model is just applicable\nfor learning concepts from single observations, and is not\ndirectly extendible to continuous sequences of observations.\nIn contrast, the proposed methods by Hajmirsadeghi et al.\n[6], [17] are applicable for learning concepts from spatiotemporal motion sequences using both perceptual and functional properties. In these models, each relational concept\nis represented by a group of distinct HMM prototypes that\neach symbolize a different perceptual variant of that concept.\nSeparated modeling of prototypes in these models [6], [17],\nleads to neglecting their common structural relations and\nconsequently each prototype should relearn the common\nknowledge again. Therefore, the learning speed decreases\nand more observations are needed for generalization. This is\nin contradiction to the main idea of the imitation learning\nthat supports expediting the autonomous training of robots\nusing the minimum number of demonstrations.\nConsidering the mentioned requirements and limitations,\nthis paper presents a gradual and incremental learning algorithm to abstract and generalize the observed multimodal\nspatio-temporal demonstrations based on both their perceptual and functional characteristics during the imitation.\nThe proposed method comprises low-level and high-level\nmodules. The low-level module abstracts the observed spatiotemporal demonstrations based on their perceptual properties\nusing an RNNPB network [9], [10], [12]. The high-level\nmodule acquires relational concepts based on the formed\nperceptual prototypes and the perceived teacher’s feedbacks.\nThe proposed memory rehearsal procedure enables the robot\nto gradually extract and utilize the common structural relations among concepts. Therefore, the learning process is\nexpedited especially at the initial stages and the generaliza-\n\nTABLE I\nD EFINITION OF S OME S YMBOLS\nName\n\nMem\n\nConstituents\n\nType\n\nnPrototypes\n\nInt\n\nTrajectoryNet\n\nNetwork\n\nPBs\n\nSet\n\nPBs rec\n\nSet\n\nnumSamples\n\nSet\n\nnumSteps\n\nSet\n\ninitialInfo\n\nSet\n\nconceptLabels\n\nSet\n\ngenerationError\n\nSet\n\nDescription\nNumber of all consolidated exemplars and prototypes in Mem.\nThe RNNPB that abstracts and symbolizes the\nconsolidated exemplars and prototypes.\nPB vectors assigned to the learned demonstrations\nby TrajectoryNet.\nPB vectors generated by TrajectoryNet when recognizing each learned demonstration.\nNumber of sufficiently similar observed demonstrations associated to each consolidated exemplar\nor prototype in Mem.\nNumber of time steps of each consolidated\ndemonstrations in Mem.\nInitial configuration of each consolidated demonstration in Mem.\nConcept label assigned to each of the consolidated demonstrations in Mem.\nError of regenerating each consolidated demonstration in Mem.\n\nFig. 1. Mem and consolidated exemplars and prototypes. Filled shapes\nshow prototypes and unfilled shapes depict demonstrations and exemplars.\n\ntion capability is improved as well as the robustness against\nnoise and variations among observed demonstrations.\nII. IL O CI: T HE PROPOSED METHOD FOR I NCREMENTAL\nL EARNING OF C ONCEPTS BY I MITATION\nIn a nutshell, ILoCI has a low-level and a high-level\nmodule. The low-level module of ILoCI is a dynamic model\nof mirror neuron systems, called RNNPB, which abstracts\nthe observed multimodal spatio-temporal demonstrations as\nperceptual concepts. For more details on RNNPB refer to\n[9], [10], [12]. It automatically assigns a PB vector to\neach acquired perceptual prototype. The acquired PB vectors\ncan be exemplars or prototypes based on their associated\ninformation in the high-level module. An exemplar PB vector\nstands for only one demonstration and a prototype PB vector\nis the medoid of demonstrations with sufficient perceptual\nsimilarity. All the exemplar and prototype PB vectors along\nwith their associated information are stored in a memory\nin the high-level module, called ”Mem” (see Table I). A\nrelational concept is defined as a set of perceptually variant\nexemplars and prototypes in the memory that have same\nfunctional properties. The high-level module learns the relational concepts by employing the low-level module and\nthe acquired teacher’s feedbacks through interactions. Fig. 1\nillustrates the relations among exemplars, prototypes and\nconcepts. In the sequel, ILoCI is explained in more details.\n\n\fA. Learning Phase\nThe main procedure of ILoCI is an iterative cycle triggered by the advent of a new teacher’s demonstration. After\nperceiving a new demonstration, the smoothing, scaling and\nfitting post-processes are activated consecutively. Then, the\nprocessed demonstration is fed into the inverse kinematics\nfunction to compute its corresponding motor data. Afterwards, the obtained sensory and motor data are input into the\nlow-level module to recognize the corresponding concept.\nAfter recognizing the concept, the robot performs an\naction in response to the teacher and receives a reinforcement\nsignal accordingly. Receiving a reward, the robot uses the\nobserved demonstration to update or develop its memory.\nIn contrast, in the case of punishment, robot tries other\navailable concepts until receiving a reward. If none of the\nformer concepts in the robot’s memory are proper for the\nnew demonstration, a new concept will be generated and\nconsolidated in memory. In this way, the robot gradually and\nincrementally learns and develops the relational concepts in\nimitation of the teacher to increase its lifetime rewards. In\nfollowing, steps are described in more details.\n1) Perceiving new demonstration: At first an observation\nfrom the teacher goes through pre-processing. Details are\ndescribed in Section III. After preparing the observed motion\nsequence, the robot tries to find its associated concept. To do\nso, the observed motion sequence in terms of sensory and\nmotor data, is fed into Mem.TrajectoryNet and the value of\nPBobs is computed for it by back propagating and minimizing\nthe error between the target and the predicted values of\nsensory and motor data. Afterwards, in order to find the most\nsimilar consolidated PBs rec in memory, the computed value\nof PBobs is compared with the untried associated PBs rec\nvalues of the consolidated concepts in memory.\nThe concept of the most similar consolidated exemplar or\nprototype is selected as the guessed concept of the novel\nobserved demonstration (CLobs ) and is added to the set of\nthe currently tried concepts (Qtried ). Then, in response to\nthe teacher, the robot executes the action with the lowest\ngeneration error among the actions with CLobs concept in its\nmemory. After performing the selected action, robot receives\na feedback (reward or punishment) from the teacher, which\nhelps it to adjust its concepts. According to the received\nreinforcement signal, robot faces three situations:\nReceiving positive reinforcement signal with high similarity between the compared PB vectors: A positive feedback shows that the robot has found the concept of the\nnewly observed demonstration correctly. Moreover, it is an\nevidence of a highly similar exemplar or prototype for the\nthat demonstration in the robot’s memory and fulfills the\nneed of relearning. Therefore, the most similar consolidated\ndemonstration in the robot’s memory is strengthened as a\npotential candidate for the new observed demonstration.\nReceiving positive reinforcement signal with low similarity\nbetween the compared PB vectors: In this case, CLobs has\nbeen found correctly but there is no enough perceptually\nsimilar exemplar or prototype for that demonstration in the\nmemory. Therefore, the robot should learn a new prototype\n\nFig. 2. An illustration for the clustering process of the triangle concept, (a)\nnew demonstration is observed and consolidated in the memory as a new\nperceptual representation of the triangle concept, (b) clustering is performed\nand valid clusters are determined based on the validity criteria, (c) the\nmedoid of the exemplars and prototypes in the valid cluster is substituted\nfor other members through memory rehearsal.\n\nfor that relational concept in its memory and consolidate it\nthrough memory rehearsal. After a while, memory may be\noverpopulated with perceptually similar exemplars and prototypes. Therefore, these demonstrations should be abstracted\nand clustered in order to select the best representatives of\ntheir counterpart clusters. Thus, a complete link hierarchical\nagglomerative clustering is called when a new exemplar of a\nconcept is added to the memory while the number of samples\nof both prototypes and exemplars of that concept exceeds\nNumthreshold . Afterwards, final valid clusters are selected\nbased on two criteria. First, the number of demonstrations\nshould exceed a predefined threshold with at least one\nexemplar in the cluster. Second, the mean of the pairwise\nEuclidean distances among PB vectors within the cluster\nshould be less than Dcuto f f (1). This threshold is computed\nbased on the mean (µ) and the standard deviation (σ ) of the\npairwise Euclidean distances across all vectors in the clusters\nof the desired concept.\nDcuto f f = µ − Kcuto f f ∗ σ\n\n(1)\n\nIn (1), Kcuto f f is a predefined parameter that controls\nthe granularity level of the algorithm. Higher values of\nKcuto f f lead to more number of specific prototypes; while\nlower values bring more general prototypes. However, all\nvariant perceptual prototypes of a concept will be generalized as one relational concept in the high-level module.\nIn our experiments, this parameter is set to an equitable\nvalue selected based on some prior knowledge and trial\nand errors. However, it could be set to a desired value to\nsatisfy the requirements of the application. Fig. 2 illustrates\nthe clustering process when a new demonstration of triangle\nconcept is added to the memory.\nReceiving negative reinforcement signal: In the case of\nreceiving a negative signal, the robot uses its next most\nsimilar untried concept (i.e the one not in Qtried ), until it\nreceives a positive feedback. If the robot uses all its learned\nconcepts without receiving a positive feedback, then the new\nobserved demonstration will be learned as a novel exemplar\nof a new concept using memory rehearsal.\n\n\f2) No other untried concept exists in the robot’s memory:\nThis situation means that none of the former tried concepts\nin the robot’s memory were proper for the novel demonstration; therefore, a new concept is generated and the new\ndemonstration is consolidated in the robot’s memory as an\nexemplar of that concept through memory rehearsal.\n3) Memory rehearsal: Memory rehearsal is performed to\nlearn a novel demonstration of a new concept, or to form a\nnovel prototype for an earlier learned concept. Learning new\ndemonstrations faces memory interference which damages\npreviously learned patterns in the memory. This is due to\nthe distributed representation of all patterns in a single\nnetwork (various patterns share the same synaptic weights\nin the network). Despite its numerous advantages, memory\ninterference is one of the challenges of employing distributed\nrepresentation scheme to abstract patterns. To overcome\nthis difficulty, rehearsing and consolidation according to a\nbiological hypothesis is employed [18].\nIn the memory rehearsal, previous consolidated prototypes and exemplars in Mem are first regenerated using\nMem.TrajectoryNet as a long-term memory. To do this,\nthe values of PB neurons and initial input neurons in the\nnetwork’s input layer are set to the associated values of\nthe consolidated prototypes or exemplars in Mem. Then,\nthe corresponding patterns are regenerated. The regenerated\npatterns are temporarily stored in a temporal storage called\ntemporal memory. New demonstration is also added to the\ntemporal memory. Next, Mem.TrajectoryNet is trained with\nall the patterns in the temporal memory, starting from the\nprevious network in order to speed up the network’s training\nprocess. After that, Mem is updated based on the new trained\nMem.TrajectoryNet and the prior associated information of\npatterns in temporal memory (e.g. nPrototypes, numSamples,\nnumSteps, initalInfo and conceptLables). Finally, the temporal memory is released.\nLike infants in their early years of life, a naı̈ve robot\nshould spend considerable time for learning a sufficient\nnumber of patterns through rehearsing and consolidation.\nIn this step, more interactions with teacher are needed to\nlearn concepts during imitation. However, as time passes,\nthe robot has a variety of previously learned concepts in its\nmemory and consequently it responds to the teacher more\nappropriately with less interactions. But, it is clear that by\nobserving a new concept, the robot should spend time to\nrehearse and consolidate it. This is similar to the costs and\npractices that humans experience to learn a new skill.\nB. Inference Phase\nIn an incremental method, the learning process never\nstops. However, to assess the performance of ILoCI, an\ninference phase is designed. In this phase, no further feedbacks are provided by the teacher. When observing a new\ndemonstration, the robot uses its current acquired knowledge\nduring the learning phase to recognize the concept of the\nnew demonstration. PBobs is computed and its value is\ncompared with the values of consolidated PBs rec vectors\nin the memory. The concept of the most similar vector is\n\nconsidered as the concept of the demonstration and a proper\naction is responded to the teacher.\nIII. R ESULTS AND D ISCUSSION\nTo assess the generalization ability of ILoCI in facing large\nnumber of concepts and to make it directly comparable with\nother competing algorithms, its performance is evaluated on a\nstandard benchmark data set, called LASA [19], [20]. LASA\nconsists of 26 various handwriting motions, collected from\npen input using a tablet PC [19], [20] (supplementary data).\nAll motion shapes constitute 22 distinct relational concepts\ntogether in total. It is worthy to note that the shapes are\nincrementally and gradually demonstrated to the robot to\nlearn their relational concepts while imitating and interacting\nwith the teacher.\nTo recognize and generate the observed demonstrations\nin future, the robot needs to learn the motor data along\nwith the associated observed sensory information. Thereby,\nthe observed teacher’s handwriting motion is scaled and\nfitted in a selected y-z plane in the robot’s workspace.\nThe selected workspace, depicted as a supplementary figure,\nassures the feasibility of executing the action by robot\nconsidering its physical limitations and valid workspace [21].\nOur test platform is the Aldebaran Roboticsr Nao humanoid\nrobot version V3.2 [22]. After scaling and fitting processes,\nthe joint angles of Nao’s right arm will be obtained by\napplying the built-in inverse kinematics module (IK) on the\nprocessed demonstration. To make the results invariant to\nthe possible translational and rotational transformations, the\nrelative displacement values of sensory and motor data are\nused instead of their absolute values as the inputs to the\nlearning algorithm.\nFive-fold cross-validation is used to examine the performance of the proposed algorithm. Each fold consists of\ndifferent combinations of demonstrations for training and\ntesting. Variant perceptual representations of each shape are\nrandomly divided to five partitions and each of the partitions\nis used once as training and four times as testing data set.\nThe ideal situation for the robot is to learn the concepts\nfast while observing only a few numbers of demonstrations\nand acquiring more comprehensive prototypes. Thus, only\n20% of the demonstrations are used for training and the\nremaining 80% are used for testing in each fold. In the\nexperiment, Mem.TrajectoryNet has 6 input/output nodes, 4\nPB neurons, 25 context and 60 hidden neurons. Moreover,\nKcuto f f , Numthreshold and Similaritythreshold are set to 0.5, 3\nand 0.1 values, respectively.\nThe average correct classification rate over all five folds\nis 91.346 ± 3.511 during the inference phase. Table II\npresents the sparse representation of the average normalized\nconfusion and confidence matrices. The full representation\nof these matrices are available as supplementary data. True\npositive values in Table II show that the robot can correctly\nrecognize demonstrations of each relational concept with\nhigh confidence values. Although, some motion shapes in\nLASA data set have considerable degree of similarity with\neach other, but the algorithm can discriminate them properly.\n\n\fTABLE II\nS PARSE REPRESENTATION OF THE AVERAGE NORMALIZED CONFUSION\nMATRIX AND THE CORRESPONDING AVERAGE CONFIDENCE VALUES ON\n\nLASA HANDWRITING DATA SET OVER 5- FOLD CROSS - VALIDATION .\nB OLD TEXTS INDICATE TRUE POSITIVE VALUES .\n\nAngle\nBendedLine\nCShape\n\nActual Concept\n\nGShape\nJShape\nKhamesh\nLShape\nLeaf\nLine\nNShape\nPshape\nRShape\nSaeghe\nSine\nSnake\nSpoon\nSshape\nTrapezoid\nWShape\nWorm\nZShape\nHeee\n\nPredicted Concept:(Normalized Confusion, Confidence)\nAngle: (66.67, 1.71), Line: (3.33, 0.01), NShape: (13.33, 0.15),\nTrapezoid: (10, 0.12), Worm: (6.67, 0.07)\nBendedLine: (100, 9.12)\nCShape: (96.67, 7.08), Sshape: (3.33, 0.01)\nGShape: (80, 2.98), CShape: (6.67, 0.13), Sshape: (10, 0.04),\nWorm: (3.33, 0.06)\nJShape: (100, 7.99)\nKhamesh: (100, 4.31)\nLShape: (96.67, 2.51, Heee: (3.33, 0.04)\nLeaf: (91.67, 6.52), JShape: (1.66, 0.13), Snake: (6.67, 0.12)\nLine: (86.67, 3.13), Saeghe: (13.33, 0.21)\nNShape: (60, 1.65), Angle: (6.67, 0.07), Worm: (33.33, 0.68)\nPShape: (96.67, 2.87), Trapezoid: (3.33, 0.02)\nRShape: (100, 4.05)\nSaeghe: (80, 3.32), Line: (20, 0.53)\nSine: (100, 3.69)\nSnake: (100, 4.34)\nSpoon: (95, 3.54), Heee: (5, 0.04)\nSshape: (90, 2.96), GShape: (10, 0.03)\nTrapezoid: (100, 3.88)\nWShape: (95, 3.20), Khamesh: (5, 0.03)\nWorm: (86.67, 2.61), NShape: (13.33, 0.49)\nZShape: (100, 3.56)\nHeee: (65, 2.02), LShape: (10, 0.10), Spoon: (3.33, 0.15),\nZShape: (21.67, 0.21)\n\nThese similarities also explain the false negative values for\nsome shapes like Line and Saeghe as well as Angle, NShape\nand Worm. However, the low confidence values for the false\nnegatives indicate that the algorithm is unsure about these\nresults. This ability to properly judge its outcomes brings\nthe metacognition property to the robot.\nMoreover, to assess the learning speed and the interaction\nquality of the proposed algorithm, the reinforcement signals\ngiven by the teacher during the learning phase is investigated.\nFig. 3 shows the average reinforcement signals (over five\nfolds) given by the teacher. Because of the discrete nature\nof the reinforcement signals (+1 for reward and -1 for\npunishment), the results in Fig. 3 has been smoothed with a\nbackward moving average with window length of seven to\nreflect the expected behavior clearly. Results show that robot\nis capable of learning the relational concepts of the observed\ndemonstrations very fast especially at the initial stages of\nlearning. According to Fig. 3, in 85% (in average) of the\nexperiments, the robot has correctly recognized the relational\nconcepts in the first interaction after merely learning 45\ndemonstrations (25% of the data). Two specific reasons\ncan be cited for this notable property. First, when a new\ndemonstration with a novel relational concept is observed, it\nwill be consolidated and probably updated later in the memory as a representative of the perceived relational concept.\nConsequently, the robot has at least one representation for\neach relational concept in the memory due to the functional\nabstraction. Therefore, it can recognize new demonstrations\nquickly using prototypes in its memory without relearning\n\nFig. 3. Smoothed average reinforcement signal issued by the teacher during\nthe learning phase in the experimental scenario on LASA data set.\n\nthem from scratch. Second, all consolidated exemplars and\nprototypes are stored in one memory (distributed representation) through memory rehearsal which brings about the\nutilization of their common structural relations in order to\nexpedite and enhance the learning process.\nFurthermore, ILoCI unites all different perceptual prototypes of each relational concept in the high-level module\nbased on the teachers’ feedbacks. Fig. 4 shows the symbol\nspace (PB space) of the acquired perceptual prototypes in\nthe fifth fold using non-metric multidimensional scaling\n(MDS). The figure shows the 2D visualization of the acquired\n4D PB vectors. In Fig. 4, all PB vectors associating with\ndifferent perceptual prototypes of one relational concept are\nrepresented with same markers, which shows their unity as\none relational concept (e.g. both acquired perceptual prototypes of BendedLine are shown with blue square markers).\nThe results also show that ILoCI almost finds the same\nnumber of perceptual prototypes for each relational concept\nas the number of their real perceptual variants. However,\ntwo different perceptual prototypes are acquired here for\nLShape which has only one distinct perceptual representation\nsince the teachers can draw shapes freely. So, the observed\ndemonstrations might vary and consequently two different\nperceptual prototypes are formed for LShape. However, it is\nnotable that all variant perceptual prototypes of each relational concept are unified in the high-level module through\nthe functional abstraction.\nIn addition, the proposed algorithm generates smooth\nand comprehensive prototypes for each relational concept,\ndespite the discrepancies in the observed demonstrations,\nwithout any smoothing post-processing. Fig. 5 shows one\nregenerated example for each acquired relational concept\nby the robot. The smoothness of the generated prototypes\nsupports the generalization ability of the algorithm. The\nsupplementary videos show the execution of some presented\nmotions by Nao humanoid robot.\nIV. CONCLUSIONS\nThis paper introduced an incremental and gradual model\nfor learning concepts by imitation as one of the manifesta-\n\n\fR EFERENCES\n\nFig. 4. 2D visualization of the PB space of the consolidated perceptual\nprototypes in the fifth fold.\n\nFig. 5. Regenerated samples for each relational concept in the fifth fold.\nThe red circles show the starting points.\n\ntions of true imitation learning. The presented algorithm autonomously and incrementally learns concepts from observed\nmultimodal spatio-temporal demonstrations, based on both\ntheir perceptual and functional properties during imitation. It\nabstracts demonstrations both at the trajectory and the symbolic levels, which is a significant challenge in integrating the\nsymbolic AI and the continuous control of robots [3]. In this\nmethod, all perceptual concepts are incrementally learned\nin a single recurrent neural network through the proposed\nmemory rehearsal. Functional similarities between concepts\nare also acquired through a limited number of interactions\nwith the teacher. Incremental learning of acquired concepts\ntogether through memory rehearsal enables robot to utilize\nthe common structural relations among demonstrations. Consequently the learning process is expedited especially at the\ninitial stages and the generalization ability of the algorithm\nis also increased.\nThe performance of the proposed method was assessed\nusing standard LASA benchmark data set [19], [20]. Results\nshow that due to abstraction and generalization in both perceptual and functional spaces, robot acquires comprehensive\nprototypes and therefore it can truly recognize concepts of\nobserved demonstrations during the imitation. The mentioned\nproperties make the proposed method a good choice for\nreal-world applications in which robots should comprehend\nintentions of their partners while interacting with them.\nV. S UPPLEMENTARY M ATERIAL\nThe supplementary material is available at https://\ngoo.gl/ojowSx.\n\n[1] M. Alibeigi, M. N. Ahmadabadi, and B. N. Araabi, “A fast, robust,\nand incremental model for learning high-level concepts from human\nmotions by imitation,” IEEE Transactions on Robotics, vol. 33, no. 1,\npp. 153–168, 2017.\n[2] C. C. Kemp, A. Edsinger, and E. Torres-Jara, “Challenges for robot\nmanipulation in human environments,” IEEE Robotics and Automation\nMagazine, vol. 14, no. 1, p. 20, 2007.\n[3] A. Billard, S. Calinon, R. Dillmann, and S. Schaal, “Handbook of\nrobotics chapter 59: Robot programming by demonstration,” Handbook of Robotics. Springer, 2008.\n[4] M. Lopes, F. Melo, L. Montesano, and J. Santos-Victor, “Abstraction\nlevels for robotic imitation: Overview and computational approaches,”\nin From Motor Learning to Interaction Learning in Robots, pp. 313–\n355, Springer, 2010.\n[5] J. Call and M. Carpenter, “Three sources of information in social\nlearning,” Imitation in animals and artifacts, pp. 211–228, 2002.\n[6] H. Hajimirsadeghi, M. N. Ahmadabadi, and B. N. Araabi, “Conceptual\nimitation learning based on perceptual and functional characteristics\nof action,” IEEE Transactions on Autonomous Mental Development,\nvol. 5, no. 4, pp. 311–325, 2013.\n[7] T. Inamura, I. Toshima, H. Tanie, and Y. Nakamura, “Embodied symbol emergence based on mimesis theory,” The International Journal\nof Robotics Research, vol. 23, no. 4-5, pp. 363–377, 2004.\n[8] H. Kadone and Y. Nakamura, “Segmentation, memorization, recognition and abstraction of humanoid motions based on correlations and\nassociative memory,” in 2006 6th IEEE-RAS International Conference\non Humanoid Robots, pp. 1–6, IEEE, 2006.\n[9] J. Tani, M. Ito, and Y. Sugita, “Self-organization of distributedly\nrepresented multiple behavior schemata in a mirror system: reviews\nof robot experiments using rnnpb,” Neural Networks, vol. 17, no. 8,\npp. 1273–1289, 2004.\n[10] M. Ito and J. Tani, “On-line imitative interaction with a humanoid\nrobot using a dynamic neural network model of a mirror system,”\nAdaptive Behavior, vol. 12, no. 2, pp. 93–115, 2004.\n[11] D. Kulić, W. Takano, and Y. Nakamura, “Incremental learning, clustering and hierarchy formation of whole body motion patterns using\nadaptive hidden markov chains,” The International Journal of Robotics\nResearch, vol. 27, no. 7, pp. 761–784, 2008.\n[12] J. Tani and M. Ito, “Interacting with neurocognitive robots: A dynamical system view,” in Proc. 2nd int. workshop on man-machine\nsymbiotic systems, kyoto, japan, pp. 123–134, 2005.\n[13] M. Donald, Origins of the modern mind: Three stages in the evolution\nof culture and cognition. Harvard University Press, 1991.\n[14] M. Mahmoodian, H. Moradi, M. N. Ahmadabadi, and B. N. Araabi,\n“Hierarchical concept learning based on functional similarity of actions,” in Robotics and Mechatronics (ICRoM), 2013 First RSI/ISM\nInternational Conference on, pp. 1–6, IEEE, 2013.\n[15] T. R. Zentall, M. Galizio, and T. S. Critchfield, “Categorization,\nconcept learning, and behavior analysis: An introduction,” Journal of\nthe experimental analysis of behavior, vol. 78, no. 3, pp. 237–248,\n2002.\n[16] H. Mobahi, M. N. Ahmadabadi, and B. Nadjar Araabi, “A biologically inspired method for conceptual imitation using reinforcement\nlearning,” Applied Artificial Intelligence, vol. 21, no. 3, pp. 155–183,\n2007.\n[17] H. Hajimirsadeghi, “Conceptual imitation learning based on functional\neffects of action,” in EUROCON-International Conference on Computer as a Tool (EUROCON), 2011 IEEE, pp. 1–6, IEEE, 2011.\n[18] L. R. Squire, N. J. Cohen, and L. Nadel, “The medial temporal region\nand memory consolidation: A new hypothesis,” Memory consolidation:\nPsychobiology of cognition, pp. 185–210, 1984.\n[19] S. M. Khansari-Zadeh and A. Billard, “Learning stable nonlinear\ndynamical systems with gaussian mixture models,” IEEE Transactions\non Robotics, vol. 27, no. 5, pp. 943–957, 2011.\n[20] A. Lemme, Y. Meirovitch, M. Khansari-Zadeh, T. Flash, A. Billard,\nand J. J. Steil, “Open-source benchmarking for learned reaching motion generation in robotics,” Paladyn, Journal of Behavioral Robotics,\nvol. 6, no. 1, 2015.\n[21] M. Alibeigi, S. Rabiee, and M. N. Ahmadabadi, “Inverse kinematics\nbased human mimicking system using skeletal tracking technology,”\nJournal of Intelligent & Robotic Systems, pp. 1–19, 2016.\n[22] “Nao humanoid robot.” https://www.aldebaran.com/en,\n2016.\n\n\f",
         "train",
         "35474",
         "5251"
        ],
        [
         "16",
         "17257",
         "cs.AI",
         "Artificial Intelligence",
         "1709.04909v1.pdf",
         "arXiv:1709.04909v1 [cs.LG] 14 Sep 2017\n\nShared Learning: Enhancing Reinforcement in Q-Ensembles\nRakesh R Menon\n\nBalaraman Ravindran\n\nCollege of Information and Computer Sciences\nUniversity of Massachusetts Amherst\nrrmenon@cs.umass.edu\n\nDepartment of Computer Science and Engineering\nRobert Bosch Centre for Data Science and AI\nIndian Institute of Technology Madras\nravi@cse.iitm.ac.in\n\nAbstract\nDeep Reinforcement Learning has been able to achieve amazing successes in a variety of domains from video games to\ncontinuous control by trying to maximize the cumulative reward. However, most of these successes rely on algorithms\nthat require a large amount of data to train in order to obtain results on par with human-level performance. This is\nnot feasible if we are to deploy these systems on real world\ntasks and hence there has been an increased thrust in exploring data efficient algorithms. To this end, we propose the\nShared Learning framework aimed at making Q-ensemble algorithms data-efficient. For achieving this, we look into some\nprinciples of transfer learning which aim to study the benefits of information exchange across tasks in reinforcement\nlearning and adapt transfer to learning our value function estimates in a novel manner. In this paper, we consider the special case of transfer between the value function estimates in\nthe Q-ensemble architecture of BootstrappedDQN. We further empirically demonstrate how our proposed framework\ncan help in speeding up the learning process in Q-ensembles\nwith minimum computational overhead on a suite of Atari\n2600 Games.\n\nIntroduction\nReinforcement Learning (RL) deals with learning how to\nact in an environment by trying to maximize the cumulative payoff (Sutton and Barto 1998). However, the early\napproaches in RL did not scale well to environments with\nlarge state spaces. Recently, Deep Reinforcement Learning\n(DRL) has gained a great deal of interest because of its ability to map high-dimensional observations to actions using\na neural network function approximator (Mnih et al. 2015;\nWang et al. 2016; Schaul et al. 2015; Mnih et al. 2016).\nWith the development of many algorithms, researchers have\nbeen able to show the effectiveness of deep reinforcement\nlearning in trying to solve problems in complex domains.\nHowever, most of these architectures require a large amount\nof training data in order get near human-level performance.\nThis problem of data inefficiency has been well established\npreviously in (Lake et al. 2016).\nPrior attempts at improving data efficiency in reinforcement learning, involved the use of an Experience\nReplay mechanism (Lin 1992) which allowed the agent\nto replay trajectories from a memory buffer to learn more\n\neffectively from each sample trajectory. This idea was first\nintroduced in deep Q-learning by (Mnih et al. 2015). Later,\n(Wang et al. 2017) was able to use the idea of Experience\nReplay to create a sample efficient actor-critic along with\nsome other modifications. Hindsight Experience Replay\n(Andrychowicz et al. 2017) tries to add samples to the\nreplay memory which help the agent to learn about both\nthe desired and undesired states in the environment more\nefficiently. Another line of work involves auxiliary tasks\nthat learn how to control the environment on the high\ndimensional visual observations (Jaderberg et al. 2017;\nLample and Singh Chaplot 2016). More recently, combining model-based methods and model-free methods have\nbeen shown to be make learning data-efficient (Weber\net al. 2017). We aim to develop an agent that can learn\nmore efficiently from each sample in the Experience Replay.\nThe framework we propose builds upon some ideas\nfrom transfer in reinforcement learning literature (Taylor\nand Stone 2009). In particular, we have focused on transfer\nthrough action advice (Taylor et al. 2014) to perform online\ntransfer. While online transfer has been done before in\n(Zhan and Taylor 2015), our framework differs from this\nalgorithm in the sense that the action advice happens while\nlearning from samples collected in the Experience Replay.\nA Q-ensemble is an suitable architecture to perform online\ntransfer since we can take advantage of the independent\nvalue function estimates within the architecture. The\nBootstrappedDQN architecture (Osband et al. 2016) is an\nexample of one such Q-ensemble algorithm that learns to\nexplore complex environments more efficiently by planning\nover several timesteps. Experimentally, BootstrappedDQN was shown to perform better than Double DQN\n(Van Hasselt, Guez, and Silver 2016) on most Atari 2600\ngames. (Chen et al. 2017) proposed 3 algorithms, Ensemble\nVoting, UCB exploration and UCB+InfoGain exploration,\ninspired by concepts from bayesian reinforcement learning\nand bandit algorithms. These algorithms were shown to\nperform better than BootstrappedDQN and Double DQN\non many Atari 2600 games. In this paper, we present a new\nframework, Shared Learning, that learns to share knowledge\nbetween the value function estimates of BootstrappedDQN\nand Ensemble Voting which allows for data-efficiency and\nthen show how our framework can be extended to any\n\n\fQ-ensemble algorithm.\n\nrepresentation of the value function.\n\nThe rest of the paper is structured as follows: we will\nlook at some related works in data-efficient reinforcement\nlearning, Q-ensembles and transfer learning. Following\nwhich we touch upon some necessary background before\nmoving on to the main section on Shared Learning. We first\nmotivate and analyze how our framework helps through\ntoy Markov Decision Process(MDP) chains. Further, we go\non to show the efficacy of our proposed framework on the\nArcade Learning Environment (Bellemare et al. 2013) Atari\n2600 games.\n\nModel-based methods are known to be one of the best\nmethods for data-efficient learning because such algorithms\ncan perform planning. However, such algorithms are\nhinged on the fact that they have access to a model of the\nenvironment. This is not such an easy task in the case of\ndeep reinforcement learning. (Weber et al. 2017) has been\nable to achieve some success by combining model-based\nand model-free methods to get a data-efficient learning\nalgorithm. Their algorithm makes use of an imperfect model\nof the environment to create imagination-based trajectories\nand the final policy and value function are provided as\na combination of the model-based and the model-free\nalgorithm.\n\nRelated Work\nData Efficiency\nWith the evolution of deep learning and RL, many algorithms were developed which could solve many complex\nproblems in domains like robotics and games. However,\nmost of these algorithms suffer from some fundamental\nissues that were highlighted in (Lake et al. 2016). Some\nof these fundamental issues include data inefficiency,\nbrittle nature of learned policies and the inability to adapt\nto new tasks. Here, we focus on some works that try to\ntackle the problem of data efficiency. The first work on\ndeep Q-learning (Mnih et al. 2015) introduced the idea of\nExperience Replay (Lin 1992) to improve data-efficiency .\nBy replaying the trajectories visited by the agent, the agent\nwas able to decorrelate samples for training and also learn\nmore robustly from each sample. (Wang et al. 2017) was\nable to apply the idea of Experience Replay along with\nsome other modifications into the on-policy actor-critic and\nmake the whole architecture sample efficient. Recently,\n(Andrychowicz et al. 2017) proposed Hindsight Experience\nReplay, a method allowing the agent to learn as much\ninformation about the undesired outcomes as it would\nof the desired outcomes. To do this they take as input,\nthe observation and the goal state that is to be achieved\n(experiments were done on environments where the goal\nstate was known) and train the neural network to act in\norder to get to the goal state. They further add samples in\nthe Experience Replay that reward the agent upon reaching\ndifferent states visited in the agents trajectories. This allows\nfor more information to be learned about the environment.\n(Jaderberg et al. 2017) introduced a method of learning multiple unsupervised auxiliary tasks on the visual data\nstream that allow the agent to learn to control and predict\ndifferent aspects of the environment. The proposed agent,\nUNREAL, significantly outperformed previous baselines\nbased on the on-line A3C (Mnih et al. 2016) architecture.\nThe algorithm also learned robust policies and was able to\nlearn with much less data when compared to A3C. (Lample\nand Singh Chaplot 2016) tries to predict the actions that\nare required to be taken by the agent along with predictions of some game features which lead to an increase in\nperformance on VizDoom (Kempka et al. 2016). (Kulkarni\net al. 2016) also tries to reproduce the current state of the\nenvironment as an auxiliary task along with the successor\n\nExploration Strategies\nExploration strategies in reinforcement learning have\nbeen able to achieve near-optimal guarantees for many\nsmall domains like Markov Decision Process chains and\npuddle world in the past (Brafman and Tennenholtz 2002;\nKearns and Koller 1999). However, these near-optimal\nalgorithms were not able to scale well to large domains\nthat deep reinforcement learning aims to solve. Most of the\nrecently proposed exploration strategies, have made use of\npseudo counts for state visitations (Bellemare et al. 2016;\nOstrovski et al. 2017), hashing (Tang et al. 2016), exploration bonuses(Stadie, Levine, and Abbeel 2015) and\nintrinsic motivation (Houthooft et al. 2016). However, there\nwas a need for strategies that can perform deep exploration\nover multiple time-steps.\nThe Q-ensemble architecture was first introduced in\nDRL by (Osband et al. 2016) through the BootstrappedDQN architecture to perform deep exploration along with\nsome level of planning. The architecture derives most of\nits inspiration from Posterior Sampling for Reinforcement\nLearning (PSRL) (Osband, Russo, and Van Roy 2013).\nBootstrappedDQN maintains multiple Q-value estimates\nand was able to perform more efficient exploration than\nDouble DQN (Van Hasselt, Guez, and Silver 2016) on\nmajority of the Atari Games. Recently, (Chen et al. 2017)\nmodified BootstrappedDQN to further improve exploration\nby adapting the UCB algorithm (Auer, Cesa-Bianchi, and\nFischer 2002) to the Q-ensemble architecture and further\nusing the disagreement among the value function estimates\nin order to provide a reward bonus signal. Additionally, the\npaper also proposed an exploitation Q-ensemble algorithm\ncalled Ensemble Voting where the agent follows a policy\nwhich is the majority vote of the heads.\n\nTransfer in DRL\nTransfer for reinforcement learning has been studied to a\ngreat extent in the past (Taylor and Stone 2009). While several methods for performing transfer have been proposed in\nthe past, here we study action advice in reinforcement learning. In action advice, we have a teacher advice the student\nwhat kind of action needs to be taken at each step. A2T (Rajendran et al. 2017) tries to provide action advice from mul-\n\n\ftiple trained experts to a new agent to try and capture different skills from each teacher through positive policy transfer.\nOther methods like (Parisotto, Ba, and Salakhutdinov 2016;\nRusu et al. 2016) have involved knowledge transfer from one\n(or multiple) source tasks to a target task in order to speed\nup the learning process by learning from transitions of the\nexpert agents. These methods were also shown to be able\nto learn more general representations of the environment on\nAtari 2600 games. However, these algorithms depend on an\nagent that has been trained completely on a task(or a teacher)\nto perform the knowledge transfer to a fresh agent(or a student). (Zhan and Taylor 2015) is one of the first papers to\npresent online transfer between agents that are still learning\nhow to act in the environment. The paper further goes on to\nshow that classical transfer is a specific case of online transfer and prove the convergence of Q-learning and SARSA\nusing online transfer.\n\nBackground\nRL Notations\nA common approach to solving an RL problem is through\nvalue functions that indicate the expected reward that can be\nobtained from each state. In this paper, we only concern ourselves with state-action value functions Q(s, a) which is the\nreturn that an agent is expected to receive from a particular\nstate s upon taking an action a. One common approach for\nlearning the value functions is an off-policy TD-algorithm\ncalled Q-learning (Watkins and Dayan 1992). The optimal\npolicy can be achieved by behaving greedily with respect\nto the learned state-action value function in each state. The\nupdate rule for the Q-learning is as follows,\n\nsquared TD-error as the loss signal given to the neural network.\nLi (θi ) = Es,a,r,s0 [((r + γmaxa0 Q(s0 , a0 ; θi− )\n− Q(s, a; θi ))2 ]\n\n(2)\n\nHere, θi represents the weights of online network and θi−\nrefers to the target network weights. The target network\nensures that the learning happens in a stable manner while\nthe replay memory ensures that network can learn from\nindependent identically distributed(i.i.d.) samples hence\nensures stable neural network training.\nThe max operator in Q-learning has been shown to\nproduce an overestimation error in the value function\n(Hasselt 2010). To overcome this overestimation error in\nDQNs, (Van Hasselt, Guez, and Silver 2016) introduced\nDouble Deep Q-Networks (DDQN), a low computational\noverhead algorithm, in which the greedy policy is evaluated\nusing the online network and the value is given by the target\nnetwork for the learning update. Thus the loss signal for the\nDDQN becomes:\nLi (θi ) = Es,a,r,s0 [(r + γQ(s0 , argmaxa0 Q(s0 , a0 ; θi ); θi− )\n− Q(s, a; θi ))2 ]\n\n(3)\n\nBootstrappedDQN\n\nQt+1 (st , at ) = Qt (st , at ) + α(rt + γmaxa Qt (st+1 , a)\n− Qt (st , at ))\n(1)\nHere, st is the state, at is the action taken and rt is the reward\nobtained by taking that action at time t. From here on, we\nwill refer to Q(s, a) as value function.\n\nDeep Q-Networks (DQN)\nIn environments with large state spaces, it is not possible to\nlearn values for every possible state-action pair. The need\nfor generalizing from experience of a small subset of the\nstate space to give useful approximations of the value function becomes a key issue (Sutton and Barto 1998). Neural\nnetworks, while attractive as potential value function approximators, were known to be unstable or even to diverge\non reinforcement learning problems. Through some seminal\nwork on representation learning using deep neural networks\n(LeCun, Bengio, and Hinton 2015) were able to create new\nmethods for learning algorithms from the high dimensional\nvisual observations. (Mnih et al. 2015) successfully used\ndeep neural networks in order to carry out Q-learning using the high dimensional Atari 2600 (Bellemare et al. 2013)\nscreen observation as input. Additionally, (Mnih et al. 2015)\nalso overcomes the problem of stability in learning using\ntwo crucial ideas: replay memory and target networks. The\nparametrized value function is trained using the expected\n\nFigure 1: BootstrappedDQN architecture\nBootstrappedDQN (Osband et al. 2016) introduces a novel\nexploration strategy that performs deep exploration in\nenvironments with large state spaces. The idea mainly\ndraws inspiration from two prior works on PSRL (Osband,\nRusso, and Van Roy 2013) and RLSVI (Osband, Roy,\nand Wen 2016). The Q-ensemble architecture maintains\nmultiple parametrized value function estimates or “heads”.\nBootstrappedDQN depends on the independent initializations of the heads and the fact that each head is trained\nwith different set of samples. However, it was shown\nthat training each head with different samples was not as\nmuch an important criteria as the independent initializations.\nAt the start of every episode, BootstrappedDQN samples a single value function estimate at random according\nto a uniform distribution. The agent then follows the greedy\n\n\f(a) 40-state chain MDP\n\n(b) 45-state chain MDP\n\n(c) 50-state chain MDP\n\nFigure 2: Comparison of number of steps taken by Shared Learning-Bootstrap, Bootstrap, Q-learning and Double Q-learning\nalgorithm during each run (averaged over 50 runs). When the algorithm has converged there is a zero variance line corresponding\nto the fastest path to the goal state which takes n − 2 steps in an n-state MDP chain.\npolicy with respect to the selected estimate until the end of\nthe episode. The authors propose that this is an adaptation\nof the Thompson sampling heuristic to RL that allows for\ntemporally extended (or deep) exploration.\nBootstrappedDQN is implemented by adding multiple\nheads which branch out from the output of the convolutional\nlayers as shown in Figure 1. Suppose there are K heads\nin this network. The outputs from each head represent\ndifferent independent estimates of the action-value function.\nLet Qk (s, a; θi ) be the value estimate and Qk (s, a; θi− ) be\nthe target value estimate of the k th head. The loss signal for\nthe kth head is given as follows,\n\nThis where Shared Learning steps in, our framework for\nQ-ensemble algorithms which is able to allow the ensemble\nestimates to learn from each other through action advice\nin the learning update. The results for Shared Learning, in\nFigure 2, indicate that our framework converges to the goal\nstate solution faster than Bootstrap.\n\nLi (θi ) = Es,a,r,s0 [(r + γQk (s0 , argmaxa0 Qk (s0 , a0 ; θi ); θi− )\n− Qk (s, a; θi ))2 ]\n\n(4)\n\nEach of the K heads is updated this way and the gradients\nare aggregated and normalized at the convolutional layers.\n\nShared Learning\nA motivating example\nConsider the task of solving an MDP chain environment as\nin Figure 3 with state space S = {s1 , s2 , ..., sn } and action\nspace A = {Jump to s1 , Right, Left, No-op}. In this task, the\nagent begins at state s2 and has to reach state sn to get a reward of +10 and if it goes to state s1 , it gets a reward of -10.\nThe episode terminates when either state s1 or sn is reached.\nThis is an environment that good exploration algorithms can solve very fast. Algorithms like Q-learning and\nDouble Q-learning (Hasselt 2010) find it very hard to solve\nsuch an environment. As shown in the graph in Figure\n2, a tabular adaptation of BootstrappedDQN, which we\ncall the Bootstrap algorithm here, is able to solve larger\nchains when compared to Q-learning (Watkins and Dayan\n1992) and Double Q-learning. However, the algorithm\ntakes a long time to converge to the goal state because\nall the value function estimates have to learn from their\nindependent experiences. So, we need a method to transfer\nthe knowledge among other value function estimates.\n\nFigure 3: MDP chain with n-states\n\nKnowledge Sharing in Learning Update\nThe motivation for Shared Learning is to allow the different\nvalue function estimates to learn from each other so that\nthe complete agent can solve a task much faster and more\nefficiently. To this end, knowledge must be transferred from\nan apparent expert to the other estimates. Transfer learning\nliterature suggests that in order to make sure that other\nestimates are able to replicate the rewarding trajectories of\nthe expert, we should perform action advice. Instead, we\nintroduce a novel method of trying to influence an estimate\nto attempt to go along the direction of the chosen estimate\nthrough a minor modification in the learning update of\nBootstrappedDQN as given in Equation 5.\nLi (θi ) = Es,a,r,s0 [(r + γQk (s0 , argmaxa0 Qm (s0 , a0 ; θi ); θi− )\n− Qk (s, a; θi ))2 ]\n\n(5)\n\nwhere m 6= k. Since our requirement is to follow directions\nalong maximum reward, we can choose the estimate that is\nable to give the highest(best) expected reward to perform\nthe knowledge sharing. So, we modify the above equation to\n\n\fgive the following update rule,\nLi (θi ) = Es,a,r,s0 [(r + γQk (s0 , argmaxa0 Qbest (s0 , a0 ; θi ); θi− )\n− Qk (s, a; θi ))2 ]\n\n(6)\n\nWhile (Zhan and Taylor 2015) tried to show how action advice during learning can help in the overall training process\nwe have shown, in a novel manner, how to use action advice\nin the learning update to perform faster learning.\n\nRobust Target Estimates\nWhile proposing to use Double Q-learning in DQNs in\n(Van Hasselt, Guez, and Silver 2016), the author(s) proposed a low computational overhead modification which\nwas shown to reduce the overestimation errors in DQNs\nby using the online network to provide the greedy policy\nwhile using the target network for the value estimate. But,\nthe target network, being a previous iteration of the online\nnetwork, is coupled with the online network. This reduces\nthe capability of the Double Q-learning update and has been\nreported in (Van Hasselt, Guez, and Silver 2016).\nHowever, through Shared Learning we can ensure that\nmost of the time the estimate that is providing the greedy\naction (Qbest ) is not the same as the estimate that provides\nthe target value(Qk ). Hence, the effect of coupling further\nreduces through our update and learning becomes more\nrobust. This is a second advantage of our framework and we\nbelieve that this allows for better learning from each sample\nin the replay memory leading to better understanding on the\nworld. Additionally, we would like to note that the framework is expected to get better at reducing overestimations\nwith increasing number of heads since the chances of a\ngiven head providing the greedy action to its own target\nestimate reduces and so the coupling effect also reduces.\nWe have summarised the Shared Learning framework\nfor any deep Q-ensemble algorithm X in Algorithm 1.\nThrough the combined ability of transferring knowledge about rewarding states and robust learning updates,\nShared Learning is able to replay rewarding sequences more\noften and also have a better understanding of rewarding\nstates. Empirically, this can be observed from the results\non the MDP chain environment in Table 1 and Figure 4\nwhere the Shared Learning algorithm is able to make more\ngoal-state visitations than Bootstrap algorithm. Additionally, we can also see the effect of the choice of “best” head\nas Shared Learning is able to get to the goal state more\noften than a Random Head algorithm, where a “random”\nhead is chosen to give the target estimate. In some sense,\nShared Learning can be assumed to have developed a biased\nimplicit curriculum towards rewarding states as simpler\ngoals can be learnt much faster through our framework\nallowing the agent to focus on more complex goals in the\nenvironment.\n\nExperiments and Discussion\nIn this section, we try to answer the following questions:\n\nNo. of\nstates\nin MDP\nchain\n40\n50\n60\n70\n\nNo. of\nepisodes\nper run\n150\n300\n700\n1500\n\nBootstrap Random\nAlgoHead\nrithm\nAlgorithm\n56.62\n58.28\n74.22\n89.96\n146.48\n166.88\n99.96\n151.6\n\nShared\nLearning\nAlgorithm\n60.36\n93.18\n184.46\n164.78\n\nTable 1: Comparison of the number of visitations of the goal\nstate made by each algorithm on an n-state MDP chain. The\nresults have been averaged over 50 runs.\n\nFigure 4: Comparison of the number of times the goal state\nis reached by Shared Learning, Bootstrap and Random Head\nalgorithm on the MDP chain environment.\nAlgorithm 1 Shared Learning - X\nInput: Value function networks Q with K outputs {Qk }K\nk=1\n1: Let B be a replay buffer storing experience for training and\nselect best int be the interval during which the best head is\nselected.\n2: numSteps ← 0\n3: best head ∼ Uniform{1, 2, . . . , K}\n4: for each episode do\n5:\nObtain initial state from environment s0\n6:\nfor step t = 1, . . . until end of episode do\n7:\nPick an action according to Q-ensemble algorithm X\n8:\nTake action at and receive state st+1 and reward rt\n9:\nStore transition (st ,at ,rt ,st+1 ) in B\n10:\nSample minibatch from B\n11:\nTrain network with loss function given in equation 6\n12:\nnumSteps ← numSteps + 1\n13:\nif numSteps mod select best int == 0 then\n14:\nbest head = argmaxk Qk (st , at )\n15:\nend if\n16:\nend for\n17: end for\n\n• Can Shared Learning become data-efficient with deep reinforcement learning algorithms?\n• Can the algorithm be extended to exploitation Q-\n\n\f(a) Seaquest\n\n(b) Enduro\n\n(c) Kangaroo\n\n(d) Pong\n\n(e) Freeway\n\n(f) Riverraid\n\nFigure 5: Comparison of Shared Learning-Bootstrap vs BootstrappedDQN algorithm\n\n(a) Seaquest\n\n(b) Enduro\n\n(c) Kangaroo\n\n(d) Pong\n\n(e) Freeway\n\n(f) Riverraid\n\nFigure 6: Comparison of Shared Learning-Ensemble Voting vs Ensemble Voting algorithm\nensemble algorithms?\nTo this end, we test the efficacy of the Shared Learning\nframework on an exploration Q-ensemble algorithm and an\nexploitation Q-ensemble algorithm with BootstrappedDQN\n\nand Ensemble Voting (Chen et al. 2017) respectively. The\nhyperparameters were tuned for 6 Atari Games (Seaquest,\nRiverraid, Kangaroo, Pong, Freeway and Enduro) and were\nkept constant throughout both experiments.\n\n\fIn our experiments, the most important parameter to be\ndealt with is the frequency with which we choose the “best”\nhead among the value function estimates. Here, we have\nchosen the frequency to be 10,000 steps, i.e., the head that\nis required to perform knowledge sharing is chosen once every 10,000 steps. The DQN code has been taken from OpenAI baselines1 and our algorithms are evaluated on the Atari\nGames in OpenAI Gym (Brockman et al. 2016), which is\nsimulated by Arcade Learning Environment (Bellemare et\nal. 2013) and trained for 40 million frames on each game.\nFor the graphs, we have plotted the learning curves for the algorithms against the number of episodes played over 40 million frames. We believe that in doing so we get to see that our\nproposed framework plays lesser number of episodes within\nthe same number of timesteps and still gets to a higher score\nwhich essentially shows that the framework makes for data\nefficiency.\n\nShared Learning-BootstrappedDQN\nThe training curves for Shared Learning-BootstrappedDQN\nvs BootstrappedDQN is shown in Figure 5. We have also\nsummarised the highest scores obtained during training on\nthe different games in Table 2. We refer to the algorithm\nBootstrappedDQN as BDQN and the application of Shared\nLearning on BDQN as SLBDQN. From the graph and the\ntable, we can see that Shared Learning is able to do equal\nor better than BootstrappedDQN on 5 out of 6 games in\nterms of score and it is also able to achieve these scores\nwith lesser data. We claim this is because of the ability of\nthe framework to replay rewarding trajectories much more\noften because of the knowledge sharing that happens between the value function estimates making the framework\ndata-efficient for the exploration algorithm. Further, we see\nthat the graphs have an increasing slope in Seaquest, Kangaroo and Enduro which indicates that we can get better scores\nwith more training.\nGame\n\nBDQNMeanMax\nPong\n20.53\nKangaroo 3476\nRiverraid 5307.9\nEnduro\n501.48\nFreeway 32.81\nSeaquest 4989.4\n\nSLBDQNMeanMax\n20.74\n9120\n10242.8\n911.47\n32.39\n9086.4\n\nBDQNEpMax\n21\n10600\n9280\n1007\n34\n14880\n\ndifferent games in Table 3. We refer to the algorithm Ensemble Voting as EV and the application of Shared Learning on\nEV as SLEV. From the graph and the table, we can see that\nShared Learning is able to do equal or better than Ensemble\nVoting on 5 out of 6 games in terms of score and it is also\nable to achieve these scores with lesser data due to the same\nreasons as mentioned in the previous subsection. However,\nwe believe that the data efficiency and the improved scores\nare not as profound as in BootstrappedDQN because we are\napplying a biased curriculum on an exploitation algorithm.\nGame\n\nEVMeanMax\nPong\n20.6\nKangaroo 9694\nRiverraid 10443.1\nEnduro\n1098.5\nFreeway 33.48\nSeaquest 6456.6\n\nSLEVMeanMax\n20.87\n11215\n12118.2\n1206.77\n33.16\n13176\n\nEVEpMax\n21\n14700\n15770\n1882\n34\n20360\n\nSLEVEpMax\n21\n15200\n16530\n1940\n34\n35180\n\nTable 3: Experimental results for Shared LearningEnsemble Voting and Ensemble Voting experiments. Here\nMeanMax represents the scores from the mean curves in\nFigure 6, EpMax represents the maximum score achieved\nin an episode by the algorithm.\n\nConclusion & Future Work\nWe have proposed a low computational overhead framework Shared Learning to make Q-ensemble algorithms dataefficient. We have also shown that the framework is applicable to exploration and exploitation algorithms such as BootstrappedDQN and Ensemble Voting respectively. Our action\nadvice in learning update framework shows a significant improvements in game score for some of the Atari Games indicating faster learning through robust estimates.\nIn this paper, we have fixed the interval for choosing the\n\nSLBDQNEpMax\n21\n15000\n15370\n1869\n33\n23970\n\nTable 2: Experimental results for Shared Learning-Bootstrap\nand BootstrappedDQN experiments. Here MeanMax represents the scores from the mean curves in Figure 5, EpMax\nrepresents the maximum score achieved in an episode by the\nalgorithm.\n\nShared Learning-Ensemble Voting\nThe training curves for Shared Learning-Ensemble Voting\nvs Ensemble Voting is shown in Figure 6. We have also summarised the highest scores obtained during training on the\n1\n\nhttps://github.com/openai/baselines\n\nFigure 7: Freeway using 20,000-step interval for choosing\nthe “best head”, is able to learn much faster initially than the\n10,000-step interval. Analysis done for SLBDQN vs BDQN.\n“best” head to share knowledge among the other heads.\nHowever, we could look to tune this hyperparameter and\n\n\fmake it dynamic. For example, we can see in Figure 7 that\nupon changing the parameter from 10,000 steps to 20,000\nsteps for Freeway, we can make the framework learn faster\ninitially. We could also tune the number of heads to share\nknowledge from to improve the robustness of the learning\nrule. Since, we have shown that our framework is able to\nperform better learning updates when compared to DoubleDQN, we could test the effect of our learning update on\nmasking BootstrappedDQN. We leave these modifications\nfor Shared Learning to future work.\n\nAcknowledgements\nWe would like to thank Manu Srinath Halvagal, EPFL, for\nsome useful discussions as well Joe Eappen, IIT Madras, and\nYash Chandak, UMass Amherst, for their valuable feedback\non the work.\n\nReferences\n[Andrychowicz et al. 2017] Andrychowicz, M.; Wolski, F.;\nRay, A.; Schneider, J.; Fong, R.; Welinder, P.; McGrew, B.;\nTobin, J.; Abbeel, P.; and Zaremba, W. 2017. Hindsight\nExperience Replay. ArXiv e-prints.\n[Auer, Cesa-Bianchi, and Fischer 2002] Auer, P.; CesaBianchi, N.; and Fischer, P. 2002. Finite-time analysis\nof the multiarmed bandit problem. Machine learning\n47(2-3):235–256.\n[Bellemare et al. 2013] Bellemare, M. G.; Naddaf, Y.; Veness, J.; and Bowling, M. 2013. The Arcade Learning Environment: An evaluation platform for general agents. J. Artif.\nIntell. Res.(JAIR) 47:253–279.\n[Bellemare et al. 2016] Bellemare, M.; Srinivasan, S.; Ostrovski, G.; Schaul, T.; Saxton, D.; and Munos, R. 2016. Unifying Count-based Exploration and Intrinsic Motivation. In\nAdvances in Neural Information Processing Systems, 1471–\n1479.\n[Brafman and Tennenholtz 2002] Brafman, R. I., and Tennenholtz, M. 2002. R-max-a general polynomial time algorithm for near-optimal reinforcement learning. Journal of\nMachine Learning Research 3(Oct):213–231.\n[Brockman et al. 2016] Brockman, G.; Cheung, V.; Pettersson, L.; Schneider, J.; Schulman, J.; Tang, J.; and Zaremba,\nW. 2016. OpenAI Gym. ArXiv e-prints.\n[Chen et al. 2017] Chen, R. Y.; Sidor, S.; Abbeel, P.; and\nSchulman, J. 2017. UCB and InfoGain Exploration via QEnsembles. ArXiv e-prints.\n[Hasselt 2010] Hasselt, H. V. 2010. Double Q-learning. In\nAdvances in Neural Information Processing Systems, 2613–\n2621.\n[Houthooft et al. 2016] Houthooft, R.; Chen, X.; Duan, Y.;\nSchulman, J.; De Turck, F.; and Abbeel, P. 2016. Vime: Variational Information Maximizing Exploration. In Advances\nin Neural Information Processing Systems, 1109–1117.\n[Jaderberg et al. 2017] Jaderberg, M.; Mnih, V.; Czarnecki,\nW. M.; Schaul, T.; Leibo, J. Z.; Silver, D.; and Kavukcuoglu,\nK. 2017. Reinforcement learning with unsupervised auxiliary tasks.\n\n[Kearns and Koller 1999] Kearns, M., and Koller, D. 1999.\nEfficient Reinforcement Learning in Factored MDPs. In IJCAI, volume 16, 740–747.\n[Kempka et al. 2016] Kempka, M.; Wydmuch, M.; Runc, G.;\nToczek, J.; and Jaśkowski, W. 2016. ViZDoom: A\nDoom-based AI Research Platform for Visual Reinforcement Learning. ArXiv e-prints.\n[Kulkarni et al. 2016] Kulkarni, T. D.; Saeedi, A.; Gautam,\nS.; and Gershman, S. J. 2016. Deep Successor Reinforcement Learning. ArXiv e-prints.\n[Lake et al. 2016] Lake, B. M.; Ullman, T. D.; Tenenbaum,\nJ. B.; and Gershman, S. J. 2016. Building machines that\nlearn and think like people. Behavioral and Brain Sciences\n1–101.\n[Lample and Singh Chaplot 2016] Lample, G., and Singh\nChaplot, D. 2016. Playing FPS Games with Deep Reinforcement Learning. ArXiv e-prints.\n[LeCun, Bengio, and Hinton 2015] LeCun, Y.; Bengio, Y.;\nand Hinton, G.\n2015.\nDeep learning.\nNature\n521(7553):436–444.\n[Lin 1992] Lin, L.-H. 1992. Self-improving reactive agents\nbased on reinforcement learning, planning and teaching.\n[Mnih et al. 2015] Mnih, V.; Kavukcuoglu, K.; Silver, D.;\nRusu, A. A.; Veness, J.; Bellemare, M. G.; Graves, A.; Riedmiller, M.; Fidjeland, A. K.; Ostrovski, G.; et al. 2015.\nHuman-level Control through Deep Reinforcement Learning. Nature 518(7540):529–533.\n[Mnih et al. 2016] Mnih, V.; Badia, A. P.; Mirza, M.; Graves,\nA.; Lillicrap, T. P.; Harley, T.; Silver, D.; and Kavukcuoglu,\nK. 2016. Asynchronous Methods for Deep Reinforcement\nLearning. In International Conference on Machine Learning.\n[Osband et al. 2016] Osband, I.; Blundell, C.; Pritzel, A.; and\nVan Roy, B. 2016. Deep Exploration via Bootstrapped\nDQN. In Advances In Neural Information Processing Systems, 4026–4034.\n[Osband, Roy, and Wen 2016] Osband, I.; Roy, B. V.; and\nWen, Z. 2016. Generalization and Exploration via Randomized Value Functions. In Proceedings of the 33nd International Conference on Machine Learning, ICML 2016,\nNew York City, NY, USA, June 19-24, 2016, 2377–2386.\n[Osband, Russo, and Van Roy 2013] Osband, I.; Russo, D.;\nand Van Roy, B. 2013. (more) Efficient Reinforcement\nLearning via Posterior Sampling. In Advances in Neural\nInformation Processing Systems, 3003–3011.\n[Ostrovski et al. 2017] Ostrovski, G.; Bellemare, M. G.; van\nden Oord, A.; and Munos, R. 2017. Count-Based Exploration with Neural Density Models. ArXiv e-prints.\n[Parisotto, Ba, and Salakhutdinov 2016] Parisotto, E.; Ba,\nJ. L.; and Salakhutdinov, R. 2016. Actor-mimic: Deep multitask and transfer reinforcement learning.\n[Rajendran et al. 2017] Rajendran, J.; Lakshminarayanan,\nA.; Khapra, M. M.; Prasanna, P.; and Ravindran, B. 2017.\nAttend, adapt and transfer: Attentive deep architecture for\nadaptive transfer from multiple sources in the same domain.\n\n\f[Rusu et al. 2016] Rusu, A. A.; Colmenarejo, S. G.; Gulcehre, C.; Desjardins, G.; Kirkpatrick, J.; Pascanu, R.; Mnih,\nV.; Kavukcuoglu, K.; and Hadsell, R. 2016. Policy distillation.\n[Schaul et al. 2015] Schaul, T.; Quan, J.; Antonoglou, I.; and\nSilver, D. 2015. Prioritized Experience Replay. arXiv\npreprint arXiv:1511.05952.\n[Stadie, Levine, and Abbeel 2015] Stadie, B. C.; Levine, S.;\nand Abbeel, P. 2015. Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models. CoRR\nabs/1507.00814.\n[Sutton and Barto 1998] Sutton, R. S., and Barto, A. G.\n1998. Reinforcement Learning: An Introduction, volume 1.\nMIT press Cambridge.\n[Tang et al. 2016] Tang, H.; Houthooft, R.; Foote, D.;\nStooke, A.; Chen, X.; Duan, Y.; Schulman, J.; Turck, F. D.;\nand Abbeel, P. 2016. #Exploration: A Study of Countbased Exploration for Deep Reinforcement Learning. CoRR\nabs/1611.04717.\n[Taylor and Stone 2009] Taylor, M. E., and Stone, P. 2009.\nTransfer learning for reinforcement learning domains: A survey. Journal of Machine Learning Research 10(Jul):1633–\n1685.\n[Taylor et al. 2014] Taylor, M. E.; Carboni, N.; Fachantidis,\nA.; Vlahavas, I.; and Torrey, L. 2014. Reinforcement learning agents providing advice in complex video games. Connection Science 26(1):45–63.\n[Van Hasselt, Guez, and Silver 2016] Van Hasselt, H.; Guez,\nA.; and Silver, D. 2016. Deep Reinforcement Learning with\nDouble Q-Learning. In AAAI, 2094–2100.\n[Wang et al. 2016] Wang, Z.; Schaul, T.; Hessel, M.;\nVan Hasselt, H.; Lanctot, M.; and De Freitas, N. 2016.\nDueling network architectures for deep reinforcement learning. In Proceedings of the 33rd International Conference on\nInternational Conference on Machine Learning-Volume 48,\n1995–2003. JMLR. org.\n[Wang et al. 2017] Wang, Z.; Bapst, V.; Heess, N.; Mnih, V.;\nMunos, R.; Kavukcuoglu, K.; and de Freitas, N. 2017. Sample efficient actor-critic with experience replay.\n[Watkins and Dayan 1992] Watkins, C. J., and Dayan, P.\n1992. Q-learning. Machine learning 8(3-4):279–292.\n[Weber et al. 2017] Weber, T.; Racanière, S.; Reichert, D. P.;\nBuesing, L.; Guez, A.; Jimenez Rezende, D.; Puigdomènech\nBadia, A.; Vinyals, O.; Heess, N.; Li, Y.; Pascanu, R.;\nBattaglia, P.; Silver, D.; and Wierstra, D. 2017. ImaginationAugmented Agents for Deep Reinforcement Learning.\nArXiv e-prints.\n[Zhan and Taylor 2015] Zhan, Y., and Taylor, M. E. 2015.\nOnline transfer learning in reinforcement learning domains.\narXiv preprint arXiv:1507.00436.\n\n\f",
         "train",
         "37068",
         "5910"
        ],
        [
         "17",
         "19527",
         "cs.AI",
         "Artificial Intelligence",
         "1610.08469v4.pdf",
         "Kissing Cuisines: Exploring Worldwide\nCulinary Habits on the Web\n∗\n\nSina Sajadmanesh? , Sina Jafarzadeh? , Seyed Ali Osia? , Hamid R. Rabiee? , Hamed Haddadi†\nYelena Mejova‡ , Mirco Musolesi] , Emiliano De Cristofaro] , Gianluca Stringhini]\n\narXiv:1610.08469v4 [cs.CY] 25 Apr 2017\n\n?\n\nSharif University of Technology, † Queen Mary University of London\n‡\nQatar Computing Research Institute, ] University College London\n\nABSTRACT\n\nhow these factors are related to individuals’ health. With this motivation in mind, in this paper, we set to investigate the way in\nwhich ingredients relate to different cuisines and recipes, as well\nas the geographic and health significances thereof. We use a few\ndatasets, including 157K recipes from over 200 cuisines crawled\nfrom Yummly, BBC Food data, and country health statistics.\n\nFood and nutrition occupy an increasingly prevalent space on the\nweb, and dishes and recipes shared online provide an invaluable\nmirror into culinary cultures and attitudes around the world. More\nspecifically, ingredients, flavors, and nutrition information become\nstrong signals of the taste preferences of individuals and civilizations. However, there is little understanding of these palate varieties. In this paper, we present a large-scale study of recipes published on the web and their content, aiming to understand cuisines\nand culinary habits around the world. Using a database of more\nthan 157K recipes from over 200 different cuisines, we analyze ingredients, flavors, and nutritional values which distinguish dishes\nfrom different regions, and use this knowledge to assess the predictability of recipes from different cuisines. We then use country health statistics to understand the relation between these factors\nand health indicators of different nations, such as obesity, diabetes,\nmigration, and health expenditure. Our results confirm the strong\neffects of geographical and cultural similarities on recipes, health\nindicators, and culinary preferences across the globe.\n\n1.\n\nOverview & Contributions. First, we characterize different cuisines\naround the world by their ingredients and flavors. Then, we train a\nSupport Vector Machine classifier and use deep learning models to\npredict a cuisine from its ingredients. This also enables us to discover the similarity across different cuisines based on their ingredients – e.g., Chinese and Japanese – while, intuitively, they might\nbe considered different. We look at the diversity of ingredients in\nrecipes from different countries and compare them to geographic\nand human migration statistics. We also measure the relationship\nbetween the nutrition value of the recipes vis-à-vis public health\nstatistics such as obesity and diabetes.\nPaper Organization. The rest of the paper is organized as follows.\nIn Section 2, we present the datasets used in our study, then Section 3 presents an analysis of the diversity of the ingredients around\nthe world, looking at geographic diversity patterns of cuisines and\nnotable ingredients in particular ones. In Section 4, we look at the\nsimilarity between the cuisines based on their ingredients and flavors, and use these results to train machine-learning classifiers for\ningredient-based cuisine prediction models in Section 5. In Section\n6, we correlate the nutrition values of recipes for different countries\nwith their public health statistics. After reviewing related work in\nSection 7, the paper concludes in Section 8.\n\nINTRODUCTION\n\nNowadays, food has become an essential part of today’s digital sphere and an important source for our social media footprints.\nNew jargon has entered our vocabulary with expressions like “foodie”,\n“food porn”, and “food tourism”, hint at the buzz around the entertainment arising from our culinary experiences. With the rise of\nsocial media, and the proliferation of always-on always-connected\ndevices, this gobbling revolution is not confined to our kitchens,\nrestaurants, and food stalls, but naturally breaks out on the social\nweb. Sharing pictures of one’s food has become a growing passion\nfor both tourists and locals [15], and dedicated food searching and\nsharing apps, along with recipe websites and the ubiquitous social\npresence of celebrity chefs, have all contributed to a thriving culture and passion around food worldwide.\nAround the world, different cuisines are naturally intertwined\nwith cultures, traditions, passions, and religion of individuals living in different countries and continents. Sushi, curry, kebab, pasta,\ntacos – these are just examples of foods conventionally associated\nwith specific countries, as are specific cuisines and ingredients.\nDifferent dietary habits around the world are also closely related\nto various health statistics, including cancer incidence [3], death\nrates [12], cardiovascular complications [17], and obesity [13].\nAlthough there are many common beliefs about cuisines, recipes,\nand their ingredients, it is still unclear what types of ingredients\nare unique in/about different countries, what factors make cuisines\nsimilar to each other (e.g., in terms of ingredients or flavors), and\n∗\n\n2.\n\nDATASETS\n\nOur study relies on a number of datasets, namely, a large set\nof recipes collected from Yummly, a list of ingredients compiled\nby BBC Food, and country health statistics. In this section, we\ndescribe these datasets in detail.\n\n2.1\n\nYummly data\n\nYummly is a website offering recipe recommendations based on\nthe user’s taste.1 It allows users to search for recipes, learning\nwhich dishes the user likes and providing them with recipe suggestions. It also provides a user-friendly API, which we use to collect\nrecipes. First, we crawled Wikipedia for a list of cuisines2 , then, in\nSummer 2016, we queried the Yummly API for recipes belonging\nto each cuisine. In the end, we obtained 157,013 recipes belonging\nto over 200 different cuisines. Due to API restrictions, we limited\nthe number of recipes per to 5,000.\n1\n2\n\nA preliminary version of this paper appears in WWW 2017 Web Science Track.\n\n1\n\nhttp://www.yummly.com\nhttps://en.wikipedia.org/wiki/List_of_cuisines\n\n\f2.3\n\nEach recipe obtained from the Yummly API contains a number\nof attributes. In our study, we use the following:\n\nAs diet is directly related to the health of individuals, we also set\nto relate Yummly statistics to real-world health data. To this end,\nwe will use the diabetes prevalence estimates from World Development Indicators by The World Bank4 , the health expenditure as\na percentage of total GDP from The World Bank5 , and the obesity\nprevalence from the World Health Organization6 in the countries\nto which the cuisines are mapped, using the most recent available\ndata, which is from 2014.\n\n1. Ingredients: Each recipe contains a list of the ingredients\nthat are required to prepare it. Since Yummly acts as a recipe\naggregator from various cooking sites, the ingredients do not\nalways appear with the same wording. In fact, it is very\ncommon to see the same ingredient written with different\nspellings or by using a different terminology. We overcome\nthese issues through a standardization process described in\nSection 2.2.\n\n3.\n\n2. Flavors: Recipes are identified by six flavors, specifically,\nsaltiness, sourness, sweetness, bitterness, savoriness, and spiciness. These scores are on a range of 0 to 1.\n\n4. Nutrition: Unfortunately, the Yummly search API does not\ndirectly provide nutritional information for the recipes. As a\nconsequence, we designed a simple web crawler to fetch the\ncorresponding web page for each recipe in our dataset, and\nextract information on the amount of protein, fat, saturated\nfat, sodium, fiber, sugar, and carbohydrate of a recipe (per\nserving), as well as calories.\n\n3.1\n\nDiversity of ingredients\n\nAiming to investigate the diversity of ingredients in dishes of a\ncuisine, we set to answer the following questions:\n1. How many different unique ingredients are used in total in\ndishes of each country? In other words, what is the number\nof unique ingredients the people of a country have ever used\nto prepare a culinary dish? The answer to this question is\nwhat we refer to as the global diversity.\n\nAlthough some ingredients appear in other languages (e.g., German, French, etc), the recipes presented here are mostly in English;\nhence it is possible that some more authentic or niche local recipes\nmight be missing from our dataset. However, considering the number of recipes and a large cut-off threshold introduced later on, we\nare confident this does not significantly affect our analysis. Moreover, authors of the recipes might not represent the entire population, given the fact that they are likely to be tech-savvy. This might\nintroduce a potential bias in the dataset, but at the same time, this\npotential issue is compensated by its richness in terms of the variety\nof dishes from different countries available in it.\n\n2. How different are the dishes of an individual country relative\ntogether in terms of their ingredients combination? In other\nwords, do different dishes usually share some ingredients or\ntheir ingredients are almost different? The answer to this\nquestion is what we call local diversity.\nThe local and global diversity of ingredients in a country depend on many parameters including the geographical location, climatic conditions, agricultural situation, or even the amount of immigration which directly influences the diversity of culinary cultures. The calculation of the global diversity is performed in two\nsteps. Since the number of recipes per different cuisines are variable, we first set a fixed number of 100 recipes per cuisine, discarding cuisines containing fewer number of recipes, and sampling\nfrom cuisines containing more number of recipes uniformly at random, to have an equal number of recipes in all cuisines. This results\nin a final set of 82 different cuisines each containing 100 recipes.\nWe then map the result obtained for each cuisine to its corresponding country. Some countries are mapped with more than one cuisine, for these, we record the average result over their associated\ncuisines.\nTo calculate the local diversity, we look at each cuisine as a probability distribution over all standard ingredients. By counting the\ntotal number of occurrences of each ingredient in all recipes of a\nparticular cuisine, and then normalizing the values such that they\nsum to one, we obtain the ingredient distribution for that cuisine.\nWe then calculate the entropy of these distributions as the local\ndiversity of their corresponding cuisines. The entropy of the ingredient distribution measures the unpredictability of ingredients\nused in the dishes. Therefore, the higher the entropy of the ingredient distribution of a particular cuisine, the more different the\n\nBBC Food Data\n\nBBC Food3 is a part of the BBC website providing information\nabout recipes, ingredients, chefs, cuisines, and other information\nrelated to cooking and dishes from all BBC programs. In Summer\n2016, we crawled all the ingredients from the BBC Food website,\ncollecting about 1,000 ingredients, which we used to organize and\nstandardize the ingredients in the Yummly dataset. The standardization process is as follows:\n(i) We extracted all the 11,000 ingredients from the Yummly\ndataset and performed a preliminary data cleaning, i.e., removing measurement units (mass, volume, etc), numbers,\npunctuation marks, and other symbols.\n(ii) Due to the multilingualism of the Yummly data, we used the\nGoogle Translate API to perform automatic language detection and translation of all the Yummly ingredients to English.\n(iii) We used the BBC list of ingredients as a reference, and mapped\nall possible ingredients from the Yummly list to it.\n(iv) As not all ingredients from the Yummly list were successfully mapped, we merged the similar ones into groups, and\nthe ingredients in each group were manually mapped to its\nrepresentative ingredient.\n\n4\n\nhttp://data.worldbank.org/indicator/SH.STA.DIAB.ZS\nhttp://data.worldbank.org/indicator/SH.XPD.TOTL.ZS\n6\nhttp://apps.who.int/gho/data/view.main.2450A\n\nOverall, this process yields about 3,000 standardized ingredients.\n3\n\nINGREDIENTS AROUND THE WORLD\n\nIn this section, we provide a characterization of the ingredients\nused in dishes from all over the world. First, we investigate the\ndiversity of ingredients in different countries. Next, we define the\nconcept of “complexity” of a dish in terms of its ingredients and\nlook at how complexity changes around the world. Finally, we discuss a series of case studies of most notable and significant ingredients in some eminent cuisines.\n\n3. Rating: Users are encouraged to provide a rating, from 1 to\n5, for the recipes that they try. We use the average review\nrating for each recipe as a measure of its popularity.\n\n2.2\n\nCountry health statistics\n\n5\n\nhttp://www.bbc.co.uk/food/\n\n2\n\n\f180\n\n195\n\n210\n\n225\n\n240\n\n255\n\n270\n\n285\n\n4.20\n4.10\n\n4.35\n\n4.50\n\n(a) Global diversity\n\n4.65\n\n4.80\n\n4.95\n\n5.10\n\n5.25\n\n(b) Local diversity\n\nFigure 1: Diversity of ingredients used in dishes around the world. The dark blue reflects the least diverse countries while the dark\nred shows the most diverse ones.\n300\n\ningredients combination of its recipes, and thus the higher the local\ndiversity. To preserve the smoothness of the ingredient distributions, we again keep the 82 cuisines with more than 100 recipes.\nAfter calculating the local diversity for each cuisine, we follow the\nsame procedure as for the global diversity to map the cuisine-based\nresults to countries.\nFigure 1 shows the local and global diversities of ingredients for\ndifferent countries around the world. The local and global diversities have a meaningful correlation with each other. The countries\nwith high global diversity have also high local diversity, and countries with low global diversity tend to have low local diversity as\nwell. This happens because as the global diversity increases, people will have more options to choose as the ingredients for their\nfoods, so they can prepare relatively different dishes.\nAnother interesting trend from Figure 1 is that countries like the\nUnited States and Australia, which usually accept a high number of\nimmigrants, have a relatively high ingredient diversity. Regarding\nthis, we hypothesized that the number of immigrants coming to a\ncountry must have an influence on the ingredient diversity of that\ncountry. To investigate this fact, we collected the net migration\ndata from the World Bank7 which shows the difference between the\ntotal number of immigrants and emigrants during a time period. We\ncorrelated the global diversity with the average net migration from\n1960 to 2016. To this end, we fitted a polynomial curve to the\ndata points considering the global diversity and the net migration\nof 100 countries. The result is illustrated in Figure 2. As expected,\nan increase in the net migration results in an increase in the global\ndiversity of ingredients. When the net migration is above zero, for\nwhich the countries accept more immigrants than emigrants, the\nincrease in global diversity is much more considerable compared\nto the case having negative net migration. This is mainly due to\nimmigrants bringing their native culinary culture with themselves,\nwhich in turn makes the cuisines of their target country richer.\n\n3.2\n\nGlobal Diversity\n\n280\n\n240\n220\n200\n180\n160\n\n−8\n\n−6\n\n−4\n\n−2\n\n0\n\n2\n\nNet Migration\n\n4\n·104\n\nFigure 2: Relationship between the global ingredient diversity\nand the average net migration of different countries\n\nCumulative Probability\n\n1.0\n\n0.8\n\n0.6\n\n0.4\nNorwegian\nTunisian\nLao\n\n0.2\n\n0.0\n\n0\n\n5\n\n10\n\n15\n\n20\n\n25\n\n30\n\n35\n\n# ingredients\n\nComplexity of dishes\n\nAnother interesting concept about the culinary preferences of\ndifferent countries is the complexity of dishes. The complexity of a\ndish is simply the number of unique ingredients required to prepare\nit. Accordingly, a cuisine is more complex than another one if its\ndishes are proportionally more complex than the another’s.\nFormally speaking, each cuisine is associated with the complexity distribution of its dishes. For a sample cuisine, this distribution,\n7\n\n260\n\nFigure 3: Cumulative complexity distribution of dishes for\nsome representative cuisines.\n\nnamely P (X = i), specifies the probability of a dish from that\ncuisine to have exactly i unique ingredients. This way, the cumulative complexity distribution (CCD) will give us an insight about\nthe complexity of dishes in a particular cuisine.\n\nhttp://data.worldbank.org/indicator/SM.POP.NETM\n\n3\n\n\fother similar cases, which we do not present here due to space constraints. The bigger the name of an ingredient, the more distinctive\nit is in its associated cuisine. The soundness of results can be easily\nverified using Google Trends.8 For example, the term “Mozzarella”\nhas the highest search frequency in Italy, while “Garam masala” is\nthe most popular food additive in India according to its search volume.\n\n4.\n\nSIMILARITY OF CUISINES\n\nIn this section, we set to determine the similarities between cuisines,\nusing a number of different methods and data.\n\n0.0146 0.0148 0.0150 0.0152 0.0154 0.0156 0.0158 0.0160\n\n4.1\n\nAt first, we calculate the similarity between different cuisines\nbased on the ingredients used in their recipes. To this end, we\nconvert cuisines into vector space, representing each cuisine as\na vector where each element indicates the frequency of an specific ingredient in that cuisine. Thereby, for each cuisine we obtain an ingredient-based feature vector which we leverage to calculate the similarity between different cuisines. If we normalize\neach ingredient-based feature vector such that the elements of a\nvector sum to one, then each vector will represent a probability\ndistribution over standard ingredients. This way, we can use the\ndistance measures proposed for probability distributions as a measure of similarity between two vectors. For this purpose, we use\nJensen-Shannon (JS) divergence, which is defined between two\nprobability distributions P and Q as:\n\nFigure 4: Complexity of dishes around the world. Countries\nwith the least complex dishes are shown in dark blue while the\nones with most complex plates are depicted in dark red.\n\nFigure 3 depicts the cumulative complexity distribution (CCD)\nfor Norwegian, Tunisian, and Lao cuisines as an illustrative example. We observe that the CCD for Norwegian cuisine grows faster\nthan the others, while for Lao, it is relatively slower. As a result,\nabout half of the Lao dishes have more than 15 ingredients, while\nfor Norwegian cuisine, this fraction is below 10%. This means that\nLao dishes are relatively more complex than Norwegian ones. Thus\nfor each cuisine, the area under its CCD is inversely related to its\ncomplexity. Hence, we use the reciprocal of the area under CCD as\na measure of complexity for a cuisine.\nFigure 4 shows the complexity of dishes for different countries\naround the world. Here we have used the same approach as in Section 3.1 to map the cuisines to countries. Except for some cases,\nthe complexities are consistent with the diversities. This is due\nto the fact that as the number of available ingredients increases in a\ncountry (which is the result of global diversity,) people can leverage\nmore ingredients and prepare more complex dishes. The exceptions\nhere are China and India, two countries with the most population\nin the world. the complexity of dishes in these countries are relatively high, while their ingredients diversity is low. This can be the\nresult of overpopulation or special culinary culture in these countries. Perhaps, these countries had or have good chefs that could\ncook more complex foods with the available ingredients!\n\n3.3\n\nIngredient-based similarity\n\nJS(P, Q) =\n\n1\n[KL(P k M ) + KL(Q k M )]\n2\n\nwhere M = 12 (P + Q) and KL(P k M ) is the Kullback-Leibler\n(KL) divergence from M to P . Since the JS divergence is a distance measure between 0 and 1, we take 1 − JS(P, Q) as the similarity measure between two cuisines with their associated ingredient distributions P and Q. We have used JS divergence instead of\nthe simpler KL divergence because KL(P k Q) goes to infinity\nwhen for an ingredient like i, P (i) is non-zero while Q(i) is. This\ncase almost always happens in our data due to the geographical locality of ingredients. Therefore, we turned to JS divergence which\ndoes not have this drawback.\nUsing the above similarity metric, we calculated all similarities\nbetween each pair of cuisines. To assert the smoothness of ingredient distributions needed to compute JS divergence, we limited\nour cuisines to those 82 ones having more than 100 recipes. Figure 6a illustrates the obtained results in a graph-based fashion. In\nthis graph, each node represents a cuisine and is linked to its top-5\nmost similar cuisines. Link weights are proportional to the obtained\nsimilarity score between two endpoints. We colored each cuisine\nnode according to the geographical region it resides in, including\nNorth America, Latin America, Africa, Western Europe, Eastern\nEurope, Middle East, South Asia, East Asia, and Oceania. To visualize the graph, we have used ForceAtlas graph drawing algorithm\nimplemented in Gephi tool. This a force-directed algorithm which\nmakes densely connected nodes to be grouped together [18, 24] and\nthus the communities become revealed.\nFigure 6a shows that cuisines which reside in the same region\nare more similar to themselves and thus have been grouped together. For example, we clearly see the clusters formed by Eastern\nand Southern Asian, Middle Eastern and African, Latin American,\nand Western European cuisines. This indicates that the geography\nhas a direct impact on the ingredients people use for their dishes.\n\nNotable ingredients\n\nDue to the geographical locality of the ingredients, specific cuisines\nare mostly associated with different sets of ingredients. Some of\nthese ingredients are used worldwide, while there are some others\nwhich are local to specific cuisines. We call the latter kind of ingredients “notable” since they tend to signify the cuisines in which\nthey are used. We now study the most notable ingredients associated to some well-known cuisines using our dataset of recipes. An\ningredient is more notable to a specific cuisine if (1) It is used in\nmost dishes of that cuisine; and (2) It is barely used in dished of\nother cuisines.\nWe use the Term Frequency - Inverse Document Frequency (TFIDF) to find notable ingredients in each cuisine. In this approach,\neach ingredient is considered as an atomic word, and the collection\nof all the ingredients appeared within a cuisine is considered as a\ndocument. A TF-IDF calculation leads us to find the weight of each\ningredient in the corpus of documents. This way, we can specify\nthe importance of each ingredient within each cuisine.\nFigure 5 shows the top-50 most notable ingredients for Italian,\nIndian, and Mexican cuisines as a case study. We also looked at\n\n8\n\n4\n\nhttps://www.google.com/trends\n\n\f(a) Italian\n\n(b) Indian\n\n(c) Mexican\n\nFigure 5: Notable ingredients in Italian, Indian, and Mexican cuisines. More notable ingredients have been drawn larger.\nused flavor-based similarity between cuisines. We observe that\neven though the flavors are not as much discriminant as ingredients, still we can observe some geographical patterns. For instance\nthe clusters formed by Eastern Asian, Middle Eastern, Latin American, and Northern European cuisines are clear in this case as well.\nBut what is obvious here is the fact that although there is a sense of\ntaste similarity between the dishes from neighboring countries, the\nflavors are naturally shared all over the world.\nGenerally, some of the similarities depicted in Figure 6 appear\nto be fallacious at first look, but after precise inspections, we find\nthem to be valid. For example, the Welsh cuisine is found to be\nsimilar to Asian cuisines, which seems to be somewhat peculiar.\nBy further investigation, we have found out that Asians are the\nsecond major ethnic group in Wales, based on the 2011 census9 .\nTherefore, it seems that the Welsh cuisine is mostly influenced by\nthe Asian migrants and their culinary culture. Another interesting\nexample is Indian cuisine, which is found to be similar to African\nand Ethiopian cuisines. We have found that both of the African and\nEthiopian cuisines mostly contain spicy dishes, like Indian cuisine\nwhich is famous for its spicy plates. Accordingly, they share many\nspices like ginger, cardamom, cinnamon, chili pepper, and clove,\nwhich in turn makes them to be similar to each other. This can be\nverified by referring to the Wikipedia page of these cuisines10 .\n\nFurthermore, due to the similarity of cultures in Europe and North\nAmerica, and even Oceania, it can be seen that clusters formed by\nthe cuisines of these regions greatly overlap with each other. Therefore, ethnicity and culture can also greatly affect the culinary habits\nof the people.\nThere are examples here that confirm the impact of migrations\non the culinary culture of a region. For instance, since most of\nthe South American countries were former colonies of either Spain\nor Portugal, we see that Spanish and Portuguese cuisines are both\nvery close to the Latin American ones. The same holds for the\nOceanic and North American cuisines, where their corresponding\ncountries were formerly the colonies of the United Kingdom, being\nsimilar to British cuisine. However, as opposed to the Latin American cuisines, the similarity of Oceanic and American cuisines are\nnot confined to British cuisine, due to the high rate of immigrations\nand thus the diversity of the population.\n\n4.2\n\nFlavor-based similarity\n\nIn addition to the ingredient-based similarity, we calculate the\nsimilarity between cuisines in terms of the flavors provided in their\nrecipes. This can help us understand how different cuisines are\nrelated to each other based on the taste of their dishes.\nAs mentioned in Section 2.1, each recipe contains the flavor\nscores for six different flavors including saltiness, sourness, sweetness, bitterness, savoriness, and spiciness. To calculate the similarity between cuisines based on these flavors, as done for ingredientbased similarity, we consider each cuisine as a distribution over\ndifferent flavors. As different flavors of a recipe are correlated\nto each other – for instance, a dish can hardly be both sweet and\nspicy simultaneously – and due to the continuity of flavor scores,\nwe hypothesize that the flavor scores are sampled from a multivariate Gaussian distribution, where each covariate corresponds a\nparticular flavor. Considering this assumption, we fit a multivariate\nGaussian distribution to each cuisine so that each one becomes associated by a mean vector representing the average of flavor scores\nover all of its recipes, and a covariance matrix representing how\nflavors change relative to each other within that cuisine.\nAfter fitting a multivariate Gaussian distribution to each cuisine\nusing maximum likelihood estimation, we use KL divergence to\nmeasure the distance between the distributions associated to each\npair of cuisines. As KL divergence is an asymmetric measure, for\neach pair of cuisines with P and Q as their corresponding fla\u0003−1\n\u0002\nas\nvor distributions, we use 21 (KL(P k Q) + KL(Q k P ))\na symmetric similarity measure between them.\nFigure 6b shows the result of flavor-based similarity between\ndifferent cuisines in a graph-based manner. We followed exactly\nthe same steps as in Figure 6a to draw the graph, except that we\n\n5.\n\nCUISINE CLASSIFICATION\n\nWe now address the question of “How good we can predict a\nrecipe’s cuisine, given its ingredients?”. The answer to this question can help us understand the fact that how good a combination of\ningredients can represent a cuisine, as opposed to Section 3.3 where\ningredients were singly considered as cuisines signatures. To answer this question, We use two different classifiers, Support Vector\nMachine (SVM), which is previously used in [22] for the same task,\nand Deep Neural Network (DNN), which is popular nowadays for\nclassification purposes. To extract a feature vector for each recipe,\nwe convert it into a boolean bag of words vector, considering each\ningredient as an atomic word. Therefore, each recipe is represented\nas a vector with a length equal to the total number of ingredients,\nwhich is 3,286. The labeling of recipes are performed according to\none of the following settings:\n• Cuisine Prediction: Each recipe is labeled to its cuisine. we\nconsider 82 different cuisines having more than 100 recipes\nas different classes, resulting in about 100K recipes.\n9\n\nhttp://www.ons.gov.uk/ons/dcp171778_290982.pdf\nSee https://en.wikipedia.org/wiki/Ethiopian_cuisine#Traditional_ingredients\nhttps://en.wikipedia.org/wiki/North_African_cuisine\n\n10\n\n5\n\nand\n\n\fNorth America\n\nLatin America\n\nWestern Europe\n\nEastern Europe\n\nMiddle East\n\nAfrica\n\nSouth Asia\n\nEast Asia\n\nOceania\n\nIranian\nLebanese\n\nChinese\n\nArab\nItalian\nMediterranean\nArmenian\nSicilian\nItalian-American\nTurkish\nSyrian Egyptian\nGreek\nSwiss\nIsraeli\nHungarian\nCajun\nAustralian\nBulgarian\nBasque\nLouisiana\nMoroccan\nTunisian\nCornish\nBritish\nCanadian\nSpanish\nPolish\nPortuguese\nEthiopian\nBerber\nCroatian\nAfrican\nDutch\nAmerican\nRomanianChilean\nIcelandic\nIndian\nJamaican\nPeruvian\nPunjabi\nSaint-Lucian\nColombian\nUkrainianWelsh\nBengali\nOceanic\nMexican\nCaribbean\nRussian\nCuban\nAztec\nSri-Lankan\nBelgianEnglish\nBrazilian\nLatin-American\n\nAsian\nJapanese\n\nGerman Austrian\nScottish\nDanish\nSwedish\nFinnish\nNorwegian\n\nHungarian\nSpanish\nLao\nCantonese\nLouisiana Mexican\nItalian-American\nChilean\nPeruvian\nMongolian\nLatin-American\nIndian\nCajun\nCuban\nMediterranean\nSwiss\nTunisian\nCaribbean\nJamaican\nAmerican\nPhilippine\nEthiopian\nBerber\nCanadian\nAfrican\nPortuguese\nItalian\nIsraeli Cornish\nAustralian\nBasqueBrazilian\nBulgarian BritishMoroccan\nEnglish\nFinnish\nUkrainian\nSicilian\nHong\nIrish\nColombian\nOceanic\nBelgian\nAustrian\nNorwegian\nLebanese ArabArmenian\nGreek Dutch\nGerman\nScottish\nCroatian\nSwedish\nEgyptian\nIranian\nRomanian\nDanish\nTurkish Polish\nRussian\nFrench\n\nCambodian\nLao\n\nJapanese\n\nThai\n\nVietnamese\nMalaysian\n\nWelsh\n\nFrench\nIrish\nMaltese\n\nIndonesian\nKorean\n\nMalaysian\nVietnamese\nKorean Philippine\nThai\nTaiwanese Mongolian\nIndonesian\nHong\nAsian\nCantonese\nChinese\n\n(b) Flavor-based similarity\n\n(a) Ingredient-based similarity\n\nFigure 6: Graph of similarity between different cuisines in terms of their ingredients and flavors. Each cuisine is linked with five\nmost similar ones. Color of a cuisines denote the geographical region it resides in.\n• Region Prediction: Each recipe is labeled according to one\nof the 9 geographical regions where its cuisine belongs to.\nThe regions are considered the same as in Section 4. This\nresults to have about 157K recipes.\n\nSVM\n\nFor multi-class classification with SVM, we use linear kernel\nwith one vs. rest coding. The class imbalance problem is resolved\nwith adjusting the weight of each cuisine inversely proportional\nto its frequency. The implementation is done using Scikit-learn\nmachine learning library in python [4]. For DNN, we use Keras\ndeep learning library [6] and create four dense hidden layers and\na softmax output layer. Each of the first two hidden layers consists of 1000 neurons, and the two last ones each have 500 neurons.\nDropout regularization [21] is used for all of the hidden layers. We\nuse Adadelta [26] with default parameters as the optimizer. For\nboth methods we take 80% of the data as training set and the remaining 20% as the test set. The prediction performance of both\nmethods are evaluated under accuracy and F-measure.\nFigure 7 shows the results with both SVM and DNN, Figure 7a\nillustrates those for cuisine prediction, while Figure 7b the region\nprediction task. The DNN model performs about 24% better than\nSVM for cuisine prediction task under accuracy and over 13% better under F-measure. For region prediction task, since the number of classes are much fewer than cuisine prediction, both methods performed relatively better. In this case, the accuracy and Fmeasure achieved by the DNN model is about 12% and 9% better\nrelative to those achieved by SVM, respectively.\nAiming to shed light on the similarity of recipes in different regions, we use the confusion matrix of the DNN model for region\npredictions in Table 1. Each region name is abbreviated in two\nletters, e.g., LA denotes Latin American and AF African cuisines.\nThe number of correctly classified recipes are shown in bold and\nfor each class, the greatest number of miss-classifications is shown\nin red. This table clearly demonstrates that almost all of the miss-\n\nDNN\n\nSVM\n\n0.75\n\n0.75\n\n0.70\n\n0.70\n\n0.65\n\n0.65\n\n0.60\n\n0.60\n\n0.55\n\n0.55\n\n0.50\n\n0.50\n\n0.45\n\n0.45\n\n0.40\n\nDNN\n\n0.40\nAcc\n(a) Cuisine Prediction\n\nF1\n\nAcc\n\nF1\n\n(b) Region Prediction\n\nFigure 7: The prediction performance of different methods for\ncuisine and region prediction tasks.\nclassifications fall under Western European. This is probably due to\nthe huge ethnic composition of Western European countries which\nresulted in the diversity of culinary cultures of that region. The table shows that for some regions like Southern and Eastern Asian,\nthe number of miss-classified recipes are somewhat low relative to\nthe correctly classified ones. This result is analogous to Figure 6a\nin which these regions were almost disconnected from the others.\nOn the other hand, for some cuisines like Oceanic, Eastern European, and Northern America, the number of miss-classifications are\nrelatively high, mostly with Western European. This is due to the\nfact that the cultures in these regions are very similar to each other,\nmainly due to the common ethnics and history.\n\n6.\n\nHEALTH AND NUTRITION\n\nIn this section, we investigate the relation between the nutrition\nvalues of the recipes associated with countries and their hard mea6\n\n\f10\n\nAverage Diabetes\n\nAverage Obesity\n\n25\n20\n15\n\nCarbohydrate\nCalorie\nFat\nProtein\nSugar\n\n10\n5\n0\n\n10\n\n20\n\n30\n\n40\n\n50\n\n8\nCarbohydrate\nCalorie\nFat\nProtein\nSugar\n\n6\n\n60\n\n0\n\n10\n\n20\n\n30\n\n40\n\n50\n\n60\n\nAverage Health Expenditure\n\n30\n10\n\n8\nCarbohydrate\nCalorie\nFat\nProtein\nSugar\n\n6\n\n4\n\n2\n\n0\n\n10\n\n20\n\n30\n\n40\n\nFigure 8: Average health measures of bottom-k countries, based on nutrition values in their recipes. The values on x-axis indicate\ndifferent values of k. As the value of k increases, the countries with higher amounts of nutrition values contribute to the average.\n\nTable 1: Confusion Matrix for DNN Region Prediction\n\nTable 2: Correlation of Different Health Measures with Nutrition Values of Recipes\n\nActual Class\n\nPrediction Outcome\n\nLA\nSA\nOC\nEA\nAF\nWE\nME\nEE\nNA\n\nLA\n\nSA\n\nOC\n\nEA\n\nAF\n\nWE\n\nME\n\nEE\n\nNA\n\n1888\n18\n21\n49\n31\n453\n35\n51\n127\n\n15\n961\n2\n37\n23\n49\n24\n30\n7\n\n2\n1\n177\n2\n2\n21\n9\n1\n5\n\n84\n52\n21\n5211\n28\n660\n107\n58\n128\n\n25\n16\n3\n13\n704\n85\n72\n29\n22\n\n455\n40\n119\n342\n136\n9430\n366\n885\n1045\n\n13\n17\n5\n26\n57\n165\n634\n41\n16\n\n33\n5\n6\n24\n7\n541\n78\n1320\n60\n\n92\n3\n18\n51\n15\n557\n17\n94\n1508\n\nCorrelation Values\n\nsures of health, including obesity rate, diabetes rate and health expenditure. Similar to Section 3, we map cuisines to countries by\nassigning all the recipes of those cuisines that relates to a specific\ncountry. Afterwards, we calculate the average calorie, protein, fat,\ncarbohydrate and sugar values for each country over its recipes,\nweighted by user provided ratings as a measure of recipe popularity. Then, we calculated the correlations between average nutrition\nvalues and health measures. Pearson correlation, which captures\nthe linear correlation between the two variables, and Kendall-Tau\ncorrelation, which measures the ordinal correlation, have been used\nfor this task. The result is presented in Table 2. As the results suggest, nutrition values show a significant correlation with the health\nrelated measures of countries. The dominant positively correlated\nnutrients are the sugar and carbohydrate. It is intuitive because\nthose are the main elements of snack meals like cakes, creams, etc\nwhich can contribute to the health difficulties and the consequence\nexpenditures eventually. On the other hand, protein value shows\nstrong negative correlation with the level of obesity and diabetes in\ncountries. Noticeably, the positive impact of high-protein diets on\nlosing weight is frequently studied in the literature [10].\nFigure 8 exhibits the relationship between the nutrients and health\nmeasures from a different perspective. In Figure 8a, the average\nobesity of the k countries intaking the least amounts of different nutrients (shown in different colors and line-styles) is plotted against\nthe value of k. The same is shown for diabetes and health expenditure in Figures 8b and 8c, respectively. The trend of the diagrams\nendorses that including the countries with higher average nutrition\nvalues (except protein) results in an increase in the average health\nmeasures (e.g. average obesity). Proteins show completely opposite patterns as expected. Including the countries with higher protein diets decreases the rate of health difficulties (e.g. obesity or\ndiabetes). A noticeable trait in both Table 2 and Figure 8 is that the\n\nHealth Measure\n\nNutrient\n\nPearson\n\nKendall-Tao\n\nObesity\n\nCalorie\nProtein\nFat\nCarbohydrate\nSugar\n\n−0.104\n−0.483\n−0.115\n0.300\n0.461\n\n−0.110\n−0.299\n−0.127\n0.201\n0.293\n\nDiabetes\n\nCalorie\nProtein\nFat\nCarbohydrate\nSugar\n\n−0.077\n−0.162\n−0.123\n0.173\n0.142\n\n−0.048\n−0.022\n−0.063\n0.106\n0.066\n\nHealth Expend.\n\nCalorie\nProtein\nFat\nCarbohydrate\nSugar\n\n0.098\n−0.083\n0.197\n−0.064\n0.134\n\n0.110\n−0.022\n0.141\n−0.015\n0.069\n\ncorrelations and trends are more highlighted in the obesity results\nrather than the diabetes and health expenditure. The reason is that\nthe diabetes and health expenditure are more elaborate phenomena than the obesity. For example, in addition to consuming foods,\nthere are a variety of other genetic and environmental factors that\nmay cause the diabetes. Remarkably, the genetic susceptibility of\ndifferent ethnics varies so much [8]. As another example, over intaking of proteins itself can lead to an spectrum of adverse effects\n[7]. Therefore the relation of protein intaking and health expenditures of the countries is not as clear as the relation between obesity\nand proteins.\n\n7.\n\nRELATED WORK\n\nRecently, public health has been increasingly analyzed through\nthe lens of the web and social media. We refer the reader to [5]\nfor an overview of the recent research in this area. Abbar et al. [1]\nrelate food mentions on Twitter conversations to the obesity and diabetes rates, using caloric values, and find a high correlation (coefficient 0.77) between caloric values of tweets and obesity values in\nvarious states in the US. Low-obesity areas of USA have also been\nshown to be more socially active on Instagram (posting comments\nand likes) than those from high-obesity ones by Mejova et al. [16],\nwho present a large-scale analysis of pictures taken at 164K restaurants in the US. Silva et al. [20] identify cultural boundaries and\n7\n\n\fsimilarities across populations at different scales based on the analysis of Foursquare check-ins.\nAhn et al. [2] study culture-specific ingredient connections, creating a “flavor network” from a dataset of about 56K recipes and\nrelating them to the geographical groupings of countries. Similar “flavor-based” food pairing studies are conducted on cuisines\nin distinct geographical areas such as India [11]. West et al. [25]\nmine logs of recipe-related queries to uncover temporal patterns in\nconsumption. Using Fourier transforms, they show the yearly and\nweekly periodicity in food “density” of the searched recipes, with\ndifferent trends in Southern and Northern hemispheres, suggesting\na link between food selection and climate. A study of Austrian\nrecipe sites by Wagner et al. [23] also highlights differences in the\nrecipes of regions which are further apart. Zhu et al. [27] conduct a similar study on Chinese recipes to investigate the effect of\ngeographical and climatic proximities on ingredients similarity of\ndomestic cuisines.\nKular et al. [14] create a network of recipes using a dataset of 300\nrecipes from 15 different countries, and show the network’s smallworld and scale-free properties. As opposed to this line of work,\nwe also exploit flavor and nutritional information, alongside health\nstatistics countries to provide a deeper analysis about the dishes,\ncuisines, culinary cultures, and the impact of food on human life.\nSu et al. [22] investigate underlying connections between cuisines\nand ingredients via machine learning classification, with an application to predicting the cuisine by looking at recipes. Like our\nanalysis, theirs is based on a large-scale data collection of recipes—\nspecifically, 226K recipes collected from food.com. However, they\nonly look at classifying cuisines using Support Vector Machine\n(SVM), while we propose a deep neural network architecture to\ncapture the highly non-linear relation of a recipe cuisine and its associated ingredients. The results approve that the proposed deep\nmodel outperforms SVM by a significant margin in terms of prediction accuracy and F-measure.\nThere are major differences between our work and the ones discussed above, in both scale and domain. An important characteristic of our work comes from the size and the quality of the various\ndatasets we used, which enable us to derive first-of-its-kind insight\non worldwide cuisines and their relationship to health factors. In\naddition to the ingredients, we also exploited flavor and nutritional\ninformation, alongside health and immigration statistics, allowing\nus to perform a deeper analysis of the dishes, cuisines, culinary\ncultures, as well as the impact of food on human life.\n\n8.\n\nbetween ingredients and health conditions, such as diabetes, can be\nvery useful to public health experts, where behavior nudges or recommendation of similar dishes in flavor and ingredient complexity\ncan be utilized to improve dietary intake [19, 9].\nIn future work, we plan to explore the possibility of recipe recommendation based on regional and personal tastes and user ratings. This is important as a local Chinese dish or a distinct flavor\ncombination may be “alien” to, e.g., a Western person, but of interest to a Japanese individual. We also wish to asses the ability to\nmodel flavors with ingredients, and discover ingredients to match\na specific flavor palette. Finding answers to these questions would\nprovide a better understanding of the composition of flavors and\ningredients in popular dishes and provide a better recommendation\nsystem for a healthier, tastier, and more diverse experience.\n\n9.\n\nREFERENCES\n\n[1] S. Abbar, Y. Mejova, and I. Weber. You tweet what you eat:\nStudying food consumption through Twitter. In Proceedings\nof the 33rd Annual ACM Conference on Human Factors in\nComputing Systems, pages 3197–3206, 2015.\n[2] Y.-Y. Ahn, S. E. Ahnert, J. P. Bagrow, and A.-L. Barabási.\nFlavor network and the principles of food pairing. Nature\nScientific reports, 2011.\n[3] B. Armstrong and R. Doll. Environmental factors and cancer\nincidence and mortality in different countries, with special\nreference to dietary practices. International journal of\ncancer, 15(4):617–631, 1975.\n[4] L. Buitinck, G. Louppe, M. Blondel, F. Pedregosa,\nA. Mueller, O. Grisel, V. Niculae, P. Prettenhofer,\nA. Gramfort, J. Grobler, R. Layton, J. VanderPlas, A. Joly,\nB. Holt, and G. Varoquaux. API design for machine learning\nsoftware: experiences from the scikit-learn project. In ECML\nPKDD Workshop: Languages for Data Mining and Machine\nLearning, pages 108–122, 2013.\n[5] D. Capurro, K. Cole, M. I. Echavarría, J. Joe, T. Neogi, and\nA. M. Turner. The use of social networking sites for public\nhealth practice and research: a systematic review. Journal of\nmedical Internet research, 16(3):e79, 2014.\n[6] F. Chollet. Keras. https://github.com/fchollet/keras, 2015.\n[7] I. Delimaris. Adverse effects associated with protein intake\nabove the recommended dietary allowance for adults. ISRN\nnutrition, 2013, 2013.\n[8] S. C. Elbein. Genetics factors contributing to type 2 diabetes\nacross ethnicities. Journal of diabetes science and\ntechnology, 3(4):685–689, 2009.\n[9] G. D. Foster, A. P. Makris, and B. A. Bailer. Behavioral\ntreatment of obesity. The American journal of clinical\nnutrition, 82(1):230S–235S, 2005.\n[10] T. L. Halton and F. B. Hu. The effects of high protein diets\non thermogenesis, satiety and weight loss: a critical review.\nJournal of the American College of Nutrition,\n23(5):373–385, 2004.\n[11] A. Jain, N. Rakhi, and G. Bagler. Analysis of food pairing in\nregional cuisines of india. PloS one, 10(10):e0139539, 2015.\n[12] A. Keys, A. Mienotti, M. J. Karvonen, C. Aravanis,\nH. Blackburn, R. Buzina, B. Djordjevic, A. Dontas,\nF. Fidanza, M. H. Keys, et al. The diet and 15-year death rate\nin the seven countries study. American journal of\nepidemiology, 124(6):903–915, 1986.\n[13] M. Kratz, T. Baars, and S. Guyenet. The relationship\nbetween high-fat dairy consumption and obesity,\n\nCONCLUSION\n\nThis paper presented a large-scale study of user-generated recipes\non the web, their ingredients, nutrition, similarities across countries, and their relation with country health statistics. Our results\nhave multiple implications: we found strong similarities between\ncuisines in neighboring countries, yet, the diversity of ingredients\nand flavors varies largely across the continents, mostly affected by\nnet migration trends. We found quantitative evidence of a strong\ncorrelation between nutrition information of the recipes (e.g., in\nterms of sugar intake) and obesity. Also, we demonstrated that deep\nlearning can be used to effectively predicting cuisines from ingredients, potentially providing possibility for fine-grained analysis of\nfood and dishes as well as improved recipe recommendations based\non individuals’ profile.\nOur findings indicate that certain ingredients (e.g., mozzarella)\nuniquely represent a certain cuisine (e.g., Italian) and there are\nstrong clusters of ingredients across neighboring countries. This\nfeature eases the prediction of regions (e.g., continents) from the\ncombination of ingredients in a cuisine. Moreover, the correlation\n8\n\n\f[14]\n\n[15]\n\n[16]\n\n[17]\n\n[18]\n[19]\n[20]\n\ncardiovascular, and metabolic disease. European journal of\nnutrition, 52(1):1–24, 2013.\nD. K. Kular, R. Menezes, and E. Ribeiro. Using network\nanalysis to understand the relation between cuisine and\nculture. In Network Science Workshop (NSW), 2011 IEEE,\npages 38–45, 2011.\nY. Mejova, S. Abbar, and H. Haddadi. Fetishizing food in\ndigital age:# foodporn around the world. In International\nAAAI Conference on Web and Social Media (ICWSM 2016),\n2016.\nY. Mejova, H. Haddadi, A. Noulas, and I. Weber. #FoodPorn:\nObesity patterns in culinary interactions. In Proceedings of\nthe 5th International Conference on Digital Health 2015,\npages 51–58, 2015.\nM. Michel de Lorgeril, P. Salen, J.-L. Martin, I. Monjaud,\nJ. Delaye, and N. Mamelle. Mediterranean diet, traditional\nrisk factors, and the rate of cardiovascular complications\nafter myocardial infarction. Heart failure, 11:6, 1999.\nA. Noack. Modularity clustering is force-directed layout.\nPhys. Rev. E, 79:026102, Feb 2009.\nN. Regulating. Judging nudging: can nudging improve\npopulation health? Bmj, 342:263, 2011.\nT. Silva, P. Vaz De Melo, J. Almeida, M. Musolesi, and\nA. Louriero. You are What you Eat (and Drink): Identifying\nCultural Boundaries by Analyzing Food & Drink Habits in\nFoursquare. In Proceedings of the 8th AAAI International\nConference on Weblogs and Social Media (ICWSM’14), Ann\nArbor, Michigan, USA, June 2014.\n\n[21] N. Srivastava, G. E. Hinton, A. Krizhevsky, I. Sutskever, and\nR. Salakhutdinov. Dropout: a simple way to prevent neural\nnetworks from overfitting. Journal of Machine Learning\nResearch, 15(1):1929–1958, 2014.\n[22] H. Su, T.-W. Lin, C.-T. Li, M.-K. Shan, and J. Chang.\nAutomatic recipe cuisine classification by ingredients. In\nProceedings of the 2014 ACM Joint Conference on Pervasive\nand Ubiquitous Computing, pages 565–570, 2014.\n[23] C. Wagner, P. Singer, and M. Strohmaier. Spatial and\nTemporal Patterns of Online Food Preferences. In\nProceedings of the Companion Publication of the 23rd\nInternational Conference on World Wide Web Companion,\nWWW Companion ’14, pages 553–554. International World\nWide Web Conferences Steering Committee, 2014.\n[24] L. Waltman, N. J. van Eck, and E. C. Noyons. A unified\napproach to mapping and clustering of bibliometric\nnetworks. Journal of Informetrics, 4(4):629–635, 2010.\n[25] R. West, R. W. White, and E. Horvitz. From cookies to\ncooks: insights on dietary patterns via analysis of web usage\nlogs. In WWW, 2013.\n[26] M. D. Zeiler. Adadelta: an adaptive learning rate method.\narXiv preprint arXiv:1212.5701, 2012.\n[27] Y.-X. Zhu, J. Huang, Z.-K. Zhang, Q.-M. Zhang, T. Zhou,\nand Y.-Y. Ahn. Geography and similarity of regional cuisines\nin china. PloS one, 8(11):e79161, 2013.\n\n9\n\n\f",
         "train",
         "48815",
         "7568"
        ],
        [
         "18",
         "18111",
         "cs.AI",
         "Artificial Intelligence",
         "1801.04134v2.pdf",
         "Deep Episodic Memory: Encoding, Recalling, and Predicting\nEpisodic Experiences for Robot Action Execution\n\narXiv:1801.04134v2 [cs.AI] 28 Feb 2018\n\nJonas Rothfuss∗† , Fabio Ferreira∗† , Eren Erdal Aksoy ‡ , You Zhou† , and Tamim Asfour†\nAbstract— We present a novel deep neural network architecture for representing robot experiences in an episodic-like\nmemory which facilitates encoding, recalling, and predicting\naction experiences. Our proposed unsupervised deep episodic\nmemory model 1) encodes observed actions in a latent vector\nspace and, based on this latent encoding, 2) infers most\nsimilar episodes previously experienced, 3) reconstructs original\nepisodes, and 4) predicts future frames in an end-to-end fashion.\nResults show that conceptually similar actions are mapped\ninto the same region of the latent vector space. Based on\nthese results, we introduce an action matching and retrieval\nmechanism, benchmark its performance on two large-scale action datasets, 20BN-something-something and ActivityNet and\nevaluate its generalization capability in a real-world scenario\non a humanoid robot.\n\nFig. 1: The ARMAR-IIIa humanoid robot recalling previous\nvisual episodes in a kitchen scene.\n\nI. I NTRODUCTION\nHumans are ingenious: We have unique abilities to predict\nthe consequences of observed actions, remember the most\nrelevant experiences from the past, and transfer knowledge\nfrom previous observations in order to adapt to novel situations. The episodic memory which encodes contextual,\nspatial and temporal experiences during development plays\na vital role to introduce such cognitive abilities in humans.\nA core challenge in cognitive robotics are compact and\ngeneralizable mechanisms which allow for encoding, storing\nand retrieving spatio-temporal patterns of visual observations. Such mechanisms would enable robots to build a\nmemory system, allowing them to efficiently store gained\nknowledge from past experiences and both recalling and\napplying such knowledge in new situations. Inspired by\ninfants that learn by observing and memorizing what adults\ndo in the same visual setting, we investigate in this paper\nhow to extend cognitive abilities of robots to autonomously\ninfer the most probable behavior and ultimately adapt it to\nthe current scene. Considering the situation of the humanoid\nrobot ARMAR-IIIa standing in front of a table with a juice\ncarton (see Fig. 1) one can ask what the most suitable action\nis and how it would best be performed.\nTo achieve this goal, we introduce a novel deep neural\nnetwork architecture for encoding, storing, and recalling past\naction experiences in an episodic memory-like manner. The\nproposed deep network encodes observed action episodes\nin a lower-dimensional latent space. Such a formulation in\nThe research leading to these results has received funding from the\nEuropean Unions Horizon 2020 Research and Innovation programme under\ngrant agreement No 641100 (TIMESTORM).\n† Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany.\n‡ School of Information Technology, Halmstad University, Sweden\n∗ Authors contributed equally to this work\n\nthe latent space allows robots to store visual experiences,\ncompare them based on their conceptual similarities and retrieve the most similar episodes to the query scene or action.\nFurther, the same network leads to predict and generate the\nnext possible frames of a currently observed action.\nTo the best of our knowledge, this is the first study introducing that cognitive abilities concerning action representing, storing, memorizing, and predicting can be seamlessly\nachieved in a single coherent framework.\nWe hypothesize that latent subsymbolic encodings that\nour network generates from visual observations are rich and\ndescriptive enough to be compared with those collected from\npreviously experienced episodes.\nIn this way, ARMAR-IIIa can trace all previous observations and select the most similar episode (e. g. “pushing\nthe juice” or “grasping the juice”) in the latent space. The\nrobot can further generate similar behavior by adapting to\nnew situations based on memorized action representations.\nContribution: The contribution of this work is manifold:\n(1) We implement a new deep network to encode action\nframes into a low-dimensional latent vector space. (2) Such a\nvector representation is used to reconstruct the action frames\nin an auto-encoder manner. (3) We show that the same\nlatent vectors can also be employed to predict future action\nframes. (4) We introduce a mechanism for matching and\nretrieving visual episodes and provide an evaluation of the\nproposed method on two different well-known action largescale datasets. (5) Finally, we demonstrate the possible application of our approach on the humanoid robot ARMAR-IIIa.\nII. R ELATED W ORK\nWe discuss related work from two relevant perspectives:\nthe role of episodic memories in cognitive architectures and\n\n\faction understanding based on deep learning approaches.\nA. Episodic Memory and Cognitive Architectures\nIn contrast to working memory where the information is\ntemporarily stored for a finite length of time, the long-term\nmemory holds the innate knowledge that enables operation\nof the system and facilitates learning. The episodic memory,\nconsidered as a part of the long-term memory, persists instances of past experiences which can be retrieved to support\nplanning and inference [1]. Hereby, the persisted experiences\ncan be represented in manifold ways. Reinforcement learning\nbased architectures implement memories to store and retrieve\naction episodes [2], [3]. A different approach is to persist\ninstances of the working memory that were involved in\nsolving a specific problem and subsequently retrieve previous\nsolutions from the episodic memory. Thereby, planning can\nbe enhanced and even facilitate one-shot learning capabilities [4]–[9]. Predominantly, instances stored in the episodic\nmemory are symbolic high-level representations [7], [10].\nWhen restricted to a specific context, symbolic representations and pre-specified perceptual instances stored in an\nepisodic memory can indeed be a powerful approach for\nenhancing the reasoning capabilities of a cognitive system,\nas shown in Soar [4]. However, most of the described\napproaches are customized to a specific problem domain\nand rely on pre-defined, problem specific representations\n[6], [10]. In complex real world scenarios transferring and\ngeneralizing knowledge persisted in the episodic memory\nis very limited when pre-defined symbolic representations\nare used. Accounting for nuances and fuzziness may require\ninterpolation between concepts, demanding more flexibility\nthan traditional declarative memory concepts. Our proposed\nepisodic memory, on the other hand, derives subsymbolic\nrepresentation of actions in a data driven manner and, hence,\nrequires no pre-defined information.\nAn approach towards an episodic-like memory of video\nscenes, based on subsymbolic representations, uses Fisher\nVectors of convolutional neural network (CNN) percepts\nto generate encodings of temporal video segments [11].\nAlthough the approach is able to match conceptually related\nvideo segments, it is not possible to reconstruct perceptual\ninformation from the Fisher Vector representations.\nB. Action Understanding with Deep Neural Nets\nMany deep neural network based approaches to understand\nhuman action videos combine CNNs and recurrent neural\nnetworks (RNNs) [12]–[14]. CNNs capture spatial information in each video frame and aggregate it into a higherlevel representation, which is then fed through a Long ShortTerm Memory (LSTM) that captures temporal information\nthroughout a sequence of frames. Instead of stacking an\nLSTM on top of a CNN, Shi et al. [15] combine the ideas\nof spatial weight sharing through convolution and temporal\nweight sharing through recurrence into a new model called\nconvolutional LSTMs (convLSTM).\nOverall, there are two main approaches with regard to deep\nlearning based action understanding: 1) Supervised learning\n\non activity recognition corpora [16]–[18] and 2) Unsupervised video frame prediction [19]–[22]. Latest models for\nactivity recognition involve spatial and temporal attention\nmechanisms [23], [24], temporal pooling [25] and long-range\ntemporal structure modelling [26].\nAside from human action recognition, the lack of comprehensively labelled video datasets makes supervised training\nchallenging. Another approach towards learning to understand videos is the future frame prediction. Given a sequence\nof video frames, a deep neural network is trained to predict\nthe next frame(s) in a video. To successfully predict future\nvideo frames, the network is forced to generate latent representations of the inherent structure and dynamics of videos.\nSrivastava et al. [14] present a composite model consisting\nof three LSTM networks, conceptually combining an autoencoder with future frame prediction. The first LSTM serves as\nan encoding network which creates a representation vector\nof a given video frame sequence. Taking this representation\nvector as input, one decoder network attempts to reconstruct\nthe frames that were given as input while another decoder\npredicts future frames. They show that the composite architecture outperforms both a pure autoencoder and future\nframe prediction model. However, since input and output\nspace are CNN features instead of raw video frames, their\nmodel is not able to recover the video frames from the latent\nrepresentation. Our approach is inspired by the composite\nencoder-decoder architecture but overcomes the described\ndrawback by being able to encode raw frames in an endto-end fashion and also reconstruct the raw frame sequence\nfrom the latent representation.\nSubsequent work aims to predict the pixel changes between the current and the next frame [20]–[22] instead\nof regressing directly into the RGB-pixel space. Another\napproach is generative modeling of video [27]. While such\nmodels are shown to be useful for semantic segmentation\n[21], planning robot motion [28] or generating videos [27]\ndo not create a representation of an episode that can later be\nreconstructed.\nIII. M ETHOD\nA. The Neural Network Model\nIn this section, we describe our neural network model\nand the methods applied for comparing and matching visual\nexperiences in the latent space. The network architecture is\nillustrated in Fig. 2.\nWe were inspired by the composite encoder-decoder architecture proposed in [14]. Our proposed model conceptually\ncombines an autoencoder with future frame prediction and\nconsists of one encoder and two decoders (see Fig. 2).\nIn this model, a visual experience is represented as a\nsequence of consecutive video frames X = Xr kXp =\nx1 , .., xk kxk+1 , ..., xn , wherein Xr is the first part of the\nframe sequence until frame xk and Xp represents the remaining n − k frames.\nThe encoder network E processes the sequence Xr =\nx1 , ..., xk and projects it into a latent vector space, yielding\n\n\fFig. 2: Structure of the proposed composite encoder-decoder network. It represents the shape of an unrolled network over\nmultiple time steps. The encoder E receives multiple video frames as input and maps them into a latent vector space. The\nresulting vector representation V (highlighted in red) is forwarded to the two decoder networks. The first decoder (Dr ) is\ntrained to reconstruct the video frames that were provided to the encoder while the second decoder (Dp ) attempts to predict\nthe future frames. The dashed box on the left depicts the layers of the encoder network. The label inside each layer denotes\nthe kernel size of the convolutional layer or the number of hidden units of the fully connected (fc) layer, respectively.\n\na representation of the given frame sequence as a single latent\nvector V as:\nV = E (Xr ) .\n(1)\nSubsequently, the vector V , indicated in red in Fig. 2,\nis forwarded to both decoders independently which receive\nthe latent vector representation as input and construct a\nsequence of video frames in return. The first decoder, i. e. the\nreconstruction-decoder Dr , attempts to recover the frames\nXr = x1 , .., xk that were initially provided to the encoder.\nTherefore, Dr is trained to output a frame sequence Yr =\ny1 , ..., yk that matches Xr , such that\nDr (V ) = Yr = y1 , ..., yk\n\n.\n\n(2)\n\nThe second decoder, the so-called prediction-decoder Dp ,\nattempts to predict the future frames Yp = yk+1 , ..., yn as,\nDp (V ) = Yp = yk+1 , ..., yn\n\n.\n\n(3)\n\nDuring training, Xp is employed as ground truth for\nassessing how good the predictions Yp are and for also computing the error. It is important to note that for determining\nthe reconstruction and prediction error during training, both\nimage sequences Xr and Xp are used. However, during test\ntime, only Xr is fed into the encoder network.\nThe core idea of the proposed network structure rests upon\nthe latent space vector V being the only linkage between\nE and both Dr and Dp . The two decoder networks solely\nrely on V as their only source of information to reconstruct\na given scene and predict future frames. To obtain robust\nreconstructions and future frame predictions, the encoder is\nforced to compress the entire video frame sequence Xr into\na comparably low-dimensional latent representation V and,\n\nat the same time, to preserve as much relevant information\nas possible. E and Dr together constitute an autoencoder\narchitecture, requiring that relevant information is preserved\nthroughout the network. However, this only involves remembering the frame sequence Xr but not necessarily requires\nto capture abstract concepts such as temporal dynamics of\nobjects or actors. By adding the frame predictor which has to\nextrapolate motions into the future, the encoder must capture\nhigher-level concepts like the scene dynamics in Xr and\nembed abstract concepts such as trajectories in V so that\nDp can properly infer possible future frames.\nThe input and output frames xi and yi used in this work\nhave a resolution of 128 × 128 pixels and 3 color channels.\nSince the main task of the network is to capture spatiotemporal concepts, we make use of convolutional LSTM cells\n[15]. The encoder network E is comprised of a stack of\nconvolution LSTM and normal convolution layers (henceforth referred to as convLSTM and conv layers) in alternating\norder (see Fig. 2). While the conv layers are operated with\na stride of 2 in order to reduce the spatial size of the\nfeature maps, the convLSTM layers preserve the spatial size\nand forward information to the next time step through their\nhidden state and cell state. After the alternating series of\nconv and convLSTM layers in the encoder, we add a fully\nconnected layer, followed by a fully connected LSTM layer\nf c LST M to the stack.\nWith f c LST M being the top layer of E and as LSTM\ncell connected over time, its cell state ci and hidden state\nhi represent the video frame sequence until the current time\nstep i. Once the entire frame sequence Xr = x1 , ..., xk is\nprocessed by the encoder, the hidden state hk and cell state ck\n\n\fof f c LST M at time step k are extracted and concatenated,\nyielding the latent vector V = hk kck .\nBoth decoders have the inverted structure of the encoder,\nmeaning that transposed convolution layers are used to\nincrease the spatial size of the feature maps throughout\nthe decoding layers until the full video frame resolution of\n128 × 128 is recovered.\nTo compute the error L during the network training, we\nuse a linear combination of image reconstruction loss (Lmse )\nand gradient difference loss (Lgd ) [19] functions as follows\nL = (1 − η) Lmse + η Lgd\n\n,\n\n(4)\n\nwhere we set η = 0.4 to trade off between the two loss\nfunctions\nn\n1X\nkyi − xi k22 , and\n(5)\nLmse =\nn i=1\nLgd =\n\nn\n1 XX\nk|xiu,v − xiu−1,v | − |yiu,v − yiu−1,v |k22 +\nn i=1 u,v\n(6)\n\nk|xiu,v−1 − xiu,v | − |yiu,v−1 − yiu,v |k22\n\n.\n\nThe loss is computed over all ground truth frames xi in\nX = Xr kXp and the output frames yi in Y = Yr kYp which\nare produced by Dr and Dp . The reconstruction loss Lmse\ncompares the generated images yi and ground truth images\nxi in a pixel wise manner. When solely trained with Lmse\nloss, neural network models that regress on images are prone\nto linear blurring and unstable to small image deformations\n[12]. In contrast, the Lgd loss compares the horizontal and\nvertical image gradients of xi and yi , thereby penalizing\nblurriness and enforcing sharper edges [19].\nThe described neural network is trained with mini-batch\ngradient decent using the adaptive learning rate method\nADAM [29] in conjunction with an exponentially decaying\nlearning rate schedule. After each network layer except the\nlast encoder and decoder layer (since these are the output\nlayers), we use layer normalization [30] and dropout with a\ndropout rate between 10% and 20%. In order to force the\nencoder to use the entire latent vector space and produce\ndistinct representations V , we add Gaussian noise N (0, σ)\nwith σ = 0.1 to the latent vector V during the training,\nbefore forwarding V to the decoder networks. In all of our\nexperiments, the vector V has a dimension of 2000.\nThe source code and experimental data are publicly available on the supplementary web page1 .\nB. Matching Visual Experiences in the Latent Space\nOne of the central contributions of our work is to compare\nvisual experiences based on their conceptual similarities\nencoded in the latent space. Given a new visual experience,\nwe can retrieve the most similar episodes from the episodic\nmemory that holds the hidden representations Vi of episodes\nexperienced in the past. We use the cosine similarity\ncos(V, V 0 ) =\n\nV ·V0\n||V || · ||V 0 ||\n\n1 h2t-projects.webarchiv.kit.edu/projects/episodicmemory\n\n(7)\n\nto measure the similarity of latent vectors. To find the best\nmatches in the latent space, we compute the cosine similarity\ncos(Vq , Vi ) between the query representation Vq and each\nof the Vi in the memory. Finally, the n memory instances\ncorresponding to the Vi with the highest cosine similarity are\nretrieved from the memory 2 .\nIV. E XPERIMENTAL E VALUATION\nWe evaluate the hypothesis that the encoder-decoder network creates latent representations that embed the inherent\ndynamics and concepts of a provided visual episode.\nFor this purpose, we train the neural network in an\nunsupervised fashion on two video datasets and analyze the\nsimilarity structure within the latent space. We assess the\nmodel’s abilities to reconstruct the past episode from the\nlatent representation and predict future frames. Subsequently,\nwe benchmark the proposed matching / retrieval mechanism\nagainst other state-of-the art approaches and test its robustness in a robotic application.\nA. Datasets\nFor the evaluation of our methods we use the largescale labeled video datasets ActivityNet [17] and 20BNsomething-something (from now on referred to as 20BN)\n[31]. We favored these two datasets over other popular\ndatasets like UCF-101 [16] and HMDB-51 [18] since our\nemphasis is reasoning, planning and executing of robotic\ntasks in indoor household environment rather than understanding outdoor activities. The ActivityNet dataset [17],\na benchmarking corpus for human activity understanding,\nconsists of 10, 024 training and 4926 validation video snippets collected from YouTube. It is organized in 93 higher\nlevel categories that comprise 203 different activity classes\ninvolving activities such as household work, sports and\npersonal care.\nWhile ActivityNet targets higher-level concepts like “vacuuming the floor” and “shovelling snow” that embed semantic\nmeaning, the 20BN dataset focuses on detailed physical\nproperties of actions and scenes. It contains 174 classes\nsuch as “Pushing something from left to right” and “Putting\nsomething into something”. The core challenge of this novel\ndataset is that the type of involved objects as well as the\nbackground setting of a given scene only play a neglectable\nrole. Rather than recognizing familiar items and scene backgrounds, the neural network needs to understand the physical\ncomposition and motion within the video clips. The dataset\nconsists of 86, 017 training and 11, 522 validation videos in\ntotal.\nB. Training\nWe train the neural network on the respective training split\nof the ActivityNet (actNet) and 20BN dataset. Both models\nare trained with n = 10 frames per video (selected equally\nspaced). The first k = 5 frames are fed into the encoder\nE to be reconstructed by Dr while the last five frames are\nemployed as ground truth for the future frame predictor Dp .\n2 For large episodic memories we recommend approximate nearest neighbor search methods such as k-d trees.\n\n\fC. Conceptual Similarity and Proximity in the Latent Space\nTo examine our hypothesis that conceptually similar\nvideos are mapped into the same region of the latent space,\nwe compute the pairwise cosine similarities (see section IIIB) of latent vectors. To measure the conceptual similarity,\nwe use the class labels provided in the datasets as the proxy\nvalue and assume that videos belonging to the same class are\nconceptually similar. We generate the latent representation\nfor each video in the validation split of both ActivityNet and\n20BN datasets and subsequently compute all pairwise cosine\nsimilarities between the latent vectors.\nIn Fig. 3, the results are visualized as similarity matrices\nwhere each row and column of a matrix corresponds to\na class label and each entry represents the mean pairwise\ncosine similarity between the latent vectors belonging to the\nrespective classes. The class labels are arranged horizontally\nand vertically in the same order, ensuring that the diagonal\nelements of the matrix depict intra-class similarities and offdiagonals represent inter-class similarities. Due to lack of\nspace, full similarity matrices with class labels are only\nprovided on our supplementary website1 . Fig. 3 shows that\nin each matrix the intra-class similarity (diagonal elements)\nis considerably higher than the inter-class similarity. This\nis a clear indication that conceptual similarity of videos is\nreflected by the proximity of their vector representations in\nthe latent space. Consequently, our proposed model captures\nhigh-level action concepts within two different datasets,\nalthough the model is trained in an unsupervised fashion\nand thus has never seen any class labels.\nSince the latent representation must embed all information for the decoders necessary to reconstruct and predict\nframes, it may also encode many details (e. g. colors and\nshapes) in the background that are irrelevant for describing actions. To compile the information embedded in the\nlatent representation to a subset that is more relevant for\noptimally separating the different classes within the latent\nspace, we apply principal component analysis (PCA) on\nthe mean latent vectors of each class. We assume that\nless important features are identically distributed in all the\nclasses and thus share approximately the same mean value\nwhen averaged over the class. Hence, transforming the latent\nspace towards the principal components computed on the\ncovariance matrix of the mean vectors emphasizes relevant\nfeatures and neutralizes less important features. Fig. 3b and\n3d show that transforming the latent representations with\nPCA leads to a better distribution of latent vectors, pushing\nconceptually similar representations closer together while\nkeeping representations of different classes farther apart.\nD. Frame Reconstruction and Future Frame Prediction\nBy reconstructing video frames and predicting upcoming\nframes, the network resembles episodic memory-like capabilities. Fig. 4 depicts generated video frame sequences from\nboth ActivityNet and 20BN for a qualitative assessment.\nTo evaluate the quality of the reconstructed and predicted\nframes, we compute the Peak-Signal-to-Noise-Ratio (PSNR)\nbetween the original frames X and generated frames Y\n\n(a) latent vector V\n\n(b) 200 PCA components\n\n(c) latent vector V\n\n(d) 200 PCA components\n\nFig. 3: Cosine similarity matrices for ActivityNet (top) (93×\n93) and 20BN (bottom) (174 × 174). PCA (right column)\nyields a more favorable distribution in the latent space.\n\nas proposed in [19]. Fig. 5 depicts the PSNR for each of\nthe 5 reconstructed and predicted frames, averaged over\nthe validation split of both datasets. Results indicate that\nthe reconstruction quality is significantly higher than the\nquality of the predicted frames. Also, the PSNR is roughly\nconstant throughout the reconstructed frames whereas for the\npredicted future frames it decreases over time. The expected\ndecline in prediction quality is very much due to the increase\nin the uncertainty about the future over successive time steps.\nE. Matching and Retrieving Visual Episodes\nTo investigate the matching and retrieval of visual episodes\nintroduced in section III-B, we compare our approach to\nstandard baselines as well as state-of-the-art action descriptors. The benchmarking comprises Fisher vector encodings\nof CNN, SIFT and STIP features as well as LSTM encodings\nto represent and match visual experiences.\nAs proposed in [11], we compute Fisher Vectors based on\nGMMs in order to create a visual vocabulary from CNN\nfeatures of the video frames. In particular, we select 5\nequidistant frames from the videos and compute VGG-fc1\n[32] as well as ResNet-50 [33] features. Furthermore, we\ncompare our approach against the composite LSTM network\nintroduced in [14]. We train their LSTM network using\nVGG-FC1 and ResNet-50 features. In all our experiments\nwe used the default parameters coming with the publicly\navailable source codes.\nTo quantitatively benchmark our approach against the\nbaselines, we phrase the matching and retrieval of memorized episodes as a document retrieval problem. Thereby,\nwe assume that a retrieved episode is only relevant if\nit originates from the same action category as the query\nepisode. For evaluating the performance of retrieving relevant\nvisual episodes, we report the precision of the first match\n\n\fOriginal\n\nGenerated\n\nOriginal\n\nGenerated\nreconstruction\n\nfuture prediction\n\nFig. 4: Frame reconstruction and future frame prediction of our model compared to the original frame sequence. Top:\nValidation sample from ActivityNet. Bottom: Validation sample (pulling sth. from right to left) from 20BN.\nTABLE I: Benchmark results showing the matching and\nretrieving performance of our approach against the baselines.\nWe report the precision for the first match and the mean\naverage precision (mAP) for retrieving the 3 closest matches.\nFisher Vectors are abbreviated to FV.\n\nFig. 5: Peak-Signal-to-Noise-Ratio (PSNR) for each of the 5\nreconstructed and predicted frames generated by the 20BN\n(shown in green) and actNet (shown in orange) model\naveraged over the entire validation dataset.\n\nand the mean average precision (mAP). Since the setting is\npurely unsupervised, the precisions reported in this context\nare not to be confused with precisions for a classification\ntask. Overall, we use the ActivityNet and the 20BN dataset\nto train and evaluate the different methods. For computing\nthe performance metrics, we split the validation set of the\nrespective dataset into 5 shuffled folds. In each fold, 80% of\nthe videos are used as memory whereas the remaining 20%\nare used to query the memory. The results illustrated in Table\nI are averaged over the 5 folds.\nThe evaluations were conducted with various numbers of\nGMM components and two different distance metrics (i.e.\neuclidean and cosine) for matching the video encodings. We\nwant to emphasize that we always report the best results out\nof these experimental evaluations.\nAs the results in Table I indicate, representations of\nconventional descriptors such as SIFT and STIP seemingly\nlack the representational capacity to capture abstract spatiotemporal concepts in videos such as action. In contrast, using\nCNN features yields significantly higher average matching\nprecision. Our proposed method has the highest precision\nvalues and especially outperforms the state of the art approaches by a significant margin in terms of precision at\nthe first match. For completeness, Table I also reports the\nmatching precisions with 200 PCA components. Similar to\nthe observations discussed in section IV-C, PCA further\n\nActivityNet (in %)\n\n20BN-sth.-sth. (in %)\n\nModel and Features\n\nPrecision\n\nmAP\n\nPrecision\n\nSIFT FV\nSTIP FV [34]\nResNet-50 FV [11]\nVGG-16 FV [11]\nResNet-50 LSTM [14]\nVGG-16 LSTM [14]\nours (no PCA)\n\n5.27\n5.47\n32.31\n24.30\n36.29\n17.18\n44.31\n\n3.76\n3.71\n23.23\n18.19\n26.32\n12.16\n26.93\n\n1.05\n3.37\n6.08\n5.56\n10.08\n4.51\n11.63\n\n0.64\n2.67\n3.98\n3.62\n7.20\n2.82\n8.12\n\nours with PCA (200)\n\n45.55\n\n28.18\n\n11.81\n\n8.32\n\nmAP\n\nimproves the matching. The precisions on ActivityNet are\nsubstantially higher since it has a) fewer categories than the\n20BN dataset and b) richer features among the categories.\nIn addition to the quantitative benchmark, we qualitatively\nexamined the matching and retrieval results. The matching\nappears to be conceptually consistent, predominantly yielding visual episodes with closely related action types and\nsettings. Fig 6 (a) shows sample matching results of our\napproach on the 20BN dataset.\nIn most cases of categorical mismatches, the retrieved\nepisode is closely related to the action type of the query\nepisode. However, we also observe that the background color\nbiases the matching results, meaning that videos with dark\nbackground tend to be matched to videos in memory of the\nsame kind. The same applies to bright videos respectively.\nAll in all, our proposed model achieves the best matching\nresults among the compared approaches. The qualitative\nstudy shows that, beyond the strict categorical setting imposed in the baseline comparison, our mechanism predominantly produces consistent matches. It is also important to\nnote that our approach is the only one that can reconstruct\nthe visual episode given the encoding.\n\n\fFig. 6: The proposed matching and retrieval mechanism evaluated on different visual episodes of object manipulations. The\nfigure depicts three exemplary query episodes and the corresponding 3 closest matches in the latent space of our proposed\nnetwork. The latent representations are generated by the 20BN model. While (a) shows a query on the 20BN dataset, (b)\nand (c) comprise human demonstrations for the ARMAR-IIIa robot (see section IV-F ).\n\nF. Robot Manipulation Learned From Episodic Memory\nResults in the previous section indicate that given a query\naction, our proposed network provides a robot with the ability\nto remember similar scenarios from a large video corpora.\nIn the following, we show how our network can be applied\nto robot manipulation tasks.\nFor this purpose, we record 120 visual episodes in which\na human subject is demonstrating to our humanoid robot\nARMAR-IIIa [35] how to perform 10 different manipulation\nactions such as “pushing two objects closer to each other”\nand “putting something behind something” (see Fig. 6 (b-c)).\nThe reason of introducing this new dataset is twofold: First,\nwe attempt to evaluate the scalability of our approach to new\ndatasets that have much less training data. Second, for the\npurpose of action execution we require the depth cue which\nis missing in the ActivityNet and 20BN datasets. We store\n100 of our new visual episodes to form the memory, whereas\nthe remaining 20 episodes are introduced as queries to test\nthe matching and retrieval mechanism with ARMAR-IIIa.\nThe visual episodes are fed through the encoder of the\ntrained 20BN model, thereby receiving its respective latent\nrepresentations. The cosine similarity in the latent space is\nthen computed based on the first 50 principal components of\nthe latent representations (see section III-B).\nFig. 6 (b-c) illustrate two exemplary query episodes and\nthe corresponding 3 closest matches in the latent space\nfrom our recordings. For the great majority of the queries,\nthe retrieved episodes are conceptually similar, indicating\nthat the proposed episodic-like memory mechanism reliably\nmatches visual episodes.\nSo far, the matching and retrieval mechanism is evaluated\non manipulation action videos where spatio-temporal cues\nare implicitly embedded. We further investigate whether\nstatic scene frames can trigger recalling of past visual\nepisodes. This gives a high chance to robots to autonomously\npredict and even execute an action that can possibly be\nperformed in the observed scene. We conduct a pilot study\nto explore the use of our proposed method.\nFig. 7 illustrates a scenario where the robot ARMAR-IIIa\nis observing a scene with a sponge on the table. Acquired\n\nimages of this static scene are directly sent to our matching\nand retrieval mechanism which returns the matched episode\nwhere a subject is demonstrating “pushing a green cup”.\nNext, we apply a real-time object detector [36] to detect and\ntrack all objects in the recalled episode. This process yields\nthe extracted pushing trajectory that the subject is following.\nThe tracked motion is then learned by dynamic movement\nprimitives [37] to be further processed by the robot in order\nto execute the same pushing motion on the perceived sponge.\nFig. 7 depicts sample frames from the best matched episode\nand detected objects together with the computed motion\nprofile and snapshots from the robot execution of the recalled\npushing action. See the supplementary movie showing the\nentire robot execution.\nThis experiment clearly supports our hypothesis that the\nproposed network model can help robots autonomously trace\nprevious observations and select the one that matches best\nto the currently observed scene even without necessarily\nrequiring any temporal cue. Hence, the robot can transfer\nrelevant knowledge, e. g. the motion profile, from previous\nexperiences to further apply the remembered action to novel\nobjects in the scene. These findings play a vital role in\ncognitive robotics to infer possible actions, reason about the\naction consequences, and even generate actions by transferring knowledge from the past experiences.\n\nFig. 7: Robot execution of a matched pushing action.\n\n\fV. C ONCLUSION\nWe proposed a deep neural network implementing an\nepisodic memory. Given a set of training data, the proposed\nnetwork first generates subsymbolic representation of action\nepisodes. Such a latent encoding can be used to distinguish\nactions, reconstruct memorized episodes, and predict future\nframes based on the spatio-temporal features extracted by\nthe deep architecture. We show that conceptual similarity\nof videos is reflected by the proximity of their vector\nrepresentation in the latent space. Using this property of\nthe latent space, we introduce a matching and retrieval\nmechanism, which enables the recollection of previously\nexperienced visual episodes. Benchmarking our proposed\nmechanism against a variety of action descriptors, we show\nthat our model outperforms other state-of-the-art approaches\nin terms of matching precision. We conduct various experiments showing that the proposed framework can help\nextending the cognitive abilities of a humanoid robot such as\naction encoding, storing, memorizing, and predicting through\na single coherent framework.\nTo the best of our knowledge, this is the first comprehensive study that attempts to encode visual experiences\nnot only for matching and retrieving purposes but also for\nprediction and reconstruction in a longer time scale. Comparable work such as [11], [14] can only achieve unsupervised\naction matching without reconstructing the memorized video\nepisodes. Video prediction models, introduced in [21], [28],\ncan only predict a single future frame at a time. Thus,\nthe mentioned approaches lack key features to resemble an\nepisodic memory. Our model overcomes the architectural\ndrawback of [14] and comprises the full episodic-memory\ncapabilities described above. Also, we are not aware of any\nprevious work that extensively applies an episodic memorylike framework to such large and complex datasets.\nR EFERENCES\n[1] I. Kotseruba, O. J. A. Gonzalez, and J. K. Tsotsos, “A Review of\n40 Years of Cognitive Architecture Research: Focus on Perception,\nAttention, Learning and Applications,” 2016.\n[2] R. Sun, E. Merrill, and T. Peterson, “From implicit skills to explicit\nknowledge: A bottom-up model of skill learning,” in Cognitive Science, vol. 25, no. 2, 2001, pp. 203–244.\n[3] B. Rohrer, M. Bernard, D. J. Morrow, F. Rothganger, and P. Xavier,\n“Model-free learning and control in a mobile robot,” in ICNC, 2009,\npp. 566–572.\n[4] A. M. Nuxoll and J. E. Laird, “Extending Cognitive Architecture with\nEpisodic Memory,” in AAAI, Vancouver, British Columbia, Canada,\n2007, pp. 1560–1565.\n[5] W. Dodd and R. Gutierrez, “The role of episodic memory and emotion\nin a cognitive robot,” in RO-MAN, 2005, pp. 692–697.\n[6] N. S. Kuppuswamy, S. H. Cho, and J. H. Kim, “A cognitive control\narchitecture for an artificial creature using episodic memory,” in SICEICASE, 2006, pp. 3104–3110.\n[7] D. Stachowicz and G. J. M. Kruijff, “Episodic-like memory for\ncognitive robots,” TAMD, vol. 4, no. 1, pp. 1–16, 2012.\n[8] D. Vernon, C. von Hofsten, and L. Fadiga, “The iCub Cognitive\nArchitecture,” in A Roadmap for Cognitive Development in Humanoid\nRobots, 2010, pp. 121–153.\n[9] G. M. Park, Y. H. Yoo, D. H. Kim, and J. H. Kim, “Deep art neural\nmodel for biologically inspired episodic memory and its application\nto task performance of robots,” IEEE Transactions on Cybernetics,\nvol. PP, no. 99, pp. 1–14, 2018.\n\n[10] D. R. Kuokka, “MAX: A Meta-Reasoning Architecture for ”X”,”\nSIGART Bulletin, vol. 2, no. 4, pp. 93–97, 1991.\n[11] J. Doshi, Z. Kira, and A. Wagner, “From deep learning to episodic\nmemories: Creating categories of visual experiences,” in ACS, 2015,\np. 15.\n[12] M. Ranzato, A. Szlam, J. Bruna, M. Mathieu, R. Collobert, and\nS. Chopra, “Video (language) modeling: a baseline for generative\nmodels of natural videos,” CoRR, vol. abs/1412.6604, 2014.\n[13] D. et al., “Long-term recurrent convolutional networks for visual\nrecognition and description,” in CVPR, vol. 07-12-June, 2015, pp.\n2625–2634.\n[14] N. Srivastava, E. Mansimov, and R. Salakhudinov, “Unsupervised\nlearning of video representations using lstms,” in ICML, 2015, pp.\n843–852.\n[15] X. Shi, Z. Chen, H. Wang, D.-Y. Yeung, W.-k. Wong, and W.-c.\nWoo, “Convolutional LSTM network: A machine learning approach\nfor precipitation nowcasting,” in NIPS, 2015, pp. 802–810.\n[16] K. Soomro, A. R. Zamir, and M. Shah, “UCF101: A dataset of 101\nhuman actions classes from videos in the wild,” CoRR, 2012.\n[17] F. C. Heilbron, V. Escorcia, B. Ghanem, and J. C. Niebles, “ActivityNet: A large-scale video benchmark for human activity understanding,” in CVPR, 2015, pp. 961–970.\n[18] H. Kuehne, H. Jhuang, E. Garrote, T. Poggio, and T. Serre, “HMDB:\nA large video database for human motion recognition,” in ICCV, 2011,\npp. 2556–2563.\n[19] M. Mathieu, C. Couprie, and Y. LeCun, “Deep multi-scale video\nprediction beyond mean square error,” in ICLR, 2015, pp. 1–14.\n[20] W. Lotter, G. Kreiman, and D. Cox, “Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning,” 2016.\n[21] V. Patraucean, A. Handa, and R. Cipolla, “Spatio-temporal video\nautoencoder with differentiable memory,” in ICLR, 2016, pp. 1–10.\n[22] C. Finn, I. Goodfellow, and S. Levine, “Unsupervised Learning for\nPhysical Interaction through Video Prediction,” in NIPS, 2016, pp.\n64–72.\n[23] S. Sharma, R. Kiros, and R. Salakhutdinov, “Action recognition using\nvisual attention,” CoRR, vol. abs/1511.04119, 2015.\n[24] W. Zhu, J. Hu, G. Sun, X. Cao, and Y. Qiao, “A Key Volume Mining\nDeep Framework for Action Recognition,” in CVPR, vol. Mi, 2016,\npp. 1991–1999.\n[25] H. Bilen, B. Fernando, E. Gavves, A. Vedaldi, and S. Gould, “Dynamic\nImage Networks for Action Recognition,” CVPR, 2016.\n[26] L. Wang, Y. Xiong, Z. Wang, Y. Qiao, D. Lin, X. Tang, and L. van\nGool, “Temporal segment networks: Towards good practices for deep\naction recognition,” in LNCS, vol. 9912, 2016, pp. 20–36.\n[27] C. Vondrick, H. Pirsiavash, and A. Torralba, “Generating videos with\nscene dynamics,” in NIPS, 2016.\n[28] C. Finn and S. Levine, “Deep visual foresight for planning robot\nmotion,” in ICRA, 2017, pp. 2786–2793.\n[29] D. P. Kingma and J. L. Ba, “Adam: a Method for Stochastic Optimization,” in ICLR, 2015, pp. 1–15.\n[30] J. L. Ba, J. R. Kiros, and G. E. Hinton, “Layer Normalization,” 2016.\n[31] G. et al., “The ”something something” video database for learning and\nevaluating visual common sense,” 2017.\n[32] K. Simonyan and A. Zisserman, “Very deep convolutional networks\nfor large-scale image recognition,” CoRR, vol. abs/1409.1556, 2014.\n[33] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for\nimage recognition,” CoRR, vol. abs/1512.03385, 2015.\n[34] I. Laptev and T. Lindeberg, “Space-time interest points,” in ICCV,\n2003, pp. 432–439 vol.1.\n[35] T. Asfour, K. Regenstein, P. Azad, J. Schroder, A. Bierbaum,\nN. Vahrenkamp, and R. Dillmann, “Armar-iii: An integrated humanoid\nplatform for sensory-motor control,” in Humanoids, 2006, pp. 169–\n175.\n[36] J. Redmon, S. K. Divvala, R. B. Girshick, and A. Farhadi, “You only\nlook once: Unified, real-time object detection,” CoRR, 2015.\n[37] J. A. Ijspeert, J. Nakanishi, and S. Schaal, “Movement imitation with\nnonlinear dynamical systems in humanoid robots,” in ICRA, 2002, pp.\n1398–1403.\n\n\f",
         "train",
         "41333",
         "6465"
        ],
        [
         "19",
         "18359",
         "cs.AI",
         "Artificial Intelligence",
         "1710.04334v1.pdf",
         "DisSent: Sentence Representation Learning from Explicit Discourse\nRelations\nAllen Nie∗1 Erin D. Bennett∗2 Noah D. Goodman1,2\n1\nDepartment of Computer Science 2 Department of Psychology\nStanford University\nanie@cs.stanford.edu\n\n{erindb,ngoodman}@stanford.edu\n\narXiv:1710.04334v1 [cs.CL] 12 Oct 2017\n\nAbstract\nSentence vectors represent an appealing\napproach to meaning: learn an embedding that encompasses the meaning of a\nsentence in a single vector, that can be\nused for a variety of semantic tasks. Existing models for learning sentence embeddings either require extensive computational resources to train on large corpora, or are trained on costly, manually\ncurated datasets of sentence relations. We\nobserve that humans naturally annotate the\nrelations between their sentences with discourse markers like “but” and “because”.\nThese words are deeply linked to the\nmeanings of the sentences they connect.\nUsing this natural signal, we automatically\ncollect a classification dataset from unannotated text. Training a model to predict\nthese discourse markers yields high quality sentence embeddings. Our model captures complementary information to existing models and achieves comparable generalization performance to state of the art\nmodels.\n\n1\n\nIntroduction\n\nWhen humans read a sentence they extract a flexible representation of meaning that can be used for\nmany tasks. Developing wide-coverage models to\nrepresent the meaning of a sentence is thus a key\ntask in natural language understanding. The applications of such general-purpose representations of\nsentence meaning are many — paraphrase detection, summarization, knowledge-base population,\nquestion-answering, automatic message forwarding, and metaphoric language, to name a few.\n∗\n\nequal contribution\n\nLearning flexible meaning representations requires a sufficiently demanding, yet tractable,\ntraining task. We propose to leverage a highlevel relationship between sentences that is both\nfrequently and systematically marked in natural\nlanguage: the discourse relations between sentences. Human writers naturally use a small set\nof very common transition words between sentences1 to identify the relations between adjacent\nideas. These words, such as because, but, although, which mark the relationship between two\nsentences on the highest level, have been widely\nstudied in linguistics, both formally and computationally, and have many different names. We use\nthe name “discourse markers”. Because discourse\nmarkers annotate deep conceptual relations between sentences, similar to entailment, they may\npermit learning from much less data; because discourse markers are produced in natural text, unlike\nentailment, they don’t require hand annotation.\nWe thus propose the DisSent model and Discourse Prediction Task to train sentence embeddings. We choose pairs of sentences linked with\ncommon discourse markers, and, using a simple\ndata preprocessing scheme, we are able to automatically curate a sizable training set. We then\ntrain a sentence encoding model to learn embeddings for each sentence in a pair such that a classifier can identify, based on the embeddings, which\ndiscourse marker was used to link the sentences.\nConneau et al. (2017) published an evaluation\nframework, SentEval2 , to evaluate sentence embeddings. They compile a set of pre-defined sentence classification tasks on which a good sentence representation should perform well. They\nused these tasks to evaluate their InferSent model\n1\nWe will use “sentences” to mean either whole sentences\nor the main clauses of a compound sentence.\n2\nhttps://github.com/facebookresearch/\nSentEval\n\n\fwhich they trained on a natural language inference\ntask (Bowman et al., 2015). We use the SentEval\nto evaluate our models. Using a model architecture similar to InferSent, but trained on our new\ndiscourse classification task, our DisSent embeddings achieve comparable results on many evaluation tasks. Combining our embeddings and those\nfrom InferSent achieves state of the art performance, superior to either embedding alone.\n\n2\n\nDiscourse Prediction Task\n\nWe propose a new task for natural language understanding: discourse marker prediction. Given\ntwo sentences in a corpus, the model must predict\nwhich discourse marker was used by the author\nto link the two ideas. Without a semantic understanding of the sentence, it is difficult to predict\nthe discourse connectives. For example, “She’s\nlate\nshe missed the bus” would likely be\ncompleted with because, but “She’s sick\nshe missed the class” would likely be completed\nwith so, and “She’s skilled\nshe missed the\ngoal” would likely be completed with but. All of\nthese example pairs have similar syntactic structures and more than half their words in common.\nBut the meanings of the component sentences\nlead to strong intuitions about which discourse\nmarker makes the most sense. Success at choosing the correct discourse marker likely requires the\nlearned representation to reflect the meaning of a\nsentence.\nHobbs (1990) argues that discourse relations are\nalways present, and that they fall under a small set\nof categories. Given this assumption, researchers\nhave attempted to identify the correct relation for\na given pair of sentences (Marcu and Echihabi,\n2002), or to determine when and why a discourse\nrelation will be made explicit with a discourse\nmarker (Patterson and Kehler, 2013; Yung et al.,\n2017). Such studies make use of corpora like the\nPenn Discourse Treebank (PDTB) (Robaldo et al.,\n2008), where each sentence is annotated with its\nrelation. However, determining the correct relations can be an unnatural and difficult task for annotators, requiring extensive training. In addition,\nthere has been disagreement among researchers\nand annotators about what exactly is the correct\ncategorization of discourse relations (e.g. Hobbs,\n1990; Jasinskaja and Karagjosova, 2015). While\nsometimes overlapping and ambiguous in the relations they represent, discourse markers in general\n\nmap onto specific discourse relations (Pitler et al.,\n2008). We can therefore use explicit discourse\nmarkers as proxies for true relations between sentences, without relying on costly and debated annotations of implicit discourse relations.\nThis task leverages the intrinsic nature of a\ndiscourse marker and how it is commonly used,\nwithout curation. For instance, because common\ndiscourse markers appear in similar distributions\nacross a range of genres (See e.g. Altenberg, 1984,\nfor causal discourse markers), the representations\nnecessary to do well at this task should be less sensitive to style than to content. This is a desirable\nfeature for a sentence embedding that aims to reflect the sentence’s meaning.\nmarker\n\nBookCorpus\n\nbut\nso\nif\nwhen\nbefore\nstill\nafter\nbecause\nwhile\nalthough\nhowever\nmeanwhile\nfor example\n\n51.56\n28.57\n26.32\n22.56\n13.08\n10.41\n9.45\n8.64\n6.02\n1.17\n1.15\n0.11\n0.07\n\ntotal\n\n179.11 (1.82%)\n\nTable 1: Frequencies (in 100K) of discourse markers within BookCorpus and percent within the full\ncorpus.\n\n3\n\nModel\n\nDisSent Model We adapt the best architecture\nfrom Conneau et al. (2017) as our sentence encoder. This architecture uses a standard bidirectional LSTM (Graves et al., 2013), followed\nby temporal max-pooling to create sentence vectors. We parameterize the BiLSTM with the same\nweight θ for both forward and backward processing to control the parameter growth.\n→\n−\nht = LSTMt (w1 , ..., wT |θ)\n←\n−\nht = LSTMt (wT , ..., w1 |θ)\n\n(1)\n\nWe apply temporal max pooling on the resulting\nsequences of hidden vectors to construct the forward and backward encodings for each sentence.\nTemporal max pooling builds a sentence representation from all time steps in the processing of a\n\n\fsentence (Collobert and Weston, 2008; Conneau\net al., 2017), providing regularization and shorter\nback-propagation paths.\n−\n→\n−\n→\n→\n−\nH = [h1 , ..., hT ]\n←\n−\n←\n−\n←\n−\nH = [h1 , ..., hT ]\n→\n−\n→\n−\ns = MaxPool( H )\n\nAfter pooling, we combine the final forward and\nbackward encodings into a single encoding for\n−\neach sentence via addition, si =→\nsi + ←\ns−i .\nOur objective is to predict the discourse relations between two sentences from their vectors,\ns1 and s2 . To do so we must combine the vectors, and some non-linear interactions are likely to\nbe needed. However, because we want generally\nuseful sentence vectors after training, the learned\ncomputation should happen before the sentences\nare combined. To achieve this, we include a fixed\nset of common pair-wise vector operations: subtraction, multiplication, and average.\n\n(3)\n\nsmul = s1 ∗ s2\ns = [s1 ,s2 , savg , ssub , smul ]\nFinally we project the concatenated vector s\ndown to a vector of label size (the number of discourse markers), and use softmax to compute the\nprobability distribution over discourse relations.\n\nData Collection\n\nWe describe below a simple, automatic way to\ncollect a large corpus of sentence pairs and the\nrelations between them. We collected such sentence pairs from BookCorpus (Zhu et al., 2015),\na dataset of text from unpublished novels (Romance, Fantasy, Science fiction, and Teen genres),\nwhich was used by (Kiros et al., 2015) to train their\nSkipThought model. We use this dataset to train\nour model.\n4.1\n\nstring only\nstring + dep-parse\ndep-parse only\n\nbut, for example, when, meanwhile\nbecause, although, while, if\nbefore, after, however, so, still, though\n\n(2)\n\n←\n−\n←\ns−i = MaxPool( H )\n\n4\n\nmarkers\n\nTable 2: Collection method used for each discourse marker.\n\ni\n\n1\nsavg = (s1 + s2 )\n2\nssub = s1 − s2\n\nmethod\n\nDiscourse Markers\n\nWe chose relatively frequent discourse markers\n(accounting for at least 1% of discourse markers\nin the overall corpus) from a large set of discourse\n\nmarkers identified in the manual for the preparation of the Penn Discourse TreeBank (PDTB)\n(Prasad et al., 2007). We excluded a few discourse\nmarkers (and, then, and as) that were very difficult\nto systematically separate from the sentences they\nconnect or very ambiguous with usages other than\nas a discourse marker. We present our final set of\ndiscourse markers and their frequencies in Table 1.\n4.2\n\nSentence Collection\n\nWe processed and collected discourse markers\nfrom the BookCorpus dataset (Zhu et al., 2015).\nWe used the same tokenization as used to train\nSkipThought (Kiros et al., 2015). While discourse\nmarkers are quite separable from the sentences\nthey link, there are some complications in extracting sentence pairs from raw text.\nMany discourse markers in English occur almost exclusively between the two sentences they\nconnect, and for these discourse markers we simply split on the discourse marker such that the first\nsentence in the pair (S1) was the part of the sentence before the discourse marker and the second\n(S2) was the part after.\nFor other discourse markers, their position in\nthe sentence relative to S1 and S2 is less systematic, and for these markers, we ran Stanford\nCoreNLP dependency parser (Schuster and Manning, 2016). For discourse markers with consistent patterns, we simply used this parse to exclude pairs that were obviously not linked by that\ndiscourse marker. For other discourse markers,\nwe collected pairs by extracting subphrases of the\nappropriate dependency relation from the dependency parse. The method used for each discourse\nmarker is shown in Table 2.\nUsing a dependency parse had the added benefit\nof filtering out many uses of these words that are\nnot discourse markers at all. For example, some\ndiscourse markers, (e.g. so) are ambiguous between their discourse marker usage and other usages (e.g. “that’s so cool!”).\nDespite these advantages, this method also introduces some problems. The dependency parser\n\n\fS1\n\nmarker\n\nS2\n\nher profile picture was cute ,\nnone of these thoughts amounted to much\n, she could move into town as a full-time witch .\nmyrtle had just decided to give georgias cognitive skills a go\nthe rush of energy hit us before the sound .\ncomplications are to be expected .\n“ tomorrow , , i need to go in front of them . ”\nshe looked tired and battered .\n\nbut\nbecause\nif\nwhen\nso\nfor example\nbefore\nstill\n\nyou couldnt trust those .\nshe had no choice in the matter .\nshe could make enough money\nthere was a sudden , piercing shriek .\nwe had a moment of being hit\n, i can not be allowed to encounter myself .\nthe search party starts out\n, i had never in my life seen someone more beautiful .\n\nTable 3: Example pairs from our Books 8 dataset.\nproduces some incorrect parses, which can result\nin unrelated pairs., e.g. “I won’t tell him that I\ndidn’t actually buy them so you can’t tell him either.” was parsed as [“that i didnt actually buy\nthem”, so, “you cant tell him either”]. Incorrect\nparses also introduced errors in extracting subphrases, when the discourse marker was embedded within S2, e.g. given the sentence “Okay, so it\nwas what you said, too,” S1 was extracted as “okay\n, , too .”\n4.3\n\nLength-based Filtering\n\nAs a way to exclude extremely uninformative sentence pairs and standardize lengths of sentences,\nwe filtered pairs based on several criteria on the\nlengths of the two sentences. We excluded any\npair where one of the two sentences was less than\n5 or more than 50 words long. We additionally excluded any pairs where one of the two sentences\nwas more than 5 times the length of the other.\n4.4\n\nTraining Dataset\n\nUsing these methods, we curated a dataset\nof 9,297,461 pairs of sentences for 13 discourse markers. Examples are shown in Table 3. We then randomly divide the dataset into\ntrain/validation/test set with 0.9, 0.1, 0.1 split. The\ndataset is inherently unbalanced but in our experiments the model is still able to learn rarer classes\nquite well.\nWe will also consider smaller sets of discourse markers, resulting in smaller data sets.\nFor our experiment on 8 discourse markers, we\nhave 8,396,747 sentence pairs in total, and for\nour experiment on 5 discourse markers, we have\n7,442,573 sentence pairs in total. Selected markers are displayed in Table 4.\n\n5\n\nRelated Work\n\nCurrent state of the art models summarize the\nmeaning of a sentence via a sentence vector, re-\n\nlying on completely unsupervised learning or supervised learning through high-level classification\ntasks.\nSkipthought (Kiros et al., 2015) is an unsupervised sequence model that has proven to generate\nuseful sentence embeddings. However, it requires\nlarge amounts of training data and long training\ntime to perform well. In SkipThought, each word\nin the previous sentence is used to generate each\nword in the next sentence. In DisSent, each word\nin both sentences is used to classify the discourse\nmarker, which is often extracted from the second\nsentence.\nInferSent (Conneau et al., 2017) explores the\nidea that sentence embeddings can be learned\nfrom by capitalizing on sentence relationships.\nThey trained a classifier to predict entailment relations in the Stanford Natural Language Inference (SNLI) (Bowman et al., 2015) and MultiNLI\n(Williams et al., 2017) corpora, achieving comparable performance to SkipThought on generalization tasks, but with much less data and shorter\ntraining time. However, the training set used was\nbuilt using human annotation, and is therefore laborious and expensive to collect. The InferSent\nmodel is therefore limited in the size and variety of\ndataset it can be trained on. In contrast, while DisSent also leverages sentence relationships, it can\nbe trained on automatically collected data.\nJernite et al. (2017) have proposed a model that\nleverages discourse relations. They manually put\ndiscourse markers into several categories based on\nhuman interpretations of discourse marker similarity, and the model predicts the category instead\nthe individual discourse marker. Their model also\ntrains on sentence ordering and ranking of the following sentence. Their data collection methods\nonly allow them to look at paragraphs longer than\n8 sentences, and they only obtained 1.4M sentence\npairs that contain discourse markers from a much\nlarger corpus. Our proposed model achieves com-\n\n\fparable results to Jernite et al. (2017) without any\nauxiliary tasks or manual categorization of discourse markers.\n\n6\n\nExperiments\n\nFor all our models, we tuned the hyperparameters\non the validation set, and report results from the\ntest set. We use stochastic gradient descent with\ninitial learning rate 0.1, and we anneal by half each\ntime the validation accuracy is lower than previous epoch. We train our models for 10 epochs.\nWe set the feedforward dropout rate to be 0.2 and\ndid not explicitly tune dropout rate. We also clip\nthe gradient norm to 5.0. Parameters were initialized uniformly from [-0.1, 0.1]. We experimented\nwith both temporal mean pooling and temporal\nmax pooling and found the later to perform much\nbetter at transfer tasks.\nLabel\n\nDiscourse Markers\n\nBooks 5\nBooks 8\n\nbut, because, if, when, so\nbut, because, if, when, so, for example,\nbefore, still\n\nTable 4: Discourse marker sets used in our experiments.\nDiscourse Marker Set To investigate the qualitative relations among the A LL marker set, we\nbuild a confusion matrix based on predictions on\nthe test set (Figure 4). We see that many discourse\nmarkers are misclassified as the most common\nmarker but (likely an effect of the unbalanced data\nset). Different markers are misclassified as but to\ndifferent degrees. The most common such confusion is when the synonymous marker although is\nmistakenly classified as but.\nThe temporal relation markers before and after,\ntwo intuitively very similar discourse markers, are\nalmost never confused for anything but each other.\nThe fact that they are indeed confusable may reflect the tendency of authors to mark temporal relation primarily when it is ambiguous.\nThe discourse marker while is an interesting\ncase, since it can be used to express either contrasting or temporal relationships between two sentences. When the model misclassifies while, it\nis usually either misclassified as the temporal discourse marker when or the contrast classifier but.\nBecause there appear to be intrinsic conceptual\noverlap in the set of ALL markers, we experimented on different subsets of discourse markers.\n\nFigure 1: Confusion matrix for best-performing\nmodel trained on A LL from BookCorpus. Each\ncell represents the proportion of instances of the\nactual discourse marker misclassified as the classified discourse marker. This proportion is logtransformed to highlight small differences.\nWe choose sets of 5 and 8 discourse markers that\nseemed non-overlapping and frequent, both intuitively and with respect to confusions in Figure 1.\nThe set of sentence pairs for each smaller dataset\nis a strict subset of those in any larger dataset. Our\nchosen sets are shown in Table 4.\nTransfer Tasks We evaluate the performance\nof our generated sentence embeddings on a series of natural language understanding benchmark tests provided by Conneau et al. (2017).\nThe tasks we chose include sentiment analysis\n(MR, SST), question-type (TREC), product reviews (CR), subjectivity-objectivity (SUBJ), opinion polarity (MPQA), entailment (SICK-E) and relatedness (SICK-R). These tasks are all classification tasks with 2-6 classes, except for relatedness, for which the model predicts human similarity judgements.\n6.1\n\nResults\n\nTraining task On the discourse marker prediction task that our model is trained for, we achieve\nhigh levels of test performance for all discourse\nmarkers. (Though it is interesting that because,\nperhaps the conceptually deepest relation, is also\nsystematically the hardest for our model.) The\nlarger the set, the more difficult the task becomes\nand we see lower test accuracy overall when the\nsize of the discourse marker set increases. Training task performance for each of our models is\nshown in Table 6.\n\n\fTraining data\n\nEmbedding size\n\nMR\n\nCR\n\nSUBJ\n\nMPQA\n\nSST\n\nTREC\n\nSICK-R\n\nSICK-E\n\nBooks 5\nBooks 8\nBooks ALL\n\n2048\n2048\n2048\n\n83.1\n82.8\n82.5\n\n81.6\n81.7\n80.2\n\n92.7\n92.5\n92.4\n\n89.7\n89.7\n89.6\n\n81.1\n78.5\n82.9\n\n86.4\n86.8\n84.6\n\n0.803\n0.808\n0.791\n\n81.7\n81.9\n80.3\n\nTable 5: Discourse marker set: Generalization task results for DisSent model using SentEval framework\non three different discourse marker sets, holding embedding size constant at 2048 dimensions.\nMarker\n\nAll\n(2048)\n\nBooks 8\n(2048)\n\nBooks 8\n(4096)\n\nBooks 5\n(2048)\n\nBooks 5\n(4096)\n\nbut\nbecause\nif\nwhen\nso\nfor example\nbefore\nstill\nafter\nalthough\nhowever\nmeanwhile\nthough\nwhile\n\n0.90\n0.45\n0.90\n0.71\n0.75\n0.37\n0.83\n0.84\n0.53\n0.09\n0.66\n0.49\n0.73\n0.71\n\n0.95\n0.57\n0.88\n0.89\n0.83\n0.55\n0.83\n0.79\n—\n—\n—\n—\n—\n—\n\n0.94\n0.60\n0.90\n0.90\n0.82\n0.63\n0.88\n0.84\n—\n—\n—\n—\n—\n—\n\n0.97\n0.53\n0.87\n0.89\n0.86\n—\n—\n—\n—\n—\n—\n—\n—\n—\n\n0.97\n0.55\n0.86\n0.91\n0.88\n—\n—\n—\n—\n—\n—\n—\n—\n—\n\nOverall\n\n0.84\n\n0.88\n\n0.89\n\n0.90\n\n0.91\n\nTable 6: Training task performance: Test recall for each discourse marker on the classification task.\nDiscourse marker set Varying the set of discourse markers doesn’t seem to help or hinder\nthe model’s performance on generalization tasks.\nGeneralization performance on the three sets of\ndiscourse markers for embedding size 2048 is\nshown in Table 5. Similar generalization performance was achieved when training on 5, 8, and all\n13 discourse markers. The lack of improvement\nwhen training on more discourse markers may\nreflect the overlap in meaning and usage across\nmany discourse markers. It may also simply reflect the fact that the top 5 discourse markers capture most of the relationships in the training data.\nComparison to previous approaches In comparing to previous work, we used the Books 8 and\nBooks 5 datasets and trained a model with 4096\nembedding size3\nResults of our top performing models, and comparison to other approaches, are shown in Table\n7. Despite being a much simpler task, with faster\ntraining, than SkipThought, the DisSent embeddings outperforms SkipThought embeddings on 5\ntasks.\n3\nConneau et al. (2017) showed that model generalization\nperformance improved as sentence embedding size increased.\nWe found the same to be true in our experiments. We chose to\npresent the same embedding size as InferSent for comparison.\n\nOur approach performs similarly to or better\nthan InferSent on four tasks, while doing slightly\nworse on the remaining four. Some of these differences may be due to small differences in model or\ntraining, while the remaining differences may be\ndue to the different task and very different source\nof data (human curated vs natural corpus).\nCombining embeddings from different tasks\nIt may be that models trained to predict discourse\nmarkers learn complementary information compared to models trained for natural language inference. This idea suggests that better performance\ncan be achieved by combining the embedding vectors. Indeed, we found that by combining sentence\nrepresentations from our model and InferSent, the\nconcatenated model in Table 7 outperforms either\none of the individual models on most tasks (InferSent still outperforms the combined model on\ntwo tasks).\n\n7\n\nDiscussion\n\nThe ability of discourse marker prediction as a\ntraining task to shape sentence embeddings into\na useful, roughly state of the art, form for generalization tasks is encouraging. Yet a number of\nissues for future research are apparent.\n\n\fmodel\n\nMR\n\nCR\n\nSUBJ\n\nMPQA\n\nSST\n\nTREC\n\nSICK-R\n\nSICK-E\n\n90.0\n90.0\n—\n\n82.5\n80.2\n—\n\n87.0\n87.2\n81.0\n\n0.821\n0.817\n—\n\n82.6\n81.5\n—\n\n90.6\n90.1\n\n83.7\n83.6\n\n90.4\n89.4\n\n0.885\n0.886\n\n87.1\n87.7\n\n—\n—\n82.0\n82.9\n\n76.8\n80.4\n92.2\n88.4\n\n—\n—\n0.858\n0.858\n\n—\n—\n82.3\n79.5\n\n—\n84.6\n\n81.0\n88.2\n\n—\n0.884\n\n—\n86.1\n\nIntrinsically-supervised training methods\nDisSent Books 5 (4096)\nDisSent Books 8 (4096)\nDiscourse BiGRU (512) (Jernite et al., 2017)\n\n83.4\n82.9\n—\n\n81.8\n81.4\n—\n\n93.4\n93.2\n88.6\n\nConcatenated model\nDisSent Books 5 (4096) + InferSent (4096)\nDisSent Books 8 (4096) + InferSent (4096)\n\n84.3\n84.3\n\n84.6\n85.0\n\n94.0\n93.9\n\nUnsupervised training methods\nFastSent (Hill et al., 2016)\nFastSent + AE (Hill et al., 2016)\nSkipthought (Kiros et al., 2015)\nSkipthought-LN (Conneau et al., 2017)\n\n70.8\n71.8\n76.5\n79.4\n\n78.4\n76.7\n80.1\n83.1\n\n88.7\n88.8\n93.6\n93.7\n\n80.6\n81.5\n87.1\n89.3\n\nSupervised training methods\nDictRep (bow) (Conneau et al., 2017)\nInferSent (4096) (Conneau et al., 2017)\n\n76.7\n81.1\n\n78.7\n86.3\n\n90.7\n92.4\n\n87.2\n90.2\n\nTable 7: Generalization task results using SentEval. InferSent sentence embedding size is 4096 dimensions. SkipThought-LN model trained on 600-dimension word embeddings and produced 2400dimension sentence embeddings.\nLimitations of evaluation The generalization\ntasks that we (following (Conneau et al., 2017))\nuse to compare models focus on sentiment, entailment, and similarity. These are narrow operational definitions of semantic meaning. A model\nthat generates meaningful sentence embeddings\nshould excel at these tasks. However, success at\nthese tasks does not necessarily imply that a model\nhas learned a deep semantic understanding of a\nsentence.\nSentiment classification, for example, in many\ncases only requires the model to understand local structures. Text similarity can be computed\nwith various textual distances (e.g., Levenshtein or\nJaro distance) on bag-of-words, without a compositional representation of the sentence. Thus, the\nability of our, and other, models to achieve high\nperformance on these metrics may reflect a competent representation sentence meaning; but more\nrigorous tests are needed to understand whether\nthese embeddings capture sentence meaning in\ngeneral.\nShallow or deep features Different discourse\nmarkers appear in different syntactic frames.\nOur extraction method maintained punctuation\nand capitalization, which may have provided the\nmodel with surface-level syntactic cues that could\nmake the task of classifying discourse markers\neasier without a semantic understanding of the\nsentence. These same cues, if encoded in our\n\nembedding, may be useful in some generalization\ntasks. For example, for TREC, punctuation and\nsyntactic structure may be indicative of question\ntype. It seems unlikely that the same surface level\ncues are useful for all the tasks — DisSent’s high\nperformance on a range of tasks does suggest it\nis capturing at least some deeper semantic understanding of a sentence.\n\nImplicit and explicit discourse relation We focus on explicit discourse relations for training our\nembeddings. Another meaningful way to exploit\ndiscourse relations in training is to predict sentence ordering. Jernite et al. (2017) showed the\npower of such a method in generating meaningful\nsentence embeddings.\nThis approach makes the assumption that adjacent sentences are closer together in meaning\nspace (or generated from similar latent topics).\nThis may be true of many adjacent sentences, especially those whose relation is unmarked. But\nadjacent sentences can be related to one another\nin many different, complicated ways. For example, sentences linked by contrastive markers, like\nbut or however are likely expressing different or\nopposite ideas.\nCombining explicit and implicit signals about\ndiscourse for training embedding models is an appealing direction for future research.\n\n\f8\n\nConclusion\n\nWe present a discourse marker prediction task for\ntraining sentence embeddings to reflect the meaning of a sentence. We train our model on this task\nand show that the resulting embeddings lead to\nhigh generalization performance on a number of\nestablished tasks for sentence embeddings.\nThis type of training task can use large amounts\nof unannotated text, since it relies only on the\nkinds of annotations (sentence boundaries and discourse markers) that humans naturally mark in\ntheir communications with each other. A dataset\nfor this task is therefore easy to collect relative to\nother supervised tasks. Compared to unsupervised\nmethods that train on a full corpus, our method\nyields more targeted and faster training. Encouragingly a model trained on discourse marker prediction achieves comparable generalization performance to other state of the art models.\n\nReferences\nBengt Altenberg. 1984. Causal linking in spoken and\nwritten english. Studia linguistica 38(1):20–69.\nSamuel R. Bowman, Gabor Angeli, Christopher Potts,\nand Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP). Association for Computational Linguistics.\nRonan Collobert and Jason Weston. 2008. A unified\narchitecture for natural language processing: Deep\nneural networks with multitask learning. In Proceedings of the 25th international conference on\nMachine learning. ACM, pages 160–167.\nAlexis Conneau, Douwe Kiela, Holger Schwenk, Loic\nBarrault, and Antoine Bordes. 2017. Supervised\nlearning of universal sentence representations from\nnatural language inference data. arXiv preprint\narXiv:1705.02364 .\nAlex Graves, Navdeep Jaitly, and Abdel-rahman Mohamed. 2013. Hybrid speech recognition with deep\nbidirectional lstm. In Automatic Speech Recognition\nand Understanding (ASRU), 2013 IEEE Workshop\non. IEEE, pages 273–278.\nFelix Hill, Kyunghyun Cho, and Anna Korhonen.\n2016.\nLearning distributed representations of\nsentences from unlabelled data. arXiv preprint\narXiv:1602.03483 .\nJerry R Hobbs. 1990. Literature and cognition. 21.\nCenter for the Study of Language (CSLI).\n\nKatja Jasinskaja and Elena Karagjosova. 2015. Rhetorical relations.\nYacine Jernite, Samuel R. Bowman, and David Sontag. 2017. Discourse-Based Objectives for Fast\nUnsupervised Sentence Representation Learning.\narXiv:1705.00557 [cs, stat] ArXiv: 1705.00557.\nhttp://arxiv.org/abs/1705.00557.\nRyan Kiros, Yukun Zhu, Ruslan R Salakhutdinov,\nRichard Zemel, Raquel Urtasun, Antonio Torralba,\nand Sanja Fidler. 2015. Skip-thought vectors. In\nAdvances in neural information processing systems.\npages 3294–3302.\nDaniel Marcu and Abdessamad Echihabi. 2002. An\nunsupervised approach to recognizing discourse relations. In Proceedings of the 40th Annual Meeting\non Association for Computational Linguistics. Association for Computational Linguistics, pages 368–\n375.\nGary Patterson and Andrew Kehler. 2013. Predicting\nthe presence of discourse connectives. In EMNLP.\npages 914–923.\nEmily Pitler, Mridhula Raghupathy, Hena Mehta, Ani\nNenkova, Alan Lee, and Aravind K Joshi. 2008.\nEasily identifiable discourse relations .\nRashmi Prasad, Eleni Miltsakaki, Nikhil Dinesh, Alan\nLee, Aravind Joshi, Livio Robaldo, and Bonnie L\nWebber. 2007. The penn discourse treebank 2.0 annotation manual .\nAlan Lee Eleni Miltsakaki Livio Robaldo, Aravind\nJoshi Rashmi Prasad, Nikhil Dinesh, and Bonnie\nWebber. 2008. The penn discourse treebank 2.0. In\nProceedings of the Sixth International Conference\non Language Resources and Evaluation (LREC08),\nMarrakech, Morocco, may. European Language Resources Association (ELRA). http://www. lrec-conf.\norg/proceedings/lrec2008.\nSebastian Schuster and Christopher D Manning. 2016.\nEnhanced english universal dependencies: An improved representation for natural language understanding tasks. In LREC.\nAdina Williams, Nikita Nangia, and Samuel R Bowman. 2017. A broad-coverage challenge corpus for\nsentence understanding through inference. arXiv\npreprint arXiv:1704.05426 .\nFrances Yung, Kevin Duh, Taku Komura, and Yuji\nMatsumoto. 2017. A psycholinguistic model for the\nmarking of discourse relations. Dialogue & Discourse 8(1):106–131.\nYukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and Sanja\nFidler. 2015. Aligning books and movies: Towards\nstory-like visual explanations by watching movies\nand reading books. In Proceedings of the IEEE\ninternational conference on computer vision. pages\n19–27.\n\n\f",
         "train",
         "31454",
         "4866"
        ],
        [
         "20",
         "19153",
         "cs.AI",
         "Artificial Intelligence",
         "1802.09129v1.pdf",
         "Multi-Evidence Filtering and Fusion for Multi-Label Classification, Object Detection and\nSemantic Segmentation Based on Weakly Supervised Learning\n\narXiv:1802.09129v1 [cs.CV] 26 Feb 2018\n\nWeifeng Ge\nSibei Yang\nYizhou Yu\nDepartment of Computer Science, The University of Hong Kong\n\nAbstract\n\nGiven image level supervision only, researchers have\nproposed many weakly supervised algorithms for detecting\nobjects and labeling pixels. These algorithms employ different mechanisms, including bottom-up, top-down [42, 23]\nand hybrid approaches [31], to dig out useful information.\nIn bottom-up algorithms, pixels are usually grouped into\nmany object proposals, which are further classified, and the\nclassification results are merged to match groundtruth image labels. In top-down algorithms, images first go through\na forward pass of a deep neural network, and the result is\nthen propagated backward to discover which pixels actually\ncontribute to the final result [42, 23]. There are also hybrid\nalgorithms [31] that consider both bottom-up and top-down\ncues in their pipeline.\nAlthough there exist many weakly supervised algorithms, the accuracy achieved by top weakly supervised algorithms is still significantly lower than their fully supervised counterparts. This is reflected in both the precision\nand recall of their results. In terms of precision, results from\nweakly supervised algorithms contain much more noise and\noutliers due to indirect and incomplete supervision. Likewise, such algorithms also achieve much lower recall because there is insufficient labeled information for them to\nlearn comprehensive feature representations of target object\ncategories. However, different types of weakly supervised\nalgorithms may return different but complementary subsets\nof the ground truth.\nThese observations motivate an approach that first collect as many evidences and results as possible from multiple types of solution mechanisms, put them together, and\nthen remove noise and outliers from the fused results using\npowerful filtering techniques. This is in contrast to deep\nneural networks trained from end to end. Although this\napproach needs to collect results from multiple separately\ntrained networks, the filtered and fused evidences are eventually used for training a single network used for the testing\nstage. Therefore, the running time of the final network during the testing stage is still comparable to that of state-ofthe-art end-to-end networks.\nAccording to the above observations, we propose a\nweakly supervised curriculum learning pipeline for object\nrecognition, detection and segmentation. At a high level, we\n\nSupervised object detection and semantic segmentation\nrequire object or even pixel level annotations. When there\nexist image level labels only, it is challenging for weakly\nsupervised algorithms to achieve accurate predictions. The\naccuracy achieved by top weakly supervised algorithms is\nstill significantly lower than their fully supervised counterparts. In this paper, we propose a novel weakly supervised curriculum learning pipeline for multi-label object recognition, detection and semantic segmentation. In\nthis pipeline, we first obtain intermediate object localization and pixel labeling results for the training images, and\nthen use such results to train task-specific deep networks\nin a fully supervised manner. The entire process consists\nof four stages, including object localization in the training\nimages, filtering and fusing object instances, pixel labeling for the training images, and task-specific network training. To obtain clean object instances in the training images, we propose a novel algorithm for filtering, fusing and\nclassifying object instances collected from multiple solution\nmechanisms. In this algorithm, we incorporate both metric learning and density-based clustering to filter detected\nobject instances. Experiments show that our weakly supervised pipeline achieves state-of-the-art results in multi-label\nimage classification as well as weakly supervised object detection and very competitive results in weakly supervised\nsemantic segmentation on MS-COCO, PASCAL VOC 2007\nand PASCAL VOC 2012.\n\n1. Introduction\nDeep neural networks give rise to many breakthroughs in\ncomputer vision by usinging huge amounts of labeled training data. Supervised object detection and semantic segmentation require object or even pixel level annotations, which\nare much more labor-intensive to obtain than image level labels. On the other hand, when there exist image level labels\nonly, due to incomplete annotations, it is very challenging to\npredict accurate object locations, pixel-wise labels, or even\nimage level labels in multi-label image classification.\n4321\n\n\fobtain object localization and pixelwise semantic labeling\nresults for the training images first using their image level\nlabels, and then use such intermediate results to train object detection, semantic segmentation, and multi-label image classification networks in a fully supervised manner.\nSince image level, object level and pixel level analysis has mutual dependencies, they are not performed independently but organized into a single pipeline with four\nstages. In the first stage, we collect object localization results in the training images from both bottom-up and topdown weakly supervised object detection algorithms. In\nthe second stage, we incorporate both metric learning and\ndensity-based clustering to filter detected object instances.\nIn this way, we obtain a relatively clean and complete set of\nobject instances. Given these object instances, we further\ntrain a single-label object classifier, which is applied to all\nobject instances to obtain their final class labels. Third, to\nobtain a relatively clean pixel-wise probability map for every class and every training image, we fuse the image level\nattention map, object level attention maps and an object detection heat map. The pixel-wise probability maps are used\nfor training a fully convolutional network, which is applied\nto all training images to obtain their final pixel-wise label\nmaps. Finally, the obtained object instances and pixel-wise\nlabel maps for all the training images are used for training\ndeep networks for object detection and semantic segmentation respectively. To make pixel-wise label maps of the\ntraining images help multi-label image classification, we\nperform multi-task learning by training a single deep network with two branches, one for multi-label image classification and the other for pixel labeling. Experiments show\nthat our weakly supervised curriculum learning system is\ncapable of achieving state-of-the-art results in multi-label\nimage classification as well as weakly supervised object detection and very competitive results in weakly supervised\nsemantic segmentation on MS-COCO [25], PASCAL VOC\n2007 and PASCAL VOC 2012 [12].\nIn summary, this paper has the following contributions.\n\nalgorithm for fusing image level and object level attention\nmaps with an object detection heat map. The fused maps\nare used for training a fully convolutional network for pixel\nlabeling.\n\n2. Related Work\nWeakly Supervised Object Detection and Segmentation.\nWeakly supervised object detection and segmentation respectively locates and segments objects with image-level labels only [27, 7]. They are important for two reasons: first,\nlearning complex visual concepts from image level labels is\none of the key components in image understanding; second,\nfully supervised deep learning is too data hungry.\nWeakly supervised object detection/localization is usually performed in a bottom-up manner. Methods in [27, 10,\n9] treat the weakly supervised localization problem as an\nimage classification problem, and obtain object locations\nin specific pooling layers of their networks. Methods in\n[4, 37] extract object instances from images using selective search [39] or edge boxes [46], convert the weakly supervised detection problem into a multi-instance learning\nproblem [8]. The method in [8] at first learns object masks\nas in [10, 9], and then uses the E-M algorithm to force the\nnetwork to learn object segmentation masks obtained at previous stages. Since it is very hard for a network to directly\nlearn object locations and pixel labels without sufficient supervision, in this paper, we decompose object detection and\npixel labeling into multiple easier problems, and solve them\nprogressively in multiple stages.\nNeural Attention. Neural attention aims to find out the\nrelationship between the pixels in the input image and the\nneural responses in every layer of a network. Many efforts [42, 2, 23] have been made to explain how neural\nnetworks work. The method in [23] extends layer-wise\nrelevance propagation (LRP) [1] to comprehend inherent\nstructured reasoning of deep neural networks. To further ignore the cluttered background, a positive neural attention back-propagation scheme, called excitation backpropagation (Excitation BP), is introduced in [42]. The\nmethod in [2] locates top activations in each convolutional\nmap, and maps these top activation areas into the input image using bilinear interpolation.\nNeural attention provides a top-down mechanism to obtain pixel-wise class probabilities using image level labels\nonly. In our pipeline, we adopt the excitation BP [42] to\ncalculate pixel-wise class probabilities. However for images with multiple category labels, a deep neural network\ncould fuse the activations of different categories in the same\nneurons. To solve this problem, we train a single-label object instance classification network and perform excitation\nBP in this network to obtain more accurate pixel level class\nprobabilities.\nCurriculum Learning. Curriculum learning [3] is part of\n\n• We propose a novel weakly supervised pipeline for multilabel object recognition, detection and semantic segmentation. In this pipeline, we first obtain intermediate labeling\nresults for the training images, and then use such results to\ntrain task-specific networks in a fully supervised manner.\n• To obtain clean object instances detected in the training\nimages, we propose a novel algorithm for filtering, fusing and classifying object instances collected from multiple solution mechanisms. In this algorithm, we incorporate\nboth metric learning and density-based clustering to filter\ndetected object instances.\n• To obtain a relatively clean pixel-wise probability map for\nevery class and every training image, we propose a novel\n4322\n\n\f(a) Image Level Stage: Proposal Generation\nand Multi Evidence Fusion\nInput/Image\n\nObject Heatmap\n\nObject Instances\n\n(b) Instance Level Stage: Outlier Detection and\nObject Instance Filtering\nTriplet Loss Net\n\n(c) Pixel Level Stage: Probability Map Fusion\nand Pixel Label Prediction\n\nFiltered Object Instances\n\nLabel Map with\nUncertainty\n\nInstance Attention Map\n\nProbability Map\n\nImage Attention Map\nInstance Classifier\n\nFigure 1. The proposed weakly supervised pipeline. From left to right: (a) Image level stage: fuse the object heatmaps H and the image\nattention map Ag to generate object instances R for the instance level stage, and provide these two maps for information fusion at the pixel\nlevel stage. (b) Instance level stage: perform triplet loss based metric learning and density based clustering for outlier detection, and train a\nsingle label instance classifier φs (·, ·) for instance filtering. (c) Pixel level stage: integrate the object heatmaps H, instance attention map\nAl , and image attention map Ag for pixel labeling with uncertainty.\n\nthe broad family of machine learning methods that starts\nwith easier subtasks and gradually increases the difficulty\nlevel of the tasks. In [3], Yoshua et al. describe the concept\nof curriculum learning, and use a toy classification problem\nto show the advantage of decomposing a complex problem\ninto several easier ones. In fact, the idea behind curriculum learning has been widely used before [3]. Hinton et\nal. [17] trained a deep neural network layer by layer using\na restricted Boltzmann machine [35] to avoid the local minima in deep neural networks. Many machine learning algorithms [36, 14] follow a similar divide-and-conquer strategy\nin curriculum learning.\nIn this paper, we adopt this strategy to decompose the\npixel labeling problem into image level learning, object instance level learning and pixel level learning. All the learning tasks in these three stages are relatively simple using\nthe training data in the current stage and the output from the\nprevious stage.\n\n(a) Heatmap Proposals\n\n(b) Attention Proposals\n\n(c) Fused Proposals\n\nFigure 2. (a) Proposals Rh and Rl generated from an object\nheatmap, (b) proposals generated from an attention map, (c) filtered proposals (green), heatmap proposals (red and blue), and attention proposals (purple).\n\ndivide-and-conquer idea in curriculum learning [3], we decompose the pixel labeling task into three stages: the image\nlevel stage, the instance level stage and the pixel level stage.\n\n3. Weakly Supervised Curriculum Learning\n\n3.2. Image Level Stage\n\n3.1. Overview\n\nThe image level stage not only decomposes multi-label\nimage classification into a set of single-label object instance\nclassifications, but also provides an initial set of pixel-wise\nprobability maps for the pixel level stage.\nObject Heatmaps. Unlike the fully supervised case,\nweakly supervised object detection produces object instances with higher uncertainty and also misses a higher\npercentage of true objects. To reduce the number of missing detections, we propose to compute an object heatmap\nH for every object class existing in the image.\nFor an image I with width W and height H, a dense\nset of object proposals R = (R1 , R2 , ..., Rn ) are generated\nusing sliding anchor windows. And the feature stride λs is\n\nGiven an image I associated with an image level label\nvector y I = [y 1 , y 2 , ..., y C ]T , our weakly supervised curriculum learning aims to obtain pixel-wise labels Y I =\n[y 1 , y 2 , ..., y P ]T , and then use these labels to assist weakly\nsupervised object detection, semantic segmentation and\nmulti-label image classification. Here C is the total number of object classes, P is the total number of pixels in I,\nand y l is binary. y l = 1 means the l-th object class exists in\nI, and y l = 0 otherwise. The label of a pixel p is denoted\nby a C-dimensional binary vector y p . The number of object\nclasses existing in I, which is the same as the number of\npositive components of y I is denoted by K. Following the\n4323\n\n\fset to 8. The number of locations in the input image where\nwe can place anchor windows is H/λs × W/λs . Denote the\nshort side of image I by Lρ. Following the setting used for\nRPN [28], we let the anchor windows at a single location\nhave four scales [Lρ/8, Lρ/4, Lρ/2, Lρ] and three aspect\nratios [0.5, 1, 2]. After proposals out of image borders have\nbeen removed, there are usually 12000 remaining proposals\nper image. Here we define a stack of object heatmaps H =\n[H 1 , H 2 , ..., H C ] as a C ×H ×W matrix, and all values are\nset to zero initially. The object detection and classification\nnetwork φd (·, ·) used here is the weakly supervised object\ntesting net VGG-16 from [37]. For every proposal Ri in\nR, its object class probability vector φd (I, Ri ) is added to\nall the pixels in the corresponding window in the heatmaps.\nThen every heatmap is normalized to [0, 1] as follows,\n\n(a) Input Proposals\n\n(b) Distance Map\n\nFigure 3. (a) Input proposals of the triplet-loss network, (b) distance map computed using features from the triplet-loss network.\n\nRl and Ra . All these object proposals have corresponding\nclass labels. During the fusion, for each object class, the attention proposals Ra which cover more than 0.5 of any proposals in Rh are preserved. We denote these proposals by\nR, each of which is modified slightly to completely enclose\nthe corresponding proposal in Rh meanwhile be completely\ncontained inside the corresponding proposal in Rl (Fig 2).\n\nH c = (H c − min(H c ))/max(H c ),\nwhere H c is the heatmap for the c-th object class. Note\nthat only the heatmaps for object classes existing in I are\nnormalized. All the other heatmaps are ignored and set to\nzeros.\nMultiple Evidence Fusion. The object heatmaps highlight the regions that may contain objects even when the\nlevel of supervision is very weak. However, since they are\ngenerated using sliding anchor windows at multiple scales\nand aspect ratios, they tend to highlight pixels near but outside true objects, as shown in Fig 2. Given an image classification network trained using the image level labels (here\nwe use GoogleNet V1 [42]), neural attention calculates the\ncontribution of every pixel to the final classification result.\nIt tends to focus on the most influential regions but not necessarily the entire objects. Note that false positive regions\nmay occur during excitation BP [42]. To obtain more accurate object instances, we integrate the top-down attention maps Ag = [A1g , A2g , ..., ACg ] with the object heatmaps\nH = [H 1 , H 2 , ..., H C ].\nFor object classes existing in image I, their corresponding heatmaps H and attention maps Ag are thresholded by\ndistinct values. The heatmaps H are too smooth to indicate\naccurate object boundaries, but they provide important spatial priors to constrain object instances obtained from the\nattention maps. We assume that regions with a sufficiently\nhigh value in the object heatmaps should at least include\nparts of objects, and regions with sufficiently low values\neverywhere do not contain any objects. Following this assumption, we threshold the heatmaps with two values 0.65\nand 0.1 to identify highly confident object proposals Rh =\nh\n(R1h , R2h , ..., RN\n) and relatively low confident object proh\nl\nl\nl\nposals R = (R1 , R2l , ..., RN\n) after connected component\nl\nextraction. Then the attention maps are thresholded by 0.5\na\nto attention proposals Ra = (R1a , R2a , ..., RN\n) as shown\na\nin Fig 2. Nh , Nl and Na are the proposal numbers of Rh ,\n\n3.3. Instance Level Stage\nSince multiple object categories present in the same image make it hard for neural attention to obtain an accurate\npixel-wise attention map for each class, we train a singlelabel object instance classification network and compute attention maps in this network to obtain more accurate pixel\nlevel class probabilities. The fused object instances from\nthe image level stage are further filtered by metric learning\nand density-based clustering. The remaining labeled object\nproposals are used for training this object instance classifier, which can also be used to further remove remaining\nfalse positive object instances.\nMetric Learning for Feature Embedding. Metric learning is popular in face recognition [33], person reidentification and object tracking [33, 44, 38]. It embeds\nan image X into a multi-dimensional feature space by associating this image with a fixed size vector, φt (X, ·), in\nthe feature space. This embedding makes similar images\nclose to each other and dissimilar images apart in the feature space. Thus the similarity between two images can\nbe measured by their distance in this space. The tripletloss network φt (·, ·) proposed in [33] has the additional\nproperty that it can well separate classes even when intraclass distances have large variations. When there exist\ntraining samples associated with incorrect class labels, the\nloss stays at a high value and the distances between correctly labeled and mislabeled samples remain very large\neven after the training process has run for a long time.\nNow let R = [R1 , R2 , ..., RO ]T denote the fused object\ninstances from all training images in the image level stage,\nand Y = [y 1 , y 2 , ..., y O ]T are their labels. Here O is the\n4324\n\n\ftotal number of fused instances, and y l is the label vector\nof instance Rl . We train a triplet-loss network φt (·, ·) using\nGoogleNet V2 with BatchNorm as in [33]. Each mini-batch\nfirst chooses b object classes randomly, and then chooses a\ninstances from these classes randomly. These instances are\ncropped out from the training images and fed into φt (·, ·).\nFig. 3 visualizes a mini-batch composition and the corresponding pairwise distances among instances.\n\na full knowledge about the objects in an image but sometimes only focuses on the most important object parts. The\nobject instance classifier has a local view of each individual\nobject. With the help of object-specific local attention maps\ngenerated from the instance classifier, we can avoid missing\nsmall objects.\nInstance Attention Map. Here we define the instance attention map Al as a C × H × W matrix, and all values\nare zero initially. For every surviving object instance from\nthe instance level stage, the object instance classifier φs (·, ·)\nis used to extract its local attention map, and add it to\nthe corresponding region in the instance attention map Al .\nNormalize the range of Al to [0, 1] as we did for object\nheatmaps.\nProbability Map Integration. The final attention map A\nis obtained by calculating the element-wise maximum between the image attention map Ag and the instance attention map Al . That is, A = max(Al , Ag ). For both the\nheatmap H and the attention map A, only the classes existing in the image are considered. The background maps of\nA and H are defined as follows,\n\nClustering for Outlier Removal. Clustering aims to remove outliers that are less similar to other object instances\nin the same class. Specifically, we perform density based\nclustering [30] to form a single cluster of normal instances\nwithin each object class independently, and instances outside this cluster are considered outliers. This is different\nfrom that in [30]. Let Rc denote instances in R with class\nlabel c, and Nc is the number of instances in Rc . Calculate the pairwise distances d(·, ·) among these instances, and\nobtain the Nc by Nc distance matrix D c . For an instance\nRcn , if its distance from another instance is less than λd (=\n0.8), its density dcn is increased by 1. Rank these instances\nby their densities in a descending order, and choose the instance ranked at the top as the seed of the cluster. Then\nadd instances to the cluster following the descending order\nif their distance to any element in the cluster is less than λd\nand their density is higher than Nc /4.\n\nA0 = max(0, 1 − ΣCl=1 y l Al ),\nH 0 = max(0, 1 − ΣCl=1 y l H l ).\nNow both A and H become (C + 1) × H × W matrices.\nFor the l-th channel, if y l = 0, Al = 0 and H l = 0.\nThen we perform softmax on both maps along the channel\ndimension independently. The final probability map P is\ndefined as the result of applying softmax to the elementwise product between A and H by treating H as a filter.\nThat is, P = softmax(H A).\nPixel Labeling with Uncertainty. Pixel labels Y I are initialized with the probability map P . For every pixel p, if\nthe maximum element in its label vector y p is larger than\na threshold (=0.6), we simply set the maximum element to\n1 and other elements to 0; otherwise, the class label at p is\nuncertain.\n\nInstance Classifier for Re-labeling. Since metric learning and clustering screen object instances in an aggressive\nway and may heavily decrease their recall, we use the normal instances surviving the previous clustering step to train\nan instance classifier, which is in turn used to re-label all\nobject proposals generated in the image level stage again.\nThis is a single-label classification problem as each object\ninstance is allowed a single label. GoogleNet V1 with the\nSoftMax loss serves as the classifier φs (·, ·), and it is finetuned from the image level classifier. For every object proposal generated in the previous image level stage, if its label predicted by the instance classifier does not match its\noriginal label, it is labeled as an outlier and permanently\ndiscarded.\n\n4. Object Recognition, Detection and Segmentation\n\n3.4. Pixel Level Stage\nIn previous stages, we have already built an image classifier, a weakly supervised object detector, and an object\ninstance classifier. Each of these deep networks produces\nits own inference result from the input image. For example, the image classifier generates a global attention map,\nand the object detector generates the object heatmaps. In\nthe pixel level stage, we still perform multi-evidence filtering and fusion to integrate the inference results from all\nthese component networks to obtain the pixelwise probability map indicating potential object categories at every pixel.\nThe global attention map Ag from the image classifier has\n\n4.1. Semantic Segmentation\nGiven pixel-wise labels generated at the end of the pixel\nlevel stage for all training images, we train a fully convolutional network (FCN) similar to the network in [26] to\nperform semantic segmentation. Note that all pixels with\nuncertain class labels are excluded during training. In the\nprediction part, we adopt atrous spatial pyramid pooling as\nin [5]. The resulting trained network can be used for labeling all pixels in any testing image as well as pixels with\nuncertain labels in all training images.\n4325\n\n\f(a) Input/Image\n\n(b) Object Heatmap (c) Image Attention (d) Instance Attention (e) Probability\n\n(e) Segmentation\n\nFigure 4. The pixel labeling process in the pixel level stage. White pixels in the last column indicate pixels with uncertain labels.\n\n4.2. Object Detection\n\n5. Experimental Results\n\nOnce all pixels with uncertain labels in the training images have been re-labeled using the above network for semantic segmentation, we generate object instances in these\nimages by computing bounding boxes of connected pixels\nsharing the same semantic label. As in [37] and [24], we\ntrain fast RCNN [13] using these bounding boxes and their\nassociated labels. Since the bounding boxes generated from\nthe semantic label maps may contain noise, we filter them\nusing our object instance classifier as in Section 3.3. VGG16 is still the base network of our object detector, which is\ntrained with five scales and flip as in [37].\n\nAll our experiments are implemented using Caffe [18]\nand run on an NVIDIA TITAN X(Maxwell) GPU with\n12GB memory. The hyper-parameters in Section 3 are set\naccording to common sense and confirmed after we visually\nverify that the segmentation results on a few training samples are valid. The same parameter setting is used for all\ndatasets and has not been tuned on any validation sets.\n\n5.1. Semantic Segmentation\nDatasets and performance measures. The Pascal VOC\n2012 dataset [11] serves as a benchmark in most existing\nwork on weakly-supervised semantic segmentation. It has\n21 classes and 10582 training images (the VOC 2012 training set and additional data annotated in [15]), 1449 for validation and 1456 for testing. Only image tags are used as\ntraining data in our experiments. We report results on both\nthe validation (supplemental materials) and test sets.\nImplementation details. Our network is based on VGG16. The layers after relu5 3 and layer pool4 are removed.\nDilations in layers conv5 1, conv5 2, and conv5 3 are set\nto 2. The feature stride λs at layer relu5 3 is 8. We add the\natrous spatial pyramid pooling as in DeepLab V3 [5] after\nlayer relu5 3. The dilations in our atrous spatial pyramid\npooling layers are [1, 2, 4, 6]. This FCN is implemented in\npy-faster-rcnn [29]. For data augmentation, we use five image scales (480, 576, 688, 864, 1024) (the shorter side is\nresized to one of these scales) and horizontal flip, and cap\nthe longer side at 1200. During testing, the original size of\nan input image is preserved. The network is fine-tuned from\nthe pre-trained model for ImageNet in [34]. The learning\nrate γ is set to 0.001 in the first 20k iterations, and 0.0001\nin the next 20k iterations. The weight decay is 0.0005, and\nthe mini-batch size is 1. Post-processing using CRF [22] is\nadded during testing.\nResult comparison. We compare our method with existing state-of-the-art algorithms. Table 1 lists the results of\nweakly supervised semantic segmentation on Pascal VOC\n2012. The proposed method achieves 55.6% mean IoU,\ncomparable to the state of the art (AE-SPL [?]). Recent\nalgorithms, including AE-PSL[?], F-B [32], FCL [31], and\nSEC [21], all conduct end-to-end training to learn object\n\n4.3. Multi-label Classification\nThe main component in our multi-label classification\nnetwork is the structure of ResNet-101 [16]. There are\ntwo branches after layer res4b22 relu of the main component, one branch for classification and the other for semantic\nsegmentation. Both branches share the same structure after layer res4b22 relu. Here we adopt multi-task learning\nto train both branches. The idea is using the training data\nfor the segmentation branch to make the convolutional kernels in the main component more discriminative and powerful. This network architecture is shown in the supplemental\nmaterials. Layer pool5 of ResNet-101 in the classification\nbranch is removed, and the output X(∈ R14×14×2048 ) of\nlayer res5c is a 14 × 14 × 2048 matrix. X is directly fed\ninto a 2048 × 1 × 1 × C convolutional layer, and a classification map Ŷ cls (∈ R14×14×C ) is obtained. We let the\nsemantic label map Ŷ seg (∈ R14×14×C ) play the role of an\nattention map Ŷ att after the summation over each channel\nof the semantic label map is normalized to 1. The final image level probability vector ŷ is the result of spatial average\npooling over the element-wise product between Ŷ cls and\nŶ att . Here Ŷ att is used to identify important image regions and assign them larger weights. At the end, the probability vector ŷ is fully connected to an output layer, which\nperforms binary classification for each of the C classes. The\ncross-entropy loss is used for training the multi-label classification network. The segmentation branch uses atrous spatial pyramid pooling to perform semantic segmentation, and\nsoftmax is applied to enforce a single label per pixel.\n4326\n\n\fFigure 5. The detection and semantic segmentation results on Pascal VOC 2012 test set (the first row) and Pascal VOC 2007 test set (the\nsecond row). The detection results are gotten by select proposals with the highest confidence of every class. The semantic segmentation\nresults are post-processed by CRF [22].\nmethod\n\nbg\n\naero\n\nbike\n\nbird\n\nboat\n\nbottle\n\nbus\n\ncar\n\ncat\n\nchair\n\ncow\n\ntable\n\ndog\n\nhorse\n\nmbike\n\nperson\n\nplant\n\nsheep\n\nsofa\n\ntrain\n\ntv\n\nmIoU\n\nSEC[21]\nFCL[31]\nTP-BM[20]\n[?]\n\n83.5\n85.7\n83.4\n-\n\n56.4\n58.8\n62.2\n-\n\n28.5\n30.5\n26.4\n-\n\n64.1\n67.6\n71.8\n-\n\n23.6\n24.7\n18.2\n-\n\n46.5\n44.7\n49.5\n-\n\n70.6\n74.8\n66.5\n-\n\n58.5\n61.8\n63.8\n-\n\n71.3\n73.7\n73.4\n-\n\n23.2\n22.9\n19.0\n-\n\n54.0\n57.4\n56.6\n-\n\n28.0\n27.5\n35.7\n-\n\n68.1\n71.3\n69.3\n-\n\n62.1\n64.8\n61.3\n-\n\n70.0\n72.4\n71.7\n-\n\n55.0\n57.3\n69.2\n-\n\n38.4\n37.0\n39.1\n-\n\n58.0\n60.4\n66.3\n-\n\n39.9\n42.8\n44.8\n-\n\n38.4\n42.2\n35.9\n-\n\n48.3\n50.6\n45.5\n-\n\n51.7\n53.7\n53.8\n55.7\n\nOurs+CRF\n\n86.6\n\n72.0\n\n30.6\n\n68.0\n\n44.8\n\n46.2\n\n73.4\n\n56.6\n\n73.0\n\n18.9\n\n63.3\n\n32.0\n\n70.1\n\n72.2\n\n68.2\n\n56.1\n\n34.5\n\n67.5\n\n29.6\n\n60.2\n\n43.6\n\n55.6\n\nTable 1. Comparison among weakly supervised semantic segmentation methods on PASCAL VOC 2012 segmentation test set.\n\nscore maps. Our method demonstrates that if we filter and\nintegrate multiple types of intermediate evidences at different granularities during weakly supervised training, the results become equally competitive or even better.\n\nVOC 2007 test set (Table 2) and Pascal VOC 2012 test\nset (supplemental materials) are reported. Object localization results on Pascal VOC 2007 trainval set and Pascal\nVOC 2012 trainval set are also reported (supplemental material). On Pascal VOC 2012 test set, our algorithm achieves\nthe highest mAP (47.5%), at least 5.0% higher than the\nlatest state-of-the-art algorithms including OICR [37] and\nHCP+DSD+OSSH3[19]. Our trained model also achieves\nthe highest mAP (51.2%) among all weakly supervised algorithms on Pascal VOC 2007 test set, 4.2% higher than\nthe latest result from [37]. The object localization accuracy\n(CorLoc) of our trained model on Pascal VOC 2007 trainval set and Pascal VOC 2012 trainval set are respectively\n67% and 69.4%, which are 2.7% and 3.8% higher than the\nprevious best.\n\n5.2. Object Detection\nDatasets and performance measures. The performance of\nour object detector in Section 4.2 is evaluated on the popular Pascal VOC 2007 and Pascal VOC 2012 datasets [11].\nEach of these two datasets is divided into train, val and test\nsets. The trainval sets (5011 images for 2007 and 11540 images for 2012) are used for training, and only image tags are\nused. Two measures are used to test our model: mAP and\nCorLoc. According to the standard Pascal VOC protocol,\nthe mean average precision (mAP) is used for testing our\ntrained models on the test sets, and the correct localization\n(CorLoc) is used for measuring the object localization accuracy [6] on the trainval sets whose image tags are already\nused as training data.\nImplementation details. We use the code for py-fasterrcnn [29] to implement fast R-CNN [13]. The network is\nstill VGG-16. The learning rate is set to 0.001 in the first\n30k iterations, and 0.0001 in the next 10k iterations. The\nmomentum and weight decay are set to 0.9 and 0.0005 respectively. We follow the same data augmentation setting in\n[37], use five image scales (480, 576, 688, 864, 1200) and\nhorizontal flip, and cap the longer image side at 2000.\nResult comparison. Object detection results on Pascal\n\n5.3. Multi-Label Classification\nDataset and performance measures.\nMicrosoft\nCOCO [25] is the most popular dataset in multi-label\nclassification. MS-COCO was primarily built for object\nrecognition tasks in the context of scene understanding.\nThe training set is composed of 82081 images in 80\nclasses, on average 2.9 object labels per image. Since\nthe groundtruth labels of the test set is not available,\nperformance evaluation is conducted on the validation set\nwith 40504 images. We train our models on the training set\nand test them on the validation set.\nPerformance measures for multi-label classification is\n4327\n\n\fmethod\n\naero\n\nbike\n\nbird\n\nboat\n\nbottle\n\nbus\n\ncar\n\ncat\n\nchair\n\ncow\n\ntable\n\ndog\n\nhorse\n\nmbike\n\nperson\n\nplant\n\nsheep\n\nsofa\n\ntrain\n\ntv\n\nmAP\n\nOM+MIL+FRCNN[24]\nHCP+DSD+OSSH3[19]\nOICR-Ens+FRCNN[37]\n\n54.5\n54.2\n65.5\n\n47.4\n52.0\n67.2\n\n41.3\n35.2\n47.2\n\n20.8\n25.9\n21.6\n\n17.7\n15.0\n22.1\n\n51.9\n59.6\n68.0\n\n63.5\n67.9\n68.5\n\n46.1\n58.7\n35.9\n\n21.8\n10.1\n5.7\n\n57.1\n67.4\n63.1\n\n22.1\n27.3\n49.5\n\n34.4\n37.8\n30.3\n\n50.5\n54.8\n64.7\n\n61.8\n67.3\n66.1\n\n16.2\n5.1\n13.0\n\n29.9\n19.7\n25.6\n\n40.7\n52.6\n50.0\n\n15.9\n43.5\n57.1\n\n55.3\n56.9\n60.2\n\n40.2\n62.5\n59.0\n\n39.5\n43.7\n47.0\n\nOurs+FRCNN w/o clustering\nOurs+FRCNN w/o uncertainty\nOurs+FRCNN w/o instances\nOurs+FRCNN\n\n66.7\n66.8\n67.7\n64.3\n\n61.8\n63.4\n62.9\n68.0\n\n55.3\n54.5\n53.1\n56.2\n\n41.8\n42.2\n44.4\n36.4\n\n6.7\n5.8\n11.2\n23.1\n\n61.2\n60.5\n62.4\n68.5\n\n62.5\n58.3\n58.5\n67.2\n\n72.8\n67.8\n71.2\n64.9\n\n12.7\n7.8\n8.3\n7.1\n\n46.2\n46.1\n45.7\n54.1\n\n40.9\n40.3\n41.5\n47.0\n\n71.0\n71.0\n71.0\n57.0\n\n67.3\n68.2\n68.0\n69.3\n\n64.7\n62.6\n59.2\n65.4\n\n30.9\n30.7\n30.3\n20.8\n\n16.7\n16.5\n15.0\n23.2\n\n42.6\n41.1\n42.4\n50.7\n\n56.0\n55.2\n56.0\n59.6\n\n65.0\n66.8\n67.2\n65.2\n\n26.5\n25.2\n26.8\n57.0\n\n48.5\n47.5\n48.1\n51.2\n\nTable 2. Average precision (in %) of weakly supervised methods on PASCAL VOC 2007 detection test set.\nmethod\n\nF1-C\n\nP-C\n\nR-C\n\nF1-O\n\nP-O\n\nR-O\n\nF1-C/top3\n\nP-C/top3\n\nR-C/top3\n\nF1-O/top3\n\nP-O/top3\n\nR-O/top3\n\nCNN-RNN[40]\nRLSD[43]\nRNN-Attention[41]\nResNet101-SRN[45]\n\n70.0\n\n81.2\n\n63.3\n\n75.0\n\n84.1\n\n67.7\n\n60.4\n62.0\n67.4\n66.3\n\n66.0\n67.6\n79.1\n85.8\n\n55.6\n57.2\n58.7\n57.5\n\n67.8\n66.5\n72.0\n72.1\n\n69.2\n70.1\n84.0\n88.1\n\n66.4\n63.4\n63.0\n61.1\n\nResNet101(448 × 448)(baseline)\nOurs\n\n72.8\n74.9\n\n73.8\n80.4\n\n72.9\n70.2\n\n76.3\n78.4\n\n77.5\n85.2\n\n75.1\n72.5\n\n69.5\n70.6\n\n78.3\n84.5\n\n63.7\n62.2\n\n73.1\n74.7\n\n83.8\n89.1\n\n64.9\n64.3\n\nTable 3. Performance comparison among multi-label classification methods on Microsoft COCO 2014 validation set.\n\nquite different from those for single-label classification.\nFollowing [45, 41], we employ macro/micro precision,\nmacro/micro recall, and macro/micro F1-measure to evaluate our trained models. For precision, recall and F1measure, labels with confidence higher than 0.5 are considered positive. “P-C”, “R-C” and “F1-C” represent the average per-class precision, recall and F1-measure while “P-O”,\n“R-O” and “F1-O” represent the average overall precision,\nrecall and F1-measure. These measures do not require a\nfixed number of labels per image. To compare with existing state-of-the-art algorithms, we also report the results of\ntop-3 labels with confidence higher than 0.5 as in [41].\n\nC of ResNet101-SRN. In comparison to the baseline, our\ntwo-branch network further achieves overall better performance. Specifically, the P-C of our two-branch network is\n6.6% higher than the baseline, the R-C is 2.7% lower, and\nthe F1-C is 2.1% higher. All F1-measures (F1-C, F1-O, F1C/top3 and F1-O/top3) of our two-branch network are the\nhighest among all state-of-the-art algorithms.\n\n5.4. Ablation Study\nWe perform an ablation study on Pascal VOC 2007 detection test set by replacing or removing a single component\nin our pipeline every time. First, to verify the importance\nof object instances, we remove all steps related to object\ninstances, including the entire instance level stage and the\noperations related to the instance attention map in the pixel\nlevel stage. The mAP is decreased by 3.1% as shown in Table 2. Second, the clustering and outlier detection step in\nthe instance level stage is removed. We directly train an instance classifier using the object proposals from the image\nlevel stage. The mAP is decreased by 2.7%. Third, instead\nof labeling a subset of pixels only in the pixel level stage,\nwe assign a unique label to every pixel even in the case of\nlow confidence. The mAP drops to 47.5%, 3.7% lower than\nthe performance of the original pipeline.\n\nImplementation details. Our main network for multi-label\nclassification is ResNet-101 as described earlier. The resolution of the input images is at 448 × 448. We first train a\nnetwork with the classification branch only. As a common\npractice, a pre-trained model for ImageNet is fine-tuned\nwith the learning rate γ set to 0.001 in the first 20k iterations, and 0.0001 in the next 20k iterations. The weight\ndecay is 0.0005. Then we add the segmentation branch\nand train this new branch only by fixing all the layers before layer res4b22 relu and the classification branch. The\nlearning rate is set to 0.001 in the frist 20k iterations, and\n0.0001 in the next 20k iterations. At last, we train the\nentire network with both branches using the cross-entropy\nloss for multi-label classification for 30k iterations with a\nlearning rate 0.0001 while still fixing the layers before layer\nres4b22 relu.\n\n6. Conclusions\nIn this paper, we have presented a new pipeline for\nweakly supervised object recognition, detection and segmentation. Different from previous algorithms, we fuse and\nfilter object instances from different techniques and perform\npixel labeling with uncertainty. We use the resulting pixelwise labels to generate groundtruth bounding boxes for object detection and attention maps for multi-label classification. Our pipeline has achieved clearly better performance\nin all of these tasks. Nevertheless, how to simplify the steps\nin our pipeline deserves further investigation.\n\nResult comparison. In addition to our two-branch network,\nwe also train a ResNet-101 classification network as our\nbaseline. The multi-label classification performance of both\nnetworks on MS-COCO is reported in Table 3. Since the input resolution of our baseline is 448 × 448, in comparison\nto the latest work (ResNet101-SRN) [45], the performance\nof our baseline is slightly better. Specifically, the F1-C of\nour baseline is 72.8%, which is 2.8% higher than the F14328\n\n\fReferences\n\n[16] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages\n770–778, 2016. 4326\n[17] G. E. Hinton, S. Osindero, and Y.-W. Teh. A fast learning algorithm for deep belief nets. Neural computation,\n18(7):1527–1554, 2006. 4323\n[18] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. In Proceedings of the 22nd ACM international conference on Multimedia, pages 675–678. ACM, 2014. 4326\n[19] Z. Jie, Y. Wei, X. Jin, J. Feng, and W. Liu. Deep self-taught\nlearning for weakly supervised object localization. In The\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017. 4327, 4328\n[20] D. Kim, D. Cho, D. Yoo, and I. So Kweon. Two-phase learning for weakly supervised object localization. In The IEEE\nInternational Conference on Computer Vision (ICCV), Oct\n2017. 4327\n[21] A. Kolesnikov and C. H. Lampert. Seed, expand and constrain: Three principles for weakly-supervised image segmentation. In European Conference on Computer Vision,\npages 695–711. Springer, 2016. 4326, 4327\n[22] P. Krähenbühl and V. Koltun. Efficient inference in fully\nconnected crfs with gaussian edge potentials. In Advances\nin neural information processing systems, pages 109–117,\n2011. 4326, 4327\n[23] S. Lapuschkin, A. Binder, G. Montavon, K.-R. Muller, and\nW. Samek. Analyzing classifiers: Fisher vectors and deep\nneural networks. In Proceedings of the IEEE Conference\non Computer Vision and Pattern Recognition, pages 2912–\n2920, 2016. 4321, 4322\n[24] D. Li, J.-B. Huang, Y. Li, S. Wang, and M.-H. Yang. Weakly\nsupervised object localization with progressive domain adaptation. In Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition, pages 3512–3520, 2016.\n4326, 4328\n[25] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, and C. L. Zitnick. Microsoft coco: Common objects in context. In European conference on computer\nvision, pages 740–755. Springer, 2014. 4322, 4327\n[26] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional\nnetworks for semantic segmentation. In Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition, pages 3431–3440, 2015. 4325\n[27] M. Oquab, L. Bottou, I. Laptev, and J. Sivic. Is object localization for free?-weakly-supervised learning with convolutional neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages\n685–694, 2015. 4322\n[28] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards\nreal-time object detection with region proposal networks. In\nAdvances in neural information processing systems, pages\n91–99, 2015. 4324\n[29] S. Ren, K. He, R. Girshick, and J. Sun. Faster R-CNN: Towards real-time object detection with region proposal net-\n\n[1] S. Bach, A. Binder, G. Montavon, F. Klauschen, K.-R.\nMüller, and W. Samek. On pixel-wise explanations for nonlinear classifier decisions by layer-wise relevance propagation. PloS one, 10(7):e0130140, 2015. 4322\n[2] D. Bau, B. Zhou, A. Khosla, A. Oliva, and A. Torralba. Network dissection: Quantifying interpretability of deep visual\nrepresentations. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017. 4322\n[3] Y. Bengio, J. Louradour, R. Collobert, and J. Weston. Curriculum learning. In Proceedings of the 26th annual international conference on machine learning, pages 41–48. ACM,\n2009. 4322, 4323\n[4] H. Bilen and A. Vedaldi. Weakly supervised deep detection\nnetworks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2846–2854,\n2016. 4322\n[5] L.-C. Chen, G. Papandreou, F. Schroff, and H. Adam. Rethinking atrous convolution for semantic image segmentation. arXiv preprint arXiv:1706.05587, 2017. 4325, 4326\n[6] T. Deselaers, B. Alexe, and V. Ferrari. Weakly supervised\nlocalization and learning with generic knowledge. International journal of computer vision, 100(3):275–293, 2012.\n4327\n[7] A. Diba, V. Sharma, A. Pazandeh, H. Pirsiavash, and\nL. Van Gool. Weakly supervised cascaded convolutional networks. arXiv preprint arXiv:1611.08258, 2016. 4322\n[8] T. G. Dietterich, R. H. Lathrop, and T. Lozano-Pérez. Solving the multiple instance problem with axis-parallel rectangles. Artificial intelligence, 89(1):31–71, 1997. 4322\n[9] T. Durand, T. Mordan, N. Thome, and M. Cord. Wildcat: Weakly supervised learning of deep convnets for image\nclassification, pointwise localization and segmentation. In\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR 2017), 2017. 4322\n[10] T. Durand, N. Thome, and M. Cord. Weldon: Weakly supervised learning of deep convolutional neural networks. In\nProceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition, pages 4743–4752, 2016. 4322\n[11] M. Everingham, S. A. Eslami, L. Van Gool, C. K. Williams,\nJ. Winn, and A. Zisserman. The pascal visual object classes\nchallenge: A retrospective. International journal of computer vision, 111(1):98–136, 2015. 4326, 4327\n[12] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and\nA. Zisserman. The pascal visual object classes (voc) challenge. International journal of computer vision, 88(2):303–\n338, 2010. 4322\n[13] R. Girshick. Fast r-cnn. In Proceedings of the IEEE international conference on computer vision, pages 1440–1448,\n2015. 4326, 4327\n[14] A. Graves, M. G. Bellemare, J. Menick, R. Munos, and\nK. Kavukcuoglu. Automated curriculum learning for neural networks. arXiv preprint arXiv:1704.03003, 2017. 4323\n[15] B. Hariharan, P. Arbeláez, L. Bourdev, S. Maji, and J. Malik.\nSemantic contours from inverse detectors. In Computer Vision (ICCV), 2011 IEEE International Conference on, pages\n991–998. IEEE, 2011. 4326\n\n4329\n\n\f[30]\n\n[31]\n\n[32]\n\n[33]\n\n[34]\n\n[35]\n\n[36]\n\n[37]\n\n[38]\n\n[39]\n\n[40]\n\n[41]\n\n[42]\n\n[43]\n\n[44] L. Zheng, Y. Yang, and A. G. Hauptmann. Person reidentification: Past, present and future. arXiv preprint\narXiv:1610.02984, 2016. 4324\n[45] F. Zhu, H. Li, W. Ouyang, N. Yu, and X. Wang. Learning spatial regularization with image-level supervisions for\nmulti-label image classification. In The IEEE Conference\non Computer Vision and Pattern Recognition (CVPR), July\n2017. 4328\n[46] C. L. Zitnick and P. Dollár. Edge boxes: Locating object\nproposals from edges. In European Conference on Computer\nVision, pages 391–405. Springer, 2014. 4322\n\nworks. In Advances in Neural Information Processing Systems (NIPS), 2015. 4326, 4327\nA. Rodriguez and A. Laio. Clustering by fast search and\nfind of density peaks. Science, 344(6191):1492–1496, 2014.\n4325\nA. Roy and S. Todorovic. Combining bottom-up, top-down,\nand smoothness cues for weakly supervised image segmentation. In Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition, pages 3529–3538, 2017.\n4321, 4326, 4327\nF. Saleh, M. S. A. Akbarian, M. Salzmann, L. Petersson,\nS. Gould, and J. M. Alvarez. Built-in foreground/background\nprior for weakly-supervised semantic segmentation. In European Conference on Computer Vision, pages 413–432.\nSpringer, 2016. 4326\nF. Schroff, D. Kalenichenko, and J. Philbin. Facenet: A unified embedding for face recognition and clustering. In Proceedings of the IEEE Conference on Computer Vision and\nPattern Recognition, pages 815–823, 2015. 4324, 4325\nK. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. CoRR,\nabs/1409.1556, 2014. 4326\nP. Smolensky. Information processing in dynamical systems:\nFoundations of harmony theory. Technical report, COLORADO UNIV AT BOULDER DEPT OF COMPUTER\nSCIENCE, 1986. 4323\nL. Sun, Q. Huo, W. Jia, and K. Chen. A robust approach for\ntext detection from natural scene images. Pattern Recognition, 48(9):2906–2920, 2015. 4323\nP. Tang, X. Wang, X. Bai, and W. Liu. Multiple instance\ndetection network with online instance classifier refinement.\nIn The IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR), July 2017. 4322, 4324, 4326, 4327,\n4328\nG. Tsagkatakis and A. Savakis. Online distance metric\nlearning for object tracking. IEEE Transactions on Circuits\nand Systems for Video Technology, 21(12):1810–1821, 2011.\n4324\nJ. R. Uijlings, K. E. Van De Sande, T. Gevers, and A. W.\nSmeulders. Selective search for object recognition. International journal of computer vision, 104(2):154–171, 2013.\n4322\nJ. Wang, Y. Yang, J. Mao, Z. Huang, C. Huang, and W. Xu.\nCnn-rnn: A unified framework for multi-label image classification. In Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition, pages 2285–2294, 2016.\n4328\nZ. Wang, T. Chen, G. Li, R. Xu, and L. Lin. Multi-label\nimage recognition by recurrently discovering attentional regions. In Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition, pages 464–472, 2017. 4328\nJ. Zhang, Z. Lin, J. Brandt, X. Shen, and S. Sclaroff. Topdown neural attention by excitation backprop. In European\nConference on Computer Vision, pages 543–559. Springer,\n2016. 4321, 4322, 4324\nJ. Zhang, Q. Wu, C. Shen, J. Zhang, and J. Lu. Multi-label\nimage classification with regional latent semantic dependencies. arXiv preprint arXiv:1612.01082, 2016. 4328\n\n4330\n\n\f",
         "train",
         "48920",
         "7747"
        ],
        [
         "21",
         "20069",
         "cs.AI",
         "Artificial Intelligence",
         "1711.05508v1.pdf",
         "O PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nA Generally Applicable, Highly Scalable Measurement\nComputation and Optimization Approach to Sequential\nModel-Based Diagnosis∗\nPatrick Rodler†\nWolfgang Schmid\nKonstantin Schekotihin\n\nPATRICK . RODLER @ AAU . AT\nWOLFGANG . SCHMID @ AAU . AT\nKONSTANTIN . SCHEKOTIHIN @ AAU . AT\n\narXiv:1711.05508v1 [cs.AI] 15 Nov 2017\n\nAlpen-Adria Universität Klagenfurt, Universitätsstraße 65-67,\n9020 Klagenfurt, Austria\n\nAbstract\nModel-based diagnosis deals with the identification of the real cause of a system’s malfunction based on a formal system model and observations of the system behavior. When a malfunction is detected, there is usually not enough information available to pinpoint the real cause\nand one needs to discriminate between multiple fault hypotheses (diagnoses). To this end,\nsequential diagnosis approaches ask an oracle for additional system measurements.\nThis work presents strategies for (optimal) measurement selection in model-based sequential diagnosis. In particular, assuming a set of leading diagnoses being given, we show how\nqueries (sets of measurements) can be computed and optimized along two dimensions: expected number of queries and cost per query. By means of a suitable decoupling of two optimizations and a clever search space reduction the computations are done without any inference\nengine calls. For the full search space, we give a method requiring only a polynomial number\nof inferences and show how query properties can be guaranteed which existing methods do not\nprovide. Evaluation results using real-world problems indicate that the new method computes\n(virtually) optimal queries instantly independently of the size and complexity of the considered diagnosis problems and outperforms equally general methods not exploiting the proposed\ntheory by orders of magnitude.\n\n1. Introduction\nModel-based diagnosis (MBD) is a widely applied approach to finding explanations for unexpected behavior of observed systems such as hardware [Reiter, 1987, Dressler and Struss, 1996],\nsoftware [Stumptner and Wotawa, 1999, Mateis et al., 2000, Steinbauer et al., 2005], knowledge\nbases [Parsia et al., 2005, Kalyanpur, 2006, Shchekotykhin et al., 2012, Rodler, 2015], discrete\nevent systems [Darwiche and Provan, 1996, Pencolé and Cordier, 2005], feature models [White\net al., 2010] and user interfaces [Felfernig et al., 2009]. MBD assumes a formal system model\n∗. Parts of this work have been accepted for publication at DX’17 – Workshop on Principles of Diagnosis. First,\nthe reduction of model-based diagnosis problems to knowledge base debugging problems (Sec. 2.3) is treated\nin [Rodler and Schekotihin, 2017]. Second, the query computation approach dealt with in Sec. 3 is discussed\nin [Rodler et al., 2017]. This work extends the previously published ones significantly in several respects. For\ninstance, it comprises a much more detailed treatment of the underlying theory, all proofs, numerous illustrating\nexamples, various additional remarks and a much more comprehensive experimental evaluation.\n†. Corresponding author\n\n1\n\n\fand a set of relevant possibly faulty system components (e.g. lines of code, gates in a circuit).\nThe model includes descriptions of the interrelation between the components (e.g. wires between gates), descriptions of the components’ nominal behavior (e.g. relation between inputs\nand outputs of a gate) and other relevant knowledge (e.g. axioms of Boolean logic). An MBD\nproblem arises if observations (e.g. sensor readings, system outputs) of the system’s behavior\ndiffer from predictions based on the system model. In this case, the set of observations is inconsistent with the system model under the assumption that all system components are exhibiting a\nnominal behavior. The sought solution to an MBD problem is a diagnosis pinpointing the faulty\ncomponents causing the observed system failure. Normally, however, due to initially insufficient\nobservations, this fault localization is ambiguous and multiple possible diagnoses exist.\nSequential Diagnosis methods [de Kleer and Williams, 1987, Pietersma et al., 2005, Feldman\net al., 2010, Siddiqi and Huang, 2011, Shchekotykhin et al., 2012] address this issue. These\ncollect additional information by generating a sequence of queries and assume available some\noracle providing answers to these queries. Depending on the MBD application domain, queries\ncan be, for instance, measurements (e.g. probes in a circuit), system tests (observations about\nthe system’s behavior upon new system inputs), questions to a domain expert (e.g. to a doctor\nwhen debugging a medical knowledge base) or component inspections (e.g. checking the battery\nof a car). Likewise, the instantiation of the oracle might be, for instance, an electrical engineer\nperforming probes using a voltmeter, an IDE running software tests or a car mechanic inspecting\ncomponents of a vehicle. If queries are chosen properly, each query’s answer eliminates some\ndiagnoses and thus reduces the diagnostic uncertainty (pruning of the space of possible diagnoses). As query answering is normally costly, the goal of sequential diagnosis is to minimize\nthe diagnostic cost in terms of, e.g., time, manpower or equipment required to achieve a diagnostic goal, e.g., the extraction of a diagnosis with a probability above some threshold or the\nisolation of a single remaining diagnosis (which then corresponds to the actual diagnosis, i.e.\nthe actual cause of the system failure).\nA generic sequential diagnosis system is illustrated by Fig. 1. It gets the inputs SD (system\ndescription), COMPS (system components), OBS (initial observations), MEAS (additional observations / performed measurements), which altogether make up a diagnosis problem instance\n(DPI), and possibly some fault information (e.g. in terms of failure probabilities of system components). The usual workflow (see numbers in Fig. 1) followed by such a system involves the\n(1) computation of a (feasible) set of diagnoses by a diagnosis engine using the DPI and fault\ninformation, (2) computation of a set of query candidates by a query generation module based\non the given diagnoses, (3) selection of the best query from the given candidates, (4) answering\nof this query by the interacting oracle, (5+6) addition of the returned query along with its answer\nto the DPI in terms of new measurements (MEAS). The diagnosis engine uses these new measurements to perform various updates (e.g. pruning of the diagnoses space, adapting the fault\ninformation). If the diagnostic goal is not accomplished, the entire process starts anew from (1).\nOtherwise, the best diagnosis is output. The focus of this work lies on the optimization of steps\n(2) and (3) in terms of both efficiency and output quality (see violet shaded area in Fig. 1).\nNote, the steps (1) and (2) draw on a logical reasoner. Since logical reasoning is one of the\nmain sources of complexity in sequential diagnosis, the amount of reasoning should be ideally as\nminimal as possible, indicated by the red arrow in Fig. 1. Basically, there are two different rea2\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nInput: SD, COMPS, OBS, MEAS\n\nSEQUENTIAL DIAGNOSIS SYSTEM\n2: Queries\n\nQuery\nGeneration\n\nQuery Selection\n\n5: Query+Answer\n\nDPI\n\n3: Best Query\n\n4: Answer\n\nOracle\n\n1: Diagnoses\n6: New Measurement(s)\nInput\n\nDiagnosis\nEngine\n\nFault Information\n\nLogical Reasoner\n\nOutput: Diagnosis D*\n\nFigure 1: Schematic view on a generic sequential diagnosis system. The area shaded in violet shows\nthe part of the system optimized by the approach in this work. The red arrow emphasizes that\n(expensive) reasoner calls have to be minimized.\n\nsoning paradigms sequential diagnosis systems might use, glass-box and black-box. Glass-box\napproaches directly integrate reasoning with diagnoses finding with the goal of achieving better\nperformance. To this end the internals of the reasoner are suitably modified or, respectively,\nreasoners are complemented by additional services, e.g., bookkeeping in an ATMS [de Kleer,\n1986]. One example [de Kleer and Williams, 1987] is the storing of (minimal) environments\n(sets of logical sentences sufficient) for entailments predicted by the system model. These are\nleveraged to compute so-called nogood sets [de Kleer, 1986], i.e. environments for entailments\ninconsistent with observations. The latter can be directly used for diagnoses construction. Glassbox approaches are therefore dependent on the particular (modified) reasoner and thus on the\nparticular logic for which the reasoner is sound and complete. Black-box approaches use the\nreasoner as an oracle for answering consistency or entailment queries. The reasoner is used as-is\nwithout requiring any alterations to its implementation or any supplements. Consequently, these\napproaches are independent of the logic used for describing the system model and of the particular reasoner employed, and can benefit from latest improvements of reasoning algorithms.\nFor instance, black-box approaches can switch to reasoners specialized in a certain sublanguage\n(e.g. polynomial-time reasoner ELK [Kazakov et al., 2014] for OWL EL [Krötzsch, 2010]) of a\nlogic (e.g. OWL 2 [Grau et al., 2008] where reasoning is N2EXPTIME-complete) “for free” in\na simple plug-in fashion if the system description is formalized in this sublanguage.\nFirst, while glass-box approaches in many cases offer some performance gain over blackbox approaches, this gain was shown to be not that significant – in most cases the time cost of\nboth paradigms lay within the same order of magnitude – in extensive evaluations carried out by\n[Horridge, 2011] using Description Logics [Baader et al., 2007] of reasoning complexity ranging\nfrom polynomial to N2EXPTIME-complete. Black-box approaches even outperformed glass3\n\n\fbox approaches in a significant number of cases, witnessed in similar experiments conducted by\n[Kalyanpur, 2006]. When using bookkeeping methods, the information stored by these might\ngrow exponentially with the problem size [Schiex and Verfaillie, 1994]. Moreover, switching\nto more efficient reasoners (e.g., for fragments of a logic, see above) is not (easily) possible for\nglass-box approaches. Second, system descriptions (SD) in MBD might use a wide range of different knowledge representation formalisms such as First-Order Logic fragments, Propositional\nLogic, Horn clauses, equations, constraints, Description Logics or OWL. For these reasons we\npresent a logics- and reasoner-independent black-box approach to sequential diagnosis which\nis appropriate for all monotonic and decidable knowledge representation languages. This preserves a maximal generality of our approach and makes it broadly applicable across different\nMBD application domains.\nBecause the problem of optimal query selection1 is NP-complete [Hyafil and Rivest, 1976],\nsequential diagnosis approaches have to bear on a trade-off between query optimality and computational complexity. Therefore, it is current practice to rely on myopic (usually one-step\nlookahead) methods to guide diagnoses discrimination [de Kleer and Williams, 1987, Feldman\net al., 2010, Gonzalez-Sanchez et al., 2011, Shchekotykhin et al., 2012, Rodler et al., 2013].\nEmpirical [de Kleer et al., 1992b, Shchekotykhin et al., 2012, Rodler et al., 2013] and theoretical [Pattipati and Alexandridis, 1990] evaluations have evidenced that such heuristic methods\nin many cases deliver reasonable and in some scenarios even (nearly) optimal results. Moreover, query selection based on a multi-step lookahead is computationally prohibitive due to the\ninvolved expensive model-based reasoning (cf. Sec. 5). In common with the above-mentioned\napproaches we model the query selection heuristic as a query selection measure m assigning a\nreal-value to each query based on its quality (regarding diagnoses discrimination). One popular\nsuch measure is entropy [de Kleer and Williams, 1987], which favors queries with a maximal\nexpected information gain or, equivalently, a maximal expected reduction of the diagnostic uncertainty. The goal of any such measure m is the minimization of the number of queries required\nuntil achieving the appointed diagnostic goal.\nWhereas sequential diagnosis approaches usually incorporate the optimization of a query\nselection measure m, they often do not optimize the query (answering) cost such as the time\nrequired to perform measurements [Heckerman et al., 1995]. We model this cost by a query cost\nmeasure c, a function allocating a real-valued cost to each query. The approach suggested in this\nwork is devised to compute optimized queries along the m and c axes at each (query selection)\nstep in the sequential diagnosis process while minimizing the required computational resources.\nMore concretely, the contributions of this work are the following:\nContributions. We present a novel query optimization method that is generally applicable to\nany MBD problem in the sense of [de Kleer and Williams, 1987, Reiter, 1987] and\n1. defines a query as a set of First-Order Logic sentences and thus generalizes the measurement notion of [de Kleer and Williams, 1987, Reiter, 1987],\n2. given a set of leading diagnoses [de Kleer and Williams, 1989], allows the two-dimensional\noptimization of the next query in terms of the expected number of subsequent queries\n(measure m) and query cost (measure c),\n1. Also known as Optimal Test Sequencing Problem [Pattipati and Alexandridis, 1990] or Optimal Decision Tree\nProblem [Hyafil and Rivest, 1976].\n\n4\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\n3. for an aptly refined (yet exponential) query search space, finds – without any reasoner\ncalls – the globally optimal query w.r.t. measure c that globally optimizes measure m,2\n4. for the full query search space, finds – with a polynomial number of reasoner calls – the\n(under reasonable assumptions) globally optimal query w.r.t. m that includes, if possible,\nonly “cost-preferred” sentences (e.g. those answerable using built-in sensors),\n5. guarantees the proposal of queries that discriminate between all leading diagnoses and\nthat unambiguously identify the actual diagnosis.\nFurthermore,\n6. we show that any MBD problem can be reduced to a Knowledge Base Debugging (KBD)\nproblem [Shchekotykhin et al., 2012, Rodler, 2015]. This result establishes a formal relationship between these two paradigms, shows the greater generality of the latter and\nenables the transferral of findings in the KBD domain to the MBD domain.\nIn a nutshell, the presented query optimization method can be subdivided into three phases,\nP1, P2 and P3. In the first place, P1 optimizes the next query’s discrimination properties (e.g.\nthe expected information gain) based on the criteria imposed by the given QSM m, realized\nby a heuristic backtracking search. Then, as a first option, P2 computes an optimal query Q∗\nregarding the given QCM c by running a uniform-cost hitting set tree search over a suitable\n(and explicitly given) set of partial leading diagnoses. This is done in a way Q∗ meets exactly\nthe optimal discrimination properties determined in P1. P2 explores the largest possible query\nsearch space that can be handled without any reasoner calls in a complete way. The output\nQ∗ suggests the inspection of the system component(s) that is least expensive for the oracle\n(QCM c) among all those that yield the highest information (QSM m). As a second option\nand alternative to P2, P3 performs a two-step optimization consisting of a first generalization\nof the addressed search space and a subsequent divide-and-conquer exploration of this search\nspace focused on cost-preferred measurements. P3 returns a cost-optimal query Q∗ (w.r.t. some\nQCM c) complying with the optimal discrimination properties fixed in P1. Q∗ may include\nmeasurements of arbitrary type, depending on priorly definable requirements.\nRoughly, the efficiency of the novel approach is possible by the recognition that the optimizations of m and c can be decoupled and by using logical monotonicity as well as the inherent\n(already inferred) information in the (⊆-minimal) leading diagnoses. The latter is leveraged to\nachieve a retention of costly reasoner calls until the final query computation stage (P3), and\nhence to reduce them to a minimum. In particular, the method is inexpensive as it\n(a) avoids the generation and examination of unnecessary (non-discriminating) or duplicate\nquery candidates,\n(b) actually computes only the single best query by its ability to estimate a query’s quality\nwithout computing it, and\n(c) guarantees soundness and completeness w.r.t. an exponential query search space independently of the properties and output of a reasoner.\n2. The term globally optimal has its standard meaning (cf. [Luenberger and Ye, 2015, p. 184]) and emphasizes that\nthe optimum over all queries in the respective query search space is meant.\n\n5\n\n\fModern sequential diagnosis methods like [de Kleer and Williams, 1987] and its derivatives\n[Feldman et al., 2010, Shchekotykhin et al., 2012, Rodler et al., 2013] do not meet all properties\n(a) – (c). The black-box approaches among them extensively call a reasoner in order to compute\na query. As we show in our evaluations, the presented method can save an exponential overhead\ncompared to these approaches.\nMoreover, we emphasize that our approach can also deal with problems where the query\nspace is implicit, i.e. all possible system measurements cannot be enumerated in polynomial\ntime in the size of the system model. E.g., in a digital circuit all measurement points (and hence\nthe possible queries) are given explicitly by the circuit’s wires which can be directly extracted\nfrom the system description (SD). In, e.g., knowledge-based problems, by contrast, the possible\nmeasurements, i.e. questions to an expert, must be (expensively) inferred and are not efficiently\nenumerable. In fact, we show that for problems involving implicit queries, approaches not using\nthe proposed theory might be drastically incomplete and hence might miss optimal queries.\nFinally, by the generality of our query notion, our method explores a more complex search\nspace than [de Kleer and Williams, 1987, de Kleer and Raiman, 1993], thereby guaranteeing\nproperty (5) above.\nOrganization. The rest of this work is organized as follows. Sec. 2 provides theoretical foundations needed in later sections. In particular, it gives a short introduction on Model-Based\nDiagnosis (MBD) in Sec. 2.1, on Knowledge Base Debugging (KBD) in Sec. 2.2 and formally\nproves that each MBD problem can be reduced to a KBD problem in Sec. 2.3. Henceforth, the\nwork focuses w.l.o.g. just on KBD. Basics on Sequential Diagnosis including important definitions, the formal characterization of the addressed problem, and a generic algorithm to solve this\nproblem are treated in Sec. 2.4. The main part of the paper starts with Sec. 3, where we first\nformalize the measurement selection problem (Sec. 3.1) and then discuss the proposed novel\nalgorithm to solve this problem (Sec. 3.2). The presentation of our method is subdivided into\na first part attempting to give the reader a prior intuition, motivation and overview of the later\nintroduced theoretical concepts (Sec. 3.2.1), and three further parts, one dedicated to each phase\n(P1, P2 and P3) of the new algorithm (Sec. 3.2.2, 3.2.3 and 3.2.5). Besides an extensively exemplified expansion of the relevant theory, each phase description includes a complexity analysis.\nA formal specification of the computed solution’s properties for P1+P2 is given in Sec. 3.2.4 and\nfor P3 in Sec. 3.2.6. Finally, Sec. 3.2.7 recapitulates the entire approach by means of a detailed\nexample. Sec. 4 includes the description of our experimental evaluations in order to complement the theoretical findings of Sec. 3.2. The experimental settings are explicated in Sec. 4.1,\nwhereas the experimental results are discussed in Sec. 4.2. Subsequently, there is a section on\nrelated work (Sec. 5) before we conclude with Sec. 6. Appendix A comprises all proofs that are\nnot given in the text. Appendix B provides a table including all important symbols used in the\ntext along with their meaning.\n\n2. Preliminaries\nIn this section, we revise the general theory of Model-Based Diagnosis (MBD) proposed by\n[Reiter, 1987], define the knowledge base debugging framework (KBD) we will use to formalize\nMBD problems in this work, and demonstrate that KBD is a generalization of MBD.\n6\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\n2.1 Model-Based Diagnosis\nWe briefly review the classical model-based diagnosis (MBD) problem described by [Reiter,\n1987]. At first, we characterize a system, e.g. a digital circuit, a car or some software, which is\nthe subject of a diagnosis task:\nDefinition 1 (System). A system is a tuple (SD, COMPS) where SD, the system description,\nis a set of First-Order Logic sentences, and COMPS, the system components, is a finite set of\nconstants c1 , . . . , cn .\nThe distinguished unary “abnormal” predicate AB is used in SD to model the expected behavior of components c ∈ COMPS. Let us denote the First-Order Logic sentence describing this\nexpected behavior of c by beh(c) and let SDbeh := {¬AB(c) → beh(c) | c ∈ COMPS}. The latter\nsubsumes a statement of the form “if c is nominal (not abnormal), then its behavior is beh(c)”\nfor each system component c ∈ COMPS. Any behavior different from beh(c) implies that c is\nat fault, i.e. AB(c) holds. But, an abnormal component does not necessarily manifest a faulty\nbehavior in each situation (weak fault model [de Kleer et al., 1992a, Feldman et al., 2009]), e.g.\nfor an or-gate c stuck at 1 faulty behavior ¬beh(c) can only be observed if both inputs are 0.\nFurther, SD might include general axioms describing the system domain or descriptions of the\ninterplay between the system components. Let us call the set of these general axioms SDgen . So,\nSD = SD beh ∪ SD gen .\nThe behavior of a system (SD, COMPS) assuming all components working correctly is captured by the description SD ∪ {¬AB(c) | c ∈ COMPS}. Note, this description is equal to SDgen ∪\n{beh(c) | c ∈ COMPS}.\nA diagnosis problem arises when the observed system behavior – represented by a finite set\nof First-Order Logic sentences OBS – differs from the expected system behavior. Formally, this\nmeans that SD ∪ {¬AB(c) | c ∈ COMPS} ∪ OBS |= ⊥. For instance, in circuit diagnosis OBS\nmight be the observation of the system inputs and outputs.\nThere are usually multiple different hypotheses (diagnoses) that explain the discrepancy\nbetween observed and predicted system behavior. Discrimination between these hypotheses can\nthen be accomplished by means of additional observations MEAS called measurements [Reiter,\n1987, de Kleer and Williams, 1987]. Each measurement m in the set of measurements MEAS\nis a set of First-Order Logic sentences [Reiter, 1987] describing additional knowledge about the\nactual system behavior, e.g. whether a particular wire in a faulty circuit is high or low. Usually\nnew measurements are conducted and added to MEAS until some diagnostic goal G is achieved,\ne.g. the presence of just a single or one highly probable remaining hypothesis. Each added\nmeasurement m, if chosen properly, will invalidate some hypotheses. Throughout this paper we\nassume stationary health [Feldman et al., 2010], i.e. that one and the same (faulty) behavior can\nbe constantly reproduced for each c ∈ COMPS during system diagnosis.\nFormalized, these notions lead to the definitions of an MBD diagnosis problem instance\n(MBD-DPI) and of an MBD-diagnosis.\nDefinition 2 (MBD-DPI). Let OBS (system observations) be a finite set of First-Order Logic\nsentences, MEAS (measurements) be a finite set including finite sets mi of First-Order Logic\nsentences, and let (SD, COMPS) be a system. Then the tuple (SD, COMPS, OBS, MEAS) is an\nMBD diagnosis problem instance (MBD-DPI).\n7\n\n\fDefinition 3. Let DPI := (SD, COMPS, OBS, MEAS) be an MBD-DPI and UMEAS denote the\nunion of all m ∈ MEAS. Then SD∗ [∆] := SD ∪{AB(c) | c ∈ ∆}∪{¬AB(c) | c ∈ COMPS \\ ∆}∪\nOBS ∪ UMEAS for ∆ ⊆ COMPS denotes the behavior description of the system ( SD, COMPS )\n• under the current state of knowledge given by the DPI in terms of OBS and MEAS, and\n• under the assumption that all components in ∆ ⊆ COMPS are faulty and all components\nin COMPS \\ ∆ are healthy.\nDefinition 4 (MBD-Diagnosis). Let DPI := (SD, COMPS, OBS, MEAS) be an MBD-DPI. Then\n∆ ⊆ COMPS is an MBD-diagnosis for DPI iff SD∗ [∆] is consistent (∆ explains OBS and MEAS).\nAn MBD-diagnosis ∆ for DPI is called minimal iff there is no MBD-diagnosis ∆0 for DPI such\nthat ∆0 ⊂ ∆.\nIn many practical applications there are multiple (minimal) MBD-diagnoses for a given\nMBD-DPI. Without additional information about the system, one cannot conjecture a unique\ndiagnosis. The idea is then to perform measurements in order to discriminate between competing (minimal) MBD-diagnoses until a sufficient degree of diagnostic certainty (the specified\ndiagnostic goal G) is reached. This is the problem addressed by Sequential MBD and can be\nstated as follows:\nProblem 1 (Sequential MBD). .\nGiven: An MBD-DPI DPI := (SD, COMPS, OBS, MEAS) and a diagnostic goal G.\nFind: MEASnew ⊇ ∅ and ∆, where MEASnew is a set of new measurements such that ∆ is a\nminimal MBD-diagnosis for the MBD-DPI DPInew := (SD, COMPS, OBS, MEAS ∪ MEASnew )\nand ∆ satisfies G.\nRemark 1 Due to the intractability of the computation of the entire set of minimal diagnoses\n[Bylander et al., 1991], both the measurement selection and the decision whether a diagnostic\ngoal G is satisfied for some diagnosis D is usually made by using a (computationally feasible)\nset of leading minimal diagnoses D [de Kleer and Williams, 1989]. D acts as an approximation\nof all minimal diagnoses for the given DPI and usually comprises the most probable minimal\n[de Kleer and Williams, 1989] or minimum-cardinality [Feldman et al., 2010] diagnoses for a\nDPI. Given a set of leading minimal diagnoses D for DPInew , examples for the specification\nof G are G1 := “D is the only minimal diagnosis for DPInew ” [de Kleer and Raiman, 1993],\nG2 := “D exceeds some predefined probability threshold t”, e.g. t := 0.95 [de Kleer and\nWilliams, 1987, Shchekotykhin et al., 2012] or G3 := “D has ≥ k times the probability of all\nother elements in D”. Note that the goal G1 represents a maximally strict requirement on the\nfinal diagnostic result as it requires the verification of the invalidity of all but the correct minimal\ndiagnosis (we call a diagnostic goal Gi more strict than a diagnostic goal Gj if Gj is satisfied\nearlier in any diagnostic session than Gi ). The specification of (constants in) G depends on the\nseriousness of misdiagnosis, e.g. higher probability thresholds signify higher criticality.\nIn general, the size of the search space for minimal MBD-diagnoses for (SD, COMPS, OBS,\nis in O(2|COMPS| ). A useful concept to restrict this search space is the one of an MBDconflict [Reiter, 1987, de Kleer and Williams, 1987], a set of components whose elements cannot\nall be healthy given OBS and MEAS:\nMEAS)\n\n8\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nX1\n\ncircuit inputs (from top to bottom)\n1\n0\n1\ncircuit outputs (from top to bottom)\n1\n0\n\nX2\n\nA2\n\nA1\n\nO1\n\nFigure 2: MBD Example due to [Reiter, 1987] from the domain of circuit diagnosis.\nDefinition 5 (MBD-Conflict). Let DPI := (SD, COMPS, OBS, MEAS) be an MBD-DPI. Then\nC ⊆ COMPS is an MBD-conflict for DPI iff SD ∪{¬AB(c) | c ∈ C}∪ OBS ∪UMEAS is inconsistent.\nAn MBD-conflict C for DPI is called minimal iff there is no MBD-conflict C 0 for DPI such that\nC 0 ⊂ C.\nDefinition 6 (Hitting Set). Let S = {S1 , . . . , Sn } be a collection of sets. Then H is called a\nhitting set of S iff H ⊆ US and H ∩ Si 6= ∅ for all i = 1, . . . , n. A hitting set H of S is minimal\niff there is no hitting set H 0 of S such that H 0 ⊂ H.\nThe following result [Reiter, 1987] can be used to determine MBD-diagnoses through the\ncomputation of MBD-conflicts:\nTheorem 1. A (minimal) MBD-diagnosis for a DPI is a (minimal) hitting set of all minimal\nMBD-conflicts for this DPI.\nExample 1 Let us revisit the circuit diagnosis example given in [Reiter, 1987] shown in Fig. 2.\nThe first step towards diagnosing the circuit using MBD is to formulate the problem as an MBDDPI. The result ExM := (SD, COMPS, OBS, MEAS) is given by Tab. 1 and explained next.\nThe circuit, i.e. the system to be diagnosed, includes five gates X1 , X2 (xor-gates), A1 , A2\n(and-gates) and O1 (or-gate), which are at the same time the system components COMPS of\ninterest. The system description SD = SDbeh ∪ SDgen consists of a knowledge base SDbeh =\n{α1 , . . . , α5 } describing the behavior of each gate given it is working properly, e.g. for gate\nX1 , SDbeh includes the sentence α1 := (¬AB(X1 ) → out(X1 ) = xor(in1(X1 ), in2(X1 ))).\nBesides, SD includes a knowledge base SDgen = {α6 , . . . , α12 } describing which gate-terminals\nare connected by wires, e.g. the wire connecting X1 to X2 is defined by the sentence α7 :=\n(out(X1 ) = in1(X2 )). For simplicity we omit the explicit statement of additional general\ndomain knowledge in SDgen such as axioms for Boolean algebra or axioms restricting wires to\nonly either 0 or 1 values. The observations OBS = {α13 , . . . , α17 } are given by the system inputs\nand outputs (see the table in Fig. 2). Finally, since there are no already performed measurements,\nthe set MEAS is empty.\nAssuming all components are healthy, i.e. all gates function properly, we find out that SD∗ [∅]\nis inconsistent (cf. Def. 3). That is, the assumption of no faulty components conflicts with the\nobservations OBS made. E.g., if X1 and X2 manifest nominal behavior, we can deduce that\n9\n\n\fthe output out(X2 ) = 0 which contradicts the observation sentence α16 := (out(X2 ) = 1).\nSupposing either of the components X1 , X2 to be nominal, we can no longer deduce out(X2 ) =\n0 (or any other sentence contradicting OBS). Therefore, C1 := {X1 , X2 } is a minimal MBDconflict (cf. Def. 5). Similarly, we find that C2 := {X1 , A2 , O1 } is the only other minimal\nMBD-conflict for ExM. Computing minimal hitting sets of all minimal MBD-conflicts C1 , C2 ,\nwe obtain three minimal MBD-diagnoses ∆1 := {X1 }, ∆2 := {X2 , A2 } and ∆3 := {X2 , O1 }.\nLet the diagnostic goal G be the achievement of complete diagnostic certainty, i.e. to single\nout the correct minimal MBD-diagnosis. The goal of the MBD-problem is then to find new measurements m1 , . . . , mk such that there is a single minimal diagnosis ∆ for (SD, COMPS, OBS,\nMEAS ∪ {m1 , . . . , mk }). Let the first measurement m1 be the observation of the terminal\nout(X1 ), and let the value of it be 0. Then, ∆1 is still a minimal MBD-diagnosis for ExMnew :=\n(SD, COMPS, OBS, MEAS ∪ {{out(X1 ) = 0}}) since the abnormality of X1 explains both OBS\nand MEAS. Moreover, all other MBD-diagnoses for ExMnew must contain X1 (since its faultiness is the only explanation for MEAS) and thus be supersets of ∆1 . Hence, ∆1 is the only\nminimal MBD-diagnosis for ExMnew and thus the actually faulty component in this scenario is\nX1 (under the assumption that a ⊆-minimal set of components is broken). This fact could be\nderived by conducting only one measurement.\n\n2.2 Knowledge Base Debugging\nIn this section we revisit the knowledge base debugging (KBD) problem [Friedrich and Shchekotykhin, 2005, Shchekotykhin et al., 2012, Rodler, 2015] which we will use subsequently as a\ngeneralized reformulation of Reiter’s original MBD problem described above. Besides offering some notational conveniences, KBD allows users to specify negative measurements (or test\ncases) [Felfernig et al., 2004a]. Contrary to (positive) measurements m ∈ MEAS as characterized\nabove, negative measurements state properties that must not hold. In other words, any diagnosis\nmust fulfill that – under its assumption – the system description together with the observations\nand positive measurements does not entail any negative measurement. Additionally, it is possible in KBD to postulate stronger logical properties apart from consistency. For example, when\ndebugging an ontology (i.e. a system where COMPS are ontology axioms) one might want the\nassumption of a diagnosis to yield a coherent [Schlobach et al., 2007, Parsia et al., 2005] system description (repaired ontology), i.e. one without unsatisfiable classes. In First-Order Logic\nterms (using logic programming notation), an unsatisfiable class in a KB K is an n-ary predicate r such that K |= ∀X ¬r(X) where X = X1 , . . . , Xn . That is, coherency means that every\npredicate in K can have some instance without yielding an inconsistency.\nAnother possible use case for the adoption of (logical) requirements such as coherency is\nthe fault localization in flawed (e.g. inconsistent) system models used for MBD. For instance, a\nmodel (which is itself a KB) used to describe the circuit in Fig. 2 might include an unsatisfiable\nclass xor (which essentially makes the model inconsistent after the creation of, e.g., the sentence\nxor (X1 ) declaring X1 as an xor-gate). The reason for this incoherency might be that SDgen\nincludes the sentences xor (G) → gate(G) and gate(G) → and (G) ∨ or (G) ∨ not(G) (where\nthe system modeler forgot to include xor (G)) as well as sentences stating that no instance can\n10\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\ni\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\nαi\n¬AB(X1 ) → beh(X1 )\n¬AB(X2 ) → beh(X2 )\n¬AB(A1 ) → beh(A1 )\n¬AB(A2 ) → beh(A2 )\n¬AB(O1 ) → beh(O1 )\nout(X1 ) = in2(A2 )\nout(X1 ) = in1(X2 )\nout(A2 ) = in1(O1 )\nin1(A2 ) = in2(X2 )\nin1(X1 ) = in1(A1 )\nin2(X1 ) = in2(A1 )\nout(A1 ) = in2(O1 )\nin1(X1 ) = 1\nin2(X1 ) = 0\nin1(A2 ) = 1\nout(X2 ) = 1\nout(O1 ) = 0\n\nSD beh\n\nSD gen\n\ni\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\nOBS\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\nCOMPS\n\n{X1 , X2 , A1 , A2 , O1 }\nc\nX1\nX2\nA1\nA2\nO1\n\nbeh(c) for c ∈ COMPS\nout(X1 ) = xor(in1(X1 ), in2(X1 ))\nout(X2 ) = xor(in1(X2 ), in2(X2 ))\nout(A1 ) = xor(in1(A1 ), in2(A1 ))\nout(A2 ) = xor(in1(A2 ), in2(A2 ))\nout(O1 ) = xor(in1(O1 ), in2(O1 ))\n\ni\n×\n\nMEAS\n\nαi\nout(X1 ) = xor(in1(X1 ), in2(X1 ))\nout(X2 ) = xor(in1(X2 ), in2(X2 ))\nout(A1 ) = and(in1(A1 ), in2(A1 ))\nout(A2 ) = and(in1(A2 ), in2(A2 ))\nout(O1 ) = or(in1(O1 ), in2(O1 ))\nout(X1 ) = in2(A2 )\nout(X1 ) = in1(X2 )\nout(A2 ) = in1(O1 )\nin1(A2 ) = in2(X2 )\nin1(X1 ) = in1(A1 )\nin2(X1 ) = in2(A1 )\nout(A1 ) = in2(O1 )\nin1(X1 ) = 1\nin2(X1 ) = 0\nin1(A2 ) = 1\nout(X2 ) = 1\nout(O1 ) = 0\n\ni\n×\n\npi ∈ P\n×\n\ni\n×\n\nni ∈ N\n×\n\ni\n1\n\nri ∈ R\nconsistency\n\nK\n•\n•\n•\n•\n•\n\nB\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\nmin KBD-conflicts\n{α1 , α2 } , {α1 , α4 , α5 }\nmin KBD-diagnoses\n{α1 } , {α2 , α4 } , {α2 , α5 }\n\n×\n\nTable 1: MBD-DPI ExM obtained from circuit diagnosis problem in Fig. 2.\n\nTable 2: KBD-DPI ExM2K obtained from\nMBD-DPI ExM from Tab. 1.\n\nbe of more than one type of gate. That is, KBD (with the coherency requirement) could be used\nin such scenario to repair the model thus enabling a sound diagnostic process.\n2.2.1 T HE U SED N OTATION\nLet L denote some formal knowledge representation language. We will call αL , α1,L , α2,L , . . . ∈\nL logical sentences over L and a set of logical sentences KL ⊆ 2L a knowledge base (KB) over\nL. Sentences in KL will sometimes be referred to as axioms. We denote by |=L ⊆ 2L × L the\nsemantic entailment relation for the logic L and we write KL |=L αL to state that αL is a logical\nconsequence of the KB KL . For brevity, we will write K1,L |=L K2,L for two KBs K1,L and\nK2,L to denote that K1,L |=L αL for all αL ∈ K2,L and K1,L 6|=L αL to state that K1,L 6|=L αL\nfor some αL ∈ K2,L .\nGiven a collection of sets X, we use UX and IX to denote the union and intersection, respectively, of all elements in X. Further, Tab. 7 (see Appendix B) summarizes the meaning of\nother formalisms used in the paper (many of them introduced at some later point).\n11\n\n\f2.2.2 A SSUMPTIONS\nThe KBD techniques described in this work are applicable to any knowledge representation\nformalism L which is Tarskian, i.e. for which the semantic entailment relation |=L is monotonic,\nidempotent and extensive [Tarski, 1983, Ribeiro, 2012] and for which reasoning procedures for\ndeciding consistency of a KB over L are available.\nDefinition 7. The relation |=L is called\n• monotonic iff whenever KL |=L αi,L then KL ∪ {αk,L } |=L αi,L\n(i.e. adding new sentences to a KB cannot invalidate any entailments of the KB)\n• idempotent iff KL |=L αi,L and KL ∪ {αi,L } |=L αk,L implies KL |=L αk,L\n(i.e. adding entailed sentences to a KB does not yield new entailments of the KB)\n• extensive iff KL |=L αL for all αL ∈ KL\n(i.e. each KB entails all sentences it comprises).\nIn the following, “sentence” will always mean “logical sentence”. We will omit the index\nL for brevity when referring to sentences or KBs, tacitly assuming that any sentence or KB we\nspeak of is formulated over some (fixed) language L where L meets the conditions given above.\nExamples of logics that comply with these requirements include, but are not restricted to\nPropositional Logic, Datalog [Ceri et al., 1989], (decidable fragments of) First-Order Predicate\nLogic, The Web Ontology Language (OWL [Patel-Schneider et al., 2004], OWL 2 [Grau et al.,\n2008, Motik et al., 2009]), sublanguages thereof such as the OWL 2 EL Profile (with polynomial\ntime reasoning complexity [Kazakov et al., 2014]), Boolean or linear equations and various\nDescription Logics [Baader et al., 2007] and constraint languages.\n2.2.3 D EFINITIONS AND P ROPERTIES\nWe next state the KBD problem and give some important definitions and properties (discussed\nin detail in [Rodler, 2015]).\nThe inputs to a KB debugging problem can be characterized as follows: Given is a KB K to\nbe repaired and a KB B (background knowledge). All sentences in B are considered correct and\nall sentences in K are considered potentially faulty. K∪B does not meet postulated requirements\nR (where consistency is a least requirement3 ) or does not feature desired semantic properties,\ncalled test cases. Positive test cases (aggregated in the set P ) correspond to necessary entailments and negative test cases (aggregated in the set N ) represent necessary non-entailments of\nthe correct (repaired) KB (together with the background KB B). Each test case p ∈ P and\nn ∈ N is a set of sentences. The meaning of a positive test case p ∈ P is that the union of the\nrepaired KB and B must entail each sentence (or the conjunction of sentences) in p, whereas a\nnegative test case n ∈ N signalizes that some sentence (or the conjunction of sentences) in n\nmust not be entailed by this union.\nThe described inputs to the KB debugging problem are captured by the notion of a KBD\ndiagnosis problem instance (KBD-DPI):\n3. We assume consistency a minimal requirement to a solution KB provided by a debugging system, as inconsistency makes a KB completely useless from the semantic point of view.\n\n12\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\ni\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\nαi\n¬H ∨ ¬G\nX ∨F →H\nE → ¬M ∧ X\nA → ¬F\nK→E\nC→B\nM →C∧Z\nH→A\n¬B ∨ K\n\nK\n•\n•\n•\n•\n•\n•\n•\n\ni\n1\n\npi ∈ P\n{¬X → ¬Z}\n\ni\n1\n2\n3\n\nni ∈ N\n{M → A}\n{E → ¬G}\n{F → L}\n\ni\n1\n\nri ∈ R\nconsistency\n\nB\n\n•\n•\n\nmin KBD-conflict X\nC1\nC2\nC3\nC4\n\n{i | αi ∈ X}\n{1, 2, 3}\n{2, 4}\n{2, 7}\n{3, 5, 6, 7}\n\nexplanation\n|= n2\n∪ {8} |= ¬F (|= n3 )\n∪ {p1 , 8} |= n1\n∪ {9} |= ¬M (|= n1 )\n\nmin KBD-diagnosis X\nD1\nD2\nD3\nD4\nD5\nD6\n\n{i | αi ∈ X}\n{2, 3}\n{2, 5}\n{2, 6}\n{2, 7}\n{1, 4, 7}\n{3, 4, 7}\n\nexplanation\nTheorem 3\nTheorem 3\nTheorem 3\nTheorem 3\nTheorem 3\nTheorem 3\n\nTable 4: Minimal KBD-conflicts and KBD-diagnoses\nfor the KBD-DPI ExK in Tab. 3.\n\nTable 3: Running example KBD-DPI ExK\nover Propositional Logic.\n\nDefinition 8 (KBD-DPI). Let\n•\n•\n•\n•\n•\n\nK be a KB,\nP , N be sets including sets of sentences,\nR ⊇ {consistency} be a set of (logical) requirements,\nB be a KB such that K ∩ B = ∅ and B satisfies all requirements r ∈ R, and\nthe cardinality of all sets K, B, P , N be finite.\n\nThen we call the tuple hK, B, P , N iR a KBD diagnosis problem instance (KBD-DPI).\n\nExample 2 An example ExK of a Propositional Logic KBD-DPI is depicted by Tab. 3. ExK\nwill serve as a running example throughout this paper. It includes a KB K with seven axioms\nα1 , . . . , α7 , a background KB B with two axioms α8 , α9 , one singleton positive test case p1 and\nthree singleton negative test cases n1 , n2 , n3 . There is one requirement r1 = consistency in R\nimposed on the correct (repaired) KB. It is easy to verify that the standalone KB B = {α8 , α9 }\nis consistent, i.e. satisfies all r ∈ R, and that K ∩ B = ∅. Hence, ExK indeed constitutes a\nKBD-DPI as per Def. 8.\nA solution (KB) for a DPI is characterized as follows:\n\n13\n\n\fDefinition 9 (Solution KB). Let DPI := hK, B, P , N iR be a KBD-DPI. Then a KB K∗ is called\nsolution KB w.r.t. DPI iff all the following conditions hold:\n∀r ∈ R :\n∀p ∈ P\n∀n ∈ N\n\n:\n:\n\nK∗ ∪ B fulfills r\n\n(1)\n\n∗\n\n(2)\n\n∗\n\n(3)\n\nK ∪ B |= p\nK ∪ B 6|= n.\n\nA solution KB K∗ w.r.t. DPI is called maximal iff there is no solution KB K0 w.r.t. DPI such that\nK0 ∩ K ⊃ K∗ ∩ K (i.e. K∗ has a set-maximal intersection with K among all solution KBs).\nUsually, observing the Principle of Parsimony [Reiter, 1987], maximal solution KBs K∗ will\nbe preferred to non-maximal ones since they result from the input KB K through the modification\nof a minimal set of axioms.\nExample 3 For the KBD-DPI ExK given by Tab. 3, K = {α1 , . . . , α7 } is not a solution KB\nw.r.t. hK, B, P , N iR since, e.g. clearly K ∪ B = {α1 , . . . , α9 } 6|= p1 which is a positive test\ncase and therefore has to be entailed. Another reason why K = {α1 , . . . , α7 } is not a solution\nKB w.r.t. ExK is that K ∪ B ⊃ {α1 , α2 , α3 } |= n2 , which is a negative test case and hence must\nnot be an entailment. This is straightforward since {α1 , α2 , α3 } imply E → X, X → H and\nH → ¬G and thus clearly n2 = {E → ¬G}.\nOn the other hand, Ka∗ := {}∪{Z → X} is clearly a solution KB w.r.t. ExK as {Z → X}∪B\nis obviously consistent (satisfies all r ∈ R), does entail p1 ∈ P and does not entail any ni ∈\nN , (i ∈ {1, 2, 3}). However, Ka∗ is not a maximal solution KB since, e.g. α5 = (K → E) ∈ K\ncan be added to Ka∗ without resulting in the violation of any of the Equations (1) – (3). Note\nthat also e.g. {¬X → ¬Z, A1 → A2 , A2 → A3 , . . . , Ak−1 → Ak } for arbitrary finite k ≥ 0\nis a solution KB, albeit not a maximal one, although it has no axioms in common with K and\nincludes an arbitrary number of axioms not occurring in K. However, to maintain a maximum\namount of the knowledge specified in the KB K of interest, one will usually prefer minimally\ninvasive modifications (i.e. maximal solution KBs) while repairing faults in K.\nMaximal solution KBs w.r.t. the given DPI are, e.g. Kb∗ := {α1 , α4 , α5 , α6 , α7 , p1 } (resulting from the deletion of {α2 , α3 } from K and the addition of p1 ) or Kc∗ := {α1 , α2 , α5 , α6 , p1 }\n(resulting from the deletion of {α1 , α4 , α7 } from K and the addition of p1 ). That these KBs constitute solution KBs can be verified by checking the three conditions named by Def. 9. Indeed,\nadding an additional axiom in K to any of the two KBs leads to the entailment of a negative test\ncase n ∈ N . That is, no solution KB can contain a proper superset of the axioms from K that\nare contained in any of the two solution KBs Kb∗ and Kc∗ . Hence, both are maximal.\nRemark 2 There are generally infinitely many (maximal) solution KBs resulting from the\ndeletion of one and the same set of axioms D from the original KB K. This stems from the fact\nthat there are infinitely many (semantically equivalent) syntactical variants of any set of suitable\nsentences that can be added to K \\ D in order for Eq. (2) to be satisfied. One reason for this\nis that there are infinitely many tautologies that might be included in these sentences, another\nreason is that sentences can be equivalently rewritten, e.g. A → B ≡ A → B ∨ ¬A ≡ A →\nB ∨ ¬A ∨ ¬A ≡ . . . .\n14\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nIn terms of our running example, this circumstance can be illustrated as follows:\nExample 4 Consider again ExK in Tab. 3 and assume D = {α2 , α3 } is deleted from K. Then\none solution KB constructible from K\\D is Kb∗ given in the last example. To determine the maximal solution KB Kb∗ from K\\D, the most straightforward way of adding just all sentences occurring in positive test cases in P has been chosen in this case. Other maximal solution KBs obtain∗ := {α , α , α , α , α , Z → X} (which difable from adding sentences to K \\ D are, e.g. Kb1\n1\n4\n5\n6\n7\n∗ := {α , α , α , α , α , Z → X ∧ W }\nfers syntactically, but not semantically from Kb∗ ) and Kb2\n1\n4\n5\n6\n7\n(which differs both syntactically and semantically from Kb∗ yielding the entailment Z → W\nwhich is not implied by Kb∗ ).\nDespite generally multiple semantically different solution KBs, the diagnostic evidence of a\nDPI in terms of positive test cases P does not justify the inclusion of sentences (semantically)\ndifferent from UP (cf. [Friedrich and Shchekotykhin, 2005, Shchekotykhin et al., 2012]). Since\nwe are moreover interested in only one instance of a solution KB resulting from K \\ D for each\nD, we define K \\ D ∪ UP as the canonical solution KB for D w.r.t. DPI iff K \\ D ∪ UP is a\nsolution KB w.r.t. DPI.\nA KBD-diagnosis is defined in terms of the axioms D that must be deleted from the KB K\nof a DPI in order to construct a solution KB w.r.t. this DPI. In particular, the deletion of D from\nK targets the fulfillment of Equations (1) and (3) such that UP can be added to the resulting\nmodified KB K \\ D without introducing any new violations of (1) or (3).\nDefinition 10 (KBD-Diagnosis). Let DPI := hK, B, P , N iR be a KBD-DPI. A set of sentences\nD ⊆ K is called a KBD-diagnosis w.r.t. DPI iff (K \\ D) ∪ UP is a solution KB w.r.t. DPI (i.e.\nK∗ := (K \\ D) ∪ UP meets Equations (1) – (3)). A KBD-diagnosis D w.r.t. DPI is\n• minimal iff there is no D0 ⊂ D such that D0 is a KBD-diagnosis w.r.t. DPI\n• a minimum cardinality KBD-diagnosis w.r.t. DPI iff there is no KBD-diagnosis D0 w.r.t.\nDPI such that |D0 | < |D|.\nWe will write D ∈ allDDPI to state that D is a KBD-diagnosis w.r.t. DPI and D ∈ minDDPI to\nstate that D is a minimal KBD-diagnosis w.r.t. DPI.\nRemark 3 Since (K \\ D) ∪ UP trivially satisfies (2) due to the inclusion of UP , D is a KBDdiagnosis w.r.t. DPI iff K∗ := (K \\ D) ∪ UP satisfies (1) and (3).\nThe next theorem captures the relationship between maximal canonical solution KBs and\nminimal KBD-diagnoses w.r.t. a DPI. In fact, it tells us that we can concentrate only on the\ncomputation of minimal KBD-diagnoses in order to find all maximal canonical solution KBs.\nTheorem 2. Let DPI := hK, B, P , N iR be a KBD-DPI. Then the set of all maximal canonical\nsolution KBs w.r.t. DPI is given by {(K \\ D) ∪ UP | D is a minimal KBD-diagnosis w.r.t. DPI}.\nIn a completely analogous way as MBD-conflicts provide an effective mechanism for focusing the search for MBD-diagnoses, we can exploit KBD-conflicts for KBD-diagnoses calculation. Simply put, a (minimal) KBD-conflict is a (minimal) per se faulty subset of the original\nKB K, i.e. one source causing the faultiness of K in the context of B ∪ UP . For a KBD-conflict\n15\n\n\fthere is no extension that yields a solution KB. Instead, such an extension is only possible after\ndeleting appropriate axioms from the KBD-conflict.\nDefinition 11 (KBD-Conflict). Let DPI := hK, B, P , N iR be a KBD-DPI. A set of formulas\nC ⊆ K is called a KBD-conflict w.r.t. DPI iff C ∪ UP is not a solution KB w.r.t. DPI (i.e.\nK∗ := C ∪ UP violates at least one of the Equations (1) – (3)). A KBD-conflict C w.r.t. DPI is\nminimal iff there is no C 0 ⊂ C such that C 0 is a KBD-conflict w.r.t. DPI.\nTheorem 3. [Friedrich and Shchekotykhin, 2005, Prop. 2] Let DPI be a KBD-DPI. Then a\n(minimal) KBD-diagnosis w.r.t. DPI is a (minimal) hitting set of all minimal conflicts w.r.t. DPI.\nProposition 1. [Rodler, 2015, Prop. 3.4] Let DPI := hK, B, P , N iR be a KBD-DPI. Then a\nKBD-diagnosis w.r.t. DPI exists iff B ∪ UP satisfies all r ∈ R and B ∪ UP 6|= n for all n ∈ N .\nExample 5 Tab. 4 gives a list of all minimal KBD-conflicts w.r.t. our running example ExK.\nLet us briefly reflect why these are KBD-conflicts (cf. third col. of Tab. 4). Recall Ex. 3, where\nwe explained why C1 is a KBD-conflict (violation of n2 ∈ N ). C1 is minimal since, first, it is\nconsistent, i.e. satisfies all r ∈ R, and does not entail any of the negative test cases n1 , n3 . So,\nby logical monotonicity no proper subset of C1 can violate r, n1 or n3 . Second, the elimination\nof any axiom αi (i ∈ {1, 2, 3}) from C1 breaks the entailment of the negative test case n2 .\nRegarding C2 := {α2 , α4 }, we have that (any superset of) C2 is a KBD-conflict due to (the\nmonotonicity of Propositional Logic and) the fact that α2 ≡ {X → H, F → H} together with\nα8 (∈ B) = H → A and α4 = A → ¬F clearly yields F → ¬F ≡ ¬F which, in particular,\nimplies n3 = {F → L} ≡ {¬F ∨ L}.\nC3 is a minimal KBD-conflict since it is a ⊆-minimal subset of the KB K which, along with\nB and UP (in particular with α8 ∈ B and p1 ∈ P ), implies that n1 ∈ N must be true. To see\nthis, realize that α7 |= M → Z, p1 = Z → X, α2 |= X → H and α8 = H → A, from which\nn1 = {M → A} follows in a straightforward way.\nFinally, C4 is a KBD-conflict since α7 |= M → C, α6 = C → B, α9 ≡ B → K,\nα5 = K → E and α3 |= E → ¬M . Again, it is now obvious that this chain yields the\nentailment ¬M which in turn entails {¬M ∨ A} ≡ {M → A} = n1 . Clearly, the removal of\nany axiom from this chain breaks the entailment ¬M . As this chain is neither inconsistent nor\nimplies any negative test cases other than n1 , the conflict C4 is also minimal. It is not very hard\nto verify that there are no other minimal KBD-conflicts w.r.t. ExK apart from C1 , . . . , C4 .\nExample 6 The set minDExK of all minimal KBD-diagnoses w.r.t. ExK (Tab. 3) is shown in\nTab. 4. Theorem 3 and the illustration (given in Ex. 5) of why C1 , . . . , C4 constitute a complete\nset of minimal KBD-conflicts w.r.t. ExK provide the explanation for minDExK . For instance,\nD1 = {α2 , α3 } “hits” the element α2 of Ci (i ∈ {1, 2, 3}) and the element α3 of C4 . Note\nalso that it hits two elements of C1 which, however, is not necessarily an indication of the nonminimality of the hitting set. Indeed, if α2 is deleted from D1 , it has an empty intersection with\nC2 and C3 and, otherwise, if α3 is deleted from it, it becomes disjoint with C4 . Hence D1 is\nactually a minimal hitting set of all minimal KBD-conflicts.\nThe relationship between the notions KBD-diagnosis, solution KB and KBD-conflict is as\nfollows (cf. [Rodler, 2015, Cor. 3.3]):\n16\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nProposition 2. Let D ⊆ K. Then the following statements are equivalent:\n1. D is a KBD-diagnosis w.r.t. hK, B, P , N iR .\n2. (K \\ D) ∪ UP is a solution KB w.r.t. hK, B, P , N iR .\n3. (K \\ D) is not a KBD-conflict w.r.t. hK, B, P , N iR .\nExample 7 Since, e.g., K \\ D := {α1 , α2 } is not a KBD-conflict w.r.t. ExK (Tab. 3), we obtain\nthat D = K\\(K\\D) = {α1 , . . . , α7 }\\{α1 , α2 } = {α3 , . . . , α7 } is a KBD-diagnosis w.r.t. ExK,\nalbeit not a minimal one (α5 and α6 can be deleted from it while preserving its KBD-diagnosis\nproperty). Further on, (K \\ D) ∪ UP = {α1 , α2 , p1 } must be a solution KB w.r.t. ExK.\n2.3 Reducing Reiter’s MBD Problem to KB Debugging\nWe next demonstrate that the classical MBD problem described in Sec. 2.1 can be reduced to\nthe KBD problem explicated in Sec. 2.2 [Rodler and Schekotihin, 2017]. That is, any MBD-DPI\ncan be modeled as a KBD-DPI, and the solutions of the latter directly yield the solutions of the\nformer.\nTheorem 4 (Reduction of MBD to KBD). Let mDPI := (SD, COMPS, OBS, MEAS) be an MBDDPI where COMPS = {c1 , . . . , cn }. Then, mDPI can be formulated as a KBD-DPI kDPI such\nthat there is a bijective correspondence between KBD-diagnoses for kDPI and MBD-diagnoses\nfor mDPI. Moreover, all MBD-diagnoses for mDPI can be computed from the KBD-diagnoses\nfor kDPI.\nProof. We first show how mDPI can be formulated as a KBD-DPI kDPI. To this end, we\nspecify how kDPI = hK, B, P , N iR can be written in terms of the components of mDPI =\n(SDbeh ∪ SDgen , COMPS, OBS, MEAS):\nK = {αi | αi := beh(ci ), ci ∈ COMPS}\n\n(4)\n\nB = OBS ∪ SDgen\n\n(5)\n\nP = MEAS\n\n(6)\n\nN =∅\n\n(7)\n\nR = {consistency}\n\n(8)\n\nThat is, K captures SDbeh ∪ {¬AB(ci ) | ci ∈ COMPS}, i.e. the nominal behavioral descriptions\nof all system components. By Def. 10 and Remark 3, D ⊆ K is a KBD-diagnosis for kDPI iff\n(K \\ D) ∪ B ∪ UP satisfies all r ∈ R\n\n(i.e. is consistent)\n\n(9)\n\nand\n(K \\ D) ∪ B ∪ UP 6|= n for all n ∈ N\n\n(10)\n\nLet now D be an arbitrary KBD-diagnosis for kDPI such that D = {αi | i ∈ I} for the index set\nI ⊆ {1, . . . , n}.\n17\n\n\fUsing (4) – (8) above, condition (9) for D is equivalent to the consistency of SDbeh ∪{AB(ci ) |\ni ∈ I} ∪ {¬AB(ci ) | i ∈ {1, . . . , n} \\ I} ∪ OBS ∪ SDgen ∪ UMEAS which in turn yields that\nSD\n\n∪ {AB(ci ) | ci ∈ ∆} ∪ {¬AB(ci ) | ci ∈ COMPS \\ ∆} ∪ OBS ∪ UMEAS is consistent\n\n(11)\n\nfor ∆ := {ci | ci ∈ COMPS, i ∈ I}. But, (11) is exactly the condition defining an MBDdiagnosis (see Def. 4). Note, since N = ∅ by (7), condition (10) is satisfied for any D satisfying\n(9) and can thus be neglected. Hence, D = {αi | i ∈ I} ⊆ K is a KBD-diagnosis w.r.t. kDPI iff\n∆ = {ci | ci ∈ COMPS, i ∈ I} ⊆ COMPS is an MBD-diagnosis for mDPI.\nAlso, there is a bijective correspondence between KBD-conflicts and MBD-conflicts:\nProposition 3. Let mDPI = (SD, COMPS, OBS, MEAS) be an MBD-DPI and kDPI = hK, B, P ,\nN iR a KBD-DPI modeling mDPI as per (4) – (8). Further, let COMPS = {c1 , . . . , cn } and\nI ⊆ {1, . . . , n}. Then, C = {ci | ci ∈ COMPS, i ∈ I} ⊆ COMPS is an MBD-conflict for mDPI\niff C = {αi | i ∈ I} ⊆ K is a KBD-conflict w.r.t. kDPI.\nProof. C is a KBD-conflict w.r.t. kDPI iff K \\ C = {αi | i ∈ {1, . . . , n} \\ I} is not a KBDdiagnosis w.r.t. kDPI (Prop. 2) iff {ci | ci ∈ COMPS, i ∈ {1, . . . , n} \\ I} is not an MBD-diagnosis\nfor mDPI (Theorem 4) iff {ci | ci ∈ COMPS, i ∈ I} = C is an MBD-conflict for mDPI ([Reiter,\n1987, Prop. 4.2]).\nLet us exemplify these theoretical results:\nExample 8 Reconsider the circuit diagnosis example (Fig. 2). The formalization of the circuit\nproblem as an MBD-DPI ExM was discussed in Ex. 1. The formulation of this MBD-DPI as a\nKBD-DPI ExM2K as per Eq. (4) – (8) is depicted by Tab. 2. All minimal KBD-conflicts and their\nminimal hitting sets, i.e. the minimal KBD-diagnoses (Theorem 3), are given in the lower part of\nTab. 2. For instance, C = {α1 , α4 , α5 } is a KBD-conflict w.r.t. ExM2K since C ∪ B ∪ UP |= ⊥.\nWe briefly sketch why this holds. α13 (∈ B) = (in1(X1 ) = 1), α14 (∈ B) = (in2(X1 ) = 0)\nand α1 = (out(X1 ) = xor (in1(X1 ), in2(X1 ))) imply that out(X1 ) = xor (1, 0) = 1, which,\nalong with α6 (∈ B) = (out(X1 ) = in2(A2 )), entails in2(A2 ) = 1, which in turn, together\nwith α15 (∈ B) = (in1(A2 ) = 1) and α4 = (out(A2 ) = and (in1(A2 ), in2(A2 ))), lets us\ndeduce that out(A2 ) = and (1, 1) = 1. Because of α8 (∈ B) = (out(A2 ) = in1(O1 )) we\nhave that in1(O1 ) = 1 which yields out(O1 ) = or (1, in2(O1 )) = 1 due to α5 = (out(O1 ) =\nor (in1(O1 ), in2(O1 ))). However, α17 ∈ B states that out(O1 ) = 0, a contradiction.\nC is minimal since all elements of C were necessary to derive the outlined contradiction. In\nfact, no proper subset of C can be used to deduce any negative test case (trivially, as the set N is\nempty) or any contradiction (possibly different from the one given above). Intuitively, the latter\nholds since any C 0 ⊂ C includes too few behavioral descriptions of components so that there is\nno “open” path for constraint propagation from inputs to outputs of the circuit. C, on the other\nhand, enables to propagate information from all three inputs via gates X1 , A2 and O1 towards\nthe second output. What becomes nicely evident at this point is the principle of transformation\nbetween MBD and KBD. Whereas in MBD behavioral descriptions of components are “disabled” via abnormality assumptions about components, in KBD it is exactly these descriptions\nthat make up the KB, and they are “inactivated” by just deleting them from the KB.\n18\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nThe justification for the minimal KBD-conflict {α1 , α2 } follows essentially the same argumentation as was given in Ex. 1 to explain C1 .\nTo sum up, we can find all diagnoses for any MBD-DPI by representing it as a KBD-DPI and\nsolving the KBD-DPI (Theorem 4). Thus, KBD methods [Shchekotykhin et al., 2012, Rodler,\n2015] are suitable for MBD as well. Moreover, computing all minimal diagnoses for KBD-DPIs\nleads us to all maximal (canonical) solution KBs w.r.t. the DPI in a trivial way (Theorem 2).\nDue to these results we can henceforth w.l.o.g. restrict our focus to KBD problems and the\ncomputation of minimal diagnoses w.r.t. these problems. However, we bear in mind that the\npresented methods apply to MBD problems as well and the obtained solutions can be easily\nreformulated as solutions for knowledge-based system debugging.\nHence, whenever we will write DPI, diagnosis and conflict in the rest of this work, we will\nrefer to KBD-DPI, KBD-diagnosis and KBD-conflict, respectively. The problem of Sequential\nDiagnosis, which will generalize the Sequential MBD-Problem as per Prob. 1, will be discussed\nin detail in the next section.\n2.4 Sequential Diagnosis\nGiven multiple diagnoses for a DPI, sequential diagnosis techniques [de Kleer and Williams,\n1987, Brodie et al., 2003, Feldman et al., 2010, Siddiqi and Huang, 2011, Rodler et al., 2013,\nShchekotykhin et al., 2014, Rodler, 2015] target the acquisition of additional information to\nminimize the diagnostic uncertainty, i.e. to reach a predefined diagnostic goal G (cf. Remark 1\nfor some examples). Depending on the sequential diagnosis framework, different types of information might be incorporated. For example, the framework used by [Brodie et al., 2003,\nShchekotykhin et al., 2016] tests (sets of) components directly and takes the information about\ntheir normal/abnormal state into account. On the other hand, the approaches of [de Kleer and\nWilliams, 1987, Siddiqi and Huang, 2011] indirectly measure values of variables influenced by\nthe normal/abnormal behavior of components. As opposed to these probing techniques, testing\napproaches [Pattipati and Alexandridis, 1990, Shakeri et al., 2000, Feldman et al., 2010] observe\nparticular system outputs after varying particular system inputs, i.e. the gathered information in\nthis paradigm corresponds to input-output vectors.\nOur approach uses a way of information representation that, in principle, allows to model all\naforementioned paradigms (see Ex. 9). Namely, we define a proposed measurement generally\nas a set of sentences (over some logic complying with the criteria given in Sec. 2.2.2), according\nto [Reiter, 1987]. We call a proposed measurement a query [Settles, 2012] if the additional\ninformation it gives eliminates in any case at least one (known) diagnosis [Shchekotykhin et al.,\n2012, Rodler, 2015]. Further on, we assume an entity, called oracle, capable of performing\nthe required measurements. That is, an oracle answers queries by assessing the correctness of\nthe sentences in the query. When diagnosing physical systems [de Kleer and Williams, 1987,\nReiter, 1987, Heckerman et al., 1995], the oracle might be constituted by a human operator or\nautomatic sensors making observations. For instance, when diagnosing a car, a car mechanic\nmight act as an oracle. During the diagnosis of knowledge-based systems [Rodler, 2015] such\nas configuration systems [Felfernig et al., 2004a] or ontologies [Shchekotykhin et al., 2012],\n19\n\n\fthe oracle could be a domain expert or some automatic information extraction system providing\ndomain-specific knowledge.\nGiven a query Q = {α1V\n, . . . , αk } containing the sentences4 α1 , . . . , αk , posing Q to the oracle means asking whether ki=1 αi must be true, or equivalently, whether each single sentence\nαi ∈ Q must be true. Hence, a query is answered by true (t) if the performed measurements\nconfirm all sentences in Q, and by false if the measurements disprove some sentence(s) in Q.\nDepending on the concrete diagnosis task at hand, queries are answered w.r.t. different reference\npoints. For instance, in the KB debugging domain, the desired model of the domain of interest,\ni.e. the correct KB, is the relevant reference point. That is, measurements in this case might correspond to cognitive activity (of a domain expert thinking about the truth of the sentences in Q)\nor the process of information extraction (of e.g. some system browsing some knowledge source\nrelevant to Q). On the other hand, when diagnosing some physical device, the reference point is\nconstituted by the actual behavior of the device. In this case a measurement is the observation of\nsome system aspect(s) relevant to Q. So, given a reference point Ref , a positive answer to the\nquery Q means that Ref |= Q, a negative one that Ref 6|= Q.\nIn the sequential diagnosis process, the information provided by answered queries is incorporated into the current DPI, yielding a new (updated) DPI. In particular, a positively answered\nquery Q is added as a positive test case to the current DPI hK, B, P , N iR resulting in the new\nDPI hK, B, P ∪ {Q} , N iR . Likewise, a negatively answered query Q is added as a negative test\ncase to the current DPI hK, B, P , N iR resulting in the new DPI hK, B, P , N ∪ {Q}iR . In this\nvein, the successive addition of new answered queries to the test cases gradually reduces the diagnostic uncertainty by restricting the set of diagnoses. Note, if an oracle is able to provide any\nadditional information, sentence(s) Y , beyond the mere query answer, e.g., an explanation or\njustification for a negative query answer, the presented approach enables to integrate and exploit\nthis information for the invalidation of further diagnoses. To this end, Y is simply added to the\nset P as a positive test case.\n2.4.1 D EFINITIONS AND P ROPERTIES\nWe now present the concept of a query in more formal terms. In the following, given a DPI\nDPI := hK, B, P , N iR and some minimal diagnosis Di w.r.t. DPI, we will use the following\nabbreviation for the canonical solution KB obtained by deletion of Di along with the given\nbackground knowledge B:\nKi∗ := (K \\ Di ) ∪ B ∪ UP\n\n(12)\n\n4. We could also w.l.o.g. define a query to be a single logical sentence because it is interpreted as the conjunction\nof the sentences it contains, which is simply a “bigger” sentence. For technical reasons, we stick to the representation as a set of sentences (cf. [Reiter, 1987]), since we will present query minimization approaches for\nreducing the number of sentences in the query. This would correspond to reducing the length or complexity of\nthe sentence in the single sentence interpretation of a query.\n\n20\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nProposition 4. Let DPI := hK, B, P , N iR be a DPI, X be a set of sentences and D ⊆\nminDDPI . Then X induces a partition PD (X) := D+ (X), D− (X), D0 (X) on D where5\nD+ (X) := {Di ∈ D | Ki∗ |= X}\nD− (X) := {Di ∈ D | (∃n ∈ N : Ki∗ ∪ X |= n) ∨ (∃r ∈ R : Ki∗ ∪ X violates r)}\nD0 (X) := D \\ (D+ (X) ∪ D− (X))\nSince the computation of all (minimal) diagnoses is computationally prohibitive in general,\nwe exploit a subset D of all minimal diagnoses w.r.t. a DPI for measurement selection. D is\nreferred to as the leading diagnoses (cf. Rem. 1). From a query we postulate two properties. It\nmust for any outcome (1) invalidate at least one (leading) diagnosis (search space restriction)\nand (2) preserve the validity of at least one (leading) diagnosis (solution preservation). In fact,\nthe sets D+ (X) and D− (X) are the key in deciding whether a set of sentences X is a query or\nnot. Based on Prop. 4, we define:\nDefinition 12 (Query, q-Partition). Let DPI := hK, B, P , N iR be a DPI, D ⊆ minDhK,B,P ,N iR\nbe the leading diagnoses and Q be a set of sentences with PD (Q) = D+ (Q), D− (Q), D0 (Q) .\nThen Q is a query w.r.t. D iff Q 6= ∅, D+ (Q) 6= ∅ and D− (Q) 6= ∅. We denote the set of all\nqueries w.r.t. D by QD . Further, we refer to the set of those Q ∈ QD with D0 (Q) = ∅ by QA0D .\nPD (Q) is called the q-partition of Q (or: a q-partition) iff Q is a query. Inversely, Q is called\na query with (or: for) the q-partition PD (Q). Given a q-partition P, we sometimes denote its\nthree entries in turn by D+ (P), D− (P) and D0 (P).6\nGiven the formal definition of a query, the oracle is formally defined as function ans : QD →\n{t, f } which outputs an answer ans(Q) for Q ∈ QD .\nD+ (Q) and D− (Q) denote those diagnoses in D consistent only with Q’s positive and\nnegative outcome, respectively, and D0 (Q) those consistent with both outcomes. In other words,\ngiven the prior DPI DPI := hK, B, P , N iR and leading diagnoses D ⊆ minDDPI , then the\nposterior still valid diagnoses from D w.r.t. hK, B, P ∪ {Q} , N iR (i.e. after adding Q to the\npositive test cases) are those in D+ (Q) ∪ D0 (Q). The posterior still valid subset of D w.r.t.\nhK, B, P , N ∪ {Q}iR (i.e. after adding Q to the negative test cases) is D− (Q)∪D0 (Q). We also\nsay that diagnoses in D+ (Q) predict Q’s positive answer, those in D− (Q) predict Q’s negative\nanswer, and those in D0 (Q) do not predict any of Q’s answers. Since Q ∈ QD (Def. 12) implies\nthat both D+ (Q) and D− (Q) are non-empty, clearly Q’s outcomes both dismiss and preserve at\nleast one diagnosis, as postulated.\nOf course, in many cases a query will also invalidate some (unknown) non-leading diagnoses\nin allDDPI \\ D. In fact, each query Q ∈ QD is necessarily also a query w.r.t. all minimal\ndiagnoses, i.e. Q ∈ QminDDPI , and a query w.r.t. all diagnoses, i.e. Q ∈ QallDDPI . However,\nthere might be sets of sentences X ∈\n/ QD which are in fact queries w.r.t. a different (e.g. a\n0\nlarger) set of leading diagnoses D 6= D, i.e. X ∈ QD0 . Still, we point out that, facing the\ngeneral intractability of the computation of multiple diagnoses, the best we can do is using the\n5. We will often say “X violates R or N ” to state that (∃n ∈ N : X |= n) ∨ (∃r ∈ R : X violates r).\n6. In existing literature, e.g. [Shchekotykhin et al., 2012, Rodler et al., 2013, Shchekotykhin and Friedrich, 2010],\na q-partition is often simply referred to as partition. We call it q-partition to emphasize that not each partition of\nD into three sets is necessarily a q-partition.\n\n21\n\n\fcurrently given evidence in terms of the leading diagnoses D to differentiate between queries\nQ ∈ QD (definitely discriminating among all diagnoses) and non-queries Q0 ∈\n/ QD (potentially\nnon-discriminating among all diagnoses).\nAs the set D0 (Q) comprises those diagnoses that cannot be eliminated given any of Q’s\noutcomes, queries with non-empty D0 (Q) have a weaker discrimination power than others. The\nreason is that they discriminate only among the (leading) diagnoses D \\ D0 (Q). Therefore, one\nwill usually try to focus on queries with a set D0 (Q) as minimal in size as possible.7 In fact,\n[Rodler, 2015, p. 107 ff.] shows that it is always possible to enforce queries with empty D0 (Q)\nby making the comprised sentences sufficiently strong (in logical terms). Our new method presented in Sec. 3 guarantees the computation of only Q’s with D0 (Q) = ∅. On the one hand, this\ninvolves a focus on the promising query candidates (in that better discrimination among leading\ndiagnoses lets us expect better discrimination among all diagnoses). On the other hand, it reduces the query (or more precisely: the q-partition) search space from O(3|D| ) (all 3-partitions\nof |D| diagnoses) to O(2|D| ) (all 3-partitions of D with one of the 3 sets, i.e. D0 , being empty).\nFor example, the methods of [de Kleer and Williams, 1987, Shchekotykhin et al., 2012, Rodler\net al., 2013] do not ensure these properties.\nExample 9 Consider the electronic circuit in Fig. 2. We exemplify how queries consisting of\n(e.g. First-Order Logic) sentences can be used to model direct (component) probing, indirect\nprobing and testing.\nDirect Probing: A query representing a direct test of a component, say X1 , would be represented as Q = {beh(X1 )} = {out(X1 ) = xor (in1(X1 ), in2(X1 ))} (cf. Tab. 1 and Tab. 2), i.e.\n“Does component X1 work as expected?”. Such a direct test of a component might, depending\non the application, involve visible, tangible or audible inspection, component examination using\nspecialized tools, a check of operation logs for the component, etc. For instance, given a car that\ndoes not start, a direct component probe could involve testing whether the battery is working or\ndead using a battery test device.\nIndirect Probing: An indirect test of gates X1 and A1 could be formulated as a query Q =\n{out(A2 ) = 1}. The reason why these two gates are implicitly tested by answering Q is that\nthese are the only gates influencing whether the tested wire between A2 and O1 is high or low\n(cf. Fig. 2). Note, if Q is answered negatively, this tells us that at least one component among\n{X1 , A2 } is defective. But if Q is positively answered, this gives us no definite information about\nthe state of any of the two components (weak fault model). That is, both could be nominal, any\n7. In fact, one can construct examples where a query Q with D0 (Q) 6= ∅ is better (w.r.t. to some query goodness\nmeasure m) than another one, Q0 , with D0 (Q0 ) = ∅. E.g., let m be the entropy measure [de Kleer and Williams,\n1987] and p be a probability measure, then one such example is Q with p(D+ (Q)), p(D− (Q)), p(D0 (Q)) =\nh0.49, 0.49, 0.02i and Q0 with p(D+ (Q0 )), p(D− (Q0 )), p(D0 (Q0 )) = h0.99, 0.01, 0i. Nevertheless, first, in\npractice, given that Q is in QD , the existence of a query Q00 ∈ QD with small |p(D+ (Q00 )) − p(D+ (Q))| and\nsmall |p(D− (Q00 )) − p(D− (Q))| as well as p(D0 (Q00 )) = 0 is likely (e.g. by making Q logically stronger,\ncf. [Rodler, 2015, Chap. 8]). Second, we need to compare the best query with empty D0 with the best query\nwith non-empty D0 (as we will present a search that finds the best query among those with empty D0 ). Except\nfor very small search spaces (where brute force methods considering all queries are anyway practical), a query\nlike Q0 will most probably not be the best query with empty D0 . Third, the query space |QD | is normally large\nenough to ensure the existence of (even multiple) very close-to-optimal queries as per some measure m even\nthough those with non-empty D0 are neglected (cf. Sec. 4).\n\n22\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nsingle one could be flawed, e.g. stuck-at-1, or both could be abnormal, e.g. X1 stuck-at-0 and\nA2 stuck-at-1. In the car example, an indirect test of the battery charge (and possibly some other\ncomponents) could involve a test of the car’s ignition.\nTesting: Let us say we want to acquire diagnostic information by experimenting with various\ninputs and observing the resulting outputs of the circuit. A query testing whether the desired\noutput (0, 0) results from the given input (0, 0, 0), would be of the form Q = {(in1(X1 ) =\n0 ∧ in2(X1 ) = 0 ∧ in1(A2 ) = 0) → (out(X2 ) = 0 ∧ out(O1 ) = 0)}.\nExample 10 Let us consider our running example DPI ExK = hK, B, P , N iR (Tab. 3) let us\nfurther suppose that some diagnosis computation algorithm provides the set of leading diagnoses\nD = {D1 , D2 , D3 , D4 } (see Tab. 4). Then Q1 := {M → B} is a query w.r.t. D, i.e. Q1 ∈ QD .\nTo verify this, we use Def. 12 directly and show that both D+ (Q1 ) 6= ∅ and D− (Q1 ) 6= ∅.\nWe first consider the leading diagnosis D4 = {α2 , α7 } ∈ D. As per Eq. (12), we build\nthe solution KB (with background knowledge) resulting from the application of D4 as K4∗ :=\n(K \\ D4 ) ∪ B ∪ UP . Since this KB does not entail Q1 (as can be easily verified using Tab. 3\nand Tab. 4), D4 ∈\n/ D+ (Q1 ) (cf. D+ (X) in Prop. 4). So, we check whether D4 is an ele−\nment of D (Q1 ). To this end, we first build K4∗ ∪ Q1 := (K \\ D4 ) ∪ B ∪ UP ∪ Q1 =\n{α1 , α3 , α4 , α5 , α6 , α8 , α9 , p1 , M → B}. As α9 ≡ B → K, α5 = K → E and α3 |= E →\n¬M , it is clear that {M → A} = n1 ∈ N is an entailment of K4∗ ∪ Q1 . Hence, D4 ∈ D− (Q1 )\n(cf. D− (X) in Prop. 4) which is why D− (Q1 ) 6= ∅.\nNow, we have a look at D2 = {α2 , α5 }. We have that K2∗ := (K \\ D2 ) ∪ B ∪ UP =\n{α1 , α3 , α4 , α6 , α7 , α8 , α9 , p1 } |= {M → B} = Q1 due to α7 |= M → C and α6 = C → B.\nTherefore, D2 ∈ D+ (Q1 ) which is why D+ (Q1 ) 6= ∅. All in all, we have proven that Q1 ∈ QD .\nIf we complete the assignment to sets in the q-partition for all Di ∈ D, we obtain the qpartition PD (Q1 ) = h{D1 , D2 } , {D3 , D4 } , ∅i. The justification for the assignment of D1 and\nD3 is a follows. As K1∗ includes α6 , α7 we can conclude in an analogous way as above that K1∗ |=\nQ1 . In the case of D3 , we observe that K3∗ ∪ Q1 includes α3 , α5 , M → B and α9 . As explicated\nabove, these axioms entail n1 ∈ N . The q-partition PD (Q1 ) indicates that D1 , D2 are invalidated given the oracle answers Q1 negatively, i.e. D1 , D2 ∈\n/ minDhK,B,P ,N ∪{Q1 }iR . Conversely,\nD3 , D4 are ruled out given Q1 ’s positive answer, i.e. D3 , D4 ∈\n/ minDhK,B,P ∪{Q1 },N iR .\nSome important properties of q-partitions and their relationship to queries are summarized\nby the next proposition:\nProposition 5. [Rodler, 2015, Sec. 7.3 – 7.6] Let DPI := hK, B, P , N iR be a DPI and D ⊆\nminDDPI . Further, let Q ∈ QD . Then:\n1. hD+ (Q), D− (Q), D0 (Q)i is a partition of D.\n2. D− (Q) contains exactly those diagnoses Di ∈ D where Di is not a diagnosis w.r.t.\nhK, B, P ∪ {Q} , N iR . D+ (Q) contains exactly those diagnoses Di ∈ D where Di is not\na diagnosis w.r.t. hK, B, P , N ∪ {Q}iR . D0 (Q) contains exactly those diagnoses Di ∈ D\nwhere Di is a diagnosis w.r.t. both hK, B, P ∪ {Q} , N iR and hK, B, P , N ∪ {Q}iR .\n3. For Q there is one and only one q-partition hD+ (Q), D− (Q), D0 (Q)i.\n23\n\n\f4. Q is a set of common entailments of all KBs in {Ki∗ | Di ∈ D+ (Q)}. That is, letting\nDC (X) denote the deductive closure of a set of sentences X, Q is a subset of the intersection of all DC (Ki∗ ) where Di used to construct Ki∗ is an element of D+ (Q).\n5. A set of sentences X 6= ∅ is a query w.r.t. D iff D+ (X) 6= ∅ and D− (X) 6= ∅.\n6. For each q-partition PD (Q) = hD+ (Q), D− (Q), D0 (Q)i it holds that D+ (Q) 6= ∅ and\nD− (Q) 6= ∅.\n7. If |D| ≥ 2, then\n(a) Q := UD \\ Di is a query w.r.t. D for all Di ∈ D,\n(b) h{Di } , D \\ {Di } , ∅i is the q-partition associated with Q, and\n(c) a lower bound for the number of queries w.r.t. D is |D|.\n2.4.2 T HE S EQUENTIAL D IAGNOSIS P ROBLEM\nThe Sequential Diagnosis Problem we consider next is similar to the Sequential MBD-Problem\n(Prob. 1). The difference is that the former generalizes the latter by assuming an oracle that is\nallowed to not only specify positive test cases (cf. MEAS in Sec. 2.2.3) but also negative ones in\norder to narrow down the set of possible diagnoses.\nProblem 2 (Sequential Diagnosis). .\nGiven: A DPI DPI := hK, B, P , N iR and a diagnostic goal G.\nFind: Pnew , Nnew ⊇ ∅ and D, where Pnew , Nnew are sets of positive and negative test cases,\nrespectively, such that D is a minimal diagnosis w.r.t. DPInew := hK, B, P ∪ Pnew , N ∪ Nnew iR\nand D satisfies G.\nA generic algorithm solving this problem is given next.\n2.4.3 A G ENERIC S EQUENTIAL D IAGNOSIS A LGORITHM\nThe overall sequential diagnosis algorithm we take as a basis is described by Alg. 1. Similar\nalgorithms are used e.g. in [de Kleer and Raiman, 1993, Shchekotykhin et al., 2012, Rodler,\n2015]. Next, we briefly comment on the inputs, the output and the various steps of the algorithm\n(referred to by their line number in Alg. 1).\n(Inputs): The algorithm gets a DPI DPI and a diagnostic goal G as inputs (cf. Prob. 2). Further on, we assume some probability measure p that can be used to compute fault probabilities of\nsentences αi ∈ K and of diagnoses D ⊆ K. That is, we regard p as (i) a function p : K → [0, 1]\nassigning to each axiom in K (or: component in COMPS) a fault probability and (ii) a function\np : allDDPI → [0, 1] mapping each diagnosis D w.r.t. DPI to its probability p(D). The latter is\ninterpreted as the probability that all axioms in D are faulty and all axioms in K \\ D are correct.\nIn the circuit example of Fig. 2 and other physical devices, p might result from known or\nestimated fault probabilities of components (e.g. obtained from the component manufacturer or\nby observation) and other heuristic or experiential information [de Kleer and Kurien, 2004]. In\na knowledge-based application, p might result from (an integration of) information about e.g.\n24\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\ncommon logical fault patterns [Roussey et al., 2009], logs of previous faults recorded by KB\neditors such as Protégé [Noy et al., 2000] or WebProtégé [Tudorache et al., 2011], user fault\nprobabilities regarding syntactical [Shchekotykhin et al., 2012] or ontological [Rodler, 2015]\nelements in the KB, possibly coupled with provenance information about the KB’s sentences\n[Kalyanpur et al., 2006]. [Rodler, 2015, Sec. 4.6] provides a detailed discussion of applicable\ninformation sources for p and a derivation of diagnoses fault probabilities from axiom (or: component) fault probabilities or other sources. Hence, one can w.l.o.g. provide Alg. 1 only with\naxiom fault probabilities, i.e. the function in (i) above. Because the function in (ii) can be derived\nfrom the one in (i).\nLastly, the algorithm is provided with a query quality measure qqm which enables the comparison of queries in QD and thus the determination of a favorable next query in each iteration.\n(Line 2): As a first step, the function COMPUTE L EADING D IAGNOSES computes a set of\nleading diagnoses D ⊆ minDDPI where |D| ≥ 2 if |minDDPI | ≥ 2. D usually comprises a\nnumber of most probable (by exploiting p) or minimum-cardinality diagnoses. To this end, several algorithms might be employed such as HS-T REE [Reiter, 1987] (possibly coupled with\na minimal-conflict searcher, e.g. Q UICK X PLAIN [Junker, 2004], M ERGE X PLAIN [Shchekotykhin et al., 2015] or P ROGRESSION [Marques-Silva et al., 2013]), STATIC HS or DYNAMIC HS\n[Rodler, 2015], HS-DAG [Greiner et al., 1989], I NV-HS-T REE [Shchekotykhin et al., 2014] or\nBoolean algorithms [Jiang and Lin, 2003, Pill and Quaritsch, 2012]. The computed number |D|\nof leading diagnoses might be, e.g., predefined to some constant k [de Kleer and Raiman, 1993,\nShchekotykhin et al., 2012], dependent on desired minimal and maximal bounds or computation\ntime [Rodler, 2015], or a function of the probability measure p [de Kleer and Williams, 1989].\n(Line 3): Then, the algorithm tests (usually by means of p, cf. Remark 1) whether the diagnostic goal G is satisfied for D. If so, the must probable leading diagnosis is returned (line 4)\nand the algorithm stops.\n(Line 5): Otherwise, the function CALC Q UERY determines a query Q by means of D, DPI,\np and the qqm. Roughly, Q should discriminate optimally among minDDPI , or more precisely,\namong the leading diagnoses D, which is the currently available evidence regarding minDDPI .\nThe meaning of “discriminating optimally” is determined by qqm which possibly relies upon p.\nThat is, a query with best (or sufficiently good [de Kleer and Williams, 1987]) value as per qqm\nis sought among the queries in QD . One example of a qqm is the information-entropy-based\n$(.) function suggested by [de Kleer and Williams, 1987].\n(Line 6): The calculated query is presented to the oracle and an answer ans(Q) is returned.\nThis is the (only) point in the algorithm where an oracle inquiry takes place. For technical\nreasons, the oracle function ans is regarded as a total function, i.e. the oracle is assumed to be\nable to answer any posed query. We emphasize however that this is not a necessary requirement\nfor our presented method which can handle do not know answers (e.g. if some measurement\npoints in a physical device are not accessible to a technician) as well by simply offering the\noracle the next-best query. Hence, one can imagine a (not shown) loop between lines 5 and 6 of\nthe algorithm.\n(Line 7): Given the query-answer pair (Q, ans(Q)), the current DPI is updated by a respective addition of Q to the positive test cases P (i.e. P ← P ∪ {Q}) if ans(Q) = t and to N (i.e.\nN ← N ∪ {Q}) in case ans(Q) = f . Moreover, the function UPDATE DPI involves an adap25\n\n\ftation of the diagnoses probability measure based on ans(Q) in terms of a Bayesian probability\nupdate according to [de Kleer and Williams, 1987, Shchekotykhin et al., 2012]. That is, for Q’s\nanswer aQ ∈ {t, f } the new probability of any D ∈ allDDPI is computed as\np(D | ans(Q) = aQ ) =\n\np(ans(Q) = aQ | D) p(D)\np(ans(Q) = aQ )\n\nThe probabilities required to evaluate the above-notedP\nformula are established as follows. Given\nthe current leading diagnoses D, we define p(X) := D∈X p(D) for X ⊆ D and assume p to\nbe normalized over D such that that p(D) = 1. Since D includes only still possible diagnoses,\np(D) > 0 must hold for all D ∈ D. Further, assuming that each non-predicting diagnosis\nD ∈ D0 (Q) predicts each answer with a probability of 12 , we define\np(D0 (Q))\n(13)\n2\n(i.e. the probability of the leading diagnoses predicting Q’s positive answer plus half the probability of the non-predicting leading diagnoses) and p(ans(Q) = f ) = 1 − p(ans(Q) = t) (i.e.\nthe probability of the leading diagnoses predicting Q’s negative answer plus half the probability\nof the non-predicting leading diagnoses). Finally,\n\n+\n\n1, if D ∈ D (Q)\np(ans(Q) = t | D) := 0, if D ∈ D− (Q)\n\n1\n0\n2 , if D ∈ D (Q)\np(ans(Q) = t) := p(D+ (Q)) +\n\nand p(ans(Q) = f | D) = 1 − p(ans(Q) = t | D).\nRemark 4 When Alg. 1 computes a new set of leading diagnoses Dnew (line 2) after executing\nthe DPI update in line 7, it computes Dnew as minimal diagnoses w.r.t. the new DPI. That\nis, D will usually (but not necessarily always, cf. [Rodler, 2015, Rem. 12.6]) comprise the\nremaining diagnoses from the leading diagnoses D used in the previous iteration and some new\nones computed in line 2. The remaining diagnoses from D given ans(Q) = aQ are D+ (Q) ∪\nD0 (Q) for aQ = t and D− (Q) ∪ D0 (Q) for aQ = f (cf. Prop. 5.2).\n(Outputs): The algorithm executes the while-loop until the given diagnostic goal G is fulfilled. Let DPI∗ be the current DPI and D be the current leading diagnoses in the iteration where\nthis holds. Then Alg. 1 returns the most probable minimal diagnosis D∗ ∈ D ⊆ minDDPI∗ .\n2.4.4 A LGORITHM C ORRECTNESS\nTo show that Alg. 1 solves the Sequential Diagnosis problem (Prob. 2), we use the fact that for\nany non-singleton set of leading diagnoses D a query – and hence the opportunity to discriminate\namong elements of D – exists [Rodler, 2015, Sec. 7.6]:\nProposition 6. Let DPI be a DPI and D ⊆ minDDPI such that |D| ≥ 2. Then QD 6= ∅.\nTheorem 5. Let COMPUTE L EADING D IAGNOSES be a sound and complete procedure for the\ncomputation of minimal diagnoses w.r.t. a DPI, CALC Q UERY be a sound method for query\ncomputation that returns at least one query for any D where QD 6= ∅, and G be an arbitrary\n26\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nAlgorithm 1 Sequential Diagnosis\nInput: DPI DPI := hK, B, P , N iR , diagnostic goal G, probability measure p (used to compute sentence\nand diagnoses fault probabilities), query quality measure qqm\nOutput: The most probable minimal diagnosis D∗ ∈ D ⊆ minDDPI∗ where DPI∗ is some DPI\nhK, B, P 0 , N 0 iR where P 0 ⊇ P and N 0 ⊇ N such that the diagnostic goal G is met for D\n1: while true do\n2:\nD ← COMPUTE L EADING D IAGNOSES(DPI, p)\n3:\nif GOAL R EACHED(G, D, p) then\n4:\nreturn GET M OST P ROBABLE D IAGNOSIS(D, p)\n5:\nQ ← CALC Q UERY(D, DPI, p, qqm)\n. see Algorithm 2\n6:\nanswer ← ans(Q)\n. oracle inquiry\n7:\nDPI ← UPDATE DPI(DPI, p, Q, answer)\n\ndiagnostic goal that is at most as strict as G1 in Rem. 1. Then, for arbitrary inputs DPI (DPI),\np (diagnoses probability measure) and qqm (query quality measure), Alg. 1 solves Prob. 2.\nProof. (Sketch) Let us assume that G := G1 (“there is only a single minimal diagnosis w.r.t.\nthe current DPI”) from Rem. 1 and let us refer to the DPI used by Alg. 1 in iteration i (of the\nwhile-loop) by DPIi , i.e. the input DPI DPI is denoted by DPI1 . If the first call of COMPUTE L EADING D IAGNOSES returns a singleton D = {D}, then |minDDPI | = 1, thus G1 is met and\nAlg. 1 returns D in line 4 which obviously meets Prob. 2 (Pnew = Nnew = ∅).\nOtherwise, the first call of COMPUTE L EADING D IAGNOSES returns some D where |D| ≥ 2.\nIf G is not satisfied in line 3, then CALC Q UERY will return a query Q by Prop. 6. Due to\n[Rodler, 2015, Cor. 12.4], each answer ans(Q) implies that allDDPI1 ⊃ allDDPI2 where DPI2\nis the result of applying UPDATE DPI in line 7 to DPI1 .\nWe can now adopt the same argumentation for the second and any further call of COM PUTE L EADING D IAGNOSES (iterations 2, 3, . . . ). However, |allDDPI1 | must be finite as each\ndiagnosis is a subset of K and K must be finite due to Def. 8. Hence, there must be some finite k\nsuch that G is met in line 3 of iteration k. Therefore, Alg. 1 outputs the single minimal diagnosis\nD w.r.t. DPIk which meets Prob. 2 (Pnew includes all the k1 positively answered queries in these\nk iterations, and Nnew all the k − k1 negatively answered ones).\nSince any diagnostic measure G Alg. 1 might be used with is at most as strict (cf. Rem. 1) as\nG1 , which we used for our argumentations, we obtain that such a finite k must always exist.\n2.4.5 A PPLICABILITY AND D IAGNOSTIC ACCURACY\nProp. 6 and Theorem 5 have two further implications: First, a precomputation of only two minimal diagnoses is required in each iteration to generate a query and proceed with sequential diagnosis. Despite its NP-hardness, the generation of two (or more) minimal diagnoses is practical in\nmany real-world settings [de Kleer, 1991, Shchekotykhin et al., 2014], making query-based sequential diagnosis commonly applicable. Second, the query-based approach guarantees perfect\ndiagnostic accuracy, i.e. the unambiguous identification of the actual diagnosis (e.g. by using the\ndiagnostic goal G := G1 in Alg. 1).\n27\n\n\f3. Efficient Optimized Query Selection for Sequential Model-Based Diagnosis\nIn this section we present the main contribution of this work, which is a novel implementation\nof the CALC Q UERY function in Alg. 1. But first, we have a look at the measurement selection\nproblem in sequential diagnosis.\n3.1 Measurement Selection for Sequential Diagnosis\nAs argued, the (q-)partition PD (Q) enables both the verification whether a candidate Q is indeed\na query and an estimation of the impact Q’s outcomes have in terms of diagnoses invalidation.\nAnd, given axiom (or: component) fault probabilities, it enables to gauge the probability of observing a positive or negative query outcome. Active learning query selection measures (QSMs)\nm : Q 7→ m(Q) ∈ R [Settles, 2012] use exactly these query properties characterized by the qpartition to assess how favorable a query is. They aim at selecting queries such that the expected\nnumber of queries until obtaining a deterministic diagnostic result is minimized, i.e.\nX\np(D)q# (D) → min\n(14)\nD⊆K\n\nwhere q# (D) is the number of queries required, given the initial DPI, to derive that D must be\nthe actual diagnosis. Solving this problem is known to be NP-complete as it amounts to optimal\nbinary decision tree construction [Hyafil and Rivest, 1976]. Hence, as it is common practice in\nsequential diagnosis [de Kleer and Williams, 1987, Brodie et al., 2003, Pietersma et al., 2005,\nShchekotykhin et al., 2012, Rodler et al., 2013], we restrict our algorithm to the usage of QSMs\nthat make a locally optimal query selection through a one-step lookahead. This has been shown\nto be optimal in many cases and nearly optimal in most cases [de Kleer et al., 1992b]. Several\ndifferent QSMs m such as split-in-half, entropy, or risk-optimization have been proposed, well\nstudied and compared against each other [de Kleer and Williams, 1987, Shchekotykhin et al.,\n2012, Rodler et al., 2013, Rodler, 2017]. For instance, using entropy as QSM, m would be\nexactly the scoring function $() derived in [de Kleer and Williams, 1987]. Note, we assume\nw.l.o.g. that the optimal query w.r.t. any m is the one with minimal m(Q).\nBesides minimizing the number of queries in a diagnostic session (Eq. (14)), a further goal\ncan be the minimization of the query (answering) cost arising for the oracle. For instance, assume a malfunctioning physical system such as a car or a turbine. Then there might be parts\nof the system which are easier accessible, cheaper (in terms of required tools, time or manpower), less dangerous, etc. for measurements than others. In a car, it is clearly much easier and\nfaster to check some, say cable, that is directly accessible after opening the engine cover than\nsome internals of the engine. Apart from that, systems might include built-in sensors able to\nprovide information about certain parts of the system quasi for free, whereas other parts must\nbe manually measured. On the other hand, e.g., in knowledge-based systems, there might be\nsentences about the intended domain that are easier to evaluate than others. For example, sentences comprising complex logical notation are certainly more difficult to read, understand and\nthus to answer than, e.g., facts or simple implications (cf. [Ceraso and Provitera, 1971, Horridge\net al., 2011]). Moreover, aside from the syntax of sentences, the comprehension of their content\nin terms of the expressed topic, can be a smaller or larger hurdle, depending on the oracle’s\n28\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nexpertise in the topic. E.g., given a faulty biomedical KB [Noy et al., 2009], a biologist acting as an oracle might be much less confident in answering a medicine-specific query than a\nbiology-specific one.\nTo this end, we allow the user of our tool to specify a query cost measure (QCM) c : Q 7→\nc(Q) ∈ R+ that assigns to each query a real-valued cost. Examples of QCMs are\nP\n• cΣ (Q) := ki=1 ci\n(minimize overall query cost)\n• cmax (Q) := maxi∈{1,...,k} ci\n(minimize maximal cost of single measurements)\n• c|·| (Q) := |Q|\n(minimize number of measurements)\nwhere Q = {q1 , . . . , qk } and ci is the cost of evaluating the truth of the sentence qi . For example,\nthe QCM cΣ could be used to minimize query answering time given that the ci ’s represent\nmeasurement time. Alternatively, cmax could be adopted, e.g., when the ci ’s account for human\ncognitive load, in order to keep the necessary cognitive skill to answer the query minimal. In\nscenarios where all potential measurements are known or assumed to be (approximately) equally\ncostly to answer, one might pursue queries with a minimal number of sentences, which would\nbe reflected by using the QCM c|·| . An example would be a digital circuit where all components\nand wires, respectively, are equally well accessible for measurements. Note that the QCM c|·|\nis a special case of cΣ , i.e. cΣ simulates c|·| if ci = cj for all i, j. In the following, we assume\nw.l.o.g. that the optimal query w.r.t. any c is the one with minimal c(Q).\nWhile the costs ci (e.g. accessibility of systems parts) relevant for physical systems might\nbe more or less directly derivable from the structure or other properties of the system, the costs\nci (e.g. comprehensibility of sentences) relevant for knowledge-based systems might be plausibly derivable from the available fault information [Rodler, 2015, Sec. 4.6.1]. For instance, the\ncognitive complexity of understanding a queried sentence correctly in terms of syntax and topic\ncan be expected to be closely related to the fault probability of the sentence computed from fault\ninformation about logical elements (e.g. ∀, ¬, ∧) and non-logical elements (e.g. concepts such\nas toxoplasmosis or odontalgia in a medical KB). Intuitively, the more a sentence captures the\nexpertise of the oracle (i.e. the lower its fault probability for the oracle is), the easier it is to\nunderstand and answer for the oracle.\n3.1.1 T HE A DDRESSED M EASUREMENT S ELECTION P ROBLEM\nNow, the problem tackled by the new algorithm introduced in this work is:\nProblem 3 (Optimal Query Selection). .\nGiven: A DPI DPI, D ⊆ minDDPI where |D| ≥ 2, a QSM m, a QCM c, a query search space\nS ⊆ QD .\nFind: A query Q∗ with minimal cost w.r.t. c among all queries in S that are optimal w.r.t. m. Formally: Q∗ = arg minQ∈OptQ(m,S) c(Q) where OptQ(m, S) := {Q0 | Q0 = arg minQ∈S m(Q)}.\nNote, there can be multiple equally good solutions Q∗ ∈ QD to Prob. 3.\n3.2 The Suggested Algorithm\nIn this section we propose a novel algorithm (Alg. 2) for two-way optimized query computation\nin sequential diagnosis which solves Prob. 3 (for different settings of the query search space\n29\n\n\fAlgorithm 2 Optimized Query Computation\nInput: DPI DPI, D ⊆ minDDPI where |D| ≥ 2, a QSM m, a QCM c (including information about\nsentence costs ci , cf. page 29), probability measure p (to compute axiom fault probabilities), threshold\ntm (i.e. |m(Q) − mopt | ≤ tm ⇒ Q regarded as optimal; mopt := optimal value of m), inference\nengine Inf , set ET of entailment types, pref (preference information used for query optimization),\na Boolean enhance (if true, optional query enhancement is run)\nOutput: an optimized query Q∗ ∈ QD w.r.t. m, tm and c (cf. Theorems 7 and 8)\n1: P ← OPTIMIZE QPARTITION(D, p, m, tm )\n. P1\n2: if enhance = true then\n3:\nQ0 ← EXPAND Q UERY F OR QPARTITION(DPI, P, ET, Inf )\n. (optional) P3\n4:\nQ∗ ← OPTI M INIMIZE Q UERY F OR QPARTITION(DPI, P, Q0 , pref , Inf )\n. (optional) P3\n5: else\n6:\nQ∗ ← OPTIMIZE Q UERY F OR QPARTITION(P, c)\n. (default) P2\n7: return Q∗\n\nS).8 The described query computation procedure can be divided into three phases: Phase P1\n(line 1), (the default) Phase P2 (line 6) and (the optional) Phase P3 (lines 3-4). After giving the\nreader an intuition and overview of its functioning, we explain all three phases of it. Further\nimplementation details can be found in the extended version [Rodler, 2016] of the paper.\n3.2.1 I NTUITION AND OVERVIEW\nThe main idea to achieve an inexpensive high-quality query generation is the exploitation of\nthe information inherent in the ⊆-minimal leading diagnoses and a decoupling of the optimizations of a QSM (first), i.e. the minimization of the expected number of queries until diagnostic\ncertainty is given, and a QCM (second), i.e. the minimization of the query (answering) costs.\nPhase P1, given a QSM m, determines an optimal QP w.r.t. m (which implies that all queries\nhaving this QP are optimal regarding m) by completely avoiding the use of reasoning services.\nFor this purpose, we present a polynomial-space (heuristic) search technique that explores a generally exponential space of q-partitions in a sound and complete way. That is, without expensive\nreasoner calls, all non-QPs are automatically neglected (i.e. no unnecessary time is spent for\nexploring non-QPs) and the proven optimal QP in the explored space is found. As the key to\nthe realization of this search, we introduce the notions of canonical queries and canonical QPs.\nAdditionally, the use of these two concepts in phase P1 automatically disregards a broad class of\nsuboptimal QPs, which leads to a generally significant refinement of the relevant search space.\nAfter an optimal QP P as per m has been determined and fixed, there are two options (parameter\nenhance): The execution of either\n• phase P2 (restricted search space, no reasoner calls, instantaneous output) or\n• phase P3 (full search space, polynomial number of reasoner calls, reasonably fast output).\nPhase P2 (enhance = false) realizes the finding of an optimal query w.r.t. any of the QCMs\ndiscussed on page 29 for the optimal QP P from P1. In order to make this query computation\n8. A Protégé plugin for KB debugging implementing i.a. the presented algorithm can be found on\nhttp://isbi.aau.at/ontodebug/. Protégé [Noy et al., 2000] is the most widely used open-source KB (ontology)\neditor in the world and available at https://protege.stanford.edu/.\n\n30\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nvery efficient, P2 focuses on a restricted class of queries wherein the calculation of a (globally)\noptimal query is possible without reasoning aid. The query output by P2 represents the system\ncomponent(s) whose inspection is least expensive (QCM c) among all those that yield the highest\ninformation (QSM m). In this vein, P2 computes an optimized query for scenarios such as the\nones discussed in [Brodie et al., 2003].\nPhase P3 (enhance = true) performs a query enhancement, subdivided into two consecutive\nsteps. The first step “enriches” the canonical query of the optimal QP P from P1 by additional sentences of preferred types (augmentation to the full search space regarding preferred\nqueries). The second step finds an optimized ⊆-minimal contraction of the enriched canonical\nquery (searching for an optimal solution in full search space). Overall, phase P3 computes a\nquery that globally optimizes the QCM cmax (see page 29) among all queries that – under the\nreasonable assumption given by Conjecture 1 (see later) – globally optimize the QSM m over\nthe full query search space. To this end, P3 requires only a polynomial number of reasoner calls.\nMoreover, given any predefined set of preferred query elements (e.g. measurements with small\ncosts), P3 ensures that the returned optimized query includes only such preferred elements, if\nsuch a query exists.\n3.2.2 P HASE P1: O PTIMIZING THE Q-PARTITION\nIn this section we describe the functioning of OPTIMIZE QPARTITION in Alg. 2. At this first\nstage P1, we optimize the given QSM m – for now without regard to the QCM c, which is\noptimized later in phase P2. This decoupling of optimization steps is possible since the QSM\nvalue m(Q) of a query Q is only affected by the (unique) q-partition of Q and not by Q itself.\nOn the contrary, the QCM value c(Q) is a function of (the sentences in) Q only and not of Q’s\nq-partition. Therefore, the search performed in P1 will consider only q-partitions and target the\ndetermination of a (close-to) optimal q-partition P. This q-partition remains fixed throughout\nall further phases of the algorithm, where an optimal query with exactly this q-partition P is\nsought.\nRemark 5 A decoupling of optimizations in the reverse order, i.e. QCM c before QSM m,\nis not reasonably possible. First, the q-partition is a necessary prerequisite for the verification\nwhether a set of sentences is in fact a query (see Def. 12). Because without the associated\n(q-)partition one has no guiding principle of which Q is allowed (i.e. a query) and which is not\n(i.e. a set of sentences that is not a query) when trying to find some query Q with minimal c(Q).\nSecond, once the query is fixed, so is its q-partition (see Prop. 5.3). So, there is no chance to\noptimize m for some already fixed query Q.\nCanonical Queries and Q-Partitions. As the determination of an optimal q-partition w.r.t.\nthe given QSM m should be as efficient as possible, we want to neglect any partition which is\nnot a q-partition in the search. That is, we do not even want to generate any non-q-partitions.\nHowever, to verify whether a given 3-partition P of a set of leading diagnoses D is a q-partition,\nwe need a query Q 6= ∅ with a q-partition PD (Q) = P. Q can be seen as a concrete witness\nproving that P is not solely a partition of D, but indeed a q-partition (cf. Def. 12). But:\n\n31\n\n\fProposition 7. Let P be a (fixed) q-partition. Then |{Q | Q query, PD (Q) = P}| > 1, i.e.\nthere are multiple queries for P.\nProof. Since a query is a non-empty set of sentences, it must include at least one sentence α.\nThis sentence can be equivalently rewritten in different ways, e.g. α ≡ α ∧ τ for an arbitrary\ntautology τ .\nWhereas the proof draws on a semantically equivalent rewriting (that is possible for any\nsentence in infinitely many ways) to show Prop. 7, we point out that there are, in most cases,\nqueries with equal q-partitions that are semantically non-equivalent – and not even rewritings\nof one another. This holds true also for ⊆-minimal queries. i.e. queries where the removal of\nany sentence in them leads to a change of their associated q-partition. We will provide some\nexamples later.\nThe idea is now to appoint one well-defined representative query for each q-partition, i.e. we\nseek the definition of a unique query for each q-partition such that the former allows us to verify\nthe latter. And, we want such a query to be easily computable. Furthermore, in order to devise a\ntime and space saving q-partition search method, the potential size of the explored search space\nshould to be minimized. To achieve this, a key idea is to omit those q-partitions in the search that\nare proven suboptimal. One such class of suboptimal q-partitions are those P with non-empty\nD0 (P) because they do not discriminate among all (leading) diagnoses (cf. the discussion in\nSec. 2.4.1). Hence, a second postulation to the representative queries for q-partitions is that the\nfocus on such queries implies the exclusion of the mentioned suboptimal q-partitions. In other\nwords, each suboptimal q-partition should have no such representative query.\nTo realize these postulations, we introduce the notion of a canonical query (CQ). The requirement of easy computability means that we would like to be able to determine a CQ without\nperforming any expensive or (generally) intractable operations. Since by Prop. 4.4 any query\nfor a q-partition D+ , D− , D0 is a subset of the common entailments of all KBs in the set\n{Ki∗ | Di ∈ D+ }, the operations of interest in query computation are entailment calculations.\nOnce calls to a reasoning engine are involved, the complexity of one such call is already NPcomplete for Propositional Logic. However, a straightforward way of entailment calculation\nwithout involving reasoning aid or other expensive operations is the restriction to the computation of explicit entailments. An entailment α of a KB X is called explicit iff α ∈ X, implicit\notherwise [Rodler, 2015, Def. 8.1]. But, as indicated by [Rodler, 2015, Prop. 8.3], just these explicit entailments are also the key to achieve a disregard of suboptimal q-partitions. Therefore,\nCQs should be characterized as queries including only explicit entailments. Henceforth, we call\na query Q ∈ QD explicit-entailments query iff Q ⊆ K.\nIndeed, a restriction to the consideration of only explicit-entailments queries leads to a focus\non non-suboptimal q-partitions:\nProposition 8. Let DPI := hK, B, P , N iR be a DPI, D ⊆ minDDPI and Q a query in QD\nsuch that Q ⊆ K. Then D0 (Q) = ∅.\nProof. We have to show that for an arbitrary diagnosis Di ∈ D either Di ∈ D+ (Q) or Di ∈\nD− (Q). Therefore two cases must be considered: (a) K \\ Di ⊇ Q and (b) K \\ Di 6⊇ Q. In\ncase (a), by the fact that the entailment relation is extensive for L, K \\ Di |= Q and thus, by\n32\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nmonotonicity of L, Ki∗ = (K \\ Di ) ∪ B ∪ UP |= Q. So, Di ∈ D+ (Q). In case (b) there exists\nsome axiom α ∈ Q ⊆ K such that α ∈\n/ K \\ Di , which means that (K \\ Di ) ∪ Q ⊃ (K \\ Di ).\nFrom this we can derive that Ki∗ ∪ Q must violate R or N by the ⊆-minimality property of each\ndiagnosis in D, in particular of Di . Hence, Di ∈ D− (Q).\nThe proof of Prop. 8 exhibits a decisive advantage of using explicit-entailments queries. In\nfact, it reveals that the task of verifying whether a set of explicit entailments is a query in QD\nis very easy in that it can be reduced to set comparisons. That is, subset checks are traded for\nreasoning. To build the q-partition P(Q) associated with some explicit-entailments query Q it\nmust solely be tested for each Di ∈ D whether K \\ Di ⊇ Q or not. More specifically:\nProposition 9. Let DPI := hK, B, P , N iR be a DPI, D ⊆ minDDPI and Q be a query in QD\nsuch that Q ⊆ K. Then D ∈ D+ (Q) iff K \\ D ⊇ Q and D ∈ D− (Q) iff K \\ D 6⊇ Q.\nThe next proposition describes the shape any explicit-entailments query must have:\nProposition 10. Let DPI be any DPI, D ⊆ minDDPI and Q be a query in QD such that\nQ ⊆ K. Then Q must include some axiom(s) in UD (i.e. Q ∩ UD 6= ∅), can but need not include\nany axioms in K \\ UD , and must not include any axioms in ID (i.e. Q ∩ ID = ∅). Further on,\nelimination of axioms in K \\ UD from Q does not affect the q-partition P(Q) of Q.\nAs suggested by Prop. 10, the sentences in the KB K of a DPI that are crucial for the definition of an explicit-entailments query – and hence for the characterization of a CQ – are given\nby UD as well as ID . In fact, as the proofs of Lemmata 1 and 2 in Appendix A show, the noninclusion of sentences from ID is necessary to allow for non-empty D+ (Q) and the inclusion of\nsome sentence(s) from UD is required to allow for non-empty D− (Q). Without these properties\na set of sentences Q does not discriminate among the leading diagnoses D. For this reason, we\ngive these essential sentences UD \\ ID a distinct name:\nDefinition 13. We call DiscD := UD \\ ID the discrimination sentences wrt. D.\nExample 11 Let us consider the set of leading diagnoses\nD = {D1 , D2 , D3 } = {{α2 , α3 }, {α2 , α5 }, {α2 , α6 }}\n\n(cf. Tab. 4)\n\nw.r.t. our running example DPI ExK (Tab. 3). Then, UD = {α2 , α3 , α5 , α6 } and ID = {α2 }.\nNow, all ⊆-minimal explicit-entailments query candidates we might build according to Prop. 10\n(which provides necessary criteria to explicit-entailments queries) are\n{{α3 , α5 , α6 } , {α3 , α5 } , {α3 , α6 } , {α5 , α6 } , {α3 } , {α5 } , {α6 }}\n\n(15)\n\nThat is, all these seven candidates include at least one element out of UD and no elements out of\nK \\ UD = {α1 , α4 , α7 } or ID . Clearly, there are exactly six different q-partition candidates with\nempty D0 w.r.t. the three diagnoses in D, i.e. there are three possibilities to select one, and three\npossibilities to select two diagnoses to constitute the set D+ with ∅ ⊂ D+ ⊂ D (the set D−\nis already set after D+ is chosen since D+ , D− , D0 is a partition of D). Hence, QD might\ncomprise at most six explicit-entailments queries with different q-partitions because each one of\nthem must feature an empty D0 -set in its q-partition, as stated by Prop. 8. By the Pigeonhole\n33\n\n\fPrinciple, either at least two candidates in Eq. (15) have the same q-partition or at least one\ncandidate is not a query at all. As we require that there must be exactly one CQ per q-partition\nand seek a method that computes only queries (and no candidates that turn out to be no queries),\nwe see that Prop. 10 is not yet restrictive enough to constitute also a sufficient criterion for CQs.\nSo let us now find out where the black sheep among the candidates above is. The key to\nfinding it is the fact that each query Q is a common entailment of all Ki∗ := (K \\ Di ) ∪ B ∪ UP\nwhere Di is in the D+ (Q)-set of Q’s q-partition (cf. Prop. 5.4). Since the candidates for CQs\nin Eq. (15) are all constituted of just explicit entailments αi ∈ K, we immediately see that we\nmust postulate that each CQ Q is a set of common elements of all K \\ Di where Di is in the\nD+ (Q)-set of Q’s q-partition. The K\\Di sets for diagnoses Di ∈ D are given below. Starting to\nverify this for the first candidate {α3 , α5 , αT\n6 } above, we quickly find out that there is no possible\n+\nD (Q)-set of a q-partition such that Q ⊆ Di ∈D+ (Q) K \\ Di because none of these intersected\nsets includes all elements out of {α3 , α5 , α6 }. Thus, the first candidate is no query at all.\nK \\ D1 = {α1 , α4 , α5 , α6 , α7 }\nK \\ D2 = {α1 , α3 , α4 , α6 , α7 }\nK \\ D3 = {α1 , α3 , α4 , α5 , α7 }\nPerforming an analogue verification for the other candidates, we recognize that all of them\nare indeed queries and no two of them exhibit the same q-partition. Concretely, the q-partitions\nassociated with the queries in the set above (minus the first set {α3 , α5 , α6 }) are as follows:\nP({α3 , α5 }) = h{D3 } , {D1 , D2 } , ∅i\nP({α3 , α6 }) = h{D2 } , {D1 , D3 } , ∅i\nP({α5 , α6 }) = h{D1 } , {D2 , D3 } , ∅i\nP({α3 }) = h{D2 , D3 } , {D1 } , ∅i\n\n(16)\n\nP({α5 }) = h{D1 , D3 } , {D2 } , ∅i\nP({α6 }) = h{D1 , D2 } , {D3 } , ∅i\nBased on these thoughts, we now define a CQ as follows:\nDefinition 14 (Canonical Query). Let DPI be a DPI, D ⊆ minDDPI and ∅ ⊂ D+ ⊂ D.\nThen Qcan (D+ ) := (K \\ UD+ ) ∩ DiscD is the canonical query (CQ) w.r.t. the seed D+ if\nQcan (D+ ) 6= ∅. Else, Qcan (D+ ) is undefined.9\nTo interpret this definition, note that K \\UD+ are exactly the common explicit entailments of\n| D ∈ D+ } (cf. Prop. 5.4). Intuitively, the CQ extracts all discrimination sentences DiscD\nfrom these entailments, thereby removing all elements that do not affect the q-partition (cf.\nProp. 10). Recall that we requested a well-defined representative for q-partitions; hence, we\nspecify this representative in a way it includes no obviously immaterial elements.\n\n{Ki∗\n\nRemark 6 There might be multiple seeds that lead to the same canonical query. That is,\n+\n+\n+\nQcan (D+\ni ) = Qcan (Dj ) might hold for seeds Di 6= Dj (because in spite of this difference\n9. We will often not mention the seed of a CQ if it is not relevant in a particular discussion.\n\n34\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nUD+ = UD+ might be true). For instance, let D := {D1 , D2 , D4 , D5 } = {{α2 , α3 }, {α2 , α5 },\ni\n\nj\n\n{α2 , α7 }, {α1 , α4 .α7 }} (cf. Tab.4) be a set of leading diagnoses w.r.t. our running example DPI\n+\nExK (Tab. 3). Then the seeds D+\n1 := {D1 , D5 } as well as D2 := {D1 , D4 , D5 } give rise to the\nsame CQ Q = {α5 }.\nIt is trivial to see from Def. 14 that:\nProposition 11. Any canonical query is an explicit-entailments query.\nProposition 12. Let ∅ ⊂ D+ ⊂ D. Then, if existent, the canonical query w.r.t. D+ is unique.\nWe now show that a CQ is indeed a query in the sense of Def. 12.\nProposition 13. If Q is a canonical query, then Q is a query.\nWe define a canonical q-partition as a q-partition for which there is a canonical query with\nexactly this q-partition:\nDefinition 15 (Canonical Q-Partition). Let DPI be a DPI and D ⊆ minDDPI where |D| ≥ 2.\nLet further P0 = hD+ , D− , ∅i be a partition of D. Then we call P0 a canonical q-partition\n(CQP) iff P0 = PD (Qcan (D+ )), i.e. hD+ , D− , ∅i = hD+ (Qcan (D+ )), D− (Qcan (D+ )), ∅i. In\nother words, given the partition hD+ , D− , ∅i, the canonical query w.r.t. the seed D+ must have\nexactly the q-partition hD+ , D− , ∅i.\nExample 12\n\nEq. (16) shows exactly all CQs and CQPs w.r.t. the set D given in Ex. 11.\n\nRemark 7 In general, the expression D+ (Qcan (D+ )) is not necessarily equal to D+ . The\nD+ within parentheses is the seed used to construct the CQ Qcan (D+ ) (cf. Def. 14), whereas\nthe function D+ (X), given a set of sentences X, maps to the set of all leading diagnoses Di ∈ D\nfor which Ki∗ entails X. As explained in Rem. 6, there might be different seeds that imply the\nsame CQ. For instance, recalling the example given in Rem. 6, we have that D+ (Qcan (D+\n1 )) =\n+\n.\nWe\ncould\nthence\nsay\nthat\na\nCQP\nis\nexactly\na q))\n=\n{D\n,\nD\n,\nD\n}\n=\nD\nD+ (Qcan (D+\n1\n4\n5\n2\n2\n+\n+\npartition P whose D (P) set is stable under the application of the functions Qcan () and D (),\ni.e. D+ (Qcan (D+ (P))) = D+ (P).\nAs a direct consequence of Def. 15 and Prop. 13 we obtain that each CQP is a q-partition:\nCorollary 1. Each canonical q-partition is a q-partition.\nMoreover, there is a one-to-one relationship between CQPs and CQs:\nProposition 14. Given a canonical q-partition, there is exactly one canonical query associated\nwith it and vice versa. In particular, the unique canonical query associated with the canonical\nq-partition P is the set of sentences Qcan (D+ (P)).\nNo CQP is a suboptimal q-partition in the sense of our discussion in Sec. 2.2.3 in that each\nCQ discriminates among all leading diagnoses:\nProposition 15. Any canonical q-partition hD+ , D− , D0 i satisfies D0 = ∅.\n35\n\n\fSeed S\n{D5 , D6 }\n{D1 , D6 }\n{D1 , D5 }\n{D1 }\n{D5 }\n{D6 }\n\n{i | αi ∈ Qcan (S)}\n{2, 5, 6} ∩ {1, 2, 3, 4, 7} = {2}\n{1, 5, 6} ∩ {1, 2, 3, 4, 7} = {1}\n{5, 6} ∩ {1, 2, 3, 4, 7} = ∅\n{1, 4, 7} ∩ {1, 2, 3, 4, 7} = {1, 4, 7}\n{2, 3} ∩ {1, 2, 3, 4, 7} = {2, 3}\n{1, 2} ∩ {1, 2, 3, 4, 7} = {1, 2}\n\ncanonical q-partition\nh{D5 , D6 } , {D1 } , ∅i\nh{D1 , D6 } , {D5 } , ∅i\n×\nh{D1 } , {D5 , D6 } , ∅i\nh{D5 } , {D1 , D6 } , ∅i\nh{D6 } , {D1 , D5 } , ∅i\n\nTable 5: All CQs and associated CQPs w.r.t. D = {D1 , D5 , D6 } (cf. Tab. 4) and the example DPI ExK\ngiven by Tab. 3.\n\nProof. Let P0 = hD+ , D− , D0 i be a canonical q-partition. Then, by Def. 15, there is a canonical query Q for which P0 is equal to the q-partition PD (Q) = hD+ (Q), D− (Q), D0 (Q)i of Q.\nBy Def. 14, ∅ ⊂ Q ⊆ K. Hence, by Prop. 8, D0 (Q) = ∅ and thus D0 = ∅ must hold.\nLet us at this point illustrate the introduced notions by the following example:\nExample 13 Consider the leading diagnoses\nD = {D1 , D5 , D6 } = {{α2 , α3 } , {α1 , α4 , α7 } , {α3 , α4 , α7 }}\n\n(cf. Tab. 4)\n\n(17)\n\nw.r.t. our example DPI ExK (Tab. 3). The potential solution KBs given this set of leading diagnoses D are {K1∗ , K2∗ , K3∗ } (cf. Eq. (12)) where\nK1∗ = {α1 , α4 , α5 , α6 , α7 , α8 , α9 , p1 }\nK2∗ = {α2 , α3 , α5 , α6 , α8 , α9 , p1 }\nK3∗ = {α1 , α2 , α5 , α6 , α8 , α9 , p1 }\nThe discrimination sentences DiscD are UD \\ ID = {α1 , α2 , α3 , α4 , α7 }. Tab. 5 lists all possible seeds S (i.e. proper non-empty subsets of D) and, if existent, the respective (unique) CQ\nQcan (S) as well as the associated (unique) CQP. Note that the CQ for the seed S = {D1 , D5 } is\nundefined which is why there is no CQP with a D+ -set {D1 , D5 }. This holds since K \\ US =\n{α1 , . . . , α7 } \\ ({α2 , α3 } ∪ {α1 , α4 , α7 }) = {α5 , α6 } has an empty intersection with DiscD .\nSo, by Def. 14, Qcan (S) = ∅.\nAdditionally, we point out that there is no query Q (and hence no q-partition) – and therefore\nnot just no canonical query – for which D+ (Q) corresponds to {D1 , D5 }. Because for such Q\nto exist, D6 ∈ D− (Q) must hold. Under this assumption, there must be a set of common\nentailments Ents of K1∗ and K5∗ (cf. Prop. 5.4) which, along with K6∗ , violates R or N (cf.\nProp. 4). As all sentences in Ents are entailed by K \\ (D1 ∪ D5 ) ∪ B ∪ UP as well, and due to\nthe observation that K \\ (D1 ∪ D5 ) ⊂ K \\ D6 , by monotonicity of Propositional Logic, every\ncommon entailment of K1∗ and K5∗ is also an entailment of K6∗ . Due to the definition of a solution\nKB (cf. Def. 9), which implies that K6∗ neither violates R nor N , this means that there cannot\nbe a query Q satisfying D+ (Q) = {D1 , D5 }. So, obviously, in this example every q-partition\n(with empty D0 ) is also a CQP.\n\n36\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nAdvantages of Using Canonical Queries and Q-Partitions. The restriction to the consideration of only CQs during phase P1 has some nice implications:\n1. CQs and CQPs can be generated by cheap set operations. No inference engine calls are\nrequired. (Prop. 9)\nRemark: The main causes why this is possible are the ⊆-minimality of leading diagnoses\nand the monotonicity of the logic underlying the DPI. Intuitively, the concepts of CQs\nand CQPs just leverage the already available information (obtained by logical reasoning\nduring diagnosis computation) inherent in the leading diagnoses in a clever way to avoid\nany further reasoning during the q-partition search.\n2. Each CQ is a query in QD for sure, no verification of its q-partition (as per Def. 12) is required, thence no unnecessary candidates (which turn out to be no queries) are generated.\n(Prop. 13)\n3. Automatic computation of only queries Q with full discrimination power regarding D (i.e.\nof those Q with empty D0 (Q)). (Prop. 15)\n4. No duplicate queries or q-partitions are generated as there is a one-to-one relationship\nbetween CQs and CQPs. (Prop. 14)\n5. The explored search space for q-partitions is not dependent on the particular (entailments\noutput by an) inference engine, as CQs are explicit-entailments queries. (Prop. 11)\nWe emphasize that all these properties do not hold for normal (i.e. non-canonical) queries\nand q-partitions. The overwhelming impact on the query computation time of this strategy of\nfirst narrowing down the search space to only such computationally “benign” queries to find an\noptimal q-partition, and the later reintroduction of the full query search space when searching\nfor an optimal query for this fixed optimal q-partition will be demonstrated in Sec. 4.\nThe Q-Partition Search Procedure. Now, having at hand the notion of a CQP, we describe\nthe sound and complete (heuristic) CQP search procedure performed in P1.\nA (heuristic) search problem [Russell and Norvig, 2010] is defined by the initial state, a\nsuccessor function enumerating all direct neighbor states of a state, the step costs from a state to\na successor state, the goal test to determine if a given state is a goal state or not, and (possibly)\nsome heuristic function to estimate the remaining effort from each state towards a goal state.\nWe define the initial state, i.e. the partition hD+ , D− , D0 i to start with, as h∅, D, ∅i where\nD is the given set of leading diagnoses. The idea is to transfer diagnoses step-by-step from D−\nto D+ to construct all CQPs systematically. The step costs are irrelevant in our application, as\nonly the found q-partition as such counts. In other words, the required solution is a q-partition\nand not the path to reach it from the initial state. Heuristics derived from the given QSM m\ncan be (optionally) integrated into the search to enable faster convergence to a goal state. A\nq-partition P is a goal state if it optimizes m up to a given threshold tm (cf. [de Kleer and\nWilliams, 1987], see Alg. 2). To make this precise, let us call a query Q optimal w.r.t. m and tm\niff |m(Q) − mopt | ≤ tm where mopt is the optimal theoretically achievable value of m. Then P\nis a goal iff an arbitrary query Q (e.g. the CQ) for P is optimal w.r.t. m and tm . Recall that each\n37\n\n\fquery Q for P yields the same m(Q) as m is only dependent on the q-partition of a query (cf.\nthe discussion on page 31).10\nThe search strategy adopted by the CQP search in phase P1 can be characterized as depthfirst, local best-first backtracking strategy. We now explicate informally how the search tree is\nevolved by means of this strategy. Starting from the initial partition h∅, D, ∅i (or: root node), the\nsearch will proceed downwards until (a) a goal q-partition has been found, (b) all successors of\nthe currently analyzed q-partition (or: node) have been pruned (based on the QSM m) or (c) there\nare no successors of the currently analyzed q-partition (or: node). This behavior is implied by\nthe depth-first strategy.\nAt each current q-partition (or: node), the focus moves on to the best successor q-partition\n(or: child node), possibly according to some given heuristic function (based on the QSM m).\nThis behavior is implied by the local best-first strategy.\nThe search procedure is ready to backtrack in case all successors (or: child nodes) of a qpartition (or: node) have been explored or pruned and no goal q-partition has been found yet.\nIn this case, the next-best unexplored sibling of the node will be analyzed next according to the\nused local best-first depth-first strategy. This behavior is implied by the backtracking strategy.\nWe emphasize that this local best-first depth-first backtracking strategy involves a linear\nspace complexity, as opposed to a (global) best-first strategy.\nWhat we have not formally specified yet is the used successor function. We dedicate the rest\nof the q-partition search procedure description to the derivation and definition of the successor\nfunction. The soundness and completeness of this function with regard to the computation of all\nand only CQPs for D will guarantee the soundness and completeness w.r.t. CQPs of the overall\nsearch procedure.\nIn order to characterize a suitable successor function, we define a direct neighbor of a qpartition as follows:\n−\n+\n−\nDefinition 16. Let DPI be a DPI, D ⊆ minDDPI and Pi := hD+\ni , Di , ∅i, Pj := hDj , Dj , ∅i\nbe partitions of D. Then, Pi 7→ Pj is a minimal D+ -transformation from Pi to Pj iff Pj is a\n+\n+\n+\n−\n+\n+\n0\nCQP, D+\ni ⊂ Dj and there is no CQP hDk , Dk , ∅i with Di ⊂ Dk ⊂ Dj . A CQP P is called\na successor of a partition P iff P0 results from P by a minimal D+ -transformation.\n\nIntuitively, a successor P0 of a partition P results from the transfer of a ⊆-minimal set of\ndiagnoses from D− (P) (comprising all leading diagnoses D if P is the initial state) to D+ (P)\n(empty for initial state P) such that the resulting partition P0 is a CQP.\nThe successor function Sall then maps a given partition P of D to the set of all its possible\nsuccessors, i.e. to the set including all CQPs that result from P by a minimal D+ -transformation.\nThe reliance upon a minimal D+ -transformation guarantees that the search is complete w.r.t.\nCQPs because one cannot skip over any CQPs when transforming a state into a direct successor\nstate. As the initial state is not a q-partition (cf. Def. 12), the definition of the successor function\nSall involves specifying\n• a function Sinit that maps the initial state to the set of all CQPs that can be reached by it\nby a single minimal D+ -transformation, and\n10. Therefore, we will sometimes write m(P) to denote m(Q) for arbitrary Q for which PD (Q) = P.\n\n38\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\n• a function Snext that maps any CQP to the set of all CQPs that can be reached by it by a\nsingle minimal D+ -transformation.\nSinit can be easily specified by means of the following proposition which is a consequence of\nProp. 5.7.\nProposition 16. Let DPI be a DPI and D ⊆ minDDPI where |D| ≥ 2. Then, h{Di }, D \\\n{Di }, ∅i is a canonical q-partition for all Di ∈ D.\nSince only one diagnosis is transferred from the initial D− set D to the D+ -set of the partition to obtain any CQP as per Prop. 16 from the initial state, it is clear that all these CQPs indeed\nresult from the application of a minimal D+ -transformation from the initial state (soundness).\nAs for all other CQPs the D+ set differs by more than one diagnosis from the initial D+ set ∅\n(and thus includes a proper superset of {D} for some D ∈ D), it is obvious that all other CQPs\ndo not result from the initial state by some minimal D+ -transformation (completeness). Hence:\nProposition 17. Given the initial state P0 := h∅, D, ∅i, the function\nSinit : h∅, D, ∅i 7→ {h{D} , D \\ {D} , ∅i | D ∈ D}\nis sound and complete, i.e. it produces all and only (canonical) q-partitions resulting from P0\nby minimal D+ -transformations.\nNote that in fact all q-partitions with empty D0 , not only all CQPs, that a reachable from P0\nby a minimal D+ -transformation, are generated by Sinit . The reason for this is that there are no\nother possibilities to build (q-)partitions with a singleton D+ set and an empty D0 set.\nIn order to define Snext , we utilize Prop. 18 which provides sufficient and necessary criteria\nwhen a partition of D is a CQP.\nProposition 18. Let DPI := hK, B, P , N iR be a DPI, D ⊆ minDDPI and P = hD+ , D− , ∅i\nbe a partition of D with D+ 6= ∅ and D− 6= ∅. Then, P is a canonical q-partition iff\n1. UD+ ⊂ UD and\n2. there is no Dj ∈ D− such that Dj ⊆ UD+ .\nThe following example uses Prop. 18 to check the CQP property for two candidate partitions:\nExample 14 Let (by referring to αi by i for clarity)\nP1 := h{D1 , D2 , D3 } , {D4 , D5 , D6 } , ∅i\n= h{{2, 3} , {2, 5} , {2, 6}} , {{2, 7} , {1, 4, 7} , {3, 4, 7}} , ∅i\nP2 := h{D1 , D2 , D5 } , {D3 , D4 , D6 } , ∅i\n= h{{2, 3} , {2, 5} , {1, 4, 7}} , {{2, 6} , {2, 7} , {3, 4, 7}} , ∅i\n\n(18)\n(19)\n\nbe two partitions of the leading diagnoses D = minDExK for our example DPI ExK in Tab. 3.\nThen UD+ (P1 ) = {2, 3, 5, 6}, UD+ (P2 ) = {1, 2, 3, 4, 5, 7} and UD = {1, . . . , 7}. Since\nUD+ (P1 ) ⊂ UD as well as UD+ (P2 ) ⊂ UD , the first condition of Prop. 18 is satisfied for both\npartitions of D. As to the second condition, given that 7 ∈ D4 , D5 , D6 , but 7 6∈ UD+ (P1 ) , it\n39\n\n\fholds that Dj 6⊆ UD+ (P1 ) for all j ∈ {4, 5, 6}. Therefore, P1 is a CQP. P2 , on the other hand,\nis not a CQP because, e.g., D4 = {2, 7} ⊂ {1, 2, 3, 4, 5, 7} = UD+ (P2 ) (second condition of\nProp. 18 violated). We point out that one can verify that there is in fact no query with q-partition\nP2 . That is, the partition P2 of D is no CQP and no q-partition.\n−\nLet in the following for a DPI hK, B, P , N iR and a partition Pk = hD+\nk , Dk , ∅i of D and\nall Di ∈ D ⊆ minDhK,B,P ,N iR\n(k)\n\nDi\n\n:= Di \\ UD+\nk\n\n(20)\n\nThe next corollary establishes the relationship between Eq. (20) and CQPs based on Prop. 18:\n−\n+\n−\nCorollary 2. Let D ⊆ minDhK,B,P ,N iR , Pk = hD+\nk , Dk , ∅i a partition of D with Dk , Dk 6=\n−\n∅ and UD+ ⊂ UD . Then P := D+\nk , Dk , ∅ is a canonical q-partition iff\nk\n\n(k)\n\n= ∅ for all Di ∈ D+\nk , and\n\n(k)\n\n6= ∅ for all Di ∈ D−\nk.\n\n1. Di\n2. Di\n\nExample 15 For the purpose of illustration, let us examine both partitions discussed in Ex. 14\n−\nagain by means of Cor. 2. To this end, we write the partitions Pk = hD+\nk , Dk , ∅i (for k = 1, 2)\nin the form\nDn\no n\no E\n(k)\n(k)\n−\nDi | Di ∈ D+\n,\nD\n|\nD\n∈\nD\ni\ni\nk\nk ,∅\nMoreover, natural numbers j in the sets again refer to the respective sentences αj (as in Ex. 14).\nFor the partition P1 in Eq. (18) (i.e. for k = 1) we get h{∅, ∅, ∅} , {{7} , {1, 4, 7} , {4, 7}} , ∅i.\n(1)\n(1)\nSince all Di in D−\nin D+\n1 are non-empty (and all Di\n1 are empty, which is always trivially\nfulfilled), Cor. 2 confirms the result we obtained in Ex. 14, namely that P1 is a CQP.\nOn the contrary, P2 (i.e. k = 2) given by Eq. (19) is not a CQP according to Cor. 2 since,\nrepresented in the same form as P1 above, P2 evaluates to h{∅, ∅, ∅} , {{6} , ∅, ∅} , ∅i. We see\n(2)\n(2)\nthat D4 and D6 are both equal to the empty set, but D4 , D6 ∈ D−\n2 which must not be the\ncase if P2 is a CQP due to Cor. 2. Again, the result we got in Ex. 14 is successfully verified. In\n(2)\nfact, P2 can be transformed into a CQP by transferring all diagnoses Di ∈ D−\n2 where Di = ∅,\ni.e. D4 and D6 , to D+\n2 . The resulting partition, in this case h{D1 , D2 , D4 , D5 , D6 } , {D3 } , ∅i, is\n+\nthen a CQP according to Cor. 2. This necessary shift of diagnoses from D−\nk to Dk is also the\nmain idea exploited in the specification of the function Snext . The next example picks up on this\nissue in more detail.\nThe next example analyzes situations that might occur when transferring a single diagnosis\n+\nfrom the D−\nk set of a CQP to its Dk set in order to generate a successor CQP of it. In particular,\n+\nit makes evident that (i) not every diagnosis in D−\nk might be eligible to be shifted to Dk in\nterms of a minimal D+ -transformation and (ii) the transfer of some (eligible) diagnosis D might\nnecessitate the transfer of other diagnoses, which we informally call necessary followers of D in\nthe following. That is, minimal D+ -transformations might involve the simultaneous relocation\nof multiple diagnoses.\n40\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nExample 16 We continue discussing our running example DPI ExK (see Tab. 3). Assume as in\nEx. 15 that D = minDExK . Let us consider the CQP Pk := h{D1 , D2 } , {D3 , D4 , D5 , D6 } , ∅i.\nWritten in the form\nD\nn\noE\n(k)\nUD+ , Di | Di ∈ D−\n(standard representation of CQPs)\n(21)\nk\nk\n\nPk is given by\nh{2, 3, 5} , {{6} , {7} , {1, 4, 7} , {4, 7}}i\n\n(22)\n\n(k)\n\nNote, by the definition of Di (see Eq. (20)) the sets that are elements of the right-hand set of\nthis tuple are exactly the diagnoses in D−\nk reduced by the elements that occur in the left-hand\nset of this tuple. For instance, {6} results from D3 \\ UD+ = {2, 6} \\ {2, 3, 5}. We now analyze\nk\n\nPk w.r.t. necessary followers of the diagnoses in D−\nk . The set of necessary followers of D3 is\nempty. The same holds for D4 . However, D5 has two necessary followers, namely {D4 , D6 },\n(k)\nwhereas D6 has one, given by D4 . The intuition is that transferring D3 with D3 = {6} to D+\nk\nyields the new set D+\n:=\n{D\n,\nD\n,\nD\n}\nwith\nU\n+ = {2, 3, 5, 6}. This new set however causes\n∗\n1\n2\n3\nk\nD ∗\n(k∗ )\nDi\n\nk\n\nD−\nk∗\n\nno set\nfor Di in\nto become the empty set. Hence the transfer of D3 necessitates no\nrelocations of any other elements in D−\nk∗ .\nFor D6 , the situation is different. Here the new set UD+∗ = {2, 3, 4, 5, 7} which implicates\nk\nn\no\n∗\n∗\n∗\n(k )\n(k )\n(k )\nD3 , D4 , D5\n= {{6} , ∅, {1}}\n∗\nfor Di in D−\nk∗ . Application of Cor. 2 now yields that Pk is not a CQP due to the empty set\n(k∗ )\nD4 . As explained in Ex. 15, turning Pk∗ into a CQP requires the transfer of all diagnoses Di\n(k∗ )\nassociated with empty sets Di to D+\nk∗ .\n\nImportantly, notice that the CQP Ps∗ := h{D1 , D2 , D4 , D6 } , {D3 , D5 } , ∅i resulting from\nthis cannot be reached from Pk by means of a minimal D+ -transformation. The reason is\nthat Ps := h{D1 , D2 , D4 } , {D3 , D5 , D6 } , ∅i is a CQP as well and results from Pk by fewer\n∗\nchanges to D+\nk than Ps . In fact, only CQPs resulting from the transfer of diagnoses Di ∈\n(k)\n−\n+\nDk with ⊆-minimal Di to D+\nk are reachable from Pk by a minimal D -transformation. As\nbecomes evident from Eq. (22), only the CQPs created from Pk by means of a shift of D3 (with\n(k)\nD3 = {6}) or D4 ({7}) to D+\nk are successors of Pk compliant with the definition of a minimal\n+\nD -transformation (Def. 16).\nFinally, let us inspect the CQP Pr = {{D2 , D3 , D4 , D5 } , {D1 , D6 } , ∅} with the standard\nrepresentation h{1, 2, 4, 5, 6, 7} , {{3} , {3}}i. We find that there are no CQPs reachable by a\nminimal D+ -transformation from Pr . The reason behind this is that transferring either of the\n+\ndiagnoses D1 , D6 in D−\nr to Dr requires the transfer of the other, since both are necessary\nfollowers of each other. An empty D− -set – and hence no (canonical) q-partition – would be the\nresult. Generally, two diagnoses Di , Dj ∈ D−\nr bear a necessary follower relation to one another\n(r)\n(r)\n(w.r.t. a CQP Pr ) iff Di = Di .\n41\n\n\f(k)\n\nThe previous examples indicate that the sets Di (see Eq. (20)) for Di ∈ D−\nk play a central role when it comes to specifying the successors of the CQP Pk in terms if minimal D+ transformations. For this reason we dedicate a special name to them:\n(k)\n\n−\n−\nDefinition 17. Let Pk = hD+\nk , Dk , ∅i be a CQP and Di ∈ Dk . Then Di is called the trait of\n−\nDi (w.r.t. Pk ). The relation associating two diagnoses in Dk iff their trait is equal is denoted\nby ∼k .\n\nClearly:\nProposition 19. ∼k is a equivalence relation (over D−\nk ).\nLet us denote the equivalence classes w.r.t. ∼k by [Di ]∼k where Di ∈ D−\nk.\nExample 17 Consider the CQP Pk = {{D4 , D5 } , {D1 , D2 , D3 , D6 } , ∅} related to our running example DPI ExK (Tab. 3). Using the standard representation of CQPs (introduced by\nEq. (21)) this q-partition amounts to h{1, 2, 4, 7} , {{3} , {5} , {6} , {3}}i. Now,\n∼k = {hD1 , D1 i , hD2 , D2 i , hD3 , D3 i , hD6 , D6 i , hD1 , D6 i , hD6 , D1 i}\nand the equivalence classes w.r.t. ∼k are\n{[D1 ]∼k , [D2 ]∼k , [D3 ]∼k } = {{D1 , D6 } , {D2 } , {D3 }}\nNote that [D1 ]∼k = [D6 ]∼k holds. The number of the equivalence classes gives an upper bound\nof the number of successors resulting from a minimal D+ -transformation from Pk . The traits\nof these equivalence classes are given by\n{{3} , {5} , {6}}\nThese can be just read from the standard representation above. Since all traits are ⊆-minimal,\nthere are exactly three successors of Pk as per Def. 16.\nThe concept of a trait and the relation ∼k enable the formal characterization Snext as follows:\n−\n∼k\nbe the set of all\nCorollary 3. Let Pk := D+\nk , Dk , ∅ be a canonical q-partition, EQ\nequivalence classes w.r.t. ∼k and\nn\no\n(k)\n(k)\n∼k\nk\nEQ∼\n:=\n[D\n]\n|\n6\n∃j\n:\nD\n⊂\nD\ni\nj\ni\n⊆\nk\ni.e. EQ∼\n⊆ includes all equivalence classes w.r.t. ∼k which have a ⊆-minimal trait. Then, the\nfunction\no\n(n\n∼k\n+\n−\nD\n∪\nE,\nD\n\\\nE,\n∅\n|\nE\n∈\nEQ\nif |EQ∼k | ≥ 2\n⊆\nk\nk\n−\nSnext : D+\n,\nD\n,\n∅\n→\n7\nk\nk\n∅\notherwise\n\nis sound and complete, i.e. it produces all and only canonical q-partitions resulting from Pk by\nminimal D+ -transformations.\nProp. 17 and Cor. 3 immediately entail that the successor function Sall , defined as Sinit if\nthe input is the initial state h∅, D, ∅i and as Snext otherwise, is sound and complete as regards\n42\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nsuccessor CQP generation in terms of Def. 16. Let the backtracking algorithm implemented\nby phase P1 return the best found canonical q-partition, given that all possible states have been\nexplored and no goal has been found. Then:\nTheorem 6. The backtracking algorithm performed by phase P1 using successor function Sall\nis sound and complete. That is:\n• (Completeness) If there is a canonical q-partition which is a goal (as defined on page 37),\nthen P1 returns a canonical q-partition which is a goal.\n• (Soundness) If P1 returns a q-partition P, then P is canonical. Further, P is a goal, if a\ngoal exists. Otherwise, P is the best existing canonical q-partition w.r.t. m and tm .\nProof. The theorem follows directly from the soundness and completeness of the successor\nfunction Sall (Prop. 17, Cor. 3) and the fact that backtracking algorithms over finite search spaces\nusing a sound and complete successor function are sound and complete (cf. [Rossi et al., 2006,\nChap. 4]).\nSize of the Explored Search Space. Through Cor. 2 we realize that UD+ already defines a\nCQP uniquely. The next corollary exploits this fact to compute the number of CQPs w.r.t. a\nset of leading minimal diagnoses D. Note that the number of CQPs w.r.t. D is equal to the\nnumber of CQs w.r.t. D (Prop. 14) which in turn constitutes a lower bound of the number of\nall (semantically different) queries w.r.t. D. Furthermore, since Sall is a sound and complete\nsuccessor function (and thus prohibits the non-consideration of any CQP), the number of CQPs\nw.r.t. D is exactly the size of the search space explored by phase P1 in the worst case. The worst\ncase will occur if there are no CQPs that are goal states w.r.t. the QSM m and the given optimality\nthreshold tm , or if there is a single goal state which happens to be explored only after all other\nstates have been explored. Note that the full search space will rarely be completely explored in\npractice even if the worst case occurs. This is due to pruning techniques (based on m) [Rodler,\n2016, p. 98ff. and Alg. 6] that can be incorporated into the search. In our evaluations (Sec. 4)\nwe even observed the exploration of only a negligible fraction of the search space in most cases.\nCorollary 4. Let D ⊆ minDhK,B,P ,N iR with |D| ≥ 2. Then, for the number c of canonical\nq-partitions w.r.t. D the following holds:\n\b\nc = UD+ | ∅ ⊂ D+ ⊂ D \\ {UD } ≥ |D|\n(23)\nExample 18 To concretize Cor. 4, let us apply it to our example DPI ExK (Tab. 3) using the set\nof leading diagnoses D := minDExK = {{2, 3} , {2, 5} , {2, 6} , {2, 7} , {1, 4, 7} , {3, 4, 7}}\n(cf. Tab. 4). Building all possible unions of sets in D, i.e. all possible UD+ sets, such that\neach union is not equal to (i.e. a proper subset of) UD = {1, . . . , 7}, yields 29 different UD+\nsets. Note, there might be many more different D+ sets for ∅ ⊂ D+ ⊂ D than UD+ sets.\nThese UD+ sets directly correspond to the CQPs w.r.t. D, i.e. the CQP associated with UD+\nis hD+ , D \\ D+ , ∅i. There are no other CQPs. Since there is one and only one CQ per CQP\n(cf. Prop. 12), we can immediately infer from this result that there are exactly 29 (semantically)\ndifferent CQs w.r.t. D.\n\n43\n\n\fCanonical Q-Partitions versus All Q-Partitions. Whether q-partitions hD+ , D− , ∅i exist\nwhich are no CQPs is not yet clarified, but both theoretical and empirical evidence indicate\nthe negative.\nFirst, [Rodler, 2016, Sec. 3.4.2] provides a thorough theoretical analysis of the relation between canonical and non-canonical q-partitions implying that a q-partition must fulfill sophisticated requirements if it is non-canonical. When we did not succeed in deriving the conjectured\ncontradiction resulting from the theoretical requirements to a non-canonical q-partition which\nwould rule out such cases theoretically, we tried hard to devise, at least in theory, an instance of\na non-canonical q-partition. But we were not able to come up with one.\nSecond, [Rodler, 2016, Sec. 3.4.2] applies the results of the conducted theoretical analysis\nto a comprehensive study on hundreds of real-world KBs with sizes of several thousands of\nsentences [Horridge et al., 2012]. The findings are that, if possible at all, the probability of the\nexistence of non-canonical q-partitions is very low.\nThird, an analysis of ≈ 900 000 q-partitions we ran for different leading diagnoses sets\nD of different cardinalities for different DPIs (see Sec. 4, Tab. 6) showed that all q-partitions\nwere indeed CQPs. Concretely, we were performing for each (D,DPI) combination a brute force\nsearch for q-partitions relying on a reasoning engine using the algorithm given in [Shchekotykhin\net al., 2012, Alg. 2], and another one exploiting the notions of CQs and CQPs. None of these\nsearches returned a q-partition which is not canonical. This motivates the following conjecture:\nConjecture 1. Let D ⊆ minDhK,B,P ,N iR and QPA0D denote the set of all q-partitions w.r.t. D\nwith empty D0 , and CQPD the set of canonical q-partitions w.r.t. D. Then CQPD = QPA0D .\nNote, this conjecture is by no means necessary for the proper functioning of our presented\nalgorithms. In case Conjecture 1 turned out to be wrong, the consequence would be just the\ninvalidity of perfect completeness w.r.t. all q-partitions achieved by the restriction to only CQPs.\nStill, we could cope well with that since CQs and CQPs bring along nice computational properties (cf. 1 – 5 on page 37) and prove extremely efficient by the total avoidance of reasoning\n(see Sec. 4). Moreover, methods not incorporating the canonical notions prove to be strongly\nincomplete regarding query and QP computation due to their dependence on (the entailments\ncomputed by) the used inference engine (cf. Advantage 5 of CQs on page 37). Although executing a brute force search, they sometimes compute only 1% and on average less than 40% of the\nQPs our proposed novel approach is able to find.\nAlso, our conducted experiments (see Sec. 4) manifested the successful finding of optimal qpartitions in all evaluated cases for all discussed QSMs m that are also adopted e.g. in the works\nof [de Kleer and Williams, 1987, Shchekotykhin et al., 2012, Rodler et al., 2013]. For, given\npractical numbers of leading diagnoses per iteration, e.g. any number ≥ 5, cf. [Shchekotykhin\net al., 2012, Rodler et al., 2013], the CQP search space size considered by our strategy proves\nby far large enough to guarantee the inclusion of (often multiple) goal q-partitions (also for\nnegligibly small thresholds). Theoretical support for this is given by Cor. 4, empirical support\nby Figures 6, 12 and 13 and their discussions.\nThe following example showcases one entire execution of the CQP search performed by\nphase P1 applied to our running example:\n44\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\n0.01\nD1\n{2, 3}\n\n0.33\nD2\n{2, 5}\n\n0.99\nD2 , D3 , D4 , D5 , D6\n{5} , {6} , {7} , {1, 4, 7} , {4, 7}\n\no\n\n0\n∅\n∅\n\n{D1 }\n0.01\n\n0.49\n\n0.67\nD1 , D3 , D4 , D5 , D6\n{3} , {6} , {7} , {1, 4, 7} , {3, 4, 7}\n\n1\nD1 , D2 , D3 , D4 , D5 , D6\n{2, 3} , {2, 5} , {2, 6} , {2, 7} , {1, 4, 7} , {3, 4, 7}\n\n{D2 }\n\nq\n\n{D6 }\n\n0.33\n\n0.04\nD6\n{3, 4, 7}\n\n0.17\n{D3 }\n\n0.14\nD3\n{2, 6}\n\n0.86\nD1 , D2 , D4 , D5 , D6\n{3} , {5} , {7} , {1, 4, 7} , {3, 4, 7}\n\n0.07\nD4\n{2, 7}\n\n0.93\nD1 , D2 , D3 , D5 , D6\n{3} , {5} , {6} , {1, 4} , {3, 4}\n\ns\n\n0.14\n{D4 }\n\n{D5 }\n\n0.41\nD5\n{1, 4, 7}\n\n0.43\n\n{D4 }\n\nt\n0.48\nD4 , D5\n{1, 2, 4, 7}\n\n0.52\nD1 , D2 , D3 , D6\n{3} , {5} , {6} , {3}\n\n0.96\nD1 , D2 , D3 , D4 , D5\n{2} , {2, 5} , {2, 6} , {2} , {1}\n\n0.41\n\n\u0016\n\n0.59\nD1 , D2 , D3 , D4 , D6\n{2, 3} , {2, 5} , {2, 6} , {2} , {3}\n\n{D6 }\n\n0.07\n\n0.02\n\n\u001f\n\n0.07\n\n0.36\n\nt\n\n0.04\n\n0.45\nD5 , D6\n{1, 3, 4, 7}\n\n0.09\n\n0.04\n\n\u001a\n\n0.55\nD1 , D2 , D3 , D4\n{2} , {2, 5} , {2, 6} , {2}\n\n0.05\n\nFigure 3: Search for optimal CQP in phase P1 for example DPI ExK (Tab. 3) w.r.t. m := ENT and\nthreshold tm := 0.05.\n\nExample 19 Consider the example DPI ExK (Tab. 3) and leading diagnoses D = minDExK\n(see Tab. 4). Let the diagnoses probabilities hp(D1 ), p(D2 ), p(D3 ), p(D4 ), p(D5 ), p(D6 )i for\nDi ∈ D be given by h0.01, 0.33, 0.14, 0.07, 0.41, 0.04i. The search tree for a goal QP w.r.t. m :=\nENT and tm := 0.01 produced by phase P1 is shown in Fig. 3. At this, ENT denotes the entropy\nQSM [de Kleer and Williams, 1987, Shchekotykhin et al., 2012]. Roughly, it evaluates a query\nthe better, the closer the query answer probabilities approach a discrete uniform distribution. Let\nus therefore assume a very simple heuristic function h which assigns h(P) = |p(D+ ) − 0.5| to\na QP P := D+ , D− , D0 (recall that the probability of positive and negative answers amount\nto p(D+ ) and p(D− ), respectively, for empty D0 , cf. Eq. (13)) where smaller h values imply\nmore promising QPs w.r.t. ENT. Further, let us use a pruning function that stops the generation\nof successors at any QP P whose p(D+ ) probability exceeds 0.5 (as no descendant node of P\ncan have a better ENT value than P itself). For ENT, the optimal QSM-value mopt = 0 and\nthus a QP P is a goal state iff |m(P)| ≤ tm = 0.01 (cf. Alg. 2).\n−\n0\nIn Fig. 3, a node in the search tree representing the CQP Pk = D+\nk , Dk , Dk is denoted\n−\nby a frame including a table with three rows where (1) the topmost row shows p(D+\nk ) | p(Dk )\n(relevant for computing QSM m and heuristic function h, and for making pruning decision),\n−\n(2) the middle row depicts D+\nk | Dk and (3) the bottommost row gives the standard representation of the CQP (cf. Eq. (21)). The framed value at the bottom right corner of the large frame\nquotes the heuristic value h(Pk ) computed for the CQP Pk . No such value for the root node is\ngiven since it is not a QP and hence does not qualify as a solution. Furthermore, the (for CQPs)\nalways empty D0k set is omitted. A frame is dashed / continuous / double if the associated node\nis generated (but not expanded) / expanded / a returned goal CQP. Arrows represent minimal\n\n45\n\n0.46\n\n\fD+ -transformations, i.e. an arrow’s destination QP is a result of a minimal D+ -transformation\napplied to its source (q-)partition. Arrow labels give the set of diagnoses and the probability\nmass (i.e. the sum of the single diagnoses probabilities) moved from the D− -set of the source\n(q-)partition to the D+ -set of the destination QP.\nStarting from the root node (initial state) representing the partition h∅, D, ∅i, the successor\nfunction Sinit generates all possible CQPs resulting from the transfer of a single diagnosis from\nthe D− -set of the initial state to its D+ -set. Since there are six diagnoses in D, the initial state\nhas exactly six successors (Prop. 17). From all these generated neighbor nodes of the initial\nstate, the best one according to the heuristic function h is selected for expansion. In this case,\nit is the CQP P1 := h{D5 } , {D1 , D2 , D3 , D4 , D6 } , ∅i as it exhibits the best (lowest) heuristic\nvalue 0.09 among all the six open nodes.\nFor P1 , Snext generates exactly two CQPs that result from it by a minimal D+ -transformation\n(Cor. 3). This can be seen by considering the traits of the diagnoses in D− (P1 ) shown in the\nright column of the third row in the table representing P1 . Among the five traits there are only\n(1)\n(1)\ntwo ⊆-minimal ones, i.e. D4 := {2} and D6 := {3}. All the other traits are proper supersets\nof either of these. This means that all successors of P1 can be constructed by shifting either\nD4 or D6 from D− (P1 ) to D+ (P1 ) yielding P21 := h{D4 , D5 } , {D1 , D2 , D3 , D6 } , ∅i and\nP22 := h{D5 , D6 } , {D1 , D2 , D3 , D4 } , ∅i, respectively.\nAt this stage, the best QP among the two successors P21 and P22 of P1 (depth-first, local\nbest-first) is determined for expansion by means of h. As p(D+ (P21 )) differs by less (0.02)\nfrom 0.5 than p(D+ (P22 )) (0.05), P21 is chosen. However, as tm has been set to 0.01 and\nm(P21 ) ≈ 0.001 ≤ 0.01, P21 is a goal and returned as the solution of phase P1 of Alg. 2. Note,\nthere were no backtrackings or tree prunings necessary as the used heuristic function guided\nthe search directly towards a goal state. This behavior could also be frequently observed in our\nexperiments (see Sec. 4).\nComplexity of P1. Concerning time, the worst-case scenario occurs if the search in P1 explores the entire CQP search space, e.g. because no goal CQP exists. As becomes directly\nevident through Cor. 4, the worst-case time complexity of P1, assuming one time unit for the\nprocessing of a CQP, is as follows:\n\b\nProposition 20. P1 terminates in O( UD+ | ∅ ⊂ D+ ⊂ D \\ {UD } ) ⊆ O(2|D| ) time.\nProof. The left O(.) expression follows from Cor. 4. The inclusion between the O(.) expressions\nholds due to fact that the worst case for the left O(.) expression arises exactly when all sets in\nD are mutually disjoint. Because in this case each set UD+ differs from all other sets UD+ for\ni\n\nj\n\n+\n|D| − 2 such sets.\nD+\ni 6= Dj . Hence, excluding U∅ and UD , there are exactly 2\n\nNote, the time complexity is equal to the size of the full CQP search tree. The worst-case\nspace complexity of P1, however, is (much) lower in general. As explained above, this is due to\nthe depth-first, local best-first backtracking strategy pursued by the CQP search which implies\na linear space complexity O(b ∗ d) where b is the branching factor, i.e. the maximal number\nof generated successors for any node, and d the maximal depth of the search tree. In fact,\ngiven that D is the considered leading diagnoses set, no node (partition) occurring in the search\n46\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\ncan have more than |D| successors (in terms of Def. 16). The reason is that Sinit generates\nexactly |D| successors (Prop. 17) and Snext generates at most |D| − 1 successors (Cor. 3). The\nlatter holds, first, as Snext is only applied to a QP with non-empty D+ which is why D− can\ninclude only at most |D| − 1 diagnoses that might be transferred to D+ in the course of a\nminimal D+ -transformation, and, second, since a set of |D| − 1 elements cannot be partitioned\nk\ninto more than the same number of equivalence classes, i.e. |EQ∼\n⊆ | ≤ |D| − 1 (cf. Cor. 3).\nHence, b = |D|. The search tree depth d = |D| − 1 because, starting from the initial state\nhD+ , D− , ∅i = h∅, D, ∅i, at least one element from D− is transferred to D+ on any edge along\nany downward search tree branch (such that the result is still a QP, i.e. D− 6= ∅, cf. Def. 16). All\nin all we have:\nProposition 21. P1 consumes O(|D|2 ) space.\nAs we will demonstrate in Sec. 4 (see Fig. 12), these benign complexity results enable the\nsearch to explore search spaces with a theoretical complexity of up to 2500 within reasonable\ntime yielding a result whose QSM-value differs negligibly from the theoretical QSM-optimum.\n3.2.3 P HASE 2: S ELECTING AN O PTIMAL Q UERY FOR THE O PTIMAL Q-PARTITION\nIn this section, we describe the functioning of OPTIMIZE Q UERY F OR QPARTITION in Alg. 2. By\nnow, we have demonstrated in Section 3.2.2 how an optimal q-partition P w.r.t. a given QSM m\ncan be computed by our algorithm’s phase P1. What we also have at hand so far is one particular\nwell-defined query for the identified q-partition P, namely the CQ of P. If we impose no further\nconstraints on the query than an optimal discrimination (as per the used QSM) among (leading)\ndiagnoses, which is solely determined by the query’s q-partition, then we are already done and\ncan simply output the CQ and ask the oracle to answer it. However, in many practical scenarios\nwe can expect that a least quality criterion apart from efficient diagnoses discrimination, i.e. the\nminimization of the number of queries, is the ⊆-minimality of queries. This means that we will\nusually want to minimize the number of sentences appearing in a query and hence the effort\ngiven for the oracle to walk through them and answer the query – while guaranteeing that the\noptimal discrimination properties (described by P) are not affected by this minimization. In\nother words, we consider the consultation of the oracle a very expensive “operation”, as it might\ninvolve human interaction and time, the use of high-cost instruments or the call of potentially\nexpensive procedures.\nHowever, exactly these latter factors might motivate a targeted selection of a query which is\nnot solely based on ⊆-minimality, but on additional query (answering) cost considerations. To\nenable the fulfillment of such advanced query quality criteria, we assume some QCM that our\nmethod allows the user to specify (see page 29). Hence, the problems we tackle now are\n1. how to obtain a ⊆-minimal query for the given optimal q-partition P returned by phase\nP1, and\n2. how to calculate a query that optimizes the QCM among all ⊆-minimal queries existent\nfor P.\nLet us first devote our attention to problem 1.\n47\n\n\fComputation of ⊆-Minimal Queries for a Fixed Q-Partition. At first sight, we might simply choose to employ the same approach that has been exploited in [Shchekotykhin et al., 2012,\nRodler et al., 2013, Rodler, 2015]. This approach involves the usage of a modification of the\nQ UICK X PLAIN algorithm due to [Junker, 2004] which implements a divide-and-conquer strategy with regular calls to a reasoning service.11 The output is one ⊆-minimal subset Q0 of a\ngiven query Q (in our case the CQ of P) such that the minimization preserves the q-partition,\ni.e. such that PD (Q0 ) = PD (Q). One concrete implementation of a suitable Q UICK X PLAINmodification for this purpose is the MIN Q algorithm presented and profoundly analyzed in\n[Rodler, 2015, Sec. 8.3 ff.]. Although the number of calls to a reasoner required by MIN Q\n|Q|\nis polynomial in O(|Q0 | log2 |Q\n0 | ), we will learn in this section that we can in fact do without\nany calls to a reasoner. This is due to the task constituting a search for a ⊆-minimal explicitentailments query Q0 ⊆ Q (because the CQ Q is an explicit-entailments query).\n(EE,P)\nLet QD\ndenote the subset of QD containing all explicit-entailments queries associated\n(EE,P)\nwith a the q-partition P. Subsequently, we analyze the shape of QD\n. The results will\nbe exploited to solve problems 1 and 2 stated above. More precisely, let us consider the lattice (2DiscD , ⊆) consisting of all subsets of DiscD (cf. Def. 13) which are partially ordered by\n⊆. Recall that by Prop. 10 we can w.l.o.g. restrict the focus on queries that are subsets of\nDiscD (because the inclusion of sentences from K \\ DiscD does not affect the q-partition of an\nexplicit-entailments query). We are now interested in the elements in the lattice (2DiscD , ⊆) that\n(EE,P)\nconstitute upper and, more importantly, lower bounds of the partially ordered set (QD\n, ⊆P )\nwhere ⊆P denotes the query-subset relation under preservation of the q-partition P. That is,\n(EE,P)\nQi ⊆P Qj holds for Qi , Qj ∈ QD\niff Qi ⊆ Qj and PD (Qi ) = PD (Qj ). Given such upper\n(EE,P)\nand lower bounds, we have a complete description of QD\n. The next proposition illuminates\nthis aspect. Let for this purpose MHS(X) denote the set of all minimal hitting sets of some\ncollection of sets X (cf. Def. 6).\nProposition 22. Let D ⊆ minDhK,B,P ,N iR and P = hD+ , D− , ∅i be a q-partition w.r.t. D.\nThen Q ⊆ DiscD is a query with q-partition P iff there is some H ∈ MHS(D− ) such that\nH ⊆ Q ⊆ Qcan (D+ ).\nThat is, the construction of a ⊆-minimal explicit-entailments query for a fixed q-partition\nrequires finding a minimal hitting set of all diagnoses in D− . As regards upper\n(EE,P)\nand lower bounds of QD\n, the conclusion is that there are generally multiple lower bounds\n(given by all these minimal hitting sets) and a unique upper bound (given exactly by the CQ for\n(EE,P)\n(EE,P)\nP). Therefore, (QD\n, ⊆P ) is a join-semilattice (every subset of QD\nhas a least upper\n(EE,P)\nbound or supremum), but not (necessarily) a meet-semilattice (not every subset of QD\nneeds\nto have a greatest lower bound or infimum). As a consequence of this, there is generally an\nexponential number (in |D− |) of ⊆-minimal queries for a fixed P – despite the restriction to just\nexplicit-entailments queries. And, the CQ for P is the explicit-entailments query of maximal\nsize (and thus the one containing the most information) for P. We will leverage this fact to\nproduce the most yielding query enhancement for P using the CQ of it in phase P3.\nhD+ , D− , ∅i\n\n11. A formal proof of Q UICK X PLAIN’s correctness, a detailed description of its use in diagnosis tasks and related\nexamples can be found in [Rodler, 2015, Sec. 4.4.1].\n\n48\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nHence, by Prop. 22, the computation of all ⊆-minimal reductions of the CQ for the qpartition P = hD+ , D− , ∅i under preservation of P is possible by using e.g. the classical\nHS-T REE [Reiter, 1987] (or some other hitting set algorithm mentioned in Sec. 2.4.3). Let\nthe complete hitting set tree produced by HS-T REE for D− be denoted by T . Then the set of all\n⊆-minimal queries with associated q-partition P is given by\n{H(n) | n is a node of T labeled by valid (X)}\nwhere H(n) denotes the set of edge labels on the path from the root node to the node n in T .\nWe want to make the reader explicitly aware of the fact that a critical source of complexity\nwhen constructing a hitting set tree is the computation of the node labels which might be very\nexpensive (cf. [Reiter, 1987, Chandrasekaran et al., 2011]), e.g. when calls to a reasoning service\nare required. For instance, if a propositional satisfiability checker is employed, each consistency\ncheck it performs is already NP-complete [Cook, 1971]. In our situation, however, all the sets\nused to label the nodes of the tree are already explicitly given. Hence the construction of the\nhitting set tree will usually be very efficient in the light of the fact that the number of diagnoses\nin D− is bounded above by the predefined fixed parameter |D| (which is normally relatively\nsmall, e.g. ≈ 10, cf. [Shchekotykhin et al., 2012, Rodler et al., 2013]). Apart from that, we\nare usually satisfied with a single ⊆-minimal query which implies that we could stop the tree\nconstruction immediately after having found the first node labeled by valid.\nAlthough this search is already very efficient, it can be even further accelerated. The key\n−\nobservation to this end is that each explicit-entailments query w.r.t. Pk = D+\nk , Dk , ∅ must\nnot include any axioms in UD+ , which follows from Prop. 22 and Lem. 7. This brings us back\nk\n\nto the concept of the trait\n\n(k)\nDi\n\n:= Di \\ UD+ (cf. Def. 17 and Eq. (20)) of a diagnosis Di ∈ D−\nk\nk\n\ngiven Pk . Let in the following Tr(Pk ) denote the set of all traits of diagnoses in D−\nk w.r.t. the\nq-partition Pk . As a consequence of Prop. 22, we can now state the following:\n−\nCorollary 5. Let D ⊆ minDhK,B,P ,N iR and Pk = hD+\nk , Dk , ∅i be a q-partition w.r.t. D. Then\nQ ⊆ DiscD is a ⊆-minimal query with q-partition Pk iff Q = H for some H ∈ MHS(Tr(Pk )).\n\nContrary to minimal diagnoses, traits of minimal diagnoses might be equal to or proper\nsubsets of one another (cf. Ex. 16 and 17). By [Reiter, 1987] (where a proof is given by [Rodler,\n2015, Prop. 12.6]), we have\nIf F is a collection of sets, and if S ∈ F and S 0 ∈ F such that S ⊂ S 0 , then\nFsub := F \\ {S 0 } has the same minimal hitting sets as F .\nThus we can replace Tr(Pk ) by Trmin (Pk ) in Cor. 5 where Trmin (Pk ) terms the set of all ⊆minimal traits of diagnoses in D−\nk w.r.t. Pk , i.e. all traits t in Tr(Pk ) for which there is no\ntrait t0 in Tr(Pk ) such that t0 ⊂ t. The possibility to solve problem 1 by means of hitting set\ncomputation brings us directly to the solution of problem 2.\nComputation of Optimal Queries for a Fixed Q-Partition. The insights gained in this section enable us to construct a ⊆-minimal query w.r.t. a given q-partition systematically. The idea\nis to use a uniform-cost variant of e.g. Reiter’s HS-T REE which enables the detection of minimized queries with particular properties (first). One instance of such an algorithm is the proven\n49\n\n\fsound and complete HS algorithm proposed by [Rodler, 2015, Alg. 2]. The desired query properties are specified in form of the QCM c. Whenever the function in a uniform-cost search that\nassigns costs to nodes nd in the search tree is a monotonic set function (with regard to the set\nof edge labels along the branch to nd), the search finds the goals in lowest-cost-first order (cf.\n[Russell and Norvig, 2010]). Given a set X, a function f : 2X → R is a monotonic set function\niff f (Y ) ≤ f (Z) whenever Y ⊆ Z for Y, Z ⊆ X. Hence, as a direct consequence of Cor. 5:\nProposition 23. A uniform-cost hitting set computation over the collection of sets Trmin (Pk )\nreturns explicit-entailments queries Q in best-first order w.r.t. their QCM value c(Q) given that\nc is a monotonic set function.\nNote that it is quite natural for a (query) cost measure to be a monotonic set function, as it\nis hard to imagine situations where the inclusion of additional measurements makes a query less\ncostly than before. In fact, all QCMs cΣ , cmax and c|·| discussed above (see page 29) satisfy\nthis monotonicity property. So, the usage of any of these guarantees the retrieval of the optimal\nexplicit-entailments query for a fixed q-partition P, e.g. the one with minimum cardinality (using\nc|·| ) or minimal cost (using cΣ ). When relying on Q UICK X PLAIN (or MIN Q, respectively) to\nminimize a query in a manner its q-partition is preserved (cf. [Rodler, 2015, Rodler et al., 2013,\nShchekotykhin et al., 2012]), one has less influence on the properties of the returned query.\nThis issue will be of interest in phase P3 of Alg. 2 (see Sec. 3.2.5) where we will discuss the\nminimization of arbitrary queries and state guarantees MIN Q can give in general under suitable\nmodifications of its input.\nLet us now exemplify the functioning of phase P2 of Alg. 2:\nExample 20 Let the considered DPI be again ExK (Tab. 3) and let the QP P21 from Ex. 19\nbe the output of phase P1 (function OPTIMIZE QPARTITION) and the input to phase P2 (function\nOPTIMIZE Q UERY F OR QPARTITION ) of Alg. 2, along with the QCM c := c|.| (see page 29). That\nis, the aim is to obtain the query Q∗ with minimal cost where the cost amounts to the number\nof sentences in Q∗ . Now, the set Trmin (P21 ) of all ⊆-minimal traits for P21 is {{3}, {5}, {6}}\n(cf. right column of last row of the double frame in Fig. 3). Since all traits are singletons,\nthey produce only one hitting set. Thence, there is a single (optimal) explicit-entailments query\n{3, 5, 6} for P21 which (in this case) coincides with the CQ for P21 .\nComplexity of P2. The problem of finding a minimum-cardinality hitting set is known to be\nNP-hard [Karp, 1972]. This can be interpreted as the computation of a minimum-cost hitting\nset using the cost function that assigns to each hitting set its cardinality. This cost function, in\nparticular, is a monotonic set function. Therefore, this problem can be reduced to the problem\nof finding a minimum-cost hitting set for costs assigned by any monotonic set function. As a\nconsequence, the latter problem is NP-hard as well. Hence, P2 addresses an NP-hard problem.\nThis theoretical result is discouraging at first sight. However, one can view the problem at a\nmore fine granular level in terms of parameterized complexity [Downey and Fellows, 2013]. In\nfact, the problem depends on two parameters d and b where d := |D| is the number of leading\ndiagnoses and b := max{|D| | D ∈ D} their maximal size. The former can be predefined or at\nleast bounded above by allowing an arbitrarily small upper bound d ≥ 2 (without harming the\nproper functioning of our approach, cf. Prop. 5.7). In fact, the number of sets that a set produced\n50\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nby P2 must hit is at most d − 1 as P2 is only called for a QP and QPs have non-empty D+ which\nis why |D− | ≤ |D| − 1 = d − 1. The latter parameter b is generally bounded by the number\nof minimal conflicts (i.e. independent sources of fault) for a given DPI (since D comprises only\nminimal diagnoses). For real-world DPIs, b is often relatively small and, in general, is not a\nfunction of the size of the DPI, i.e. the size of the KB (diagnosed system) K in particular, cf.\nTables 8 and 12 in [Shchekotykhin et al., 2012]. For instance, the chance that a large number\nof components fail simultaneously is usually small in physical systems [de Kleer and Williams,\n1987, Shakeri et al., 2000], as is the chance of a large number of independent faults in KBs\n(assuming regular validation steps are performed [Shchekotykhin et al., 2014]).\nDue to these arguments, it makes sense to analyze the problem addressed by P2 for the case\nwhere the parameters b and d are bounded. To this end, we define: A parameterized version of\na decision problem P is given by a tuple hx, ki where x is an instance of P and k is a (set of)\nparameter(s) associated with the instance x. A parameterized decision problem is called fixed\nparameter tractable (or: in FPT ) iff there is an algorithm A and a computable function f such\nthat, for all x, k, A decides hx, ki correctly and runs in time at most f (k)|x|O(1) [Downey and\nFellows, 2013]. Roughly, fixed parameter tractability means that a problem becomes tractable\ngiven that its parameter(s) are bounded above by an arbitrary number.\nThe size |x| of the hitting set problem instance x for phase P2 is in O(bd) (the size of the\ndescription of S, see Def. 6). The parameters are k = hb, di. Assuming a uniform-cost HST REE construction in P2, the computation time is in O(bd |x|) since b is the maximal branching\nfactor, d − 1 an upper bound of the maximal tree depth, and |x| the cost of verifying whether the\nlabels along a path already constitute a hitting set of all sets in S. Hence, f (k) = f (hb, di) = bd .\nOverall, we have shown the following:\nProposition 24. !\n1. Phase P2 solves an NP-hard problem.\n2. Assuming b ≤ b0 and d ≤ d0 for fixed b0 , d0 ∈ N, the problem solved by phase P2 is in\nFPT , i.e. fixed parameter tractable.12\n3. Phase P2 runs in O(bd bd) = O(dbd+1 ) time and requires O(bd + bd) space where d is\nspecifiable by the user and can be set to an arbitrary natural number larger than 1.\n3.2.4 S OLUTION P RODUCED BY P HASES 1 AND 2\nIn order to establish the merit of phases P1 and P2 regarding the formulated optimal measurement selection problem (Prob. 3), the next result shows that any explicit-entailments query necessarily has a CQP as its q-partition. That is, when searching for the an optimal CQP (phase P1)\nand, after such a CQP P is found, for an optimal explicit-entailments query for P (phase P2),\nthis amounts to exploring the entire space of explicit-entailments queries.\nProposition 25. Let DPI = hK, B, P , N iR be a DPI and D ⊆ minDDPI and Q ∈ QD where\nQ ⊆ K. Then the q-partition PD (Q) of Q is a canonical q-partition.\n12. The hitting set problem is already in FPT if only b is assumed fixed [Abu-Khzam, 2010]. In this case the\nproblem is called b-Hitting Set.\n\n51\n\n\fHence, the execution of phases P1 and P2 yields a solution to optimal measurement selection\nas per Prob. 3 with restricted search space S without a single inference engine call.\nTheorem 7. Phases P1 and P2 (using the threshold tm := 0) compute a solution Q∗ to Prob. 3\nwith the search space S := {X | X ∈ QD , X ⊆ K}.\nSo, the query Q∗ output by phase P2 is optimized along two dimensions (number of queries\nas per the QSM m and cost per query as per the QCM c) over the restricted search space S.\nThere are two ways to proceed after phase P2:\n(a) Q∗ can be directly proposed as the next query or\n(b) an optimized query over an extended search space can be computed in phase P3.\nConsidering case (a), an explicit-entailments query like Q∗ would correspond to a direct examination of one or more system components in a physical system (cf. Direct Probing in Ex. 9).\nExamples include the pinging of servers in a distributed system [Brodie et al., 2003], the test of\ngates using a voltmeter in circuits [de Kleer and Williams, 1987] or the inspection of potentially\nfaulty components of a car [Heckerman et al., 1995]. On the other hand, in knowledge-based\nsystem debugging Q∗ would mean e.g. to ask the stakeholders of a software, configuration or\nKB system [Wotawa, 2002, Felfernig et al., 2004a, Friedrich and Shchekotykhin, 2005] whether\nspecified code lines, constraints or logical sentences, respectively, are correct. In these examples, query costs can be motivated e.g. by the difficulty of inspecting a physical component or\nby the complexity of software code lines or logical sentences. We concentrate on case (b) in the\nnext section where we deal with phase P3.\n3.2.5 P HASE 3: Q UERY E XPANSION AND O PTIMIZED C ONTRACTION\nPhase P3 consists of two steps. The first one involves an expansion of the CQ obtained from\nphase P1, thereby extending the search space S in terms of Prob. 3. The second one encompasses\na minimization of the expanded query such that the resulting query is ⊆-minimal and to comprise\nonly “cost-preferred” elements, if such a query exists. We discuss both steps in turn next.\nStep 1: Query Expansion. We next describe the functioning of EXPAND Q UERY F OR QPARTI TION in Alg. 2. Here, the already optimal CQP P returned by P1 is regarded as an intermediate\nresult to building a solution query to Prob. 3 with full search space S = QA0D (of queries discriminating among all elements of D, cf. Def. 12). To this end, using the CQ Q of P, a (finite)\nset Qexp of sentences of preferred entailment types ET is computed.13 Intuitively, the goal is to\nadd Qexp to Q and achieve a larger pool of sentences from which an optimal minimized subset\ncan be generated in the second step of phase P3. Of course, we want the (optimal) QP P to be\nunaffected by the query extension, i.e. it should be the same for both Q and Q ∪ Qexp . The usage\nof the CQ Q as a basis for the expansion is well motivated since the CQ constitutes the most\ninformative of all explicit-entailments queries for P, as we have shown in Sec. 3.2.3. From Q’s\nextension Qexp = {α1 , . . . , αr } we postulate that\n13. ET might be specified so as to restrict the computed entailments to, e.g., simple atoms, implication sentences of\ntype A → B, or sentences formulated only over a selected sub-vocabulary of the KB (e.g. given a problematic\nmedical KB, a dermatologist might only be able to answer queries including dermatological terms, but none\nrelated to other medical disciplines).\n\n52\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\n1. α1 , . . . , αr ∈\n/ K ∪ B ∪ UP\n(each element of Qexp must be “new”, i.e. not an explicit entailment occurring in the\n(background) KB or the positive test cases)\n2. S |= {α1 , . . . , αr } where S is some solution KB S w.r.t. the given DPI hK, B, P , N iR\nsatisfying Q ⊆ S ⊆ K ∪ B ∪ UP\n(Qexp must be “sound”, i.e. be entailed by a fault-free KB S that subsumes the CQ Q)\n3. no αi for i ∈ {1, . . . , r} is an entailment of S \\ Q\n(each element of Qexp must “depend on” Q, i.e. Qexp must not comprise any “unnecessary” entailments)\n4. the syntactic type of each αi for i ∈ {1, . . . , r} is some type listed in ET\n(each element of Qexp must be of some “preferred” type)\n5. P = PD (Q) = PD (Q ∪ Qexp )\n(the extension must be QP-preserving)\nTo realize the computation of Qexp we assume a logical consequence operator EntET : 2L →\n2L which assigns a set of sentences EntET (X) over L to a set of sentences X over L such that\n(a)\n(b)\n(c)\n(d)\n\nX |= EntET (X) (logical soundness),\nEntET (X) contains only sentences of types listed in ET (type soundness),\nEntET (X 0 ) ⊆ EntET (X 00 ) whenever X 0 ⊂ X 00 (monotonicity), and\nfor Y ⊆ X 0 ⊂ X 00 and all eY where Y |= eY it holds that eY ∈ EntET (X 0 ) iff eY ∈\nEntET (X 00 ) (entailments generated for some set are generated for all its supersets).\n\nOne possibility to realize such a service is to employ a reasoner for the (decidable) logic L\nand use it to extract (the finite set of) all entailments of a predefined type it can compute (cf.\n[Rodler, 2015, Remark 2.3]). For Propositional Horn Logic, e.g. one might extract only all\nliterals that are entailments of a KB X. For general Propositional Logic, e.g. one might calculate\nall formulas of the form A B for propositional variables A, B and logical operators\n∈\n{→, ↔}, and for Description Logics [Baader et al., 2007], e.g. only all subsumption and/or\nclass assertion formulas that are entailments could be computed. An example of entailment types\nthat might be extracted for (decidable fragments of) First-Order Logic can be found in [Rodler,\n2015, Example 8.1]. For all these examples, DL [Baader et al., 2007] and OWL [Grau et al.,\n2008] reasoners, respectively, such as Pellet [Sirin et al., 2007], HermiT [Shearer et al., 2008],\nFaCT++ [Tsarkov and Horrocks, 2006] or KAON214 could be used with their classification and\nrealization reasoning services (cf. [Baader et al., 2007, Sec. 9.2.2]).\nNote, the operator EntET does not need to be complete, i.e. {e | X |= e, type(e) ∈ ET } ⊆\nEntET (X) does not necessarily hold. If it is complete, the last property (d) of EntET given\nabove is obsolete. The next proposition shows how an operator satisfying the said properties (a)\n– (d) can be leveraged to implement the postulated query expansion.\n14. See http://kaon2.semanticweb.org\n\n53\n\n\fProposition 26. Let D ⊆ minDhK,B,P ,N iR , Q ∈ QD with q-partition PD (Q) = hD+ , D− , ∅i\nsuch that Q ⊆ DiscD (in particular, the CQ for the seed D+ is such a query). Further, let\nEntET (X) be a logical consequence operator as described by (a) – (d) above. The Postulations\n1. – 4. above are satisfied if\nh\n\u0001\n\u0001i\nQexp = EntET (K \\ UD ) ∪ Q ∪ B ∪ UP \\ EntET (K \\ UD ) ∪ B ∪ UP\n\\ Q (24)\nThe result of expanding the CQ Q according to Prop. 26 is\nQ0 := Q ∪ Qexp\n\n(25)\n\nAs we show next, the expanded query Q0 has the same QP as Q.\nProposition 27. Let D ⊆ minDhK,B,P ,N iR and Q ∈ QD such that Q ⊆ DiscD . Further, let Q0\nbe defined as in Eq. (25). Then Postulation 5. holds, i.e. PD (Q0 ) = PD (Q).\nThe function EntET might e.g. be realized by a Description Logic reasoner (computing, for\ninstance, subsumption and realization entailments) for many decidable fragments of First-Order\nLogic (cf. [Baader et al., 2007]), by a forward chaining algorithm [Russell and Norvig, 2010] for\nHorn Logic or by a constraint propagator for CSPs [Dechter, 2003, de Kleer and Reiter, 1987,\nde Kleer and Williams, 1987].\nMore generally, given a sound and complete consistency checker CC (e.g. some resolutionbased procedure [Chang and Lee, 1973]) over (the decidable) knowledge representation formalism L underlying the given DPI, one can use the following implementation of the EntET calls\nin Eq. (24) to obtain a query expansion Qexp . Let r be the desired number of entailments in\nthe query expansion, s a desired maximal and t the absolute maximal number of consistency\nchecks to be used. Let us refer to the left and right EntET calls in Eq. (24) by Ent1 and Ent2 ,\nrespectively. Now, Ent1 can be realized as follows:\n1. i = 1 (iteration counter), A = ∅ (already tested sentences), E (computed entailments to\nbe tested by Ent2 ).\n2. Generate (randomly) a potentially entailed sentence αi ∈\n/ A of one of the postulated\nentailment types in ET which is not an element of (K \\ UD ) ∪ Q ∪ B ∪ UP .\n3. Run CC to prove (K \\ UD ) ∪ Q ∪ B ∪ UP ∪ {¬αi } inconsistent in a way that, whenever\npossible, sentences of Q are involved in the proof (if e.g. CC implements linear resolution,15 a way to realize this is to test sentences of Q always first for applicability as a side\nclause for the next resolution step). If inconsistent is returned and a proof involving at\nleast one sentence of Q was found, then add αi to E.\n4. If\n|E| ≥ r\n(r potential elements of Qexp have been generated) or\ni + |E| ≥ t\n(the computed number of required consistency checks exceeds t) or\ni + |E| ≥ s ∧ |E| ≥ 1 (the computed number of required consistency checks exceeds s and at least one potential element of Qexp has been\ngenerated)\n15. Note that linear resolution is complete for full First-Order Logic [Chang and Lee, 1973].\n\n54\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nthen terminate and pass E on to Ent2 .\n5. Add αi to A. i = i + 1.\nEnt2 , given the output E of Ent1 , can be realized as follows: Run CC to test the consistency\nof (K \\ UD ) ∪ B ∪ UP ∪ {¬αi } for each αi ∈ E. Add all αi ∈ E for which consistent is returned\nto Qexp and discard all others. Return Qexp .\nWe note that the implementation of the EntET calls in Eq. (24) as per and Ent1 and Ent2 is\ncompliant with all the Postulations 1. – 5. given above. Moreover, with any implementation of\nEntET , it might be the case that Qexp = ∅ (e.g. because there are in fact no implicit entailments\nof (K \\ UD ) ∪ Q ∪ B ∪ UP that are not entailed by (K \\ UD ) ∪ B ∪ UP ). In this case, as the\nexpanded query Q0 is just equal to the CQ Q (an explicit-entailments query), phase P2 is run\ninstead of Step 2 of phase P3 (for simplicity, this fact is not shown in Alg. 2). All the theoretical\nresults remain valid in case of empty Qexp .\nExample 21 As we have seen in Ex. 20, the optimized query Q∗ returned by phase P2 is\ngiven by {3, 5, 6} = {E → ¬M ∧ X, K → E, C → B} (cf. Tab. 3). However, suppose the\nuser is a domain expert with only rudimentary logical skills and wants to get presented a query\ncontaining only literals or simple implication sentences of the form X → Y for literals X, Y .\nIn this case, they would set enhance := true (see line 2 of Alg. 2), causing the algorithm to\nperform (the optional) phase P3. In Step 1 of this phase, applying an, e.g., Description Logic\nreasoner such as Pellet or HermiT [Sirin et al., 2007, Shearer et al., 2008] capable of handling\nthe logic L (in this case Propositional Logic) used in ExK, the result Q0 of the query expansion\nis {E → ¬M ∧ X, K → E, C → B, C → ¬M, E → X, K → ¬M, E → ¬M, B → ¬M }.\nNote, Q0 has the same QP as Q∗ by Prop. 27. Given Q0 , the idea is now to find an irreducible\nsubset of it which has the same QP, namely P21 , as Q0 (and Q∗ ) and includes only sentences (of\nthe types) preferred by the user. This is accomplished by Step 2, which we describe next.\nStep 2: Optimized Contraction of the Expanded Query. We next describe the functioning\nof OPTI M INIMIZE Q UERY F OR QPARTITION in Alg. 2. The objective of this function is the QPpreserving minimization of the expanded query Q0 returned by Step 1 to obtain a ⊆-minimal\nsubset Q∗ of Q0 . In general, there are multiple possible minimizations of Q0 . Given some\ninformation about (a user’s) preferences pref regarding elements in Q0 , the aim is to find some\npreferred query among all minimal ones. For instance, there might be a scenario where some\nelements of Q0 , the subset Q0+ , are favorable, and all other elements, i.e. Q0− := Q0 \\ Q0+ , are\nunfavorable. In other words, the desideratum is that Q∗ ⊆ Q0+ . For example, when diagnosing\na physical system, those measurements executable automatically by available built-in sensors\ncould be assigned to Q0+ and the more costly manual measurements to Q0− . Another strategy is\nto use the preferred entailments Qexp computed in Step 1 as Q0+ .\nMore generally, a user might be able to specify a strict (partial) preference order ≺ over Q0 ,\ne.g. by exploiting the (evaluation) costs ci of sentences qi ∈ Q0 (cf. Sec. 3.1) in a way that qi ≺ qj\niff ci < cj .16 Note, the partitioning of Q0 into favorable (Q0+ ) and non-favorable elements (Q0− )\nstated before corresponds to the special case where x ≺ y iff x ∈ Q0+ and y ∈ Q0− (i.e. the DAG\ncorresponding to this order is bipartite).\n16. We denote by x ≺ y that x is preferred to y.\n\n55\n\n\fGiven a strict partial order ≺ over Q0 , one might want to obtain the best query according to\nthis order ≺. The authors of [Junker, 2004] (and originally [Brewka, 1989]) define what the term\n“best” in such a context might refer to. They suggest to use an (anti-)lexicographic preference\norder over sets of interest (in our case: minimal subsets of Q0 ) based on some linearization17 of\n≺. Adhering to this suggested notion of “best” we define according to Def. 6 and 7 in [Junker,\n2004]:\nDefinition 18. Given a strict total order < on Q0 (e.g. a linearization of ≺), let the elements\nof Q0 be enumerated in increasing order q1 , . . . , qk (i.e. qi < qj implies i < j). Further, let\nX, Y ⊆ Q0 . Then X <antilex Y (in words: X is antilexicographically preferred to Y ) iff there is\nsome r such that qr ∈ Y \\ X and X ∩ {qr+1 , . . . , qk } = Y ∩ {qr+1 , . . . , qk }.\nIntuitively, X <antilex Y iff, when visiting the elements of Q0 starting from the most dispreferred ones qk , qk−1 , . . . , one first encounters only elements that are in both or none of X, Y ,\nbut the first element (qr ) that is in exactly one of the sets X, Y is in Y . Hence, excluding those\nmost dispreferred elements on which X, Y are equal, Y contains the most dispreferred element.\nExample 22 Suppose Q0 = {a, b, . . . , z} and < to be the standard lexicographic order on Q0 ,\ni.e. a < b, b < c, . . . . Then, e.g., X := {c, g, h, m, r, u, w} <antilex {c, g, h, n, r, u, w} =: Y\nbecause, deleting all most dispreferred elements {r, u, w} ∈ X ∩ Y , Y comprises the most\ndispreferred element n.\nDefinition 19. Let Q0 ∈ QD be a query with q-partition P and ≺ be a strict partial (preference)\norder over Q0 and let < be a linearization of ≺. A subset Q ⊆ Q0 is a preferred query iff\nP = PD (Q) and there is no Q̄ ⊆ Q0 such that P = PD (Q̄) and Q̄ <antilex Q.\nFor the purpose of finding a preferred query given Q0 with QP P and ≺, one can use a variant\nof the divide-and-conquer method Q UICK X PLAIN proposed in [Junker, 2004]. One appropriate\nsuch variant is the MIN Q procedure given in [Rodler, 2015, p. 111 ff.]. Roughly, it works\nas Q UICK X PLAIN, but calls a function IS QPART C ONST (see [Rodler, 2015, Alg. 4]), which\nreturns true iff the QP of its input is equal to P, instead of the ¬IS C ONSISTENT test in line 4 of\n[Junker, 2004, Alg. Q UICK X PLAIN]. That is, the verification whether a KB is still inconsistent\nin Q UICK X PLAIN is traded for a test whether the QP is still the same in MIN Q. The following\nproposition about MIN Q was proven in [Rodler, 2015, Prop. 8.7]:\nProposition 28. Let D ⊆ minDDPI and Q0 ∈ QD a query with q-partition P. Then, MIN Q,\ngiven Q0 , P and DPI as inputs, returns a ⊆-minimal query Q∗ ⊆ Q0 such that PD (Q∗ ) = P.\nGiven a sorted input, the output of MIN Q is characterized as the next proposition states. It is\na direct consequence of [Junker, 2004, Theorem 1] and Prop. 28.\n17. A partial order ≺0 over a set X is a linear extension (or: linearization) of a partial order ≺ over X iff ≺0 is a\ntotal order and x ≺0 y whenever x ≺ y. A linearization for a partial order ≺ over X can be found in linear time\nin O(|X| + n≺ ) where n≺ denotes the number of tuples x ≺ y in the partial order ≺ [Knuth, 1997, Sec. 2.2.3.].\n\n56\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nProposition 29. Let D ⊆ minDDPI , Q0 ∈ QD a query with q-partition P, ≺ a strict (partial)\norder over Q0 and Q0sort := [q1 , . . . , qk ] an ascending sorting of Q0 based on any linearization\n< of ≺. Then, MIN Q, given Q0sort , P and DPI as inputs, returns a preferred query Q∗ .\nLet us explicate the implications of Prop. 29. Let |Q∗ | = s. Studying Def. 18 carefully,\nwe see that Q∗ , among all ⊆-minimal subsets of Q0 with the same QP P as Q0 , is the one with\nthe leftmost rightmost element w.r.t. the sorting Q0sort . Moreover, among the (possibly multiple)\nsubsets of Q0 with this property, Q∗ is the one with the leftmost 2nd-rightmost element w.r.t. the\nsorting Q0sort , and so on for all lth-rightmost elements for l ∈ {1, . . . , s}. This insight leads to\nsome interesting corollaries, which we state after a small illustrating example:\nExample 23 Let Q0sort = [x1 , qb , qd1 , x2 , qa , x3 , qa,b , qc , x4 , qa,b,c , qd2 , x5 ] where the ⊆-minimal\nQP-preserving subsets of Q0 are Qa := {qa , qa,b , qa,b,c }, Qb := {qb , qa,b , qa,b,c }, Qc := {qc , qa,b,c }\nand Qd := {qd1 , qd2 } and the elements xi are irrelevant in that they do not occur in any of the\nsubsets Qi (i ∈ {a, . . . , d}) of interest. Then MIN Q, given Q0sort , returns Qb . The explanation\nis as follows: The leftmost rightmost element (regarding the used sorting of Q0 ) of any of the\nsets of interest is qa,b,c (note, qd2 is another rightmost element, namely of Qd , but lies more to\nthe right), i.e. Qd is definitely not the returned set. Fixing qa,b,c (rightmost element of the returned set), the leftmost 2nd-rightmost element contained in any of the remaining possible sets\n(Qa , Qb , Qc ) is qa,b , i.e. Qc is definitely not the result. Finally, the leftmost 3rd-rightmost element comprised by any of the remaining sets (Qa , Qb ) with common intersection {qa,b , qa,b,c }\nof largest elements (indices 7 to 12) in Q0sort is qb , which is why Qb <antilex Qa .\nThe first corollary testifies that the QCM cmax (see page 29) is optimized by MIN Q if costs\nof sentences in the query Q0 are available (cf. Sec. 3.1).\nCorollary 6. Let ci be the cost of qi ∈ Q0 and Q0sort = [q1 , . . . , qk ] be sorted in ascending order\nby cost, i.e. ci < cj implies that qi occurs before qj in Q0sort . Then, MIN Q, given the other inputs\nas stated in Prop. 29, returns a query that is optimal regarding the QCM cmax .\nGiven a partitioning of Q0 into favored and unfavored elements, MIN Q computes a query\nconsisting of only favored elements, if such a query exists.\nCorollary 7. Let Q0+ ⊆ Q0 be the preferred and Q0− = Q0 \\ Q0+ be the dispreferred elements\nof Q0 . Further, define Q0sort as the list resulting from the concatenation Q0+ kQ0− . Then, if such\na query Q∗ ⊆ Q0 exists, MIN Q, given the other inputs as stated in Prop. 29, returns a query\nQ∗ ⊆ Q0+ .\nIf, for example, preferences are only given over elements of Q0− (e.g. because one puts all\npreferred entailments Qexp (see Eq. (24)) computed in Step 1 into Q0+ and is indifferent between\nthem), then we can combine Cor. 6 and 7 to:\nCorollary 8. Let Q0+ , Q0− be as in Cor. 7, ≺ be a (partial) strict order over Q0− and Q0−,sort be a\nsorting of Q0− based on some linearization of ≺. Further, define Q0sort as the list resulting from\nthe concatenation Q0+ kQ0−,sort . Then, if such a query Q∗ ⊆ Q0 exists, MIN Q, given the other\ninputs as stated in Prop. 29, returns a query Q∗ ⊆ Q0+ . Otherwise, it returns a query that is\noptimal regarding the QCM cmax .\n57\n\n\fNote that (under the assumption of P 6= NP) it is not achievable by a single MIN Q-call to\nfind a minimum-cardinality query with the same QP as Q0 . One way to see this is by the fact\nthat MIN Q runs in polynomial time (modulo the time required for calls to IS QPART C ONST),\nas observed in [Rodler, 2015, Prop. 8.8], and by Prop. 24 which states that finding cardinalityminimal QP-preserving queries is already an NP-hard problem for explicit-entailments queries\nQ0 , a subclass of all queries in QD . Hence, assuming MIN Q to be a polynomial procedure for\nfinding QP-preserving subqueries of minimal size for arbitrary queries Q0 ∈ QD would imply\nin particular the existence of a polynomial procedure for the problem over the said subclass\nof queries because IS QPART C ONST can be reduced to set comparisons and therefore runs in\npolynomial time for explicit-entailments queries (see Prop. 9). Thus, we could in this case\nderive the equality P = NP.\nFurthermore, we point out that there might be multiple preferred queries since Def. 19 assumes an arbitrary linearization of the partial order ≺. However, if there are multiple preferred\nqueries, then all of them are incomparable w.r.t. ≺. That is, they stand in no necessary preference\nrelationship with each other in the sense of Def.18.\nExample 24 Let Q0sort = [a1 , b1 , b2 , a2 , c1 , c2 ] where {x1 , x2 } constitute all possible preferred\nqueries and x1 ≺ x2 are the only preferences given, for x ∈ {a, b, c}. In this case, MIN Q will\nreturn {b1 , b2 } since its rightmost element (b2 , index 3 in Q0sort ) is the leftmost of all rightmost\nelements x2 for x ∈ {a, b, c} (indices of other rightmost elements are 4 for a2 and 6 for c2 ). But,\n≺ admits e.g. also the sorting Q0sort = [c1 , c2 , a1 , b1 , b2 , a2 ] which would involve the output of\n{c1 , c2 }. Since no ci is comparable with any xi for x ∈ {a, b} and i ∈ {1, 2}, ≺ is indifferent\nbetween the sets {b1 , b2 } (result in the first case) and {c1 , c2 } (result in the second case). Obviously, there is also a sorting which favors {a1 , a2 }. If however ≺ includes additionally a2 ≺ c1 ,\nthen ≺ always prefers {a1 , a2 } to {c1 , c2 } and the only possible outcomes, depending on the\nused linearization of ≺, are {a1 , a2 } or {b1 , b2 }.\nLet us now reconsider our running example to see the results of applying Step 2 to the\nexpanded query computed in Ex. 21.\nExample 25 Recall from Ex. 20 that the final computed query, if possible, should contain only\nliterals or simple implication sentences of the form X → Y for literals X, Y . Therefore, the\nexpanded query Q0 (see Ex. 20) is to be partitioned into the preferred sentences Q0+ = {K →\nE, C → B, C → ¬M, E → X, K → ¬M, E → ¬M, B → ¬M } and dispreferred ones\nQ0− = {E → ¬M ∧ X}. Given the (ordered) list Q0sort := Q0+ kQ0− (see equations below, cf.\nCor. 7) as well as P := P21 (QP of Q0 , see Ex. 19) and the DPI DPI := ExK (see Tab. 3) as\ninputs, we roughly illustrate the functioning of MIN Q. At this, we assume that MIN Q splits the\nstill relevant sublist of Q0sort in half in each iteration (this yields the lowest worst case complexity,\ncf. [Junker, 2004]). Further, the single underlined sublist denotes the current input to the function\nIS QPART C ONST , the double underlined elements are those that are already fixed elements of the\nreturned solution Q∗ , and the grayed out elements those that are definitely not in the returned\nsolution Q∗ . Finally, × and X signify that the QP of the underlined subquery is different from\n58\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nor equal to P, respectively. Next, we show the algorithm’s actions on Q0sort :\n[K → E, C → B, C → ¬M, E → X, K → ¬M, E → ¬M, B → ¬M, E → ¬M ∧ X] X\n[K → E, C → B, C → ¬M, E → X, K → ¬M, E → ¬M, B → ¬M, E → ¬M ∧ X] ×\n[K → E, C → B, C → ¬M , E → X, K → ¬M, E → ¬M, B → ¬M, E → ¬M ∧ X] ×\n[K → E, C → B, C → ¬M, E → X, K → ¬M, E → ¬M, B → ¬M, E → ¬M ∧ X] ×\n[K → E, C → B, C → ¬M, E → X, K → ¬M, E → ¬M, B → ¬M, E → ¬M ∧ X] X\nFor instance, in the first line, IS QPART C ONST returns true (see X) since the (underlined)\nleft half Q0sort [1..4] is still a query with the same QP (i.e. P21 ) as Q0 . Thence, the right half\nof elements can be dismissed (one solution is guaranteed to be in the left half). The latter is again split in half and the left part Q0sort [1..2] := [K → E, C → B] is tested by\nIS QPART C ONST , which returns negatively (line 2). The reason is that PD (Q0sort [1..2]) =\nh{D1 , D4 , D5 , D6 } , {D2 , D3 } , ∅i =\n6 h{D4 , D5 } , {D1 , D2 , D3 , D6 } , ∅i = P21 . Thus, a half of\nthe right part is added to the left part, yielding Q0sort [1..3] (see underlined elements in line 3), and\nagain tested. Once more it is found that PD (Q0sort [1..3]) = h{D4 , D5 } , {D1 , D2 , D3 } , {D6 }i =\n6\nP21 . Note, due to the positive IS QPART C ONST check in line 1, it is now clear that E → X (see\ndouble underline in line 4) must be in the solution Q∗ . From now on, E → X is part of\nany input to IS QPART C ONST argument. Since Q0sort [1..2] (along with E → X) has the QP\nh{D4 , D5 } , {D2 , D3 , D6 } , {D1 }i (see line 4), it is now a fact that C → ¬M must as well be an\nelement of Q∗ . Eventually, the (positive) IS QPART C ONST test for Q0sort [3..4] (see line 5) proves\nthat the latter must be a ⊆-minimal subquery Q∗ of Q0 with QP P21 . Lastly, Q∗ is returned.\nWe observe that, Q∗ ⊆ Q0+ holds, as required. That is, the returned query contains only\npreferred sentences.\nComplexity of P3. Step 1 requires exactly 2 calls of the function EntET , if there is a reasoner implementing such a function directly (see page 54). Alternatively, using a consistency\nchecker CC to realize EntET (see page 54), the latter requires maximally a constant number t\nof consistency checks. The complexity of EntET (and of consistency checks) depends on the\nexpressivity of the underlying knowledge representation formalism. Hence:\nProposition 30. Step 1 of P3 runs in O(1) time (modulo reasoning time).\nStep 2, as was shown by [Rodler, 2015] (for MIN Q) and originally by [Junker, 2004] (for\nQ UICK X PLAIN), requires a polynomial number of calls to IS QPART C ONST:\nProposition 31. MIN Q runs in O(|Q∗ | log2\nC ONST).\n\n|Q0 |\n|Q∗ | )\n\ntime (modulo the time required for IS QPART-\n\nIn order to further refine this result, let Q0sub ⊆ Q0 be any subquery of Q0 . Then IS QPARTC ONST, given the argument Q0sub , verifies the preserved membership of each D ∈ D in its\nrespective part of the QP, i.e. whether D ∈ DZ (Q0 ) =⇒ D ∈ DZ (Q0sub ) for Z ∈ {+, −, 0}.\nWe note that each D ∈ D+ (Q0 ) is also an element of D+ (Q0sub ) by Prop. 4. Hence, the membership verification is only necessary for the diagnoses in D− (Q0 ) ∪ D0 (Q0 ). Moreover, by logical\nmonotonicity and Prop. 4, each diagnosis in D− (Q0 ), if not in D− (Q0sub ), can be in D0 (Q0sub ) or\n59\n\n\fD+ (Q0sub ), but each diagnosis in D0 (Q0 ), if not in D0 (Q0sub ), can only be in D+ (Q0sub ). Therefore, as witnessed by [Rodler, 2015, Lem. 8.1], for each Dr ∈ D− (Q0 ), one needs to verify\nthat Dr ∈ D− (Q0sub ), i.e. that some x ∈ R ∪ N is violated by Kr∗ ∪ Q0sub . The latter operation\nrequires a maximum of |R| + |N | logical consistency checks (where |R| is predefined and constant, i.e. in O(1), whereas |N | might grow during a diagnostic session, cf. Def. 8). Also due\nto [Rodler, 2015, Lem. 8.1], for each Dr ∈ D0 (Q0 ), one needs to verify that Dr ∈\n/ D+ (Q0sub ).\nThis operation can involve at most |Q0sub | ≤ |Q0 | logical consistency checks (to verify whether\neach sentence in Q0sub is entailed by Kr∗ ). Importantly, if one of all these verification steps fails,\ni.e. if any diagnosis Dr ∈ D− (Q0 ) ∪ D0 (Q0 ) has a different position in the QP of Q0sub than\nin the QP of Q0 , then IS QPART C ONST immediately terminates (negatively), cf. [Rodler, 2015,\nAlg. 4]. Overall, we found that IS QPART C ONST runs in O(m |D|) time (modulo consistency\nchecking) where m := max{|N |, |Q0 |}. The complexity of a single consistency check depends\non the expressivity of the underlying knowledge representation formalism L.\nHence, we recognize that Step 2 of P3 runs in polynomial time (disregarding the complexity\nof consistency checking):\nProposition 32. Let q := max{m, |D|, |Q0 |}. Then Step 2 of P3 runs in O(q 4 ) time (modulo\nthe time required for consistency checking).\nProof. By Prop. 31 and the argumentation given, Step 2 of P3 runs in O(m |D| |Q∗ | log2\ntime (modulo the time required for consistency checking). Further, |Q∗ | log2\n|Q∗ | ≤ |Q0 | ≤ q and log2\nq that m |D| ∈ O(q 2 ).\n\n|Q0 |\n|Q∗ |\n\n|Q0 |\n|Q∗ |\n\n|Q0 |\n|Q∗ | )\n\n∈ O(q 2 ) since\n\n≤ log2 |Q0 | ≤ |Q0 | ≤ q. Finally, it follows from the definition of\n\n3.2.6 S OLUTION P RODUCED BY P HASE 3\nAltogether, phase P3, i.e. query expansion (Step 1) along with optimized query contraction\n(Step 2), using the QP returned by phase P1, achieves the following:\nTheorem 8. Let Conjecture 1 hold and the QCM be cmax . Then P1 and P3 (using the threshold\ntm := 0) solve Prob. 3 with full search space S = QA0D (of queries discriminating among all\nelements of D, cf. Def. 12). Moreover, for any predefined set of preferred (query) sentences, the\nreturned solution will contain only preferred elements, if such a solution exists.\nRemark 8 We again stress that Conjecture 1 is by no means necessary for the proper functioning of our presented algorithms. Please see our more detailed discussion on this on page 44,\nafter we stated Conjecture 1.\n3.2.7 R ECAPITULATION OF THE P RESENTED Q UERY S ELECTION A LGORITHM\nTo wrap up Sec. 3, let us exemplify the entire query selection process executed by Alg. 2 using\nthe MBD example stated by Fig. 2 and Tab. 2:\nExample 26 Suppose we got the information from the manufacturer of the gates that and-, orand xor-gates fail with a probability of 0.05, 0.02 and 0.01, respectively. As we have already\n60\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\ndiscussed (cf. Ex. 8), the set of minimal diagnoses for ExM2K (see Tab. 2) is minDExM2K =\n{D1 , D2 , D3 } = {{α1 }, {α2 , α4 }, {α2 , α5 }} corresponding to the (abnormality assumptions\nof the) sets of components {{X1 }, {X2 , A2 }, {X2 , O1 }}. Let the leading diagnoses be D :=\nminDExM2K . Exploiting the formula given in [de Kleer and Williams, 1987, Sec. 4.4], the\ndiagnoses probabilities (normalized over D and rounded) amount to hp(D1 ), p(D2 ), p(D3 )i =\nh0.93, 0.05, 0.02i.\n(Phase P1:) Starting from the initial partition h∅, D, ∅i, the generated successors are P1 :=\nh{D1 } , {D2 , D3 } , ∅i, P2 := h{D2 } , {D1 , D3 } , ∅i and P3 := h{D3 } , {D1 , D2 } , ∅i. Note that\nall these successors are QPs (proven by Prop. 16). Assuming the same QSM m, threshold tm ,\nheuristic h and pruning function as used in Ex. 19, the heuristic values hh(P1 ), h(P2 ), h(P3 )i\nof these QPs are h0.43, 0.45, 0.48i. Since P1 has the best (i.e. least) h-value, but is not a\ngoal, P1 continues with the expansion of P1 after storing P1 as the currently best visited\nQP so far. However, since p(D+ (P1 )) = 0.93 > 0.5, the pruning criterion is met and\nno successors are generated. Instead, the next best sibling of P1 , namely P2 is considered.\nHere, no pruning takes n\nplace and the\no successors generated based on the ⊆-minimal traits (cf.\n(2)\n(2)\nDef. 17) Trmin (P2 ) = D1 , D3\n= {{α1 } , {α5 }} are P21 := h{D2 , D1 } , {D3 } , ∅i and\nP22 := h{D2 , D3 } , {D1 } , ∅i with h(P21 ) = 0.48 and h(P22 ) = 0.43. Due to the facts that for\nP21 the pruning condition is satisfied, P22 has no successor QPs (cf. Cor. 3), and none of P21 ,\nP22 is a goal, P1 backtracks and proceeds with the QP P3 . In an analogue way as shown for P2 ,\nthe successor QP P31 = h{D3 , D1 } , {D2 } , ∅i is generated. Note that P1, in that it stores diagnoses that must not be moved from D− to D+ to avoid duplicates (for details see the extended\nversion of the paper [Rodler, 2016, p. 92 ff.]), does not generate P32 = h{D3 , D2 } , {D1 } , ∅i\nbecause it is equal to P22 which has already been explored. Again, no successors are generated\nfor P31 (pruning). Hence, the complete (pruned) backtracking search tree has been constructed\nand the stored best (of all) CQP(s) for D, P1 , is returned.\n(Phase P2:) Let us suppose that a globally optimal query w.r.t. the QCM cΣ (see page 29)\nover the restricted search space considered by P2 (see Theorem 6) is desired by the user (accounted for by setting enhance := false, see Alg. 2). Moreover, let the expected\nn cost of testing\no\n(1)\n(1)\nan and-, or- and xor-gate, respectively, be 1, 3 and 2. Then Trmin (P1 ) = D2 , D3\n=\n∗\n{{α2 , α4 } , {α2 , α5 }}is used to extract the cΣ -optimal query Q = {α2 } = {beh(X2 )} =\n{out(X2 ) = xor(in1(X2 ), in2(X2 ))} as the minimal hitting set with least cost (cΣ (Q∗ ) = 2)\nof all elements of Trmin (P1 ) (cf. Prop. 23). Note, the (only) other possible ⊆-minimal explicitentailments query for P1 is Q := {α4 , α5 } with a cost of cΣ (Q) = 1 + 3 = 4. Q∗ is a direct\ncomponent probe (cf. Ex. 9 and [Brodie et al., 2003]) and can be understood as the question\n“Does gate X2 work properly?”.\n(Phase P3:) Given that a query optimized over the full search space is wanted, enhance\nmust be set to true in Alg. 2. This causes the execution of phase P3 (instead of phase P2). As\nan input Inf to Alg. 2 we assume e.g. some constraint propagator, similar to the one described\nin [de Kleer and Williams, 1987], which computes predictions of the values at the circuit’s wires\n(cf. Fig. 2). Moreover, we suppose that the preferred entailment types ET are exactly those\nstating values of wires, e.g. out(A1 ) = 1.\n61\n\n\fIn P3, the CQ of P1 , given by Q := UD \\UD+ (P1 ) = {α1 , α2 , α4 , α5 }\\{α1 } = {α2 , α4 , α5 }\n(cf. Lem. 7), is first needed for the query enhancement (Step 1). To this end, the query expansion, Qexp , is computed as per Eq. (24) as [EntET ({α3 } ∪ {α2 , α4 , α5 } ∪ {α6 , . . . , α17 } ∪ ∅) \\\nEntET ({α3 }∪{α6 , . . . , α17 }∪∅)]\\{α2 , α4 , α5 } = [EntET ({beh(A1 )}∪{beh(X2 ), beh(A2 ),\nbeh(O1 )}∪ SDgen ∪ OBS)\\EntET ({beh(A1 )}∪ SDgen ∪ OBS)]\\{beh(X2 ), beh(A2 ), beh(O1 )} =\n[{out(X1 ) = 0, out(A2 ) = 0, out(A1 ) = 0}\\{out(A1 ) = 0}]\\{beh(X2 ), beh(A2 ), beh(O1 )} =\n{out(X1 ) = 0, out(A2 ) = 0}. Next, the contraction of the expanded query Q0 = Q ∪ Qexp =\n{beh(X2 ), beh(A2 ), beh(O1 ), out(X1 ) = 0, out(A2 ) = 0} (see Eq. (25)) takes place (Step 2).\nLet us assume that no preference order over query sentences is given, except that a user wants\nto avoid direct component tests (input argument pref , see Alg. 2). In other words, the query\nshould not include any beh(.) sentences. This is reflected by setting Q0+ := Qexp and by specifying the input to MIN Q as the (ordered) list Q0sort = Q0+ kQ0− = [out(X1 ) = 0, out(A2 ) =\n0, beh(X2 ), beh(A2 ), beh(O1 )] (cf. Cor. 7). In an analogous manner as illustrated in Ex. 25,\nMIN Q determines an optimized contracted query Q∗ as {out(X1 ) = 0}. We note that this is\nthe only ⊆-minimal query satisfying Cor. 7 because the only other ⊆-minimal query comprising\nonly elements from Q0+ is Qalt := {out(A2 ) = 0} which has not the QP P1 , i.e. is not QPpreserving. The actual QP PD (Qalt ) of Qalt is h{D1 , D2 } , {D3 } , ∅i. Hence, Alg. 2 suggests\nto probe at the wire connecting gate X1 with gates X2 and A2 . Taking into account the query\noutcome probabilities estimated from the given component fault probabilities, we see that there\nis a strong bias (probability 0.93, cf. Eq. (13)) towards a measurement outcome of out(X1 ) = 0.\nIn this case, as we have shown in Ex. 1, only a single measurement is needed to single out D1 as\nthe actual diagnosis, i.e. to come to the conclusion that X1 must be faulty.\n\n4. Evaluation\n4.1 The Experiments\nThe Used Dataset. To evaluate the presented algorithm, we used real-world inconsistent knowledge-based (KB) systems, i.e. KBD-DPIs. The reasons for this are as follows:\n1. As shown in Sec. 2.3, any MBD problem (i.e. an MBD-DPI as per Def. 2) can be reduced\nto and hence viewed as a KBD problem (i.e. a KBD-DPI).\n2. The type of the system underlying a DPI is irrelevant to our methods, only the DPI size\n(number of logical sentences), the DPI structure (size, # or probability of diagnoses),\nand – for the optional phase P3 – the DPI (reasoning) complexity (expressivity of the\nunderlying logic L) are critical.\n3. KB systems pose a hard challenge for query selection methods due to the implicit nature\nand the generally infinite number of the possible queries.18 That is, the possible queries\nare not explicitly given, but must be derived by inference. For instance, in a digital circuit,\nall probing locations are given by all of the circuit’s wires, which are known from the\nbeginning. In the case of, e.g., a medical KB, however, the set of all possible sentences\n(common entailments of sub-KBs, cf. Prop. 5.4) that might occur in questions to a medical\n18. Note that (in most logics) each sentence, i.e. element of a query, can be rewritten in infinitely many ways, each\ntime resulting in a semantically equivalent, but syntactically different sentence (cf. the argumentation in Rem. 2).\n\n62\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\na\nb\nc\nd\ne\n\nKB K\n\n|K|\n\nExpressivity a\n\n#D/min/max b\n\nUniversity (U) c\nMiniTambis (M) c\nCMT-Conftool (CC) d\nConftool-EKAW (CE) d\nTransportation (T) c\nEconomy (E) c\nOpengalen-no-propchains (O) e\nCton (C) e\n\n49\n173\n458\n491\n1300\n1781\n9664\n33203\n\nSOIN (D)\nALCN\nSIN (D)\nSHIN (D)\nALCH(D)\nALCH(D)\nALEHIF (D)\nSHF\n\n90/3/4\n48/3/3\n934/2/16\n953/3/10\n1782/6/9\n864/4/8\n110/2/6\n15/1/5\n\nDescription Logic expressivity, cf. [Baader et al., 2007, p. 525 ff.].\n#D, min, max denote the number, the minimal and the maximal size of minimal diagnoses (computable in ≤ 8 h).\nSufficiently complex systems (#D ≥ 40) used in [Shchekotykhin et al., 2012].\nHardest diagnosis problems mentioned in [Stuckenschmidt, 2008].\nHardest diagnosis problems tested in [Shchekotykhin et al., 2012].\n\nTable 6: KBs used in the experiments.\nexpert are not known in advance. As a consequence, in KBD-DPIs the considered query\nsearch space is not explicit and infinite.\nTab. 6 (column 1) shows the dataset of KBs K used in our tests. Each K constitutes an\ninconsistent and/or incoherent OWL ontology (i.e. a KB formulated over some Description\nLogic L). From each KB K we constructed a DPI as DPI := hK, ∅, ∅, ∅iR where R :=\n{consistency, coherency}, i.e. the entries corresponding to the sets B, P and N (cf. Def. 8)\nwere defined as empty sets. Accounting for the aspects given under bullet 2. that (potentially)\naffect the performance of our method, the table also shows for each constructed DPI its size in\nterms of |K| (column 2), its structure in terms of the (within 8 hours computable) number of\nminimal diagnoses #D (which is less or equal to |minDDPI |) as well as the minimal (min) and\nmaximal (max) size of a minimal diagnosis (computable within 8 hours) w.r.t. DPI (column 4),\nand the reasoning complexity in terms of the expressivity of the Description Logic underlying\nDPI (column 3).\nExperimental Settings (EXP1 – Comprehensive Evaluation of the New Method). In our\nexperiments, for each DPI and each n ∈ {10, 20, . . . , 80}, we randomly generated 5 different D ∈ minDDPI with |D| = n by using I NV-HS-T REE [Shchekotykhin et al., 2014] with\nrandomly shuffled input each of the 5 times. Each D ∈ D was assigned a uniformly random\nprobability and probabilities were normalized over D. For each of these 5 D-sets, we used\n(a) entropy (ENT) [de Kleer and Williams, 1987] and (b) split-in-half (SPL) [Shchekotykhin\net al., 2012] as QSM m and c|·| (cf. page 29) as QCM c, and then ran phases P1, P2 and P3\nto compute a query as per Theorem 7 (obtained from the execution of phases P1 and P2) and\nTheorem 8 (obtained from the execution of phases P1 and P3), respectively. We specified the\noptimality threshold tm as 0.01 (cf. Ex. 19) for m = ENT and as 0 for m = SPL. The setting\nfor ENT to a value higher than zero arises from the observation that there is practically never\na QP for which p(D+ ) and p(D− ) both have a probability of exactly 0.5. Note that the value\nof 0.01 we used is one order of magnitude smaller than the one used in other experiments, e.g.\n[Shchekotykhin et al., 2012], and thence the QSM properties postulated for an optimal query are\n63\n\n\fstricter and the search problem is harder. For SPL, on the other hand, it is reasonable to require\nthe returned query to exhibit an optimal split, i.e. half of the leading diagnoses in D+ and the\nother half in D− , because such QPs are usually frequent (in case |D| is an even number).\nFor the search in P1 we employed the simple heuristic h which assigns h(P) = |p(D+ ) −\n0.5| to a QP P := D+ , D− , D0 (cf. Ex. 19). Similarly, we used a function h where h(P) =\n|D+ | − 12 |D| as a heuristic for SPL. As regards pruning in P1, we stopped the generation of\nsuccessors at P if p(D+ ) ≥ 0.5 for ENT, and if |D+ | ≥ 12 |D| for SPL.\nIn P3 we defined the preferred entailment types ET to be the results of running classification\nand realization reasoning services [Baader et al., 2007]. In First-Order Logic terms, this means\nthat ET restricted the computed entailments to simple definite clauses of the form ∀X(a(X) →\nb(X)) and facts of the form a(c) where a, b are unary predicates and c is a constant. As a\nDescription Logic reasoner (input Inf to Alg. 2) we employed HermiT [Shearer et al., 2008].\nFinally, the preferences pref exploited during the second step of phase P3 were set in a way\nthat Q0+ := Qexp , i.e. all the (simple) sentences Qexp output by the reasoner were considered\ncost-preferred (cf. Ex. 26).\nExperimental Settings (EXP2 – Scalability Tests). In these experiments we used n = 500 as\na very test of the new approaches’ scalability. Since there are fewer than 500 minimal diagnoses\nfor the DPIs U, M, O and C (see last column of Tab. 6), the dataset for these experiments\nconsisted of the DPIs CC, CE, T and E. For each of these DPIs, we performed one run with\nrandomly generated leading diagnoses D, as described above. All other settings were equal to\nthose in EXP1 explained above.\nExperimental Settings (EXP3 – Comparison with a Method not Using the Proposed Theory). To quantify the impact of the new theoretical notions (CQs, CQPs, traits) exploited by\nAlg. 2 in order to drastically reduce reasoning activity during query computation, we compared\nAlg. 2 with a method that is as generally applicable (in terms of logics and reasoner independence, handling of implicit query spaces, cf. Sec. 1), but does not use these notions. A generic\nsuch algorithm is described, e.g., in [Shchekotykhin et al., 2012, Alg. 2]. To give this algorithm\na name and to clearly distinguish it from the newly proposed method (NEW), we call it OLD in\nSec. 4.2.\nIn a nutshell, this algorithm, starting from the set of leading diagnoses D, enumerates all\nsubsets D+ of D in the form of a recursive binary tree. At each leaf node, corresponding to\none D+ ⊂ D, a query is created. The latter is accomplished by calling a reasoner to compute\na set of common entailments X of all diagnoses in D+ (cf. Prop. 5.4). In case this set X is\nnon-empty, the diagnoses in D \\ D+ are assigned to their respective set (i.e. D+ (X), D− (X)\nor D0 (X)) according to Prop. 4 by means of a reasoner. We call the tests whether X 6= ∅ (query\nis non-empty) and whether D+ (X) 6= ∅, D− (X) 6= ∅ (X’s partition is a QP) query verification\n(cf. Def. 12). As the recursion unwinds, at each inner node of the tree, the better one among the\nbest query found in the left and the best query found in the right subtree is returned, where query\ngoodness is measured as per some QSM. The final query returned at the root node is minimized\nusing Q UICK X PLAIN (cf. Sec. 3.2.5).\nAs suggested by preliminary tests using OLD, which could not handle any more than 20\nleading diagnoses for any of the DPIs in Tab. 6, we used n ∈ {5, 10, 15, 20} in the comparison\n64\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nexperiments between NEW and OLD. We ran 5 query computation iterations for both NEW and\nOLD per (DPI,|D|) combination (cf. EXP1). In each iteration, both NEW and OLD were applied\nto exactly the same leading diagnoses sets D and diagnoses probabilities. Further, the reasoner\n(HermiT) and the computed entailment types ET used by both methods were the same. For\nNEW, all other settings remained the same as in EXP1 (see above). Only phase P1 was modified\nin a way a brute force search over all QPs was performed (no early termination by means of\nany threshold, no heuristics, no pruning) to achieve best comparability with OLD as regards\nperformance and search completeness.\nExperiment Conditions.\nWindows 7 64-bit OS.\n\nAll tests were run on a Core i7 with 3.4 GHz, 16 GB RAM and\n\n4.2 Experimental Results\nWe subdivide the presentation of the experimental results19 into discussions of various observed\naspects of the algorithms, e.g. times, reasoner calls or search space sizes. Each such set of related\naspects is illustrated by a distinct figure (named in the heading of the respective paragraph).\nWhenever we will refer to a figure, we will mean exactly the figure mentioned in the heading. If\nsome figure includes a secondary y-axis, which means a y-axis on the right side, then all aspects\nplotted with respect to the secondary axis are given in italic font (whereas those plotted based on\nthe primary, i.e. left, y-axis are written in normal font) in the figure’s key. On the x-axis, all the\nplots show the 8 (or fewer) different categories (M, U, T, E, C, O, CE, CC), one for each K in\nTab. 6. Every plotted point shows the respective aspect, as indicated by the figure’s key, in terms\nof a 5-iteration average value. That is, for each plotted point, DPI (i.e. the DPI for K) and n is\nfixed, whereas D varies over the 5 iterations (see the description of EXP1 in Sec. 4.1). Note that\nthe range of n is smaller for the categories M and C because there are no 80 minimal diagnoses\nfor these two K’s (48 for M, 15 for C, cf. Tab. 6). Further, for clarity and better visibility the\nplots only show the values for the (more costly to compute) QSM ENT. The values observed for\nthe QSM SPL were always comparable or better than for ENT. The unit of times is seconds in\nall figures. Figures 4 – 11 address EXP1, Fig. 12 EXP2 and Fig. 13 EXP3.\nDiagnoses vs. Query Computation. (Fig. 4) For both diagnoses and queries, the decisive\nfactor influencing the computation time is the number of required inference engine calls. This\nconnection can be clearly observed in the figure where the light and dark bars show the number\nof the reasoner calls for diagnoses and query computation, respectively, and the continuous and\ndashed lines display the respective computation times. Note that the shown query computation\ntime (dashed line) is the sum of the times for all phases P1, P2 and P3, i.e. constitutes an upper\nbound of both default (i.e. phases P1+P2) and optional (i.e. phases P1+P3) mode of Alg. 2.\nAlgorithms that incorporate reasoners more strongly into query computation often have to\nlimit the number of leading diagnoses to rather small numbers, e.g. 9 [Shchekotykhin et al.,\n2012]. This is necessary to keep query calculation practical because the worst case size of the\nQP search space is 2|D| , not to mention the size of the query search space which is generally\n19. The source code implementing the experiments as well as the obtained results can be accessed on\nhttp://isbi.aau.at/ontodebug/evaluation.\n\n65\n\n\f100\n10\n1\n0.1\n0.01\n0.001\n0.0001\n| |\n|D|\nM\n\n|\n|\n|CQP_D|\nU\n\nENT: time P1+P2\nT\n\nE\n\nENT: time P3\nC\n\nO\n\nBF: time P1+P2\nCE\n\nCC\n\n10,000,000\n\n1000\n\n1,000,000\n100\n100,000\n10\n\n10,000\n1,000\n\n1\n\n100\n0.1\n10\n1\n\n0.01\n| |\n|D|\n\nD: # reasoner calls\n\nQ: # reasoner calls ENT\n\nD: time\n\nQ: time ENT\n\nFigure 4: Diagnoses computation vs. query computation. D means diagnosis computation and Q means\nquery computation. The QSM m = ENT was used with the threshold tm = 0.01.\n\nagain a multiple of it. For the new method, as the figure reveals, the growth of query computation\ntime is very moderate for increasing numbers of leading diagnoses. In fact, we can state it is at\nmost linear, as the growth of the dashed line is at most parallel to the growth of the shaded area\n(note the logarithmic y-axes). Sometimes the time even sinks after raising |D|, e.g. for the cases\n|D| ∈ {70, 80} for U, T and CC. In spite of its slight tendency to increase, the query computation\ntime, by absolute numbers, is always below 3.6 sec and, except for the cases involving CE with\n|D| ≥ 30, always lower than 1 sec. That is: Even for high numbers of up to 80 leading diagnoses\n(QP search space size in O(280 )), optimized queries (as per Theorems 7 and 8) are computed\nwithin almost negligible time.\nThis is due to the main merit of the new algorithm, which is the avoidance (in default mode)\nor minimization (in optional mode) of reasoner calls. Essentially, the slight tendency of the new\nalgorithm’s computation time to increase for larger diagnoses sets can be primarily attributed to\nincreased costs of step 2 in phase P3, and secondarily to the substantially larger QP search space\nexplored by phase P1 (see also Figures 5, 8 and 11 for an illustration of this fact). On the other\nhand, the reasoning costs of step 1 in phase P3 tend to fall as a response to increasing |D| since\nthe sizes of the arguments to the two EntET calls in Eq. (24) tend to decrease given a higher\n|D|. Second, despite an increased effort faced by phase P2 for growing |D|, the absolute times\nrequired by P2 are so small (between about 10−5 and 10−3 sec) that they hardly carry weight\n(see also Fig. 11).\nThe extension of the QP search space has not such a high impact due to the used heuristic\nfunctions that proved to guide the algorithm rather quickly towards a goal QP and due to the\nused tree pruning which avoided the exploration of hopeless subtrees. The higher costs of step\n2 in phase P3 can be explained as follows: Whereas the number of IS QPART C ONST calls is\ndictated by |Q0 | which does not (directly) depend on |D|, the number of reasoner calls within\neach call of IS QPART C ONST does depend (linearly) on |D| (see Prop. 32).\n66\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nM\n\nU\n\nT\n\nE\n\nC\n\nO\n\nCE\n\nCC\n100%\n\n100\n\n90%\n80%\n70%\n60%\n50%\n\n10\n\n40%\n30%\n20%\n10%\n1\n\n0%\ntime P1\nM\n\ntime P2\n\nU\n\nT\n\ntime P3 step1\nE\n\nC\n\ntime P3 step2\nO\n\nCE\n\n||D||\nCC\n\nFigure0.035: Comparison of times for P1, P2 and P3. All times were measured for the QSM m = 1000\nENT\nwith threshold tm = 0.01.\n0.025\n100\n\n0.02\n\nWe\nfurther point out that the time axis (right y-axis) is logarithmic, i.e. an increase of 1\n0.015\non the axis means an actual increase of one order of magnitude. One conclusion we can draw\n10\nfrom 0.01\nthis is that whenever diagnoses computation requires non-negligible time, let us say more\nthan 0.005\n10 sec, then query computation is always at least one order of magnitude and up to more\nthan two orders of magnitude, i.e. a factor of 100 (case O, 80 diagnoses), faster than diagnoses\n0\ncomputation.\nNote that the diagnoses computation time grows exponentially with |D|, i.e.1 our\n| |\n|D|\nENT 0.01averaging to approximately\nachieved QSM‐value\nENT 0.01\ndata shows\nquite constant time growing|CQ|\nfactors\n2 (visible\nby the\ntime P1 ENT 0.01\noptimal QSM‐value ENT\n# gen QPs ENT 0.01\nmostly constant slope of the gray line in the figure) for all eight DPIs in Tab. 6. Hence, computing\n# exp QPs ENT 0.01\nQP search branching factor\n10 diagnoses more implies about the double computation time. Therefore, with the new method:\nWhenever the computation of a set of diagnoses is feasible, the generation of an optimized\nquery regarding the computed diagnoses is feasible and often significantly more efficient than the\ncomputation of diagnoses. Optimized query computation is thence a minor problem as compared\nto diagnoses computation.\nComparison of Times for Phases P1, P2 and P3. (Fig. 5) The figure depicts the relative\nproportion of the overall query computation time consumed by the different phases of Alg. 2. It\nis evident that phase P3 accounts for more than 78 th of the computation time in all test runs. If\nwe exclude the case U – for which the algorithm’s computation time was the lowest amongst all\nDPIs in Tab. 6, i.e. below 0.1 sec for all runs, cf. Fig. 4 – then P3 is even responsible for more\nthan 97% of the computation time in all runs. This reminds us again of the fact that reasoning\n(which is only performed in P3) has a substantially higher impact on the efficiency of query\ncomputation than the combinatorial problems solved in P1 and P2.\nThis suggests a variant of Alg. 2 which always runs the very fast P1+P2 first and shows\nthe result to the user. Meanwhile in the background, or alternatively on demand, the algorithm\nexecutes P3 to further optimize the already computed query. In this manner the user can always\nget a first query suggestion instantaneously.\n67\n\n\f50%\n\n10\n\n40%\n30%\n20%\n10%\n1\n\n0%\ntime P1\nM\n\nU\n\ntime P2\nT\n\ntime P3 step1\nE\n\nC\n\n||D||\n\ntime P3 step2\nO\n\nCE\n\nCC\n1000\n\n0.03\n0.025\n\n100\n\n0.02\n0.015\n\n10\n\n0.01\n0.005\n0\n\n1\n| |\n|D|\n\n|CQ| ENT 0.01\n\nachieved QSM‐value ENT 0.01\n\ntime P1 ENT 0.01\n\noptimal QSM‐value ENT\n\n# gen QPs ENT 0.01\n\n# exp QPs ENT 0.01\n\nQP search branching factor\n\nFigure 6: Summary of P1. ENT 0.01 means that the QSM m = ENT was used with the threshold\ntm = 0.01. |CQ| denotes the size of the canonical query, # gen QPs and # exp QPs means\nthe number of generated and expanded q-partitions, respectively. The branching factor is the\naverage number of successors of nodes in the search tree.\n\nMoreover, we recognize that P2 (see the thin black area between the darker and lighter\nshaded areas in the figure), although it solves an NP-hard problem in general, makes up a negligible fraction of the method’s computational load due to its fixed parameter tractability (cf.\nProp. 24). It is by far the fastest phase of the algorithm. Thus, even for large numbers of leading\ndiagnoses, the solved hitting set problem remains easy.\nWhat we also point out is that the query expansion (P3, step 1) is sometimes (for C and CE)\nthe most influencing factor regarding the computation time for small |D| and successively loses\nimportance against the query contraction (P3, step 2) as |D| is increased. Reasons for this were\ndiscussed above.\nSummary of Phase P1. (Fig. 6) By considering the generated and expanded QPs and the\nbranching factor we get an impression of how the search tree looks like in P1. First, it is apparent\nthat the number g of generated QPs is approximately proportional to the number of leading diagnoses |D|, i.e. g ≈ c|D|, where the factor c averages to h1.94, 1.86, 1.67, 1.75, 2.07, 2.27, 2.63,\n1.99i for hM, U, T, E, C, O, CE, CCi. Hence, we can state that, on average, for a very small\nthreshold tm of 0.01 (and 0), an optimal QP w.r.t. ENT (and SPL) can be found by generating\nno more than 3|D| QPs. As a consequence, the effort arising in P1 – notabene with heuristic and\npruning – grows linearly with the number of leading diagnoses. By absolute numbers, g was\nalways below 200 (with a maximum of 187 for the case CE with |D| = 80).\nSecond, we notice that the branching factor as well as the number of expanded QPs are\napproximately proportional, but grow sublinearly with regard to |D|. For instance, for 10, 40 and\n80 leading diagnoses, the branching factor and number of expanded QPs amounted on average\n68\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\n(over all eight DPIs) to 6, 12 and 16 as well as 3.8, 7.0 and 8.5, respectively. That is, somewhat\nsurprisingly, the branching factor is a rough (upper bound) estimate for the number of explored\nQPs until a goal is found. Moreover, continuously increasing the number of diagnoses, always\nby the same constant, leads to increases in the number of expanded QPs and in branching factor\nby continuously smaller factors. One reason for this is the tendency of diagnoses (and thus of\ntheir subset-minimal traits) to overlap more frequently if more diagnoses are computed. This\noverlap means that there are fewer equivalence classes as per Cor. 3, and thence affects the\nbranching factor negatively.\nConcerning the time required for P1 (black dashed line), we see that the maximum time over\nall cases was below 0.03 sec and, excluding the DPI CE, below 0.01 sec. Therefore, an optimal\n1\nQP (w.r.t. the threshold 0.01) can always be computed in less than 20\nth of a second.\nLet us now draw our attention to the quality of the computed QP and imagine a thought\nhorizontal line at 0.01 (left y-axis) denoting the specified threshold. It is easy to verify that the\nQSM-value of the computed QP (line labeled with the + signs) is always below this line, i.e.\na QP with at least the required quality was determined in all cases. This analysis additionally\nshows that, although the threshold is at 0.01, the actually achieved QSM-value is quite close to\nthe optimal QSM-value w.r.t. ENT, which is very close to zero (line labeled with the x signs).\nNote, w.r.t. SPL the optimal QSM-value of 0 was always hit. The optimal QSM-value was\nascertained by performing a brute-force search over all QPs (cf. Fig. 11) and storing the best\nfound QSM-value.\nFinally, the size of the canonical query, which constitutes an upper bound of the size of a\nquery constructible in phase P2, attains values between 2.8 (U, 80) and 28.4 (CE, 50). The size\nof the CQ depends on the overlapping of the diagnoses in the D+ set with those in the D− set\nof the respective (C)QP. The higher it is, the lower the cardinality of the CQ (cf. Lem. 7).\nSummary of Phase P2. (Fig. 7) In P2, the query with optimal QCM c|.| (see page 29) is computed by performing a uniform cost hitting set search over the collection of all ⊆-minimal traits\nof the optimal QP found in P1. The number of generated nodes measures the necessary effort for\nthe hitting set tree construction and depends on the number of ⊆-minimal traits (number of sets\nto be hit), their cardinality (branching factor of the hitting set tree) and their overlapping (the\nhigher it is, the lower the depth of the tree and the minimum cardinality query tend to be). For\n|D| ∈ h10, 40, 80i, the average and maximal numbers of generated nodes are h8.5, 8.5, 28.9i\nand h19, 16, 143i, respectively. That is, the size of the generated tree is easily manageable, even\nfor large sets of leading diagnoses. This fact is confirmed by the negligible time (in all runs\n6\nbetween 1001000 and 1 000\nsec) consumed by P2 (see the white squares in the figure).\nThe average size (where the average is taken over the traits of the optimal QP returned by\nphase P1) of the ⊆-minimal traits is very small with an average / maximum of 1.59 / 2.75 over\nall cases, except for CE. For CE, we measure an average / maximum of 3.88 / 5.24. Hence,\nthe branching factor of the hitting set tree is very low and the number of generated nodes is\nsignificantly higher for CE than for the other tested DPIs.\nAn explanation for the tendency of ⊆-minimal traits to shrink for higher |D| (which can\nbe best observed for the cases T, E and CE, see the figure) is the tendency of diagnoses to\nmore frequently overlap, if more diagnoses are computed (cf. Def. 17). The number of ⊆minimal traits, on the other hand, is proportional to |D|, which is quite intuitive as the number\n69\n\n\fM\n\nU\n\nT\n\nE\n\nC\n\nO\n\nCE\n\nCC\n100\n\n100\n\n90\n80\n70\n60\n50\n\n10\n\n40\n30\n20\n10\n1\n\n0\n| |\n|D|\n\navg size of min traits\n\nsize min‐card query\n\n# gen HS nodes\n\n% size reduction of CQ\n\ntime P2 ENT 0.01\n\nM\n\nU\n\nT\n\nE\n\nC\n\nO\n\n# of min traits\n\nCE\n\nCC\n\n50\nFigure1007: Summary of P2. Min traits means ⊆-minimal traits w.r.t. the (fixed) QP returned by phase\n10\n1\n\nP1. Min-card means minimum-cardinality. Gen HS nodes refers to the generated nodes in45the\n∗\n|\n40\nconstructed hitting set tree. The size reduction of the CQ is computed as (1 − |Q\n|Q| ) ∗ 100%\n35\n∗\nwhere Q is the CQ and Q the query output by P2.\n30\n25\n20\n\n0.1\n\n15\n\nof diagnoses\nin D− (i.e. the maximal possible number of ⊆-minimal traits) tends to grow with\n10\n0.01\nincreasing |D|, of course depending on (the QP properties favored by) the used QSM.\n5\n0\n0.001 median of the size of the query with optimal QCM computed by P2 is 3.8 sentences\nThe\n| |\n|D|\n#\ncalls\nENT()\n#\ncalls\nisQPartConst()\nISQPARTCONST\n(see the light gray bars). The achieved size reduction, starting from the CQ of the optimal QP\ntime P3 step1\ntime P3 step2\ntime per call ENT()\nreturned by P1\nand given as input to P2, ranges\nfrom zero percent (cases M,\n5 and U, 8 and C,\nISQPARTCONST\ntime per call isQPartConst()\n15), where the CQ coincides with the QCM-optimal query, to more than 80% (case CE, 60). In\nthe latter case, CQs of average sizes of 27 are reduced to an average size of 5.\nSummary of Phase P3. (Fig. 8) As the complexity analysis in Sec. 3.2.5 suggests, the crucial factors determining the efficiency of P3 are the number and the complexity of the required\nreasoner calls. For the first step of P3, these are the calls to EntET (cf. Eq. (24)). The figure\n(black bars) reminds us of the fact that their number is constant, i.e. 2, independent from other\nparameters. Consequently, only the complexity of the EntET calls has an effect on the hardness\nof P3, step 1. As becomes clearly evident in the figure, this complexity is ruled by (the complexity, expressivity and number of implicit entailments of) the KB K of the respective DPI, i.e. the\nblack dashed line is more or less constant for each DPI. However, it tends to slightly decrease\nupon increasing |D|. This is exactly what one would expect (cf. the discussion of Fig. 4 above).\nNote, the time consumed by P3, step 1 (continuous black line) is exactly proportional to the time\nneeded for an EntET call, which confirms that there are no other significant factors influencing\nthe complexity of this computation step. By absolute numbers, the time per EntET call never\nexceeded 0.2 sec.\nAs regards the second step of P3, the number and complexity of the IS QPART C ONST calls\nis decisive. The former is again influenced by the KB K because its complexity and expressivity\n70\n\n\f40\n30\n20\n10\n\nO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\n1\n| |\n|D|\n\navg size of min traits\n\nsize min‐card query\n\n# gen HS nodes\n\n% size reduction of CQ\n\ntime P2 ENT 0.01\n\nM\n\nU\n\nT\n\nE\n\nC\n\nO\n\n0\n\n# of min traits\n\nCE\n\nCC\n50\n\n100\n\n45\n40\n\n10\n\n35\n30\n\n1\n\n25\n20\n\n0.1\n\n15\n10\n\n0.01\n\n5\n0\n\n0.001\n| |\n|D|\n\n# calls ENT()\n\n# calls isQPartConst()\nISQPARTCONST\n\ntime P3 step1\n\ntime P3 step2\n\ntime per call ENT()\n\nISQPARTCONST\ntime per call isQPartConst()\n\nFigure 8: Summary of P3.\naffects the number of computed entailments in P3, step 1. These in turn have an impact on the\nsize of the expanded query, |Q0 |, which rules the number of IS QPART C ONST calls (cf. Prop. 32).\nIn comparison to other DPIs, CE requires a relatively high number of IS QPART C ONST calls (up\nto roundly 50) on account of the large size of the computed query expansion in P3, step 1 (see\nFig. 9). That is, the reasoner Inf returned substantially more implicit entailments for CE than for\nother DPIs. The complexity of an average IS QPART C ONST call is on the one hand determined\nby |D| (as discussed above), thus slightly increasing for each DPI (see the figure), and on the\nother hand by the reasoning complexity of the respective KB K. For example, in case of O,\nalthough the average number of IS QPART C ONST calls is clearly larger than for E, the latter\nrequires more time one average for P3, step 2 due to the higher complexity per call (dashed\ntransparent line). Over all runs, no call of IS QPART C ONST took longer than 0.01 sec and the\ntime for P3, step 2 was always below 3.5 sec.\nQuery Evolution. (Fig. 9) In this figure we see the comparison of the intermediate results in\nterms of the query size throughout phases P1 and P3 (optional mode of Alg. 2). First, phase P1\nreturns a QP (from which the CQ Q can be immediately computed, see Lem. 7). Then the CQ is\nenriched in phase P3, step 1 resulting in the expanded query Q0 . This query is finally contracted\nagain yielding the output query Q∗ .\nWe see that Q is always larger than Q∗ , i.e. altogether the enlargement and later reduction\nof the CQ Q produces a query smaller than Q. Note, |Q| is a theoretical lower bound of |Q0 |\n(cf. Eq. 25) and hence always lower than |Q0 |. As we already discussed above, the size of Q0\nin relation to the size of Q depends very much on the expressivity and (logical) complexity\nof the KB. Therefore, |Q0 | is larger for, e.g., CC than for, e.g., O, even though the size of Q\nis approximately equal in both cases. In figures, |Q| for O and CC averages to 8.9 and 10.1,\nwhereas |Q0 | for O and CC amounts to 29.4 and 52.5. The most implicit entailments could be\ncomputed in case of CE, with average sizes of the expanded query Q0 of 268. These differences\nin the number of entailments can be best seen by considering the query expansion factor (dashed\n71\n\n\fM\n\nU\n\nT\n\nE\n\nC\n\nO\n\nCE\n\nCC\n70\n\n1000\n\n60\n50\n\n100\n\n40\n30\n10\n\n20\n10\n\n1\n\nM\n100Figure 9:\n90\n80\n70\n\n0\n| |\n|D|\n\n|output query|\n\n|expanded query|\n\n|CQ|\n\nquery expansion factor\n\nquery reduction factor\n\nU\n\nT\n\nE\n\nC\n\nO\n\nCE\n\nCC\n\n1000\nQuery evolution over phases P1 and P3. Expanded query / output query refers to the query\nreturned by P3 step 1 / P3 step 2. A query expansion factor of k means that the expanded query\nis k times as large in size as the CQ. A query reduction factor of k means that the expanded\n100\nquery is k times as large in size as the output query.\n\n60\n10\n\n50\n40\n\ntransparent line) which ranges from 9.8 to 17.2 for, e.g., CE and from only 1.4 to 1.7 for, e.g.,\n1\nU.\n20\n30\n\nThe query reduction factor (dotted line), on the other hand, measures the degree of contrac0\n∗\n0tion effectuated by P3, step 2. A reduction factor of k means that |Q | = k|Q |, i.e. the size\n0.1\n1\n∗\n0\nof the contracted\nand\noptimized\nquery\nQ\nis\nth\nof\nthe\nexpanded\none,\nQ\n.\nThe\nmaximal\nvalues\n| |\n|D|\n% P1+P2 of reaction time\n% P3 of reaction time\nreaction time\nk\nof k are around 65 for, e.g., CE and around 3 for, e.g., U. That is, for CE CQs of average size\n268 are reduced to optimized queries of average size 5 while for U CQs averaging to 7.0 are\nminimized to queries averaging to 3.5. Nevertheless, the size of the finally output query Q∗ does\nnot fluctuate very strongly (gray continuous line) and has a median of 3.4.\n\n10\n\nQuery Computation vs. Debugger Reaction Time. (Fig. 10) On the one hand the figure\nshows the absolute reaction time (transparent line) of the debugger, i.e. the time passing between\nthe submission of a query answer and the provision of the next query. In other words, the\nreaction time is the time required for leading diagnoses computation plus the time for query\ngeneration. On the other hand the figure gives insight into which proportion of the reaction\ntime is due to query computation, where phases P1+P2 (dashed line) and P3 (dotted line) of the\nquery computation are shown separately, and which proportion is due to diagnoses computation\n(difference between 100 on the left y-axis and the dotted line). The debugger’s reaction time\nranges from 0.15 sec (U, 10) to 8 min 50 sec (CE, 80). Over all eight DPIs, the average reaction\ntimes for |D| ∈ h10, 20, 30, 40, 50, 60, 70, 80i are h0.8, 2.0, 3.2, 6.2, 16.5, 46.3, 87.9, 223.6i. It\nis apparent from the figure that the reaction time grows superlinearly with increasing |D|. For\nall DPIs separately, the average factor by which the reaction time grows upon adding ten leading\ndiagnoses is between 1.65 and 2.56. The average growing factor over the entire data is roundly\n72\n\n\f40\n30\n10\n\n20\n10\n\nO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n1\n\n0\n| |\n|D|\n\n|output query|\n\n|expanded query|\n\n|CQ|\n\nquery expansion factor\n\nquery reduction factor\n\nM\n\nU\n\nT\n\nE\n\nC\n\nO\n\nCE\n\nCC\n1000\n\n100\n90\n80\n\n100\n\n70\n60\n\n10\n\n50\n40\n30\n\n1\n\n20\n10\n0\n\n0.1\n| |\n|D|\n\n% P1+P2 of reaction time\n\n% P3 of reaction time\n\nreaction time\n\nFigure 10: Query computation vs. debugger reaction time. Reaction time refers to the time passing between the submission of a query answer and the finalization of the next query’s computation.\n\n2. That is, the reaction time is about doubly as high, if the number of leading diagnoses is raised\nby ten.\nHowever, using the presented algorithm, the time spent for query computation accounts for\nonly a minor fraction of the reaction time. In particular, whenever the reaction time is not very\nquick, i.e. it is, say, beyond 10 sec, the query computation is always responsible for less than\n10 percent of the reaction time when Alg. 2 is used in optional mode with query expansion and\noptimization, and for less than 3 per mill of the reaction time when it is used in default mode.\nHence, with the new method, whenever the debugger fails to react within short time, this is\ndue to diagnoses computation and not due to query computation. Moreover, the fraction of the\nreaction time needed for computing an explicit-entailments query optimizing both the QSM and\nthe QCM is always negligible, independent of other parameters.\nSearch Space Size vs. Computation Times. (Fig. 11) Here, we see a comparison of the\nabsolute computation times of the three phases of the new method (solid lines). Furthermore,\nwe performed a brute force search over all CQPs, on the one hand to determine the size of the\nsearch space explored in P1, i.e. the (exact) number |CQPD | of all existing CQPs for |D| (see\nthe dark shaded area in the figure, cf. Conjecture 1), and on the other hand to get an idea of the\nefficiency of (C)QP generation with the new algorithm. The time required for the exploration of\nall CQPs is shown by the framed transparent line in the figure. Additionally, the figure displays\nan upper bound of the size of the search space tackled by P2 (dotted line), i.e. of the number of all\n− , ∅i where P is the result returned by\nexplicit-entailments (EE) queries for the QP P = hD+ , D\n\u0001\nP\nn\n+\nphase P1. We calculated this upper bound as u := 2n − m\nk=1 k where n := |Qcan (D )| and\n∗\nn\n+\nm := |Q | − 1, i.e. 2 is the number of all subsets of the CQ Qcan (D ) of P and the subtracted\nsum counts all subsets of Qcan (D+ ) of size smaller than the minimum-cardinality query Q∗\ncomputed by phase P2. Recall, each explicit-entailments query is a subset of Qcan (D+ ) and a\nsuperset of some minimal hitting set of all (⊆-minimal) traits in D− (by Prop. 22 and Cor. 5),\n73\n\n\f1E+09\n\nM\n\nU\n\nT\n\nE\n\nC\n\nO\n\nCE\n\nCC\n\n100000000\n10000000\n1000000\n100000\n10000\n1000\n100\n10\n1\n0.1\n0.01\n0.001\n0.0001\n0.00001\n|\n|\n|CQP_D|\n\n| |\n|D|\n\nENT: time P3\n\nENT: time P2\n\n# of EE queries (UB)\n\nBF: time P1\n\nENT: time P1\n\nM\nE\nC\nO\nCE\nCC\nFigure\n11: Search\nspace Usizes versus Tquery computation\ntimes. CQP\nw.r.t.\nD denotes the set of CQPs1000\n10,000,000\n1,000,000\n\nthe leading diagnoses D. EE queries refers to explicit-entailments queries (cf. page 32), UB\nsignalizes an upper bound. BF terms a brute force search over CQPD .\n100\n\n100,000\n10\n\n10,000\n\n∗ is a hitting set of of all (⊆-minimal) traits in D− of minimum-cardinality. Hence, u is\nand Q1,000\n1\nindeed an upper bound of the number of all explicit-entailments queries for P.20\nIt is evident from the figure that P1+P2 (default mode of Alg. 2) always finish in less than\n0.03 sec outputting an optimized query w.r.t. the QSM m and the QCM c. Importantly, this\nefficiency is independent of the type (e.g., knowledge base, physical system) of the diagnosis\nproblem at hand. Because P1+P2 only do combinatorial computations that depend solely on the\ndiagnostic structure of the problem, i.e. the size, number, probabilities, overlapping, etc. of diagnoses. Moreover, it takes P1 longer than P2 in all cases, and P1’s execution time increases monotonically with |D| whereas P2’s does not. Note that albeit P1+P2 solve Prob. 3 for a restricted\nsearch space S (cf. Theorem 7), the number |CQPD | of CQPs w.r.t. D, which is just a fraction of\n|S|, already averages to roundly h300, 5 500, 28 500, 105 000, 200 000, 370 000, 475 000, 530 000i\nfor |D| ∈ h10, 20, 30, 40, 50, 60, 70, 80i. That this restricted search space S is sufficiently large\nfor all numbers of leading diagnoses |D| is also substantiated by the fact that in each single test\nrun an optimal query w.r.t. the very small threshold tm = 0.01 (90% smaller than the threshold used in [Shchekotykhin et al., 2012]) was found in S. The number of explicit-entailments\nqueries per QP, i.e. the factor c such that |S| = c|CQPD | might also be substantial, as hinted\n\n20. Unfortunately, we cannot make any statement about the strictness of this bound, nor can we give a non-trivial\ngeneral lower bound. We nevertheless included this upper bound in the figure with the intention to give an\nimpression of the worst-case complexity (domain over which the QCM is optimized) of P2.\n\n74\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nT\n\nE\n\nCE\n\nCC\n1000\n\n100\n\n10\n\n1\n100\n0.1\n\n0.01\n10\n0.001\n\n0.0001\n\n0.00001\n\n1\n|CQ|\n\n|min‐card query|\n\n|expanded query|\n\n|output query|\n\nachieved QSM‐value\n\nQ: time\n\ntime P1\n\ntime P2\n\ntime P3 step 1\n\ntime P3 step 2\n\nFigure 12: Scalability Tests. Min-card query / expanded query / output query denote the query returned\nby P2 / P3 step 1 / P3 step 2. The achieved QSM value refers to the QSM ENT. Q: time\nmeans overall query computation time (ignoring leading diagnoses computation time).\n\nby the dotted line. Although this line describes only an upper bound, it gives at least a tendency\nof the size of the domain over which P2 seeks to optimize the given QCM. The meaningfulness\nof this trend line is corroborated by the fact that the time required for P2 (bottommost line in\nthe plot) obviously correlates quite well with it. The optional further query enhancement in P3\n(omission of the search space restriction and switch to the full search space) terminates in all\ntests within less than 4 sec and returns the globally optimal query w.r.t. the QCM cmax (see\nTheorem 8). These practical times result from the moderate use of a reasoner in P3 (cf. Fig. 8).\nIn P1, also a brute force search computing all possible CQPs is feasible in most cases –\nfinishing within 50 sec in all runs (up to search space sizes of more than 120 000) except for\nthe |D| ≥ 30 cases for the DPI CE (where up to 3 million CQPs were computed). This high\ncomputational speed is possible due to the complete avoidance of costly reasoner calls by relying\non the canonical notions, CQs and CQPs.\nScalability Tests. (Fig. 12) The figure shows that even for an immense number of 500 leading diagnoses, Alg. 2 works in absolutely reasonable time, still producing a query optimized\nalong the QSM and QCM dimension. The diagnoses computation times for hT, E, CE, CCi (not\ndepicted in the figure) are h8, 11, 1031, 1405i sec. Concretely, we observe that the required\noverall query computation time amounts to roundly h0.8, 3.1, 39.2, 3.0i sec for hT, E, CE, CCi\n(gray line with white squares) and is for the most part consumed by the reasoning activity in P2\n(dotted line) which depends on |D| (cf. Prop. 32).\nBy way of comparison, the times achieved for |D| = 80 (cf. Fig. 4) for hT, E, CE, CCi\nwere h0.28, 1.11, 3.55, 0.54i sec, i.e. the time increase factors are roundly h2.9, 2.8, 11.0, 5.6i\nwhereas |D| was increased by the factor 500\n80 = 6.25. The most significant relative increase is\n75\n\n\fdue to P1 with factors around h38, 57, 20, 48i (i.e. each factor is computed as time for P1 with\n500 diagnoses divided by time for P1 with 80 diagnoses). However, this substantial growth does\nnot carry weight due to the very small absolute times required by P1. Similarly, for P2, absolute\ntimes were tiny such that the calculated factors of h6.9, 3.8, 1.7, 5.7i are of minor importance\n– contrary to the growth factors h2.4, 2.4, 11.5, 5.0i measured for P3 step 2 where the highest\nabsolute times are manifested. Note the strong correlation between the overall increase factors\nand the ones concerning step 2 of P3. Only for P3 step 1, times were basically decreasing, i.e.\nthe factors in this case are h0.9, 0.8, 1.4, 0.9i (which is well explainable, see above).\nWhereas the computation times of phases P2 and P3 depend on the underlying DPI (see the\nparallel fluctuation of the respective lines in the figure, cf. discussions above), the time of P1 is\nmostly affected by |D| (constancy of the dashed line). In fact, P1 finished in all cases within 0.6\nsec, P2 within 0.003 sec and P3 step 1 within 0.25 sec.\nThe achieved QSM-value for ENT was always below the postulated 0.01 (transparent framed\nline), confirming that a sufficiently good QP could be found in all cases. The number of QPs\nthat had to be generated and expanded until a goal QP was identified is h570, 622, 718, 629i and\nh10, 12, 18, 15i, respectively, for hT, E, CE, CCi. Note the much higher search tree branching\nfactors here, h57, 52, 40, 42i, than observed in EXP1, h15, 16, 18, 16i (cf. Fig. 6).\nConcerning the query evolution and size, we realize that the obtained values are reasonable\nand very similar to the ones seen in EXP1 (see, e.g., Fig. 9).\nComparison of Alg. 2 (NEW) with a Method (OLD) not Using the Proposed Theory. (Fig. 13)\nThe figure shows the results for all (DPI,|D|) combinations where OLD (see the description of\nEXP3 in Sec. 4.1) terminated in all 5 iterations of query computation before a predefined timeout\nof 1 hour elapsed. That is, for all DPIs in Tab. 6 it took OLD longer than 1 hour for |D| = 20.\nMoreover, for T, E and CE, OLD exceeded the timeout even for |D| = 15. Diagnoses computation worked reasonably in all cases, requiring always less than 2 min.\nWhat might seem surprising at first sight is the fact that, in all cases, NEW generates at least\nas many (different) QPs with empty D0 as OLD does, although both run a brute force search.\nBeyond that, in most of the cases the fraction f of QPs OLD is able to determine among those\ngenerated by NEW is rather small (see the size relation between light and dark gray areas in\nthe figure). In numbers, f ranges from only 1% (U15) to 99% (T10). Note that the y-axis is\nlogarithmic, i.e. albeit the light gray area for U15 seems about a third of the dark gray one, it\namounts to only about one percent (two orders of magnitude difference). That is, by absolute\nnumbers, OLD generates on average for U15 only 12 QPs from 835 QPs generated by NEW. To\nmake this aspect better visible, the figure shows the average fraction f (recall of OLD w.r.t. the\nQPs determined by NEW) over each 5 iterations in terms of the gray squares.\nThe reason for this drastic degree of incompleteness of OLD regarding QPs is the strategy\nof a direct generation of a (potential) query before its (q-)partition is constructed. This is inverse\nto how NEW behaves. Since this query candidate is generated by a reasoner, it depends strongly\non the reasoner’s output, i.e. the computed entailments. Without proper care, this generally\nleads to a neglect of the discrimination sentences (see Def. 13), which are those responsible\nfor the consideration of all and only (canonical) QPs, i.e. for soundness and completeness of\n(C)QP generation (cf. Sec. 3.2.2). As a result (cf. the discussion on page 36), this can on the one\nhand effectuate unsoundness, i.e. the construction of unnecessary duplicate QPs and unnecessary\n76\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\nQSM: % NEW better than OLD\n0\n0 M5 M10 M15\n82.9853447\n100000\n1.5520476\n59.7436656\n\nU5\n\nU10\n\nU15\n\nT5\n\nT10\n\nE5\n\nE10\n\nCE5\n\nCE10\n\nCC5\n\nCC10 CC15\n\nC5\n\nC10\n\nC15\n\nO5\n\nO10\n\nO15\n100\n90\n\n10000\n\n80\n\n89.6987346\n1000\n99.5947748\n72.4179238\n91.050121\n100\n54.6748547\n\n70\n60\n50\n\n10\n\n0\n0\n1\n99.3823729\n98.2975925\n84.6632348\n0.1\n\n40\n30\n20\n10\n\n97.3927526\n0.01\n99.2322016\n92.189648\n99.9593677\n0\n99.9000937\n99.9883263\n99.9999537\nFigure\n99.3304516\n99.9914343\n35.5616398\n99.9379635\n93.4649809\n99.781695\n99.9985525\n\n0\n\n଴ )\nNEW: # different found QPs (with empty ۲\nD0\n\nOLD: # different found QPs with empty D0\n۲଴\n\nOLD: # QP verification failed\n\nOLD: time query verification\n\nOLD: overall time\n\nNEW: overall time\n\nOLD: avg recall\n\nQSM: % NEW better than OLD\n\n13: Comparison of Alg. 2 (NEW) with a method (OLD) not using the proposed theory. The\nx-axis (on top) shows the (DPI,|D|) combinations, e.g. U15 presents 5-iteration average\nvalues for the DPI U with |D| = 15. Overall time refers to the time for the entire query\ncomputation (where diagnoses computation time is neglected). OLD: avg recall refers to the\naverage (over 5 iterations) percentage of QPs (with empty D0 ) generated by OLD among\nthose generated by NEW.\n\n0\n0\npartitions\nthat are non-QPs (thus query candidates that turn out to be no queries). On the other\nhand,00 it can cause incompleteness, i.e. the disregard of QPs. Apart from that, the search space\nof queries\nfor one (fixed) QP P explored by OLD is generally smaller than the one considered\n0\nby NEW because NEW computes a query expansion based on the most informative seed for P\n0\n(i.e. P’s\nCQ, see Sec. 3.2.5). As opposed to this, OLD computes a minimization of the (strongly\n0\n0\nreasoner-dependent) possibly much less informative initial query candidate computed for P.\n0\nPlease\nnote that these problems occur although both methods, NEW and OLD, use exactly the\n0\nsame reasoner and compute exactly the same (types of) entailments for one and the same KB.\n0\nThe crux\nis rather if, when and for what the reasoner is used.21\n0\nThe\nnumber of unnecessarily generated query candidates X (those for which the query ver0\n0\nification failed, cf. EXP3 in Sec. 4.1) by OLD is substantial in several cases (see light line with\n0\nsquares).\nFor instance, for U5 / U 10 / U15 this number averaged to over 12 / 250 / 14 000 and\nfor O5\n/\nO10\n/ O15 to 4 / 50 / 2250. Also, failed verifications outnumber successful ones (light\n0\n0\nshaded area) often by several orders of magnitude, e.g. for U15 or CC15. Consequently, OLD\n0\nmight\n0 spend most of the time unnecessarily. The reason for the failed query verification in all\n0\n\n21. One way to overcome the incompleteness issue of OLD is the manual addition of sufficiently many discrimination\n0\nsentences\nto the entailments returned by the reasoner. Nevertheless, the problems concerning duplicates and\n0\ncomputation\ntime persist.\n0\n0\n0\n86.6840384\n0\n0\n0\n0\n\n77\n\n\fthese cases is the emptiness of the D− (X) set of X’s partition. This stems from a too small\nnumber of or too weak logical sentences in X (cf. Prop. 4). NEW avoids this by exploiting the\ncanonical notions introduced in Sec. 3.2.2. Thus, whereas OLD’s query generation can be seen\nas a trial and error approach, NEW pursues a sound and complete systematic approach.\nThe massive advantage brought about by this is proven by the query computation times\nmeasured. In fact, for all cases where |D| ≥ 10, NEW required at least one order of magnitude\nless time than OLD (see black solid versus black dotted line). For example, the average execution\ntimes of NEW and OLD on hO5, O10, O15i are h0.11, 0.14, 0.35i sec and h0.41, 5.8, 186i sec,\nrespectively. Additionally, as OLD’s query computation time increases exponentially (see the\njumps of the dotted line by about an order of magnitude for one and the same DPI and different\ndiagnoses numbers, e.g., CC5 vs. CC10 vs. CC15) and NEW’s at most linearly (see Fig. 4)\nwith |D|, the time savings of NEW versus OLD grow (significantly) upon extending |D|. The\ngray line in the figure suggests that the performance of OLD suffers strongly from the enormous\ntime amount spent for query verification. Note, the latter requires extensive usage of a reasoner.\nFor instance, for U15 almost the entire computation time was dedicated to query verification.\nAnother interesting fact is that, over all DPIs and |D| = 10 (because for this configuration OLD\nalways finished before the timeout), OLD could only explore a median of 1.8 QPs within the\noverall query computation execution time (P1+P2+P3) of NEW.\nFinally, the quality (QSM-value) of NEW’s returned query proves to be always as good or\nbetter than for OLD. The percent improvement [(mold −mnew )/mold ]∗100 regarding the QSMvalue mnew achieved by NEW as compared with the QSM-value mold achieved by OLD (crosses\nin the figure) was sometimes more and sometimes less substantial (note, smaller QSM-values\nare better). As optimality is directly related to search completeness, smaller or no improvements\nare given for cases where OLD evinces high or full completeness, and vice versa. Stated in terms\nof the notation used in the figure, this means that the gray squares and the crosses are negatively\ncorrelated.\n\n5. Related Work\nThe thorough analyses of pool-based query generation and selection and the revealed shortcomings and improvement suggestions given in [Rodler, 2015] provide a foundation of and a\nmotivation for this work. Beyond that, we oriented ourselves by the structure and notation used\nin [Rodler, 2015] in our preliminary sections. A more in-depth discussion of the theory and the\nalgorithms described here and detailed, ready-to-be-implemented pseudocode plus additional\nremarks and considerations on search heuristics, search tree pruning and early termination rules\nfor the discussed QSMs and further ones can be found in [Rodler, 2016]. The generic sequential\ndiagnosis algorithm we describe in Sec. 2.4.3 is very similar to the ones given in [Shchekotykhin et al., 2012, Rodler, 2015] and follows the principled approach outlined in [de Kleer and\nRaiman, 1993, Sec. 2]. The QSMs ENT and SPL we use in our evaluations have originally been\nused for decision tree learning [Quinlan, 1986] and optimization [Moret, 1982] (here, SPL is\ncalled “separation heuristic”), but have later been adopted for diagnoses discrimination as well\n[de Kleer and Williams, 1987, Shchekotykhin et al., 2012, Rodler et al., 2013, Rodler, 2017].\n78\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nWhereas the works [Pattipati and Alexandridis, 1990, Shakeri et al., 2000, Zuzek et al., 2000,\nBrodie et al., 2003, Gonzalez-Sanchez et al., 2011] also focus on the query (probe/test) sequencing problem, they are not model-based, but rely on a test (coverage) matrix or test dictionary,\nrespectively. Such approaches are often called spectrum-based. Pros (and cons) of model-based\napproaches against such methods are discussed in [Pietersma et al., 2005] and [Davis and Hamscher, 1988, Sec. 3]. Besides the frequent reliance upon a predefined (and possibly incomplete)\nset of possible faults (e.g. single faults22 ) in such systems, one important difference to our approach is the fixed set of tests from which the system might choose in each iteration. Hence, the\nquery computation (as in our case) reduces to a query selection and the space of queries is initially known and restricted (in a way the generation and size of the test matrix remain feasible)\nwhereas it is unknown and, in principle, not restricted in the case of our work (queries need not\nbe chosen or computed in advance). Another crucial aspect is the information about the influence of test outcomes on the diagnoses. While such information in terms of prespecified fault\nmodels (relating faults to test outcomes23 ) is required to be known (or at least reliably and efficiently estimable) in the mentioned approaches, this information needs to be logically inferred\nin model-based approaches like the one described here. As discussed, this logical reasoning is\nthe major factor affecting the computational efficiency in the model-based case. Consequently,\ne.g., simulation-based non-myopic test selection strategies [Zamir et al., 2014] are not efficiently\napplicable to the problem tackled in this work. The issue is the very high reasoning cost required\nto update the diagnoses sets during these simulations.\nModel-based diagnosis methods for generating optimal tests, i.e. new sets of system inputs facilitating new gainful observations of the system behavior, are presented by the works\nof [Pietersma et al., 2005, Feldman et al., 2010]. Although test generation may be basically\nenforced with our approach by selecting appropriate entailment types ET in phase P3 (cf. also\nEx. 9), the main intention of our work, similar to, e.g., [Felfernig et al., 2004b, Shchekotykhin\net al., 2012, Rodler et al., 2013, Rodler, 2015], is the specification of an optimal next query\n(test case), defined generally as a (set of) sentence(s) formulated in some knowledge representation language. Translated to hardware or physical devices [de Kleer and Williams, 1987,\nde Kleer and Raiman, 1993, Siddiqi and Huang, 2011] a query usually corresponds to a probe,\ni.e. the measurement of (a) system variable(s). Due to the generality of the query notion our\napproach addresses a more complex query (probe) search space than the methods of [de Kleer\nand Williams, 1987, de Kleer and Raiman, 1993], thereby guaranteeing perfect diagnoses discriminability, i.e. the unambiguous localization of the actual fault (cf. Sec. 2.4.5).\nA general aspect that distinguishes our approach from probe selection algorithms is the not\nnecessarily explicit availability of the possible probes. For instance, in a digital or combinatorial\ncircuit [Reiter, 1987, de Kleer and Williams, 1987, Siddiqi and Huang, 2011] all probe locations\nare given by the circuit’s wires. In general, this is not necessarily the case, e.g. when considering\nany kind of knowledge-based system [Felfernig et al., 2004b, Kalyanpur et al., 2006, Shchekotykhin et al., 2012, Rodler et al., 2013, Rodler, 2015]. In the latter scenario, (most of the) queries\n22. [Abreu et al., 2011] extends spectrum-based approaches by considering multiple faults, but does not address the\nselection of optimal tests.\n23. Note that this information (e.g., given by the tests’ traces telling which components are involved in the each test’s\nexecution) is required in advance of running the tests when dealing with the problem of optimal test selection.\n\n79\n\n\f(e.g., possible questions to a domain expert) are normally implicit and must be (expensively) inferred.\n[Feldman et al., 2010] also describes a probing algorithm which, as opposed to ours, makes\nextensive use of an inference engine to compute the best query (probe). Moreover, it might\nconsider non-discriminating probes as well as generate duplicates (in terms of the diagnoses\neliminated for each outcome) in the search for an optimal probe. Both is impossible with our\napproach (cf. page 36).\nThe works of [Shchekotykhin et al., 2012, Rodler et al., 2013] are similar to ours in that they\ndeal with query selection for knowledge-based systems and also suggest a generic procedure\nfor query generation and selection. This procedure can be seen to “implement” the definition\nof a query (cf. Def. 12) quite directly, i.e. computing query candidates X for various seeds\nD+ ⊂ D and verifying whether X is indeed a query by checking D+ (X) 6= ∅ and D− (X) 6= ∅.\nHowever, the main focus of these works is on query selection strategies (which we call QSMs,\ncf. Sec. 3.1) and their pros and cons in various scenarios, especially with regard to the length\nof the query sequence until (high) diagnostic certainty is achieved. Our work, on the contrary,\ncan be seen to complement these works by concentrating and improving on the algorithms for\nquery computation and optimization. For this reason we have also used the QSMs discussed\nin [Shchekotykhin et al., 2012] in our evaluations. The latter (cf. Sec. 4.2, Fig. 13) show that\nour novel theory enables significant enhancements of the above-noted generic procedure by a\nwell-conceived (non-)employment of expensive reasoning.\nA difference to the works of [de Kleer and Williams, 1987, Shchekotykhin et al., 2012,\nRodler et al., 2013] is the capability of our approach to reduce the query search space a-priori to\nonly preferred queries, i.e. those that discriminate between all (leading) diagnoses (cf. discussion\non page 22). The key idea for realizing this was brought up in [Rodler, 2015, Chap. 8].\n[Siddiqi and Huang, 2011] suggest a heuristic for query selection that does not require computing the entropy of diagnoses because the latter can generally be costly for state-of-the-art\nsystems such as GDE [de Kleer and Williams, 1987] when the set of diagnoses is large. First,\nby the possibility to leverage heuristics and pruning techniques in the proposed systematic query\nsearch, our method needs to explore only minor parts of the search space (cf. Sec. 6) and can\nsave effort by computing the actual entropy of a query (q-partition) only if its heuristic value is\nsufficiently good. We have shown that in this vein queries deviating negligibly from the optimum could be computed in reasonable time for very large numbers up to 500 leading diagnoses.\nHence, the scalability is not a problem with this strategy. Second, our approach can easily handle\na variety of other QSMs (such as all those introduced in [Rodler, 2017]) apart from entropy in a\nsimple plug-in fashion. Corresponding heuristics and pruning operations suited for these QSMs\nwhen incorporated into our approach are described and explained in [Rodler, 2016]. Third, as\nnoted above, our approach can deal with implicit queries, i.e. those that need to be inferred and\nare not given in explicit form. Fourth, [Siddiqi and Huang, 2011] assume all measurements to\nhave equal costs and thus do not consider the minimization of the latter. Instead, they focus on\nthe minimization of the number of queries (measurements). Our approach incorporates both the\nnumber and the cost of queries in the optimization process.\n[Heckerman et al., 1995], e.g., does consider query (observation) costs, but, unlike our work,\nuses interleaved repair and observation actions. Also, it might test system components unnec80\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nessarily (given misleading probabilities) since no diagnostic evidence, i.e. the set of leading\ndiagnoses pinpointing what we call discrimination sentences (cf. Def. 13), is incorporated.\nFinally, and importantly, our approach uses the inference engine as a black-box (i.e. as an\noracle for consistency and/or entailment checks) and does not depend on any specific inference\nmechanism. This stands in contrast to glass-box approaches [Parsia et al., 2005] that rely on\nmodifications of the reasoner’s internals, e.g., for storing justifications [Horridge et al., 2008],\nprime implicants [Quine, 1952] and environments [de Kleer and Williams, 1987], respectively,\nfor certain entailments. This reasoner independence makes our approach very general in the\nsense that it can be applied to diagnosis problem instances formulated in any knowledge representation formalism for which a sound and complete reasoner is available. In-depth comparisons between black-box and glass-box approaches for monotonic KBs have been carried out by\n[Kalyanpur, 2006, Horridge, 2011], with the overall conclusion that, in terms of performance,\nblack-box methods compare favorably with glass-box methods while offering a higher generality\nand being more easily and robustly implementable.\n\n6. Conclusions\nWe present a method that addresses the optimal measurement (query) selection problem for\nsequential diagnosis and is applicable to any model-based diagnosis problem conforming to\n[de Kleer and Williams, 1987, Reiter, 1987]. In particular, given a set of leading diagnoses, we\nallow a query to be optimized along two dimensions, i.e. the estimated number of queries and the\ncost per query. We show that the optimizations of these properties can be naturally decoupled\nand considered in sequence.\nThat is, one can at first (phase P1) tackle the optimization of the query’s diagnoses discrimination properties (given by the query’s q-partition). Unlike existing methods do, this can be\naccomplished without any expensive reasoner calls and without yet knowing the actual query, as\nthe theory evolved in this work proves. The key idea underlying this theory is the exploitation\nof useful information that is already implicitly present in the set of precomputed leading diagnoses. Contrary to most sequential methods which use a pool-based approach (selection of an\noptimal query within the collection of possible queries), we demonstrate a sound and complete\nsystematic search for an optimal q-partition that enables the powerful application of heuristics\nand sound pruning techniques. Our evaluations show that thereby, on average, only a negligible fraction (less than 1%) of the space of possible q-partitions needs to be explored to find a\nq-partition that deviates negligibly from the optimal q-partition. In all of the several hundreds\nof test runs we performed with search spaces encompassing up to millions of q-partitions, an\noptimal one is found in less than 0.03 sec.\nOnce the (optimized) q-partition P from phase P1 is known, the user has two choices,\nnamely the instantaneous provision of a globally cost-optimal query associated with P over\na restricted (yet generally exponential) query search space (phase P2), or the computation of a\nquery for P including only “cost-preferred” sentences (e.g., low-cost measurements or observations from built-in sensors) over the full query search space (phase P3).\nRegarding phase P2, we prove that an optimal solution for the underlying problem can be\nfound by solving a hitting set problem over an explicitly given collection of sets to be hit and\n81\n\n\fwithout employing an inference engine. Despite the general NP-hardness of the hitting set problem, P2 turns out to be the most efficient part of the presented algorithm as we prove that the\nproblem can be viewed as fixed parameter tractable in our context. For up to tremendous numbers of 500 leading diagnoses and query search spaces of size up to over 3 million, P2 terminated\nalways within less than 0.006 sec, returning a globally optimal solution for any (monotonic set\nfunction) cost measure.\nPhase P3 performs the computation of a query that is optimized in a more sophisticated way,\ni.e. over a substantially extended search space, than the one determined by P2. To this end, the\nemployment of a logical reasoner is required. However, the premise is to minimize the reasoner\ncalls for best efficiency. We prove that P3 gets along with a polynomial number of reasoner calls\nwhile it is guaranteed to provide a globally optimal query w.r.t. a cost measure that minimizes\nthe maximal cost of a single measurement in the query. We show that the latter optimization is\npossible by using an existing divide-and-conquer algorithm [Junker, 2004] for set-minimization\nunder preservation of a monotonic property with a suitably modified input.\nComprehensive experiments using real-world diagnosis problems of different size, diagnostic structure (size, number, probability of diagnoses) and (reasoning) complexity demonstrate\nthe efficiency and practicality of the proposed algorithm (phases P1, P2, P3). For instance, for\nup to 80 leading diagnoses, two optimal queries (one from P2 and one from P3) are always\nestablished in no more than 4 sec. It further turns out that optimized query computation with\nthe new approach is much faster than the computation of leading diagnoses. The time of the\nformer grows at most linearly and the time of the latter exponentially with the number of leading\ndiagnoses. Consequently, optimized query computation using our theory is a minor problem as\ncompared to diagnoses computation. This was not the case with existing (black-box) methods\nwhere the leading diagnoses (and thence the information usable for query computation) needed\nto be restricted to single-digit numbers, cf., e.g., [Shchekotykhin et al., 2012]. Regarding the reaction time r (time between two queries) of the debugging system, the new algorithm accounts\nfor less than 10 percent (P3: full query search space) and less than 3 per mill (P2: restricted\nquery search space) of r whenever r amounts to at least a fifth of a minute.\nIn comparative experiments we reveal that methods M that are as generally applicable as the\npresented one and not using the proposed theory, but applying reasoners directly and improvidently during query generation, suffer from (1) a drastic incompleteness w.r.t. the query space\n(sometimes their recall is as low as 1% due to the strong dependence on the reasoner output),\n(2) the unavoidable computation of duplicate queries (and/or q-partitions) and (3) the generation\nof substantial numbers of unnecessary query candidates (up to tens of thousands) which turn\nout to be no queries after verification. Because query verification (without the presented theory)\nrequires the reasoner, these methods manifest severe performance problems. The new method\nsolves all these issues. In fact, it does so while always consuming orders of magnitude less time\nthan M for 10 or more leading diagnoses and outputting a query which is always at least as good\nas and up to more than 99% better (regarding a query quality measure) than the one returned by\nM.\nFinally, tests involving query computations given 500 leading diagnoses (search space sizes\nin O(2500 ) in P1 alone) corroborate the scalability of the new approach. In concrete terms, opti82\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nmized queries over the restricted search space (P2) and full search space (P3) could be computed\nin less than 0.7 and 40 sec, respectively.\n\n83\n\n\fAcknowledgments\nThis work was supported by the Carinthian Science Fund (KWF) contract KWF- 3520/26767/38701.\n\nAppendix A: Proofs\nProof of Theorem 2\nProof. By definition, each maximal canonical solution KB w.r.t. DPI has the form (K \\ D) ∪ UP\nfor some D ⊆ K. We show that any K∗ is not a maximal canonical solution KB w.r.t. DPI if (*)\nK∗ cannot be constructed as (K \\ D) ∪ UP for some minimal KBD-diagnosis D w.r.t. DPI.\nLet us assume K∗ is a maximal solution KB w.r.t. DPI and K∗ cannot be constructed as\n(K \\ D) ∪ UP for any minimal KBD-diagnosis D w.r.t. DPI. Then either (a) K∗ cannot be\nconstructed as (K \\ X) ∪ UP for any set X ⊆ K, or (b) K∗ can be constructed as (K \\ X) ∪ UP\nfor some X ⊆ K where X is not a KBD-diagnosis w.r.t. DPI, or (c) K∗ can be constructed as\n(K \\ X) ∪ UP for some X ⊆ K where X is a non-minimal KBD-diagnosis w.r.t. DPI.\nCase (a) together with the definition of a canonical solution KB implies that K∗ is not a\n(maximal) canonical solution KB w.r.t. DPI, a contradiction.\nCase (b) together with Def. 10 implies that K∗ is not a (maximal canonical) solution KB\nw.r.t. DPI, a contradiction.\nCase (c): Here we have that K∗ = (K \\ X) ∪ UP is a (canonical) solution KB by Def. 10\n(and the definition of a canonical solution KB). However, due to the non-minimality of the\nKBD-diagnosis X, there must be an Xmin ⊂ X such that Xmin is a minimal KBD-diagnosis\n∗\n:= (K \\ Xmin ) ∪ UP is a (canonical) solution KB as well. Then either\nw.r.t. DPI. Hence, Kmin\n∗\n∗\n∗ .\n(c1) K = Kmin or (c2) K∗ 6= Kmin\nCase (c1): Here we derive that K∗ = (K \\ Xmin ) ∪ UP for the minimal KBD-diagnosis Xmin\nw.r.t. DPI. This contradicts the assumption that K∗ cannot be constructed as (K \\ X) ∪ UP for\nany minimal KBD-diagnosis X w.r.t. DPI.\n∗ ,\nCase (c2): Since clearly K∩K∗ = (K\\X)∪(K∩UP ) ⊆ (K\\Xmin )∪(K∩UP ) = K∩Kmin\n∗\n∗\n∗\nwe conclude that K∩K ⊂ K∩Kmin which is why K cannot be a maximal (canonical) solution\nKB by Def. 9.\nProof of Proposition 4\nProof. By the definition of D0 (X), we have that D+ (X) ∪ D− (X) ∪ D0 (X) = D, D+ (X) ∩\nD0 (X) = ∅ and D− (X) ∩ D0 (X) = ∅. Let us assume that D+ (X) ∩ D− (X) 6= ∅. Then,\nthere must be some Di ∈ D+ (X) ∩ D− (X). For Di it holds that Ki∗ |= X and (∃n ∈ N :\nKi∗ ∪ X |= n) ∨ (∃r ∈ R : Ki∗ ∪ X violates r). This implies by the idempotency of L that\n(∃n ∈ N : Ki∗ |= n) ∨ (∃r ∈ R : Ki∗ violates r). By Def. 10, we can conclude that Di is not a\ndiagnosis w.r.t. DPI. But, due to Di ∈ D+ (X) ∩ D− (X), we have that Di ∈ D and thus that Di\nis a diagnosis w.r.t. DPI due to D ⊆ minDDPI . This is a contradiction. Thus, each diagnosis in\nD is an element of exactly one set of D+ (X), D− (X), D0 (X).\n84\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nProof of Proposition 10\nProof. The statement of Prop. 10 is a direct consequence of Lemmata 1, 2 and 3 that are proven\nbelow.\nLemma 1. Let DPI := hK, B, P , N iR be a DPI, D ⊆ minDDPI and Q be any query in QD .\nThen Q ∩ ID = ∅.\nProof. Assume that Q ∩ ID 6= ∅. So, let us assume\nT that one element in Q ∩ ID is α. Let Dk be\nan arbitrary diagnosis in D. Since α ∈ ID = Di ∈D Di we can conclude that α ∈ Dk . Now,\nbecause α ∈ Q, we observe that Kk∗ ∪Q = (K\\Dk )∪B ∪UP ∪Q = (K\\(Dk \\α))∪B ∪UP ∪Q.\nHowever, as Dk \\ α ⊂ Dk due to α ∈ Dk , and because of the ⊆-minimality of the diagnosis\nDk , the KB (K \\ (Dk \\ α)) ∪ B ∪ UP must violate R or N (cf. Def. 10). In consequence of the\nmonotonicity of L, it must be the case that Kk∗ ∪ Q violates R or N as well. Hence, by Prop. 4,\nwe have that Dk ∈ D− (Q). As Dk was chosen arbitrarily among elements of D− (Q), we infer\nthat D− (Q) = D. Thence, D+ (Q) = ∅ which is a contradiction to Q being a query in QD by\nDef. 12.\nNote, since Lem. 1 holds for arbitrary queries in QD , it must in particular hold for explicitentailments queries in QD .\nLemma 2. Let DPI := hK, B, P , N iR be a DPI, D ⊆ minDDPI and Q be any query in QD\nsuch that Q ⊆ K. Then Q ∩ UD 6= ∅.\nProof. Let Dk be an arbitrary diagnosis in D. Suppose that Q ∩ UD = ∅. By assumption,\nQ ⊆ K. Hence, Q ⊆ K \\ UD . For this reason, we have that Kk∗ ⊇ K \\ Dk ⊇ K \\ UD ⊇ Q.\nBy the extensiveness of L, it holds that Kk∗ |= Q. Since Dk was arbitrarily chosen among the\nelements of D, the same must hold for all Di ∈ D. Therefore, D+ (Q) = D by Prop. 4 which\nentails that D− (Q) = ∅. The latter, due to Def. 12, contradicts the assumption that Q is a query\nin QD .\nLemma 3. Let DPI := hK, B, P , N iR be a DPI, D ⊆ minDDPI and Q be any query in QD\nsuch that Q ⊆ K. Then Q0 := Q \\ (K \\ UD ) ⊆ Q is a query in QD where PD (Q0 ) = PD (Q)\n(i.e. Q and Q0 have the same q-partition).\nProof. If Q0 = Q then the validity of the statement is trivial. Otherwise, Q0 ⊂ Q and for each\nsentence α such that α ∈ Q \\ Q0 we have that α ∈ K \\ UD . By extensiveness of L, we conclude\nthat K\\UD |= α. Let Dk be an arbitrary diagnosis in D. Then Kk∗ ⊇ (K\\UD )∪B∪UP ⊇ K\\UD .\nSo, by monotonicity of L, it holds that Kk∗ |= α for all α ∈ Q \\ Q0 and all Dk ∈ D.\nLet us now assume that PD (Q0 ) 6= PD (Q). By Prop. 8 and Q0 ⊆ Q ⊆ K, it follows\nthat D0 (Q) = D0 (Q0 ) = ∅. Therefore, either D+ (Q0 ) ⊂ D+ (Q) or D− (Q0 ) ⊂ D− (Q)\nmust be true. First, suppose some diagnosis Dk ∈ D+ (Q) such that Dk ∈\n/ D+ (Q0 ). Then,\n∗\n∗\n0\n0\nKk |= Q, but Kk 6|= Q which is a contradiction due to Q ⊆ Q. Second, suppose some\ndiagnosis Dk ∈ D− (Q) such that Dk ∈\n/ D− (Q0 ). From the latter fact we can conclude that\nKk∗ ∪ Q0 satisfies R and N . Now, due to the idempotence of L and because Kk∗ |= α for all\nα ∈ Q \\ Q0 as shown above, we can deduce that Kk∗ ∪ Q = Kk∗ ∪ Q0 ∪ (Q \\ Q0 ) is logically\n85\n\n\fequivalent to Kk∗ ∪ Q0 . Hence Kk∗ ∪ Q satisfies R and N . But this is a contradiction to the\nassumption that Dk is an element of D− (Q).\nOverall, we conclude that Q and Q0 have equal q-partitions. From that and the fact that Q is\na query in QD , we derive by Def. 12 that Q0 must be a query in QD as well.\nProof of Proposition 13\nProof. Let Q be a canonical query w.r.t. some seed S satisfying ∅ ⊂ S ⊂ D. Then, Q 6= ∅ due\nto Def. 14. Hence, it suffices to demonstrate that D+ (Q) 6= ∅ as well as D− (Q) 6= ∅ in order to\nshow that Q is a query (cf. Def. 12).\nFirst, since for all Di ∈ S it holds that Di ⊆ US , we have that K\\Di ⊇ K\\US . Due to the fact\nthat the entailment relation in the used logic L is extensive, we can derive that K \\ Di |= K \\ US .\nHence, by the monotonicity of L, also Ki∗ := (K \\ Di ) ∪ B ∪ UP |= K \\ US for all Di ∈ S.\nAs Q ⊆ K \\ US by Def. 14, it becomes evident that Ki∗ |= Q for all Di ∈ S. Therefore\nD+ (Q) ⊇ S ⊃ ∅ (cf. Prop. 4).\nSecond, (*): If US ⊂ UD , then D− (Q) 6= ∅. To see why (*) holds, we point out that the\nformer implies the existence of a diagnosis Di ∈ D which is not in S. Also, there must be some\nsentence α ∈ Di ⊆ K where α ∈\n/ US . This implies that α ∈ UD because it is in some diagnosis\nin D and that α ∈\n/ ID because clearly ID ⊆ US (due to S ⊃ ∅). Thus, α ∈ (UD \\ ID ) = DiscD .\nSince Q = (K \\ US ) ∩ DiscD by Def. 14, we find that α ∈ Q must hold. So, due to Q ⊆ K, we\nhave Ki∗ ∪ Q := (K \\ Di ) ∪ B ∪ UP ∪ Q = (K \\ Di0 ) ∪ B ∪ UP for some Di0 ⊆ Di \\ {α} ⊂ Di .\nNow, the ⊆-minimality of all diagnoses in D, and thence in particular of Di , lets us derive that\nKi∗ ∪ Q must violate N or R. This means that Di ∈ D− (Q) (cf. Prop. 4) which is why (*) is\nproven.\nFinally, let us assume that D− (Q) = ∅. By application of the law of contraposition to (*),\nthis implies that US = UD . Hence, by Def. 14, Q = (K\\UD )∩(UD \\ID ) ⊆ (K\\UD )∩(UD ) =\n∅, i.e. Q = ∅. From this we get by Def. 14 that Q is undefined and hence not a canonical query.\nAs a consequence, D− (Q) 6= ∅ must hold.\nProof of Proposition 14\nProof. From Prop. 5.3 we already know that each query Q has one and only one q-partition.\nSince each CQ Q is in particular a query (Prop. 13), it must also have one and only one qpartition.\nOn the other hand, assume that there are two CQs Q1 6= Q2 for one and the same CQP\nP. Since the only variable in the computation of a CQ is UD+ where D+ is the used seed (see\n+\nDef. 14), there must be seeds D+\n1 for Q1 and D2 for Q2 such that UD+ 6= UD+ . Hence, there\n1\n\n2\n\nmust be at least one diagnosis Dk ∈ D which is in one, but not in the other set among D+\n1 and\n+\n+\nD+\n.\nSuppose\nw.l.o.g.\nthat\nD\n∈\nD\nand\nD\n∈\n/\nD\n.\nNow,\nby\nextensiveness\nof\nL\nand\nDef.\n14\nk\nk\n2\n1\n2\n∗\nwe have that Kk = (K \\ Dk ) ∪ B ∪ UP |= (K \\ Dk ) ⊇ (K \\ UD+ ) ⊇ (K \\ UD+ ) ∩ DiscD = Q1 .\n1\n1\nFrom this we see that Kk∗ |= Q1 . That is, Dk ∈ D+ (Q1 ). Further, there must be a sentence\nα ∈ Dk such that α ∈\n/ UD+ . Clearly, α ∈ UD (since Dk ∈ D) and α ∈\n/ ID (since otherwise\n2\nα would be an element of UD+ ). Thence, α ∈ DiscD . Because Q2 = (K \\ UD+ ) ∩ (DiscD ),\n2\n\n2\n\n86\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nwe obtain that α ∈ Q2 must hold. Consequently, Kk∗ ∪ Q2 ⊇ [(K \\ Dk0 ) ∪ B ∪ UP ] for Dk0 ⊆\nDk \\ {α} ⊂ Dk . Since D includes only minimal diagnoses, we can derive that Kk∗ ∪ Q2 violates\nR or N . Thus, Dk ∈ D− (Q2 ) (cf. Prop. 4) and therefore Dk ∈\n/ D+ (Q2 ). Overall, we have\nshown that D+ (Q1 ) 6= D+ (Q2 ). This is a contradiction to P being a CQP since this implies\nthat D+ (Q1 ) = D+ (Q2 ) = D+ (P).\nThat the unique CQ associated with the CQP P is Qcan (D+ (P)) follows from the CQ’s\nuniqueness for a CQP demonstrated above and Def. 15.\nProof of Proposition 16\nProof. That h{Di }, D \\ {Di }, ∅i is a q-partition follows immediately from Prop. 5.7. We now\nshow that it is canonical, i.e. a CQP. Also from Prop. 5.7, we obtain that Q := UD \\ Di is\nan (explicit-entailments) query for the q-partition hD+ (Q), D− (Q), D0 (Q)i = h{Di }, D \\\n{Di }, ∅i. As UD ⊆ K and ID ⊆ Di , we can infer that Qcan (D+ (Q)) = (K \\ UD+ (Q) ) ∩\n(DiscD ) = (K \\ Di ) ∩ (UD \\ ID ) = UD \\ Di . Hence, Qcan (D+ (Q)) = Q which is why\nhD+ (Q), D− (Q), D0 (Q)i is a CQP.\nProof of Proposition 18\nProof. “⇒”: We prove the “only-if”-direction by contradiction. That is, we derive a contradiction by assuming that P is a canonical q-partition and that ¬(1.) or ¬(2.) is true.\nBy the premise that P = D+ , D− , D0 is a canonical q-partition, the query Qcan (D+ ) :=\n(K \\ UD+ ) ∩ DiscD must have exactly P as its q-partition, i.e. D+ (Qcan (D+ )) = D+ and\nD− (Qcan (D+ )) = D− . Moreover, (∗) : Qcan (D+ ) ⊆ K \\ UD+ ⊆ (K \\ UD+ ) ∪ B ∪ UP ⊆\n(K \\ Di ) ∪ B ∪ UP =: Ki∗ for all Di ⊆ UD+ .\nNow, assuming that (1.) is false, i.e. UD+ 6⊂ UD , we observe that this is equivalent to\nUD+ = UD since UD+ ⊆ UD due to D+ ⊆ D. Due to UD+ = UD , (∗) is true for all Di ∈ D.\nIt follows that Ki∗ ⊇ Qcan (D+ ) and, due to the fact that L is extensive, that Ki∗ |= Qcan (D+ ).\nTherefore, we can conclude that D+ = D+ (Qcan (D+ )) = D (cf. Prop. 4) and thus D− = ∅.\nThe latter is a contradiction to D− 6= ∅.\nAssuming ¬(2.), on the other hand, we obtain that there is some diagnosis Dj ∈ D− with\nDj ⊆ UD+ . By (∗), however, we can derive that Kj∗ |= Qcan (D+ ) and therefore Dj ∈\nD+ (Qcan (D+ )) = D+ which contradicts Dj ∈ D− by the fact that P is a partition w.r.t.\nD which implies D+ ∩ D− = ∅.\n“⇐”: To show the “if”-direction, we must prove that P is a canonical q-partition, i.e. that\nP is a q-partition and that P is exactly the q-partition associated with Qcan (D+ ) given that (1.)\nand (2.) hold.\nBy D+ 6= ∅ and (1.), it is true that ∅ ⊂ UD+ ⊂ UD . So, there is some sentence α ∈ UD ⊆ K\nsuch that (∗∗) : α ∈\n/ UD+ . Hence, α ∈ K \\ UD+ . Clearly, α ∈\n/ ID since otherwise α would be\nan element of UD+ . Therefore, α ∈ (K \\ UD+ ) ∩ (UD \\ ID ) = Qcan (D+ ) which is why (Q1):\nQcan (D+ ) 6= ∅.\nMore precisely, since α was an arbitrary axiom in UD with property (∗∗), we have that\nUD \\ UD+ ⊆ Qcan (D+ ). By (2.), for all Dj ∈ D− there is an axiom αj ∈ K such that\nαj ∈ Dj ⊂ UD and αj ∈\n/ UD+ which implies αj ∈ UD \\ UD+ ⊆ Qcan (D+ ). Hence,\n87\n\n\fKj∗ ∪ Qcan (D+ ) must violate R or N due to the ⊆-minimality of Dj ∈ D− . Consequently,\nD− ⊆ D− (Qcan (D+ )). As D− 6= ∅ by assumption, we have that (Q2): ∅ ⊂ D− (Qcan (D+ )).\nThat Ki∗ |= Qcan (D+ ) for Di ∈ D+ follows by the same argumentation that was used above\nin (∗). Thus, we obtain D+ ⊆ D+ (Qcan (D+ )). As D+ 6= ∅ by assumption, we have that (Q3):\n∅ ⊂ D+ (Qcan (D+ )). We have shown that (Q1), (Q2) and (Q3) hold which altogether imply\nthat Qcan (D+ ) is a query in QD (cf. Def. 12).\nNow, let us assume that at least one of the two derived subset-relations is proper, i.e. (a) D− ⊂\n−\nD (Qcan (D+ )) or (b) D+ ⊂ D+ (Qcan (D+ )). If (a) holds, then there exists some D ∈\nD− (Qcan (D+ )) which is not in D− . Hence, D ∈ D+ or D ∈ D0 . The former case is impossible since D ∈ D+ implies D ∈ D+ (Qcan (D+ )) by D+ ⊆ D+ (Qcan (D+ )) (which was\ndeduced above). From this we obtain that D− (Qcan (D+ )) ∩ D+ (Qcan (D+ )) ⊇ {D} ⊃ ∅, a\ncontradiction to the fact that Qcan (D+ ) is a query in QD and Prop. 5.1. The latter case cannot\nbe true either as D0 = ∅ by assumption. In an analogue way we obtain a contradiction if we\nassume that case (b) holds. So, it must hold that P = hD+ (Qcan (D+ )), D− (Qcan (D+ )), ∅i.\nThis finishes the proof.\nProof of Corollary 2\n(k)\n\nProof. Ad 1.: This statement follows directly from the definition of Di\n\n:= Di \\ UD+ (see\nk\n\nD+\nk.\n\nThence, this proposition can never\nEq. (20)) and the trivial fact that Di ⊆ UD+ for all Di ∈\nk\nbe false.\n−\nAd 2.: We show the contrapositive of (2.), i.e. that P := D+\nk , Dk , ∅ is not a canonical\n(k)\n\nq-partition iff Di = ∅ for some Di ∈ D−\nk:\n−\n+\n−\n“⇐”: By Prop. 18, a partition Pk = hD+\nk , Dk , ∅i with Dk , Dk 6= ∅ is a canonical q−\npartition iff (1) UD+ ⊂ UD and (2) there is no Dj ∈ Dk such that Dj ⊆ UD+ . If Dj ∈ D−\nk and\nk\n\nk\n\n(k)\n\nDj := Dj \\ UD+ = ∅, then Dj ⊆ UD+ , which violates the necessary condition (2). Therefore,\nk\nk\nPk cannot be a canonical q-partition.\n−\n+\n−\n“⇒”: By Prop. 18, a partition Pk = hD+\nk , Dk , ∅i with Dk , Dk 6= ∅ is not a canonical\n−\nq-partition iff (¬1) UD+ 6⊂ UD or (¬2) there is some Di ∈ Dk such that Di ⊆ UD+ . Since\nk\n\nk\n\n(k)\n\ncondition (¬1) is assumed to be false, condition (¬2) must be true, which implies that Di\nDi \\ UD+ = ∅ for some Di ∈ D−\nk.\n\n=\n\nk\n\nProof of Corollary 3\nProof. The statement of the corollary is a direct consequence of Lem. 4 and Def. 17.\n−\nLemma 4. Let D ⊆ minDhK,B,P ,N iR and Pk = hD+\nk , Dk , ∅i be a canonical q-partition of\nD. Then\n+\n−\n+\n1. (soundness) Pk 7→ Ps for a partition Ps := hD+\ns , Ds , ∅i of D with Ds ⊇ Dk is a\nminimal D+ -transformation if\n+\n(a) D+\n⊂ UD for some D ∈ D−\nis ⊆-minimal\ny := Dk ∪ {D} such that UD+\nk and UD+\ny\ny\n\namong all D ∈ D−\nk , and\n\n88\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\n(y)\n\n= ∅} and\n\n(y)\n\n6= ∅}.\n\n(b) D+\ns := {Di | Di ∈ D, Di\n\n(c) D−\ns := {Di | Di ∈ D, Di\n\n2. (completeness) the construction of Ps as per (1a), (1b) and (1c) yields all possible minimal D+ -transformations Pk 7→ Ps .\nProof. Ad 1.: By the definition of a minimal D+ -transformation (Def. 16), we have to show that\n+\n(i) Ps is a canonical q-partition where D+\ns ⊃ Dk and that (ii) there is no canonical q-partition\n+\n−\n+\n+\nhDl , Dl , ∅i such that Dk ⊂ Dl ⊂ D+\ns.\nAd (i): To verify that Ps is indeed a canonical q-partition, we check whether it satisfies\n−\nthe premises, D+\ns 6= ∅ and Ds 6= ∅, and both conditions of Prop. 18. The first condition, i.e.\n⊂ UD , is met due to the following argumentation. First, the inclusion of only diagnoses\nUD+\ns\n(y)\n\nDi with Di\n\n+\n. Further, D+\n6⊃ UD+\n) in D+\n= ∅ (and thus Di ⊆ UD+\ns ⊇ Dy\ns implies UD+\ny\ns\ny\n(y)\n\nmust hold since, trivially, for each Di ∈ D+\n= ∅ wherefore, by (1b),\ny it must be true that Di\nDi ∈ D+\n.\nHence,\nU\n⊇\nU\nmust\nbe\ngiven.\nCombining\nthese\nfindings\nyields UD+\n= UD+\n.\ns\nD+\nD+\ns\ny\ns\ny\nBy the postulation of UD+\n⊂ UD in (1a), we obtain UD+\n⊂ UD . This finishes the proof of the\ny\ns\nvalidity of Prop. 18,(1.).\n+\n−\nDue to UD+\n⊂ UD , we must have that D+\ns ⊂ D which implies that Ds = D \\ Ds 6= ∅.\ns\n+\n+\n+\n+\nMoreover, we have seen above that D+\ns ⊇ Dy . By definition of Dy it holds that Dy ⊃ Dk\n+\nwhich is why Ds 6= ∅. Thence, both premises of Prop. 18 are given.\nProp. 18,(2.), i.e. that there is no Di ∈ D−\n, is shown next. Each\ns such that Di ⊆ UD+\ns\n(y)\n\nDi ∈ D with Di ⊆ UD+\nfulfills Di = ∅ by UD+\n= U D+\nwhich we derived above. Thus, by\ns\ns\ny\n+\n−\nthe definition of Ds and Ds in (1b) and (1c), respectively, each Di ∈ D with Di ⊆ UD+\nmust\ns\n+\n−\nbe an element of Ds and cannot by an element of Ds . This finishes the proof of Prop. 18,(2.).\nHence, Ps is a canonical q-partition.\n+\n+\n+\nMoreover, since D+\ny := Dk ∪ {D} for some diagnosis, we obtain that Dy ⊃ Dk . But,\n+\n+\n+\n+\nbefore we argued that Ds ⊇ Dy . All in all, this yields Ds ⊃ Dk . This finishes the proof of\n(i).\nAd (ii): To show the minimality of the transformation Pk 7→ Ps , let us assume that there\n+\n+\n−\n+\nis some canonical q-partition Pl := hD+\nl , Dl , ∅i with Dk ⊂ Dl ⊂ Ds . From this, we\nimmediately obtain that UD+ ⊆ UD+\nmust hold. Furthermore, we have shown above that\ns\nl\nUD+\n= UD+\n. Due to the fact that Ps is already uniquely defined as per (1b) and (1c) given\ns\ny\n+\n. Thence, UD+ ⊂ UD+\n.\nUD+\n= UD+\nand since D+\nl 6= Ds , we conclude that UD+ ⊂ UD+\ny\ns\ns\ny\nl\n\nl\n\nAdditionally, by (1a), for all diagnoses D ∈ D−\n. However,\nk it must hold that UD+ ∪{D} 6⊂ UD+\ny\nk\n\n+\n−\nas D+\nk ⊂ Dl , there must be at least one diagnosis among those in Dk which is an element\n∗\nof D+\nl . If there is exactly one such diagnosis D , then we obtain a contradiction immediately\nas UD+ = UD+ ∪{D∗ } 6⊂ UD+\n. Otherwise, we observe that, if there is a set D0 ⊆ D−\nk of\ny\nl\n\nk\n\nmultiple such diagnoses, then there is a single diagnosis D0 ∈ D0 ⊆ D−\n=\nk such that UD+\nl\nUD+ ∪D0 ⊇ UD+ ∪{D0 } wherefore we can infer that UD+ 6⊂ UD+\nmust\nhold.\nConsequently,\nthe\ny\nl\nk\nk\ntransformation Pk 7→ Ps is indeed minimal and (ii) is proven.\n89\n\n\fAd 2.: Assume that Pk 7→ Ps is a minimal D+ -transformation and that Ps cannot be\nconstructed as per (1a), (1b) and (1c).\nBy Def. 16, Ps is a canonical q-partition. Since it is a q-partition, we have that D+\ns 6= ∅ and\n−\n⊂ UD which is why, by Cor. 2, there must be some D+\nDs 6= ∅. Thence, by Prop. 18, UD+\ny\ns\n(y)\n\n(y)\n\n+\n(e.g. D+\n= ∅} and D−\n6= ∅}.\ns ) such that Ds := {Di | Di ∈ D, Di\ns := {Di | Di ∈ D, Di\n+\n+\nThence, for each minimal D -transformation there is some Dy such that (1b) ∧ (1c) is true\nwherefore we obtain that ¬(1a) must be given. That is, at least one of the following must be\n+\n+\nis\n⊂ UD , (iii) UD+\nfalse: (i) there is some D ∈ D−\nk such that Dy = Dk ∪ {D}, (ii) UD+\ny\ny\n\n⊆-minimal among all D ∈ D−\nk.\nmust\n= UD+\nFirst, we can argue analogously as done in the proof of (1.) above that UD+\ns\ny\n⊂\nU\ncannot\nbe\nfalse.\nSo,\n(ii)\ncannot\nbe\nfalse.\nhold. This along with Prop. 18 entails that UD+\nD\ny\n+\n−\nSecond, assume that (i) is false. That is, no set D+\ny usable to construct Ds and Ds as per\n+\n−\n+\n(1b) and (1c) is defined as D+\ny = Dk ∪ {D} for any D ∈ Dk . But, clearly, Ds is one such\n+\n+\n+\nset D+\ny . And, Ds ⊃ Dk as a consequence of Pk 7→ Ps being a minimal D -transformation.\n+\n+\n+\n−\nHence, there is some set Dy ⊃ Dk usable to construct Ds and Ds as per (1b) and (1c). Now,\n+\n−\nif D+\ny = Dk ∪ {D} for some diagnosis D ∈ Dk , then we have a contradiction to ¬(i). Thus,\n−\n+\n−\nD+\ny = Dk ∪ S where S ⊆ Dk with |S| ≥ 2 must hold. In this case, there is some D ∈ Dy\n+\n+\n⊇ UD+ ∪{D} . Let Ps0 be the partition induced\nsuch that Dy ⊃ Dk ∪ {D} and therefore UD+\ny\nk\n\n+\nby D+\ny 0 := Dk ∪ {D} as per (1b) and (1c).\nThis partition Ps0 is a canonical q-partition due to Cor. 2. The latter is applicable in this case,\n+\n+\n+\n+\n+\nfirst, by reason of D−\ns 6= ∅ (which means that D ⊃ Ds ) and Ds ⊇ Ds0 ⊇ Dy 0 ⊃ Dk ⊃ ∅\n(where the first two superset-relations hold due to (1b), (1c) and Eq. (20), and the last one since\n−\nPk is a q-partition by assumption), which lets us derive D+\ns0 6= ∅ and Ds0 6= ∅. Second, from\nthe said superset-relations and Prop. 18 along with Ps being a canonical q-partition, we get\nUD ⊃ UD+\n⊇ U D+ .\ns\ns0\n\n+\n+\nBut, due to D+\ns0 ⊆ Ds we can conclude that either Pk 7→ Ps is not a minimal D +\n+\ntransformation (case D+\ns0 ⊂ Ds ) or Ps can be constructed by means of Dk ∪ {D} for some\n+\n−\n+\nD ∈ Dk (case Ds0 = Ds ). The former case is a contradiction to the assumption that Pk 7→ Ps\nis a minimal D+ -transformation. The latter case is a contradiction to |S| ≥ 2. Consequently, (i)\ncannot be false.\nThird, as (i) and (ii) have been shown to be true, we conclude that (iii) must be false. Due\n+\nto the truth of (i), we can assume that D+\ny used to construct Ps can be written as Dk ∪ {D} for\n−\n−\nsome D ∈ Dk . Now, if UD+\nis not ⊆-minimal among all D ∈ Dk , then there is some D0 ∈ D−\nk\ny\nsuch that UD+ ∪{D0 } ⊂ UD+\n.\nFurther,\ndue\nto\nU\n+ = U + ⊂ UD (because of Prop. 18 and the\nDy\nDs\ny\nk\nfact that Ps is a canonical q-partition), we get UD+ ∪{D0 } ⊂ UD .\nk\n\n+\n0\nLet Ps0 be the partition induced by D+\ny 0 := Dk ∪ {D } as per (1b) and (1c). It is guaranteed\nthat Ps0 is a canonical q-partition due to Cor. 2. The first reason why the latter is applicable here\n+\n−\nis UD+ ∪{D0 } ⊂ UD . The second one is D ∈\n/ D+\ns0 which implies Ds0 6= D and thus Ds0 6= ∅,\nk\n\n+\nand D0 ∈ D+\n/ D+\ns0 (due to (1b)) which means that Ds0 6= ∅. The fact D ∈\ns0 must hold due to\nD 6⊆ UD+ ∪{D0 } . To realize that the latter holds, assume the opposite, i.e. D ⊆ UD+ ∪{D0 } . Then,\nk\nk\nsince UD+ ⊆ UD+ ∪{D0 } and UD+ ∪{D} = UD+ ∪ D, we obtain that UD+ ∪{D0 } ⊇ UD+ ∪{D} =\nk\n\nk\n\nk\n\nk\n\n90\n\nk\n\nk\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nUD+\n, a contradiction. So, both Ps0 and Ps are canonical q-partitions. However, since Ps0 is\ny\nconstructed as per (1b),(1c) by means of UD+ ∪{D0 } and Ps as per (1b),(1c) by means of UD+\ny\nk\n\n+\n+\nand since UD+ ∪{D0 } ⊂ UD+\n, it must hold that D+\ns ⊇ Ds0 . In addition, we observe that D ∈ Ds\ny\nk\n\n+\n+\n(due to D ⊆ UD+ ∪{D} = UD+ ∪ D), but D ∈\n/ D+\ns0 (as shown above). Thence, D ∈ Ds \\ Ds0\nk\n\nk\n\n+\nwhich is why D+\ns ⊃ Ds0 . This, however, constitutes a contradiction to the assumption that\nPk 7→ Ps is a minimal D+ -transformation. Consequently, (iii) must be true.\nAltogether, we have shown that neither (i) nor (ii) nor (iii) can be false. The conclusion is\nthat (1a) and (1b) and (1c) must hold for Pk 7→ Ps , a contradiction.\n\nProof of Corollary 4\nProof. The inequality holds due to Prop. 16. We know by Prop. 15 that a canonical q-partition\nhas empty D0 . Thus, there can be only one canonical q-partition for one set D+ . Further,\nsince a canonical q-partition is a q-partition, D+ 6= ∅ and D− 6= ∅ (Prop. 5.6). Thus D+ must\nneither be the empty set nor equal to D. By Prop. 18, UD+ ⊂ UD must hold for each canonical\nq-partition. By Cor. 2, there is a unique canonical q-partition for each set UD+ , i.e. we must\ncount each UD+ only once. Further, different sets UD+ 6= UD+ clearly imply different sets D+\ni\ni\n\nj\n\nand D+\nj and thus different canonical q-partitions (Cor. 2), i.e. we do not count any canonical\nq-partition twice. Hence, we must count exactly all different UD+ such that UD+ ⊂ UD . This\nis exactly what Eq. (23) specifies.\nProof of Proposition 22\nProof. The left set inclusion follows directly from Lem. 5. The right set inclusion is a consequence of Lem. 6, which states that Q ⊆ UD \\ UD+ , and Lem. 7, which testifies that\nQcan (D+ ) = UD \\ UD+ .\nLemma 5. Let D ⊆ minDhK,B,P ,N iR , P = hD+ , D− , ∅i be a q-partition w.r.t. D and Q ⊆\nDiscD an (explicit-entailments) query for P. Then Q0 ⊆ Q is a query with q-partition P, i.e.\nPD (Q0 ) = P, iff Q0 ∩ Di 6= ∅ for each Di ∈ D− .\nProof. “⇐”: Proof by contraposition. Assume there is a Di ∈ D− such that Q0 ∩ Di = ∅. Then\nKi∗ = (K \\ Di ) ∪ B ∪ UP ⊇ Q0 since K \\ Di ⊇ DiscD \\ Di ⊇ Q0 . From this Ki∗ |= Q0 follows\nby the fact that the entailment relation in L is extensive. As a result, we have that Di ∈ D+ (Q0 ).\nConsequently, as Di ∈ D− , the q-partition PD (Q0 ) of Q0 must differ from the q-partition P of\nQ.\n“⇒”: Proof by contradiction. Assume that Q0 ⊆ Q is a query with q-partition P and\n0\nQ ∩ Di = ∅ for some Di ∈ D− . Then (K \\ Di ) ∪ Q0 = (K \\ Di ) since Q0 ⊆ Q ⊆ DiscD ⊆ K\nand Q0 ∩ Di = ∅. Therefore Ki∗ ∪ Q0 = Ki∗ which implies that Q0 ⊆ Ki∗ and thus Ki∗ |= Q0\ndue the extensive entailment relation in L. Consequently, Di ∈ D+ (Q0 ) must hold. Since\nDi ∈ D− , we can derive that the q-partition PD (Q0 ) of Q0 is not equal to the q-partition P of\nQ, a contradiction.\n\n91\n\n\fLemma 6. Let D ⊆ minDhK,B,P ,N iR , P = hD+ , D− , ∅i be a q-partition w.r.t. D and Q ⊆\nDiscD an (explicit-entailments) query associated with P. Then Q0 with DiscD ⊇ Q0 ⊇ Q is a\nquery with q-partition P, i.e. PD (Q0 ) = P, iff Q0 ⊆ UD \\ UD+ .\nProof. “⇒”: Proof by contraposition. If Q0 6⊆ UD \\ UD+ then there is an axiom α ∈ Q0 such\nthat α ∈\n/ UD \\ UD+ . This implies that α ∈ UD+ because α ∈ Q0 ⊆ DiscD = UD \\ ID which\nmeans in particular that α ∈ UD . Consequently, α ∈ Dj for some diagnosis Dj ∈ D+ must\napply which is why Kj∗ ∪ Q0 must violate R or N due to the ⊆-minimality of Dj . As a result,\nDj must belong to D− (Q0 ) and since Dj 6∈ D− , we obtain that the q-partition PD (Q0 ) of Q0 is\ndifferent from P.\n“⇐”: Direct proof. If Q0 ⊇ Q and Q0 ⊆ UD \\ UD+ , then for each Di ∈ D+ it holds that\nKi∗ |= Q0 by the fact that the entailment relation in L is extensive and as Q0 ⊆ UD \\ UD+ ⊆\nK \\ Di ⊆ Ki∗ . Hence, each Di ∈ D+ is an element of D+ (Q0 ).\nFor each Dj ∈ D− , Kj∗ ∪ Q0 must violate R or N by the monotonicity of the entailment\nrelation in L, since Kj∗ ∪ Q violates R or N , and because Q0 ⊇ Q. Thus, each Dj ∈ D− is an\nelement of D− (Q0 ).\nSo far, we have shown that D+ ⊆ D+ (Q0 ) as well as D− ⊆ D− (Q0 ). To complete the\nproof, assume that that some of these set-inclusions is proper, e.g. D+ ⊂ D+ (Q0 ). In this\ncase, by D0 = ∅, we can deduce that there is some D ∈ D− such that D ∈ D+ (Q0 ). This is\nclearly a contradiction to the fact that D− ⊆ D− (Q0 ) and the disjointness of the sets D+ (Q0 )\nand D− (Q0 ) which must hold by Prop. 5.1. The other case D− ⊂ D− (Q0 ) can be led to a\ncontradiction in an analogue way. Hence, we conclude that PD (Q0 ) = P.\nLemma 7. Let DPI = hK, B, P , N iR be a DPI, D ⊆ minDDPI and ∅ ⊂ D+ ⊂ D. Then the\ncanonical query Qcan (D+ ) w.r.t. the seed D+ is equal to UD \\ UD+ which is in turn equal to\nthe union of all traits of diagnoses in D− = D \\ D+ .\nProof. Qcan (D+ ) := DiscD ∩(K\\UD+ ) = (UD \\ID )∩(K\\UD+ ) = (UD ∩K)\\(ID ∪UD+ ) =\nUD \\ UD+ where the last equality holds due to UD ⊆ K (UD is a union of diagnoses and\ndiagnoses are subsets of K, cf. Def. 10) and ID ⊆ UD+ (ID is the intersection of all diagnoses\nin D, hence a subset of all diagnoses in D and in particular of the ones in D+ ⊂ D, hence a\nsubset of the union UD+ of diagnoses in D+ ). The equality of UD \\ UD+ to the union of all\ntraits of diagnoses in D− = D \\ D+ follows directly from Def. 17.\nProof of Proposition 25\nProof. Assume the opposite, i.e. that the q-partition PD (Q) = D+ (Q), D− (Q), D0 (Q) is\nnot canonical. Due to Q ⊆ K, Def. 12, Prop. 5.4 and the ⊆-minimality of all D ∈ D, Q must\nbe a non-empty set of common explicit entailments of all K \\ Di for Di ∈ D+ (Q). That is,\n∅ ⊂ Q ⊆ K \\ UD+ (Q) . Due to Prop. 10, Q ∩ ID = ∅. Hence, by Prop. 10, Q0 := Q \\ (K \\ UD ) =\nQ ∩ UD = (Q ∩ UD ) \\ ID = Q ∩ (UD \\ ID ) = Q ∩ DiscD has the same q-partition as Q, i.e.\nPD (Q0 ) = PD (Q). Further, we observe from these equalities that Q0 ⊆ Q and Q0 ⊆ DiscD\nmust hold. So, the canonical query Qcan (D+ (Q)) = (K \\ UD+ (Q) ) ∩ DiscD ⊇ Q0 . Hence,\nD+ (Qcan (D+ (Q))) ⊆ D+ (Q0 ) = D+ (Q) as each KB that entails Qcan (D+ (Q)) must also\nentail its subset Q0 . If D+ (Qcan (D+ (Q))) = D+ (Q), then both Qcan (D+ (Q)) and Q have the\n92\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nsame q-partition due to Prop. 8 and since both are explicit-entailments queries. This means that\nPD (Q) is canonical due to Def. 15 – contradiction. Otherwise, D+ (Qcan (D+ (Q))) ⊂ D+ (Q).\nThat is, there must be some Di ∈ D+ (Q) such that Ki∗ 6|= Qcan (D+ (Q)). But, this is a\ncontradiction to Ki∗ = (K \\ Di ) ∪ B ∪ UP ⊇ (K \\ Di ) ⊇ K \\ UD+ (Q) ⊇ K \\ UD+ (Q) ∩ DiscD =\nQcan (D+ (Q)) due to the extensiveness of L.\nProof of Theorem 7\nProof. Due to Prop. 17 and Cor. 3, phase P1 (with threshold tm := 0) finds the optimal CQP\nP∗ w.r.t. the given QSM m for the leading diagnoses D. As a consequence of Prop. 25, P∗\nis the optimal q-partition of all explicit-entailments queries Q ∈ S. Therefore, OptQ(m, S)\n(see Prob. 3) is given by {Q | Q ⊆ K, PD (Q) = P∗ }, i.e. each explicit-entailments query with\nq-partition P∗ optimizes the QSM m over all queries in S. Due to Prop. 23, the query returned\nby phase P2 is Q∗ = arg minQ∈OptQ(m,S) c(Q).\nProof of Proposition 26\nProof. Ad 1.: The function EntET either does or does not compute explicit entailments (amongst\nother entailments). In case the function EntET does not compute explicit entailments, Qexp\nclearly cannot contain any elements of K ∪ B ∪ UP . Otherwise, we distinguish between explicit\nentailments in (K \\ UD ) ∪ B ∪ UP and those in Q (clearly, there cannot be any other explicit\nentailments in Qexp ). Note that Q ⊆ UD \\ UD+ ⊆ UD since due to Prop. 22 and Lem. 7.\nAdditionally, Q ∩ B = ∅ due to Q ⊆ K and Def. 8. And, Q ∩ UP = ∅ due to Q ⊆ UD and since\nno element of any minimal diagnosis D (in D), and hence no element in UD , can occur in UP .\nThe latter holds as in case D0 ∩ UP 6= ∅ for D0 ∈ D we would have that D00 := D0 \\ UP ⊂ D0 is\na diagnosis w.r.t. hK, B, P , N iR , a contradiction to the ⊆-minimality of D0 . All in all, we have\nderived that (K \\ UD ) ∪ B ∪ UP and Q are disjoint sets.\nNow, Qexp cannot include any elements of (K \\ UD ) ∪ B ∪ UP . This must be satisfied since,\nfirst, (K \\ UD ) ∪ B ∪ UP is a subset of the left- as well as right-hand EntET () expression in the\ndefinition of Qexp (Eq. (24)) and, second, both EntET () expressions must return the same set of\nentailments of (K \\ UD ) ∪ B ∪ UP by property (d) made about the operator EntET . Therefore,\nthe set defined by the squared brackets in Eq. (24) cannot include any (explicit) entailments of\n(K \\ UD ) ∪ B ∪ UP .\nFurther on, Qexp cannot contain any elements of Q. This is guaranteed by the elimination of\nall elements of Q from the set defined by the squared brackets in Eq. (24). Finally, we summarize\nthat Qexp ∩ (K ∪ B ∪ UP ) = ∅.\nAd 2.: Clearly, by the definition of a diagnosis (Def. 10), (K \\ D) ∪ B ∪ UP is a solution\nKB w.r.t. hK, B, P , N iR for all D ∈ D. In addition, since D+ 6= ∅ (cf. Prop. 5.6), there\nmust be some diagnosis D0 ∈ D+ ⊂ D such that (K \\ D0 ) ∪ B ∪ UP |= Q. This implies that\n(K \\ D0 ) ∪ B ∪ UP ∪ Q is a solution KB w.r.t. hK, B, P , N iR since L is idempotent. By UD ⊇ D0\nand by the monotonicity of the logic L we conclude that S := (K \\ UD ) ∪ B ∪ UP ∪ Q is a\nsolution KB w.r.t. hK, B, P , N iR .\nObviously, S ⊇ Q. Moreover, S ⊆ K ∪ B ∪ UP because Q ⊆ DiscD ⊆ K. Finally, by the\nleft-hand EntET () expression in Eq. (24), we obtain that S |= Qexp .\n93\n\n\fAd 3.: Assume that S is as defined in the proof of (2.) above and that there is some αi ∈ Qexp\nsuch that S \\ Q |= αi . Then, (K \\ UD ) ∪ B ∪ UP |= αi . However, in the proof of (1.) above\nwe have derived that Qexp cannot comprise any entailments of (K \\ UD ) ∪ B ∪ UP . Hence,\nαi ∈\n/ Qexp , contradiction.\nAd 4.: This property must be met since EntET satisfies the type soundness condition (b).\nWe sum up that (1.)-(4.) holds for Qexp .\nProof of Proposition 27\nProof. Let D ∈ D+ (Q). Then, (K \\ D) ∪ B ∪ UP |= Q. Since the entailment relation in L is\nidempotent, we have that (*): (K \\ D) ∪ B ∪ UP ∪ Q ≡ (K \\ D) ∪ B ∪ UP . Further, since Qexp is\na set of entailments of (K \\ UD ) ∪ B ∪ UP ∪ Q (see left-hand EntET (.) expression in Eq. (24)),\nby the monotonicity of the entailment relation in L and because of (K \\ D) ∪ B ∪ UP ∪ Q ⊇\n(K \\ UD ) ∪ B ∪ UP ∪ Q we deduce that (K \\ D) ∪ B ∪ UP ∪ Q |= Qexp . By (*), we have that\n(K \\ D) ∪ B ∪ UP |= Qexp . Due to (K \\ D) ∪ B ∪ UP |= Q the KB (K \\ D) ∪ B ∪ UP must\nentail Q0 = Qexp ∪ Q. Thus, D ∈ D+ (Q0 ) holds.\nLet D ∈ D− (Q). Then, (K \\ D) ∪ B ∪ UP ∪ Q violates some x ∈ R ∪ N . Due to\nthe monotonicity of L and the fact that Q0 = Qexp ∪ Q ⊇ Q, we immediately obtain that\n(K \\ D) ∪ B ∪ UP ∪ Q0 violates some x ∈ R ∪ N . Thus, D ∈ D− (Q0 ).\nUp to this point, we have demonstrated that D+ (Q) ⊆ D+ (Q0 ) as well as D− (Q) ⊆\nD− (Q0 ). Since Q ⊆ DiscD , Prop. 8 ensures that D0 (Q) = ∅. At this point, an analogue\nargumentation as we gave in the last paragraph of the proof of Lem. 6 can be used to realize\nthat D+ (Q) = D+ (Q0 ), D− (Q) = D− (Q0 ) as well as D0 (Q) = D0 (Q0 ). Hence, PD (Q) =\nPD (Q0 ).\nProof of Theorem 8\nProof. By Conjecture 1, the q-partition of each query in QA0D is canonical. Along with Theorem 6\nand the premise that the optimality theshold tm is set to zero, this implies that phase P1 returns\na best q-partition among the set of all q-partitions for queries in QA0D . For if a goal q-partition\n(see definition on page 37) is found, then it features the best theoretically possible m-value and\nmust be (one of) the best q-partition(s) in QA0D . Otherwise, the entire q-partition search space\nis explored (Theorem 6) since no goal is found and the best among all visited q-partitions is\nreturned. Since the QSM of a query depends only on its q-partition, we obtain that OptQ(m, S)\n(see Prob. 3) is optimized over S = QA0D . By Cor. 6, the QCM cmax is optimized over all queries\nfrom OptQ(m, S). This completes the proof of the first statement of the theorem. The second\nstatement is a direct consequence of Cor. 7.\n\nAppendix B: Symbols and Meanings\nTab. 7 provides an overview of the symbols used in this work and their meaning.\n94\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nSymbol\n\nMeaning\n\n2X\n\nthe powerset of X where X is a set\n\nUX\n\nthe union of all elements in X where X is a collection of sets\n\nIX\n\nthe intersection of all elements in X where X is a collection of sets\n\nL\n\na (monotonic, idempotent, extensive) logical knowledge representation language\n\nK\n\na (usually faulty) KB over L\n\nα(i)\n\na sentence over L (optionally with an index)\n\nB\n\na (correct) background KB over L\n\nP\n\nthe set of positive test cases (each test case is a set of sentences)\n\np(i)\n\na positive test case (optionally with an index)\n\nN\n\nthe set of negative test cases (each test case is a set of sentences)\n\nn(i)\n\na negative test case (optionally with an index)\n\nR\n\na set of (logical) requirements to the correct KB including at least consistency\n\nhK, B, P , N iR\n\na (KBD) diagnosis problem instance (DPI)\n\nallDX\n\nthe set of all diagnoses w.r.t. the (KBD-)DPI X\n\nminDX\n\nthe set of minimal diagnoses w.r.t. the (KBD-)DPI X\n\nD\n\na set of leading diagnoses where D ⊆ minDX for a given DPI X\n\nD(i)\n\na diagnosis (optionally with index i)\n\nC(i)\n\na conflict (optionally with index i)\n\nKi∗\nD+ (Q)\n\n(K \\ Di ) ∪ B ∪ UP\n/\n\nD− (Q)\n\n/\n\nD0 (Q)\n\nQD\n\nthe set of all queries w.r.t. the leading diagnoses D\n\b\nQ | Q ∈ QD , D0 (Q) = ∅\n\nQ0D\nC\n\nthe q-partition D+ (Q), D− (Q), D0 (Q) of query Q ∈ QD\n\nPD (Q)\nD+ (P)\n\nthe diagnoses predicting the positive / the negative / no answer of Q\n\n/\n\nD− (P)\n\n/\n\nD0 (P)\n\nthe leftmost / middle / rightmost entry of the q-partition P\n\nQcan (S)\n\nthe canonical query (CQ) w.r.t. seed ∅ ⊂ S ⊂ D\n\nCQPD\n\nthe set of canonical q-partitions (CQPs) w.r.t. the leading diagnoses D\n\nm\n\na query selection measure (QSM) estimating each query’s diagnoses discrimination strength\n\nc\n\na query cost measure (QSM) assigning (measurement / answering) costs to each query\n\nDiscD\n(k)\n\nthe discrimination sentences UD \\ ID w.r.t. the leading diagnoses D\n\nDi\n\nthe trait Di \\ UD+ of Di w.r.t. Pk\n\nMHS(X)\n\nthe set of all minimal hitting sets of a collection of sets X\n\np(D)\n\nthe probability of a diagnosis D\n\np(X)\n\nthe sum of probabilities of diagnoses in X where X is a set of diagnoses\n\nk\n\nTable 7: Symbols, abbreviations and their meaning.\n\nReferences\nRui Abreu, Peter Zoeteweij, and Arjan JC Van Gemund. Simultaneous debugging of software\nfaults. Journal of Systems and Software, 84(4):573–586, 2011.\nFaisal N Abu-Khzam. A kernelization algorithm for d-hitting set. Journal of Computer and\nSystem Sciences, 76(7):524–531, 2010.\n95\n\n\fFranz Baader, Diego Calvanese, Deborah L McGuinness, Daniele Nardi, and Peter F PatelSchneider, editors. The Description Logic Handbook: Theory, Implementation, and Applications. Cambridge University Press, 2007.\nGerhard Brewka. Preferred subtheories: An extended logical framework for default reasoning.\nIn IJCAI’89, volume 89, pages 1043–1048, 1989.\nMark Brodie, Irina Rish, Sheng Ma, and Natalia Odintsova. Active probing strategies for problem diagnosis in distributed systems. In IJCAI’03, pages 1337–1338, 2003.\nTom Bylander, Dean Allemang, Michael Tanner, and John Josephson. The computational complexity of abduction. Artif. Intell., 49:25–60, 1991.\nJohn Ceraso and Angela Provitera. Sources of error in syllogistic reasoning. Cognitive Psychology, 2(4):400–410, 1971.\nStefano Ceri, Georg Gottlob, and Letizia Tanca. What you always wanted to know about Datalog\n(and never dared to ask). IEEE Transactions on Knowledge and Data Engineering, I(1), 1989.\nKarthekeyan Chandrasekaran, Richard Karp, Erick Moreno-Centeno, and Santosh Vempala. Algorithms for implicit hitting set problems. In Proc. 22nd annual ACM-SIAM symposium on\nDiscrete Algorithms, pp. 614–629. Society for Industrial and Applied Mathematics, 2011.\nChin-Liang Chang and Richard Char-Tung Lee. Symbolic Logic and Mechanical Theorem Proving. Academic Press Inc., 1973.\nStephen A Cook. The complexity of theorem-proving procedures. In Proc. 3rd annual ACM\nsymposium on Theory of computing, pp. 151–158. ACM, 1971.\nAdnan Darwiche and Gregory Provan. Exploiting system structure in model-based diagnosis\nof discrete-event systems. In Proc. 7th Intl. Workshop on Principles of Diagnosis, volume\n95105, 1996.\nRandall Davis and Walter Hamscher. Model-based reasoning: Troubleshooting. Exploring\nArtificial Intelligence, 8:297–346, 1988.\nJohan de Kleer. Problem solving with the atms. Artif. Intell., 28(2):197–224, 1986.\nJohan de Kleer. Focusing on probable diagnoses. In AAAI’91, pp. 842–848, 1991.\nJohan de Kleer and James Kurien. Fundamentals of model-based diagnosis. In Proc. 5th IFAC\nSymposium on Fault Detection, Supervision, and Safety of Technical Processes (Safeprocess),\npp. 25–36, 2004.\nJohan de Kleer and Olivier Raiman. How to diagnose well with very little information. In\nWorking Notes 4th Intl. Workshop on Principles of Diagnosis, pp. 160–165, 1993.\nJohan de Kleer and Raymond Reiter. Foundations for assumption-based truth maintenance systems: Preliminary report. In AAAI’87, pp. 183–188, 1987.\n96\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nJohan de Kleer and Brian C Williams. Diagnosing multiple faults. Artif. Intell., 32(1):97–130,\n1987.\nJohan de Kleer and Brian C Williams. Diagnosis with behavioral modes. In IJCAI’89, pp.\n1324–1330, 1989.\nJohan de Kleer, Alan K Mackworth, and Raymond Reiter. Characterizing diagnoses and systems. Artif. Intell., 56, 1992a.\nJohan de Kleer, Olivier Raiman, and Mark Shirley. One step lookahead is pretty good. In\nReadings in model-based diagnosis, pp. 138–142, 1992b.\nRina Dechter. Constraint processing. Morgan Kaufmann, 2003.\nRodney G Downey and Michael R Fellows. Fundamentals of parameterized complexity, volume 4. Springer, 2013.\nOskar Dressler and Peter Struss. The consistency-based approach to automated diagnosis of\ndevices. Principles of Knowledge Representation, pp. 269–314, 1996.\nAlexander Feldman, Gregory M Provan, and Arjan JC van Gemund. Solving strong-fault diagnostic models by model relaxation. In IJCAI’09, pp. 785–790, 2009.\nAlexander Feldman, Gregory M Provan, and Arjan JC van Gemund. A model-based active\ntesting approach to sequential diagnosis. JAIR, 39:301–334, 2010.\nAlexander Felfernig, Gerhard Friedrich, Dietmar Jannach, and Markus Stumptner. Consistencybased diagnosis of configuration knowledge bases. Artif. Intell., 152(2):213–234, 2004a.\nAlexander Felfernig, Gerhard Friedrich, Dietmar Jannach, and Markus Stumptner. Consistencybased diagnosis of configuration knowledge bases. Artif. Intell., 152(2):213 – 234, 2004b.\nAlexander Felfernig, Gerhard Friedrich, Karl Isak, Kostyantyn Shchekotykhin, Erich Teppan,\nand Dietmar Jannach. Automated debugging of recommender user interface descriptions.\nApplied Intelligence, 31(1):1–14, 2009.\nGerhard Friedrich and Kostyantyn Shchekotykhin. A General Diagnosis Method for Ontologies.\nIn ISWC’05, pp. 232–246, 2005.\nAlberto Gonzalez-Sanchez, Rui Abreu, Hans-Gerhard Gross, and Arjan JC van Gemund.\nSpectrum-based sequential diagnosis. In AAAI’11, pp. 189–196, 2011.\nBernardo Cuenca Grau, Ian Horrocks, Boris Motik, Bijan Parsia, Peter F Patel-Schneider, and\nUlrike Sattler. OWL 2: The next step for OWL. Web Semantics: Science, Services and Agents\non the World Wide Web, 6(4):309–322, 2008.\nRussell Greiner, Barbara A Smith, and Ralph W Wilkerson. A correction to the algorithm in\nReiter’s theory of diagnosis. Artif. Intell., 41(1):79–88, 1989.\n97\n\n\fDavid Heckerman, John S Breese, and Koos Rommelse. Decision-theoretic troubleshooting.\nCommunications of the ACM, 38(3):49–57, 1995.\nMatthew Horridge. Justification based Explanation in Ontologies. PhD thesis, University of\nManchester, 2011.\nMatthew Horridge, Bijan Parsia, and Ulrike Sattler. Laconic and Precise Justifications in OWL.\nIn ISWC’08, pp. 323–338, 2008.\nMatthew Horridge, Samantha Bail, and Bijan Parsia. The cognitive complexity of OWL justifications. In ISWC’11, 2011.\nMatthew Horridge, Bijan Parsia, and Ulrike Sattler. Extracting justifications from BioPortal\nontologies. In ISWC’12, pp. 287–299, 2012.\nLaurent Hyafil and Ronald L Rivest. Constructing optimal binary decision trees is NP-complete.\nInformation processing letters, 5(1):15–17, 1976.\nYun-Fei Jiang and Li Lin. The computation of hitting sets with boolean formulas. Chinese\nJournal of Computers, 26(8):919–924, 2003.\nUlrich Junker. QUICKXPLAIN: Preferred Explanations and Relaxations for Over-Constrained\nProblems. In AAAI’04, volume 3, pp. 167–172. AAAI Press / The MIT Press, 2004.\nAditya Kalyanpur. Debugging and Repair of OWL Ontologies. PhD thesis, University of Maryland, College Park, 2006.\nAditya Kalyanpur, Bijan Parsia, Evren Sirin, and Bernardo Cuenca Grau. Repairing Unsatisfiable Concepts in OWL Ontologies. In The Semantic Web: Research and Applications, 3rd\nEuropean Semantic Web Conference, ESWC 2006, volume 4011 of Lecture Notes in Computer\nScience, pp. 170–184, Springer, 2006.\nRichard M Karp. Reducibility among combinatorial problems. Complexity of Computer Computations, pp. 85–103, 1972.\nYevgeny Kazakov, Markus Krötzsch, and František Simančík. The incredible ELK. Journal of\nautomated reasoning, 53(1):1–61, 2014.\nMarkus Krötzsch. Efficient inferencing for OWL EL. In JELIA, volume 6341, pp. 234–246.\nSpringer, 2010.\nDonald E Knuth. The Art of Computer Programming: Fundamental Algorithms, volume 1.\nAddison Wesley Longman, 1997.\nDavid G Luenberger and Yinyu Ye. Linear and Nonlinear Programming. Springer Publishing\nCompany, Inc., 2015.\nJoao Marques-Silva, Mikoláš Janota, and Anton Belov. Minimal sets over monotone predicates in boolean formulae. In Intl. Conference on Computer Aided Verification, pp. 592–607.\nSpringer, 2013.\n98\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nCristinel Mateis, Markus Stumptner, Dominik Wieland, and Franz Wotawa. Model-Based Debugging of Java Programs. In AADEBUG’00, 2000.\nBernard ME Moret. Decision trees and diagrams. ACM Computing Surveys (CSUR), 14(4):\n593–623, 1982.\nBoris Motik, Peter F Patel-Schneider, and Bijan Parsia. OWL 2 Web Ontology Language Structural Specification and Functional-Style Syntax. W3C recommendation, pp. 1–133, 2009.\nNatalya F Noy, Michael Sintek, Stefan Decker, Monica Crubézy, Ray W Fergerson, and Mark A\nMusen. Creating Semantic Web Contents with Protégé-2000. IEEE Intelligent Systems, 16\n(2):60–71, 2000.\nNatalya F Noy, Nigam H Shah, Patricia L Whetzel, et al. Bioportal: ontologies and integrated\ndata resources at the click of a mouse. Nucleic acids research, 37(suppl 2):170–173, 2009.\nBijan Parsia, Evren Sirin, and Aditya Kalyanpur. Debugging OWL ontologies. In WWW’05, pp.\n633–640, 2005.\nPeter F Patel-Schneider, Patrick Hayes, Ian Horrocks, et al. OWL Web Ontology Language\nSemantics and Abstract Syntax. W3C recommendation, 10, 2004.\nKrishna R Pattipati and Mark G Alexandridis. Application of heuristic search and information\ntheory to sequential fault diagnosis. IEEE Transactions on Systems, Man, and Cybernetics,\n20(4):872–887, 1990.\nYannick Pencolé and Marie-Odile Cordier. A formal framework for the decentralised diagnosis\nof large scale discrete event systems and its application to telecommunication networks. Artif.\nIntell., 164(1):121–170, 2005.\nJurryt Pietersma, Arjan JC van Gemund, and Andre Bos. A model-based approach to sequential\nfault diagnosis. In IEEE Autotestcon, 2005, pp. 621–627, 2005.\nIngo Pill and Thomas Quaritsch. Optimizations for the boolean approach to computing minimal\nhitting sets. In ECAI’12, pp. 648–653. IOS Press, 2012.\nWillard V Quine. The problem of simplifying truth functions. The American Mathematical\nMonthly, 59(8):521–531, 1952.\nJohn R Quinlan. Induction of Decision Trees. Machine Learning, 1(1):81–106, 1986.\nRaymond Reiter. A Theory of Diagnosis from First Principles. Artif. Intell., 32(1):57–95, 1987.\nMarco M Ribeiro. Belief Revision in Non-Classical Logics. SpringerBriefs in Computer Science.\nSpringer London, 2012.\nPatrick Rodler. Interactive Debugging of Knowledge Bases. PhD thesis, Alpen-Adria Universität\nKlagenfurt, 2015. http://arxiv.org/pdf/1605.05950v1.pdf.\n99\n\n\fPatrick Rodler. Towards better response times and higher-quality queries in interactive\nknowledge base debugging. Technical report, Alpen-Adria Universität Klagenfurt, 2016.\nhttp://arxiv.org/pdf/1609.02584v2.pdf.\nPatrick Rodler. On active learning strategies for sequential diagnosis. In DX’17, page (to appear),\n2017.\nPatrick Rodler and Konstantin Schekotihin. Reducing model-based diagnosis to knowledge base\ndebugging. In DX’17, page (to appear), 2017.\nPatrick Rodler, Kostyantyn Shchekotykhin, Philipp Fleiss, and Gerhard Friedrich. RIO: Minimizing User Interaction in Ontology Debugging. In Web Reasoning and Rule Systems, pp.\n153–167. 2013.\nPatrick Rodler, Wolfgang Schmid, and Konstantin Schekotihin. Inexpensive cost-optimized\nmeasurement proposal for sequential model-based diagnosis. In DX’17, page (to appear),\n2017.\nFrancesca Rossi, Peter Van Beek, and Toby Walsh. Handbook of constraint programming. Elsevier, 2006.\nCatherine Roussey, Oscar Corcho, and Luis Manuel Vilches-Blázquez. A catalogue of OWL\nontology antipatterns. ACM Press, 2009.\nStuart J Russell and Peter Norvig. Artificial Intelligence: A Modern Approach. Pearson Education, 3rd edition, 2010.\nThomas Schiex and Gérard Verfaillie. Nogood recording for static and dynamic constraint satisfaction problems. Intl. Journal on Artificial Intelligence Tools, 3(02):187–207, 1994.\nStefan Schlobach, Zhisheng Huang, Ronald Cornet, and Frank Harmelen. Debugging Incoherent\nTerminologies. Journal of Automated Reasoning, 39(3):317–349, 2007.\nBurr Settles. Active Learning. Morgan and Claypool Publishers, 2012.\nMojdeh Shakeri, Vijay Raghavan, Krishna R Pattipati, and Ann Patterson-Hine. Sequential\ntesting algorithms for multiple fault diagnosis. IEEE Trans. Systems, Man, and Cybernetics,\nPart A, 30(1):1–14, 2000.\nKostyantyn Shchekotykhin and Gerhard Friedrich. Query strategy for sequential ontology debugging. In ISWC’10, pp. 696–712, 2010.\nKostyantyn Shchekotykhin, Gerhard Friedrich, Philipp Fleiss, and Patrick Rodler. Interactive\nOntology Debugging: Two Query Strategies for Efficient Fault Localization. Web Semantics:\nScience, Services and Agents on the World Wide Web, 12-13:88–103, 2012.\nKostyantyn Shchekotykhin, Gerhard Friedrich, Patrick Rodler, and Philipp Fleiss. Sequential\ndiagnosis of high cardinality faults in knowledge-bases by direct diagnosis generation. In\nECAI’14, pages 813–818, 2014.\n100\n\n\fO PTIMIZED M EASUREMENTS FOR S EQUENTIAL D IAGNOSIS\n\nKostyantyn Shchekotykhin, Dietmar Jannach, and Thomas Schmitz. Mergexplain: Fast computation of multiple conflicts for diagnosis. In IJCAI’15, 2015.\nKostyantyn Shchekotykhin, Thomas Schmitz, and Dietmar Jannach. Efficient sequential modelbased fault-localization with partial diagnoses. In IJCAI’16, 2016.\nRob Shearer, Boris Motik, and Ian Horrocks. HermiT : A Highly-Efficient OWL Reasoner. In\nProc. 5th Int. Workshop on OWL: Experiences and Directions (OWLED 2008 EU), 2008.\nSajjad Siddiqi and J Huang. Sequential diagnosis by abstraction. JAIR, 41:329–365, 2011.\nEvren Sirin, Bijan Parsia, Bernardo Cuenca Grau, Aditya Kalyanpur, and Yarden Katz. Pellet:\nA practical OWL-DL reasoner. Web Semantics: Science, Services and Agents on the World\nWide Web, 5(2):51–53, 2007.\nGerald Steinbauer and Franz Wotawa. Detecting and locating faults in the control software of\nautonomous mobile robots. In IJCAI’05, pp. 1742–1743, 2005.\nHeiner Stuckenschmidt. Debugging OWL Ontologies - A Reality Check. In Proc. 6th Intl.\nWorkshop on Evaluation of Ontology-based Tools and the Semantic Web Service Challenge\n(EON), pp. 1–12, 2008.\nMarkus Stumptner and Franz Wotawa. Debugging functional programs. In IJCAI’99, pp. 1074–\n1079, 1999.\nAlfred Tarski. Logic, semantics, metamathematics: papers from 1923 to 1938. Hackett Publishing, 1983.\nDmitry Tsarkov and Ian Horrocks. FaCT++ description logic reasoner: System description. In\nIn Proc. Intl. Joint Conf. on Automated Reasoning (IJCAR 2006), pp. 292–297, 2006.\nTania Tudorache, Csongor Nyulas, Natalya F Noy, and Mark A Musen. WebProtégé : A Collaborative Ontology Editor and Knowledge Acquisition Tool for the Web. Semantic Web Journal,\n11-165, 2011.\nJules White, David Benavides, Douglas C. Schmidt, Pablo Trinidad, Brian Dougherty, and Antonio Ruiz Cortés. Automated diagnosis of feature model configurations. Journal of Systems\nand Software, 83(7):1094–1107, 2010.\nFranz Wotawa. On the relationship between model-based debugging and program slicing. Artif.\nIntell., 135(1-2):125–143, 2002.\nTom Zamir, Roni T Stern, and Meir Kalech. Using model-based diagnosis to improve software\ntesting. In AAAI’14, pp. 1135–1141, 2014.\nAlenka Zuzek, Anton Biasizzo, and Franc Novak. Sequential diagnosis tool. Microprocessors\nand Microsystems - Embedded Hardware Design, 24(4):191–197, 2000.\n\n101\n\n\f",
         "train",
         "313516",
         "59249"
        ],
        [
         "22",
         "18605",
         "cs.AI",
         "Artificial Intelligence",
         "1707.09219v4.pdf",
         "Recurrent Ladder Networks\n\narXiv:1707.09219v4 [cs.NE] 18 Dec 2017\n\nIsabeau Prémont-Schwarz, Alexander Ilin, Tele Hotloo Hao,\nAntti Rasmus, Rinu Boney, Harri Valpola\nThe Curious AI Company\n{isabeau,alexilin,hotloo,antti,rinu,harri}@cai.fi\n\nAbstract\nWe propose a recurrent extension of the Ladder networks [22] whose structure\nis motivated by the inference required in hierarchical latent variable models. We\ndemonstrate that the recurrent Ladder is able to handle a wide variety of complex\nlearning tasks that benefit from iterative inference and temporal modeling. The\narchitecture shows close-to-optimal results on temporal modeling of video data,\ncompetitive results on music modeling, and improved perceptual grouping based\non higher order abstractions, such as stochastic textures and motion cues. We\npresent results for fully supervised, semi-supervised, and unsupervised tasks. The\nresults suggest that the proposed architecture and principles are powerful tools\nfor learning a hierarchy of abstractions, learning iterative inference and handling\ntemporal information.\n\n1\n\nIntroduction\n\nMany cognitive tasks require learning useful representations on multiple abstraction levels. Hierarchical latent variable models are an appealing approach for learning a hierarchy of abstractions.\nThe classical way of learning such models is by postulating an explicit parametric model for the\ndistributions of random variables. The inference procedure, which evaluates the posterior distribution\nof the unknown variables, is then derived from the model – an approach adopted in probabilistic\ngraphical models (see, e.g., [5]).\nThe success of deep learning can, however, be explained by the fact that popular deep models focus\non learning the inference procedure directly. For example, a deep classifier like AlexNet [19] is\ntrained to produce the posterior probability of the label for a given data sample. The representations\nthat the network computes at different layers are related to the inference in an implicit latent variable\nmodel but the designer of the model does not need to know about them.\nHowever, it is actually tremendously valuable to understand what kind of inference is required by\ndifferent types of probabilistic models in order to design an efficient network architecture. Ladder\nnetworks [22, 28] are motivated by the inference required in a hierarchical latent variable model. By\ndesign, the Ladder networks aim to emulate a message passing algorithm, which includes a bottom-up\npass (from input to label in classification tasks) and a top-down pass of information (from label to\ninput). The results of the bottom-up and top-down computations are combined in a carefully selected\nmanner.\nThe original Ladder network implements only one iteration of the inference algorithm but complex\nmodels are likely to require iterative inference. In this paper, we propose a recurrent extension\nof the Ladder network for iterative inference and show that the same architecture can be used for\ntemporal modeling. We also show how to use the proposed architecture as an inference engine in\nmore complex models which can handle multiple independent objects in the sensory input. Thus, the\nproposed architecture is suitable for the type of inference required by rich models: those that can\nlearn a hierarchy of abstractions, can handle temporal information and can model multiple objects in\nthe input.\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\n\n\fz\nl+1\nel sl\nl\n\nel\nel−1\n\ndl+1\ndl\n\nel\n\ndl\n\nel−1\n\ndl+1\n\nzt+1\n\nyt−1 yt\n\nyt+1\n\nxt\n\nxt+1\n\ny\n\nel\n\nt−1\n\nzt−1 zt\n\nx\n\ndl\n\nx̃\n\nt\n(a)\n\n(b)\n\n(c)\n\nFigure 1: (a): The structure of the Recurrent Ladder networks. The encoder is shown in red, the\ndecoder is shown in blue, the decoder-to-encoder connections are shown in green. The dashed line\nseparates two iterations t − 1 and t. (b)-(c): The type of hierarchical latent variable models for which\nRLadder is designed to emulate message passing. (b): A graph of a static model. (c): A fragment of\na graph of a temporal model. White circles are unobserved latent variables, gray circles represent\nobserved variables. The arrows represent the directions of message passing during inference.\n\n2\n\nRecurrent Ladder\n\nRecurrent Ladder networks\nIn this paper, we present a recurrent extension of the Ladder networks which is conducive to iterative\ninference and temporal modeling. Recurrent Ladder (RLadder) is a recurrent neural network whose\nunits resemble the structure of the original Ladder networks [22, 28] (see Fig. 1a). At every iteration\nt, the information first flows from the bottom (the input level) to the top through a stack of encoder\ncells. Then, the information flows back from the top to the bottom through a stack of decoder cells.\nBoth the encoder and decoder cells also use the information that is propagated horizontally. Thus, at\nevery iteration t, an encoder cell in the l-th layer receives three inputs: 1) the output of the encoder\ncell from the level below el−1 (t), 2) the output dl (t − 1) of the decoder cell from the same level from\nthe previous iteration, 3) the encoder state sl (t − 1) from the same level from the previous iteration.\nIt updates its state value sl (t) and passes the same output el (t) both vertically and horizontally:\nsl (t) = fs,l (el−1 (t), dl (t − 1), sl (t − 1))\nel (t) = fe,l (el−1 (t), dl (t − 1), sl (t − 1)) .\n\n(1)\n(2)\n\nThe encoder cell in the bottom layer typically sends observed data (possibly corrupted by noise) as\nits output e1 (t). Each decoder cell is stateless, it receives two inputs (the output of the decoder cell\nfrom one level above and the output of the encoder cell from the same level) and produces one output\ndl (t) = gl (el (t), dl+1 (t)) ,\n\n(3)\n\nwhich is passed both vertically and horizontally. The exact computations performed in the cells can\nbe tuned depending on the task at hand. In practice, we have used LSTM [15] or GRU [8] cells in the\nencoder and cells inspired by the original Ladder networks in the decoder (see Appendix A).\nSimilarly to Ladder networks, the RLadder is usually trained with multiple tasks at different abstraction levels. Tasks at the highest abstraction level (like classification) are typically formulated at the\nhighest layer. Conversely, the output of the decoder cell in the bottom level is used to formulate\na low-level task which corresponds to abstractions close to the input. The low-level task can be\ndenoising (reconstruction of a clean input from the corrupted one), other possibilities include object\ndetection [21], segmentation [3, 23], or in a temporal setting, prediction. A weighted sum of the costs\nat different levels is optimized during training.\nConnection to hierarchical latent variables and message passing\nThe RLadder architecture is designed to mimic the computational structure of an inference procedure\nin probabilistic hierarchical latent variable models. In an explicit probabilistic graphical model,\ninference can be done by an algorithm which propagates information (messages) between the nodes\nof a graphical model so as to compute the posterior distribution of the latent variables (see, e.g., [5]).\n2\n\n\fFor static graphical models implicitly assumed by the RLadder (see Fig. 1b), messages need to be\npropagated from the input level up the hierarchy to the highest level and from the top to the bottom,\nas shown in Fig. 1a. In Appendix B, we present a derived iterative inference procedure for a simple\nstatic hierarchical model to give an example of a message-passing algorithm. We also show how that\ninference procedure can be implemented in the RLadder computational graph.\nIn the case of temporal modeling, the type of a graphical model assumed by the RLadder is shown\nin Fig. 1c. If the task is to do next step prediction of observations x, an online inference procedure\nshould update the knowledge about the latent variables yt , zt using observed data xt and compute the\npredictive distributions for the input xt+1 . Assuming that the distributions of the latent variables at\nprevious time instances (τ < t) are kept fixed, the inference can be done by propagating messages\nfrom the observed variables xt and the latent variables y, z bottom-up, top-down and from the past to\nthe future, as shown in Fig. 1c. The architecture of the RLadder (Fig. 1a) is designed so as to emulate\nsuch a message-passing procedure, that is the information can propagate in all the required directions:\nbottom-up, top-down and from the past to the future. In Appendix C, we present an example of the\nmessage-passing algorithm derived for a temporal hierarchical model to show how it is related to the\nRLadders’s computation graph.\nEven though the motivation of the RLadder architecture is to emulate a message-passing procedure,\nthe nodes of the RLadder do not directly correspond to nodes of any specific graphical model.1 The\nRLadder directly learns an inference procedure and the corresponding model is never formulated\nexplicitly. Note also that using stateful encoder cells is not strictly motivated by the message-passing\nargument but in practice these skip connections facilitate training of a deep network.\nAs we mentioned previously, the RLadder is usually trained with multiple tasks formulated at\ndifferent representation levels. The purpose of tasks is to encourage the RLadder to learn the right\ninference procedure, and hence formulating the right kind of tasks is crucial for the success of training.\nFor example, the task of denoising encourages the network to learn important aspects of the data\ndistribution [1, 2]. For temporal modeling, the task of next step prediction plays a similar role. The\nRLadder is most useful in problems that require accurate inference on multiple abstraction levels,\nwhich is supported by the experiments presented in this paper.\nRelated work\nThe RLadder architecture is similar to that of other recently proposed models for temporal modeling\n[10, 11, 9, 27, 20]. In [9], the recurrent connections (from time t − 1 to time t) are placed in the\nlateral links between the encoder and the decoder. This can make it easier to extend an existing\nfeed-forward network architecture to the case of temporal data as the recurrent units do not participate\nin the bottom-up computations. On the other hand, the recurrent units do not receive information from\nthe top, which makes it impossible for higher layers to influence the dynamics of lower layers. The\narchitectures in [10, 11, 27] are quite similar to ours but they could potentially derive further benefit\nfrom the decoder-to-encoder connections between successive time instances (green links in Fig. 1b).\nThe aforementioned connections are well justified from the message-passing point of view: When\nupdating the posterior distribution of a latent variable, one should combine the latest information\nfrom the top and from the bottom, and it is the decoder that contains the latest information from the\ntop. We show empirical evidence to the importance of those connections in Section 3.1.\n\n3\n\nExperiments with temporal data\n\nIn this section, we demonstrate that the RLadder can learn an accurate inference algorithm in tasks\nthat require temporal modeling. We consider datasets in which passing information both in time and\nin abstraction hierarchy is important for achieving good performance.\n3.1\n\nOccluded Moving MNIST\n\nWe use a dataset where we know how to do optimal inference in order to be able to compare the\nresults of the RLadder to the optimal ones. To this end we designed the Occluded Moving MNIST\n1\n\nTo emphasize this, we used different shapes for the nodes of the RLadder network (Fig. 1a) and the nodes\nof graphical models that inspired the RLadder architecture (Figs. 1b-c).\n\n3\n\n\ft=1\n\nt=2\n\nt=3\n\nt=4\n\nt=5\n\nobserved frames\n\nframes with\nocclusion\nvisualized\n\noptimal temporal\nreconstruction\nFigure 2: The Occluded Moving MNIST dataset. Bottom row: Optimal temporal recombination for a\nsequence of occluded frames from the dataset.\ndataset. It consists of MNIST digits downscaled to 14 × 14 pixels flying on a 32 × 32 white\nbackground with white vertical and horizontal occlusion bars (4 pixels in width, and spaced by 8\nvisible pixels apart) which, when the digit flies behind them, occludes the pixels of the digit (see\nFig. 2). We also restrict the velocities to be randomly chosen in the set of eight discrete velocities\n{(1, ±2), (−1, ±2), (2, ±1), (−2, ±1)} pixels/frame, so that apart from the bouncing, the movement\nis deterministic. The digits are split into training, validation, and test sets according to the original\nMNIST split. The primary task is then to classify the digit which is only partially observable at any\ngiven moment, at the end of five time steps.\nIn order to do optimal classification, one would need to assimilate information about the digit identity\n(which is only partially visible at any given time instance) by keeping track of the observed pixels\n(see the bottom row of Fig. 2) and then feeding the resultant reconstruction to a classifier.\nIn order to encourage optimal inference, we add a next step prediction task to the RLadder at the\nbottom of the decoder: The RLadder is trained to predict the next occluded frame, that is the network\nnever sees the un-occluded digit. This thus mimics a realistic scenario where the ground truth is\nnot known. To assess the importance of the features of the RLadder, we also do an ablation study.\nIn addition, we compare it to three other networks. In the first comparison network, the optimal\nreconstruction of the digit from the five frames (as shown in Fig. 2) is fed to a static feed-forward\nnetwork from which the encoder of the RLadder was derived. This is our gold standard, and obtaining\nsimilar results to it implies doing close to optimal temporal inference. The second, a temporal baseline,\nis a deep feed-forward network (the one on which the encoder is based) with a recurrent neural\nnetwork (RNN) at the top only so that, by design the network can propagate temporal information\nonly at a high level, and not at a low level. The third, a hierarchical RNN, is a stack of convolutional\nLSTM units with a few convolutional layers in between, which is the RLadder amputated of its\ndecoder. See Fig. 3 and Appendix D.1 for schematics and details of the architectures.\nFully supervised learning results. The results are presented in Table 1. The first thing to notice\nis that the RLadder reaches (up to uncertainty levels) the classification accuracy obtained by the\nnetwork which was given the optimal reconstruction of the digit. Furthermore, if the RLadder does\nnot have a decoder or the decoder-to-encoder connections, or if it is trained without the auxiliary\nprediction task, we see the classification error rise almost to the level of the temporal baseline. This\nmeans that even if a network has RNNs at the lowest levels (like with only the feed-forward encoder),\nor if it does not have a task which encourages it to develop a good world model (like the RLadder\nwithout the next-frame prediction task), or if the information cannot travel from the decoder to the\nencoder, the high level task cannot truly benefit from lower level temporal modeling.\nNext, one notices from Table 1 that the top-level classification cost helps the low-level prediction\ncost in the RLadder (which in turn helps the top-level cost in a mutually beneficial cycle). This\nmutually supportive relationship between high-level and low-level inferences is nicely illustrated by\nthe example in Fig. 4. Up until time step t = 3 inclusively, the network believes the digit to be a five\n4\n\n\fxt−1\n\nxt−1\n\nxt\n\nTemporal baseline network\n\nxt−1\n\nxt\n\nx̂t\n\nHierarchical RNN\n\nxt\n\nx̂t+1\n\nRLadder\n\nFigure 3: Architectures used for modeling occluded Moving MNIST. Temporal baseline network is a\nconvolutional network with a fully connected RNN on top.\nTable 1: Performance on Occluded Moving MNIST\nClassification error (%)\nOptimal reconstruction and static classifier\n\n0.71 ± 0.03\n\nTemporal baseline\nHierarchical RNN (encoder only)\nRLadder w/o prediction task\nRLadder w/o decoder-to-encoder conn.\nRLadder w/o classification task\nRLadder\n\n2.02 ± 0.16\n1.60 ± 0.05\n1.51 ± 0.21\n1.24 ± 0.05\n0.74 ± 0.09\n\nPrediction error, ·10−5\n\n156.7 ± 0.4\n155.2 ± 2.5\n150.1 ± 0.1\n\n(Fig. 4a). As such, at t = 3, the network predicts that the top right part of the five which has been\noccluded so far will stick out from behind the occlusions as the digit moves up and right at the next\ntime step (Fig. 4b). Using the decoder-to-encoder connections, the decoder can relay this expectation\nto the encoder at t = 4. At t = 4 the encoder can compare this expectation with the actual input\nwhere the top right part of the five is absent (Fig. 4c). Without the decoder-to-encoder connections\nthis comparison would have been impossible. Using the upward path of the encoder, the network can\nrelay this discrepancy to the higher classification layers. These higher layers with a large receptive\nfield can then conclude that since it is not a five, then it must be a three (Fig. 4d). Now thanks to the\ndecoder, the higher classification layers can relay this information to the lower prediction layers so\nthat they can change their prediction of what will be seen at t = 5 appropriately (Fig. 4e). Without a\ndecoder which would bring this high level information back down to the low level, this drastic update\nof the prediction would be impossible. With this information the lower prediction layer can now\npredict that the top-left part of the three (which it has never seen before) will appear at the next time\nstep from behind the occlusion, which is indeed what happens at t = 5 (Fig. 4f).\nSemi-supervised learning results. In the following experiment, we test the RLadder in the semisupervised scenario when the training data set contains 1.000 labeled sequences and 59.000 unlabeled\nones. To make use of the unlabeled data, we added an extra auxiliary task at the top level which\nwas the consistency cost with the targets provided by the Mean Teacher (MT) model [26]. Thus,\nthe RLadder was trained with three tasks: 1) next step prediction at the bottom, 2) classification\nat the top, 3) consistency with the MT outputs at the top. As shown in Table 2, the RLadder\nimproves dramatically by learning a better model with the help of unlabeled data independently and in\naddition to other semi-supervised learning methods. The temporal baseline model also improves the\nclassification accuracy by using the consistency cost but it is clearly outperformed by the RLadder.\n3.2\n\nPolyphonic Music Dataset\n\nIn this section, we evaluate the RLadder on the midi dataset converted to piano rolls [6]. The dataset\nconsists of piano rolls (the notes played at every time step, where a time step is, in this case, an eighth\nnote) of various piano pieces. We train an 18-layer RLadder containing five convolutional LSTMs\nand one fully-connected LSTM. More details can be found in Appendix D.2. Table 3 shows the\n5\n\n\ft=1\n\nt=2\n\nt=3\n\nt=4\n\nt=5\n\nground-truth\nunoccluded\ndigits\nf\nobserved\nframes\n\nc\nb\n\ne\n\npredicted\nframes\na\n\nprobe of internal representations\n\nd\n\nFigure 4: Example prediction of an RLadder on the occluded moving MNIST dataset. First row: the\nground truth of the digit, which the network never sees and does not train on. Second row: The actual\nfive frames seen by the network and on which it trains. Third row: the predicted next frames of a\ntrained RLadder. Fourth row: A stopped-gradient (gradient does not flow into the RLadder) readout\nof the bottom layer of the decoder trained on the ground truth to probe what aspects of the digit are\nrepresented by the neurons which predict the next frame. Notice how at t = 1, the network does\nnot yet know in which direction the digit will move and so it predicts a superposition of possible\nmovements. Notice further (red annotations a-f), that until t = 3, the network thought the digit was a\nfive, but when the top bar of the supposed five did not materialize on the other side of the occlusion\nas expected at t = 4, the network immediately concluded correctly that it was actually a three.\nTable 2: Classification error (%) on semi-supervised Occluded Moving MNIST\n1k labeled\n1k labeled & 59k unlabeled\nw/o MT\nMT\n3.50 ± 0.28\n10.86 ± 0.43\n10.49 ± 0.81\n\nOptimal reconstruction and static classifier\nTemporal baseline\nRLadder\n\n3.50 ± 0.28\n10.86 ± 0.43\n5.20 ± 0.77\n\n1.34 ± 0.04\n3.14 ± 0.16\n1.69 ± 0.14\n\nnegative log-likelhoods of the next-step prediction obtained on the music dataset, where our results\nare reported as mean plus or minus standard deviation over 10 seeds. We see that the RLadder is\ncompetitive with the best results, and gives the best results amongst models outputting the marginal\ndistribution of notes at each time step.\nThe fact that the RLadder did not beat [16] on the midi datasets shows one of the limitations of\nRLadder. Most of the models in Table 3 output a joint probability distribution of notes, unlike\nRLadder which outputs the marginal probability for each note. That is to say, those models, to output\nthe probability of a note, take as input the notes at previous time instances, but also the ground truth\nof the notes to the left at the same time instance. RLadder does not do that, it only takes as input the\npast notes played. Even though, as the example in 3.1 of the the digit five turning into a three after\nseeing only one absent dot, shows that internally the RLadder models the joint distribution.\n\n4\n\nExperiments with perceptual grouping\n\nIn this section, we show that the RLadder can be used as an inference engine in a complex model which\nbenefits from iterative inference and temporal modeling. We consider the task of perceptual grouping,\nthat is identifying which parts of the sensory input belong to the same higher-level perceptual\n6\n\n\fTable 3: Negative log-likelihood (smaller is better) on polyphonic music dataset\nPiano-midi.de\n\nNottingham\n\nMuse\n\nJSB Chorales\n\n6.48\n5.54\n6.01\n5.60\n5.03\n4.34\n3.90\n\n8.51\n7.59\n6.27\n5.56\n6.10\n5.92\n5.86\n\n7.43\n\n8.76\n\n5.69 ± 0.02\n\n5.64 ± 0.02\n\nModels outputting a joint distribution of notes:\nNADE masked [4]\nNADE [4]\nRNN-RBM [6]\nRNN-NADE (HF) [6]\nLSTM-NADE [16]\nTP-LSTM-NADE [16]\nBALSTM [16]\n\n7.42\n7.05\n7.09\n7.05\n7.39\n5.49\n5.00\n\n3.32\n2.89\n2.39\n2.31\n2.06\n1.64\n1.62\n\nModels outputting marginal probabilities for each note:\nRNN [4]\nLSTM [17]\nMUT1 [17]\nRLadder\n\n7.88\n6.866\n6.792\n6.19 ± 0.02\n\n3.87\n3.492\n3.254\n2.42 ± 0.03\n\ncomponents (objects). We enhance the previously developed model for perceptual grouping called\nTagger [13] by replacing the originally used Ladder engine with the RLadder. For another perspective\non the problem see [14] which also extends Tagger to a recurrent neural network, but does so from an\nexpectation maximization point of view.\n4.1\n\nRecurrent Tagger\n\nTagger is a model designed for perceptual grouping. When applied to images, the modeling assumption is that each pixel x̃i belongs to one of the K objects, which is described by binary variables zi,k :\nzi,k = 1 if pixel i belongs to object k and zi,k = 0 otherwise. The reconstruction of the whole image\nusing object k only is µ k which is a vector with as many elements µi,k as there are pixels. Thus, the\nassumed probabilistic model can be written as follows:\nK\nY\nY\np(zk , µ k |hk )p(hk )\n(4)\np(x̃, µ , z, h) =\nN (x̃i |µi,k , σk2 )zi,k\nk=1\n\ni,k\n\nwhere zk is a vector of elements zi,k and hk is (a hierarchy of) latent variables which define the shape\nand the texture of the objects. See Fig. 5a for a graphical representation of the model and Fig. 5b\nfor possible values of model variables for the textured MNIST dataset used in the experiments of\nSection 4.2. The model in (4) is defined for noisy image x̃ because Tagger is trained with an auxiliary\nlow-level task of denoising. The inference procedure in model (4) should evaluate the posterior\ndistributions of the latent variables zk , µ k , hk for each of the K groups given corrupted data x̃.\nMaking the approximation that the variables of each of the K groups are independent a posteriori\nY\np(z, µ , h|x̃) ≈\nq(zk , µ k , hk ) ,\n(5)\nk\n\nthe inference procedure could be implemented by iteratively updating each of the K approximate\ndistributions q(zk , µ k , hk ), if the model (4) and the approximation (5) were defined explicitly.\nTagger does not explicitly define a probabilistic model (4) but learns the inference procedure directly.\nThe iterative inference procedure is implemented by a computational graph with K copies of the same\nLadder network doing inference for one of the groups (see Fig. 5c). At the end of every iteration, the\ninference procedure produces the posterior probabilities πi,k that pixel i belongs to object k and the\npoint estimates of the reconstructions µ k (see Fig. 5c). Those outputs, are used to form the low-level\ncost and the inputs for the next iteration (see more details in [13]). In this paper, we replace the\noriginal Ladder engine of Tagger with the RLadder. We refer to the new model as RTagger.\n4.2\n\nExperiments on grouping using texture information\n\nThe goal of the following experiment is to test the efficiency of RTagger in grouping objects using\nthe texture information. To this end, we created a dataset that contains thickened MNIST digits with\n7\n\n\fh1\n\nhk\n\nh2\n\nµ1\nµk\n\nµ2\n\nz1\n\nz2\n\nzk\nK\n\nK\nx\n\nx̃\n\nx\n\nx̃\n(a)\n\n(b)\n\nπ, µ\n\nx̃\n\nπ, µ\n\n(c)\n\nFigure 5: (a): Graphical model for perceptual grouping. White circles are unobserved latent variables,\ngray circles represent observed variables. (b): Examples of possible values of model variables for the\ntextured MNIST dataset. (c): Computational graph that implements iterative inference in perceptual\ngrouping task (RTagger). Two graph iterations are drawn. The plate notation represent K copies of\nthe same graph.\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\nFigure 6: (a): Example image from the Brodatz-textured MNIST dataset. (b): The image reconstruction m0 by the group that learned the background. (c): The image reeconstruction m1 by the group\nthat learned the digit. (d): The original image colored using the found grouping π k .\n20 textures from the Brodatz dataset [7]. An example of a generated image is shown in Fig. 6a. To\ncreate a greater diversity of textures (to avoid over-fitting), we randomly rotated and scaled the 20\nBrodatz textures when producing the training data.\nThe network trained on the textured MNIST dataset has the architecture presented in Fig. 5c with\nthree iterations. The number of groups was set to K = 3. The details of the RLadder architecture are\npresented in Appendix D.3. The network was trained on two tasks: The low-level segmentation task\nwas formulated around denoising, the same way as in the Tagger model [13]. The top-level cost was\nthe log-likelihood of the digit class at the last iteration.\nTable 4 presents the obtained performance on the textured MNIST dataset in both fully supervised\nand semi-supervised settings. All experiments were run over 5 seeds. We report our results as mean\nplus or minus standard deviation. In some runs, Tagger experiments did not converge to a reasonable\nsolution (because of unstable or too slow convergence), so we did not include those runs in our\nevaluations. Following [13], the segmentation accuracy was computed using the adjusted mutual\ninformation (AMI) score [29] which is the mutual information between the ground truth segmentation\nand the estimated segmentation π k scaled to give one when the segmentations are identical and zero\nwhen the output segmentation is random.\nFor comparison, we trained the Tagger model [13] on the same dataset. The other comparison method\nwas a feed-forward convolutional network which had an architecture resembling the bottom-up pass\n(encoder) of the RLadder and which was trained on the classification task only. One thing to notice is\nthat the results obtained with the RTagger clearly improve over iterations, which supports the idea that\niterative inference is useful in complex cognitive tasks. We also observe that RTagger outperforms\nTagger and both approaches significantly outperform the convolutional network baseline in which the\nclassification task is not supported by the input-level task. We have also observed that the top-level\nclassification tasks makes the RTagger faster to train in terms of the number of updates, which also\nsupports that the high-level and low-level tasks mutually benefit from each other: Detecting object\n8\n\n\fTable 4: Results on the Brodatz-textured MNIST. i-th column corresponds to the intermediate results\nof RTagger after the i-th iteration. In the fully supervised case, Tagger was only trained successfully\nin 2 of the 5 seeds, the given results are for those 2 seeds. In the semi-supervised case, we were not\nable to train Tagger successfully.\n50k labeled\n1k labeled + 49k unlabeled\nSegmentation accuracy, AMI:\nSegmentation accuracy, AMI:\nRTagger 0.55 0.75 0.80 ± 0.01\nTagger\n−\n− 0.73 ± 0.02\nRTagger 0.56 0.74 0.80 ± 0.03\nClassification error, %:\nRTagger\nTagger\nConvNet\n\n18.2\n−\n–\n\n8.0\n−\n–\n\nClassification error, %:\n5.9 ± 0.2\n12.15 ± 0.1\n14.3 ± 0.46\n\nRTagger\nConvNet\n\n63.8\n–\n\n28.2\n–\n\n22.6 ± 6.2\n88 ± 0.30\n\nFigure 7: Example of segmentation and generation by the RTagger trained on the Moving MNIST.\nFirst row: frames 0-9 is the input sequence, frames 10-15 is the ground truth future. Second row:\nNext step prediction of frames 1-9 and future frame generation (frames 10-15) by RTagger, the colors\nrepresent grouping performed by RTagger.\n\nboundaries using textures helps classify a digit, while knowing the class of the digit helps detect the\nobject boundaries. Figs. 6b-d show the reconstructed textures and the segmentation results for the\nimage from Fig. 6a.\n4.3\n\nExperiments on grouping using movement information\n\nThe same RTagger model can perform perceptual grouping in video sequences using motion cues. To\ndemonstrate this, we applied the RTagger to the moving MNIST [25]2 sequences of length 20 and the\nlow-level task was prediction of the next frame. When applied to temporal data, the RTagger assumes\nthe existence of K objects whose dynamics are independent of each other. Using this assumption,\nthe RTagger can separate the two moving digits into different groups. We assessed the segmentation\nquality by the AMI score which was computed similarly to [13, 12] ignoring the background in the\ncase of a uniform zero-valued background and overlap regions where different objects have the same\ncolor. The achieved averageAMI score was 0.75. An example of segmentation is shown in Fig. 7.\nWhen we tried to use Tagger on the same dataset, we were only able to train successfully in a single\nseed out of three. This is possibly because speed is intermediate level of abstraction not represented\nat the pixel level. Due to its reccurent connections, RTagger can keep those representations from\none time step to the next and segment accordingly, something more difficult for Tagger to do, which\nmight explain the training instability.\n\n5\n\nConclusions\n\nIn the paper, we presented recurrent Ladder networks. The proposed architecture is motivated by\nthe computations required in a hierarchical latent variable model. We empirically validated that the\nrecurrent Ladder is able to learn accurate inference in challenging tasks which require modeling\ndependencies on multiple abstraction levels, iterative inference and temporal modeling. The proposed\nmodel outperformed strong baseline methods on two challenging classification tasks. It also produced\ncompetitive results on a temporal music dataset. We envision that the purposed Recurrent Ladder\nwill be a powerful building block for solving difficult cognitive tasks.\n2\n\nFor this experiment, in order to have the ground truth segmentation, we reimplemented the dataset ourselves.\n\n9\n\n\fAcknowledgments\nWe would like to thank Klaus Greff and our colleagues from The Curious AI Company for their\ncontribution in the presented work, especially Vikram Kamath and Matti Herranen.\n\nReferences\n[1] Alain, G., Bengio, Y., and Rifai, S. (2012). Regularized auto-encoders estimate local statistics. CoRR,\nabs/1211.4246.\n[2] Arponen, H., Herranen, M., and Valpola, H. (2017). On the exact relationship between the denoising\nfunction and the data distribution. arXiv preprint arXiv:1709.02797.\n[3] Badrinarayanan, V., Kendall, A., and Cipolla, R. (2015). Segnet: A deep convolutional encoder-decoder\narchitecture for image segmentation. arXiv preprint arXiv:1511.00561.\n[4] Berglund, M., Raiko, T., Honkala, M., Kärkkäinen, L., Vetek, A., and Karhunen, J. T. (2015). Bidirectional\nrecurrent neural networks as generative models. In Advances in Neural Information Processing Systems.\n[5] Bishop, C. M. (2006). Pattern Recognition and Machine Learning (Information Science and Statistics).\nSpringer-Verlag New York, Inc., Secaucus, NJ, USA.\n[6] Boulanger-Lewandowski, N., Bengio, Y., and Vincent, P. (2012). Modeling temporal dependencies in\nhigh-dimensional sequences: Application to polyphonic music generation and transcription. In Proceedings\nof the 29th International Conference on Machine Learning (ICML-12), pages 1159–1166.\n[7] Brodatz, P. (1966). Textures: a photographic album for artists and designers. Dover Pubns.\n[8] Cho, K., Van Merriënboer, B., Bahdanau, D., and Bengio, Y. (2014). On the properties of neural machine\ntranslation: Encoder-decoder approaches. arXiv preprint arXiv:1409.1259.\n[9] Cricri, F., Honkala, M., Ni, X., Aksu, E., and Gabbouj, M. (2016). Video Ladder networks. arXiv preprint\narXiv:1612.01756.\n[10] Eyjolfsdottir, E., Branson, K., Yue, Y., and Perona, P. (2016). Learning recurrent representations for\nhierarchical behavior modeling. arXiv preprint arXiv:1611.00094.\n[11] Finn, C., Goodfellow, I. J., and Levine, S. (2016). Unsupervised learning for physical interaction through\nvideo prediction. In Advances in Neural Information Processing Systems 29.\n[12] Greff, K., Srivastava, R. K., and Schmidhuber, J. (2015). Binding via reconstruction clustering. CoRR,\nabs/1511.06418.\n[13] Greff, K., Rasmus, A., Berglund, M., Hao, T., Valpola, H., and Schmidhuber, J. (2016). Tagger: Deep\nunsupervised perceptual grouping. In Advances in Neural Information Processing Systems 29.\n[14] Greff, K., van Steenkiste, S., and Schmidhuber, J. (2017). Neural expectation maximization. In ICLR\nWorkshop.\n[15] Hochreiter, S. and Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8), 1735–\n1780.\n[16] Johnson, D. D. (2017). Generating polyphonic music using tied parallel networks. In International\nConference on Evolutionary and Biologically Inspired Music and Art.\n[17] Jozefowicz, R., Zaremba, W., and Sutskever, I. (2015). An empirical exploration of recurrent network\narchitectures. In Proceedings of the 32nd International Conference on Machine Learning (ICML-15).\n[18] Kingma, D. and Ba, J. (2015). Adam: A method for stochastic optimization. In The International\nConference on Learning Representations (ICLR), San Diego.\n[19] Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2012). Imagenet classification with deep convolutional\nneural networks. In Advances in neural information processing systems.\n\n10\n\n\f[20] Laukien, E., Crowder, R., and Byrne, F. (2016). Feynman machine: The universal dynamical systems\ncomputer. arXiv preprint arXiv:1609.03971.\n[21] Newell, A., Yang, K., and Deng, J. (2016). Stacked hourglass networks for human pose estimation. In\nEuropean Conference on Computer Vision. Springer.\n[22] Rasmus, A., Berglund, M., Honkala, M., Valpola, H., and Raiko, T. (2015). Semi-supervised learning with\nLadder networks. In Advances in Neural Information Processing Systems.\n[23] Ronneberger, O., Fischer, P., and Brox, T. (2015). U-net: Convolutional networks for biomedical image\nsegmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention.\n[24] Springenberg, J. T., Dosovitskiy, A., Brox, T., and Riedmiller, M. (2014). Striving for simplicity: The all\nconvolutional net. arXiv preprint arXiv:1412.6806.\n[25] Srivastava, N., Mansimov, E., and Salakhudinov, R. (2015). Unsupervised learning of video representations\nusing LSTMs. In International Conference on Machine Learning, pages 843–852.\n[26] Tarvainen, A. and Valpola, H. (2017). Mean teachers are better role models: Weight-averaged consistency\ntargets improve semi-supervised deep learning results. In Advances in neural information processing systems.\n[27] Tietz, M., Alpay, T., Twiefel, J., and Wermter, S. (2017). Semi-supervised phoneme recognition with\nrecurrent ladder networks. In International Conference on Artificial Neural Networks 2017.\n[28] Valpola, H. (2015). From neural PCA to deep unsupervised learning. Advances in Independent Component\nAnalysis and Learning Machines.\n[29] Vinh, N. X., Epps, J., and Bailey, J. (2010). Information theoretic measures for clusterings comparison:\nVariants, properties, normalization and correction for chance. Journal of Machine Learning Research, 11(Oct),\n2837–2854.\n\n11\n\n\fA\n\nCells used in the decoder of the RLadder\n\nDecoder cells receive two inputs: vector vtop from the top and vector h from the encoder and produce\noutput y.\nA.1\n\nG1 and convG1 cells\n\nu = BN(Avtop + b)\ns = f (u, ws )\ny = s h + (1 − s) f (u, w) ,\nwhere BN() is batch normalization and\nf (u, w) = w0 sigmoid(w1 u + w2 ) + w3 u + w4\n(6)\nwith wi being the elements of vector w and the element-wise product. In the convolutional version\nConvG1 of that cell, u in the first formula is computed with the convolution operation ∗:\nu = A ∗ vtop + b.\nA.2\n\nconvG2 cell\n\nµ 1 = f (LN(A1 ∗ vtop ) + LN(B1 ∗ h) + c1 , w1 )\nµ 2 = f (LN(A2 ∗ vtop ) + LN(B2 ∗ h) + c2 , w2 )\ns = f (LN(As ∗ vtop ) + LN(Bs ∗ h) + cs , ws )\ny = s µ 1 + (1 − s) µ 2\nwhere f is defined in (6) and LN() is layer normalization.\nA.3\n\nconvG3 cell\n\nu = relu(LN(A ∗ vtop ) + LN(B ∗ h) + c)\ns = sigmoid(Ws ∗ u)\ny = s (D ∗ u) + (1 − s) (E ∗ u) ,\nwhere LN() is layer normalization.\nA.4\n\nDetailes of normalizations used\n\nEncoder: For all the experiments all non-recurrent layers in the encoder, whether convolutional or not,\nare normalized using batch normalization. In the convolution LSTM, there is a layer normalization\nafter the all the first convolutions of the inputs in the RLadder experiments and batch normalization\nin the RTagger experiments, these normalizations were important to get things working.\nDecoder: In the decoder gating functions, there is always a layer normalization after the first\nconvolution over the concatenation of the inputs in the RLadder experiments, and this normalization\nwas replaced by batch normalization in the RTagger experiments. A normalization at this point was\ncritical for optimal performance.\n\nB\n\nExample of approximate inference in a static model\n\nThe structure of the RLadder is designed to emulate a message-passing algorithm in a hierarchical\nlatent variable model. To illustrate this, let us consider a simple hierarchical latent variable model\nwith three one-dimensional variables whose joint probability distribution is given by\np(x, y, z) = p(z)p(y|z)p(x|y)\n(7)\np(x|y) = N (x|wx y, σx2 )\np(y|z) =\np(z) =\n\nN (y|wyz z, σy2 )\nN (z|µz , σz2 ) ,\n12\n\n(8)\n(9)\n(10)\n\n\f2\nmy wyz\n,\nwyz σy2\n\nz\ny\n\ny\n\nx\n\nx\n\nx̃\n\nx̃\n\n(a)\n\nwyz mz , σ12\ny\n\nwyz mz , σ12\n\n2\nmx wx\n2\nwx , σx\n\ny\n\n2\nmx wx\n2\nwx , σx\n\nwy my , σ12\n\nx\n\nwy my , σ12\n\nx̃, σ12\n\nx\n\nx̃, σ12\nt\n\n(b)\n\n(c)\n\n2\nmy wyz\n,\nwyz σy2\n2\nmx wx\n2\nwx , σx\n2\nmx wx\n2\nw x , σx\n\nx̃, σ12\nx̃, σ12\nt+1\n\nFigure 8: (a): Simple hierarchical latent variable model. A filled node represents an observed variable.\n(b): Directions of message propagation in an inference procedure. (c): Computational graph which\nimplements an iterative inference procedure has the RLadder architecture.\nwhere N (·|m, v) denotes the Gaussian probability density function with mean m and variance v. We\nwant to derive a denoising algorithm that recovers clean observation x from its corrupted version x̃,\nwhere the corruption is also modeled to be Gaussian:\np(x̃|x) = N (x̃|x, σ 2 ) .\n(11)\nThe reason we look at denoising is because denoising is a task which can be used for unsupervised\nlearning of the data distribution [1, 2]. The graphical representation of the model shown in Fig. 8a.\nIn order to do optimal denoising, one needs to evaluate the expectation of p(x|x̃), which can be\ndone by learning the joint posterior distribution of the unknown variables x, y and z. For this linear\nGaussian model, it is possible to derive an inference algorithm that is guaranteed to produce the exact\nposterior distribution in a finite number of steps (see, e.g., [5]). However, in more complex models,\nthe posterior distribution of the latent variables is impossible to represent exactly and therefore a\nneural network that learns the inference procedure needs to represent an approximate distribution. To\nthis end, we derive an approximate inference procedure for this simple probabilistic model.\nUsing the variational Bayesian approach, we can approximate the joint posterior distribution by a\ndistribution of a simpler form. For example, all the latent variables can be modeled to be independent\nGaussian variables a posteriori:\np(x, y, z|x̃) ≈ q(x, y, z) = q(x)q(y)q(z),\n(12)\nq(x) = N (x|mx , vx ),\n(13)\nq(y) = N (y|my , vy ),\n(14)\nq(z) = N (z|mz , vz ) .\n(15)\nand the goal of the inference procedure is to estimate parameters mx , vx , my , vy , mz , vz of the\napproximate posterior (12)–(15) for the model in (7)–(11) with fixed parameters wx , σx2 , wyz , σy2 , µz ,\nσz2 , σ 2 .\nThe optimal posterior approximation q(x, y, z) can be found by minimizing the lower bound of the\nKullback-Leibler divergence between the true distribution and the approximation:\nZ\nq(x)q(y)q(z)\nCVB = log\nq(x)q(y)q(z)dydz = hlog q(x)q(y)q(z)i − hlog p(x, y, z, x̃)i (16)\np(x, y, z, x̃)\nwhere h·i denotes the expectation over q(x, y, z). This can be done with the following iterative\nprocedure:\n1\n1\nmx = sx x̃ + (1 − sx )wy my\nsx = sigmoid(log(σx2 /σ 2 ))\nvx−1 = 2 + 2 (17)\nσ\nσx\nmx\nw2\n1\nmy = sy\n+ (1 − sy )wyz mz\nsy = sigmoid(log(σy2 wx2 /σx2 ))\nvy−1 = 2x + 2 (18)\nwx\nσx\nσy\nmz = sz\n\nmy\n+ (1 − sz )µz\nwyz\n\n2\nsz = sigmoid(log(σz2 wyz\n/σy2 ))\n\n13\n\nvz−1 =\n\n2\nwyz\n1\n+ 2.\n2\nσy\nσz\n(19)\n\n\fzt−1 zt\n\nzt+1\n\nzt−1 zt\n\nzt+1\n\nm̃z,t−1\n\nm0z,t\nmz,t−1\n\nyt−1 yt\n\nyt+1\n\nyt−1 yt\n\nyt+1\n\nm̃y,t−1\n\nm0y,t\nmy,t−1\n\nxt\n\nxt+1\n\nxt\n\nxt+1\n\nxt−1\n\n(a)\n\nx̂t\nt−1\n\n(b)\n\nxt\n\nx̂t+1\n\n(c)\n\nt\n\nFigure 9: (a): Fragment of a graph of a temporal model relevant for updating the distributions of\nunknown variables after observing xt . Light-gray circles represent latent variables whose distribution\nis not updated. (b): Directions of information propagation needed for inference. (c): The structure of\nthe RLadder network can be seen as a computational graph implementing information flow in (b).\nThe dotted arrows are the skip connections that would be needed if we forced the activations to be\nliterally interpreted as the distribution parameters of the latent variables.\n\nThus, in order to update the posterior distribution of a latent variable, one needs to combine the\ninformation coming from one level above and from one level below. For example, in order to\nupdate q(y), one needs information from below (mx /wx and wx2 /σx2 ) and from above (wyz mz and\n1/σy2 ). We can think of the information needed for updating the parameters describing the posterior\ndistributions of the latent variables as ‘messages’ propagating between the nodes of a probabilistic\ngraphical model (see Fig. 8b). Since there are mutual dependencies between mx , my and mz in\n(17)–(19), the update rules need to be iterated multiple times until convergence. This procedure can\nbe implemented using the RLadder computational graph with the messages shown in Fig. 8c. Note\nthat in practice, the computations used in the cells of the RLadder are not dictated by any particular\nexplicit probabilistic model. The original Ladder networks [22] contain only one iteration of the\nbottom-up and top-down passes. The RLadder extends the model to multiple passes. Note also that\nthe computations used in the decoder (top-down pass) of the Ladder networks are inspired by the\ngating structure of the update rules (17)–(19) in simple Gaussian models.\n\nC\n\nExample of approximate inference in a simple temporal model\n\nIn this section we consider a simple hierarchical and temporal model and look at the relationship\nbetween temporal inferance in that model and the computational structure of RLadder. Consider a\nsimple probabilistic model with three levels of hierarchy xt , yt , zt in which variables vary in time\n(see Fig. 9a). The conditional distributions given the latent variables in the past yt−1 , zt−1 are defined\nas follows:\np(xt |yt ) = N (xt |wx xt−1 + wxy yt , σx2 )\n\n(20)\n\nN (yt |wy yt−1 + wyz zt , σy2 )\nN (zt |wz zt−1 , σz2 )\n\n(21)\n\np(yt |yt−1 , zt ) =\np(zt |zt−1 ) =\n\n(22)\n\nAt time t − 1 the observed variables are x1..t−1 = (x1 , ..., xt−1 ). Using the variational Bayesian\napproach, we can approximate the joint posterior distribution of the latent variables y and z by a\ndistribution of a simpler form:\np(yt−1 , zt−1 |x1..t−1 ) ≈ q(yt−1 )q(zt−1 )\nq(yt−1 ) = N (yt−1 |my,t−1 , vy,t−1 )\nq(zt−1 ) = N (zt−1 |mz,t−1 , vz,t−1 ).\nThe cost function minimized in the variational Bayesian approach is:\nCVB = hlog q(yt )q(zt ) − log p(xt |yt )p(yt |yt−1 , zt )p(zt |zt−1 ) − log p(yt−1 )p(zt−1 )i\n14\n\n\fwhere the expectation is taken over q(yt , zt , yt−1 , zt−1 , . . . , y1 , z1 ) =\nelaborate the terms of CVB . The first term is\n\nQt\n\ns=1\n\nq(ys )q(zs ). Let us\n\n\u001c\n\n1\n1\n1\n1\n− log 2πvy,t −\n(yt − my,t )2 − log 2πvz,t −\n(zt − mz,t )2\n2\n2vy,t\n2\n2vz,t\n1\n1 1\n1\n= − log 2πvy,t − − log 2πvz,t − .\n2\n2 2\n2\n\n\u001d\n\nCq =\n\nThe second term is\n\u001d\n\u001c\n1\n1\n1\n1\n2\n2\n2\n2\nCp = − − log 2πσx − 2 (xt − wx yt ) − log 2πσy − 2 (yt − wy yt−1 − wyz zt )\n2\n2σx\n2\n2σy\n\u001c\n\u001d\n1\n1\n− − log 2πσz2 − 2 (zt − wz zt−1 )2\n2\n2σz\n1\n1\n= log 2πσx2 + 2 (x2t − 2xt wx my,t + wx2 (m2y,t + vy,t ))\n2\n2σx\n1\n1\n2\n(m2z,t + vz,t )\n+ log 2πσy2 + 2 (m2y,t + vy,t + wy2 (m2y,t−1 + vy,t−1 ) + wyz\n2\n2σy\n− 2my,t wy my,t−1 − 2my,t wyz mz,t + 2wy my,t−1 wyz mz,t )\n1\n1\n+ log 2πσz2 + 2 (m2z,t + vz,t − 2mz,t wz mz,t−1 + wz2 (m2z,t−1 + vz,t−1 )) .\n2\n2σz\nThe last term is a function of variational parameters my,t−1 , mz,t−1 , vy,t−1 , vz,t−1 which we do not\nupdate at time instance t. Taking the derivative of CVB wrt the variational parameters yields:\n∂CVB\n1\n1\n= 2 (−xt wx + wx2 my,t ) + 2 (my,t − wy my,t−1 − wyz mz,t )\n∂my,t\nσx\nσy\n1\n∂CVB\n1\nw2\n=−\n+ x2 + 2\n∂vy,t\n2vy,t\n2σx\n2σy\n1\n∂CVB\nwyz\n= 2 (wyz mz,t − my,t + wy my,t−1 ) + 2 (mz,t − wz mz,t−1 )\n∂mz,t\nσy\nσz\n2\nwyz\n∂CVB\n1\n1\n=−\n+ 2 + 2.\n∂vz,t\n2vz\n2σy\n2σz\n\nEquating the derivatives to zero yields:\n\u0013−1\nwx2\n1\n+\nσx2\nσy2\n\u0012\n\u0013\nxt wx\nwy my,t−1 + wyz mz,t\n= vy,t\n+\nσx2\nσy2\n!−1\n2\nwyz\n1\n=\n+ 2\n2\nσy\nσz\n\u0012\n\u0013\n(my,t − wy my,t−1 )wyz\nwz mz,t−1\n= vz,t\n+\n.\nσy2\nσz2\n\u0012\n\nvy,t =\nmy,t\nvz,t\nmz,t\n\nThese computations can be done by first estimating my,t , mz,t before observing xt and then correcting\nusing the observation. Let us show how it is done for y. We define m0y,t to be the posterior mean\nbefore observing xt (next step decoder prediction), m̃y,t (encoder posterior) to be the posterior means\nafter observing xt but before updating the approximate posterior of higher latent variables (z in\nthis case), and finally my,t to be the posterior mean after observing xt and updating all posteriors\n15\n\n\f(decoder, same step prediction). Thus, we can write\nm0y,t = wy my,t−1 + wyz m0z,t\n\u0013\n\u0012\nm0y,t\nxt\nxt w x\n+ 2\n= sy,t\n+ (1 − sy,t )m0y,t\nm̃y,t = vy,t\n2\nσx\nσy\nwx\nsy,t = sigmoid(log(σy2 wx2 /σx2 ))\n\u0001\nwyz vy,t\nmz,t − m0z,t ,\nmy,t = m̃y,t +\n2\nσy\n\n(23)\n(24)\n(25)\n(26)\n\nwhich if we eliminate the tilded and primed m’s, give exactly the same equations as previously.\nGeneralizing the results for an arbitrary number of variables in the chain we have that for a generic\nlevel l in a hierarchical chain, we have:\nm0l,t = wl ml,t−1 + wl,l+1 m0l+1,t\nm̃l,t\n\n(27)\n\n(1 − sl )\n= m0l,t +\n(m̃l−1,t − m0l−1,t )\nwl−1,l\n\nsl =\n\n2\nwl−1,l\n2\nσl−1\n\n1\nσl2\n\n+\n\n2\nwl−1,l\n2\nσl−1\n\n2\n2\n= sigmoid(log(σl2 wl−1,l\n/σl−1\n))\n\nml,t = m̃l,t + sl wl,l+1 (ml+1,t − m0l+1,t )\n= m̃l,t + sl wl,l+1 (ml+1,t −\n\nm0l,t\n\n− wl ml,t−1\n)\nwl,l+1\n\n(28)\n\n(29)\n(30)\n(31)\n\nThese equations suggest a computational graph as shown in Fig. 9c. This is, if we literally interpret\nm̃ to be the activations of the encoder and m and m0 to be the activations of the decoder, then we\nwould conclude that we need upward-diagonal (the grey dotted arrow in Fig. 9c) decoder to encoder\nconnections, and a recurrent decoder (curved dotted arrow in Fig. 9c). But we impose no such\nconstraint, and the dotted lines are in fact only skip connections. So as long an information can be\ncopied through accross neural network layers (which it can), and as long as each layer has sufficient\ncapacity, we can remove those skip connections and retain the same computational capabilities. This\nis what is done in RLadder. However, it would be interesting to see if adding those skip connections\nhelp with training on temporal tasks.\nUsing gatings in the bottom-up computations are justified by (28). Even though the top-down updates\n(27) and (31) are simple summations in the case of this linear Gaussian model, the more general\ngatings in the top-down pass provides more flexibility for nonlinear models. The activations in the\nlevel above can select one of a few possible evolution scenarios on the level below.\nAs we discussed previously, RLadder networks are usually trained by introducing tasks that encourage\nthe network to learn the optimal inference of the latent variables. For temporal models, the natural\nlow-level task is predicting the input at the next time instance. Thus the cost is − log(p(xt+1 |x1..t )):\nCpred = (x̂t+1 − xt+1 )2\nif we assume a Gaussian distribution for x̂.\n\nD\nD.1\n\nDetails of experiments\nDetailes of experiments with Occluded Moving MNIST\n\nThe RLadder architecture trained for the occluded moving MNIST dataset is presented in Table 5.\nThe architecture of the baseline temporal model and the static feed-forward network trained on\noptimal digit reconstructions are shown in Tables 6–7. Initially, we trained the network only on the\ntraining set using the Adam optimizer [18] with an initial learning rate of 0.001. Every time the\nclassification error on the validation set rose, we divided the learning rate by 2 until a minimum value\nof 0.0001. We then trained the network using both the training and validation sets following the\nlearning rate schedule learned previously.\n16\n\n\fTable 5: Structure of RLadder for Occluded Moving MNIST\nEncoder\nLayer\n\n# channels (size)\n\n1\n1\n1\n1\n2\n1\n1\n1\n1\n2\n1\n1\n1\n2\n\n1\n32\n32\n32\n32\nMAX\n32\n64\n64\n64\nMAX\n128\n64\n32\nAVG\n16\n10\n\nInput\nConvLSTM\nConv\nConv\nConv\nPool\nConvLSTM\nConv\nConv\nConv\nPool\nConv\nConv\nConv\nPool\nLSTM\nSoftMax\n\nTable 6: Temporal baseline network for\nOccluded Moving MNIST\nLayer\nInput\nConv\nConv\nConv\nPool\nConv\nConv\nConv\nPool\nConv\nConv\nConv\nPool\nLSTM\nSoftMax\n\nDecoder\n\nStride\n\nStride\n\n# channels\n(size)\n\n1\n1\n1\n2\n1\n1\n1\n2\n1\n1\n1\n2\n\n1\n32\n32\n32\nMAX\n64\n64\n64\nMAX\n128\n64\n32\nAVG\n16\n10\n\nfilter\nsize\n\nfilter size\n(3, 3)\n(3, 3)\n(3, 3)\n(3, 3)\n(2, 2)\n(3, 3)\n(3, 3)\n(3, 3)\n(3, 3)\n(2, 2)\n(3, 3)\n(1, 1)\n(1, 1)\n(2, 2)\n\nfilter size\nconvG3\nconvG3\nconvG3\nconvG3\nconvG3\nconvG3\nconvG3\nconvG3\nconvG3\nconvG3\nconvG3\nconvG3\nconvG3\nG1\nG1\n-\n\n(9,9)\n(3, 3)\n(3, 3)\n(3, 3)\n(6, 6)\n(9, 9)\n(3, 3)\n(3, 3)\n(3, 3)\n(6, 6)\n(3, 3)\n(3, 3)\n(3, 3)\n\nTable 7: Feed-forward network in which\nthe optimal temporal reconstruction of Occluded Moving MNIST is inputed for classification\nLayer\n\n(3, 3)\n(3, 3)\n(3, 3)\n(2, 2)\n(3, 3)\n(3, 3)\n(3, 3)\n(2, 2)\n(3, 3)\n(1, 1)\n(1, 1)\n(2, 2)\n\nInput\nConv\nConv\nConv\nPool\nConv\nConv\nConv\nPool\nConv\nConv\nConv\nPool\nSoftMax\n\n17\n\nStride\n\n# channels\n(size)\n\nfilter\nsize\n\n1\n1\n1\n2\n1\n1\n1\n2\n1\n1\n1\n2\n\n1\n32\n32\n32\nMAX\n64\n64\n64\nMAX\n128\n64\n32\nAVG\n10\n\n(3, 3)\n(3, 3)\n(3, 3)\n(2, 2)\n(3, 3)\n(3, 3)\n(3, 3)\n(2, 2)\n(3, 3)\n(1, 1)\n(1, 1)\n(2, 2)\n\n\fD.2\n\nDetails of experiments with Polyphonic Music data\n\nThe RLadder architecture trained for the music dataset is presented in Table 8. We trained using\nthe Adam optimizer with a learning rate of 0.01. Because the network overfited very rapidly, we\ndetermined the optimal stopping time using the validation set and then trained on the training and\nvalidation set for the same number of epochs (between 3 and 10 depending on the hyperparameters).\nTable 8: Structure of RLadder for Polyphonic Music dataset\nEncoder\nLayer\n\nStride\n\n# channels (size)\n\n1\n2\n2\n2\n2\n2\n\n1\n32\n64\n96\n128\n160\nAVG\n96\n19\n\nInput\nConvLSTM\nConvLSTM\nConvLSTM\nConvLSTM\nConvLSTM\nPool\nLSTM\nSoftMax\n\nD.3\n\nDecoder\nfilter size\n(1, 3)\n(1, 3)\n(1, 3)\n(1, 3)\n(1, 3)\n(1, 2)\n\nfilter size\nConvG2\nConvG2\nConvG2\nConvG2\nConvG2\nG1\nG1\nIdentity\n\n(1,3)\n(1,3)\n(1,3)\n(1,3)\n(1,3)\n\nDetails of experiments with textured MNIST\n\nThe RTagger architecture used to train on Brodatz-textured MNIST data is in Table 9. The baseline\nconvolutional network is model C from [24]. The networks were trained using the Adam optimizer\nwith learning rate 0.0004. All training results were evaluated at update 160000. The size of the\nmini-batch was 16 for all the models. Batch normalization was applied to encoder and decoder layers.\nTable 9: Structure of RTagger for textured MNIST dataset\nEncoder\nLayer\nInput\nConvLSTM\nConv\nConv\nConvLSTM\nConv\nConv\nConvLSTM\nConv\nConv\nConvLSTM\nPool\nFC\n\nDecoder\n\nStride\n\n# channels (size)\n\nfilter size\n\n2\n1\n1\n2\n1\n1\n2\n1\n1\n2\n-\n\n1\n96\n96\n96\n192\n192\n192\n192\n192\n192\n11\n11\n\n(8, 8)\n(5, 5)\n(5, 5)\n(4, 4)\n(5, 5)\n(5, 5)\n(4, 4)\n(5, 5)\n(5, 5)\n(4, 4)\n(6,6)\n-\n\n18\n\nConvG1\nConvG1\nConvG1\nConvG1\nConvG1\nConvG1\nConvG1\nConvG1\nConvG1\nConvG1\nAVERAGE\nG1\n\n\f",
         "train",
         "53361",
         "9104"
        ],
        [
         "23",
         "18017",
         "cs.AI",
         "Artificial Intelligence",
         "1711.00909v1.pdf",
         "arXiv:1711.00909v1 [cs.AI] 2 Nov 2017\n\nWeight-Based Variable Ordering in the\nContext of High-Level Consistencies\nRobert J. Woodward\nBerthe Y. Choueiry\nConstraint Systems Laboratory\nUniversity of Nebraska-Lincoln, USA\n{rwoodwar|choueiry}@cse.unl.edu\nNovember 6, 2017\nAbstract\nDom/wdeg is one of the best performing heuristics for dynamic\nvariable ordering in backtrack search [Boussemart et al., 2004]. As\noriginally defined, this heuristic increments the weight of the constraint that causes a domain wipeout (i.e., a dead-end) when enforcing\narc consistency during search. “The process of weighting constraints\nwith dom/wdeg is not defined when more than one constraint lead\nto a domain wipeout [Vion et al., 2011].” In this paper, we investigate how weights should be updated in the context of two high-level\nconsistencies, namely, singleton (POAC) and relational consistencies\n(RNIC). We propose, analyze, and empirically evaluate several strategies for updating the weights. We statistically compare the proposed\nstrategies and conclude with our recommendations.\n\n1\n\nIntroduction\n\nVariable-ordering heuristics are critical for the effectiveness of backtrack\nsearch to solve Constraint Satisfaction Problems (CSPs). Common heuristics\nimplement the fail-first principal, choosing the most constrained variable as\n1\n\n\fthe next variable to assign. One such heuristic is dom/ddeg, which selects\nthe variable with the smallest ratio of its current domain to its future degree.\nA more recent heuristic, dom/wdeg, uses the weighted degree of a variable\nby assigning a weight, initially set to one, to each constraint, and incrementing this weight whenever the constraint causes a domain wipeout [Boussemart et al., 2004]. Recently, higher-level consistencies (HLC) have shown\npromise as lookahead for solving difficult CSPs [Bennaceur and Affane, 2001;\nWoodward et al., 2011; Woodward et al., 2012; Balafrej et al., 2014].\nBecause HLC algorithms typically consider more than one constraint at\nthe same time, updating the weights of the constraints in dom/wdeg is currently an open question [Vion et al., 2011]. This paper focuses on answering\nthis question in the context of two high-level consistencies, namely, PartitionOne Arc-Consistency (POAC) [Bennaceur and Affane, 2001] and Relational\nNeighborhood Inverse Consistency (RNIC) [Woodward et al., 2011]. Our\nstudy focuses on these two consistencies because they have both been shown\nto be beneficial when used for lookahead during search.\nFor POAC and RNIC we introduce four and three strategies, respectively,\nto increment the weights of the constraints. For both consistencies we find\nthat a baseline strategy corresponding to the original dom/wdeg proposal\nis statistically the worst of the proposed strategies. We conclude the highlevel consistency should influence the weights. For POAC we find that the\nproposed strategy AllS is statistically the best. For RNIC the two nonbaseline strategies are statistically equivalent.\nOther popular variable-ordering heuristics include Impact-Based Search\n[Refalo, 2004] and Activity-Based Search [Michel and Van Hentenryck, 2012].\nThese heuristics rely on information about the domain filtering resulting from\nenforcing a given consistency. Because they ignore the operations of the consistency algorithm, it is not clear how these heuristics could be used to order\nthe propagation queue of the consistency algorithm [Wallace and Freuder,\n1992; Balafrej et al., 2014]. Further, it is also not clear how to apply them\nin the context of consistency algorithms that filter the relations [Woodward\net al., 2011; Woodward et al., 2012].\nThe paper is structured as follows. Section 2 summarizes relevant background information. Section 3 introduces our weighting schemes for POAC\nand RNIC and Section 4 empirically evaluates them. Finally, Section 5 concludes the paper.\n\n2\n\n\f2\n\nBackground\n\nA Constraint Satisfaction Problem (CSP) is defined by P = (X , D, C). X\nis a set of variables where a variable xi ∈ X has a finite domain dom(xi ) ∈\nD. A constraint ci ∈ C is specified by its scope scp(ci ) and its relation\nrel(ci ). scp(ci ) is the set of variables to which ci applies and rel(ci ) is the\nset of allowed tuples. A tuple on scp(ci ) is consistent with ci if it belongs to\nQ\nrel(ci ) ∩ xi ∈scp(ci ) dom(xi ). A solution to the CSP assigns, to each variable,\na value taken from its domain such that all the constraints are satisfied. The\nproblem is to determine the existence of a solution and is known to be NPcomplete. To this day, backtrack search remains the only known sound and\ncomplete algorithm for solving CSPs [Bitner and Reingold, 1975]. Search\noperates by assigning a value to a variable and backtracks when a dead-end\nis encountered. The variable-ordering heuristic determines the order that\nvariables are assigned in search, which can be dynamic (i.e., change during\nsearch). Boussemart et al. [2004] introduced dom/wdeg, a popular dynamic\nvariable-ordering heuristic. This heuristic associates to each constraint c ∈ C\na weight wc (c), initialized to one, that is incremented by one whenever the\nconstraint causes a domain wipeout when enforcing arc consistency. The\nnext variable xi chosen by dom/wdeg is the one with the smallest ratio of\ncurrent domain size to the weighted degree, αwdeg (xi ), given by\nX\n\nαwdeg (xi ) =\n\nwc (c)\n\n(1)\n\n(c∈Cf )∧(xi ∈scp(C))\n\nwhere Cf ⊆ C is the set of constraints with at least two future variables (i.e.,\nvariables who have not been assigned by search).\nModern solvers enforce a given consistency property on the CSP after\neach variable assignment. This lookahead removes from the domains of the\nunassigned variables values that cannot participate in a solution. Such filtering prunes from the search space fruitless subtrees, reducing thrashing and\nthe size of the search space. The higher the consistency level enforced during\nlookahead, the stronger the pruning and the smaller the search space.\nThe standard property for lookahead is Generalized Arc Consistency\n(GAC) [Mackworth, 1977]. A CSP is GAC iff, for every constraint ci , and\nevery variable x ∈ scp(ci ), every value v ∈ dom(x) is consistent with ci (i.e.,\nappears in some consistent tuple of reli ). Singleton Arc-Consistency (SAC)\nensures that no domain becomes empty when enforcing GAC after assigning\na value to a variable [Debruyne and Bessière, 1997]. This operation is called\n3\n\n\fa singleton test. Algorithms for enforcing SAC remove all domain values that\nfail the singleton test. Partition-One Arc-Consistency (POAC) adds an additional condition to SAC [Bennaceur and Affane, 2001]. Let (xi , vi ) denotes\na variable-value pair, (xi , vi ) ∈ P iff vi ∈ dom(xi ). A constraint network\nP = (X , D, C) is Partition-One Arc-Consistent (POAC) iff P is SAC and for\nall xi ∈ X , for all vi ∈ dom(xi ), for all xj ∈ X, there exists vj ∈ dom(xj )\nsuch that (xi , vi ) ∈ GAC(P ∪ {xj ← vj }), where GAC(P ∪ {xj ← vj }) is\nthe CSP after assigning xj ← vj and running GAC [Bennaceur and Affane,\n2001].\nUsing the terminology of Debruyne and Bessière [1997], we say that a\nconsistency property p is stronger than p0 if in any CSP where p holds p0 also\nholds. Further, we say that p is strictly stronger than p0 if p is stronger than\np0 , and there exists at least one CSP in which p0 holds but p does not. We say\nthat p and p0 are equivalent if p is stronger than p0 , and vice versa. Finally,\nwe say that p and p0 are incomparable when there exists at least one CSP in\nwhich p holds but p0 does not, and vice versa. In practice, when a consistency\nproperty p is stronger than another p0 , enforcing p never yields less pruning\nthan enforcing p0 on the same problem. POAC is strictly stronger than SAC\nand SAC than GAC.\nBalafrej et al. [2014] introduced two algorithms for enforcing POAC:\nPOAC-1 and its adaptive version APOAC. POAC-1 operates by enforcing\nSAC. When running a singleton test on each of the values in the domain of\na given variable, POAC-1 maintains a counter for each value in the domain\nof the remaining variables to determine whether or not the corresponding\nvalue was removed by any of the singleton tests. Values that are removed by\neach of those singleton tests are identified as not POAC and removed from\ntheir respective domains. POAC-1 was found to reach quiescence faster than\nSAC. In POAC-1, all the CSP variables are singleton tested and the process\nis repeated over all the variables until a fixpoint is reached. In APOAC, the\nadaptive version of POAC-1, the process is interrupted as soon as a given\nnumber of variables are singleton tested. This number depends on input\nparameters and is updated by learning during search.\nNeighborhood Inverse Consistency (NIC) [Freuder and Elfe, 1996] ensures\nthat every value in the domain of a variable xi can be extended to a solution\nof the subproblem induced by xi and the variables in its neighborhood. In\nthe dual graph of a CSP, the vertices represent the CSP constraints and the\nedges connect vertices representing constraints whose scopes overlap. Relational Neighborhood Inverse Consistency (RNIC) [Woodward et al., 2011]\n4\n\n\fenforces NIC on the dual graph of the CSP. That is, it ensures that any tuple\nin any relation can be extended in a consistent assignment to all the relations in its neighborhood in the dual graph. NIC and RNIC are theoretically\nincomparable [Woodward et al., 2012], but RNIC has two main advantages\nover NIC. First, NIC was originally proposed for binary CSPs and the neighborhoods in NIC likely grow too large on non-binary CSPs; second, RNIC\ncan operate on different dual graph structures to save time. Three variations\nof RNIC were introduced, wRNIC, triRNIC, and wtriRNIC, which operate\non modified dual graphs. Given an instance, selRNIC uses a decision tree to\nautomatically select the dual graph for RNIC to operate on.\n\n3\n\nWeighting Schemes\n\nWe introduce weighting schemes first in the context of singleton consistencies, namely Partition-One Arc-Consistency (POAC), and then in that of relational consistencies, namely Relational Neighborhood Inverse Consistency\n(RNIC).\nEnforcing a high-level consistency (HLC) property is typically costlier\nthan enforcing GAC, but typically yields more powerful pruning. Further, it\nis often more effective, in terms of CPU time, to run a GAC before an HLC\nalgorithm [Debruyne and Bessière, 1997], as we choose to do in this paper.\n\n3.1\n\nPartition-One Arc-Consistency\n\nWe first investigate the case of POAC, which operates by initially running a\nGAC algorithm then applying the following operation to each variable until\nno change occurs. For a given variable, it applies a singleton test to each\nvalue in the domain of the variable. A singleton test assigns the value to the\nvariable and enforces GAC on the problem. We propose four strategies to\nincrement weights during POAC:\nOld: We allow only the GAC call before POAC to increment the weight of\nthe constraint that causes a domain wipeout. That is, POAC is not\nallowed to alter the weights. This strategy is the simplest and it is a\ndirect application of the original proposal [Boussemart et al., 2004]. In\nour experiments we use this strategy as a baseline and show it does not\nperform well in practice.\n\n5\n\n\fAllS: In addition to incrementing the weights according the above strategy\n(i.e., Old), we allow every singleton test to increment the weight of\na constraint whenever enforcing GAC on this constraint during the\nsingleton test directly wipes out the domain of a variable. This update\nis made at most once for each singleton test. Under this strategy, all\nconstraints that caused domain wipeouts are affected, thus, we call\nit AllS. Notice that the weight of more than one constraint may be\nupdated even though search does not have to backtrack. This behavior\ndiffers from the original proposal [Boussemart et al., 2004].\nLastS: In addition to incrementing the weights according to Old, we increment the weight of the constraint causing a domain wipeout at the\nlast singleton test on a given variable if and only if all previous singleton tests on the values of this variable have failed. Thus, we only\nincrement the weight of a single constraint and do so only when search\nhas to backtrack, which conforms to the spirit of the original heuristic.\nNotice, the order of values singleton tested affects this strategy.\nVar: This strategy encapsulates Old as a first step and increments the\nweight of the variable on which all singleton tests have failed (thus\nforcing search to backtrack). In order to implement this strategy we\nadd a counter for the weight of each variable wv , initially zero. When\na variable fails all of its singleton tests during propagation the counter\nwv for that variable is incremented by one. We propose to integrate wv\nwith the weighted degree function of dom/wdeg as follows:\nVar\nαwdeg\n(xi ) = wv (xi ) +\n\nX\n\nwc (c)\n\n(2)\n\n(c∈Cf )∧(xi ∈scp(c))\n\nwhere Cf ⊆ C is the set of constraints with at least two future variables. The rationale behind this strategy is the following. The goal of\nthe heuristic dom/wdeg is to identify the conflicts in the problem and\naddress them earlier, rather than later, in the search. Var puts the\nblame on the variable that first caused the failure of POAC.\n\n3.2\n\nRelational Neighborhood Inverse Consistency\n\nThe relational consistency property RNIC is equivalent to enforcing Neighborhood Inverse Consistency (NIC) on the dual graph of the CSP [Freuder\n6\n\n\fand Elfe, 1996; Woodward et al., 2011]. The RNIC property ensures that\nevery tuple in every relation can be extended to a solution in the subproblem\ninduced on the dual graph of the CSP by the relation and its neighboring\nrelations. The RNIC algorithm operates on table constraints and removes,\nfrom a given relation, all the tuples that do not appear in a solution in the\ninduced (dual) CSP of its neighborhood [Woodward et al., 2011]. We propose three strategies to increment weights when RNIC is used for lookahead\nduring search:\nOld: As in POAC in Section 3.1, we allow only the GAC call (preceding\nthe call to RNIC) to increment the weight of the constraint that causes\ndomain wipeout.\nAllC: This strategy encapsulates Old as a first step. During lookahead,\nRNIC is called on each constraint with two or more future variables.\nWhen the RNIC algorithm removes all the tuples of a given relation,\nAllC increments the weights of all the relations in the induced (dual)\nCSP. The rationale being that this considered combination of relations\n(which is the relation and its neighborhood in the dual graph) is ‘collectively’ responsible for the ‘relation’ wipeout.\nHead: This strategy is similar to AllC, except that we increment only\nthe weight of the constraint whose relation was emptied by the RNIC\nalgorithm and do not increment the weights of its neighborhood in the\ndual graph.\n\n4\n\nExperimental Evaluation\n\nWe evaluate the effectiveness of the strategies proposed for POAC and RNIC\nin Sections 4.2 and 4.3, respectively.\n\n4.1\n\nExperimental Setup\n\nWe consider the problem of finding a single solution to a CSP using backtrack\nsearch with some lookahead, d-way branching, dom/wdeg dynamic variableordering heuristic [Boussemart et al., 2004], and lexicographic value ordering.\nWe use STR2+ for enforcing GAC [Lecoutre, 2011], APOAC for enforcing\n\n7\n\n\fPOAC [Balafrej et al., 2014],1 and selRNIC for enforcing RNIC [Woodward\net al., 2011]. We use the benchmark problems available from Lecoutre’s website.2 Benchmarks are selected separately for POAC and RNIC. For a given\nconsistency level, if any instance is solved by any of the weighing schemas of\nthe considered consistency within the time limit of 60 minutes and memory\nlimit of 8GB, then the entire benchmark is included in the experiment. For\nbenchmarks in intension we convert the instance to extension prior to solving and do not include the time for conversion.3 From the 254 benchmark\nproblems (total 8,549 instances) available on Lecoutre’s website, our results\nare reported on 144 benchmarks (total 4,233 instances) for POAC and 132\n(total 3,869 instances) for RNIC.\nWe summarize the results of these experiments in Tables 2–7 and Figures 1 and 2. For each strategy, we report in Tables 2–7:\n• The number of completions (# Completions) with the total number of\ninstances in parenthesis.\n• The sum of the CPU time in seconds ( CPU sec.) computed over\ninstances where at least one algorithm terminated (given in parenthesis). When an algorithm does not terminate within 60 minutes, we add\n3,600 seconds to the CPU time and indicate with a > sign that the\ntime reported is a lower bound. We boldface the smallest CPU time.\nP\n\n• The average number of node visits (Average NV) computed over the\ninstances where all strategies completed (given in parenthesis).\nFigures 1 and 2 plot the number of instances solved by each strategy (Y-axis)\nas the CPU time increases (X-axis).\nIn addition to the above experiment, we also conduct a statistical analysis\nof the relative performance of the proposed strategies. We compare pairwise\n1\n\nUsing the terminology of Balafrej et al. [Balafrej et al., 2014], we use the following parameters and their recommended values for APOAC maxK = n, last drop with β = 0.05,\nand 70%-PER. Where maxK indicates the number of processed items in the propagation queue, β is the threshold of search-space reduction during the learning phase and\n70%-PER is the percentile for learning the value of maxK.\n2\nwww.cril.univ-artois.fr/~lecoutre/benchmarks.html\n3\nIn a study not reported we found that STR2+ is faster at solving CSP instances than\nrunning GAC on the original intension constraints because STR explores the satisfying\ntuples instead of valid tuples. As STR and RNIC algorithms require table constraints we\npre-convert the instances. The conversion time is the same for each algorithm and can\nsafely be ignored.\n\n8\n\n\fthe strategies corresponding to each higher-level consistency (i.e., POAC and\nRNIC) in order to determine whether or not a statistical difference exists between the strategies. Because search may fail to complete within the time\nlimit, we consider our results to be right-censored and analyze them using\na nonparameterized Wilcoxon signed-rank test [Wilcoxon, 1945]. The test\noperates by comparing the rank of the differences of the paired data. Differences of zero have no effect on the test and are safely discarded before\nranking. Further, given the clock precision, we discard data points where the\nCPU difference is less than one second. We assume a one-tailed distribution\nand significance level of p = 0.05.4 In the presence of censored data, we adopt\nthe following procedure to generate the data for each pairwise test. First, we\nrun each strategy on each instance for the time limit (i.e., 60 minutes). If\nboth strategies solve the instance, the data is included in the analysis. If neither strategy solves the instance, the instance is excluded from the analysis\n(i.e., the difference is zero and discarded). If one strategy completes within\nthe time threshold and the other does not, we re-run the second strategy\nwith double the time limit (i.e., 120 minutes), recording this limit as the\ncompletion time in case search does not terminate earlier. By allowing the\nadditional time, the censored data no longer affects the significance of the\nanalysis [Palmieri et al., 2016].5 The results obtained with the doubled time\nlimit are used only for the statistical analysis ranking the relative performance of the strategies (Table 1 and Expression (3)), but not used for the\nresults reported in Tables 2–7.\n\n4.2\n\nPartition-One Arc-Consistency\n\nBased on the statistical analysis comparing the relative performance for Old,\nAllS, LastS, and Var for POAC, we conclude that overall (Table 1):\n• AllS outperforms all others strategies\n• LastS and Var are equivalent\n• Old exhibits the worst performance of the four strategies, showing that\nit is important for dom/wdeg to increment the weights with POAC,\n4\n\nCheck Palmieri et al. [Palmieri et al., 2016] for an overview of the Wilcoxon signedrank test and the adopted methodology.\n5\nOur approach is similar to that of Palmieri et al. [Palmieri et al., 2016] except that\nwe exclude instances that neither strategy completes with the original time limit.\n\n9\n\n\fTable 1: Statistical analysis of weighting schemes for POAC\nBenchmark\n\nRanking\nAllS\n\n>\n\nLastS\n\n≡\n\nVar\n\n>\n\nOld\n\nLastS\n\n>\n\nOld\n\n>\n\nAllS\n\n≡\n\nVar\n\n‘Graph Coloring’\n\nVar\n\n>\n\nAllS\n\n>\n\nLastS\n\n>\n\nOld\n\n‘RAND’ (random)\n\nVar\n\n>\n\nAllS\n\n≡\n\nLastS\n\n≡\n\nOld\n\n‘Crossword’\n\nVar\n\n>\n\nAllS\n\n≡\n\nLastS\n\n≡\n\nOld\n\nAll benchmarks, put together\n‘QCP/QWH,’ ‘BQWH’\n(quasi-group completion)\n\nwhich justifies our investigations.\nHowever, a careful study of the individual benchmarks shows that LastS\non many quasi-group completion benchmarks and Var are competitive on\nmany, but not all, graph coloring, random, and crossword benchmarks.6 Rerunning the statistical analysis on each group of those benchmarks yields the\nresults shown in the last four rows of Table 1. Again, we insist that even\nwhen considering individual benchmarks, the performance of AllS remains\nglobally the most robust and consistent of all four strategies.\nTable 2 summarizes the experiments’ results on the 144 tested benchmarks.\nIn terms of the number of completed instances and the CPU time,\nTable 2: Overall results of experiments for POAC\nOld\nCompletion (4,233)\nP\n\nCPU sec. (2,846)\n\nAverage NV (2,775)\n\nAllS\n\n2,804\n\n2,822\n\n>1,139,552 >1,033,699\n19,181\n\n16,712\n\nLastS\n2,814\n\nVar\n2,811\n\n>1,075,640 >1,065,547\n16,503\n\n21,875\n\nAllS is the best (with 2,822 instances and >1,033,699 seconds) and Old is\nthe worst (with 2,804 instances and >1,139,552 seconds) of the four proposed\nstrategies. In terms of the average number of nodes visited (i.e., reduction\n6\n\nUsing the categories identified on Lecoutre’s website.\n\n10\n\n\fof the search space), LastS visits the least amount of nodes on average\n(16,503), followed by AllS (16,712), Old (19,181), and Var (21,875).7\nTable 3 summarizes individual benchmark results for the quasi-group\ncompletion category. Compared to the quasi-group completion analysis in\nTable 1, the benchmarks typically follow the statistical trend with LastS\nperforming the best on the QCP-15 and QWH-20 benchmarks. However,\nalthough LastS was statistically the best, on bqwh-15-106, AllS was the\nfastest.\nTable 3: Examples of quasi-group completion benchmark for POAC\nBenchmark\nOld\nAllS LastS Var\nWhere LastS performs best\nCompletion (15)\n15\n15\n15\n15\nP\nQCP-15\n3,920 5,480 3,214 6,083\nCPU sec. (15)\nAverage NV (15) 30,488 38,641 23,963 33,589\nCompletion (10)\n9\n9\n9\n9\nP\nQWH-20\n6,625 7,329 5,631 12,337\nCPU sec. (9)\nAverage NV (9)\n57,453 58,623 45,095 63,225\n. . . but AllS can still win on such benchmarks\nCompletion (100)\n100\n100\n100\n100\nP\nbqwh-15-106\n196\n167\n189\n211\nCPU sec. (100)\nAverage NV (100)\n599\n433\n531\n507\nTable 4 summarizes individual benchmarks for graph coloring, random,\nand crossword benchmarks. For these categories of benchmarks the statistical analysis of Table 1 shows that Var performs the best. Indeed, for fullinsertion, tightness0.8, and wordsVg Var has the smallest CPU time of the\nstrategies. However, individual benchmarks may vary despite the identified\nstatistical groupings. For example, AllS performs best on the tightness0.1,\nsgb-book, and ukVg benchmark, respectively.\nWe conclude that, unless we know enough about the problem instance\n7\n\nWe offer the following hypothesis as to why Var has the largest average of nodes\nvisited. The heuristic dom/wdeg is a ‘conflict-directed’ heuristic in that it attempts to\nselect the variable that participates in the largest number of ‘wipeouts.’ By incrementing\nthe weight of the variable being singleton-tested, Var perhaps increases the importance\nof a variable that ‘sees’ the conflict rather than those variables that ‘cause’ the conflict.\nThis hypothesis deserves a more thorough investigation.\n\n11\n\n\fTable 4: Examples of graph coloring, random, crossword benchmarks for POAC\nBenchmark\nOld\nAllS\nLastS\nVar\nWhere Var performs best\nCompletion (41)\n28\n28\n28\n29\nP\nfull-insertion\n>12,720 >10,055 >10,182\n7,238\nCPU sec. (29)\nAverage NV (28)\n16,725\n12,676\n13,312\n8,749\n98\n97\n97\n99\nCompletion (100)\nP\ntightness0.8\nCPU sec. (99)\n>59,907 >53,042 >56,945 41,848\nAverage NV (97)\n1,213\n1,085\n1,196\n1,315\nCompletion (65)\n55\n56\n54\n59\nP\nwordsVg\n>24,376 >24,190 >28,533 17,913\nCPU sec. (59)\nAverage NV (54)\n298\n391\n411\n250\n. . . but AllS can still win on such benchmarks\nCompletion (26)\n20\n20\n20\n20\nP\nsgb-book\nCPU sec. (20)\n9,677\n8,315\n8,455\n8,565\nAverage NV (20)\n143,653 148,055 148,985 134,099\n100\n100\n100\n100\nCompletion (100)\nP\nCPU sec. (100)\ntightness0.1\n46,926 43,766\n44,971\n69,974\nAverage NV (100)\n10,347\n9,762\n9,948\n12,457\nCompletion (65)\n29\n31\n28\n30\nP\nukVg\n>19,466 19,040 >20,961 >19,119\nCPU sec. (31)\nAverage NV (28)\n141\n411\n133\n139\nunder consideration, we should use AllS in conjunction with POAC, as the\noverall analysis shows us.\nFigure 1 shows the cumulative number of instances completed by each\nstrategy as CPU time increases. For easy instances (< 100 seconds), the\ncompletions of the strategies are similar. As the time limit increases Old\nbecomes dominated by the other three strategies. To better compare AllS,\nLastS, and Var we examine the hard instances, zooming the chart on the\ncumulative CPU time solved between 1,000 and 3,600 seconds. Although\nVar performs well on smaller CPU time (Var contends with AllS for the\nmost completed instances between 1,000 and 1,700 seconds) it becomes dominated by AllS and LastS on the harder instances. AllS clearly dominates\nall other strategies. These curves confirm the results of the statistical analysis\ngiven in Table 1.\n12\n\n\f2800\n\nALLS\nLASTS\n\n2600\n\nVAR\nOLD\n\n2400\n\n# Completions\n\n2800\n\n2200\n\n2000\n\n2750\n\n2700\n\n2650\n\n1800\n\n2600\n\n3600\n\n3400\n\n3400 3500\n3500 3600\n\n3200\n\n3300\n\n3300\n\n3200\n\n3100\n\n3100\n\n3000 3000\n\n2900 2900\n\n2700 2700\n2800 2800\n\n2400\n\n2500 2500\n2600 2600\n\n2300\n\n2400\n\n2100\n\n2200\n\n2300\n\n2200\n\n2100 2000\n\nCPU Time\n\n2000 1900\n\n1800 1700\n1900 1800\n\n1400\n\n1600 1500\n1700 1600\n\n1300\n\n1500\n\n1100\n\n1200\n\n1400\n\n1300\n\n1100\n\n900\n\n1000\n\n800\n\n700\n\n600\n\n500\n\n400\n\n300\n\n200\n\n0\n\n1400\n\n100\n\n2500\n\n1200 1000\n\n2550\n\n1600\n\nFigure 1: Cumulative number of instances completed by CPU time for POAC\n\n4.3\n\nRelational Neighborhood Inverse Consistency\n\nThe statistical analysis compares the relative performance for Old, AllC,\nand Head for RNIC. It shows that, overall, AllC and Head are equivalent\nand Old has the worst performance. The following holds in general for all\nbenchmarks:\nAllC ≡ Head > Old\n(3)\nThe fact that Old is the worst demonstrates that RNIC’s contribution to\nthe weights of dom/wdeg should not be ignored, thus justifying our investigations.\nTable 5 summarizes the experiments’ results on all the 132 tested benchmarks. AllC is the best strategy on all measures while Old is the worst.\n\n13\n\n\fTable 5: Results of experiments for RNIC\nOld\n# Completion (3,869)\nP\n\nCPU sec. (2,416)\n\nAverage NV (2,432)\n\n2,420\n\nAllC\n\nHead\n\n2,427\n\n2,423\n\n>1,032,130 >1,010,221 >1,014,635\n77,067\n\n45,696\n\n45,803\n\nWe were not able to uncover meaningful categories of benchmarks to distinguish between AllC and Head. Table 6 summarizes individual benchmark results for the Dimacs category. Within the category, either AllC or\nHead perform the best by all measures on different benchmarks. Similar results are obtained on the graph coloring category, shown in Table 7. Having\nsuch different results between AllC and Head explains why the statistical\nanalysis found them to be equivalent. Regardless, either AllC or Head\nperforms better than Old in a statistically significant manner.\nFigure 2 shows the cumulative number of instances completed by each\nstrategy as CPU time increases. As was the case for POAC, on easy instances\n(< 100 seconds), the completions of the strategies are similar. Focusing on\nharder instances, solved between 2,300 and 3,600 seconds, Old becomes\ndominated by AllC and Head. The curves of AllC and Head remain\nclose to one another. These curves confirm the ranking in Equation 3.\n\nTable 6: Examples of Dimacs benchmarks where AllC and Head\nBenchmark\nOld\nAllC\nCompletion (8)\n4\n4\npret\nΣCPU (4)\n196\n28\nAverage NV (4)\n1,285,234\n125,793\n6\n9\nCompletion (13)\ndubois\nΣCPU (6)\n>22,041 >10,088\nAverage NV (11) 11,222,349 1,522,902\n\n14\n\nperform best\n\nHead\n4\n61\n273,736\n11\n1,348\n382,329\n\n\fTable 7: Two graph coloring benchmarks where AllC and Head perform best\nBenchmark\nOld\nAllC\nHead\nCompletion (8)\n8\n8\n8\nmug\nΣCPU (8)\n5,098\n548\n2,819\nAverage NV (8) 1,501,379 189,595 883,130\nCompletion (26)\n5\n5\n5\nleighton-15\nΣCPU (5)\n2,219\n1,493\n1,222\nAverage NV (5)\n25,014 12,461\n4,972\nALLC\n\n2400\n\nHEAD\n\nOLD\n\n2200\n\n2000\n\n1800\n\n# Completions\n\n2430\n2420\n2410\n2400\n2390\n\n1600\n\n2380\n2370\n\n1200\n\n0\n100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n1100\n1200\n1300\n1400\n1500\n1600\n1700\n1800\n1900\n2000\n2100\n2200\n2300\n2400\n2500\n2600\n2700\n2800\n2900\n3000\n3100\n3200\n3300\n3400\n3500\n3600\n\n2350\n\n2300\n2350\n2400\n2450\n2500\n2550\n2600\n2650\n2700\n2750\n2800\n2850\n2900\n2950\n3000\n3050\n3100\n3150\n3200\n3250\n3300\n3350\n3400\n3450\n3500\n3550\n3600\n\n2360\n\n1400\n\nCPU Time\n\nFigure 2: Cumulative number of instances completed by CPU time for RNIC\n\n5\n\nConclusion\n\nThis paper introduces four strategies for incrementing the weight in dom/wdeg\nfor singleton consistencies (POAC) and three strategies for relational consistencies (RNIC). For both consistencies, Old is the worst strategy and a\nweighting schema involving the higher-level consistency is necessary. We\nshow that for POAC the best method is AllS, which increments the weights\n15\n\n\fat every singleton test. For RNIC, we show AllC and Head are statistically\nequivalent. Our work is a first step in the right direction, especially given\nthe importance of higher-level consistencies in solving difficult CSPs. Future\nwork may need to investigate more complex strategies for these and other\nconsistencies.\n\nAcknowledgments\nThe idea of Var was proposed by Christian Bessiere. This research is supported by NSF Grant No. RI-111795 and RI-1619344. Experiments were\ncompleted utilizing the Holland Computing Center of the University of Nebraska, which receives support from the Nebraska Research Initiative.\n\nReferences\n[Balafrej et al., 2014] Amine Balafrej, Christian Bessiere, El-Houssine\nBouyakhf, and Gilles Trombettoni. Adaptive Singleton-Based Consistencies. In Proc. of AAAI 2014, pages 2601–2607, 2014.\n[Bennaceur and Affane, 2001] Hachemi Bennaceur and Mohamed-Salah Affane. Partition-k-AC: An Efficient Filtering Technique Combining Domain\nPartition and Arc Consistency. In Proc. of CP 2001, volume 2239 of LNCS,\npages 560–564, 2001.\n[Bitner and Reingold, 1975] James R. Bitner and Edward M. Reingold.\nBacktrack Programming Techniques. Communications of the ACM,\n18(11):651–656, November 1975.\n[Boussemart et al., 2004] Frédéric Boussemart, Fred Hemery, Christophe\nLecoutre, and Lakhdar Sais. Boosting Systematic Search by Weighting\nConstraints. In Proc. of ECAI 2004, pages 146–150, 2004.\n[Debruyne and Bessière, 1997] Romuald Debruyne and Christian Bessière.\nSome Practicable Filtering Techniques for the Constraint Satisfaction\nProblem. In IJCAI 1997, pages 412–417, 1997.\n[Freuder and Elfe, 1996] Eugene C. Freuder and Charles D. Elfe. Neighborhood Inverse Consistency Preprocessing. In Proc. of AAAI 1996, pages\n202–208, 1996.\n16\n\n\f[Lecoutre, 2011] Christophe Lecoutre. STR2: Optimized Simple Tabular\nReduction for Table Constraints. Constraints, 16(4):341–371, 2011.\n[Mackworth, 1977] Alan K. Mackworth. On Reading Sketch Maps. In Proc.\nof IJCAI 77, pages 598–606, 1977.\n[Michel and Van Hentenryck, 2012] Laurent Michel and Pascal Van Hentenryck. Activity-Based Search for Black-Box Constraint Programming\nSolvers. In Proc. of CPAIOR 2012, volume 7298, pages 228–243. Spring,\n2012.\n[Palmieri et al., 2016] Anthony Palmieri, Jean-Charles Régin, and Pierre\nSchaus. Parallel Strategies Selection. In Proc. of CP 2016, volume 9892\nof LNCS, pages 388–404. Springer, 2016.\n[Refalo, 2004] Philippe Refalo. Impact-Based Search Strategies for Constraint Programming. In Proc. of CP 2004, volume 3258 of LNCS, pages\n557–571. Springer, 2004.\n[Vion et al., 2011] Julien Vion, Thierry Petit, and Narendra Jussien. Integrating Strong Local Consistencies into Constraint Solvers. In 14th\nAnnual ERCIM International Workshop on Constraint Solving and Constraint Logic Programming, CSCLP 2009, volume 6080 of LNAI, pages\n90–104. Springer, 2011.\n[Wallace and Freuder, 1992] Richard J. Wallace and Eugene C. Freuder. Ordering Heuristics for Arc Consistency Algorithms. In AI/GI/VI 92, pages\n163–169, 1992.\n[Wilcoxon, 1945] Frank Wilcoxon. Individual Comparisons by Ranking\nMethods. Biometrics Bulletin, 1(6):80–83, 1945.\n[Woodward et al., 2011] Robert Woodward, Shant Karakashian, Berthe Y.\nChoueiry, and Christian Bessiere. Solving Difficult CSPs with Relational\nNeighborhood Inverse Consistency. In Proc. of AAAI 11, pages 112–119,\n2011.\n[Woodward et al., 2012] Robert J. Woodward, Shant Karakashian,\nBerthe Y. Choueiry, and Christian Bessiere.\nRevisiting Neighborhood Inverse Consistency on Binary CSPs. In Proc. of CP 2012, volume\n7514 of LNCS, pages 688–703. Springer, 2012.\n17\n\n\f",
         "train",
         "33094",
         "5315"
        ],
        [
         "24",
         "18471",
         "cs.AI",
         "Artificial Intelligence",
         "1803.02348v1.pdf",
         "Smoothed Action Value Functions for Learning Gaussian Policies\n\nOfir Nachum 1 Mohammad Norouzi 1 George Tucker 1 Dale Schuurmans 1 2\n\narXiv:1803.02348v1 [cs.LG] 6 Mar 2018\n\nAbstract\nState-action value functions (i.e., Q-values) are\nubiquitous in reinforcement learning (RL), giving\nrise to popular algorithms such as SARSA and Qlearning. We propose a new notion of action value\ndefined by a Gaussian smoothed version of the\nexpected Q-value. We show that such smoothed\nQ-values still satisfy a Bellman equation, making\nthem learnable from experience sampled from an\nenvironment. Moreover, the gradients of expected\nreward with respect to the mean and covariance of\na parameterized Gaussian policy can be recovered\nfrom the gradient and Hessian of the smoothed\nQ-value function. Based on these relationships,\nwe develop new algorithms for training a Gaussian policy directly from a learned smoothed Qvalue approximator. The approach is additionally\namenable to proximal optimization by augmenting the objective with a penalty on KL-divergence\nfrom a previous policy. We find that the ability to\nlearn both a mean and covariance during training\nleads to significantly improved results on standard\ncontinuous control benchmarks.\n\n1. Introduction\nModel-free reinforcement learning algorithms often alternate between two concurrent but interacting processes: (1)\npolicy evaluation, where an action value function (i.e., a\nQ-value) is updated to obtain a better estimate of the return\nassociated with taking a specific action, and (2) policy improvement, where the policy is updated aiming to maximize\nthe current value function. In the past, different notions\nof Q-value have led to distinct but important families of\nRL methods. For example, SARSA (Rummery & Niranjan,\n1994; Sutton & Barto, 1998; Van Seijen et al., 2009) uses the\nexpected Q-value, defined as the expected return of following the current policy. Q-learning (Watkins, 1989) exploits a\nhard-max notion of Q-value, defined as the expected return\n1\n\nGoogle Brain 2 Department of Computing Science, University of Alberta. Correspondence to: Ofir Nachum <ofirnachum@google.com>.\n\nof following an optimal policy. Soft Q-learning (Haarnoja\net al., 2017) and PCL (Nachum et al., 2017) both use a\nsoft-max form of Q-value, defined as the future return of\nfollowing an optimal entropy regularized policy. Clearly,\nthe choice of Q-value function has a considerable effect on\nthe resulting algorithm; for example, restricting the types of\npolicies that can be expressed, and determining the type of\nexploration that can be naturally applied. In each case, the\nQ-value at a state s and action a answers the question,\n“What would my future value from s be if I were to take an\ninitial action a?”\nSuch information about a hypothetical action is helpful\nwhen learning a policy; we want to nudge the policy distribution to favor actions with potentially higher Q-values.\nIn this work, we investigate the practicality and benefits of\nanswering a more difficult, but more relevant, question:\n“What would my future value from s be if I were to sample my\ninitial action from a distribution centered at a?”\nWe focus our efforts on Gaussian policies and thus the counterfactual posited by the Q-value inquires about the expected\nfuture return of following the policy when changing the\nmean of the initial Gaussian distribution. Thus, our new\nnotion of Q-values maps a state-action pair (s, a) to the\nexpected return of first taking an action sampled from a\nnormal distribution N (·|a, Σ(s)) centered at a, and following actions sampled from the current policy thereafter. In\nthis way, the Q-values we introduce may be interpreted as a\nGaussian-smoothed version of the expected Q-value, hence\nwe term them smoothed Q-values.\nWe show that smoothed Q-values possess a number of important properties that make them attractive for use in RL\nalgorithms. It is clear from the definition of smoothed Qvalues that, if known, their structure is highly beneficial for\nlearning the mean of a Gaussian policy. We are able to show\nmore than this: although the smoothed Q-values are not a\ndirect function of the covariance, one can surprisingly use\nknowledge of the smoothed Q-values to derive updates to\nthe covariance of a Gaussian policy. Specifically, the gradient of the standard expected return objective with respect to\nthe mean and covariance of a Gaussian policy is equivalent\nto the gradient and Hessian of the smoothed Q-value function, respectively. Moreover, we show that the smoothed\n\n\fSmoothed Action Value Functions for Learning Gaussian Policies\n\nQ-values satisfy a single-step Bellman consistency, which\nallows bootstrapping to be used to train them via function\napproximation.\nThese results lead us to propose an algorithm, Smoothie,\nwhich, in the spirit of (Deep) Deterministic Policy Gradient\n(DDPG) (Silver et al., 2014; Lillicrap et al., 2016), trains\na policy using the derivatives of a trained (smoothed) Qvalue function to learn a Gaussian policy. Crucially, unlike\nDDPG, which is restricted to deterministic policies and is\nwell-known to have poor exploratory behavior (Haarnoja\net al., 2017), the approach we develop is able to utilize a\nnon-deterministic Gaussian policy parameterized by both\na mean and a covariance, thus allowing the policy to be\nexploratory by default and alleviating the need for excessive\nhyperparameter tuning. On the other hand, compared to\nstandard policy gradient algorithms (Williams & Peng, 1991;\nKonda & Tsitsiklis, 2000), Smoothie’s utilization of the\nderivatives of a Q-value function to train a policy avoids the\nhigh variance and sample inefficiency of stochastic updates.\nFurthermore, we show that Smoothie can be easily adapted\nto incorporate proximal policy optimization techniques by\naugmenting the objective with a penalty on KL-divergence\nfrom a previous version of the policy. The inclusion of a\nKL-penalty is not feasible in the standard DDPG algorithm,\nbut we show that it is possible with our formulation, and\nit significantly improves stability and overall performance.\nOn standard continuous control benchmarks, our results are\ncompetitive with or exceed state-of-the-art, especially for\nmore difficult tasks in the low-data regime.\n\n2. Formulation\nWe consider the standard model-free RL problem represented a Markov decision process (MDP), consisting of\na state space S and an action space A. At iteration t\nthe agent encounters a state st ∈ S and emits an action\nat ∈ A, after which the environment returns a scalar reward rt ∼ R(st , at ) and places the agent in a new state\nst+1 ∼ P (st , at ).\nWe focus on continuous control tasks, where the actions are\nreal-valued, i.e., A ≡ Rda . Our observations at a state s\nare denoted Φ(s) ∈ Rds . We parameterize the behavior of\nthe agent using a stochastic policy π(a | s), which takes the\nform of a Gaussian density at each state s. The Gaussian\npolicy is parameterized by a mean and a covariance function,\nµ(s) : Rds → Rda and Σ(s) : Rds → Rda × Rda so that\nπ(a | s) = N (a | µ(s), Σ(s)), where\n\u001a\n\u001b\n1\nN (a | µ, Σ) = |2πΣ|−1/2 exp − ka − µk2Σ−1 , (1)\n2\nhere using the notation kvk2A = v T Av.\n\n2.1. Policy Gradient for Generic Stochastic Policies\nThe optimization objective (expected discounted return), as\na function of a generic stochastic policy, is expressed in\nterms of the expected action value function Qπ (s, a) by,\nZ Z\nOER (π) =\nπ(a | s)Qπ (s, a) da dρπ (s) ,\n(2)\nS\n\nA\n\nπ\n\nwhere ρ (s) is the state visitation distribution under π, and\nQπ (s, a) is recursively defined using the Bellman equation,\n\u0014\n\u0015\nZ\nQπ (s, a) = Er,s0 r + γ Qπ (s0 , a0 )π(a0 | s0 ) da , (3)\nA\n\nwhere γ ∈ [0, 1] is the discount factor. For brevity, we\nsuppress explicit denotation of the distribution R over immediate rewards and P over state transitions.\nThe policy gradient theorem (Sutton et al., 2000) expresses\nthe gradient of OER (πθ ) w.r.t. θ, the tunable parameters of a\npolicy πθ , as,\nZ Z\n∇θ OER (πθ ) =\n∇θ πθ (a | s)Qπ (s, a) da dρπ (s)\nS A\nZ\n=\nEa∼πθ (a|s) [∇θ log πθ (a | s)Qπ (s, a)] dρπ (s). (4)\nS\n\nIn order to approximate the expectation on the RHS of (4),\none often resorts to an empirical average over on-policy\nsamples from πθ (a | s). This sampling scheme results in\na gradient estimate with high variance, especially when\nπθ (a | s) is not concentrated. Many policy gradient algorithms, including actor-critic variants, trade off variance\nand bias, e.g., by attempting to estimate Qπ (s, a) accurately\nusing function approximation and the Bellman equation.\n2.2. Deterministic Policy Gradient\nSilver et al. (2014) study the policy gradient for the specific\nclass of Gaussian policies in the limit where the policy’s\ncovariance approaches zero. In this scenario, the policy\nbecomes deterministic and samples from the policy approach the Gaussian mean. Under a deterministic policy\nπ ≡ (µ, Σ → 0), one can estimate the expected future\nreturn from a state s as,\nZ\nlim\nπ(a | s)Qπ (s, a) da = Qπ (s, µ(s)) . (5)\nΣ→0\n\nA\n\nAccordingly, Silver et al. (2014) express the gradient of the\nexpected discounted return objective for πθ ≡ δ(µθ ) as,\nZ\n∂Qπ (s, a)\n∇θ OER (πθ ) =\n∇θ µθ (s)dρπ (s). (6)\n∂a\na=µθ (s)\nS\nThis characterization of the policy gradient theorem for deterministic policies is called deterministic policy gradient\n\n\fSmoothed Action Value Functions for Learning Gaussian Policies\n\n0.8\n0.7\nReward\n\nAction\n\n(DPG). Since no Monte Carlo sampling\n1.0 is required for estimating the gradient, the variance of the estimate is reduced.\nOn the other hand, the deterministic nature\nof the policy can\n0.5\nlead to poor exploration and training instability in practice.\n0.0\n\nIn the limit of Σ → 0, one can also re-express the Bellman\nequation (3) as,\nπ\n\nπ\n\n0.5\n0\n\n0\n\nQ (s, a) = Er,s0 [r + Q (s , µ(s ))] .\n\n0.6\n0.5\n0.4\n\n(7)\n\n0.3\n\n1.0\nπ\nTherefore, a value function approximator\nbe opti-10000\n0 Qw can\n5000\nmized by minimizing the Bellman error,\nTraining iteration\nX\nE(w) =\n(Qπw (s, a)−r−γQπw (s0 , µ(s0 ))2 , (8)\n\n15000\n\n0.2\n\n1.0\n\n0.5\n\n0.0\n\n0.5\n\n1.0\n\nAction\n\nReward\n\nSmoothed Reward\n\n(s,a,r,s0 )∈D\n\nfor transitions (s, a, r, s0 ) sampled from a dataset D of interactions of the agent with the environment. The deep variant\nof DPG known as DDPG (Lillicrap et al., 2016) alternates\nbetween improving the action value estimate by gradient\ndescent on (8) and improving the policy based on (6).\nTo improve sample efficiency, Degris et al. (2012) and Silver\net al. (2014) replace the state visitation distribution ρπ (s) in\n(6) with an off-policy visitation distribution ρβ (s) based on\na replay buffer. This subsititution introduces some bias in\nthe gradient estimate (6), but previous work has found that\nit works well in practice and improves the sample efficiency\nof the policy gradient algorithms. We also adopt a similar\nheuristic in our method to make use of off-policy data.\nIn practice, DDPG exhibits improved sample efficiency over\nstandard policy gradient algorithms: using off-policy data\nto train Q-values while basing policy updates on their gradients significantly improves stochastic policy updates dictated by (4), which require a large number of samples to\nreduce noise. On the other hand, the deterministic nature\nof the policy learned by DDPG leads to poor exploration\nand instability in training. In this paper, we propose an\nalgorithm which, like DDPG, utilizes derivative information of learned Q-values for better sample-efficiency, but\nwhich, unlike DDPG, is able to learn a Gaussian policy and\nimposes a KL-penalty for better exploration and stability.\n\n3. Idea\nBefore giving a full exposition, we use a simplified scenario\nto illustrate the key intuitions behind the proposed approach\nand how it differs fundamentally from previous methods.\nConsider a one-shot decision making problem over a one\ndimensional action space with a single state. Here the expected reward is given by a function over the real line, which\nalso corresponds to the optimal Q-value function; Figure 1\ngives a concrete example. We assume the policy π is specified by a Gaussian distribution parameterized by a scalar\nmean µ and standard deviation σ. The goal is to optimize\nthe policy parameters to maximize expected reward.\n\nFigure 1. A simple expected reward function, shown in green,\nwith a Gaussian-smoothed version, shown in magenta.\n\nA naive policy gradient method updates the parameters by\nsampling a ∼ π, observing reward ri , then adjusting µ and\nπ(ai )\ni\nσ in directions ∆µ = d logdµ\nri = µ−a\nσ 2 ri and ∆σ =\n\u0001\n2\nd log π(ai )\ni)\nri = (µ−a\n− σ1 ri . Note that such updates\ndσ\nσ2\nsuffer from large variance, particularly when σ is small.\nTo reduce the variance of direct policy gradient, deterministic policy gradient methods leverage a value function approximator Qπw , parameterized by w, to approximate Qπ . For\nexample, in this scenario, vanilla DPG would sample an action ai = µ + εi with exploration noise εi ∼ N (0, σ 2 ),\n∂Qπ\nw (a)\nthen update µ using ∆µ =\nand Qπw using\n∂a\na=µ\n∆w = (ri − Qπw (ai ))∇w Qπw (ai ). Clearly, this update exhibits reduced variance, but requires Qπw to approximate\nQπ (the green curve in Figure 1) to control bias. Unfortunately, DPG is not able to learn the exploration variance\nσ 2 . Variants of DPG such as SVG (Heess et al., 2015) and\nEPG (Ciosek & Whiteson, 2017) have been proposed to\nwork with stochastic policies. However they introduce a\nnoise or an approximate integral into the policy updates,\nthus losing the advantage of deterministic gradient updates.\nNote, however, that the expected value at any given location is actually given by a convolution of the Gaussian\npolicy with the underlying expected reward function. Such\na process inherently smooths the landscape, as shown in the\nmagenta curve in Figure 1. Unfortunately, DPG completely\nignores this smoothing effect by trying to approximate Qπ ,\nwhile policy gradient methods only benefit from it indirectly\nthrough sampling. A key insight is that this smoothing effect\ncan be captured directly in the value function approximator\nitself, bypassing any need for sampling or approximating\nQπ . That is, instead of using an approximator to model Qπ ,\none can directly\nR approximate the smoothed version given\nby Q̃π (a) = A N (ã|a, σ 2 )Qπ (ã) dã (the magenta curve\nin Figure 1), which, crucially, satisfies OER (π) = Q̃π (µ).\n\n\fSmoothed Action Value Functions for Learning Gaussian Policies\n\nBased on this observation, we propose a novel actor-critic\nstrategy below that uses a function approximator Q̃πw to\nmodel Q̃π . Although approximating Q̃π instead of Qπ\nmight appear to be a subtle change, it is a major alteration\nto existing actor-critic approaches. Not only is approximating the magenta curve in Figure 1 far easier than the\ngreen curve, modeling Q̃π allows the policy parameters to\nbe updated deterministically for any given action. In particular, in the simple scenario above, if one sampled an\naction from the current policy, ai ∼ π, and observed ri ,\n∂ Q̃π\nw (a)\nthen µ could be updated using ∆µ = ∂a\n, σ using\na=µ\n∆σ =\n\n∂ 2 Q̃π\nw (a)\n∂a2\na=µ\n\n(a key result we establish below), and\n\nQ̃πw using ∆w = (ri − Q̃πw (µ))∇w Q̃πw (µ).\nSuch a strategy combines the best aspects of DPG and policy gradient while conferring additional advantages: (1) the\nsmoothed value function Q̃π cannot add but can only remove local minima from Qπ ; (2) Q̃π is smoother than Qπ\nhence easier to approximate; (3) approximating Q̃π allows\ndeterministic gradient updates for π; (4) approximating Q̃π\nallows gradients to be computed for both the mean and variance parameters. Among these advantages, DPG shares\nonly 3 and policy gradient only 1. We will see below that\nthe new strategy we propose significantly outperforms existing approaches, not only in the toy scenario depicted in\nFigure 1, but also in challenging benchmark problems.\n\n4. Smoothed Action Value Functions\nMoving beyond a simple illustrative scenario, the key contribution of this paper is to introduce the general notion of\na smoothed action value function, the gradients of which\nprovide an effective signal for optimizing the parameters of\na Gaussian policy. Smoothed Q-values, which we denote\nQ̃π (s, a), differ from ordinary Q-values Qπ (s, a) by not assuming the first action of the agent is fully specified; instead,\nthey assume only that a Gaussian centered at the action is\nknown. Thus, to compute Q̃π (s, a), one has to perform an\nexpectation of Qπ (s, ã) for actions ã drawn in the vicinity\nof a. More formally, smoothed action values are defined as,\nZ\nQ̃π (s, a) =\nN (ã | a, Σ(s)) Qπ (s, ã) dã . (9)\nA\n\nOne of the key observations that enables learning a function\napproximator for Q̃π is that smoothed Q-values satisfy a\nnotion of Bellman consistency. First, note that for Gaussian\npolicies π ≡ (µ, Σ) we have the following relation between\nthe expected and smoothed Q-values:\nQπ (s, a) = Er,s0 [r + γ Q̃π (s0 , µ(s0 ))] .\n\n(11)\n\nThen, combining (9) and (11), one can derive the following\none-step Bellman equation for smoothed Q-values,\nZ\nh\ni\nQ̃π (s, a) = N (ã | a, Σ(s)) Er̃,s̃0 r̃ + γ Q̃π (s̃0 , µ(s̃0 )) dã,\nA\n\n(12)\nwhere r̃ and s̃0 are sampled from R(s, ã) and P (s, ã). Below, we elaborate on how one can make use of the derivatives of Q̃π to learn µ and Σ, and how the Bellman equation\nin (12) enables direct optimization of Q̃π .\n4.1. Policy Improvement\nWe assume a Gaussian policy πθ,φ ≡ (µθ , Σφ ) parameterized by θ and φ for the mean and the covariance respectively.\nThe gradient of the objective w.r.t. the mean parameters follows from the policy gradient theorem in conjunction with\n(10) and is almost identical to (6),\nZ\n∂ Q̃π (s, a)\n∇θ OER (πθ,φ ) =\n∇θ µθ (s)dρπ (s).\n∂a\na=µ\n(s)\nθ\nS\n(13)\nEstimating the derivative of the objective w.r.t. the covariance parameters is not as straightforward, since Q̃π is not\na direct function of Σ. However, a key result is that the\nsecond derivative of Q̃π w.r.t. actions is sufficient to exactly\ncompute the derivative of Q̃π w.r.t. Σ.\nTheorem 1.\n\n∂ Q̃π (s, a)\n1 ∂ 2 Q̃π (s, a)\n= ·\n∀s, a .\n∂Σ(s)\n2\n∂a2\n\n(14)\n\nA proof of this identity is provided in the Appendix. The\nfull derivative w.r.t. φ can then be shown to take the form,\n∇φ OER (πθ,φ ) =\n\n1\n2\n\n∂ 2 Q̃π (s, a)\n∂a2\nS\n\nZ\n\n∇φ Σφ (s)dρπ (s).\n\na=µθ (s)\n\n(15)\n\nπ\n\nWith this definition of Q̃ , one can re-express the expected\nreward objective for a Gaussian policy π ≡ (µ, Σ) as,\nZ\nOER (π) =\nQ̃π (s, µ(s)) dρπ (s) .\n(10)\nS\n\nThe insight that differentiates this approach from prior work\n(Heess et al., 2015; Ciosek & Whiteson, 2017) is that instead\nof learning a function approximator for Qπ then drawing\nsamples to approximate the expectation in (9) and its derivative, we directly learn a function approximator for Q̃π .\n\n4.2. Policy Evaluation\nThere are two natural ways to optimize Q̃πw . The first approach leverages (9) to update Q̃π based on the expectation\nof Qπ . In this case, one first trains a parameterized model\nQπw to approximate the standard Qπ function using conventional methods (Rummery & Niranjan, 1994; Sutton &\nBarto, 1998; Van Seijen et al., 2009), then fits Q̃πw to Qπw\nbased on (9). In particular, given transitions (s, a, r, s0 ) sampled from interactions with the environment, one can train\n\n\fSmoothed Action Value Functions for Learning Gaussian Policies\n\nQπw to minimize the Bellman error\n(Qπw (s, a) − r − γQπw (s0 , a0 ))2 ,\n0\n\n0\n\n0\n\nwhere a ∼ N (µ(s ), Σ(s )). Then,\nto minimize the squared error\n\nQ̃πw\n\n(16)\n\ncan be optimized\n\n(Q̃πw (s, a) − Eã [Qπw (s, ã)])2 ,\n\n(17)\n\nwhere ã ∼ N (a, Σ(s)), using several samples. When the\ntarget values in the residuals are treated as fixed (i.e., using a\ntarget network), these updates will reach a fixed point when\nQ̃πw satisfies the recursion in the Bellman equation (9).\nThe second approach requires a single function approximator for Q̃πw , resulting in a simpler implementation; hence we\nuse this approach in our experimental evaluation. Suppose\none has access to a tuple (s, ã, r̃, s̃0 ) sampled from a replay\nbuffer with knowledge of the sampling probability q(ã | s)\n(possibly unnormalized) with full support. Then we draw a\nphantom action a ∼ N (ã, Σ(s)) and optimize Q̃πw (s, a) by\nminimizing a weighted Bellman error\n1\n(Q̃π (s, a) − r̃ − γ Q̃πw (s̃0 , µ(s̃0 ))2 .\nq(ã|s) w\n\n(18)\n\nIn this way, for a specific pair of state and action (s, a) the\nexpected objective value is,\nh\ni\nEq(ã | s),r̃,s̃0 δ·(Q̃πw (s, a) − r̃ − γ Q̃πw (s̃0 , µ(s̃0 )))2 , (19)\n| ã,Σ(s))\nwhere δ = N (aq(ã\n. Note that the denominator of δ\n| s)\ncounter-acts the expectation over ã in (19) and that the\nnumerator of δ is N (a|ã, Σ(s)) = N (ã|a, Σ(s)). Therefore,\nwhen the target value r̃ + γ Q̃πw (s̃0 , µ(s̃0 )) is treated as fixed\n(i.e., using a target network) this training procedure reaches\nan optimum when Q̃πw (s, a) satisfies the recursion in the\nBellman equation (12).\n\nIn practice, we find that it is unnecessary to keep track of\nthe probabilities q(ã | s), and assume the replay buffer provides a near-uniform distribution of actions conditioned on\nstates. Other recent work has also benefited from ignoring\nor heavily damping importance weights (Munos et al., 2016;\nWang et al., 2017; Schulman et al., 2017). However, it is\npossible when interacting with the environment to save the\nprobability of sampled actions along with their transitions,\nand thus have access to q(ã | s) ≈ N (ã | µold (s), Σold (s)).\n\nAlgorithm 1 Smoothie\nInput: Environment EN V , learning rates ηπ , ηQ , discount factor γ, KL-penalty λ, batch size B, number of\ntraining steps N , target network lag τ .\nInitialize θ, φ, w, set θ0 = θ, φ0 = φ, w0 = w.\nfor i = 0 to N − 1 do\n// Collect experience\nSample action a ∼ N (µθ (s), Σφ (s)) and apply to\nEN V to yield r and s0 .\nInsert transition (s, a, r, s0 ) to replay buffer.\n// Train µ, Σ\nSample batch {(sk , ak , rk , s0k )}B\nk=1 from replay buffer.\n∂ Q̃π\nw (sk ,a)\n.\n∂a\na=µθ (sk )\n∂ 2 Q̃π\nw (sk ,a)\n.\nHk =\n∂a2\na=µθ (sk )\n\nCompute gradients gk =\n\nCompute Hessians\nCompute penalties KLk = KL(µθ , Σφ ||µθ0 , Σφ0 ).\nCompute updates\nPB\n∆θ = B1 k=1 gk ∇θ µθ (sk ) − λ∇θ KLk ,\nPB\n∆φ = B1 k=1 21 Hk ∇φ Σφ (sk ) − λ∇φ KLk .\nUpdate θ ← θ + ηπ ∆θ, φ ← φ + ηπ ∆φ.\n// Train Q̃π\nSample batch {(sk , ãk , r̃k , s̃0k )}B\nk=1 from replay buffer.\nSample phantom actions ak ∼ N (ãk , Σφ (sk )).\nCompute loss\nPB\nL(w) = B1 k=1 (Q̃πw (s, a)−r−γ Q̃πw0 (s̃0 , µθ0 (s̃0 )))2 .\nUpdate w ← w − ηQ ∇w L(w).\n// Update target variables\nUpdate θ0 ← (1 − τ )θ0 + τ θ; φ0 ← (1 − τ )φ0 + τ φ;\nw0 ← (1 − τ )w0 + τ w.\nend for\n\nstabilizing techniques have thus far not been applicable to\nalgorithms like DDPG, since the policy is deterministic. The\nformulation we propose above, however, is easily amenable\nto trust region optimization. Specifically, we may augment\nthe objective (10) with a penalty\nZ\nOTR (π) = OER (π) − λ\n\nKL (π k πold ) dρπ (s),\n\n(20)\n\nS\n\n4.3. Proximal Policy Optimization\nPolicy gradient algorithms are notoriously unstable, particularly in continuous control problems. Such instability has\nmotivated the development of trust region methods that constrain each gradient step to lie within a trust region (Schulman et al., 2015), or augment the expected reward objective with a penalty on KL-divergence from a previous policy (Nachum et al., 2018; Schulman et al., 2017). These\n\nwhere πold ≡ (µold , Σold ) is a previous version of the policy. The optimization is straightforward, since the KLdivergence of two Gaussians can be expressed analytically.\nThis concludes the technical presentation of the proposed\nalgorithm Smoothie: pseudocode for the full training procedure, including policy improvement, policy evaluation, and\nproximal policy improvement is given in Algorithm 1.\n\n\fSmoothed Action Value Functions for Learning Gaussian Policies\n\n4.4. Compatible Function Approximation\n\n5. Related Work\n\nThe approximator Q̃πw for Q̃π should be sufficiently accurate so that updates for µθ and Σφ are not affected by substi-\n\nThis paper follows a long line of work that uses Q-value\nfunctions to stably learn a policy, which in the past has been\nused to either approximate expected (Rummery & Niranjan,\n1994; Van Seijen et al., 2009; Gu et al., 2017) or optimal\n(Watkins, 1989; Silver et al., 2014; Nachum et al., 2017;\nHaarnoja et al., 2017; Metz et al., 2017) future value.\n\n∂ Q̃π (s,a)\n\n∂ 2 Q̃π (s,a)\n\nπ\n\n2\n\nπ\n\nw\nw\ntuting\nand\nfor ∂ Q̃ ∂a(s,a) and ∂ Q̃∂a(s,a)\n2\n∂a\n∂a2\nrespectively. Define \u000fk (s, θ, w) as the difference between\nthe true k-th derivative of Q̃π and the k-th derivative of the\napproximated Q̃πw at a = µθ (s):\n\n\u000fk (s, θ, w) = ∇ka Q̃πw (s, a)\n\na=µθ (s)\n\n− ∇ka Q̃π (s, a)\n\n.\n(21)\n\na=µθ (s)\n\nWe claim that a Q̃πw is compatible with respect to µθ if\n1. ∇a Q̃πw (s, a) a=µ (s) = ∇θ µθ (s)T w,\nθ\nR\n2. ∇w S ||\u000f1 (s, θ, w)||2 dρπ (s) = 0 (i.e., w minimizes\nthe expected squared error of the gradients).\nAdditionally, Q̃πw is compatible with respect to Σφ if\n1. ∇2a Q̃πw (s, a) a=µ (s) = ∇φ Σφ (s)T w,\nθ\nR\n2. ∇w S ||\u000f2 (s, θ, w)||2 dρπ (s) = 0 (i.e., w minimizes\nthe expected squared error of the Hessians).\nWe provide a proof of these claims in the Appendix. One\npossible parameterization of Q̃πw may be achieved by taking\nw = [w0 , w1 , w2 ] and parameterizing\nQ̃πw (s, a) = Vw0 (s) + (a − µθ (s))T ∇θ µθ (s)T w1\n+ (a − µθ (s))T ∇φ Σφ (s)T w2 (a − µθ (s)). (22)\nSimilar conditions and parameterizations exist for\nDDPG (Silver et al., 2014), in terms of Qπ . While it is\nreassuring to know that there exists a class of function approximators which are compatible, this fact has largely been\nignored in practice. At first glance, it seems impossible to\nsatisfy the second set of conditions without access to derivative information of the true Q̃π (for DDPG, Qπ ). Indeed, the\nmethods for training Q-value approximators (equation (8)\nand Section 4.2) only train to minimize an error between raw\nscalar values. For DDPG, we are unaware of any method\nthat allows one to train Qπw to minimize an error with respect to the derivatives of the true Qπ . However, the case\nis different for the smoothed Q-values Q̃π . In fact, it is\npossible to train Q̃πw to minimize an error with respect to\nthe derivatives of the true Q̃π . We provide an elaboration in\nthe Appendix. In brief, it is possible to use (12) to derive\nk π\nBellman-like equations which relate a derivative ∂ Q̃∂a(s,a)\nk\nof any degree k to an integral over the raw Q-values at the\nnext time step Q̃π (s̃0 , µ(s̃0 )). Thus, it is possible to devise\na training scheme in the spirit of the one outlined in Section 4.2, which optimizes Q̃πw to minimize the squared error\nwith the derivatives of the true Q̃π . This theoretical property of the smoothed Q-values is unique and provides added\nbenefits to its use over the standard Q-values.\n\nWork that is most similar to what we present are methods\nthat exploit gradient information from the Q-value function\nto train a policy. Deterministic policy gradient (Silver et al.,\n2014) is perhaps the best known of these. The method we\npropose can be interpreted as a generalization of the deterministic policy gradient. Indeed, if one takes the limit of the\npolicy covariance Σ(s) as it goes to 0, the proposed Q-value\nfunction becomes the deterministic value function of DDPG,\nand the updates for training the Q-value approximator and\nthe policy mean are identical.\nStochastic Value Gradient (SVG) (Heess et al., 2015) also\ntrains stochastic policies using an update that is similar to\nDDPG (i.e., SVG(0) with replay). The key differences with\nour approach are that SVG does not provide an update for\nthe covariance, and the mean update in SVG estimates the\ngradient with a noisy Monte Carlo sample, which we avoid\nby estimating the smoothed Q-value function. Although a\ncovariance update could be derived using the same reparameterization trick as in the mean update, that would also\nrequire a noisy Monte Carlo estimate. Methods for updating the covariance along the gradient of expected reward\nare essential for applying the subsequent trust region and\nproximal policy techniques.\nMore recently, Ciosek & Whiteson (2017) introduced expected policy gradients (EPG), a generalization of DDPG\nthat provides updates for the mean and covariance of a\nstochastic Gaussian policy using gradients of an estimated\nQ-value function. In that work, the expected Q-value used\nin standard policy gradient algorithms such as SARSA (Sutton & Barto, 1998; Rummery & Niranjan, 1994; Van Seijen\net al., 2009) is estimated. The updates in EPG therefore\nrequire approximating an integral of the expected Q-value\nfunction. Our analogous process directly estimates an integral (via the smoothed Q-value function) and avoids approximate integrals, thereby making the updates simpler. Moreover, while Ciosek & Whiteson (2017) rely on a quadratic\nTaylor expansion of the estimated Q-value function, we instead rely on the strength of neural network function approximators to directly estimate the smoothed Q-value function.\nThe novel training scheme we propose for learning the covariance of a Gaussian policy relies on properties of Gaussian integrals (Bonnet, 1964; Price, 1958). Similar identities\nhave been used in the past to derive updates for variational\nauto-encoders (Kingma & Welling, 2014) and Gaussian\n\n\fSmoothed Action Value Functions for Learning Gaussian Policies\nHalfCheetah\n\n1.0\n\nSwimmer\n\n0.8\n0.7\n\n0.0\n\n0.6\n\n6000\n\n0.5\n\n200\n4000\n\n0.4\n\n−0.5\n−1.0\n\n8000\n300\n\nReward\n\nAction\n\n0.5\n\n0\n\n5000\n\n10000\n\n15000\n\nTraining iteration\nSmoothie\n\nDDPG\n\n0.2\n−1.0\n\n100\n\n2000\n\n0.3\n−0.5\n\nReward\n\n0\n\n0.0\n\n0.5\n\n1.0\n\nAction\n\n0\n\n0.00\n\n0.25\n\n0.50\n\n0.75\n\n1.00\n\nFinally, the perspective presented in this paper, where Qvalues represent the averaged return of a distribution of\nactions rather than a single action, is distinct from recent advances in distributional RL (Bellemare et al., 2017). Those\napproaches focus on the distribution of returns of a single\naction, whereas we consider the single average return of a\ndistribution of actions. Although we restrict our attention\nin this paper to Gaussian policies, an interesting topic for\nfurther investigation is to study the applicability of this new\nperspective to a wider class of policy distributions.\n\n6. Experiments\nWe utilize the insights from Section 4 to introduce a new RL\nalgorithm, Smoothie. Smoothie maintains a parameterized\nQ̃πw trained via the procedure described in Section 4.2. It\nthen uses the gradient and Hessian of this approximation to\ntrain a Gaussian policy πθ,φ ≡ (µθ , Σφ ) using the updates\nstated in (13) and (15). See Algorithm 1 for a simplified\npseudocode of the algorithm.\nWe perform a number of evaluations of Smoothie to compare to DDPG. We choose DDPG as a baseline because it\n(1) utilizes gradient information of a Q-value approximator,\nmuch like the proposed algorithm; and (2) is a standard algorithm well-known to have achieve good, sample-efficient\nperformance on continuous control benchmarks.\n6.1. Synthetic Task\nBefore investigating benchmark problems, we first briefly\nrevisit the simple task introduced in Section 3 and reproduced in Figure 2 (Right). Here, the reward function is a\n\n1.0\n\n1.5\n\n2.0\n\n1.5\n\n2.0\n\n1.5\n\n2.0\n\nWalker2d\n\n3000\n\nback-propagation (Rezende et al., 2014).\n\n0.5\n\nHopper\n\nSmoothed Reward\n\nFigure 2. Left: The learnable policy mean and standard deviation\nduring training for Smoothie and DDPG on the simple synthetic\ntask introduced in Section 3. The standard deviation for DDPG is\nthe exploratory noise kept constant during training. Right: Copy of\nFigure 1 showing the reward function and its Gaussian-smoothed\nversion. Smoothie successfully escapes the lower-reward local\noptimum, while increasing then decreasing its policy variance as\nthe convexity/concavity of the smoothed reward function changes.\n\n0.0\n\n4000\n3000\n\n2000\n2000\n1000\n\n1000\n\n0.0\n\n0.5\n\n1.0\n\n1.5\n\n2.0\n\n0.0\n\n0.5\n\nAnt\n\n1.0\n\nHumanoid\n\n4000\n\n4000\n\n3000\n\n3000\n\n2000\n\n2000\n\n1000\n\n1000\n\n0.0\n\n0.5\n\n1.0\n\n1.5\n\n2.0\n\nSmoothie\n\n0.0\n\n0.5\n\n1.0\n\nDDPG\n\nFigure 3. Results of Smoothie and DDPG on continuous control\nbenchmarks. The x-axis is in millions of environment steps. Each\nplot shows the average reward and standard deviation clipped at\nthe min and max of six randomly seeded runs after choosing best\nhyperparameters. We see that Smoothie is competitive with DDPG\neven when DDPG uses a hyperparameter-tuned noise scale, and\nSmoothie learns the optimal noise scale (the covariance) during\ntraining. Moreoever, we observe significant advantages in terms\nof final reward performance, especially in the more difficult tasks\nlike Hopper, Walker2d, and Humanoid.\n\nmixture of two Gaussians, one better than the other, and we\ninitialize the policy mean to be centered on the worse of the\ntwo. We plot the learnable policy mean and standard deviation during training for Smoothie and DDPG in Figure 2\n(Left). Smoothie learns both the mean and variance, while\nDDPG learns only the mean and the variance plotted is the\nexploratory noise, whose scale is kept fixed during training.\nAs expected, we observe that DDPG cannot escape the local\noptimum. At the beginning of training it exhibits some\nmovement away from the local optimum (likely due to the\ninitial noisy approximation given by Qπw ). However, it is\nunable to progress very far from the initial mean. Note that\nthis is not an issue of exploration. The exploration scale is\nhigh enough that Qπw is aware of the better Gaussian. The\nissue is in the update for µθ , which is only with regard to\nthe derivative of Qπw at the current mean.\n\n\fSmoothed Action Value Functions for Learning Gaussian Policies\n\nOn the other hand, we find Smoothie is easily able to solve\nthe task. This is because the smoothed reward function\napproximated by Q̃πw has a derivative that clearly points µθ\ntoward the better Gaussian. We also observe that Smoothie\nis able to suitably adjust the covariance Σφ during training.\nInitially, Σφ decreases due to the concavity of the smoothed\nreward function. As a region of convexity is entered, it\nbegins to increase, before again decreasing to near-zero as\nµθ approaches the global optimum. This example clearly\nshows the ability of Smoothie to exploit the smoothed action\nvalue landscape.\n6.2. Continuous Control\nNext, we consider standard continuous control benchmarks\navailable on OpenAI Gym (Brockman et al., 2016) utilizing\nthe MuJoCo environment (Todorov et al., 2012).\n\nHopper\n\nWalker2d\n\n3500\n3000\n\n4000\n\n2500\n3000\n2000\n2000\n\n1500\n1000\n\n1000\n\n500\n0.0\n\n0.5\n\n1.0\n\n1.5\n\n2.0\n\n0.0\n\nAnt\n\n0.5\n\n1.0\n\n1.5\n\n2.0\n\n1.5\n\n2.0\n\nHumanoid\n\n4000\n\n4000\n\n3000\n\n3000\n\n2000\n\n2000\n\n1000\n\n1000\n\n0.0\n\n0.5\n\n1.0\n\n1.5\n\n2.0\n\nSmoothie with KL-penalty\n\n0.0\n\n0.5\n\n1.0\n\nSmoothie without KL-penalty\n\nOur implementations utilize feed forward neural networks\nfor policy and Q-values. We parameterize the covariance\nΣφ as a diagonal given by eφ . The exploration for DDPG\nis determined by an Ornstein-Uhlenbeck process (Uhlenbeck & Ornstein, 1930; Lillicrap et al., 2016). Additional\nimplementation details are provided in the Appendix.\n\nFigure 4. Results of Smoothie with and without a KL-penalty. The\nx-axis is in millions of environment steps. We observe benefits of\nusing a proximal policy optimization method, especially in Hopper\nand Humanoid, where the performance improvement is significant\nwithout sacrificing sample efficiency.\n\nWe compare the results of Smoothie and DDPG in Figure 3.\nFor each task we performed a hyperparameter search over\nactor learning rate, critic learning rate and reward scale, and\nplot the average of six runs for the best hyperparameters.\nFor DDPG we extended the hyperparameter search to also\nconsider the scale and damping of exploratory noise provided by the Ornstein-Uhlenbeck process. Smoothie, on\nthe other hand, contains an additional hyperparameter to\ndetermine the weight on KL-penalty.\n\nwith and without the KL-penalty on the four harder tasks\nin Figure 4. A KL-penalty to encourage stability is not\npossible in DDPG. Thus, Smoothie provides a much needed\nsolution to the inherent instability in DDPG training.\n\nDespite DDPG having the advantage of its exploration decided by a hyperparameter search while Smoothie must\nlearn its exploration without supervision, we find that\nSmoothie performs competitively or better across all tasks,\nexhibiting a slight advantage in Swimmer and Ant, while\nshowing more dramatic improvements in Hopper, Walker2d,\nand Humanoid. The improvement is especially dramatic for\nHopper, where the average reward is doubled. We also highlight the results for Humanoid, which as far as we know, are\nthe best published results for a method that only trains on the\norder of millions of environment steps. In contrast, TRPO,\nwhich to the best of our knowledge is the only other algorithm that can achieve competitive performance, requires on\nthe order of tens of millions of environment steps to achieve\ncomparable reward. This gives added evidence to the benefits of using a learnable covariance and not restricting a\npolicy to be deterministic.\nEmpirically, we found the introduction of a KL-penalty to\nimprove performance of Smoothie, especially on harder\ntasks. We present a comparison of results of Smoothie\n\n7. Conclusion\nWe have presented a new Q-value function concept, Q̃π , that\nis a Gaussian-smoothed version of the standard expected\nQ-value, Qπ . The advantage of Q̃π over Qπ is that its\ngradient and Hessian possess an intimate relationship with\nthe gradient of expected reward with respect to mean and\ncovariance of a Gaussian policy. The resulting algorithm,\nSmoothie, is able to successfully learn both mean and covariance during training, leading to performance that surpasses\nthat of DDPG, especially when incorporating a penalty on\ndivergence from a previous policy.\nThe success of Q̃π is encouraging. Intuitively it appears\nadvantageous to learn Q̃π instead of Qπ . The smoothed Qvalues by definition make the true reward surface smoother,\nthus possibly easier to learn; moreover the smoothed Qvalues have a more direct relationship with the expected\ndiscounted return objective. We encourage further investigation of these claims and techniques for applying the\nunderlying motivations for Q̃π to other types of policies.\n\n\fSmoothed Action Value Functions for Learning Gaussian Policies\n\n8. Acknowledgment\n\nReferences\n\nWe thank Luke Metz, Sergey Levine, and the Google Brain\nteam for insightful comments and discussions.\n\nBellemare, Marc G, Dabney, Will, and Munos, Rémi. A\ndistributional perspective on reinforcement learning. In\nICML, pp. 449–458, 2017.\nBonnet, Georges. Transformations des signaux aléatoires a\ntravers les systemes non linéaires sans mémoire. Annals\nof Telecommunications, 19(9):203–220, 1964.\nBrockman, Greg, Cheung, Vicki, Pettersson, Ludwig,\nSchneider, Jonas, Schulman, John, Tang, Jie, and\nZaremba, Wojciech. OpenAI Gym. arXiv:1606.01540,\n2016.\nCiosek, Kamil and Whiteson, Shimon. Expected policy\ngradients. arXiv preprint arXiv:1706.05374, 2017.\nDegris, Thomas, White, Martha, and Sutton, Richard S.\nOff-policy actor-critic. ICML, 2012.\nGu, Shixiang, Lillicrap, Timothy, Ghahramani, Zoubin,\nTurner, Richard E, Schölkopf, Bernhard, and Levine,\nSergey. Interpolated policy gradient: Merging on-policy\nand off-policy gradient estimation for deep reinforcement\nlearning. NIPS, 2017.\nHaarnoja, Tuomas, Tang, Haoran, Abbeel, Pieter, and\nLevine, Sergey. Reinforcement learning with deep energybased policies. ICML, 2017.\nHeess, Nicolas, Wayne, Gregory, Silver, David, Lillicrap,\nTim, Erez, Tom, and Tassa, Yuval. Learning continuous\ncontrol policies by stochastic value gradients. In NIPS,\n2015.\nKingma, Diederik P and Welling, Max. Auto-encoding\nvariational bayes. ICLR, 2014.\nKonda, Vijay R and Tsitsiklis, John N. Actor-critic algorithms, 2000.\nLillicrap, Timothy P, Hunt, Jonathan J, Pritzel, Alexander,\nHeess, Nicolas, Erez, Tom, Tassa, Yuval, Silver, David,\nand Wierstra, Daan. Continuous control with deep reinforcement learning. ICLR, 2016.\nMetz, Luke, Ibarz, Julian, Jaitly, Navdeep, and Davidson,\nJames. Discrete sequential prediction of continuous actions for deep RL. CoRR, abs/1705.05035, 2017. URL\nhttp://arxiv.org/abs/1705.05035.\nMunos, Rémi, Stepleton, Tom, Harutyunyan, Anna, and\nBellemare, Marc. Safe and efficient off-policy reinforcement learning. In NIPS, 2016.\nNachum, Ofir, Norouzi, Mohammad, Xu, Kelvin, and Schuurmans, Dale. Bridging the gap between value and policy\nbased reinforcement learning. NIPS, 2017.\n\n\fSmoothed Action Value Functions for Learning Gaussian Policies\n\nNachum, Ofir, Norouzi, Mohammad, Xu, Kelvin, and Schuurmans, Dale. Trust-pcl: An off-policy trust region\nmethod for continuous control. ICLR, 2018.\nPrice, Robert. A useful theorem for nonlinear devices having\ngaussian inputs. IRE Transactions on Information Theory,\n4(2):69–72, 1958.\nRezende, Danilo Jimenez, Mohamed, Shakir, and Wierstra, Daan. Stochastic backpropagation and approximate\ninference in deep generative models. In International\nConference on Machine Learning, pp. 1278–1286, 2014.\nRummery, Gavin A and Niranjan, Mahesan. On-line Qlearning using connectionist systems, volume 37. 1994.\nSchulman, John, Levine, Sergey, Abbeel, Pieter, Jordan,\nMichael, and Moritz, Philipp. Trust region policy optimization. In ICML, 2015.\nSchulman, John, Wolski, Filip, Dhariwal, Prafulla, Radford,\nAlec, and Klimov, Oleg. Proximal policy optimization\nalgorithms. arXiv preprint arXiv:1707.06347, 2017.\nSilver, David, Lever, Guy, Heess, Nicolas, Degris, Thomas,\nWierstra, Daan, and Riedmiller, Martin. Deterministic\npolicy gradient algorithms. In ICML, 2014.\nSutton, Richard S. and Barto, Andrew G. Introduction to\nReinforcement Learning. MIT Press, 1998.\nSutton, Richard S, McAllester, David A, Singh, Satinder P,\nand Mansour, Yishay. Policy gradient methods for reinforcement learning with function approximation. NIPS,\n2000.\nTodorov, Emanuel, Erez, Tom, and Tassa, Yuval. Mujoco:\nA physics engine for model-based control. In Intelligent\nRobots and Systems (IROS), 2012 IEEE/RSJ International\nConference on, pp. 5026–5033. IEEE, 2012.\nUhlenbeck, George E and Ornstein, Leonard S. On the\ntheory of the brownian motion. Physical review, 36(5):\n823, 1930.\nVan Seijen, Harm, Van Hasselt, Hado, Whiteson, Shimon,\nand Wiering, Marco. A theoretical and empirical analysis\nof expected sarsa. In Adaptive Dynamic Programming\nand Reinforcement Learning, 2009. ADPRL’09. IEEE\nSymposium on, pp. 177–184. IEEE, 2009.\nWang, Ziyu, Bapst, Victor, Heess, Nicolas, Mnih,\nVolodymyr, Munos, Remi, Kavukcuoglu, Koray, and\nde Freitas, Nando. Sample efficient actor-critic with\nexperience replay. ICLR, 2017.\nWatkins, Christopher John Cornish Hellaby. Learning from\ndelayed rewards. PhD thesis, University of Cambridge\nEngland, 1989.\n\nWilliams, Ronald J and Peng, Jing. Function optimization\nusing connectionist reinforcement learning algorithms.\nConnection Science, 1991.\n\n\fSmoothed Action Value Functions for Learning Gaussian Policies\n\nA. Proof of Theorem 1\nWe want to show that for any s, a,\n1 ∂ 2 Q̃π (s, a)\n∂ Q̃π (s, a)\n= ·\n∂Σ(s)\n2\n∂a2\n\n(23)\n\nWe note that similar identities for Gaussian integrals exist in the literature (Price, 1958; Rezende et al., 2014) and point the\nreader to these works for further information.\nProof. The specific identity we state may be derived using standard matrix calculus. We make use of the fact that\n∂\n1\n1\n∂\n|A|−1/2 = − |A|−3/2\n|A| = − |A|−1/2 A−1 ,\n∂A\n2\n∂A\n2\n\n(24)\n\n∂\n||v||2A−1 = −A−1 vv T A−1 .\n∂A\n\n(25)\n\nand for symmetric A,\n\nWe omit s from Σ(s) in the following equations for succinctness. The LHS of (23) is\nZ\n∂\nQπ (s, ã)\nN (ã|a, Σ)dã\n∂Σ\nA\n\u001a\n\u001b\u0012\n\u0013\nZ\n1\n∂\n1\nπ\n2\n−1/2\n−1/2 ∂\n2\n=\nQ (s, ã) exp − ||ã − a||Σ−1\n|2πΣ|\n− |2πΣ|\n||ã − a||Σ−1 dã\n2\n∂Σ\n2\n∂Σ\nA\nZ\n\u0001\n1\n=\nQπ (s, ã)N (ã|a, Σ) −Σ−1 + Σ−1 (ã − a)(ã − a)T Σ−1 dã.\n2 A\nMeanwhile, towards tackling the RHS of (23) we note that\n∂ Q̃π (s, a)\n=\n∂a\n\nZ\n\nQπ (s, ã)N (ã|a, Σ)Σ−1 (ã − a)dã .\n\n(26)\n\nA\n\nThus we have\n∂ 2 Q̃π (s, a)\n∂a2\n\n\u0012\n\u0013\n∂\n∂\nQπ (s, ã) Σ−1 (ã − a) N (ã|a, Σ) + N (ã|a, Σ) Σ−1 (ã − a) dã\n∂a\n∂a\nA\nZ\nQπ (s, ã)N (ã|a, Σ)(Σ−1 (ã − a)(ã − a)T Σ−1 − Σ−1 ) dã .\nZ\n\n=\n=\n\nA\n\n\u0004\n\nB. Compatible Function Approximation\nWe claim that a Q̃πw is compatible with respect to µθ if\n1. ∇a Q̃πw (s, a)\n2. ∇w\n\nZ \u0010\n\na=µθ (s)\n\n∇a Q̃πw (s, a)\n\nS\n\n= ∇θ µθ (s)T w,\n\na=µθ (s)\n\n− ∇a Q̃π (s, a)\n\n\u00112\na=µθ (s)\n\nof the gradients).\nAdditionally, Q̃πw is compatible with respect to Σφ if\n1. ∇2a Q̃πw (s, a)\n\na=µθ (s)\n\n= ∇φ Σφ (s)T w,\n\ndρπ (s) = 0\n\n(i.e., w minimizes the expected squared error\n\n\fSmoothed Action Value Functions for Learning Gaussian Policies\n\n2. ∇w\n\nZ \u0010\n\n∇2a Q̃πw (s, a)\n\nS\n\na=µθ\n\n− ∇2a Q̃π (s, a)\n(s)\n\n\u00112\na=µθ (s)\n\ndρπ (s) = 0\n\n(i.e., w minimizes the expected squared error\n\nof the Hessians).\nProof. We shall show how the conditions stated for compatibility with respect to Σφ are sufficient. The reasoning for\nµθ follows via a similar argument. We also refer the reader to Silver et al. (2014) which includes a similar procedure for\nshowing compatibility.\nFrom the second condition for compatibility with respect to Σφ we have\nZ \u0010\n\u0011\n\u0010\n∇2a Q̃πw (s, a) a=µ (s) − ∇2a Q̃π (s, a) a=µ (s) ∇w ∇2a Q̃πw (s, a)\n\na=µθ (s)\n\nWe may combine this with the first condition to find\nZ\n∇2a Q̃πw (s, a) a=µ (s) ∇φ Σφ (s)dρπ (s)\n\na=µθ (s)\n\nθ\n\nS\n\nθ\n\nθ\n\nS\n\nZ\n=\n\n∇2a Q̃π (s, a)\n\nS\n\n\u0011\n\ndρπ (s)\n\n=\n\n0.\n\n∇φ Σφ (s)dρπ (s) ,\n\nwhich is the desired property for compatibility.\n\n\u0004\n\nC. Derivative Bellman Equations\nThe conditions for compatibility require training Q̃πw to fit the true Q̃π with respect to derivatives. Howevever, in RL\ncontexts, one often does not have access to the derivatives of the true Q̃π . In this section, we elaborate on a method to train\nQ̃πw to fit the derivatives of the true Q̃π without access to true derivative information.\nOur method relies on a novel formulation: derivative Bellman equations. We begin with the standard Q̃π Bellman equation\npresented in the main paper:\nZ\nh\ni\nQ̃π (s, a) =\nN (ã | a, Σ(s)) Er̃,s̃0 r̃ + γ Q̃π (s̃0 , µ(s̃0 )) dã .\n(27)\nA\n\nOne may take derivatives of both sides to yield the following identity for any k:\n∂ k Q̃π (s, a)\n=\n∂ak\n\nZ\nA\n\nh\ni\n∂ k N (ã | a, Σ(s))\nπ 0\n0\n0\nE\nr̃\n+\nγ\nQ̃\n(s̃\n,\nµ(s̃\n))\ndã .\nr̃,s̃\n∂ak\n\n(28)\n\nOne may express the k-the derivative of a normal density for k ≤ 2 simply as\n∂ k N (ã | a, Σ(s))\n= N (ã | a, Σ(s))Σ(s)−k/2 · Hk (Σ(s)−1/2 (ã − a)),\n∂ak\n\n(29)\n\nwhere Hk is a polynomial. Therefore, we have the following derivative Bellman equations for any k ≤ 2:\n∂ k Q̃π (s, a)\n=\n∂ak\n\nZ\n\nh\ni\nN (ã | a, Σ(s))Σ(s)−k/2 · Hk (Σ(s)−1/2 (ã − a)) Er̃,s̃0 r̃ + γ Q̃π (s̃0 , µ(s̃0 )) dã .\n\n(30)\n\nA\n\nOne may train a parameterized Q̃πw to satisfy these consistencies in a manner similar to that described in Section 4.2.\nSpecifically, suppose one has access to a tuple (s, ã, r̃, s̃0 ) sampled from a replay buffer with knowledge of the sampling\nprobability q(ã | s) (possibly unnormalized) with full support. Then we draw a phantom action a ∼ N (ã, Σ(s)) and optimize\nQ̃πw (s, a) by minimizing a weighted derivative Bellman error\n1\nq(ã|s)\n\n!2\n∂ k Q̃πw (s, a)\n− Σ(s)−k/2 · Hk (Σ(s)−1/2 (a − ã))(r̃ + γ Q̃πw (s̃0 , µ(s̃0 ))) ,\n∂ak\n\n(31)\n\nfor k = 0, 1, 2. As in the main text, it is possible to argue that when using target networks, this training procedure reaches\nan optimum when Q̃πw (s, a) satisfies the recursion in the derivative Bellman equations (30) for k = 0, 1, 2.\n\n\fSmoothed Action Value Functions for Learning Gaussian Policies\n\nHyperparameter\nactor learning rate\ncritic learning rate\nreward scale\nOU damping\nOU stddev\nλ\ndiscount factor\ntarget network lag\nbatch size\nclipping on gradients of Q\nnum gradient updates per observation\nHuber loss clipping\n\nRange\n[1e-6,1e-3]\n[1e-6,1e-3]\n[0.01,0.3]\n[1e-4,1e-3]\n[1e-3,1.0]\n[1e-6, 4e-2]\n0.995\n0.01\n128\n4.0\n1\n1.0\n\nSampling\nlog\nlog\nlog\nlog\nlog\nlog\nfixed\nfixed\nfixed\nfixed\nfixed\nfixed\n\nTable 1. Random hyperparameter search procedure. We also include the hyperparameters which we kept fixed.\n\nD. Implementation Details\nWe utilize feed forward networks for both policy and Q-value approximator. For µθ (s) we use two hidden layers of\ndimensions (400, 300) and relu activation functions. For Q̃πw (s, a) and Qπw (s, a) we first embed the state into a 400\ndimensional vector using a fully-connected layer and tanh non-linearity. We then concatenate the embedded state with a\nand pass the result through a 1-hidden layer neural network of dimension 300 with tanh activations. We use a diagonal\nΣφ (s) = eφ for Smoothie, with φ initialized to −1.\nTo find optimal hyperparameters we perform a 100-trial random search over the hyperparameters specified in Table 1.\nThe OU exploration parameters only apply to DDPG. The λ coefficient on KL-penalty only applies to Smoothie with a\nKL-penalty.\n\n\f",
         "train",
         "48444",
         "8270"
        ],
        [
         "25",
         "19536",
         "cs.AI",
         "Artificial Intelligence",
         "1803.02839v1.pdf",
         "The emergent algebraic structure of RNNs and embeddings in\nNLP\n\narXiv:1803.02839v1 [cs.CL] 7 Mar 2018\n\nSean A. Cantrell\nExcella Consulting AI Research\nsean.cantrell@excella.com\n\nAbstract\nWe examine the algebraic and geometric properties of a uni-directional GRU and word embeddings trained end-to-end on a text classification task. A hyperparameter search over word embedding\ndimension, GRU hidden dimension, and a linear combination of the GRU outputs is performed. We\nconclude that words naturally embed themselves in a Lie group and that RNNs form a nonlinear\nrepresentation of the group. Appealing to these results, we propose a novel class of recurrent-like\nneural networks and a word embedding scheme.\n\n1\n\nIntroduction\n\nTremendous advances in natural language processing (NLP) have been enabled by novel deep neural\nnetwork architectures and word embeddings. Historically, convolutional neural network (CNN)[1, 2] and\nrecurrent neural network (RNN)[3, 4] topologies have competed to provide state-of-the-art results for\nNLP tasks, ranging from text classification to reading comprehension. CNNs identify and aggregate\npatterns with increasing feature sizes, reflecting our common practice of identifying patterns, literal or\nidiomatic, for understanding language; they are thus adept at tasks involving key phrase identification.\nRNNs instead construct a representation of sentences by successively updating their understanding of\nthe sentence as they read new words, appealing to the formally sequential and rule-based construction\nof language. While both networks display great efficacy at certain tasks [5], RNNs tend to be the\nmore versatile, have emerged as the clear victor in, e.g., language translation [6, 7, 8], and are typically\nmore capable of identifying important contextual points through attention mechanisms for, e.g., reading\ncomprehension [9, 10, 11, 12]. With an interest in NLP, we thus turn to RNNs.\nRNNs nominally aim to solve a general problem involving sequential inputs. For various more specified\ntasks, specialized and constrained implementations tend to perform better [13, 14, 15, 8, 16, 17, 18, 11,\n12, 9, 10]. Often, the improvement simply mitigates the exploding/vanishing gradient problem [19, 20],\nbut, for many tasks, the improvement is more capable of generalizing the network’s training for that\ntask. Understanding better how and why certain networks excel at certain NLP tasks can lead to more\nperformant networks, and networks that solve new problems.\nAdvances in word embeddings have furnished the remainder of recent progress in NLP [21, 22, 23, 24,\n25, 26]. Although it is possible to train word embeddings end-to-end with the rest of a network, this is\noften either prohibitive due to exploding/vanishing gradients for long corpora, or results in poor embeddings for rare words [27]. Embeddings are thus typically constructed using powerful, but heuristically\n1\n\n\fmotivated, procedures to provide pre-trained vectors on top of which a network can be trained. As with\nthe RNNs themselves, understanding better how and why optimal embeddings are constructed in, e.g.,\nend-to-end training can provide the necessary insight to forge better embedding algorithms that can be\ndeployed pre-network training.\nBeyond improving technologies and ensuring deep learning advances at a breakneck pace, gaining a\nbetter understanding of how these systems function is crucial for allaying public concerns surrounding\nthe often inscrutable nature of deep neural networks. This is particularly important for RNNs, since\nnothing comparable to DeepDream or Lucid exists for them [28].\nTo these ends, the goal of this work is two fold. First, we wish to understand any emergent algebraic\nstructure RNNs and word embeddings, trained end-to-end, may exhibit. Many algebraic structures are\nwell understood, so any hints of structure would provide us with new perspectives from which and tools\nwith which deep learning can be approached. Second, we wish to propose novel networks and word\nembedding schemes by appealing to any emergent structure, should it appear.\nThe paper is structured as follows. Methods and experimental results comprise the bulk of the paper,\nso, for faster reference, §2 provides a convenient summary and intrepretation of the results, and outlines\na new class of neural network and new word embedding scheme leveraging the results. §3 motivates the\ninvestigation into algebraic structures and explains the experimental setup. §4 Discusses the findings from\neach of the experiments. §5 interprets the results, and motivates the proposed network class and word\nembeddings. §6 provides closing remarks and discusses followup work, and §7 gives acknowledgments.\nTo make a matter of notation clear going forward, we begin by referring to the space of words as W ,\nand transition to G after analyzing the results in order to be consistent with notation in the literature\non algebraic spaces.\n\n2\n\nSummary of results\n\nWe embedded words as vectors and used a uni-directional GRU connected to a dense layer to classify\nthe account from which tweets may have originated. The embeddings and simple network were trained\nend-to-end to avoid imposing any artificial or heuristic constraints on the system.\nThere are two primary takeaways from the work presented herein:\n• Words naturally embed as elements in a Lie group, G, and end-to-end word vectors may be related\nto the generating Lie algebra.\n• RNNs learn to parallel transport nonlinear representations of G either on the Lie group itself, or\non a principal G-bundle.\nThe first point follows since 1) words are embedded in a continuous space; 2) an identity word exists\nthat causes the RNN to act trivially on a hidden state; 3) word inverses exist that cause the RNN to\nundo its action on a hidden state; 4) the successive action of the RNN using two words is equivalent\nto the action of the RNN with a single third word, implying the multiplicative closure of words; and 5)\nwords are not manifestly closed under any other binary action.\nThe second point follows given that words embed on a manifold, sentences traces out paths on the\nmanifold, and the difference equation the RNN solves bears a striking resemble to the first order equation\nfor parallel transport,\n(ht+1 − ht ) + γwt ht =0\nγwt ≡1 − Rwt ,\n2\n\n(2.1)\n(2.2)\n\n\fwhere ht is the t-th hidden state encountered when reading over a sentence and Rwt is the RNN conditioned\nby the t-th word, wt , acting on the hidden state. Since sentences trace out a path on the word manifold,\nand parallel transport operators for representations of the word manifold take values in the group, the\nRNN must parallel transport hidden states either on the group itself or on a base space, M , equipped\nwith some word field, w : M → G, that connects the path in the base space to the path on the word\nmanifold.\nLeveraging these results, we propose two new technologies.\nFirst, we propose a class of recurrent-like neural networks for NLP tasks that satisfy the differential\nequation\nDtn h(t) = 0,\n(2.3)\nwhere\nDt = ∂t + v µ (t)Γµ ,\n\n(2.4)\n\nand where Γ and v are learned functions. n = 1 corresponds to traditional RNNs, with v µ Γµ ∝ γ.\nFor n > 1, this takes the form of RNN cells with either nested internal memories or dependencies that\nextend temporally beyond the immediately previous hidden state. In particular, using n = 2 for sentence\ngeneration is the topic of a manuscript presently in preparation.\nSecond, we propose embedding schemes that explicitly embed words as elements of a Lie group. In\npractice, these embedding schemes would involve representing words as constrained matrices, and optimizing the elements, subject to the constraints, according to a loss function constructed from invariants\nof the matrices, and then applying the matrix log to obtain Lie vectors. A prototypical implementation,\nin which the words are assumed to be in the fundamental representation of the special orthogonal group,\nSO(N ), and are conditioned on losses sensitive to the relative actions of words, is the subject of another\nmanuscript presently in preparation.\nThe proposals are only briefly discussed herein, as they are the focus of followup work; the focus\nof the present work is on the experimental evidence for the emergent algebraic structure of RNNs and\nembeddings in NLP.\n\n3\n3.1\n\nMotivation and experimental setup\nIntuition and motivation\n\nWe provide two points to motivate examining the potential algebraic properties of RNNs and their space\nof inputs in the context of NLP.\nFirst, a RNN provides a function, R, that successively updates a hidden memory vector, h ∈ H,\ncharacterizing the information contained in a sequence of input vectors, {w1 , w2 , . . . } ∈ W , as it reads\nover elements of the sequence. Explicitly, R : W × H → H. At face value, R takes the same form\nas a (nonlinear) representation of some general algebraic structure, W , with at least a binary action,\n· : W × W → W , on the vector space H. While demanding much structure on W generally places a\nstrong constraint on the network’s behavior, it would be fortuitous for such structure to emerge. Generally,\nconstrained systems still capable of performing a required task will perform the task better, or, at least,\ngeneralize more reliably [29, 30, 31, 32, 33, 34]. To this end, the suggestive form RNNs assume invites\nfurther examination to determine if there exist any reasonable constraints that may be placed on the\nnetwork. To highlight the suggestiveness of this form in what follows, we represent the W argument\nof R as a subscript and the H argument by treating R as a left action on H, adopting the notation\n3\n\n\fR(w, h) → Rw h. Since, in this paper, we consider RNNs vis-à-vis NLP, we take W as the (continuous)\nset of words1 .\nSecond, in the massive exploration of hyperparameters presented in [6], it was noted that, for a given\nword embedding dimension, the network’s performance on a seq2seq task was largely insensitive to the\nhidden dimension of the RNN above a threshold (∼128). The dimension of admissible representations of\na given algebraic structure is generally discrete and spaced out. Interpreting neurons as basis functions\nand the output of layers as elements of the span of the functions [35, 36, 37], we would expect a network’s\nperformance to improve until an admissible dimension for the representation is found, after which the\naddition of hidden neurons would simply contribute to better learning the components of the proper\nrepresentation by appearing in linear combinations with other neurons, and contribute minimally to\nimproving the overall performance. In their hyperparameter search, a marginal improvement was found\nat a hidden dimension of 2024, suggesting a potentially better representation may have been found.\nThese motivating factors may hint at an underlying algebraic structure in language, at least when\nusing RNNs, but they raise the question: what structures are worth investigating?\nGroups present themselves as a candidate for consideration since they naturally appear in a variety of\napplications. Unitary weight matrices have already enjoyed much success in mitigating the exploding/vanishing gradients problem [14, 15], and RNNs even further constrained to act explicitly as nonlinear\nrepresentations of unitary groups offer competitive results [16]. Moreover, intuitively, RNNs in NLP\ncould plausibly behave as a group since: 1) the RNN must learn to ignore padding words used to square\nbatches of training data, indicating an identity element of W must exist; 2) the existence of contractions,\nportmanteaus, and the Germanic tradition of representing sentences as singular words suggest W might\nbe closed; and 3) the ability to backtrack and undo statements suggests language may admit natural\ninverses - that is, active, controlled “forgetting” in language may be tied to inversion. Indeed, groups\nseem reasonably promising.\nIt is also possible portmanteaus only make sense for a finite subset of pairs of words, so W may\ntake on the structure of a groupoid instead; moreover, it is possible, at least in classification tasks,\nthat information is lost through successive applications of R, suggesting an inverse may not actually\nexist, leaving W as either a monoid or category. W may also actually admit additional structure, or an\nadditional binary operation, rendering it a ring or algebra.\nTo determine what, if any, algebraic structure W possesses, we tested if the following axiomatic\nproperties of faithful representations of W hold:\n1. (Identity) ∃I ∈ W such that ∀h ∈ H, RI h = h\n2. (Closure under multiplication) ∀w1 , w2 ∈ W , ∃w3 ∈ W such that ∀h ∈ H, Rw2 Rw1 h = Rw3 h\n3. (Inverse) ∀w ∈ W , ∃w−1 ∈ W such that ∀h ∈ H, Rw−1 Rw h = Rw Rw−1 h = h\n4. (Closure under Lie bracket) ∀w1 , w2 ∈ W , ∃w3 ∈ W such that ∀h ∈ H, Rw2 Rw1 h−Rw1 Rw2 h = Rw3 h\nClosure under Lie bracket simultaneously checks for ring and Lie algebra structures.\nWhatever structure, if any, W possesses, it must additionally be continuous since words are typically\nembedded in continuous spaces. This implies Lie groups (manifolds), Lie semigroups with an identity\n(also manifolds), and Lie algebras (vector spaces with a Lie bracket) are all plausible algebraic candidates.\n1\n\nTraditionally, words are treated as categorical objects, and embedding them in a continuous (vector) space for computational purposes is largely a convenience; however, we relax this categorical perspective, and treat unused word vectors as\nacceptable objects as far as the algebraic structure is concerned, even if they are not actively employed in language.\n\n4\n\n\f3.2\n\nData and methods\n\nWe trained word embeddings and a uni-directional GRU connected to a dense layer end-to-end for text\nclassification on a set of scraped tweets using cross-entropy as the loss function. End-to-end training was\nselected to impose as few heuristic constraints on the system as possible. Each tweet was tokenized using\nNLTK TweetTokenizer and classified as one of 10 potential accounts from which it may have originated.\nThe accounts were chosen based on the distinct topics each is known to typically tweet about. Tokens\nthat occurred fewer than 5 times were disregarded in the model. The model was trained on 22106\ntweets over 10 epochs, while 5526 were reserved for validation and testing sets (2763 each). The network\ndemonstrated an insensitivity to the initialization of the hidden state, so, for algebraic considerations,\n( √1n , √1n , . . . ) was chosen for hidden dimension of n. A graph of the network is shown in Fig.(1).\nAlgebraic structures typically exhibit some relationship between the dimension of the structure and the\ndimension of admissible representations, so exploring the embedding and hidden dimensions for which\ncertain algebraic properties hold is of interest. Additionally, beyond the present interest in algebraic\nproperties, the network’s insensitivity to the hidden dimension invites an investigation into its sensitivity\nto the word embedding dimension. To address both points of interest, we extend the hyperparameter\nsearch of [6], and perform a comparative search over embedding dimensions and hidden dimensions to\ndetermine the impact of each on the network’s performance and algebraic properties. Each dimension in\nthe hyperparameter pair, (m, n) = (embedding dim, hidden dim), runs from 20 to 280 by increments of\n20.\n\nFigure 1: The simple network trained as a classifier: GRU→Dense→Linear→Softmax. There are 10 nonlinear neurons\ndedicated to each of the final 10 energies that are combined through a linear layer before softmaxing. This is to capitalize\non the universal approximation theorem’s implication that neurons serve as basis functions - i.e. each energy function\nis determined by 10 basis functions. The hidden dimension n of the GRU, and the word embedding dimension, are\nhyperparameters that are scanned over.\n\nAfter training the network for each hyperparameter pair, the GRU model parameters and embedding\nmatrix were frozen to begin testing for emergent algebraic structure. To satisfy the common “∀h ∈ H”\nrequirement stated in §3.1, real hidden states encountered in the testing data were saved to be randomly\nsampled when testing the actions of the GRU on states. 7 tests were conducted for each hyperparameter\npair with randomly selected states:\n1. Identity (“arbitrary identity”)\n5\n\n\f2. Inverse of all words in corpus (“arbitrary inverse”)\n3. Closure under multiplication of arbitrary pairs of words in total corpus (“arbitrary closure”)\n4. Closure under commutation of arbitrary pairs of words in total corpus (“arbitrary commutativity”)\n5. Closure under multiplication of random pairs of words from within each tweet (“intra-sentence\nclosure”)\n6. Closure of composition of long sequences of words in each tweet (“composite closure”)\n7. Inverse of composition of long sequences of words in each tweet (“composite inverse”)\nTests 6 and 7 were performed since, if closure is upheld, the composition of multiple words must also be\nupheld. These tests were done to ensure mathematical consistency.\nTo test for the existence of “words” that satisfy these conditions, vectors were searched for that,\nwhen inserted into the GRU, minimized the ratio of the Euclidean norms of the difference between the\n“searched” hidden vector and the correct hidden vector. For concreteness, the loss function for each\nalgebraic property from §3.1 were defined as follows:\n1. (Identity)\nLid =\n\n|Rx h − h|\n|h|\n\n(3.1a)\n\n2. (Closure under multiplication)\nLclosure =\n\n|Rx h − Rw2 Rw1 h|\n.\n|Rw2 Rw1 h|\n\n(3.1b)\n\n|Rx Rw h − h|\n|h|\n\n(3.1c)\n\n3. (Inverse)\nLinverse =\n4. (Closure under Lie bracket)\nLcom =\n\n|Rx h − (Rw2 Rw1 h − Rw1 Rw2 h)|\nmax (|(Rw2 Rw1 h − Rw1 Rw2 h)|, 10−6 )\n\n(3.1d)\n\nwhere wi are random, learned word vectors, h is a hidden state, and x is the model parameter trained to\nminimize the loss. We refer to Eqs.(3.1) as the “axiomatic losses.” It is worth noting that the non-zero\nhidden state initialization was chosen to prevent the denominators from vanishing when the initial state\nis selected as a candidate h in Eqs.(3.1a)&(3.1c). The reported losses below are the average across all w’s\nand h’s that were examined. Optimization over the losses in Eqs.(3.1) was performed over 5000 epochs.\nFor the associated condition to be satisfied, there must exist a word vector x that sufficiently minimizes\nthe axiomatic losses.\nIf it is indeed the case that the GRU attempts to learn a representation of an algebraic structure\nand each neuron serves as a basis function, it is not necessary that each neuron individually satisfies\nthe above constraints. For clarity, recall the second motivating point that the addition of neurons,\n6\n\n\fonce a representation is found, simply contributes to learning the representation better. Instead, only\na linear combination of the neurons must. We consider this possibility for the most task-performant\nhyperparameter pair, and two other capricious pairs. The target dimension of the linear combination, p,\nwhich we refer to as the “latent dimension,” could generally be smaller than the hidden dimension, n.\nTo compute the linear combination of the neurons, the outputs of the GRU were right-multiplied by a\nn × p matrix, P 2 :\nh →hP\nRw h →(Rw h)P\nRw2 Rw1 h →(Rw2 Rw1 h)P\n\n(3.2a)\n(3.2b)\n(3.2c)\n\nSince the linear combination is not à priori known, P is treated as a model parameter.\nThe minimization task previously described was repeated with this combinatorial modification while\nscanning over latent dimensions, p ∈ [20, n − 20], in steps of 20. The test was performed 10 times and\nthe reported results averaged for each value of p to reduce fluctuations in the loss from differing local\nminima. P was trained to optimize various combinations of the algebraic axioms, the results of which\nwere largely found to be redundant. In §4, we address the case in which P was only trained to assist\nin optimizing a single condition, and frozen in other axiomatic tests; the commutative closure condition,\nhowever, was given a separate linear combination matrix for reasons that will be discussed later.\nFinally, the geometric structure of the resulting word vectors was explored, naively using the Euclidean\nmetric. Sentences trace out (discrete) paths in the word embedding space, so it was natural to consider\nrelationships between both word vectors and vectors “tangent” to the sentences’ paths. Explicitly, the\nangles and distances between\n1. random pairs of words\n2. all words and the global average word vector\n3. random pairs of co-occurring words\n4. all words with a co-occurring word vector average\n5. adjacent tangent vectors\n6. tangent vectors with a co-occurring tangent vector average\nwere computed to determine how word vectors are geometrically distributed. Intuitively, similar words\nare expected to affect hidden states similarly. To test this, and to gain insight into possible algebraic\ninterpretations of word embeddings, the ratio of the Euclidean norm of the difference between hidden\nstates produced by acting on a hidden state with two different words to the Euclidean norm of the original\n2\n\nThere may be concern over the differing treatment of the output of the GRU and the input hidden state, since the\nformer is being projected into a lower dimension while the latter is not. If the linear combination matrix were trained in\nparallel to the GRU itself, there would be a degeneracy in the product between it and the GRU weight matrices in successive\nupdates, and it and the dense layer weight matrices after the final update, such that the effect of the linear combination\nwould be absorbed by the weight matrices. To this end, since we are considering linear combinations after freezing the\nGRU weight matrices, it is unnecessary to consider the role the linear combination matrix would play on the input hidden\nstates, and necessary for only the output of the GRU itself.\n\n7\n\n\fhidden state was computed as a function of the popular cosine similarity metric and distance between\nembeddings. This fractional difference, cosine similarity, and word distance were computed as,\n|Rw1 h − Rw2 h|\n|h|\nα α\ncos(θw ) =w1 w2 ,\n|∆w| =||w1 − w2 ||2 ,\nE=\n\n(3.3)\n(3.4)\n(3.5)\n\nwhere Einstein summation is applied to the (contravariant) vector indices.\nHigh-level descriptions of the methods will be briefly revisited in each subsection of §4 so that they\nare more self-contained and pedagogical.\n\n4\n4.1\n\nResults\nHyperparameters and model accuracy\n\nWe performed hyperparameter tuning over the word embedding dimension and the GRU hidden dimension to optimize the classifier’s accuracy. Each dimension ran from 20 to 280 in increments of 20. A\ncontour plot of the hyperparameter search is shown in Fig.(2).\n\nFigure 2: The range of the model accuracy is [50.1%, 89.7%].\nFor comparison, using pretrained, 50 dimensional GloVe vectors with this network architecture typically yielded accuracies on the order of O(50%) on this data set, even for more performant hidden\ndimensions. Thus, training the embeddings end-to-end is clearly advantageous for short text classification. It is worth noting that training them end-to-end is viable primarily because of the short length of\ntweets; for longer documents, exploding/vanishing gradients typically prohibits such training.\nThe average Fisher information of each hyperparameter dimension over the searched region was computed to determine the relative sensitivities of the model to the hyperparameters. The Fisher information for the hidden dimension was 4.63 × 10−6 ; the Fisher information for the embedding dimension was\n2.62 × 10−6 . Evidently, by this metric, the model was, on average in this region of parameter space, 1.76\ntimes more sensitive to the hidden dimension than the embedding dimension. Nevertheless, a larger word\nembedding dimension was critical for the network to realize its full potential.\n8\n\n\fThe model performance generally behaved as expected across the hyperparameter search. Indeed,\nhigher embedding and hidden dimensions tended to yield better results. Given time and resource constraints, the results are not averaged over many search attempts. Consequently, it is unclear if the pockets\nof entropy are indicative of anything deeper, or merely incidental fluctuations. It would be worthwhile\nto revisit this search in future work.\n\n4.2\n\nAlgebraic properties\n\nSeven tests were conducted for each hyperparameter pair to explore any emergent algebraic structure\nthe GRU and word embeddings may exhibit. Specifically, the tests searched for 1) the existence of an\nidentity element, 2) existence of an inverse word for each word, 3) multiplicative closure for arbitrary\npairs of words, 4) commutative closure for arbitrary pairs of words, 5) multiplicative closure of pairs of\nwords that co-occur within a tweet, 6) multiplicative closure of all sequences of words that appear in\ntweets, and 7) the existence of an inverse for all sequences of words that appear in tweets. The tests\noptimized the axiomatic losses defined in Eqs.(3.1).\nIn what follows, we have chosen L < 0.01 (or, 1% error) as the criterion by which we declare a\ncondition “satisfied.”\nThe tests can be broken roughly into two classes: 1) arbitrary solitary words and pairs of words, and\n2) pairs and sequences of words co-occurring within a tweet. The results for class 1 are shown in Fig.(3);\nthe results for class 2 are shown in Fig.(4).\n\n9\n\n\f(a)\n\n(b)\n\n(c)\n\n(d)\n\nFigure 3: The % axiomatic error as a function of the word embedding and GRU hidden dimensions. (a) The existence\nof an identity element for multiple hidden states. Note the log scale. (b) The existence of an inverse word for every word\nacting on random hidden states. Linear scale. (c) The existence of a third, ‘effective’ word performing the action of two\nrandomly chosen words in succession, acting on random states. Linear scale. (d) The existence of a third word performing\nthe action of the commutation of two randomly chosen words, acting on random states. Nonlinear scale.\n\n10\n\n\f(a)\n\n(b)\n\n(c)\n\n(d)\n\nFigure 4: The % axiomatic error as a function of the word embedding and GRU hidden dimensions. (a) The existence of\na third word performing the action of all, ordered words comprising a tweet, acting on the initial state. Linear scale. (b)\nThe existence of a word that reverses the action of the ordered words comprising a tweet that acted on the initial state.\nNonlinear scale. (c) The existence of a third word performing the action of two random words co-occurring within a tweet,\nacting on random states. Linear scale. (d) The existence of an inverse word for every word acting on random hidden states.\nThis is the same as in Fig.(3), and is simply provided for side-by-side comparison.\n\nThe identity condition was clearly satisfied for virtually all embedding and hidden dimensions, with\npossible exceptions for small embedding dimensions and large hidden dimensions. Although we did not\nexplicitly check, it is likely that even the possible exceptions would be viable in the linear combination\nsearch.\nArbitrary pairs of words were evidently not closed under multiplication without performing a linear\ncombination search, with a minimum error of 7.51% across all dimensions. Moreover, the large entropy\nacross the search does not suggest any fundamentally interesting or notable behavior, or any connections\nbetween the embedding dimension, hidden dimension, and closure property.\nArbitrary pairs of words were very badly not closed under commutation, and it is unfathomable that\neven a linear combination search could rescue the property. One might consider the possibility that\nspecific pairs of words might have still closed under commutation, and that the exceptional error was\ndue to a handful of words that commute outright since this would push the loss up with a near-vanishing\n11\n\n\fdenominator. As previously stated, the hidden states were not initialized to be zero states, and separate\nexperiments confirm that the zero state was not in the orbit of any non-zero state, so there would have\nbeen no hope to negate the vanishing denominator. Thus, this concern is in principle possible. However,\nexplicitly removing examples with exploding denominators (norm< 10−3 ) from the loss when performing\nlinear combination searches still resulted in unacceptable errors (80%+), so this possibility is not actually\nrealized. We did not explicitly check for this closure in class 2 tests since class 2 is a subset of class 1,\nand such a flagrant violation of the condition would not be possible if successful closure in class 2 were\naveraged into class 1 results. Even though commutative closure is not satisfied, it is curious to note that\nthe error exhibited a mostly well-behaved stratification.\nThe most interesting class 13 result was the arbitrary inverse. For embedding dimensions sufficiently\nlarge compared to the hidden dimension, inverses clearly existed even without a linear combination search.\nEven more remarkable was the well-behaved stratification of the axiomatic error, implying a very clear\nrelationship between the embedding dimension, hidden dimension, and emergent algebraic structure of\nthe model. It is not unreasonable to expect the inverse condition to be trivially satisfied in a linear\ncombination search for a broad range of hyperparameter pairs.\nThe same behavior of the inverse property is immediately apparent in all class 2 results. The stratification of the error was virtually identical, and all of the tested properties have acceptable errors for\nsufficiently large embedding dimensions for given hidden dimensions, even without a linear combination\nsearch.\n\n4.3\n\nLinear combination search\n\nThe optimal hyperparameter pair for this single pass of tuning was (m, n) = (280, 220), which resulted in\na model accuracy of 89.7%. This was not a statistically significant result since multiple searches were not\naveraged, so random variations in validation sets and optimization running to differing local minima may\nhave lead to fluctuations in the test accuracies. However, the selection provided a reasonable injection\npoint to investigate the algebraic properties of linear combinations of the output of the GRU’s neurons.\nFor comparison, we also considered (m, n) = (180, 220) and (m, n) = (100, 180).\nThe tests were run with the linear combination matrix, P , trained to assist in optimizing the composite\ninverse. The learned P was then applied to the output hidden states for the other properties except for\ncommutative closure, which was given its own linear combination matrix to determine if any existed that\nwould render it an emergent property.\nThe combination was trained to optimize a single condition because, if there exists an optimal linear\ncombination for one condition, and there indeed exists an underlying algebraic structure incorporating\nother conditions, the linear combination would be optimal for all other conditions.\nInitial results for the (m, n) = (280, 220) search is shown in Figs.(5)&(6). Well-optimized properties\nare shown in Fig.(5), while the expected poorly-optimized properties are shown in Fig.(6).\n3\n\nThe arbitrary inverse is neither, strictly, class 1 nor class 2 since it does not involve pairings with any other words. We\nsimply group it with class 1 to keep it distinct from the composite inverse experiment, which is decidedly class 2.\n\n12\n\n\f(a)\n\n(b)\n\n(c)\n\n(d)\n\nFigure 5: (m, n) = (280, 220). Graphs of % axiomatic error for the satisfied conditions after a linear combination search.\nThe graphs are ordered as they were in Fig.(4)\nThe four conditions examined in Fig.(5) are clearly satisfied for all latent dimensions. They all also\nreach a minimum error in the same region. Composite closure, intra-sentence closure, and arbitrary\ninverse are all optimized for p ≈ 100; composite inverse is optimized for p ≈ 120, though the variation in\nthe range [100, 140] is small (∼ 0.8% variation around the mean, or an absolute variation of ∼ 0.006% in\nthe error).\n(b)\n\n(a)\n\nFigure 6: (m, n) = (280, 220). Graphs of % axiomatic error for the unsatisfied conditions after a linear combination\nsearch.\n\nArbitrary multiplicative closure and commutative closure are highly anti-correlated, and both conditions are badly violated. It is worth noting that the results in Fig.(6)(b) did not remove commutative\npairs of words from the error, and yet the scale of the error in the linear combination search is virtually\nidentical to what was separately observed with the commutative pairs removed. They both also exhibit a\n13\n\n\fmonotonic dependence on the latent dimension. Despite their violation, this dependence is well-behaved,\nand potentially indicative of some other structure.\nBefore discussing the linear combination searches for the other selected hyperparameter pairs, it is\nworthwhile noting that retraining the network and performing the linear combination search again can\nyield differing results. Figs.(7)&(8) show the linear combination results after retraining the model for the\nsame hyperparameter pair, with a different network performance of 87.3%.\n(a)\n\n(b)\n\n(c)\n\n(d)\n\nFigure 7: (m, n) = (280, 220), retrained. Graphs of % axiomatic error for the satisfied conditions after a linear combination\nsearch. The graphs are ordered as they were in Fig.(4)\n\nQualitatively, the results are mostly the same: there is a common minimizing region of p, and conditions are satisfied, at least in the common minimal region. However, the minimizing region starkly\nshifted down, and became sharper for composite closure, intra-sentence closure, and arbitrary inverse.\n(a)\n\n(b)\n\nFigure 8: (m, n) = (280, 220), retrained. Graphs of % axiomatic error for the unsatisfied conditions after a linear\ncombination search.\n14\n\n\fOnce more, the results are mostly the same. Arbitrary closure error drastically increased, but both\nare still highly anti-correlated, and mostly monotonic, despite the erratic fluctuations in the arbitrary\nclosure error.\nFigs.(9)&(10) show the linear combination search for (m, n) = (180, 220). The model was retrained,\nand achieved 90.1% for the displayed results.\n(a)\n\n(b)\n\n(c)\n\n(d)\n\nFigure 9: (m, n) = (180, 220). Graphs of % axiomatic error for the satisfied conditions after a linear combination search.\nThe graphs are ordered as they were in Fig.(4)\nInterestingly, the optimal latent dimension occurs significantly higher than for the other reported\nhyperparameter pairs. This result, however, is not true for all retrainings at this (m, n) pair.\n(a)\n\n(b)\n\nFigure 10: (m, n) = (180, 220). Graphs of % axiomatic error for the unsatisfied conditions after a linear combination\nsearch.\n\nThe entropy in the arbitrary closure loss increased, and the commutative closure loss seemed to\nasymptote at higher latent dimension.\n15\n\n\fFigs.(11)&(12) show the linear combination search for (m, n) = (100, 180). The model was retrained,\nand achieved 87.1% for the displayed results.\n(a)\n\n(b)\n\n(c)\n\n(d)\n\nFigure 11: (m, n) = (100, 180). Graphs of % axiomatic error for the satisfied conditions after a linear combination search.\nThe graphs are ordered as they were in Fig.(4)\nAt lower dimensions, the optimal latent dimension was no longer shared between the satisfied conditions.\n(a)\n\n(b)\n\nFigure 12: (m, n) = (100, 180). Graphs of % axiomatic error for the unsatisfied conditions after a linear combination\nsearch.\n\nThe unsatisfied conditions displayed mostly the same behavior at lower dimensions.\n\n16\n\n\f4.4\n\nEmbedding structure\n\nTo explore the geometric distribution of word vectors, the angles and distances between 1) random pairs\nof words, 2) all words and the global average word vector, 3) random pairs of co-occurring words, 4) all\nwords with a co-occurring word vector average, 5) adjacent tangent vectors, 6) tangent vectors with a\nco-occurring tangent vector average were computed. The magnitudes of the average word vectors, average\nco-occurring word vectors, and average tangent vectors were also computed.\nAdditionally, the relative effect of words on states is computed verses their cosine similarities and\nrelative distances, measured by Eqs.(3.3)-(3.5).\nIn the figures that follow, there are, generally, three categories of word vectors explored: 1) random\nword vectors from the pool of all word vectors, 2) co-occurring word vectors, and 3) tangent vectors (the\ndifference vector between adjacent words).\nFig.(13) shows the distribution in the Euclidean norms of the average vectors that were investigated.\n\nFigure 13: The frequency distribution of the norm of average vectors. There was one instance of a norm for the average\nof all word vectors, hence the singular spike for its distribution. The other vector distributions were over the average for\ndifferent individual tweets.\n\nThe tangent vectors and average word vectors had comparable norms. The non-zero value of the\naverage word vector indicates that words do not perfectly distribute throughout space. The non-zero\nvalue of the average tangent vectors indicates that tweets in general progress in a preferred direction\nrelative to the origin in embedding space; albeit, since the magnitudes are the smallest of the categories\ninvestigated, the preference is only slight. The norm of the average of co-occurring word vectors is\nsignificantly larger than the norms of others categories of vectors, indicating that the words in tweets\ntypically occupy a more strongly preferred region of embedding space (e.g. in a cone, thus preventing\ncomponent-wise cancellations when computing the average).\nFig.(14) shows the distribution of the Euclidean cosine similarities of both pairs of vectors and vectors\nrelative to the categorical averages.\n\n17\n\n\f(a)\n\n(b)\n\nFigure 14: Distributions of cosine similarities of vectors with respect to (a) other vectors (b) category average vectors.\nAverages were taken as they were in Fig.(13).\nThe cosine similarity of pairs of random words and co-occurring words shared a very common distribution, albeit with the notable spikes are specific angles and a prominent spike at cos(θw ) = 1 for\nco-occurring pairs. The prominent spike could potentially be explained by the re-occurrence of punctuation within tweets, so it may not indicate anything of importance; the potential origin of the smaller\nspikes throughout the co-occurring distribution is unclear. Generally, the pairs strongly preferred to be\northogonal, which is unsurprising given recent investigations into the efficacy of orthogonal embeddings\n[38]. Adjacent pairs of tangent vectors, however, exhibited a very strong preference for obtuse relative\nangles, with a spike at cos(θw ) = −1.\nWords tended to have at most a very slightly positive cosine similarity to the global average, which\nis again indicative of the fact words did not spread out uniformly. Co-occurring words tended to form\nacute angles with respect to the co-occurring average. Meanwhile, tangent vectors strongly preferred to\nbe orthogonal to the average.\nThe strong negative cosine similarity of adjacent tangent vectors, and the strong positive cosine\nsimilarity of words with their co-occurring average, indicate co-occurring words tended to form a grid\nstructure in a cone. That is, adjacent words tended to be perpendicular to each other in the positive\nspan of some set of word basis vectors. Of course, this was not strictly adhered to, but the preferred\ngeometry is apparent.\nFig.(15) shows the distribution of the Euclidean distances of both pairs of vectors and vectors relative\nto the categorical averages.\n\n18\n\n\f(a)\n\n(b)\n\nFigure 15: Distributions of the Euclidean distances of vectors to (a) other vectors (b) category average vectors. Averages\nwere taken as they were in Fig.(13).\nDistributions of random pairs of words and co-occurring words were virtually identical in both plots,\nindicating that most of the variation is attributable to the relative orientations of the vectors rather than\nthe distances between them.\nFig.(16) shows the correlation of the similarity of the action of pairs of words to their cosine similarity\nand distances apart.\n\n19\n\n\f(a)\n\n(b)\n\nFigure 16: Plots of E with respect to (a) word cosine similarity, cos(θw ) (b) distance between words, |∆w|. Eqs.(3.3)-(3.5)\nBoth plots confirm that the more similar words are, the more similar their actions on the hidden states\nare. The strongly linear, bi-modal dependence of the fractional difference on the distance between words\nindicates that word distance is a stronger predictor of the relative meaning of words than the popular\ncosine similarity.\n\n5\n5.1\n\nDiscussion\nInterpretation of results\n\nThe important take-aways from the results are:\n20\n\n\f• The GRU trivially learned an identity ‘word’.\n• The action of the GRU for any individual word admits an inverse for sufficiently large embedding\ndimension relative to the hidden dimension.\n• The successive action of the GRU for any arbitrary pair of words is not, generally, equivalent to\nthe action of the GRU for any equivalent third ‘word’.\n• The commutation of successive actions of the GRU for any arbitrary pair of words is not equivalent\nto the action of the GRU for any equivalent third ‘word’.\n• The successive action of the GRU for any co-occurring pair of words is equivalent to the action of\nthe GRU for an equivalent third ‘word’ for sufficiently large embedding dimension relative to the\nhidden dimension.\n• The successive action of the GRU for any series of co-occuring words is equivalent to the action of\nthe GRU for an equivalent ‘word’ for sufficiently large embedding dimension relative to the hidden\ndimension.\n• The action of the GRU for any series of co-occurring words admits an inverse for sufficiently large\nembedding dimension relative to the hidden dimension.\n• Any condition satisfied for a sufficiently large embedding dimension relative to the hidden dimension\nis true for any pair of dimensions given an appropriate linear combination of the outputs of the\nGRU projected into an appropriate lower dimension (latent dimension).\n• The axiomatic errors for all satisfied conditions for the most performant models are minimized for\nspecific, shared latent dimensions, and increases away from these latent dimensions; the optimal\nlatent dimension is not shared for sufficiently small embedding dimensions.\n• Models with lower test performance tend to optimally satisfy these conditions for lower latent\ndimensions.\n• Co-occurring word vectors tend to be perpendicular to each other and occupy a cone in embedding\nspace.\n• The difference of the action of two word vectors on a hidden state increases linearly with the distance\nbetween the two words, and follows a generally bi-modal trend.\nAlthough there are still several outstanding points to consider, we offer an attempt to interpret these\nresults in this section.\nIdentity, inverse, and closure properties for co-occurring words are satisfied, and in such a way that\nthey are all related under some algebraic structure. Since closure is not satisfied for arbitrary pairs of\nwords, there are, essentially, two possible explanations for the observed structure:\n1. The union of all sets of co-occurring words is the Cartesian product of multiple Lie groups:\nW = G1 × G2 × . . . ,\n\n(5.1)\n\nwhere W is the space of words, and Gi is a Lie group. Since multiplication between groups is not\ndefined, the closure of arbitrary pairs of words is unsatisfied.\n21\n\n\f2. The GRU’s inability to properly close pairs of words it has never encountered together is the result\nof the generalization problem, and all words consequently embed in a larger Lie group:\nG1 × G2 × · · · ⊂ G = W.\n\n(5.2)\n\nIn either case, words can be considered elements of a Lie group. Since Lie groups are also manifolds, the\nword vector components can be interpreted as coordinates on this Lie group. Traditionally, Lie groups are\npractically handled by considering the Lie algebra that generates them, g, G = exp(g). The components\nof the Lie vectors in g are then typically taken to be the coordinates on the Lie group. This hints at\na connection between g and the word vectors, but this connection was not made clear by any of the\nexperiments. Furthermore, RNNs learn a nonlinear representation of the group on some latent space\nspanned by the hidden layer.\nSince sentences form paths on the embedding group, it’s reasonable to attempt to form a more precise\ninterpretation of the action of RNNs. We begin by considering their explicit action on hidden states as\nthe path is traversed:\nht+1 =Rwt ht =⇒\n(ht+1 − ht ) + γwt ht =0,\nγwt ≡1 − Rwt .\n\n(5.3a)\n(5.3b)\n(5.3c)\n\nEq.(5.3b) takes the form of a difference equation. In particular, it looks very similar to the finite form\nof the differential equation governing the nonlinear parallel transport along a path, m(t), on a principal\nfibre bundle with base space M and group G = exp(g). If the tangent vector at m(t) is v(t), and the\nvector being transported at m(t) is h(t) then we have\n∂t h(t) + v µ (t)Γµ [m(t), h(t)] =0,\n\n(5.4)\n\nwhere Γ is the (nonlinear) connection at m(t). If v were explicitly a function of m, Eq.(5.4) would take\na more familiar form:\n∂t h(t) + γm(t) [h(t)] =0,\nγm(t) ≡v µ [m(t)]Γµ [m(t), h(t)].\n\n(5.5a)\n(5.5b)\n\nGiven the striking resemblance between Eqs.(5.5a)&(5.3b), is it natural to consider either\n1. The word embedding group serving as the base space, M = G, so that the path m(t) corresponds\nexplicitly to the sentence path.\n2. A word field on the base space, w : M → G, so that there exists a mapping between m(t) and the\nsentence path.\nThe second option is more general, but requires both a candidate for M and a compelling way to connect\nm(t) and v(t). This is also more challenging, since, generally, parallel transport operators, while taking\nvalues in the group, are not closed. If the path were on G itself, closure would be guaranteed, since any\nparallel transport operator would be an element of the co-occurring subgroup, and closure arises from an\nequivalence class of paths.\nTo recapitulate the final interpretations of word embeddings and RNNs in NLP:\n• Words naturally embed as elements in a Lie group, G, and end-to-end word vectors may be related\nto the generating Lie algebra.\n• RNNs learn to parallel transport nonlinear representations of G either on the Lie group itself, or\non a principal G-bundle.\n22\n\n\f5.2\n\nProposal for class of recurrent-like networks\n\nThe geometric derivative along a path parameterized by t is defined as:\nDt = ∂t + v µ (t)Γµ ,\n\n(5.6)\n\nwhere v(t) is the tangent vector at t, and Γ is the connection. This implies RNNs learn the solution of\nthe first-order geometric differential equation:\nDt h(t) = 0.\n\n(5.7)\n\nIt is natural, then, to consider neural network solutions to higher-order generalizations:\nDtn h(t) = 0.\n\n(5.8)\n\nNetworks that solve Eq.(5.8) are recurrent-like. Updates to a hidden state will generally depend on states\nbeyond the immediately preceding one; often, this dependence can be captured by evolving on the phase\nspace of the hidden states, rather than on the sequences of the hidden states themselves. The latter\nresults in a nested RNN structure for the recurrent-like cell, similar to the structure proposed in [13].\nApplications of Eq.(5.8) are currently being explored. In particular, if no additional structure exists and RNNs parallel transport states along paths on the word embedding group itself (the first RNN\ninterpretation), geodesics emerge as a natural candidate for sentence paths to lie on. Thus, sentence generation could potentially be modeled using the geodesic equation and a nonlinear adjoint representation:\nn = 2, h ∈ g in Eq.(5.8). This geodesic neural network (GeoNN) is the topic of a manuscript presently\nin preparation.\n\n5.3\n\nProposal for new word embeddings\n\nThe embeddings trained end-to-end in this work provided highly performant results. Unfortunately,\ntraining embeddings on end-tasks with longer documents is challenging, and the resulting embeddings\nare often poor for rare words. However, it would seem constructing pre-trained word embeddings by\nleveraging the emergent Lie group structure observed herein could provide competitive results without\nthe need for end-to-end training.\nIntuitively, it is unsurprising groups appear as a candidate to construct word embeddings. Evidently,\nthe proximity of words is governed by their actions on hidden states, and groups are often the natural\nlanguage to describe actions on vectors. Since groups are generally non-commutative, embedding words in\na Lie group can additionally capture their order- and context-dependence. Lie groups are also generated\nby Lie algebras, so one group can act on the algebra of another group, and recursively form a hierarchical\ntower. Such an arrangement can explicitly capture the hierarchical structure language is expected to\nexhibit. E.g., the group structure in the first interpretation given by Eq.(5.1),\nG = G1 × G2 × G3 × . . . ,\n\n(5.9)\n\nadmits, for appropriately selected GN , hierarchical representations of the form\nRN :GN × gN −1 → gN −1 ,\nR1 :G1 × H → H,\n\n(5.10a)\n(5.10b)\n\nwhere GN = exp(gN ). Such embedding schemes have the potential to generalize current attempts at capturing hierarchy, such as Poincaré embeddings [23]. Indeed, hyperbolic geometries, such as the Poincaré\n23\n\n\fball, owe their structure to their isometry groups. Indeed, it is well known that the hyperbolic N + 1\ndimensional Minkowski space arises as a representation of SO(1, N ) + translation symmetries.\nIn practice, Lie group embedding schemes would involve representing words as constrained matrices\nand optimizing the elements, subject to the constraints, according to a loss function constructed from\ninvariants of the matrices, and then applying the matrix log to obtain Lie vectors. A prototypical\nimplementation, dubbed “LieGr,” in which the words are assumed to be in the fundamental representation\nof the special orthogonal group, SO(N ), and are conditioned on losses sensitive to the relative actions of\nwords, is the subject of another manuscript presently in preparation.\n\n6\n\nClosing remarks\n\nThe results presented herein offer insight into how RNNs and word embeddings naturally tend to structure\nthemselves for text classification. Beyond elucidating the inner machinations of deep NLP, such results\ncan be used to help construct novel network architectures and embeddings.\nThere is, however, much immediate followup work worth pursuing. In particular, the uniqueness of\nidentities, inverses, and multiplicative closure was not addressed in this work, which is critical to better\nunderstand the observed emergent algebraic structure. The cause for the hyperparameter stratification of\nthe error in, and a more complete exploration of, commutative closure remains outstanding. Additionally,\nthe cause of the breakdown of the common optimal latent dimension for low embedding dimension is\nunclear, and the bi-model, linear relationship between the action of words on hidden states and the\nEuclidean distance between end-to-end word embeddings invites much investigation.\nAs a less critical, but still curious inquiry: is the additive relationship between words, e.g. “king - man\n+ woman = queen,” preserved, or is it replaced by something new? In light of the Lie group structure\nwords trained on end tasks seem to exhibit, it would not be surprising if a new relationship, such as the\nBaker-Campbell-Hausdorff formula4 , applied.\n\n7\n\nAcknowledgements\n\nThe author would like to thank Robin Tully, Dr. John H. Cantrell, and Mark Laczin for providing useful\ndiscussions, of both linguistic and mathematical natures, as the work unfolded. Robin in particular\nprovided essential feedback throughout the work, and helped explore the potential use of free groups in\ncomputational linguistics at the outset. John furnished many essential conversations that ensured the\nscientific and mathematical consistency of the experiments, and provided useful insights into the results.\nMark prompted the investigation into potential emergent monoid structures since they appear frequently\nin state machines.\n\nReferences\n[1] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning applied to document\nrecognition,” Proceedings of the IEEE 86 no. 11, (1998) 2278–2324.\n[2] X. Zhang, J. Zhao, and Y. LeCun, “Character-level convolutional networks for text classification,”\narXiv:1509.01626.\n4\n\nSince the BCH formula is simply an non-commutative correction to the additive formula usually applied for analogies,\nit may be possible that this relation would already better represent analogies for disparately-related words.\n\n24\n\n\f[3] J. L. Elman, “Finding structure in time,” Cognitive science 14 no. 2, (1990) 179–211.\n[4] Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, and E. Hovy, “Hierarchical attention networks for\ndocument classification,” in Proceedings of the 2016 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Human Language Technologies, pp. 1480–1489.\n2016.\n[5] W. Yin, K. Kann, M. Yu, and H. Schütze, “Comparative study of cnn and rnn for natural language\nprocessing,” arXiv preprint arXiv:1702.01923 (2017) .\n[6] D. Britz, A. Goldie, T. Luong, and Q. Le, “Massive Exploration of Neural Machine Translation\nArchitectures,” ArXiv e-prints (Mar., 2017) , arXiv:1703.03906 [cs.CL].\n[7] C.-C. Chiu and C. Raffel, “Monotonic chunkwise attention,” arXiv preprint arXiv:1712.05382\n(2017) .\n[8] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and\nI. Polosukhin, “Attention is all you need,” in Advances in Neural Information Processing Systems,\npp. 6000–6010. 2017.\n[9] Y. Cui, Z. Chen, S. Wei, S. Wang, T. Liu, and G. Hu, “Attention-over-attention neural networks\nfor reading comprehension,” arXiv preprint arXiv:1607.04423 (2016) .\n[10] C. Xiong, V. Zhong, and R. Socher, “Dynamic coattention networks for question answering,” arXiv\npreprint arXiv:1611.01604 (2016) .\n[11] A. Kumar, O. Irsoy, P. Ondruska, M. Iyyer, J. Bradbury, I. Gulrajani, V. Zhong, R. Paulus, and\nR. Socher, “Ask me anything: Dynamic memory networks for natural language processing,” in\nInternational Conference on Machine Learning, pp. 1378–1387. 2016.\n[12] C. Xiong, S. Merity, and R. Socher, “Dynamic memory networks for visual and textual question\nanswering,” in International Conference on Machine Learning, pp. 2397–2406. 2016.\n[13] J. R. A. Moniz and D. Krueger, “Nested lstms,” arXiv:1801.10308.\n[14] M. Arjovsky, A. Shah, and Y. Bengio, “Unitary evolution recurrent neural networks,” in\nInternational Conference on Machine Learning, pp. 1120–1128. 2016.\n[15] S. Wisdom, T. Powers, J. Hershey, J. Le Roux, and L. Atlas, “Full-capacity unitary recurrent\nneural networks,” in Advances in Neural Information Processing Systems, pp. 4880–4888. 2016.\n[16] S. L. Hyland and G. Rätsch, “Learning unitary operators with help from u (n).,” in AAAI,\npp. 2050–2058. 2017.\n[17] R. Costa, I. A. Assael, B. Shillingford, N. de Freitas, and T. Vogels, “Cortical microcircuits as\ngated-recurrent neural networks,” in Advances in Neural Information Processing Systems,\npp. 272–283. 2017.\n[18] L. Jing, C. Gulcehre, J. Peurifoy, Y. Shen, M. Tegmark, M. Soljačić, and Y. Bengio, “Gated\northogonal recurrent units: On learning to forget,” arXiv preprint arXiv:1706.02761 (2017) .\n\n25\n\n\f[19] J. Chung, C. Gulcehre, K. Cho, and Y. Bengio, “Empirical evaluation of gated recurrent neural\nnetworks on sequence modeling,” arXiv preprint arXiv:1412.3555 (2014) .\n[20] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural computation 9 no. 8, (1997)\n1735–1780.\n[21] T. Mikolov, K. Chen, G. Corrado, and J. Dean, “Efficient estimation of word representations in\nvector space,” arXiv preprint arXiv:1301.3781 (2013) .\n[22] J. Pennington, R. Socher, and C. Manning, “Glove: Global vectors for word representation,” in\nProceedings of the 2014 conference on empirical methods in natural language processing (EMNLP),\npp. 1532–1543. 2014.\n[23] M. Nickel and D. Kiela, “Poincaré embeddings for learning hierarchical representations,” in\nAdvances in Neural Information Processing Systems, pp. 6341–6350. 2017.\n[24] R. Speer and J. Lowry-Duda, “Conceptnet at semeval-2017 task 2: Extending word embeddings\nwith multilingual relational knowledge,” arXiv preprint arXiv:1704.03560 (2017) .\n[25] T. Mikolov, E. Grave, P. Bojanowski, C. Puhrsch, and A. Joulin, “Advances in pre-training\ndistributed word representations,” arXiv preprint arXiv:1712.09405 (2017) .\n[26] L. Wu, A. Fisch, S. Chopra, K. Adams, A. Bordes, and J. Weston, “Starspace: Embed all the\nthings!,” arXiv preprint arXiv:1709.03856 (2017) .\n[27] D. Bahdanau, T. Bosc, S. Jastrzebski, E. Grefenstette, P. Vincent, and Y. Bengio, “Learning to\ncompute word embeddings on the fly,” arXiv preprint arXiv:1706.00286 (2017) .\n[28] C. Olah, A. Satyanarayan, I. Johnson, S. Carter, L. Schubert, K. Ye, and A. Mordvintsev, “The\nbuilding blocks of interpretability,” Distill (2018) . https://distill.pub/2018/building-blocks.\n[29] R. Pascanu, G. Montufar, and Y. Bengio, “On the number of response regions of deep feed forward\nnetworks with piece-wise linear activations,” arXiv preprint arXiv:1312.6098 (2013) .\n[30] G. F. Montufar, R. Pascanu, K. Cho, and Y. Bengio, “On the number of linear regions of deep\nneural networks,” in Advances in neural information processing systems, pp. 2924–2932. 2014.\n[31] R. Livni, S. Shalev-Shwartz, and O. Shamir, “On the computational efficiency of training neural\nnetworks,” in Advances in Neural Information Processing Systems, pp. 855–863. 2014.\n[32] M. Telgarsky, “Benefits of depth in neural networks,” arXiv preprint arXiv:1602.04485 (2016) .\n[33] T. Poggio, H. Mhaskar, L. Rosasco, B. Miranda, and Q. Liao, “Why and when can deep-but not\nshallow-networks avoid the curse of dimensionality: A review,” International Journal of\nAutomation and Computing 14 no. 5, (2017) 503–519.\n[34] K. Kawaguchi, L. P. Kaelbling, and Y. Bengio, “Generalization in deep learning,” arXiv preprint\narXiv:1710.05468 (2017) .\n[35] M. Raghu, J. Gilmer, J. Yosinski, and J. Sohl-Dickstein, “Svcca: Singular vector canonical\ncorrelation analysis for deep learning dynamics and interpretability,” in Advances in Neural\nInformation Processing Systems, pp. 6078–6087. 2017.\n26\n\n\f[36] B. C. Csáji, “Approximation with artificial neural networks,” Faculty of Sciences, Etvs Lornd\nUniversity, Hungary 24 (2001) 48.\n[37] K. Hornik, “Approximation capabilities of multilayer feedforward networks,” Neural networks 4\nno. 2, (1991) 251–257.\n[38] K. M. Choromanski, M. Rowland, and A. Weller, “The unreasonable effectiveness of structured\nrandom orthogonal embeddings,” in Advances in Neural Information Processing Systems,\npp. 218–227. 2017.\n\n27\n\n\f",
         "train",
         "58608",
         "9286"
        ],
        [
         "26",
         "19799",
         "cs.AI",
         "Artificial Intelligence",
         "1709.05706v6.pdf",
         "Published as a conference paper at ICLR 2018\n\nM EMORY AUGMENTED C ONTROL N ETWORKS\nArbaaz Khan, Clark Zhang, Nikolay Atanasov, Konstantinos Karydis,\nVijay Kumar, Daniel D. Lee\nGRASP Laboratory, University of Pennsylvania\n\narXiv:1709.05706v6 [cs.AI] 14 Feb 2018\n\nA BSTRACT\nPlanning problems in partially observable environments cannot be solved directly\nwith convolutional networks and require some form of memory. But, even memory\nnetworks with sophisticated addressing schemes are unable to learn intelligent\nreasoning satisfactorily due to the complexity of simultaneously learning to access\nmemory and plan. To mitigate these challenges we propose the Memory Augmented Control Network (MACN). The network splits planning into a hierarchical\nprocess. At a lower level, it learns to plan in a locally observed space. At a higher\nlevel, it uses a collection of policies computed on locally observed spaces to learn\nan optimal plan in the global environment it is operating in. The performance of\nthe network is evaluated on path planning tasks in environments in the presence of\nsimple and complex obstacles and in addition, is tested for its ability to generalize\nto new environments not seen in the training set.\n\n1\n\nI NTRODUCTION\n\nA planning task in a partially observable environment involves two steps: inferring the environment\nstructure from local observation and acting based on the current environment estimate. In the past,\nsuch perception-action loops have been learned using supervised learning with deep networks as\nwell as deep reinforcement learning (Daftry et al., 2016), (Chebotar et al., 2016), (Lee et al., 2017).\nPopular approaches in this spirit are often end-to-end (i.e. mapping sensor readings directly to motion\ncommands) and manage to solve problems in which the underlying dynamics of the environment or\nthe agent are too complex to model. Approaches to learn end-to-end perception-action loops have\nbeen extended to complex reinforcement learning tasks such as learning how to play Atari games\n(Mnih et al., 2013a), as well as to imitation learning tasks like controlling a robot arm (Levine et al.,\n2015).\nPurely convolutional architectures (CNNs) perform poorly when applied to planning problems due\nto the reactive nature of the policies learned by them (Zhang et al., 2016b), (Giusti et al., 2016).\nThe complexity of this problem is compounded when the environment is only partially observable as\nis the case with most real world tasks. In planning problems, when using a function approximator\nsuch as a convolutional neural network, the optimal actions are dependent on an internal state. If one\nwishes to use a state-less network (such as a CNN) to obtain the optimal action, the input for the\nnetwork should be the whole history of observations and actions. Since this does not scale well, we\nneed a network that has an internal state such as a recurrent neural network or a memory network.\n(Zhang et al., 2016a) showed that when learning how to plan in partially observable environments,\nit becomes necessary to use memory to retain information about states visited in the past. Using\nrecurrent networks to store past information and learn optimal control has been explored before\nin (Levine, 2013). While (Siegelmann & Sontag, 1995) have shown that recurrent networks are\nTuring complete and are hence capable of generating any arbitrary sequence in theory, this does not\nalways translate into practice. Recent advances in memory augmented networks have shown that it\nis beneficial to use external memory with read and write operators that can be learned by a neural\nnetwork over recurrent neural networks (Graves et al., 2014), (Graves et al., 2016). Specifically,\nwe are interested in the Differentiable Neural Computer (DNC) (Graves et al., 2016) which uses\nan external memory and a network controller to learn how to read, write and access locations in\nthe external memory. The DNC is structured such that computation and memory operations are\nseparated from each other. Such a memory network can in principle be plugged into the convolutional\n1\n\n\fPublished as a conference paper at ICLR 2018\n\narchitectures described above, and be trained end to end since the read and write operations are\ndifferentiable. However, as we show in our work, directly using such a memory scheme with CNNs\nperforms poorly for partially observable planning problems and also does not generalize well to new\nenvironments.\nTo address the aforementioned challenges we propose the Memory Augmented Control Network\n(MACN), a novel architecture specifically designed to learn how to plan in partially observable\nenvironments under sparse rewards.1 Environments with sparse rewards are harder to navigate since\nthere is no immediate feedback. The intuition behind this architecture is that planning problem can\nbe split into two levels of hierarchy. At a lower level, a planning module computes optimal policies\nusing a feature rich representation of the locally observed environment. This local policy along with\na sparse feature representation of the partially observed environment is part of the optimal solution\nin the global environment. Thus, the key to our approach is using a planning module to output\na local policy which is used to augment the neural memory to produce an optimal policy for the\nglobal environment. Our work builds on the idea of introducing options for planning and knowledge\nrepresentation while learning control policies in MDPs (Sutton et al., 1999). The ability of the\nproposed model is evaluated by its ability to learn policies (continuous and discrete) when trained in\nenvironments with the presence of simple and complex obstacles. Further, the model is evaluated on\nits ability to generalize to environments and situations not seen in the training set.\nThe key contributions of this paper are:\n1. A new network architecture that uses a differentiable memory scheme to maintain an estimate\nof the environment geometry and a hierarchical planning scheme to learn how to plan paths\nto the goal.\n2. Experimentation to analyze the ability of the architecture to learn how to plan and generalize\nin environments with high dimensional state and action spaces.\n\n2\n\nM ETHODOLOGY\n\nSection 2.1 outlines notation and formally states the problem considered in this paper. Section 2.2 and\n2.3 briefly cover the theory behind value iteration networks and memory augmented networks. Finally,\nin section 2.4 the intuition and the computation graph is explained for the practical implementation\nof the model.\n2.1\n\nP RELIMINARIES\n\nConsider an agent with state st ∈ S at discrete time t. Let the states S be a discrete set [s1 , s2 , . . . , sn ].\nFor a given action at ∈ A, the agent evolves according to known deterministic dynamics: st+1 =\nf (st , at ). The agent operates in an unknown environment and must remain safe by avoiding collisions.\nLet m ∈ {−1, 0}n be a hidden labeling of the states into free (0) and occupied (−1). The agent has\naccess to a sensor that reveals the labeling of nearby states through an observations zt = H(st )m ∈\n{−1, 0}n , where H(s) ∈ Rn×n captures the local field of view of the agent at state s. The local\nobservation consists of ones for observable states and zeros for unobservable states. The observation\nzt contains zeros for unobservable states. Note that m and zt are n × 1 vectors and can be indexed\nby the state st . The agent’s task is to reach a goal region S goal ⊂ S, which is assumed obstacle-free,\ni.e., m[s] = 0 for all s ∈ S goal . The\u0001 information available to the agent at time t to compute its action\nat is ht := s0:t , z0:t , a0:t−1 , S goal ∈ H, where H is the set of possible sequences of observations,\nstates, and actions. Our problem can then be stated as follows :\nProblem 1. Given an initial state s0 ∈ S with m[s0 ] = 0 (obstacle-free) and a goal region S goal ,\nfind a function µ : S → A such that applying the actions at := µ(st ) results in a sequence of states\ns0 , s1 , . . . , sT satisfying sT ∈ S goal and m[st ] = 0 for all t = 0, . . . , T .\nInstead of trying to estimate the hidden labeling m using a mapping approach, our goal is to learn a\npolicy µ that maps the sequence of sensor observations z0 , z1 , . . . zT directly to actions for the agent.\nThe partial observability requires an explicit consideration of memory in order to learn µ successfully.\nA partially observable problem can be represented via a Markov Decision Process (MDP) over\n1\n\nIn this work an agent receives a reward only when it has reached the goal prescribed by the planning task.\n\n2\n\n\fPublished as a conference paper at ICLR 2018\n\nthe history space H. More precisely, we consider a finite-horizon discounted MDP defined by\nM(H, A, T , r, γ), where γ ∈ (0, 1] is a discount factor, T : H × A → H is a deterministic transition\nfunction, and r : H → R is the reward function, defined as follows:\nT (ht , at ) = (ht , st+1 = f (st , at ), zt+1 = H(st+1 )m, at )\nr(ht , at ) = zt [st ]\nThe reward function definition stipulates that the reward of a state s can be measured only after its\noccupancy state has been observed.\nP\nGiven observations z0:t , we can obtain an estimate m̂ = max{ τ zτ , −1} of the map of the environment and use it to formulate a locally valid, fully-observable problem as the MDP Mt (S, A, f, r, γ)\nwith transition function given by the agent dynamics f and reward r(st ) := m̂[st ] given by the map\nestimate m̂.\n2.2\n\nVALUE I TERATION N ETWORKS\n\nThe typical algorithm to solve an MDP is Value Iteration (VI) (Sutton & Barto, 1998). The value of a\nstate (i.e. the expected reward over the time horizon if an optimal policy is followed) is computed\niteratively by calculating an action value function Q(s, a) for each state. The value for state s can\nthen be calculated by V (s) := maxa Q(s, a). By iterating multiple times over all states and all\nactions possible in each state, we can get a policy π = arg maxa Q(s, a). Given a transition function\nTr (s0 |s, a), the update rule for value iteration is given by (1)\nX\nVk+1 (s) = max[r(s, a) + γ\nTr (s0 |s, a)Vk (s)] .\n(1)\na\n\ns0\n\nA key aspect of our network is the inclusion of this network component that can approximate this\nValue Iteration algorithm. To this end we use the VI module in Value Iteration Networks (VIN) (Tamar\net al., 2016). Their insight is that value iteration can be approximated by a convolutional network\nwith max pooling. The standard form for windowed convolution is\nV (x) =\n\nx+w\nX\n\nV (k)u(k) .\n\n(2)\n\nk=x−w\n\nP\n(Tamar et al., 2016) show that the summation in (2) is analogous to s0 T (s0 |s, a)Vk (s) in (1).\nWhen (2) is stacked with reward, max pooled and repeated K times, the convolutional architecture\ncan be used to represent an approximation of the value iteration algorithm over K iterations.\n2.3\n\nE XTERNAL MEMORY N ETWORKS\n\nRecent works on deep learning employ neural networks with external memory (Graves et al.,\n2014), (Graves et al., 2016), (Kurach et al., 2015), (Parisotto & Salakhutdinov, 2017). Contrary to\nearlier works that explored the idea of the network learning how to read and access externally fixed\nmemories, these recent works focus on learning to read and write to external memories, and thus\nforgo the task of designing what to store in the external memory. We are specifically interested in the\nDNC (Graves et al., 2016) architecture. This is similar to the work introduced by (Oh et al., 2016)\nand (Chen et al., 2017). The external memory uses differentiable attention mechanisms to determine\nthe degree to which each location in the external memory M is involved in a read or write operation.\nThe DNC makes use of a controller (a recurrent neural network such as LSTM) to learn to read and\nwrite to the memory matrix. A brief overview of the read and write operations follows.2\n2.3.1\n\nR EAD AND W RITE O PERATION\n\nThe read operation is defined as a weighted average over the contents of the locations in the memory.\nThis produces a set of vectors defined as the read vectors. R read weightings {wtread,1 , . . . , wtread,R }\nare used to compute weighted averages of the contents of the locations in the memory. At time t the\nread vectors {re1t , . . . , reR\nt } are defined as :\nreit = Mt> wtread,i\n2\n\nWe refer the interested reader to the original paper (Graves et al., 2016) for a complete description.\n\n3\n\n(3)\n\n\fPublished as a conference paper at ICLR 2018\n\nwhere wtread,i are the read weightings, ret is the read vector, and Mt is the state of the memory at\ntime t. These read vectors are appended to the controller input at the next time step which provides it\naccess to the memory. The write operation consists of a write weight wtW , an erase vector et and\na write vector vt . The write vector and the erase vector are emitted by the controller. These three\ncomponents modify the memory at time t as :\nW >\nMt = Mt−1 (1 − wtW e>\nt ) + wt vt .\n\n(4)\n\nMemory addressing is defined separately for writing and reading. A combination of content-based\naddressing and dynamic memory allocation determines memory write locations, while a combination\nof content-based addressing and temporal memory linkage is used to determine read locations.\n2.4\n\nM EMORY AUGMENTED C ONTROL M ODEL\n\n(a) 2D Grid World\n\n(b) Sensor observation.\n\n(c) Policy for sensor observation.\n\nFigure 1: 2D Environment a) Let the agent (blue square) operate in a 2D environment. The goal\nregion is represented by the red square and the orange square represents the agents observation b)\nAgents observation. The gray area is not observable. c) It is possible to plan on this locally observed\nspace since it is a MDP.\nConsider the 2D grid world in Fig 1a. The agent is spawned randomly in this world and is represented\nby the blue square. The goal of the agent is to learn how to navigate to the red goal region. Let\nthis environment in Fig 1a be represented by a MDP M. The key intuition behind designing this\narchitecture is that planning in M can be decomposed into two levels. At a lower level, planning\nis done in a local space within the boundaries of our locally observed environment space. Let this\nlocally observed space be z 0 . Fig 1b represents this locally observed space. As stated before in\nSection 2.1, this observation can be formulated as a fully observable problem Mt (S, A, f, r, γ). It\nis possible to plan in Mt and calculate the optimal policy for this local space, πl∗ independent of\nprevious observations (Fig 1c). It is then possible to use any planning algorithm to calculate the\noptimal value function Vl∗ from the optimal policy πl∗ in z 0 . Let Π = [πl1 , πl2 , πl3 , πl4 , . . . , πln ] be the\nlist of optimal policies calculated from such consecutive observation spaces [z0 , z1 , . . . zT ]. Given\nthese two lists, it is possible to train a convolutional neural network with supervised learning.The\nnetwork could then be used to compute a policy πlnew when a new observation z new is recorded.\nThis policy learned by the convolutional network is purely reactive as it is computed for the z new\nobservation independent of the previous observations. Such an approach fails when there are local\nminima in the environment. In a 2D/3D world, these local minima could be long narrow tunnels\nculminating in dead ends (see Fig 2). In the scenario where the environment is populated with\ntunnels, (Fig 2) the environment is only partially observable and the agent has no prior knowledge\nabout the structure of this tunnel forcing it to explore the tunnel all the way to the end. Further,\nwhen entering and exiting such a structure, the agent’s observations are the same, i.e z1 = z2 , but\nthe optimal actions under the policies πl1 and πl2 (computed by the convolutional network) at these\ntime steps are not the same, i.e aπ1 6= aπ2 . To backtrack successfully from these tunnels/nodes,\ninformation about previously visited states is required, necessitating memory.\nTo solve this problem, we propose using a differentiable memory to estimate the map of the environment m̂. The controller in the memory network learns to selectively read and write information\n4\n\n\fPublished as a conference paper at ICLR 2018\n\nFigure 2: Environment with local minima. The agents observation when entering the tunnel to\nexplore it and when backtracking after seeing the dead end are the same. Using a reactive policy for\nsuch environments leads to the agent getting stuck near the dead end .\n\nto the memory bank. When such a differentiable memory scheme is trained it is seen that it keeps\ntrack of important events/landmarks (in the case of tunnel, this is the observation that the dead end\nhas been reached) in its memory state and discards redundant information. In theory one can use a\nCNN to extract features from the observation z 0 and pass these features to the differentiable memory.\nInstead, we propose the use of a VI module (Tamar et al., 2016) that approximates the value iteration\nalgorithm within the framework of a neural network to learn value maps from the local information.\nWe hypothesize that using these value maps in the differential memory scheme provides us with\nbetter planning as compared to when only using features extracted from a CNN. This architecture is\nshown in Figure 3.\nThe VI module is setup to learn how to plan on the local observations z. The local value maps (which\ncan be used to calculate local policies) are concatenated with a low level feature representation of the\nenvironment and sent to a controller network. The controller network interfaces with the memory\nthrough an access module (another network layer) and emits read heads, write heads and access\nheads. In addition, the controller network also performs its own computation for planning. The output\nfrom the controller network and the access module are concatenated and sent through a linear layer\nto produce an action. This entire architecture is then trained end to end. Thus, to summarize, the\nplanning problem is solved by decomposing it into a two level problem. At a lower level a feature\nrich representation of the environment (obtained from the current observation) is used to generate\nlocal policies. At the next level, a representation of the histories that is learned and stored in the\nmemory, and a sparse feature representation of the currently observed environment is used to generate\na policy optimal in the global environment.\nComputation Graph: To explain the computation graph, consider the case of a 2D grid world with\nrandomly placed obstacles, a start region and a goal region as shown in Fig 1a. The actions for\nthis grid world are considered to be discrete. The 2D grid world is presented in the form of an\nimage I of size m × n to the network. Let the goal region be [mgoal , ngoal ] and the start position be\n[mstart , nstart ]. At any given instant, only a small part of I is observed by the network and the rest\nof the image I is blacked out. This corresponds to the agent only observing what is visible within the\nrange of its sensor. In addition to this the image is stacked with a reward map Rm as explained in\n(Tamar et al., 2016). The reward map consists of an array of size m × n where all elements of the\narray except the one corresponding to index [mgoal , ngoal ] are zero. Array element corresponding\nto [mgoal , ngoal ] is set to a high value(in our experiments it is set to 1) denoting reward. The input\nimage of dimension [m × n × 2] is first convolved with a kernel of size (3 × 3), 150 channels and\nstride of 1 everywhere. This is then convolved again with a kernel of size (1,1), 4 channels and stride\nof 1. Let this be the reward layer R. R is convolved with another filter of size (3,3) with 4 channels.\nThis is the initial estimate of the action value function or Q(s, a). The initial value of the state V (s)\nis also calculated by taking max over Q(s, a). The operations up to this point are summarized by the\n\"Conv\" block in Figure 3. Once these initial values have been computed, the model executes a for\nloop k times (the value of k ranges based on the task). Inside the for loop at every iteration, the R and\nV are first concatenated. This is then convolved with another filter of size (3,3) and 4 channels to get\nthe updated action value of the state, Q(s, a). We find the value of the state V(s) by taking the max\n5\n\n\fPublished as a conference paper at ICLR 2018\n\nFigure 3: MACN Architecture. The architecture proposed uses convolutional layers to extract\nfeatures from the environment. The value maps are generated with these features. The controller\nnetwork uses the value maps and low level features to emit read and write heads in addition to doing\nits own planning computation.\nof the action value function. The values of the kernel sizes are constant across all three experiments.\nThe updated value maps are then fed into a DNC controller. The DNC controller is a LSTM (hidden\nunits vary according to task) that has access to an external memory. The external memory has 32\nslots with word size 8 and we use 4 read heads and 1 write head. This varies from task to task since\nsome of the more complex environments need more memory. The output from the DNC controller\nand the memory is concatenated through a linear layer to get prediction for the action that the agent\nshould execute. The optimizer used is the RMSProp and we use a learning rate of 0.0001 for our\nexperiments.\nThis formulation is easy enough to be extended to environments where the state space is larger than\ntwo dimensions and the action space is larger. We demonstrate this in our experiments.\n\n3\n\nE XPERIMENTS\n\nTo investigate the performance of MACN, we design our experiments to answer three key questions:\n• Can it learn how to plan in partially observable environments with sparse rewards?\n• How well does it generalize to new unknown environments?\n• Can it be extended to other domains?\nWe first demonstrate that MACN can learn how to plan in a 2D grid world environment. Without\nloss of generality, we set the probability of all actions equal. The action space is discrete, A :=\n{down, right, up, lef t}. This can be easily extended to continuous domains since our networks\noutput is a probability over actions. We show this in experiment 3.4. We then demonstrate that our\nnetwork can learn how to plan even when the states are not constrained to a two dimensional space\nand the action space is larger than four actions.\n3.1\n\nNAVIGATION IN PRESENCE OF SIMPLE OBSTACLES\n\nWe first evaluate the ability of our network to successfully navigate a 2D grid world populated with\nobstacles at random positions. We make the task harder by having random start and goal positions.\nThe full map shown in Fig. 4 is the top down view of the entire environment. The input to the\nnetwork is the sensor map, where the area that lies outside the agents sensing abilities is grayed out as\nexplained before. VIN: With just the VI module and no memory in place, we test the performance of\nthe value iteration network on this 2D partially observable environment. CNN + Memory: We setup\n6\n\n\fPublished as a conference paper at ICLR 2018\n\nFigure 4: Performance on grid world environment . In the map the blue square represents the start\nposition while the red square represents the goal. The red dotted line is the ground truth and the blue\ndash line represents the agents path. The maps shown here are from the test set and have not been\nseen before by the agent during training.\nModel\nVIN\nCNN + Memory\nMACN (LSTM)\nMACN\n\nPerformance\nSuccess(%)\nTest Error\nSuccess(%)\nTest Error\nSuccess (%)\nTest Error\nSuccess(%)\nTest Error\n\n16 × 16\n0\n0.63\n0.12\n0.43\n88.12\n0.077\n96.3\n0.02\n\n32 × 32\n0\n0.78\n0\n0.618\n73.4\n0.12\n85.91\n0.08\n\n64 × 64\n0\n0.81\n0\n0.73\n64\n0.21\n78.44\n0.13\n\nTable 1: Performance on 2D grid world with simple obstacles: All models are tested on maps\ngenerated via the same random process, and were not present in the training set. Episodes over 40\n(for a 16 × 16 wide map), 60 (for 32 × 32) and 80 (for 64 × 64) time steps were terminated and\ncounted as a failure. Episodes where the agent collided with an obstacle were also counted as failures.\n\na CNN architecture where the sensor image with the reward map is forward propagated through four\nconvolutional layers to extract features. We test if these features alone are enough for the memory\nto navigate the 2D grid world. A natural question to ask at this point is can we achieve planning in\npartially observable environments with just a planning module and a simple recurrent neural network\nsuch as a LSTM. To answer this we also test MACN with a LSTM in place of the memory scheme.\nWe present our results in Table 1. These results are obtained from testing on a held out test-set\nconsisting of maps with random start, goal and obstacle positions.\nOur results show that MACN can learn how to navigate partially observable 2D unknown environments. Note that the VIN does not work by itself since it has no memory to help it remember past\nactions. We would also like to point out that while the CNN + Memory architecture is similar to (Oh\net al., 2016), its performance in our experiments is very poor due to the sparse rewards structure.\nMACN significantly outperforms all other architectures. Furthermore, MACN’s drop in testing\naccuracy as the grid world scales up is not as large compared to the other architectures. While these\nresults seem promising, in the next section we extend the experiment to determine whether MACN\nactually learns how to plan or it is overfitting.\n3.2\n\nNAVIGATION IN PRESENCE OF LOCAL MINIMA\n\nThe previous experiment shows that MACN can learn to plan in 2D partially observable environments.\nWhile the claim that the network can plan on environments it has not seen before stands, this is\nweak evidence in support of the generalizability of the network. In our previous experiment the test\nenvironments have the same dimensions as in the training set, the number of combinations of random\nobstacles especially in the smaller environments is not very high and during testing some of the\nwrong actions can still carry the agent to the goal. Thus, our network could be overfitting and may\nnot generalize to new environments. In the following experiment we test our proposed network’s\ncapacity to generalize.\n7\n\n\fPublished as a conference paper at ICLR 2018\n\nFigure 5: Grid world environment with local minima. Left: In the full map the blue square\nrepresents the current position while the red square represents the goal. Center-left: The partial map\nrepresents a stitched together version of all states explored by the agent. Since the agent does not\nknow if the tunnel culminates in a dead end, it must explore it all the way to the end. Center-right:\nThe sensor input is the information available to the agent. Right: The full map that we test our agent\non after being trained on smaller maps. The dimensions of the map as well as the tunnel are larger.\n\nThe environment is setup with tunnels. The agent starts off at random positions inside the tunnel.\nWhile the orientation of the tunnel is fixed, its position is not. To comment on the the ability of our\nnetwork to generalize to new environments with the same task, we look to answer the following\nquestion: When trained to reach the goal on tunnels of a fixed length, can the network generalize to\nlonger tunnels in bigger maps not seen in the training set?\nThe network is set up the same way as before. The task here highlights the significance of using\nmemory in a planning network. The agent’s observations when exploring the tunnel and exiting the\ntunnel are the same but the actions mapped to these observations are different. The memory in our\nnetwork remembers past information and previously executed policies in those states, to output the\nright action. We report our results in Table 2. To show that traditional deep reinforcement learning\nperforms poorly on this task, we implement the DQN architecture as introduced in (Mnih et al.,\n2013b). We observe that even after one million iterations, the DQN does not converge to the optimal\npolicy on the training set. This can be attributed to the sparse reward structure of the environment.\nWe report similar findings when tested with A3C as introduced in (Mnih et al., 2016). We also\nobserve that the CNN + memory scheme learns to turn around at a fixed length and does not explore\nthe longer tunnels in the test set all the way to the end.\nModel\nDQN\nA3C\nCNN + Memory\nVIN\nMACN\n\nSuccess (%)\n0\n0\n12\n0\n100\n\nMaximum generalization length\n0\n0\n20\n0\n330\n\nTable 2: Performance on grid world with local minima: All models are trained on tunnels of\nlength 20 units. The success percentages represent the number of times the robot reaches the goal\nposition in the test set after exploring the tunnel all the way to the end. Maximum generalization\nlength is the length of the longest tunnel that the robot is able to successfully navigate after being\ntrained on tunnels of length 20 units.\nThese results offer insight into the ability of MACN to generalize to new environments. Our network\nis found capable of planning in environments it has not seen in the training set at all. On visualizing\nthe memory (see supplemental material), we observe that there is a big shift in the memory states\nonly when the agent sees the end of the wall and when the agent exits the tunnel. A t-sne (Maaten &\nHinton, 2008) visualization over the action spaces (see Fig. 6) clearly shows that the output of our\nnetwork is separable. We can conclude from this that the network has learned the spatial structure of\nthe tunnel, and it is now able to generalize to tunnels of longer length in larger maps.\n8\n\n\fPublished as a conference paper at ICLR 2018\n\nThus, we can claim that our proposed model is generalizable to new environments that are structurally\nsimilar to the environments seen in the training set but have not been trained on. In addition to\nthis in all our experiments are state and action spaces have been constrained to a small number of\ndimensions. In our next experiment we show that MACN can learn how to plan even when the state\nspace and action space are scaled up.\n\n(a) Raw Image Data\n\n(b) Output from VI module\n\n(c) Output from MACN\n\nFigure 6: T-sne visualization on 2D grid worlds with tunnels. a) T-sne visualization of the raw\nimages fed into the network. Most of the input images for going into the tunnel and exiting the\ntunnel are the same but have different action labels. b) T-sne visualization from the outputs of the pre\nplanning module. While it has done some separation, it is still not completely separable. c) Final\noutput from the MACN. The actions are now clearly separable.\n\n3.3\n\nG ENERAL G RAPH S EARCH\n\nIn our earlier experiments, the state space was constrained in two\ndimensions, and only four actions were available. It is nearly impossible to constrain every real world task to a two dimensional space\nwith only four actions. However, it is easier to formulate a lot of\npartially observable planning problems as a graph.We define our\nenvironment as an undirected graph G = (V, E) where the connections between the nodes are generated randomly (see Fig. 7). In Fig\n7 the blue node is the start state and the red node is the goal state.\nEach node represents a possible state the agent could be in. The\nagent can only observe all edges connected to the node it currently\nis in thus making it partially observable. The action space for this\nstate is then any of the possible nodes that the agent can visit next.\nAs before, the agent only gets a reward when it reaches the goal. We\nalso add in random start and goal positions. In addition, we add a Figure 7: 9 Node Graph\ntransition probability of 0.8. (For training details and generation of Search. Blue is start and Red\ngraph see Appendix.) We present our results in Table 3. On graphs is goal.\nwith small number of nodes, the reinforcement learning with DQN\nand A3C sometimes converge to the optimal goal due to the small\nstate size and random actions leading to the goal node in some of the cases. However, as before\nthe MACN outperforms all other models. On map sizes larger than 36 nodes, performance of our\nnetwork starts to degrade. Further, we observe that even though the agent outputs a wrong action\nat some times, it still manages to get to the goal in a reasonably small number of attempts. From\nthese results, we can conclude that MACN can learn to plan in more general problems where the state\nspace is not limited to two dimensions and the action space is not limited to four actions.\n3.4\n\nC ONTINUOUS CONTROL DOMAIN\n\nLearning how to navigate in unknown environments, where only some part of the environment\nis observable is a problem highly relevant in robotics. Traditional robotics solve this problem by\ncreating and storing a representation of the entire environment. However, this can quickly get memory\nintensive. In this experiment we extend MACN to a SE2 robot. The SE2 notation implies that the\n9\n\n\fPublished as a conference paper at ICLR 2018\n\nModel\nVIN\nA3C\nDQN\nCNN + Memory\nMACN (LSTM)\nMACN\n\n9 Nodes\n0.57, 23.39\nNA, 10\nNA, 12\n0.25, 81.5\n0.14, 98\n0.1, 100\n\nTest Error, Success(%)\n16 Nodes\n25 Nodes\n0.61, 14\n0.68, 0\nNA, 7\nNA, 0\nNA, 5.2\nNA, 0\n0.32, 63\n0.56, 19\n0.19, 96.27 0.26, 84.33\n0.18, 100\n0.22, 95.5\n\n36 Nodes\n0.71, 0\nNA, 0\nNA,0\n0.68, 9.7\n0.29, 78\n0.28, 89.4\n\nTable 3: Performance on General Graph Search. Test error is not applicable for the reinforcement\nlearning models A3C and DQN\n\n(b) Laser Scan\n\n(a) Robot Environment\n\n(c) Top Down View of Environment\n\nFigure 8: Navigation in a 3D environment on a continuous control robot. a) The robot is spawned\nin a 3d simulated environment. b) Only a small portion of the entire map is visible at any given point\nto the robot c) The green line denotes ground truth and red line indicates the output of MACN.\n\nrobot is capable of translating in the x-y plane and has orientation. The robot has a differential drive\ncontroller that outputs continuous control values. The robot is spawned in the environment shown in\nFig (8a). As before, the robot only sees a small part of the environment at any given time. In this case\nthe robot has a laser scanner that is used to perceive the environment.\nIt is easy to convert this environment to a 2D framework that the MACN needs. We fix the size\nof the environment to a m × n grid. This translates to a m × n matrix that is fed into the MACN.\nThe parts of the map that lie within the range of the laser scanner are converted to obstacle free and\nobstacle occupied regions and added to the matrix. Lastly, an additional reward map denoting a high\nvalue for the goal location and zero elsewhere as explained before is appended to the matrix and fed\ninto the MACN. The network output is used to generate way points that are sent to the underlying\ncontroller. The training set is generated by randomizing the spawn and goal locations and using a\nsuitable heuristic. The performance is tested on a held out test set of start and goal locations. More\nexperimental details are outlined in the appendix.\n10\n\n\fPublished as a conference paper at ICLR 2018\n\nWe observe in Table 4 that the proposed architecture\nis able to find its way to the goal a large number\nof times and its trajectory is close to the ground\ntruth. This task is more complex than the grid world\nnavigation due to the addition of orientation. The\nlack of explicit planning in the CNN + Memory\narchitecture hampers its ability to get to the goal\nTable 4: Performance on robot world\nin this task. In addition to this, as observed before\ndeep reinforcement learning is unable to converge\nto the goal. We also report some additional results in Fig 9. In Fig 9a we show that MACN converges\nfaster to the goal than other baselines.\nModel\nDQN,A3C\nVIN\nCNN + Memory\nMACN\n\nSuccess (%)\n0\n57.60\n59.74\n71.3\n\nIn addition to rate of convergence, one of the biggest advantages of MACN over other architectures,\nfor a fixed memory size is its ability to scale up when the size of the environment increases. We show\nthat MACN is able to beat other baselines when scaling up the environment. In this scenario, scaling\nup refers to placing the goal further away from the start position. While the success percentage\ngradually drops to a low value, it is observed that when the memory is increased accordingly, the\nsuccess percentage increases again. Lastly, in Fig 10 we observe that in the robot world, the\nperformance of MACN scales up to goal positions further away by adjusting the size of the external\nmemory in the differentiable block accordingly.\n\n(a) Dist. to goal vs number of steps\n\n(b) Success % vs goal distance\n\nFigure 9: Performance on simulated environment. a) We report a plot of the number of steps left\nto the goal as the agent executes the learned policy in the environment (Lower is better). In this plot,\nthe agent always starts at a position 40 steps away from the goal. b) The biggest advantage of MACN\nover other architectures is its ability to scale. We observe that as the distance to the goal increases,\nMACN still beats other baselines at computing a trajectory to the goal.(Higher success % is better)\n\nFigure 10: Effect of Memory in Robot World MACN scales well to larger environments in the\nrobot world when memory is increased suitably.\n\n11\n\n\fPublished as a conference paper at ICLR 2018\n\n3.5\n\nC OMPARISON WITH ANALYTICAL MOTION PLANNING BASELINES\n\nIn this section, we analyze the performance of the proposed network against traditional motion\nplanning baselines. As stated before, for the grid world environments and the tunnel task, we obtain\nexpert trajectories by running A∗ on the environment. In the case of the continuous control domain,\nwe use the the Human Friendly Navigation (HFN) paradigm Guzzi et al. (2013) which uses a variant\nof A∗ along with a constraint for safe distances from obstacles to plan paths from start location to\ngoal location. For the grid worlds (both with simple obstacles and local minima), we compute the\nratio of path length predicted by network architecture to the path length computed by A∗ . Our results\nare presented in Table 5.\nThe VIN alone is unable to reach the goal in a fixed number of steps. This behavior is consistent\nacross all grid worlds. In the case of the tunnels, the VIN gets stuck inside the local minima and is\nunable to navigate to the goal. Thus, the ratio of path length produced by VIN to the path length\nproduced by A∗ is infinite. In the case of the CNN+Memory, the network is able to navigate to the\ngoal only when the grid world is small enough. In the case of the tunnels, the CNN+Memory learns\nto turn around at a fixed distance instead of exploring the tunnel all the way to the end. For example,\nwhen trained on tunnels of length 20 units and tested on tunnels of length 32 and 64 units, the\nCNN+Memory turns around after it has traversed 20 units in the tunnel. For this task, to demonstrate\nthe ineffectiveness of the CNN+Memory model, we placed the goal just inside the tunnel at the dead\nend. Thus, the ratio of path length produced by CNN+Memory to A∗ is ∞ since the agent never\nexplored the tunnel all the way to the end. For the case of the MACN, we observe performance\nclose to A∗ for the small worlds. The performance gets worse when the size of the grid world is\nincreased. However, the dropoff for MACN with the DNC is lesser than that of the MACN with\nLSTM. For the tunnel world environment, both network architectures are successfully able to emulate\nthe performance of A∗ and explore the tunnel all the way to the end.\nIt is important to note here that A∗ is a model based approach and requires complete knowledge\nof the cost and other parameters such as the dynamics of the agent (transition probabilities). In\naddition, planners like A∗ require the user to explicitly construct a map as input, while MACN learns\nto construct a map to plan on which leads to more compact representations that only includes vital\nparts of the map (like the end of the tunnel in the grid world case). Our proposed method is a model\nfree approach that learns\n1. A dynamics model of the agent,\n2. A compact map representation,\n3. How to plan on the learned model and map.\nThis model free paradigm also allows us to move to different environments with a previously trained\npolicy and be able to perform well by fine-tuning it to learn new features.\nModel\nVIN\nCNN + Memory\nMACN (LSTM)\nMACN\n\nG(16 × 16)\n∞\n1.43\n1.2\n1.07\n\nA∗ Ratio\nG(32 × 32) G(64 × 64)\n∞\n∞\n2.86\n∞\n1.4\n1.62\n1.11\n1.47\n\nT(L =32)\n∞\n∞\n1.0\n1.0\n\nT(L = 64)\n∞\n∞\n1.0\n1.0\n\nTable 5: Comparison to A∗ . G corresponds to grid world with simple obstacles with the size of the\nworld specified inside the parenthesis. L corresponds to grid worlds with local minima/tunnels with\nthe length of the tunnel specified inside the parenthesis. All ratios are computed during testing. For\nthe worlds with tunnels, the network is trained on tunnels of length 20 units.\n\n4\n\nR ELATED W ORK\n\nUsing value iteration networks augmented with memory has been explored before in (Gupta et al.,\n2017). In their work a planning module together with a map representation of a robot’s free space is\n12\n\n\fPublished as a conference paper at ICLR 2018\n\nused for navigation in a partially observable environment using image scans. The image scans are\nprojected into a 2D grid world by approximating all possible robot poses. This projection is also\nlearned by the model. This is in contrast to our work here in which we design a general memory\nbased network that can be used for any partially observed planning problem. An additional difference\nbetween our work and that of (Gupta et al., 2017) is that we do not attempt to build a 2D map of the\nenvironment as this hampers the ability of the network to be applied to environments that cannot be\nprojected into such a 2D environment. We instead focusing on learning a belief over the environment\nand storing this belief in the differentiable memory. Another similar work is that of (Oh et al., 2016)\nwhere a network is designed to play Minecraft. The game environment is projected into a 2D grid\nworld and the agent is trained by RL to navigate to the goal. That network architecture uses a CNN to\nextract high level features followed by a differentiable memory scheme. This is in contrast to our\npaper where we approach this planning by splitting the problem into local and global planning. Using\ndifferential network schemes with CNNs for feature extraction has also been explored in (Chen et al.,\n2017). Lastly, a recently released paper Neural SLAM (Zhang et al., 2017) uses the soft attention\nbased addressing in DNC to mimic subroutines of simultaneous localization and mapping. This\napproach helps in exploring the environment robustly when compared to other traditional methods.\nA possible extension of our work presented here, is to use this modified memory scheme with the\ndifferentiable planner to learn optimal paths in addition to efficient exploration. We leave this for\nfuture work.\n\n5\n\nC ONCLUSION\n\nPlanning in environments that are partially observable and have sparse rewards with deep learning has\nnot received a lot of attention. Also, the ability of policies learned with deep RL to generalize to new\nenvironments is often not investigated. In this work we take a step toward designing architectures\nthat compute optimal policies even when the rewards are sparse, and thoroughly investigate the\ngeneralization power of the learned policy. In addition we show our network is able to scale well to\nlarge dimensional spaces.\nThe grid world experiments offer conclusive evidence about the ability of our network to learn how\nto plan in such environments. We address the concern of oversimplifying our environment to a 2D\ngrid world by experimenting with planning in a graph with no constraint on the state space or the\naction space. We also show our model is capable of learning how to plan under continuous control.\nIn the future, we intend to extend our policies trained in simulation to a real world platform such\nas a robot learning to plan in partially observable environments. Additionally, in our work we use\nsimple perfect sensors and do not take into account sensor effects such as occlusion, noise which\ncould aversely affect performance of the agent. This need for perfect labeling is currently a limitation\nof our work and as such cannot be applied directly to a scenario where a sensor cannot provide direct\ninformation about nearby states such as a RGB camera. We intend to explore this problem space in\nthe future, where one might have to learn sensor models in addition to learning how to plan.\n\nACKNOWLEDGEMENT\nWe gratefully acknowledge the support of ARL grants W911NF-08-2-0004 and W911NF-10-2-0016,\nARO grant W911NF-13-1-0350, ONR grants N00014-07-1-0829, N00014-14-1-0510, DARPA grant\nHR001151626/HR0011516850 and DARPA HR0011-15-C-0100, USDA grant 2015-67021-23857\nNSF grants IIS-1138847, IIS-1426840, CNS-1446592, CNS-1521617, and IIS-1328805. Clark Zhang\nis supported by the National Science Foundation Graduate Research Fellowship Program under Grant\nNo. DGE-1321851. The authors would like to thank Anand Rajaraman, Steven Chen, Jnaneswar Das,\nEkaterina Tolstoya and others at the GRASP lab for interesting discussions related to this paper.\n\nR EFERENCES\nYoshua Bengio, Jérôme Louradour, Ronan Collobert, and Jason Weston. Curriculum learning. In\nProceedings of the 26th annual international conference on machine learning, pp. 41–48. ACM,\n2009.\n13\n\n\fPublished as a conference paper at ICLR 2018\n\nYevgen Chebotar, Karol Hausman, Zhe Su, Gaurav S Sukhatme, and Stefan Schaal. Self-supervised\nregrasping using spatio-temporal tactile features and reinforcement learning. In Intelligent Robots\nand Systems (IROS), 2016 IEEE/RSJ International Conference on, pp. 1960–1966. IEEE, 2016.\nSteven W Chen, Nikolay Atanasov, Arbaaz Khan, Konstantinos Karydis, Daniel D Lee, and Vijay\nKumar. Neural network memory architectures for autonomous robot navigation. arXiv preprint\narXiv:1705.08049, 2017.\nShreyansh Daftry, J Andrew Bagnell, and Martial Hebert. Learning transferable policies for monocular\nreactive mav control. In International Symposium on Experimental Robotics, pp. 3–11. Springer,\n2016.\nAlessandro Giusti, Jérôme Guzzi, Dan C Cireşan, Fang-Lin He, Juan P Rodríguez, Flavio Fontana,\nMatthias Faessler, Christian Forster, Jürgen Schmidhuber, Gianni Di Caro, et al. A machine\nlearning approach to visual perception of forest trails for mobile robots. IEEE Robotics and\nAutomation Letters, 1(2):661–667, 2016.\nAlex Graves, Greg Wayne, and Ivo Danihelka.\narXiv:1410.5401, 2014.\n\nNeural turing machines.\n\narXiv preprint\n\nAlex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka GrabskaBarwińska, Sergio Gómez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou, et al.\nHybrid computing using a neural network with dynamic external memory. Nature, 538(7626):\n471–476, 2016.\nSaurabh Gupta, James Davidson, Sergey Levine, Rahul Sukthankar, and Jitendra Malik. Cognitive\nmapping and planning for visual navigation. arXiv preprint arXiv:1702.03920, 2017.\nJérôme Guzzi, Alessandro Giusti, Luca M Gambardella, Guy Theraulaz, and Gianni A Di Caro.\nHuman-friendly robot navigation in dynamic environments. In Robotics and Automation (ICRA),\n2013 IEEE International Conference on, pp. 423–430. IEEE, 2013.\nKarol Kurach, Marcin Andrychowicz, and Ilya Sutskever. Neural random-access machines. arXiv\npreprint arXiv:1511.06392, 2015.\nAlex X Lee, Sergey Levine, and Pieter Abbeel. Learning visual servoing with deep features and fitted\nq-iteration. arXiv preprint arXiv:1703.11000, 2017.\nSergey Levine. Exploring deep and recurrent architectures for optimal control. arXiv preprint\narXiv:1311.1761, 2013.\nSergey Levine, Chelsea Finn, Trevor Darrell, and Pieter Abbeel. End-to-end training of deep\nvisuomotor policies. arXiv preprint arXiv:1504.00702, 2015.\nLaurens van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of Machine\nLearning Research, 9(Nov):2579–2605, 2008.\nVolodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan\nWierstra, and Martin Riedmiller. Playing atari with deep reinforcement learning. arXiv preprint\narXiv:1312.5602, 2013a.\nVolodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan\nWierstra, and Martin Riedmiller. Playing atari with deep reinforcement learning. arXiv preprint\narXiv:1312.5602, 2013b.\nVolodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim\nHarley, David Silver, and Koray Kavukcuoglu. Asynchronous methods for deep reinforcement\nlearning. In International Conference on Machine Learning, pp. 1928–1937, 2016.\nJunhyuk Oh, Valliappa Chockalingam, Satinder Singh, and Honglak Lee. Control of memory, active\nperception, and action in minecraft. arXiv preprint arXiv:1605.09128, 2016.\nEmilio Parisotto and Ruslan Salakhutdinov. Neural map: Structured memory for deep reinforcement\nlearning. arXiv preprint arXiv:1702.08360, 2017.\n14\n\n\fPublished as a conference paper at ICLR 2018\n\nStuart J. Russell and Peter Norvig. Artificial Intelligence: A Modern Approach. Pearson Education, 2\nedition, 2003. ISBN 0137903952.\nHava T Siegelmann and Eduardo D Sontag. On the computational power of neural nets. Journal of\ncomputer and system sciences, 50(1):132–150, 1995.\nRichard S Sutton and Andrew G Barto. Reinforcement learning: An introduction, volume 1. MIT\npress Cambridge, 1998.\nRichard S Sutton, Doina Precup, and Satinder Singh. Between mdps and semi-mdps: A framework\nfor temporal abstraction in reinforcement learning. Artificial intelligence, 112(1-2):181–211, 1999.\nAviv Tamar, Yi Wu, Garrett Thomas, Sergey Levine, and Pieter Abbeel. Value iteration networks. In\nAdvances in Neural Information Processing Systems, pp. 2154–2162, 2016.\nSebastian Thrun and John J Leonard. Simultaneous localization and mapping. In Springer handbook\nof robotics, pp. 871–889. Springer, 2008.\nJingwei Zhang, Lei Tai, Joschka Boedecker, Wolfram Burgard, and Ming Liu. Neural slam. arXiv\npreprint arXiv:1706.09520, 2017.\nMarvin Zhang, Zoe McCarthy, Chelsea Finn, Sergey Levine, and Pieter Abbeel. Learning deep neural\nnetwork policies with continuous memory states. In Robotics and Automation (ICRA), 2016 IEEE\nInternational Conference on, pp. 520–527. IEEE, 2016a.\nTianhao Zhang, Gregory Kahn, Sergey Levine, and Pieter Abbeel. Learning deep control policies for\nautonomous aerial vehicles with mpc-guided policy search. In Robotics and Automation (ICRA),\n2016 IEEE International Conference on, pp. 528–535. IEEE, 2016b.\n\n15\n\n\fPublished as a conference paper at ICLR 2018\n\nAPPENDIX\n\nA\n\nG RID W ORLD E XPERIMENTS\n\nFor the grid world we define our sensor to be a 7 × 7 patch with the agent at the center of this patch.\nOur input image I to the VI module is [m × n × 2] image where m,n are the height and width of\nthe image. I[:, :, 0] is the sensor input. Since we set our rewards to be sparse, I[:, :, 1] is the reward\nmap and is zero everywhere except at the goal position (mgoal , ngoal ). I is first convolved to obtain a\nreward image R of dimension [n × m × u] where u is the number of hidden units (vary between\n100-150). This reward image is sent to the VI module. The value maps from the VI module after K\niterations are fed into the memory network controller. The output from the network controller (here a\nLSTM with 256 hidden units) and the access module is concatenated and sent through a linear layer\nfollowed by a soft max to get a probability distribution over A.\nDuring training and testing we roll out our sequence state by state based on the ground truth or the\nnetworks output respectively. Further, the set of transitions from start to goal to are considered to\nbe an episode. During training at the end of each episode the internal state of the controller and the\nmemory is cleared. The size of the external memory is 32 × 8 the grid world task. An additional\nhyperparameter is the number of read heads and write heads. This parameter controls the frequency\nof reads vs frequency of writes. For the the grid world task, we fix the number of read heads to 4\nand the number of write heads to 1. For the grid world with simple obstacles, we observe that the\nMACN performs better when trained with curriculum (Bengio et al., 2009). This is expected since\nboth the original VIN paper and the DNC paper show that better results are achieved when trained\nwith curriculum. For establishing baselines, the VIN and the CNN+Memory models are also trained\nwith curriculum learning. In the grid world environment it is easy to define tasks that are harder\nthan other tasks to aid with curriculum training. For a grid world with size (m, n) we increase the\ndifficulty of the task by increasing the number of obstacles and the maximum size of the obstacles.\nThus, for a 32 × 32 grid, we start with a maximum of 2 obstacles and the maximum size being 2 × 2.\nBoth parameters are then increased gradually. The optimal action in the grid world experiments is\ngenerated by A star (Russell & Norvig, 2003). We use the Manhattan distance between our current\nposition and the goal as a heuristic. Our error curves on the test set for the MACN with the LSTM\nand the addressable memory scheme are shown in Figure 11.\n\nFigure 11: Testing Error on grid world (32 x 32)\n\n16\n\n\fPublished as a conference paper at ICLR 2018\n\nB\n\nE NVIRONMENTS WITH T UNNELS\n\nWe setup the network the same way as we did for the grid world experiments with blob shaped\nobstacles. Due to the relatively simple structure of the environment, we observe that we do not really\nneed to train our networks with curriculum. Additionally, the read and write heads are both set to 1\nfor this experiment.\nB.1\n\nVI MODULE + PARTIAL M APS\n\nWe observe that for the tunnel shaped obstacle when just the VI module is fed the partial map (stitched\ntogether version of states explored) as opposed to the sensor input, it performs extremely well and is\nable to generalize to new maps with longer tunnels without needing any memory. This is interesting\nbecause it proves our intuition about the planning task needing memory. Ideally we would like the\nnetwork to learn this partial map on its own instead of providing it with a hand engineered version\nof it. The partial map represents an account of all states visited in the past. We argue that not all\ninformation from the past is necessary and the non redundant information that is required for planning\nin the global environment can be learned by the network. This can be seen in the memory ablation.\nB.2\n\nDQN\n\nAs stated in the main paper, we observe that the DQN performs very poorly since the rewards are very\nsparse. The network is setup exactly as described in (Mnih et al., 2013a). We observe that even after\n1 million iterations, the agent never reaches the goal and instead converges to a bad policy. This can\nbe seen in Figure 12. It is clear that under the random initial policy the agent is unable to reach the\ngoal and converged to a bad policy. Similar results are observed for A3C. Further, it is observed that\neven when the partial map instead of the sensor input is fed in to DQN, the agent does not converge.\n\nFigure 12: Learning optimal policy with Deep Q networks. In this case the input to the DQN\nis the sensor input. State after 1 million iterations. The agent gets stuck along the wall (left wall\nbetween 40 and 50)\n\nB.3\n\nV ISUALIZING THE M EMORY S TATE\n\nFor the tunnel task, we use an external memory with 32 rows (N = 32) and a word size of 8 (W = 8).\nWe observe that when testing the network, the memory registers a change in its states only when\nimportant events are observed. In Figure 11, the left hand image represents the activations from the\nmemory when the agent is going into the tunnel. We observe that the activations from the memory\nremain constant until the agent observes the end of the tunnel. The memory states change when\nthe agent observes the end of the tunnel, when it exits the tunnel and when it turns towards its goal\n(Figure 13). Another key observation for this task is that the MACN is prone to over fitting for this\ntask. This is expected because ideally, only three states need to be stored in the memory; entered the\ntunnel, observe end of tunnel and exit tunnel. To avoid overfitting we add L2 regularization to our\nmemory access weights.\n\n17\n\n\fPublished as a conference paper at ICLR 2018\n\nFigure 13: Shift in memory states just before and after the end of the tunnel is observed. Once the\nagent has turned around, the memory state stays constant till it reaches the end of the tunnel.\n\nC\n\nG RAPH E XPERIMENTS\n\nFor the graph experiment, we generate a random connected undirected graph with N nodes. We will\ncall this graph G = (V, E), with nodes V = {V1 , V2 , . . . , VN } and edges, E. The agent, at any point\nin the simulation, is located at a specific node Vi and travels between nodes via the edges. The agent\ncan take actions from a set U = {u1 , u2 , . . . , uN } where choosing action ui will attempt to move to\nnode Vi . We have transition probabilities\n\u001a\n0, if k 6= j or (Vi , Vj ) 6∈ E\np(Vj |Vi , uk ) =\n(5)\n1, if k = j and (Vi , Vj ) ∈ E\nAt each node, the agent has access to the unique node number (all nodes are labeled with a unique\nID), as well as the (A)i , the ith row of the adjacency matrix A. It also has access to the unique node\nnumber of the goal (but no additional information about the goal).\n\n(a) A random connected graph\n\n(b) Adjacency matrix for graph\n\nFigure 14: a) A random connected undirected graph with a the goal given by the star-shaped node,\nand the current state given by the blue node b) Shows the corresponding adjacency matrix where\nwhite indicates a connection and black indicates no connection. The goal is given by the row shaded\nin green, and the current state is given by the row shaded in blue.\nTo train the network to navigate this graph, we used supervised training with an expert demonstrating\nan intended behavior (breadth first search). Training samples were generated by running breadth first\nsearch (and connecting nodes that are explored by traveling previously explored nodes of the graph).\nThus, for each state of the node and goal, we obtain a desired action. To fit this into the framework of\nour network and 2D convolutions, we reshaped the row vector of the matrix into a matrix that could\n18\n\n\fPublished as a conference paper at ICLR 2018\n\nuse the same convolution operation. The reward prior is also a row vector with a 1 at the index of the\ngoal node and zero everywhere else. This row vector is reshaped and stacked with the observation.\nWe train the graph by giving example paths between pairs of nodes. We then test on pairs of nodes\nnot shown during training. The training network is setup as before in the grid world navigation task.\nDue to the increased action space and state space, this task is significantly more complex than the\ngrid world navigation task. We train MACN and the baselines with curriculum training. In the graph\ntask it is easy to define a measure of increasing complexity by changing the number of hops between\nthe start state and the goal state. Additionally, for the graph task the number of read heads and write\nheads are set to 1 and 4 respectively.\n\nD\n\nC ONTINUOUS C ONTROL\n\nNavigating an unknown environment is a highly\nrelevant problem in robotics. The traditional\nmethodology localizes the position of the robot\nin the unknown world and tries to estimate a\nmap. This approach is called Simultaneous Localization and Mapping (SLAM) and has been\nexplored in depth in robotics (Thrun & Leonard,\n2008). For the continuous control experiment,\nwe use a differential drive robot (Figure 15). The\nrobot is equipped with a head mounted LIDAR\nand also has a ASUS Xtion Pro that can provide\nthe depth as well as the image from the front\nfacing camera. In this work, we only use the\ninformation from the LIDAR and leave the idea\nFigure 15: Simulated ground robot\nof using data from the camera for future work.\nThe ground truth maps are generated by using\nHuman Friendly Navigation (HFN) (Guzzi et al., 2013) which generates reactive collision avoidance\npaths to the goal. Given a start and goal position, the HFN algorithm generates way points that are\nsent to the controller. For our experiment, we generate a tuple of (x, y, θ) associated with every\nobservation. To train the network, a m × n matrix (environment matrix) corresponding to the m × n\nenvironment is initialized. A corresponding reward array (reward matrix) also of size m × n with a 1\nat the goal position and zero elsewhere is concatenated with the environment matrix. The observations\ncorresponding to the laser scan are converted to a j × k matrix (observation matrix) where j < m\nand k < n. The values at the indices in the environment array corresponding to the local observation\nare updated with the values from the observation matrix. At every iteration, the environment matrix\nis reset to zero to ensure that the MACN only has access to the partially observable environment.\nFor the continuous world we define our observation to be a 10 × 10 matrix with the agent at the\nbottom of this patch. We change our formulation in the previous cases where our agent was at the\ncenter since the LIDAR only has a 270 degree field of view and the environment behind the robot is\nnot observed. Our input image I to the VI module is [m × n × 2] image where m = 200,n = 200\nare the height and width of the environment. I[:, :, 0] is the sensor input. I is first convolved to obtain\na reward image R of dimension [n × m × u] where u is the number of hidden units (200 in this\ncase). The K (parameter corresponding to number of iterations of value iteration) here is 40. The\nnetwork controller is a LSTM with 512 hidden units and the external memory has 1024 rows and a\nword size of 512. We use 16 write heads and 4 read heads in the access module. The output from\nthe access module is concatenated with the output from the LSTM controller and sent through a\nlinear layer followed by a soft max to get probability distributions for (x, y, θ). We sample from\nthese distributions to get the next waypoint. These way points are then sent to the controller. The\nwaypoints are clipped to ensure that the robot takes incremental steps.\nFor this task, we find that the performance increases when trained by curriculum training. MACN in\naddition to the baselines is first trained on maps where the goal is close and later trained on maps\nwhere the goal is further away. An additional point here, is that due to the complexity of the task, we\ntrain and test on the same map. Maps in the train set and test set differ by having random start and\ngoal regions.\n\n19\n\n\f",
         "train",
         "62606",
         "10849"
        ],
        [
         "27",
         "17695",
         "cs.AI",
         "Artificial Intelligence",
         "1803.09211v1.pdf",
         "Bernoulli Embeddings for Graphs\nVinith Misraα and Sumit Bhatiaβ ∗\nNetflix Inc., Los Gatos, CA, USA\nβ\nIBM India Research Laboratory, New Delhi, India\nvmisra@netflix.com, sumitbhatia@in.ibm.com\n\narXiv:1803.09211v1 [cs.LG] 25 Mar 2018\n\nα\n\nMarch 25, 2018\n\nAbstract\nJust as semantic hashing [Salakhutdinov and Hinton2009] can accelerate information retrieval, binary\nvalued embeddings can significantly reduce latency in the retrieval of graphical data. We introduce\na simple but effective model for learning such binary vectors for nodes in a graph. By imagining the\nembeddings as independent coin flips of varying bias, continuous optimization techniques can be applied\nto the approximate expected loss. Embeddings optimized in this fashion consistently outperform the\nquantization of both spectral graph embeddings and various learned real-valued embeddings, on both\nranking and pre-ranking tasks for a variety of datasets.\n\n1\n\nIntroduction\n\nConsider users — perhaps from the research, intelligence, or recruiting community — who seek to explore\ngraphical data — perhaps knowledge graphs or social networks. If the graph is small, it is reasonable\nfor these users to directly explore the data by examining nodes and traversing edges. For larger graphs,\nor for graphs with noisy edges, it rapidly becomes necessary to algorithmically aid users. The problems\nthat arise in this setting are essentially those of information retrieval and recommendation for graphical\ndata, and are well studied [Hasan and Zaki2011, Blanco et al.2013]: identifying the most important edges,\npredicting links that do not exist, and the like. The responsiveness of these retrieval systems is critical\n[Gray and Boehm-Davis2000], and has driven numerous system designs in both hardware [Hong et al.2011]\nand software [Low et al.2014]. An alternative is to seek algorithmic solutions to this latency challenge.\nModels that perform link prediction and node retrieval can be evaluated across two axes: the relevance\nof the retrieved nodes and the speed of retrieval. The gold standard in relevance is typically set by trained\nmodels that rely on “observable” features that quantify the connectivity between two nodes, but these models\nare often quite slow to evaluate due to the complexity of the features in question.\nAt the other extreme, binary-valued embeddings can accelerate the retrieval of graphical data, much in\nthe same manner that semantic hashing [Salakhutdinov and Hinton2009] can assist in the efficient retrieval\nof text and image data. Roughly speaking, having a binary representation for each node allows one to search\nfor similar nodes in constant time directly in the binary embedding space — much faster than the alternatives\n(Table 1).\nThe challenge is that efficient binary representations can be difficult to learn: for any reasonable metric of\naccuracy, finding optimal binary representations is NP-hard. One solution is to lean on the large body of work\naround learning continuous embeddings for graphs, and utilize modern quantization techniques to binarize\nthese continuous representations. The “catch” with this approach is that the continuous embeddings are not\noptimized with their future binarization in mind, and this hurts the relevance of retrieved nodes (Sec. 4.4).\n∗ Part\n\nof this work was conducted while both the authors were at IBM Almaden Research Center.\n\n1\n\n\fTechnique\n\nPreprocess\n\nQuery\n\nObservable features\nReal embeddings\nBinary embeddings\n(sparse similarities)\nReal embeddings\n(quantized)\nBinary embeddings\n(dense similarities)\n\nO(1) (slow)\nO(ED)\n\nO(N ) (slow)\nO(N ) (fast)\n\nO(ED)\n\nO(1)\n\nO(ED)\n\nO(1)\n\nO(N 2 )\n\nO(1)\n\nTable 1: Complexity of five different node retrieval approaches, ranked from highest to lowest accuracy (Table\n2). N nodes, E edges, and D latent dimensions.\nOur primary contribution, thus, is an end-to-end method for learning embeddings that are explicitly\noptimized with both binarization and their use in link prediction/node retrieval in mind. More concretely: in a\nmanner similar to Skip-gram [Mikolov et al.2013], the likelihood of an edge between two nodes is modeled as\na function of the Hamming distance between their bit embeddings. Rather than directly optimizing the bit\nembeddings eij for this task — an NP-hard task [Weiss et al.2009] — they are instead imagined as being\ndrawn from a matrix of independent Bernoulli random variables Eij , parametrized by their (independent)\nprobabilities of success pij . By minimizing expected loss over this (product) distribution of embeddings, and\nby applying efficient approximations to the Hamming distance (Sec. 3.4), continuous optimization techniques\ncan be applied. For convenience, we refer to bit embeddings learned in this manner as Bernoulli embeddings.\nComparisons performed on five different graphical datasets are described in Section 4. Bernoulli embeddings\nare found to achieve significantly higher test-set mean average precision than a variety of alternative\nbinary embedding options, including various quantizations of DeepWalk vectors [Perozzi et al.2014], Fiedler\nembeddings [Hendrickson2007], and several other real-valued embeddings that we ourselves introduce (Table 2).\nThis is also found to hold for the reranking scenario, where binary hashes are used as a preprocessing step\nto accelerate more computationally intensive algorithms. Further, node retrieval performed using binary\nembeddings is orders of magnitude faster than other alternatives, especially for larger datasets (Table 4).\n\n2\n\nRelated Work\n\nApproaches to node retrieval, roughly categorized in Table 1, can be evaluated in terms of both relevance\nand speed. Bernoulli embeddings occupy an unexplored but valuable niche in this spectrum: they are binary\nembeddings (O(1) retrieval) appropriate for large graphs (more than a few thousand nodes) that are learned\ndirectly from the adjacency matrix (higher relevance of retrieved nodes). In the following, we describe the\nother categories represented in Table 1.\n\n2.1\n\nObservable features\n\nMethods for link prediction and node retrieval on graphs typically rely on observable neighborhood features [Dong et al.2014]. However, computing node-node similarity using these tools can have a significant\ncomputational cost [Low et al.2014].\nSecond order neighborhood features, such as the Jaccard index [Hasan and Zaki2011] and the AdamicAdar (AA) score [Adamic and Adar2003] either implicitly or explicitly involve operations over length-2\npaths and degree-2 neighborhoods. This generally requires either one or more joins with the graph table\nor multiplications with the graph’s adjacency matrix. Even with efficient sparsity-exploiting indexing, this\noperation has complexity O(E) in the number of edges E in the graph.\nHigher order path features, such as the Katz metric, rooted PageRank [Hasan and Zaki2011], and the\nregression-based Path Ranking Algorithm [Dong et al.2014] involve even longer paths and even more such oper2\n\n\fations. State-of-the-art link prediction often harnesses dozens of such features in parallel [Cukierski et al.2011].\nOffline precomputation of the (dense) node similarity matrix can dramatically help with latency, but its\nquadratic complexity in the number of nodes leaves it an option only for smaller graphs.\n\n2.2\n\nReal-valued Embeddings\n\nWith unquantized real-valued embeddings (i.e. no use of LSH), node retrieval typically involves a brute-force\nO(N ) search for the nearest Euclidean neighbors to a query. While such embeddings have appeared most\nprominently in the context of text for reasons unrelated to retrieval, Perozzi et al [Perozzi et al.2014] apply\nthe word2vec machinery of Mikolov et al [Mikolov et al.2013] to “sentences” generated by random walks\non a graph, and Yang et al [Yang et al.2015] illustrate that a graph embedding can be a powerful tool in\nthe context of semisupervised learning. The world of knowledge graphs has been particularly welcoming to\nembeddings, starting with the work of Hinton [Hinton1986], and continuing with the models of Bordes et\nal. [Bordes et al.2011], Sutskever et al. [Sutskever et al.2009], Socher et al. [Socher et al.2013] and others.\nAdditionally, graph Laplacian eigenvectors, which find prominent use in spectral clustering, can be\ninterpreted as a latent embedding (“Fiedler embedding” [Hendrickson2007]) analogous to LSA. Knowledge\ngraphs, which are more naturally represented with tensors than with adjacency matrices, analogously suggest\nthe use of tensor factorizations and approximate factorizations [Nickel et al.2012].\n\n2.3\n\nDiscrete Embeddings\n\nHinton and Salakhudtinov [Salakhutdinov and Hinton2009] introduce semantic hashing as the solution to a\nvery similar problem in a different domain. Instead of relying on indexed TF-IDF vectors for the retrieval of\nrelevant documents, a discrete embedding is learned for every document in the corpus. At query time, a user\ncan rapidly retrieve a shortlist of relevant documents simply by scanning the query’s neighborhood in the\n(discrete) embedding space. If the embedding is sufficiently compact, the neighborhood will be nonempty and\nthe scan will be fast. If the embedding is very compact, this retrieval yields a pre-ranked list that may be\nreranked using more computationally demanding algorithms. These results have fueled the development of a\nvariety of similar techniques, all seeking to learn compact binary encodings for a given dataset.\nQuantized Real-valued Embeddings: The most popular approach, taken by Weiss et al. [Weiss et al.2009],\nGong and Lazebnik [Gong and Lazebnik2011] and others, is to assume that the data consists of short real\nvectors. To apply these algorithms to graphical data, one must first learn a real-valued embedding for the\nnodes of the graph. We compare against these baselines in Sec. 4.\nBinary Embeddings from Similarity Matrix: In this approach, also known as “supervised hashing” ’ [Liu et al.2012, Kulis and Grauman2012, Norouzi et al.2012], a matrix of pairwise similarities between\nall data points is supplied. The objective is to preserve these similarities in the discrete embedding space.\nOn the surface, this appears very similar to the graphical setting of interest to us. However, no sparsity\nassumption is placed on the similarity matrix. As such, proposed solutions (typically, variations of coordinate\ndescent) fall victim to an O(N 2 ) complexity, and application is limited to graphs with a few thousand nodes.\nNote that an embedding-learning approach specifically avoids this issue by exploiting the sparse structure of\nmost graphs.\nLiu et al. [Liu et al.2014] also assume that one is supplied a matrix of similarities for the data. Rather\nthan directly attempting to replicate these similarities in the embedded space, they perform a constrained\noptimization that forces the embedded bits to be uncorrelated and zero-mean. In the graph setting, this\nacts as an approximation to the sign bits of the Fiedler embedding, which appears amongst our empirical\nbaselines.\n\n3\n\n\f3\n3.1\n\nArchitecture\nBernoulli Embeddings\n\nWe consider a generic graph, consisting of N nodes X , {1, 2, . . . , N } and a binary-valued adjacency matrix\nG ∈ {0, 1}N ×N .\nThe goal is formulated as learning a matrix of probabilities p = {pij : 1 ≤ i ≤ N , 1 ≤ j ≤ d}, from which\nthe node embeddings E are sampled as a matrix of independent Bernoulli random variables Eij ∼ β(pij ). For\nconvenience, one may reparameterize the embeddings as Eij = 1(pij > Θij ), where ΘN ×d is a matrix of iid\nrandom thresholds distributed uniformly over the interval [0, 1].\n\n3.2\n\nModel and Objective\n\nRecall the use case for short binary codes: to retrieve a shortlist of nodes Y ∈ X m similar to a query node\nx ∈ X , one should merely have to look up entries indexed at nearby locations in the embedding space. As\nsuch, we seek a model where the Hamming distance between embeddings monotonically reflects the likelihood\nof a connection between the nodes.\nFor real-valued embeddings, a natural and simple choice — used for instance with Skip-gram [Mikolov et al.2013]\n— is to treat the conditional link probability between nodes i and j as a softmax-normalized cosine distance\nbetween embeddings:\n\u0002\n\u0003\nexp (Ei · Ej )\nP (j|i; p) = P|X |\n(1)\n= softmaxj EiT E .\nk=1 exp (Ei · Ek )\nTo translate this to the setting of binary vectors, it is natural to substitute Hamming distance dH (Ei , Ej ) for\nthe cosine distance Ei · Ej in (1). As the distance dH is limited to taking values in the set {0, 1, . . . , d}, a\ntransformation is required. Empirically, we find that more complex transformations are unnecessary for the\npurpose of learning a good embedding1 , and a simple linear scaling suffices\n\u0002\n\u0003\nP (j|i; p) = softmaxj adH (EiT , E) ,\n(2)\n\nwhere dH (x, y) = xT (1 − y) + (1 − x)T y represents the Hamming distance, and a is the (potentially negative)\nscaling parameter.\nGiven the model of (2), we seek to maximize the expected log likelihood of the observed graph edges:\nX\n\u0002\n\u0001\u0003\n−E log softmaxj aEiT E Θ .\nL(G; p) =\n(3)\n(i,j)∈G\n\nThe expression in (3) unfortunately introduces two obstacles: (1) the softmax, which requires a summation\nover all candidate nodes j, and (2) the expectation of a discrete-valued functional, which presents difficulties for\noptimization. The first is addressed by means of noise contrastive estimation [Gutmann and Hyvärinen2010],\ndetailed in Sec. 3.3. The second is addressed via several approximation techniques, detailed in Sec. 3.4.\n\n3.3\n\nNoise Contrastive Estimation (NCE)\n\nTo sidestep the softmax summation, we follow in the steps of Mnih and Kavukcuoglu [Mnih and Kavukcuoglu2013]\nand employ NCE [Gutmann and Hyvärinen2010], whose minimum coincides with that of (3). Specifically,\nsoftmax normalization is replaced with a learnable parameter b, and one instead optimizes for the model’s\n1 More specifically: while a complex choice of transformation can improve the optimization objective (4), we find no consistent\nor significant improvement to the test set precision-recall metrics reported in Sec. 4.4. Essentially, beyond a point, parametrization\nof the mapping appears to improve the probabilities produced in a forward pass through the network, but does not noticeably\nimprove the embedding-parameter-gradients it returns in the backwards pass.\n\n4\n\n\feffectiveness at distinguishing a true data point (i, j) ∈ G from randomly generated noise (i, Kij ). This\nobjective is given by\n\"\n#\nX\neadH (Ei ,Ej )+b\npK (Kij |i)\nL(G) =\n−E log ad (E ,E )+b\n+ log ad (E ,E )+b\n(4)\n,\ne H i j\n+ pK (j|i)\ne H i Kij\n+ pK (Kij |i)\n(i,j)∈G\n\nθ\n\nwhere Kij is a negative sample drawn from the conditional noise distribution pK (·|i).\nGutmann and Hyvärinen [Gutmann and Hyvärinen2010] argue that one should choose the noise distribution to resemble the data distribution as closely as possible. We experiment with distributions ranging\nfrom powers of the unigram, to distributions over a node’s 2nd-degree neighborhood (in accordance with\nthe locally closed world assumption of Dong et al. [Dong et al.2014]), to mixtures thereof, to curricula that\ntransition from easily identified noise to more complex noise models. Empirically, we find that none of these\ntechniques outperform the uniform noise distribution either significantly or consistently.\n\n3.4\n\nApproximation of objective\n\nThe objective function in (4) presents a challenge to gradient-based optimization. The expectation over Θ is\ndifficult to evaluate analytically, and because the argument to the expectation is discrete, the reparameterization trick [Kingma and Welling2013] does not help. We introduce two continuous approximations to the\ndiscrete random variable DH (Ei , Ej ) that maneuver around this difficulty.\nFirst, according to the independent-Bernoulli model for the embedding matrix Eij = 1(pij > Θij ), the\nnormalized Hamming distance between two embeddings is the mean of d independent (but not identically\ndistributed) Bernoullis F1 , . . . , Fd :\nd\n\nd\n\nl=1\n\nl=1\n\n1\n1X\n1X\nDH (Ei , Ej ) =\nEil (1 − Ejl ) + (1 − Eil )Ejl =\nFl .\nd\nd\nd\nBy Kolmogorov’s strong law [Sen and Singer1994], this quantity converges with d almost surely to its\nexpectation. Therefore, for sufficiently large d, the Θ-expectation in (4) is approximated by\nLmean (G) =\n\nX\n\n(i,j)∈G\n\n− log\n\npK (Kij |i)\neadH (pi ,pj )+b\n− log ad (p ,p )+b\n,\nad\n(p\n,p\n)+b\ni\nj\ni\nH\nH\nK\ne\n+ pK (Kij |i)\ne\n+ pK (j|i)\n\n(5)\n\nwhich is amenable to gradient-based optimization.\nWhile the approximation of (5) is accurate for larger dimensionality d, recall that our goal is to learn\nshort binary codes. A sharper approximation is possible for smaller d by means of the central limit theorem\nas follows.\n1\n2\nDH (Ei , Ej ) ≈ N µij = DH (pi , pj ),σij\nd\n(6)\n!\nd\nX\n=\nDH (pik , pjk )(1 − DH (pik , pjk )) .\nk=1\n\nApplying the reparametrization trick [Kingma and Welling2013], our objective takes the form\nLCLT (G) =\n\nX\n\n(i,j)∈G\n\n\u0014\n−E log\n\nea(µij +σij Z)+b\nea(µij +σij Z)+b + pK (j|i)\npK (Kij |i)\n+ log a(µ +σ Z)+b\ne ij ij\n+ pK (Kij |i)\n\n5\n\n\u0015\n\n(7)\n,\nZ\n\n\fwhere Z is a zero mean and unit variance Gaussian. Observe that the argument to the expectation is now\ndifferentiable with respect to the parameters (p, a, b), as is the case with (5).\nA common approach [Kingma and Welling2013] to optimizing an expected-reparameterized loss such\nas LCLT is to use Monte Carlo integration to approximate the gradient over N \u0001samples of noise Z. This\nyields an unbiased estimate for the gradient with variance that converges O N1 . However, Monte Carlo\nintegration is generally appropriate for approximating higher dimensional integrals. For a single dimensional\nintegral, numerical quadrature\n\u0001 — while deterministic and therefore biased — can have the significantly faster\nerror convergence of O N14 (midpoint rule). For small N , accuracy can be further improved by performing\nquadrature with respect to the Gaussian CDF Φz . Letting f denote the intra-expectation computation in (7),\nE [f (µij + σij Z)]Z =\n\nZ\n\n1\n\nf (µij + σij z)dΦz\n\n0\n\n\u0012\n\u0012\n\u0013\u0013\nN\n2n − 1\n1 X\n−1\n≈\nf µij + σij Φz\n.\n2N n=1\n2N\n\n(8)\n\nFigure 1 compares the mean approximation with the quadrature normal approximation over the range of\nembedding dimensionalities we consider. For smaller embedding dimensionalities, the greater accuracy of the\nquadrature approximation leads to a lower test set log loss.\n\nFigure 1: Comparison of Bernoulli models optimized for Lmean and for LCLR (N = 5 samples) on the KG\ndataset. Left: Error (absolute) between approximate loss and true loss. Right: True loss.\n\n3.5\n\nOptimization and Discretization\n\nThe training set loss, as given by LCLT and approximated by (8), is minimized with stochastic gradient\ndescent with the diagonalized AdaGrad update rule [Duchi et al.2011]. To generate a discrete embedding\nE = 1(p < Θ) from a Bernoulli matrix p, each entry is rounded to 0 or 1 (i.e. Θ = 1/2), in accordance with\nmaximum likelihood.\n\n6\n\n\f4\n\nExperiments\n\n4.1\n\nDatasets\n\nResults are evaluated on five datasets. Five percent of the edges of each dataset are held out for the test set,\nand the remainder are used in training.\nKG (115K entities, 1.3M directed edges)2 is a knowledge graph extracted from the Wikipedia corpus\nusing statistical relation extraction software [Castelli et al.2012]. Edges are filtered to those with more than\none supporting location in the text, and both entity and relation types are ignored. Despite this filtration, KG\npossesses a large number of spurious edges and entities. Such a noisy dataset is representative of automatically\nconstructed knowledge graphs commonly encountered in enterprise settings [Bhatia et al.2016].\nWordnet (82K entities, 232K directed edges) is a comparatively low-noise, manually constructed graph\nconsisting of the noun-to-noun relations in the Wordnet dataset [Miller1995]. As with KG, we ignore the edge\ntype attribute.\nSlashdot (82K entities, 948K directed edges), Flickr (81K entities, 5.9M undirected edges), and BlogCatalog (10K entities, 334K undirected edges) are standard social graph datasets consisting of links between\nusers of the respective websites [Leskovec et al.2009, Tang and Liu2009].\n\n4.2\n\nBaselines and Comparisons\n\nWhile there is little work specifically in obtaining bit-valued embeddings for graphs, we compare Bernoulli\nembeddings against quantizations of three classes of real-valued embeddings.\nB1: Fiedler embeddings [Hendrickson2007] are computed using the unnormalized graph Laplacian,\nsymmetric graph Laplacian, and random-walk graph Laplacian.\nB2: DeepWalk embeddings are computed using the Skip-gram-inspired model of Perozzi et al [Perozzi et al.2014].\nB3: Real-valued distance embeddings (DistEmb) are obtained by modifying the Bernoulli embedding objective to predict link probabilities from the Hamming, `1 , `2 , or cosine distance between real-valued\nembedded vectors. Note that the Hamming distance case is equivalent to using the Bernoulli probabilities p\nas embeddings, and the cosine distance variety can be interpreted as DeepWalk modified with NCE and a\nwindow size of 2.\nThree different quantizations of the above embeddings are computed. Random-hyperplane LSH [Charikar2002]\nis selected due to its explicit goal of representing cosine similarity — used by both the DeepWalk and the\ncosine-distance variety of DistEmb. Spectral Hashing (SH) is chosen for its similarity in objective to Fiedler\nembeddings. Iterative Quantization (IQ), another data-driven embedding, has been found to outperform SH\non several datasets [Gong and Lazebnik2011], and as such we consider it as well.\nB4: Observable predictor. Additionally, for use in re-ranking,\nwe perform logistic regression with\nP\nseveral observable neighborhood features of the form s(x, y) = z∈Γ(x)∩Γ(y) f (Γ(z)), where Γ(x) indicates\nthe degree-1 neighborhood of x. Specifically, we compute the number of common neighbors (f (x) = x), the\nAdamic-Adar (AA) score (f (x) = 1/log(x)), variations of AA (f (x) = x−0.5 , x−0.3 ), and transformations\nT (s) = [s, log(s + 1), s0.5 , s0.3 , s2 ] of each score. Despite being far from state-of-the-art, we find that this\npredictor can significantly improve performance when reranking results produced with binary embeddings.\nBoth 10- and 25-dimensional embeddings are trained: for the scale of graphs we consider, the (sparsely\npopulated) latter is useful for instant-retrieval via semantic-hashing, while the (densely populated) former is\nuseful for reranking. Furthermore, we find that the quantizations of the real embeddings B1-B3 perform best\nwhen highly-informative 100 and 200 dimensional Fiedler/DeepWalk/DistEmb embeddings are quantized\ndown to the 10 and 25 bit vectors that are sought.\n\n4.3\n\nEvaluation metrics\n\nEach of the methods considered is likely to excel in the metric it is optimized for: Bernoulli embeddings\nfor expected log loss, DeepWalk for Skip-gram context prediction, etc. Our interest, however, lies in node\n2 http://sumitbhatia.net/source/datasets.html\n\n7\n\n\fretrieval, and more specifically in the ranked list of nodes returned by each algorithm. Mean Average Precision\n(MAP) is a commonly used and relatively neutral criterion appropriate for this task.\nA subtlety, however, lies in the choice of set on which to evaluate MAP. Document retrieval algorithms\ncommonly evaluate precision and recall on documents in the training set [Salakhutdinov and Hinton2009].\nThis does not lead to overfitting, as the algorithms typically only make use of the training set documents\nand not their labeled categories/similarities. Embedding-based link-prediction algorithms, however, explicitly\nlearn from the labeled similarity information, as represented by the edge list / adjacency matrix. Alternatively\nstated: rather than extrapolating similarities from input text, the goal is to generalize and predict additional\nsimilarities from those that have already been observed.\nAs such, we measure generalization via “test set precision”: for a query node, a retrieved node is only\njudged as relevant if an edge between it and the query appears in the test set. Observe that this is much\nsmaller than typically reported MAP, as all edges appearing in the training set are judged non-relevant. More\nspecifically, for small test sets, its value can rarely be expected to exceed the inverse of the average degree.\nFurthermore, in reporting observed results, scores corresponding to “DistEmb”, “DeepWalk”, and “Fiedler”\nembeddings are the best observed test set score amongst all variations of quantizer type (SH, LSH, and ITQ),\ngraph laplacian type (unnormalized, symmetric, random walk), and distance embedding (Hamming and `2 3 ).\nThese optimizations almost certainly represent test set overfitting, and present a challenging baseline for the\nBernoulli embeddings.\n\n0.05\n\n0.18\n\nBernoulli\n\n0.14\n\nDeepwalk (LSH)\n\nPrecision\n\nPrecision\n\nFiedler (IQ)\n0.03\n\nObservable\nBernoulli\n\n0.16\n\nDistEmb (`2,SH)\n\n0.04\n\n0.02\n\nDistEmb (`2,SH)\n\n0.12\n\nFiedler (IQ)\n\n0.10\n\nDeepwalk (IQ)\n\n0.08\n0.06\n0.04\n\n0.01\n\n0.02\n0.00\n0.0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n0.00\n0.0\n\n1.0\n\nRecall\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1.0\n\nRecall\n\nFigure 2: Left: 25-bit Ranking. Right: 10-bit Reranking. Mean precision/recall of binary embeddings on\nthe Flickr test set, averaged over 1000 random queries. Real embeddings are quantized to 25 bits from 100\ndimensions, and only their highest test set MAP parameterizations are shown.\n\n4.4\n\nEmpirical results\n\nIn the case of directly retrieving results from binary embeddings, Bernoulli embeddings are found to significantly\noutperform the various alternative binary embeddings (Fig. 2 and Table 2). It is also interesting to compare\nto the unquantized real embeddings (last four rows of Table 2). Despite their informational disadvantage,\nBernoulli embeddings are competitive.\nOn most datasets, the observable-feature predictor achieves significantly higher MAP than any of the\nlatent embedding models — real or binary. This is in line with our expectations, and one can in fact\nexpect even better such results from a state-of-the-art link predictor. To harness this predictive power\nwithout the computational expense of computing observable features, a compelling option is to re-rank the\n3 `1\n\nand cos similarity are consistently outperformed.\n\n8\n\n\fDataset\nd (Dimensionality)\n\nQ-DistEmb\nQ-DeepWalk\nQ-Fiedler\nBernoulli\nQ-DistEmb\nReranked, Binary Q-DeepWalk\nQ-Fiedler\nEi ∈ {0, 1}d\nBernoulli\nObservables\nDistEmb\nRanked, Real\nFiedler\nd\nEi ∈ R\nDeepWalk\nRanked, Binary\nEi ∈ {0, 1}d\n\nKG\n10\n25\n.0016\n.0047\n.0004\n.0004\n.0011\n.0026\n.0042 .0112\n.0122\n.0179\n.0049\n.0060\n.0091\n.0129\n.0249 .0267\n.0865\n.0216\n.0254\n.0085\n.0086\n.0022\n.0021\n\nWordnet\n10\n25\n.0021\n.0212\n.0011\n.0012\n.0001\n.0004\n.0054 .1013\n.0074\n.0178\n.0031\n.0030\n.0019\n.0024\n.0101 .0514\n.0126\n.0195\n.1227\n.0020\n.0016\n.0761\n.0777\n\nSlashdot\n10\n25\n.0014\n.0213\n.0002\n.0004\n.0009\n.0216\n.0016 .0298\n.0471 .0493\n.0081\n.0189\n.0420\n.0402\n.0516 .0487\n.0898\n.0313\n.0350\n.0269\n.0270\n.0326\n.0326\n\nFlickr\n10\n25\n.0051\n.0054\n.0014\n.0017\n.0021\n.0039\n.0087 .0161\n.0092\n.0084\n.0056\n.0112\n.0044\n.0074\n.0240 .0487\n.0349\n.0196\n.0256\n.0065\n.0077\n.0037\n.0037\n\nBlogCatalog\n10\n25\n.0073\n.0094\n.0048\n.0053\n.0065\n.0080\n.0131 .0181\n.0098\n.0198\n.0196 .0210\n.0139\n.0172\n.0181\n.0241\n.0524\n.0255\n.0282\n.0118\n.0116\n.0074\n.0074\n\nTable 2: Test set MAP at both 10 and 25 dimensions. For DistEmb, DeepWalk, Fiedler, and quantizations\nQ-* we present the maximum MAP across Laplacian varieties, choice of DistEmb distance function, and\nchoice of quantizer. Bold indicates category leaders.\nhighest-confidence nodes retrieved by binary embeddings [Salakhutdinov and Hinton2009]. Observe the two\ncomputational bottlenecks at play here: searching in the embedded space to populate the pre-ranked list of\nentities, and computing observable features for each of the pre-ranked entities.\nWe re-rank under constraints on both of these operations: no more than 10000 locations in the embedded\nspace may be searched, and no more than 1000 nodes can be subject to re-ranking. As illustrated in Fig. 2\nand documented in the second four rows of Table 2, Bernoulli embeddings are again found to outperform the\nalternatives.\nFinally, note that while both the Bernoulli objective function and the test-set MAP evaluation center around\nthe prediction of unknown links, generalization with those metrics also translates into a more qualitatively\nmeaningful ranking of known links. Table 3 illustrates this for the KG dataset. Notice that the observed\nquality of the retrieved entities roughly reflects the MAP scores of the respective predictors/embeddings.\nQuery\n\"New Delhi\"\n\"Roger Federer\"\n\"Bruce Wayne\"\n\nRank\n1st\n2nd\n3rd\n1st\n2nd\n3rd\n1st\n2nd\n3rd\n\nDistEmb (`2 ,SH)\n\"Ministry of Education\"\n\"Indonesian\"\n\"Poet\"\n\"Gael Monfils\"\n\"Third Round\"\n\"Second Round\"\n\"Dick Grayson\"\n\"Damian Wayne\"\n\"Gotham\"\n\nBernoulli\n\"Delhi\"\n\"Mumbai\"\n\"British India\"\n\"Grand Slam Final\"\n\"Maria Sharapova\"\n\"Rafael Nadal\"\n\"Joker\"\n\"Batman\"\n\"Arkham Asylum\"\n\nBernoulli Reranked\n\"Delhi\"\n\"India\"\n\"Indian\"\n\"Rafael Nadal\"\n\"French Open\"\n\"Novak Djokovic\"\n\"Batman\"\n\"Robin\"\n\"Joker\"\n\nObservable\n\"Delhi\"\n\"India\"\n\"Alumni\"\n\"Rafael Nadal\"\n\"French Open\"\n\"Wimbledon\"\n\"Batman\"\n\"Robin\"\n\"Joker\"\n\nTable 3: Top-3 retrieved nodes (excluding the query node) in the KG dataset for several queries.\n\n4.5\n\nEfficiency Results\n\nTraining a 25-dimensional embedding on the KG dataset — the largest problem we consider — takes roughly\n10s per epoch on a 2.2GHz Intel i7 with 16GB of RAM, and validation loss is typically minimized between 30\nand 60 epochs.\nTable 4 reports the average time taken by different methods to retrieve the node most similar to a query\nnode. By considering a d-dimensional binary embedding as an address/hash in the d-dimensional space,\nretrieval reduces to a near-instant look up of the hashtable: 0.003 ms for 25-dimension embeddings (Table 4).\nNote that this retrieval speed is independent of the embedding dimensionality d and the dataset size. At the\n9\n\n\fMethod\n\nTime (ms)\n\nbinary embeddings, hash based retrieval\nranking using observables (KG)\nre-ranking using observables (KG)\nbinaryBruteForce (100d, 100K nodes)\nbinaryBruteForce (100d, 1M nodes)\nbinaryBruteForce (100d, 10M nodes)\nbinaryBruteForce (100d, 100M nodes)\nrealBruteForce (100d, 100K nodes)\nrealBruteForce (100d, 1M nodes)\nrealBruteForce (100d, 10M nodes)\nrealBruteForce (100d, 100M nodes)\n\n0.003\n2949\n7.6\n0.7\n4.5\n91.7\n1147.9\n23.5\n181.6\n2967.1\nOOM\n\nTable 4: Time taken in milliseconds by different methods for retrieving similar nodes given a query node.\nTimes reported are averaged over 50 runs, ran on a system running Ubuntu 14.10, with 32GB RAM and 16\nCore 2.3 GHz Intel Xeon processor. OOM indicates Out of Memory.\nother extreme, the high-performance observables model for the KG dataset (115K entities) takes 2949 ms\nand scales linearly with the number of nodes in the dataset. Finally, the “Goldilocks” solution takes 7 ms: a\n10-dimensional embedding is used to obtain a shortlist, which is then reranked using the observables model.\nHash based lookup is not the only way to exploit binary embeddings. If one replaces a brute force nearest\nneighbor search amongst real valued embeddings with a brute force search amongst binary embeddings,\norder-of-magnitude memory and speed advantages remain despite the O(N ) runtime: binary embeddings\ntake up 32 to 64 times less space than real embeddings, and Hamming distance can be computed much faster\nthan Euclidean distance. Table 4 illustrates this on synthetically generated embeddings for web-scale graphs\nof up to 100 million nodes.\n\n5\n\nConclusion\n\nWe introduce the problem of learning discrete-valued embeddings for graphs, as a graphical analog to\nsemantic hashing. To sidestep the difficulties in optimizing a discrete graph embedding, the problem is\nreformulated as learning the continuous parameters of a distribution from which a discrete embedding is\nsampled. Bernoulli embeddings correspond to the simplest such distribution, and we find that they are\ncomputable with appropriate approximations and sampling techniques. On a variety of datasets, in addition to\nbeing memory and time efficient, Bernoulli embeddings demonstrate significantly better test-set precision and\nrecall than the alternative of hashed real embeddings. This performance gap continues to hold when retrieval\nwith binary embeddings is followed by reranking with a more powerful (and cumbersome) link predictor. In\nthis latter case, precision and recall can rival or exceed that of the link predictor, while performing retrieval\nin time more or less independent of the data set size.\n\nReferences\n[Adamic and Adar2003] Lada A. Adamic and Eytan Adar. Friends and neighbors on the web. Social networks,\n25(3):211–230, 2003.\n[Bhatia et al.2016] Sumit Bhatia, Alok Goel, Elizabeth Bowen, and Anshu Jain. Separating wheat from the\nchaff - A relationship ranking algorithm. In The Semantic Web - ESWC 2016 Satellite Events,, pages\n79–83, 2016.\n\n10\n\n\f[Blanco et al.2013] Roi Blanco, Berkant Barla Cambazoglu, Peter Mika, and Nicolas Torzec. Entity recommendations in web search. In The Semantic Web–ISWC 2013, pages 33–48. Springer, 2013.\n[Bordes et al.2011] Antoine Bordes, Jason Weston, Ronan Collobert, and Yoshua Bengio. Learning structured\nembeddings of knowledge bases. In Conference on Artificial Intelligence, 2011.\n[Castelli et al.2012] Vittorio Castelli, Hema Raghavan, Radu Florian, Ding-Jung Han, Xiaoqiang Luo, and\nSalim Roukos. Distilling and exploring nuggets from a corpus. In Proceedings of the 35th international\nACM SIGIR conference on Research and development in information retrieval, pages 1006–1006. ACM,\n2012.\n[Charikar2002] Moses S. Charikar. Similarity estimation techniques from rounding algorithms. In Proceedings\nof the thiry-fourth annual ACM symposium on Theory of computing, pages 380–388. ACM, 2002.\n[Cukierski et al.2011] William Cukierski, Benjamin Hamner, and Bo Yang. Graph-based features for supervised link prediction. In Neural Networks (IJCNN), The 2011 International Joint Conference on, pages\n1237–1244. IEEE, 2011.\n[Dong et al.2014] Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy,\nThomas Strohmann, Shaohua Sun, and Wei Zhang. Knowledge vault: A web-scale approach to probabilistic\nknowledge fusion. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge\ndiscovery and data mining, pages 601–610. ACM, 2014.\n[Duchi et al.2011] John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online\nlearning and stochastic optimization. The Journal of Machine Learning Research, 12:2121–2159, 2011.\n[Gong and Lazebnik2011] Yunchao Gong and Svetlana Lazebnik. Iterative quantization: A procrustean\napproach to learning binary codes. In Computer Vision and Pattern Recognition (CVPR), 2011 IEEE\nConference on, pages 817–824. IEEE, 2011.\n[Gray and Boehm-Davis2000] Wayne D. Gray and Deborah A. Boehm-Davis. Milliseconds matter: An\nintroduction to microstrategies and to their use in describing and predicting interactive behavior. Journal\nof Experimental Psychology: Applied, 6(4):322, 2000.\n[Gutmann and Hyvärinen2010] Michael Gutmann and Aapo Hyvärinen. Noise-contrastive estimation: A\nnew estimation principle for unnormalized statistical models. In International Conference on Artificial\nIntelligence and Statistics, pages 297–304, 2010.\n[Hasan and Zaki2011] Mohammad Al Hasan and Mohammed J. Zaki. A Survey of Link Prediction in Social\nNetworks. In Social Network Data Analytics, pages 243–275. Springer US, 2011.\n[Hendrickson2007] Bruce Hendrickson. Latent semantic analysis and Fiedler retrieval. Linear Algebra and its\nApplications, 421(2):345–355, 2007.\n[Hinton1986] Geoffrey E. Hinton. Learning distributed representations of concepts. In Proceedings of the\neighth annual conference of the cognitive science society, volume 1, page 12. Amherst, MA, 1986.\n[Hong et al.2011] Sungpack Hong, Tayo Oguntebi, and Kunle Olukotun. Efficient parallel graph exploration\non multi-core CPU and GPU. In Parallel Architectures and Compilation Techniques (PACT), 2011\nInternational Conference on, pages 78–88. IEEE, 2011.\n[Kingma and Welling2013] Diederik P. Kingma and Max Welling.\narXiv:1312.6114 [cs, stat], December 2013. arXiv: 1312.6114.\n\nAuto-Encoding Variational Bayes.\n\n[Kulis and Grauman2012] Brian Kulis and Kristen Grauman. Kernelized locality-sensitive hashing. Pattern\nAnalysis and Machine Intelligence, IEEE Transactions on, 34(6):1092–1104, 2012.\n\n11\n\n\f[Leskovec et al.2009] Jure Leskovec, Kevin J. Lang, Anirban Dasgupta, and Michael W. Mahoney. Community\nstructure in large networks: Natural cluster sizes and the absence of large well-defined clusters. Internet\nMathematics, 6(1):29–123, 2009.\n[Liu et al.2012] Wei Liu, Jun Wang, Rongrong Ji, Yu-Gang Jiang, and Shih-Fu Chang. Supervised hashing\nwith kernels. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages\n2074–2081. IEEE, 2012.\n[Liu et al.2014] Wei Liu, Cun Mu, Sanjiv Kumar, and Shih-Fu Chang. Discrete graph hashing. In Advances\nin Neural Information Processing Systems, pages 3419–3427, 2014.\n[Low et al.2014] Yucheng Low, Joseph E. Gonzalez, Aapo Kyrola, Danny Bickson, Carlos E. Guestrin,\nand Joseph Hellerstein. Graphlab: A new framework for parallel machine learning. arXiv preprint\narXiv:1408.2041, 2014.\n[Mikolov et al.2013] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Corrado, and Jeff Dean. Distributed\nrepresentations of words and phrases and their compositionality. In Advances in Neural Information\nProcessing Systems, pages 3111–3119, 2013.\n[Miller1995] George A. Miller. WordNet: a lexical database for English. Communications of the ACM,\n38(11):39–41, 1995.\n[Mnih and Kavukcuoglu2013] Andriy Mnih and Koray Kavukcuoglu. Learning word embeddings efficiently\nwith noise-contrastive estimation. In Advances in Neural Information Processing Systems 26, pages\n2265–2273. 2013.\n[Nickel et al.2012] Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. Factorizing YAGO: scalable\nmachine learning for linked data. In Proceedings of the 21st international conference on World Wide Web,\npages 271–280. ACM, 2012.\n[Norouzi et al.2012] Mohammad Norouzi, Ali Punjani, and David J. Fleet. Fast search in hamming space\nwith multi-index hashing. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference\non, pages 3108–3115. IEEE, 2012.\n[Perozzi et al.2014] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. DeepWalk: Online Learning of Social\nRepresentations. arXiv:1403.6652 [cs], pages 701–710, 2014. arXiv: 1403.6652.\n[Salakhutdinov and Hinton2009] Ruslan Salakhutdinov and Geoffrey Hinton. Semantic hashing. International\nJournal of Approximate Reasoning, 50(7):969–978, July 2009.\n[Sen and Singer1994] P.K. Sen and J.M. Singer. Large Sample Methods in Statistics: An Introduction with\nApplications. Chapman & Hall/CRC Texts in Statistical Science. Taylor & Francis, 1994.\n[Socher et al.2013] Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. Reasoning With\nNeural Tensor Networks for Knowledge Base Completion. In Advances in Neural Information Processing\nSystems 26, pages 926–934. 2013.\n[Sutskever et al.2009] Ilya Sutskever, Joshua B. Tenenbaum, and Ruslan R Salakhutdinov. Modelling Relational Data using Bayesian Clustered Tensor Factorization. In Advances in Neural Information Processing\nSystems 22, pages 1821–1828. Curran Associates, Inc., 2009.\n[Tang and Liu2009] Lei Tang and Huan Liu. Relational learning via latent social dimensions. In Proceedings\nof the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pages\n817–826. ACM, 2009.\n[Weiss et al.2009] Yair Weiss, Antonio Torralba, and Rob Fergus. Spectral hashing. In Advances in neural\ninformation processing systems, pages 1753–1760, 2009.\n12\n\n\f[Yang et al.2015] Huei-Fang Yang, Kevin Lin, and Chu-Song Chen. Supervised Learning of SemanticsPreserving Hashing via Deep Neural Networks for Large-Scale Image Search. arXiv:1507.00101 [cs], July\n2015. arXiv: 1507.00101.\n\n13\n\n\f",
         "train",
         "39838",
         "6071"
        ],
        [
         "28",
         "17684",
         "cs.AI",
         "Artificial Intelligence",
         "1711.10789v1.pdf",
         "arXiv:1711.10789v1 [cs.LG] 29 Nov 2017\n\nEfficient exploration with\nDouble Uncertain Value Networks\nThomas M. Moerland, Joost Broekens and Catholijn M. Jonker\nDepartment of Computer Science\nDelft University of Technology, The Netherlands\n{T.M.Moerland,D.J.Broekens,C.M.Jonker}@tudelft.nl\n\nAbstract\nThis paper studies directed exploration for reinforcement learning agents by tracking uncertainty about the value of each available action. We identify two sources of\nuncertainty that are relevant for exploration. The first originates from limited data\n(parametric uncertainty), while the second originates from the distribution of the\nreturns (return uncertainty). We identify methods to learn these distributions with\ndeep neural networks, where we estimate parametric uncertainty with Bayesian\ndrop-out, while return uncertainty is propagated through the Bellman equation as a\nGaussian distribution. Then, we identify that both can be jointly estimated in one\nnetwork, which we call the Double Uncertain Value Network. The policy is directly\nderived from the learned distributions based on Thompson sampling. Experimental\nresults show that both types of uncertainty may vastly improve learning in domains\nwith a strong exploration challenge.\n\n1\n\nIntroduction\n\nReinforcement learning (RL) is the dominant class of algorithms to learn sequential decision-making\nfrom data. In RL we start with zero prior knowledge and need to actively collect our own data.\nTherefore, we should not settle on a policy too early, instead of trying out actions we have not\nproperly explored yet. However, we neither want to continue exploring sub-optimal actions, when we\nalready know what is best. This challenge is known as the exploration/exploitation trade-off.\nMost state-of-the-art reinforcement learning implementations use undirected forms of exploration,\nsuch as \u000f-greedy or Boltzmann exploration. These methods act on point estimates of the mean actionvalue, usually applying some random perturbation to avoid only selecting the currently optimal action.\nHowever, these undirected methods are known to be highly inefficient (Osband et al., 2014). By only\ntracking point estimates of the mean state-action value, these algorithms lack the information to, for\nexample, discriminate between an action that has never been tried before (and requires exploration)\nand an action that has been tried extensively and deemed sub-optimal (and can be avoided).\nA natural solution to this problem originates from tracking uncertainties/distributions. The intuition\nis that with limited data and large uncertainty there is reason to explore, while narrow distributions\nnaturally transfer to exploitation (see Appendix C for a detailed illustration). For this work we identify\ntwo types of uncertainties/distributions that are interesting for exploration:\n• Parametric uncertainty: This is the classical statistical uncertainty which is a function of the\nnumber of available data points. The cardinal example is the posterior distribution of the\nmean (action-value).\n• Return uncertainty: This is the distribution over returns from a state-action pair given the\npolicy. For this work we focus on deterministic domains, which makes the return distribution\nentirely induced by the (exploratory) stochastic policy.\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\n\n\fWe argue that - for deterministic environments - we can explore by acting probabilistically optimal\nwith respect to both distributions (see Section 3). We identify neural network methods to estimate\neach of them separately, and subsequently show that both can be combined in one network, which we\ncall the Double Uncertain Value Network (DUVN). To the best of our knowledge, we are the first to\n1) distinguish between uncertainty due to limited data (parametric) and uncertainty over the return\ndistribution, 2) propagate both through the Bellman equation, 3) track both with neural networks (i.e.,\nhigh-capacity function approximators), and 4) use both to improve exploration.1\nThe remainder of this paper is organized as follows. In Section 2 we provide a general introduction\nto Bayesian deep learning and distributional reinforcement learning. In Section 3, we discuss\nparametric and return uncertainty, and identify their potential for exploration. Section 4 discusses\ntheir implementations for policy evaluation with neural networks, and also discusses how to derive\na policy from the learned distributions based on Thompson sampling. Sections 4, 5 and 6 show\nexperimental results, discuss future work, and draw conclusions, respectively.\n\n2\n\nPre-liminaries\n\n2.1\n\nBayesian deep learning\n\nBayesian neural networks (MacKay, 2003) represent the uncertainty in the model through posterior\ndistributions over the model parameters. Assume we observe some random variables X and Y and\nare interested in the conditional distribution p(Y |X). We introduced a neural network pφ (Y |X) with\nparameters φ ∈ Φ to estimate this conditional distribution. In the Bayesian setting, we treat the model\nparameters φ as random variables themselves. Given an observed dataset H, we may use the posterior\ndistribution over model parameters p(φ|H) to obtain the posterior predictive distribution\np(y ? |x? , H) =\n\nZ\n\np(y ? |x? , φ)p(φ|H)dφ\n\n(1)\n\nfor a new observed datapoint x? . In the non-linear neural networks of practical interest, the posterior\ndistribution p(φ|H) is analytically intractable. Gal and Ghahramani (2016) showed that the wellknown empirical procedure drop-out actually produces a Monte-Carlo approximation to Eq. 1,\nproviding samples from the posterior predictive distribution by simply retaining drop-out during test\ntime (prediction). We use this technique in this paper, and discuss alternative methods for Bayesian\ninference in neural networks in the Future work section.\n2.2\n\nDistributional reinforcement learning\n\nIn reinforcement learning (RL) (Sutton and Barto, 1998) agents are studied that interact with an unknown environment with the goal to optimize some long-term performance measure. The framework\nadopts a Markov Decision Process (MDP) given by the tuple {S, A, T , R, γ}. At every time-step\nt we observe a state st ∈ S and pick an action at ∈ A = {1...NA }, for NA available discrete\nactions. The MDP follows the transition dynamics st+1 = T (·|st , at ) ∈ S and returns rewards\nrt = R(st , at ) ∈ R. For this work, we assume a discrete action space and deterministic transition\nand reward functions.\nWe act in the MDP according to a stochastic policy π, i.e. a ∼ π(·|s) ∈ P(A). The discounted return\nZ π (s, a) from a state-action pair (s, a) is a random process given by\n\nZ π (s, a) =\n\n∞\nX\n\nγ t rt ,\n\nst+1 = T (·|st , at ), at+1 ∼ π(·|st+1 ), s0 = s, a0 = a\n\n(2)\n\nt=0\n\nfor discount factor γ ∈ [0, 1]. We emphasize that the return Z π is a random variable, where the\ndistribution of Z π is induced by the stochastic policy (as we assume a deterministic environment). We\n1\n\nAs a side contribution, we introduce the Initial Return Entropy (IRE) as a measure of task exploration\ndifficulty. See Appendix B.\n\n2\n\n\fmay rewrite equation 2 into a recursive form, known as the distributional Bellman equation (omitting\nthe π superscript from now on):\nZ(s, a) = rt + γZ(s0 , a0 ),\n\ns0 = T (·|s, a), a0 ∼ π(·|s0 ).\n\n(3)\n\nNote that the equality sign represents distributional equality here (Engel et al., 2005). We are now\nready to define the action-value function. Denote by Eπ the expectation over all traces induced by\nthe policy π. Applying this operator to Z(s, a) defines the state-action value Q(s, a) = Eπ [Z(s, a)].\nApplying this operator to Eq. 2 gives\nQ(s, a) = rt + γEs0 =T (·|s,a),a0 ∼π(·|s0 ) [Q(s0 , a0 )]\n\n(4)\n\nwhich is known as the Bellman equation (Sutton and Barto, 1998). Most RL papers actually start-off\nfrom Eq. 4. We present the current introduction to emphasize that the mean action value Q(s, a) is a\nquantity that we estimate by sampling from an underlying return distribution p(Z|s, a).2\nWe approximate the action-value (distribution) with a deep neural network. We write Qφ (s, a) for a\nnetwork predicting a (point estimate) action-value, and pφ (Z|s, a) for a network approximating the\nentire return distribution. To learn the state-action value RL algorithms follow variants of a scheme\nknown as generalized policy iteration (GPI) (Sutton and Barto, 1998). GPI iterates between policy\nevaluation, in which we calculate a new estimates Ψ(s, a) of the state-action value based on (new)\nsample data (e.g., for one-step SARSA Ψ(s, a) = r(s, a) + γQ(s0 , a0 )), and policy improvement, in\nwhich we use the estimate Ψ(s, a) to improve the policy (whether with a value-based, actor-critic or\npolicy gradient algorithm).\n\n3\n\nDistributional perspective on exploration\n\nWe will now argue for a probabilistic perspective on value functions and exploration. There are two\ndistributions that might be useful from an exploration point of view: 1) the statistical parametric\nuncertainty of the mean action value, and 2) the distribution of the return.\nParametric uncertainty of the mean Given a policy the state-action value Q(s, a) is a scalar\nnumber by definition, as it is an expectation over all possible future traces. However, from a statistical\npoint of view it makes sense to treat our estimate of Q(s, a) as a random variable, as we need to\napproximate it from a finite number of samples. We call this the parametric uncertainty.\nParametric exploration, i.e. acting optimistic with respect to the uncertainty of the mean action-value,\nhas been very successful in the bandit setting. However, it has been sparsely applied to RL (see\nAppendix A for related work). We believe this is due to a fundamental complication regarding\nuncertainties in RL, which has only been identified by Dearden et al. (1998) before. Bandits are\none-step decision problems with pay-offs originating from a stationary distribution, which makes the\nvalue approximation an ordinary supervised learning problem. However, in RL the target distribution\nis highly non-stationary. A standard target like r + γQ(s0 , a0 ) falsely assumes that Q(s0 , a0 ) is known,\nwhile it is actually uncertain itself. Therefore, repeatedly visiting a state-action pair should not\nmakes us certain about its value if we are still uncertain about what to do next. In other words: the\nstate-action value certainty depends on the future policy certainty. Standard parametric uncertainty\ncannot account for this problem (the ‘local’ parametric uncertainty will converge as if it is supervised\nlearning), and we somehow need to propagate the uncertainty of future state-action pairs’ value (the\n‘global’ uncertainty) back through the Bellman equation. An illustration is seen in Fig. 1b right,\nwhere the uncertainty in φ influences both the current and future value estimates (ignoring the Z\ndistributions in that graph for now, as the need to propagate the parametric uncertainty p(φ) over\ntimesteps already applies when we learn mean action-values).\n2\n\nWe empirically observe that the shape of this return distribution strongly differs between domains. This\nmatters because the shape of the return distribution also influences how easily we can estimate its expectation, or\nsome other quantity like an upper confidence bound, from samples. For example, a long, thin right tail in the\nreturn distribution - as frequently the case in RL with only a few ‘good’ traces - may give our mean estimate high\nvariance (it would actually need importance sampling). In Appendix B we visualize return distributions for some\nwell-known domains, and also introduce the Initial Return Entropy as a measure of task exploration difficulty.\n\n3\n\n\fFigure 1: a) Three types of neural networks with different uncertanties/probabilitiy distributions. Circles are\nprobabilistic nodes. Left: parametric uncertainty over the mean action-value. Middle: propagating (return)\ndistributions for point estimate parameters. Right: parametric uncertainty over propagating distribution (=\nDouble Uncertain Value Network). b) Illustration of propagating distributions. Subscripts identify unique\nstate-action pairs. We initialize all state-action pairs with a prior parametric uncertainty p(φ) and prior output\ndistribution pφ (Z). Then, for a new observed transition, we want to update our estimates of pφ (Z) at the current\nstate action pair by propagating the distribution of the next node p(Z 0 ) through the Bellman operator T (instead\nof just propagating the mean). For this work, we consider two quantities to propagate: i) the return distribution\n0\nat the next node\nR pφ (Z0 ) (for point estimate φ), or ii) the parametric uncertain return distribution at the next\n0\nnode p(Z ) = pφ (Z )p(φ|H)dφ. Arrows point backwards because we focus on the direction of uncertainty\npropagation/back-up (which runs in the different direction than our exploration).\n\nReturn distribution Standard RL, and also the parametric uncertainty introduced above, usually\ndeal with the mean action-value Q(s, a). However, from an exploration point of view, it makes\nmore sense to learn the full return distribution p(Z|s, a). Note that we still focus on deterministic\nenvironments. Therefore, the distribution over returns is solely induced by our own policy. As we\nmay modify our own policy, it makes sense to act optimistically with respect to the return distribution\nwe observe. As an illustration, consider a state-action pair with particular mean action value estimate\nQ(s, a). It really matters whether this average originates from a highly varying return, or from\nconsistently the same return. It matters because our policy may influence the shape of this distribution,\ni.e. for the highly varying returns we may actively transform the distribution towards the good returns.\nIn other words, what we really care about in deterministic domains is the best return, or the upper end\nof the return distribution.3\nIt turns out that both challenges focus around propagating either parametric uncertainty and/or return\ndistributions through the Bellman equation (Fig 1b). The overall idea is to memorize the propagating\nglobal MDP uncertainties in a neural network, which makes them locally available at action selection\ntime. We thereby avoid the need for any forward planning (to get global information), and our\napproach is entirely model-free.\n\n4\n\nDouble Uncertain Value Networks\n\n4.1\n\nPolicy evaluation\n\nWe now discuss three probabilistic policy evaluation approaches that incorporate the uncertainties\nintroduced in the previous section: 1) (local) parametric uncertainty only, 2) return distribution only,\nand 3) both combined. The respective network structures are illustrated in Fig. 1a. Implementation\ndetails are provided in Appendix E.\nParametric uncertainty only To estimate our parametric uncertainty we may use any type of\nBayesian inference method suitable for neural networks. For this paper we consider the Bayesian\ndropout (Gal et al., 2016), as it has a very simple practical implementation (see Sec. 2.1). This\ngives\nus a sample from the posterior predictive distribution of the mean action value: p(Q|s, a, H) =\nR\nQφ (s, a)p(φ|H)dφ. The associated network structure is visualized in Figure 1a, left.\n3\n\nFor stochastic domains the return distribution has additional noise for which we do want to act on the\nexpectation.\n\n4\n\n\fReturn distribution only We next consider the problem of learning return distributions instead\nof mean action-values. For this work we will assume that the return distribution p(Z|s, a) can be\napproximated by a Gaussian. Therefore, we modify our neural network to output the distribution\nparameters µZ (s, a) and σ Z (s, a), where clearly µZ (s, a) = Q(s, a). Note that the network parameters φ are point estimates now. The associated network structure is visualized in Figure 1a, middle.\nDuring policy evaluation we need to estimate distributional targets instead of point estimate targets. We will construct bootstrap estimators based on the distributional Bellman equation (Eq. 3).\nThe derivation for the mean µZ (s, a) = Q(s, a) is well-known from standard RL, so we focus on\npropagating the return standard deviation through the distributional Bellman equation:\nh\ni\nh\ni\nh\ni\nX\nX\nSd p(Z|s, a) = Sd r(s, a) + γ\nπ(a0 |s0 )p(Z|s0 , a0 ) = γ\nπ(a0 |s0 )Sd p(Z|s0 , a0 ) (5)\na0 ∈A\n\na0 ∈A\n\nbecause γ ≥ 0, π(a|s) ≥ 0, and we assume the next state distributions are independent so we may\nignore the covariances.4 We see that the standard deviation of p(Z|s, a) is a linear combination of\nthe standard deviations p(Z|s0 , a0 ) (one timestep ahead), reweighted by the policy probabilities and\nshrunken by γ. We approximate the sum over the policy probabilities π(a0 |s0 ) by sampling from our\npolicy (as is the usual solution in RL, which will be right in expectation over multiple traces). The\nnetwork may then be trained to move the current predictions closer to these targets, for example with\na squared loss\n\u0010\n\u00112 \u0010\n\u00112\n0 0\nZ\nZ 0 0\nZ\nL(φ) = r(s, a) + γµZ\n(s\n,\na\n)\n−\nµ\n(s,\na)\n+\nγσ\n(s\n,\na\n)\n−\nσ\n(s,\na)\nφ\nφ\nφ\nφ\n\n(6)\n\nwhere we as usual fix the bootstrap predictions at (s0 , a0 ), i.e. the training gradients w.r.t. φ are\nblocked there. This approach can be seen as a form of analytic approximate return propagation with a\n(heuristic) distributional loss (see Appendix A.2 for other distributional losses). Similar ideas with\napproximate return propagation were recently explored with discrete network output distributions\n(Bellemare et al., 2017), which may also accommodate for propagating multimodality.\nA second, more simple propagation method which we also experimented with is sampling-based\npropagation. In that setting we sample M values zm (s0 , a0 ) ∼ pφ (Z|s0 , a0 ), push these through\nthe Bellman operator to construct Ψm (s, a) = r(s, a) + γzm (s0 , a0 ), and train our network on this\ncollection of samples with, e.g., a maximum likelihood loss. This may require more samples and be\nless accurate, but it will also work for complicated network output distributions (like deep generative\nmodels) for which analytic propagation and projection is infeasible. Results of this approach are not\nshown, but were comparable to the results with approximate return propagation shown in Section 5.\nParametric uncertainty over return distributions We finish with the observation that both ideas\nmay actually naturally be combined in one function approximator (Fig 1a, right). Note that we can\nnow propagate both the return distribution and its parametric uncertainty at the next timestep, i.e.\nwe are effectively propagating uncertain return distributions (the parametric uncertainty over the\nnetwork output distribution). Starting from a sampled transition now, we want to propagate the return\ndistribution weighted over the parametric uncertainty at the next timestep:\nZ(s, a) =\n\nZ h\n\nZ\ni\nr + γZφ (s0 , a0 ) p(φ|H)dφ = r + γ Zφ (s0 , a0 )p(φ|H)dφ\n\n(7)\n\nBesides that, the same distributional Bellman propagating machinery applies as above.5 We refer to\nthe general mechanism of uncertainty propagation (parametric, return or both) as Bellman uncertainty.\nThe appearance of the network, with both uncertainty over the network parameters φ and over the\noutput distribution to track the propagating (uncertain) return distributions, makes us refer to it as the\nFor random variables X, Y and scalar constants a, b, c we have: Var[a + bX + cY ] = b2 Var[X] +\nc Var[Y ] + 2bc Cov[X, Y ].\n5\n0\n0\nZ 0\n0\nSample from p(φ|H) at the next time-step, make network predictions µZ\nφ (s , a ) and σφ (s , a ), and do\nthe Bellman propagation. Repeated sampling of φ does Monte Carlo integration over p(φ|H), as a numerical\nintegration like in Dearden et al. (1998) is infeasible for the neural network setting.\n4\n\n2\n\n5\n\n\fDouble Uncertain Value Network (DUVN) (Fig 1a, right). The intuition is that during early learning\nwe will mostly be propagating uncertainty, while with converging distributions we will eventually\nstart propagating true return distributions.\nIn summary, we identified three types of probabilistic policy evaluation algorithms (with the three\nassociated network structures visualized in Fig. 1a):6\nR\n1. The (local) parametric uncertainty of the mean value: p(Q|s, a, H) = Qφ (s, a)p(φ|H)dφ.\n2. The (propagating) distribution of the return: pφ (Z|s, a, H) (with point parameters φ).\nR\n3. Both, (propagating) uncertain return distr.: p(Z|s, a, H) = pφ (Z|s, a, H)p(φ|H)dφ.\n4.2\n\nPolicy improvement\n\nWe now describe how to use any of these distributions to naturally balance exploration versus\nexploitation, based on Thompson sampling (Thompson, 1933) (see Appendix C as well). To\ngeneralize notation, we introduce a new random variable Θ with distribution p(Θ|s, a) to capture any ofQ\nthe three policy evaluation distributions introduced in the previous section. We write\np(Θ|s) = a? ∈A p(Θ|s, a? ) for the joint action-value distribution in a state s, where we assume\nthe posterior distributions per action are independent. Thompson sampling selects action a with\nprobability equal to:\nZ\nπ(a|s) =\n\np(Θa > Θa? 6=a )p(Θ|s)dΘ\n\n(8)\n\nwhere Θa = Θ(s, a) and Θa? 6=a notational convention for Θ(s, a? )∀a? ∈ A, a? 6= a. In words, we\nchoose action a with probability equal to the probability that the specific action is the optimal one\nwhen averaging over all uncertainty in the joint distribution p(Θ|s). The practical implementation of\nThompson sampling is very simple, as we may just sample from p(Θ|s, a) for every a and argmax\nover these values:\n1. Sample φ ∼ p(φ) (or equivalently a dropout mask).\n2. Sample Z(s, a? ) ∼ pφ (Z|s, a? ) ∀ a? ∈ A.\n3. Select a = arg maxa? ∈A Z(s, a? ).\nIf we do not consider parametric uncertainty, then we ignore the first sampling step and just use the\ncurrent parameter point estimates. If we do not consider the Bellman uncertainty, then we replace the\nsecond sampling step with a deterministic prediction Qφ (s, a).\nThompson sampling is not the only possible choice to make decisions under uncertainty, but it has\nshown good empirical performance in the bandit literature (Chapelle and Li, 2011). It naturally\nperforms policy improvement, as it gradually starts to prefer the better actions when the distributions start narrowing/converging. We thereby hope to improve on the instability of greedy policy\nimprovement (see also Bellemare et al. (2017)) or undirected exploration. Ideally, the uncertain return\ndistribution would gradually narrow and for a deterministic environment eventually converge to a\nDirac distribution on the optimal value function.\n\n5\n\nExperiments\n\nWe now evaluate the different types of probabilistic policy evaluation in combination with Thompson\nsampling exploration. We refer to Thompson sampling on the three types of discussed policy evaluation as parametric exploration, return exploration, and uncertain return exploration. Experimental\ndetails are provided in Appendix E.\nWe first consider the Chain domain (Appendix D, Figure 6). The domain consists of a chain of states\nof length N , with two available actions at each state. The only trace giving a positive, non-zero\n6\n\nWe could think of another algorithm that does propagate (i.e., has a probabilistic network\noutput), but only\nR\npropagates the parametric uncertainty of the mean at the next time-step p(Q0 |H) = Q0φ p(φ|H)dφ (and not\nthe entire return distribution). We did not come up with such an algorithm, but concurrently with our work,\nO’Donoghue et al. (2017) did focus on this problem. See Related Work.\n\n6\n\n\fFigure 2: Learning curves on Chain domain for Thompson sampling on parametric uncertainty, return distribution and uncertain return distribution versus \u000f-greedy exploration (\u000f = 0.05). Plots progress row-wise for\nincreased depth of the Chain, i.e. increased exploration difficulty. Note that the correct action at each state in the\nchain is initialized at random (i.e. not always action 2, as in the visualization in Fig. 6). Results averaged over 5\nrepetitions.\n\nreward is to select the ‘correct’ action at every step. The correct action per step is determined at\ndomain initialization by sampling from a uniform Bernoulli. The domain has a strong exploration\nchallenge, which grows exponentially with the length of the chain (see Appendix D).\nLearning curves for the Chain domain are shown in Fig. 2, for different lengths of the chain. First\nof all, we note that the \u000f-greedy strategy does not learn in this domain at all (not even for the short\nlength). The three probabilistic approaches do explore, with best performance for the uncertain return\nexploration. In the longest chain, of length 100, all probabilistic exploration methods also get trouble\nsolving the domain. However, they do see some rewards, which makes us hypothesize this could be\nan issue of stabilization (more than that the exploration does not work). See Appendix D.1 for results\nwhen the correct action is always the same, as in the original variants of this problem (Osband et al.,\n2016).\nWe next test our method on a set of tasks from the OpenAI Gym repository (Fig. 3). We see that\nour exploration methods manage to learn on all domains. The achieved end policies all reflect\ngood policies on each problem. \u000f-greedy exploration is a bit unstable on some domains (CartPole,\nLunarLander), but generally performs reasonable as well. We note that the uncertainty exploration\nmethods, which have a completely different exploration mechanism compared to \u000f-greedy exploration,\nnever really perform worse on these domains.\nWe hypothesize these domains have too much structure and are not challenging enough to show\nthe same exploration difference as seen for the Chain domain. Future work should address more\nchallenging (high-dimensional) exploration problems. We also want to stress that probabilistic\nexploration will not always outperform undirected methods, especially not on domains with relatively\nsimple exploration. Uncertainty methods will generally create a cautious agent, that first wants to\nproperly verify all parts of the domain. In contrast, undirected exploration agents may exploit sooner,\nwhich can be beneficial in domains with non-deep exploration (i.e., with quick rewards).\n\n6\n\nFuture work\n\nWe identify several directions for future work:\n1. Other types of Bayesian inference in neural networks (for parametric uncertainty): we\nhypothesize that the Bayesian drop-out may be too unstable and tedious to tune, as we\nsometimes observed in our experiments as well. Potentially, different methods to approximate the posterior over the network parameters (e.g., Welling and Teh (2011)) may improve\nestimation of parametric uncertainty.\n2. More expressive output distributions (for Bellman uncertainty propagation): for this work\nwe only experimented with Gaussian distributions for propagation. Recently, Bellemare et al.\n(2017) studied return distribution propagation with categorical distributions, which more\nnaturally accommodate for multi-modality (see Related Work as well). Another extension\ncould involve more expressive continuous network distributions, e.g. based on conditional\nvariational inference (Moerland et al., 2017).\n7\n\n\fFigure 3: Learning curves for parametric exploration, return exploration and uncertain return exploration on\ndifferent OpenAI Gym environments. Results averaged over 5 repetitions.\n\n3. Continuous action-spaces: the current implementations only focussed on discrete action\nspaces, where Thompson sampling can easily be applied by maintaining a distribution per\naction and enumerating all actions for action selection. Extension to the continuous setting\nwould require either directly propagating policy uncertainty, or learning a parametric policy\nwhose distribution mimics the uncertainty in the value function.\n4. Stochastic environments: this paper entirely focussed on domains with deterministic\nreward and transition functions, which makes the return distribution only induced by the\nstochastic policy. In stochastic domains the return distribution will have additional noise for\nwhich we do want to act on the expectation, to prevent continuing to act optimistically with\nrespect to something we can’t influence.\nFinally, we want to stress that the RL algorithms in this paper are entirely model-free. The uncertainty\ntheme also appears in model-based RL, where it is useful/necessary to track the uncertainty on an\nestimated transition and/or reward function (Deisenroth and Rasmussen, 2011; Depeweg et al., 2017).\nThis parametric model uncertainty is different from the parametric value/policy uncertainty studied\nin this work, but our ideas may be extended to the model-based setting as well (which would add\nanother source of uncertainty).\n\n7\n\nConclusion\n\nThis paper introduced Double Uncertain Value Networks (DUVN), which, to the best of our knowledge, is the first algorithm that 1) distinguishes between uncertainty due to limited data (parametric)\nand uncertainty over the return distribution, 2) propagates both through the Bellman equation, 3)\ntracks both with neural networks (i.e., high-capacity function approximators), and 4) uses both to\nimprove exploration. We implemented the DUVN algorithm with Bayesian dropout for the parametric uncertainty and a Gaussian distribution for the Bellman uncertainty propagation. The main\nappeal of this implementation is its simplicity: any deep Q-network implementation can be easily\nextended as in this work by adding drop-out to the neural network layers and specifying a Gaussian\noutput distribution instead of a mean-only prediction. This should take no more then a few lines\nof code in most automatic differentiation software packages. We showed that, even for the vanilla\nimplementation, we at least match or improve undirected exploration performance on a variety of\nproblems, and drastically improve performance on an exploration heavy domain (Chain). We believe\nfurther improvements in the distributional approach to RL, e.g. with more expressive network output\ndistributions that capture multi-modality, is a promising direction for RL exploration research.\n8\n\n\fReferences\nAuer, P., Cesa-Bianchi, N., and Fischer, P. (2002). Finite-time analysis of the multiarmed bandit problem.\nMachine learning, 47(2-3):235–256.\nBellemare, M., Srinivasan, S., Ostrovski, G., Schaul, T., Saxton, D., and Munos, R. (2016). Unifying countbased exploration and intrinsic motivation. In Advances in Neural Information Processing Systems, pages\n1471–1479.\nBellemare, M. G., Dabney, W., and Munos, R. (2017). A distributional perspective on reinforcement learning.\narXiv preprint arXiv:1707.06887.\nBlundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra, D. (2015). Weight uncertainty in neural networks.\narXiv preprint arXiv:1505.05424.\nBrafman, R. I. and Tennenholtz, M. (2002). R-max-a general polynomial time algorithm for near-optimal\nreinforcement learning. Journal of Machine Learning Research, 3(Oct):213–231.\nChapelle, O. and Li, L. (2011). An empirical evaluation of thompson sampling. In Advances in neural\ninformation processing systems, pages 2249–2257.\nDearden, R., Friedman, N., and Andre, D. (1999). Model based Bayesian exploration. In Proceedings of the\nFifteenth conference on Uncertainty in artificial intelligence, pages 150–159. Morgan Kaufmann Publishers\nInc.\nDearden, R., Friedman, N., and Russell, S. (1998). Bayesian Q-learning. In AAAI/IAAI, pages 761–768.\nDeisenroth, M. and Rasmussen, C. E. (2011). PILCO: A model-based and data-efficient approach to policy\nsearch. In Proceedings of the 28th International Conference on machine learning (ICML-11), pages 465–472.\nDepeweg, S., Hernández-Lobato, J. M., Doshi-Velez, F., and Udluft, S. (2017). Uncertainty Decomposition in\nBayesian Neural Networks with Latent Variables. arXiv preprint arXiv:1706.08495.\nEngel, Y., Mannor, S., and Meir, R. (2003). Bayes meets Bellman: The Gaussian process approach to temporal\ndifference learning. In Proceedings of the 20th International Conference on Machine Learning (ICML-03),\npages 154–161.\nEngel, Y., Mannor, S., and Meir, R. (2005). Reinforcement learning with Gaussian processes. In Proceedings of\nthe 22nd international conference on Machine learning, pages 201–208. ACM.\nGal, Y. (2016). Uncertainty in deep learning. PhD thesis, PhD thesis, University of Cambridge.\nGal, Y. and Ghahramani, Z. (2016). Dropout as a Bayesian approximation: Representing model uncertainty in\ndeep learning. In international conference on machine learning, pages 1050–1059.\nGal, Y., McAllister, R. T., and Rasmussen, C. E. (2016). Improving PILCO with bayesian neural network\ndynamics models. In Data-Efficient Machine Learning workshop, volume 951, page 2016.\nGhavamzadeh, M. and Engel, Y. (2007a). Bayesian actor-critic algorithms. In Proceedings of the 24th\ninternational conference on Machine learning, pages 297–304. ACM.\nGhavamzadeh, M. and Engel, Y. (2007b). Bayesian policy gradient algorithms. In Advances in neural information\nprocessing systems, pages 457–464.\nGuez, A., Silver, D., and Dayan, P. (2012). Efficient Bayes-adaptive reinforcement learning using sample-based\nsearch. In Advances in Neural Information Processing Systems, pages 1025–1033.\nHouthooft, R., Chen, X., Duan, Y., Schulman, J., De Turck, F., and Abbeel, P. (2016). Vime: Variational\ninformation maximizing exploration. In Advances in Neural Information Processing Systems, pages 1109–\n1117.\nKearns, M. and Singh, S. (2002). Near-optimal reinforcement learning in polynomial time. Machine Learning,\n49(2-3):209–232.\nKocsis, L. and Szepesvári, C. (2006). Bandit based monte-carlo planning. In ECML, volume 6, pages 282–293.\nSpringer.\nMacKay, D. J. (2003). Information theory, inference and learning algorithms. Cambridge university press.\n\n9\n\n\fMannor, S., Simester, D., Sun, P., and Tsitsiklis, J. N. (2004). Bias and variance in value function estimation. In\nProceedings of the twenty-first international conference on Machine learning, page 72. ACM.\nMannor, S., Simester, D., Sun, P., and Tsitsiklis, J. N. (2007). Bias and variance approximation in value function\nestimates. Management Science, 53(2):308–322.\nMannor, S. and Tsitsiklis, J. (2011). Mean-variance optimization in Markov decision processes. arXiv preprint\narXiv:1104.5601.\nMatthias, P., Rein, H., Prafulla, D., Szymon, S., Richard Y., C., Xi, C., Tamim, A., Pieter, A., and Marcin, A.\n(2017). Parameter Space Noise for Exploration. arXiv preprint arXiv:1706.01905.\nMoerland, T. M., Broekens, J., and Jonker, C. M. (2017). Learning Multimodal Transition Dynamics for\nModel-Based Reinforcement Learning. arXiv preprint arXiv:1705.00470.\nMorimura, T., Sugiyama, M., Kashima, H., Hachiya, H., and Tanaka, T. (2012). Parametric return density\nestimation for reinforcement learning. arXiv preprint arXiv:1203.3497.\nO’Donoghue, B., Osband, I., Munos, R., and Mnih, V. (2017). The Uncertainty Bellman Equation and\nExploration. arXiv preprint arXiv:1709.05380.\nOsband, I., Blundell, C., Pritzel, A., and Van Roy, B. (2016). Deep exploration via bootstrapped DQN. In\nAdvances in Neural Information Processing Systems, pages 4026–4034.\nOsband, I., Van Roy, B., and Wen, Z. (2014). Generalization and exploration via randomized value functions.\narXiv preprint arXiv:1402.0635.\nRasmussen, C. E., Kuss, M., et al. (2003). Gaussian Processes in Reinforcement Learning. In NIPS, volume 4,\npage 1.\nSobel, M. J. (1982). The variance of discounted Markov decision processes. Journal of Applied Probability,\n19(4):794–802.\nStadie, B. C., Levine, S., and Abbeel, P. (2015). Incentivizing exploration in reinforcement learning with deep\npredictive models. arXiv preprint arXiv:1507.00814.\nSutton, R. S. and Barto, A. G. (1998). Reinforcement learning: An introduction, volume 1. MIT press Cambridge.\nTamar, A., Di Castro, D., and Mannor, S. (2016). Learning the variance of the reward-to-go. Journal of Machine\nLearning Research, 17(13):1–36.\nThompson, W. R. (1933). On the likelihood that one unknown probability exceeds another in view of the\nevidence of two samples. Biometrika, 25(3/4):285–294.\nvan Hoof, H., Tanneberg, D., and Peters, J. (2017). Generalized exploration in policy search. Machine Learning,\n106(9-10):1705–1724.\nWelling, M. and Teh, Y. W. (2011). Bayesian learning via stochastic gradient Langevin dynamics. In Proceedings\nof the 28th International Conference on Machine Learning (ICML-11), pages 681–688.\nWhite, D. (1988). Mean, variance, and probabilistic criteria in finite Markov decision processes: a review.\nJournal of Optimization Theory and Applications, 56(1):1–29.\n\n10\n\n\fA\n\nRelated work\n\nExploration is a widely studied topic in reinforcement learning. We will discuss work based on\nparametric (value/policy) uncertainty, return distributions/uncertainty, and add some context on\nother exploration approaches (count-based/intrinsic motivation) and other uncertainty methods in RL\n(uncertainty in model-based RL).\nA.1\n\nParametric uncertainty of the mean\n\nThis research direction uses the uncertainty of the mean action value, either from a frequentist\nor Bayesian direction, to direct exploration. Exploration is usually based on ’optimism under\nuncertainty’. Parametric uncertainty has been extensively studied in the bandit setting, which are\nenvironments with a single state, multiple actions and unknown, stochastic rewards. Succesful\napproaches are UCB Auer et al. (2002), which acts on the upper confidence bound of a frequentist\nconfidence interval, and Thompson sampling Thompson (1933), which is also studied in this paper.\nThere are a few extensions of these ideas to the RL/MDP setting. The first occurrence of parametric\nuncertainty in RL seems to be Bayesian Q-learning by Dearden et al. (1998). The authors use\ntabular Q-learning with normal distributions and conjugate updating. They are also the only ones\nthat explicitly identify the necessity to propagate parametric uncertainty from future states. Their\nexploration is based on either Thompson sampling (which they call Q-value sampling), while they\nalso consider myopic value of perfect information (VPI) as another exploration strategy.\nOsband et al. (2014) extended these ideas to the linear function approximation setting with randomized\nleast-squares value iteration (RLSVI). In the neural network context, parametric uncertainty based\non variational inference was studied for bandits by Blundell et al. (2015). Gal and Ghahramani\n(2016) studied the use of dropout uncertainty for parametric value uncertainty similar to our work,\nbut did not consider any propagation, nor the distribution over returns. Osband et al. (2016) also\nstudied parametric exploration in RL with neural networks, using the non-parametric bootstrap\n(i.e., a frequentist approach to uncertainty estimation, not to be confused with the use of the term\n‘bootstrapping’ in RL).\nConcurrently with the present paper, O’Donoghue et al. (2017) also identified the need to propagate\nparametric uncertainty over timesteps. Their approach is based on a variance estimate, which has a\nsimilar role as the σ in our Gaussian uncertainty propagation. Their neural network implementation\nderives the local parametric uncertainty estimates from the linearity of their last network layer and\nfrequentist uncertainty estimates known from linear regression. This contrasts to our Bayesian\napproach to parametric uncertainty. Moreover, they still propagate uncertainty about the mean action\nvalue, and do not consider the returns as in our paper.\nThere is more work that does track uncertainty for policy evaluation, but does not use these for policy\nimprovement / exploration. Most of these have focussed on Gaussian Process regression (Engel\net al., 2003). Rasmussen et al. (2003) uses two Gaussian Processes: one to track the parametric\nuncertainty in the value, and a second one to model the uncertainty in the transition model. However,\nthe paper still uses a greedy policy improvement. The Gaussian Process approach was also extended\nto continuous action spaces. There are actor-critic (Ghavamzadeh and Engel, 2007a) and policy\nsearch (Ghavamzadeh and Engel, 2007b) algorithms that track the uncertainty in the gradients, but\nagain only to stabalize the update, not to direct exploration.\nThe idea of exploration based on parametric uncertainty also connects to the difference between\naction space and parameter space / episode-based exploration (Matthias et al., 2017; van Hoof et al.,\n2017). Most (undirected) exploration methods, like \u000f-greedy and Boltzmann, inject exploration noise\nat the action space level. However, it can be beneficial to inject the noise at parameter level instead,\nusually because it allows you to retain a particular noise setting over multiple steps (e.g. an entire\nepisode). The risk of action-space exploration noise is that the agent has to redecide at every timestep\nand therefore cannot stick with an exploration decision. The effect might be jittering behaviour\nbetween exploration and exploitation steps. This has also been identified as the challenge of ensuring\n‘deep’ exploration Osband et al. (2016). We have not considered this problem in this paper, but it\ncould for example be implemented by fixing the dropout mask over an entire episode.\nWe also want to note that the exact same exploration problem occurs in classical (tree) search.\nSuccesful Monte Carlo Tree Search (MCTS) algorithms, like Upper Confidence Bounds for Trees\n11\n\n\f(UCT) Kocsis and Szepesvári (2006), act on the upper confidence bound of a frequentist confidence\ninterval of the value at each state-action pair. The overlap between reinforcement learning and (modelbased) search has been identified for long Sutton and Barto (1998), where RL i) does not assume\nan a-priori known environment model, and ii) usually includes a parametric function approximator\nto represent the value/policy, while search stores these in a tree structure (which is technically an\neffective sparse form of tabular representation). But besides that, the same exploration themes appear\nin both fields.\n\nA.2\n\nReturn uncertainty\n\nWhile the distributional Bellman equation (Eq. 3) is certainly not new Sobel (1982); White (1988),\nnearly all RL research has focussed on the mean action-value. Most papers that do study the\nunderlying return distribution study the ’variance of the return’. Engel et al. (2005) learned the\ndistribution of the return with Gaussian Processes, but did not use it for exploration. Tamar et al.\n(2016) studied the variance of the return with linear function approximation. Mannor and Tsitsiklis\n(2011) theoretically studies policies that bound the variance of the return.\nThe variance of the return does not need to be used with ’optimism under uncertainty’, and actually\nhas more frequently been considered for risk-sensitive RL. In several scenarios we may want to\navoid incidental large negative pay-offs, which can e.g. be desastrous for a real-world robot, or in a\nfinancial portfolio. Morimura et al. (2012) studied parametric return distribution propagation as well.\nThey do risk-sensitive exploration by softmax exploration over quantile Q-functions (also known as\nthe Value-at-Risk (VaR) in financial management literature). Their distribution losses are based on\nKL-divergences (including Normal, Laplace and skewed Laplace distributions), which could be a\nbetter distributional loss than the heuristic loss in Eq. 6. However, their implementations do remain\nin the tabular setting.\nRecently, Bellemare et al. (2017) theoretically studied the distributional Bellman operator. The authors\nshow that the operator is still a contraction in the policy evaluation setting, but not a contraction\nin any distribution metric for the control setting. They hypothesize this is due to the ‘inherent\ninstability of greedy updates’ in the Bellman optimality operator. Their algorithm (called C51) uses a\ncategorical distribution to propagate returns distributions, which may more easily accommodate for\nmultimodality compared to the Gaussian distribution used in this work. C51 backs-up the complete\nBellman distributions, but they do not use these for exploration. Their methods nevertheless improves\nover all other previous deep Q-networks on Atari games.\n\nA.3\n\nCount-based Exploration & Intrinsic Motivation\n\nCount-based exploration uses a slightly different incentive for exploration, focussing or rewarding\nregions of state-space that have not been visited (often). These ideas were extensively studied in the\ntabula rasa setting, e.g. R-max Brafman and Tennenholtz (2002) and Explicit-Explore or Exploit\n(E 3 ) Kearns and Singh (2002). Guez et al. (2012) explicitly plans ahead using Monte Carlo Tree\nSearch over uncertain transition dynamics models. Applications in high-dimensional domains include\nStadie et al. (2015) and Bellemare et al. (2016).\nIntrinsic motivation generalizes this notion of novelty to any internal reward for domain-independent\ncharacteristics, i.e. next to the domain-dependent external reward function. An example is rewarding\nactions that decreases the parametric uncertainty in the transition model (Houthooft et al., 2016).\nAlltogether, this class of exploration methods usually depends on the ability to learn good transition\nmodels (from limited data), a problem which is not trivial itself (Deisenroth and Rasmussen, 2011;\nDepeweg et al., 2017; Moerland et al., 2017).\nA theoretical problem with count-based / intrinsic motivation approaches can be that they change the\nRL objective itself. For example, bonuses on novelty might make an agent continue to visit a region\nof state-space where the value functions are already very certain, yet not all states are frequently\nvisited yet (like continuously walking around a room to view it from all angles, which gives a new\nvisual state each time). Nevertheless, intrinsic motivation-based approaches hold the state-of-the-art\non challenging exploration problems like Montezuma’s Revenge (Bellemare et al., 2016).\n12\n\n\fA.4\n\nUncertainty in model-based RL\n\nAll work in this paper only considered model-free RL. However, similar issues with uncertainty\nappear when learning the transition and/or reward function, known as ‘model-based RL’. Dearden\net al. (1999) was again the first to address this problem for the tabular setting. Mannor et al. (2004,\n2007) studied two environment sources of variance that may influence the return distribution: the\n‘internal variance’ due to a stochastic environment, and the ‘parametric (model) variance’ due to bias\nin the environment model. Neither of these were considered in this work, but both may be added.\nThese ideas were studied in neural networks by Depeweg et al. (2017), who instead uses the terms\nempistemic uncertainty for the model bias and aleatoric uncertainty for the inherent environment\nnoise/stochasticity. Their approach, which infers distributions on neural network parameters to\ncapture model bias, and uses expressive output distributions to capture true environment stochasticity,\nactually has a similar structure as our Double Uncertain Value Network (in some sense, they learn\na ‘Double Uncertain Transition Network’). Of course, transition model learning does not involve\nany uncertainty propagation (it is a well-defined supervised learning problem). Finally, Gal et al.\n(2016) used Bayesian drop-out, as considered in this work for parametric value uncertainty, to track\nparametric model uncertainty.\n\n13\n\n\fB\n\nInitial Return Entropy (IRE) as a measure of initial exploration difficulty\n\nDefine the initial return distribution (IRD) pinit (Z) as the distribution over trace returns Z ∈ R when\nsampling an initial state sinit from some initial state distribution and following a uniform random\npolicy from there on. For undirected exploration, the uniform policy is the best policy we can specify\nuntil we start encountering varying returns. Define the initial return entropy (IRE) as the entropy of\nthis distribution:\nZ\nH(Z) =\n\n\u0010\n\u0011\npinit (Z) · log pinit (Z) dZ\n\n(9)\n\nWe propose that the IRE is an interesting measure of the domain exploration difficulty, where\nlower values indicate a higher exploration challenge. Figure 4 shows the IRD and IRE for various\ndomains from the OpenAI Gym repository. We see quite large differences between the shape of\nthese distributions. Importantly, some domains with hard exploration, for example the Atari game\nMontezuma’s Revenge, show a very spiked IRD and therefore low IRE. The challenge of such\ndomains is that nearly all initial traces give the same return, which makes it hard to ever find a first\nindication of where to go. In many of such domains nearly all traces then give 0 reward, but for\nexample Mountain Car shows all traces giving -200 reward (there is a -1 penalty per timestep, and\nGym caps MountainCar episodes at length 200 by default). The entropy of the return distribution\nis of course robust against such reward function translations, making it a stable measure of initial\nexploration difficulty.\nWe do not propose this is the only measure of domain exploration difficulty. For example, a wellknown exploration challenge is choosing between a small suboptimal pay-off and exploring further\nto obtain a potential higher reward. This type of exploration challenge is not accurately reflected in\nthe IRE, as simple early rewards spread out the initial return distribution and may falsely suggest the\ndomain is easy. There are of course many more dimensions that influence the RL task difficulty, like\nthe state and action space cardinality, but the IRE nicely illustrates why a low-dimensional task like\nthe Chain (Appendix D) can actually be quite challenging.\n\nFigure 4: Return distributions from the initial state in different environments for a uniform random policy.\nHistogram produced over 50.000 traces of maximum 500 steps. The first 8 domains are directly taken from the\nOpenAI Gym. The Chain domain is introduced in Appendix D. Orange line is a kernel density estimate, with the\nvertical dashed line its empirical mean (a Monte Carlo estimate of Q(s, a) under a uniform random policy. The\ntop-right display the initial return entropy (IRE) estimate for the domain.\n\n14\n\n\fC\n\nIllustration of undirected versus directed exploration\n\nWe will quickly elaborate on the difference between undirected exploration methods, like \u000f-greedy\nand Boltzmann exploration, and directed methods, like Thompson sampling, in a theoretical example.\nConsider two available actions which, given some observed data H, both have some posterior actionvalue distribution p(Q|H). Figure 5 shows two scenario’s, I (left) and II (right). The only difference\nbetween both scenario’s is our uncertainty about the value of action a1 : in the second scenario we are\nmuch more uncertain about its true value. We now compare how \u000f-greedy, Boltzmann and Thompson\nsampling will act in both scenario’s. The main point will be that undirected methods cannot leverage\nthe uncertainty information.\n\nFigure 5: Example posterior value distributions for two available actions. Scenario I (left): Action 1 (blue solid\nline) has µ1 = 0, σ1 = 1, Action 2 (green dashed line) has µ2 = 2, σ2 = 1. Scenario II (right): The same\nexcept for σ1 = 5.\n\n1. \u000f-greedy exploration only uses the distribution means and will act the same in both scenarios,\npreferring action 2 and selecting action 1 with (small) probability \u000f.\n2. Boltzmann (soft-max) exploration is usually seen as more subtle, gradually preferring actions\nwith a higher pay-off. Boltzmann does consider the numerical scale of the action means, including\ntheir difference (something \u000f-greedy ignores):\nπBoltzmann (a|s) = P\n\neµa\n\na? ∈A\n\neµa?\n\nHowever, it still acts the same in scenario I and II, because Boltzmann approximates a distribution\nover both actions by still only considering their means. Although the softmax returns a probability distribution over actions, this should can not be interpreted as their uncertainty.7 Another problem with\nBoltzmann action selection is that it is non-robust against translation of the reward function, making\nit tedious to tune. Therefore, many undirected implementations still prefer \u000f-greedy exploration.\n3. Thompson sampling, a directed exploration method, uses π(a1 |s) = p(Q1 > Q2 ). For the\nexample with normal random variables Q1 ∼ N (·|µ1 , σ1 ) and Q2 ∼ N (·|µ2 , σ2 ), we can analytically\ncalculate P (Q1 > Q2 ) = P (Q1 − Q2 > 0). Define X = Q1 − Q2 , then X will still\np have a normal\ndistribution, and by standard laws of probability, E[X] = µ1 − µ2 , and Sd[X] = (σ1 )2 + (σ2 )2 .\nApplying\nthis to the example, gives us for Scenario I (left) π(a1 ) = N (Q1 −Q2 > 0|µX √\n= −1, σX =\n√\n2) ≈ 0.08, and for Scenario II (right) π(a1 ) = N (Q1 − Q2 > 0|µX = −1, σX = 26) ≈ 0.35.\nNote how Thompson sampling naturally assigns extra probability mass to action a1 in Scenario II,\nwhere we are much more uncertain about its potential value.\n7\n\nA similar phenomenon happens with the softmax and cross-entropy loss in classification tasks. The outputs\nof this softmax are also frequently falsely interpreted as a measure of uncertainty over classes (Gal, 2016).\nHowever, when we extrapolate (far) away from our observed data, one of the classes usually gets a high\nprobability. It thereby appears as we are very certain, but since we have not observed any data in this region of\ninput space, we should actually be very uncertain. This illustrates how point estimates over a discrete set cannot\nbe transformed to uncertainties (what we need is an entire uncertainty/distribution per class output).\n\n15\n\n\fD\n\nIllustration of exploration challenge: Chain domain\n\nWe now study the Chain domain, an example MDP (Fig. 6) that illustrates the difficulty of exploration\nwith sparse rewards. This domain is also empirically studied in the results section of this paper. The\nMDP consists of a chain of states S = {1, 2..., N }. At each time step the agent has two available\nactions: a1 (‘left’) and a2 (‘right’). At every step, one of both actions is the ‘correct’ one, which\ndeterministically moves the agent one step further in the chain. The wrong action terminates the\nepisode. All states have zero reward except the final chain state N , which has r = 1. Variants\nof these problem have been studied more frequently in RL (Osband et al., 2014). In the ‘ordered’\nimplementation, the correct action is always the same (e.g. a2 ), and the optimal policy is to always\nwalk right. This is the variant illustrated in Fig. 6 as well.\n\nFigure 6: Chain domain. Example MDP where undirected exploration is highly inefficient. Based on (Osband\net al., 2014).\n\nOsband et al. (2014) studied the expected regret for a variant of this scenario. We here present a\ndifferent illustration, where we show the expected time until the first visit to the terminal state (i.e.\nthe first non-zero trace in this domain).\nExample 1. Let l denote the number of episodes before we first reach state N . Clearly, before\nwe reach N for the first time, we have seen no reward information, and undirected exploration will\nfollow a uniform random policy. The probability of a trace reaching state N under the uniform policy\nis p = 2−(N −1) . Therefore, the number of episodes until we first reach N follows a negative binomial\n(N −1)\ndistribution with success probability p, i.e. l ∼ N B(1, p). It follows that E[l] = 1−p\n− 1.\np =2\nExample 1 shows that, for undirected exploration on point estimates, the required number of exploratory episodes scales exponentially with the exploration depth N . Although this is clearly a\nsimplified domain, it is important to note that this setting is actually very representative of the\nexploration problem in sparse reward domains. This is well visible in Fig. 4, where we can see the\nChain domain having similar initial return distributions as for example Montezuma’s Revenge, a\ngame notorious for its challenging exploration.\nD.1\n\nAdditional results for ordered Chain\n\nThe experiments section in the paper discusses the unordered Chain, where the correct action at\nevery step is randomized. We here compare to the ‘ordered’ Chain, where the correct action at every\nstep is always a2 . Although this is the standard implementation in literature, we believe there is a\nsystematic bias in this domain that makes them not really exponentially challenging for exploration.\nThe problem is that the optimal policy has a network predicting a2 at every step. This will happen\ntoo easily in a function approximator (like a neural network) due to its natural tendency to generalize.\nWe show the results on the ordered Chain in Fig. 7. First of all, compared to the results in Fig. 2, we\nsee that exploration is indeed much easier in the ordered problem. For example, \u000f-greedy now also\nsolves the problem, something which we would not expect from the exponential exploration time\ndiscussed above. Nevertheless, we see that the probabilistic exploration methods still outperform\n\u000f-greedy, especially when the length of the chain increases.\n\n16\n\n\fFigure 7: Learning curves on the ordered Chain domain.\n\nE\n\nImplementation Details\n\nNetwork architecture consists of a 3 layer network for each discrete action with 128 nodes in each\nhidden layer and ReLu activations. For parametric uncertainty, each hidden layer has drop-out\napplied to its output, with pkeep probability to keep a node. We use separate subnetworks per action\nto explicitly separate their uncertainty. For larger problems, the initial representation layers may\nbe shared. Learning rates are fixed at 0.001 on all experiments. Optimization is performed with\nstochastic gradient descent using Adam updates in Tensorflow. For the experiments with parametric\nexploration (parametric uncertainty only) we train on a standard squared loss between new target\nand predicted mean action value, i.e. the first half of Eq. 6. We use a target network and replay\ndatabase, where we replay 10% of times in a prioritized way (by maintaining a separate prioritized\nreplay queue based on the total temporal difference error in the previous time this trace was trained\non). All domains (except for the Chain) are taken from the OpenAI Gym repository available at\nhttps://github.com/openai/gym.\nAll \u000f-greedy experiments have \u000f fixed at 0.05 throughout learning. Drop-out rates were either\npkeep = 0.75 (for parametric uncertainty only) or pkeep = 0.90 (for uncertain returns). All experiments used one-step SARSA (ie., on-policy updates with eligibility traces parameter λ = 0 (Sutton\nand Barto, 1998)), except for the MountainCar experiments, which use λ = 0.9. Note that the ideas\nabout eligibility traces and cutting traces equally apply to the propagation of distributions, i.e. they\nallow for quicker propagation over multiple timesteps (always at the risk of propagating on-policy,\nexploratory results too quickly/far).8\nThompson sampling uses the same policy for exploration and evaluation. In some sense, proper uncertainty policies somewhat blur the line between on- and off-policy (where the behavioural/exploration\npolicy differs from the target/evaluation policy), as there is just on reasonable probabilistic policy\nincorporating all uncertainty. Nevertheless, we could consider Thompson sampling exploration while\nevaluating with a policy that does act on some mean value again.\n\n8\nWe do believe that the uncertainty-based policies, like Thompson sampling, may also benefit work on\ncutting traces. Trace cutting is usually based on importance sampling ratios between the exploratory policy\nand the target policy. Thompson sampling may provide more realistic probabilities for exploratory actions,\nwhich may allow for more natural trace cutting. For example, \u000f-greedy always strongly cuts a trace for every\nexploratory step, no matter whether the exploratory action is very close to the best one, or known to be very bad.\nIn contrast, probabilistic policies will cut traces when other possible actions in the state have much uncertainty\nleft, which should indeed stop the speed of our back-ups. A challenge is that our neural network implementation\nnaturally samples a next action, but the associated probability of each action is not directly available. Of course,\nfor a small discrete action space we could approximate it by repeatedly sampling from our policy.\n\n17\n\n\f",
         "train",
         "60138",
         "9289"
        ],
        [
         "29",
         "19597",
         "cs.AI",
         "Artificial Intelligence",
         "1801.09317v1.pdf",
         "A Cyber Science Based Ontology for Artificial\nGeneral Intelligence Containment\nJason M. Pittman1,* and Courtney E. Soboleski1\n1 Capitol\n\nTechnology University, Synthetic Intelligence Research Institute , Laurel, MD, USA\nauthor\n\n* corresponding\n\narXiv:1801.09317v1 [cs.AI] 28 Jan 2018\n\nABSTRACT\nThe development of artificial general intelligence is considered by many to be inevitable. What such intelligence\ndoes after becoming aware is not so certain. To that end, research suggests that the likelihood of artificial\ngeneral intelligence becoming hostile to humans is significant enough to warrant inquiry into methods to limit such\npotential. Thus, containment of artificial general intelligence is a timely and meaningful research topic. While\nthere is limited research exploring possible containment strategies, such work is bounded by the underlying field\nthe strategies draw upon. Accordingly, we set out to construct an ontology to describe necessary elements in\nany future containment technology. Using existing academic literature, we developed a single domain ontology\ncontaining five levels, 32 codes, and 32 associated descriptors. Further, we constructed ontology diagrams to\ndemonstrate intended relationships. We then identified humans, AGI, and the cyber world as novel agent objects\nnecessary for future containment activities. Collectively, the work addresses three critical gaps: (a) identifying and\narranging fundamental constructs; (b) situating AGI containment within cyber science; and (c) developing scientific\nrigor within the field.\n\n1. Introduction\nArtificial intelligence (AI) is a timely and germane topic. No longer the esoteric domain of academics and researchers\nalone, the public is well aware of the extensive progress in the field. Mainstream media has brought practical\napplications such as autonomous vehicles (e.g. Tesla) and leisure game victories (e.g., Waston, AlphaGo) to the\nforefront of daily life. Thinking machines are a realization of science fiction, writ large. Certainly, the positive\naspects of continuing to develop and deploy such systems are disruptive (Sotala & Yampolskiy, 2016). However,\nsuch narrow AI operates in limited operational scope and presents little direct risk to human life. On the other hand,\na synthetic intelligence with the ability to dynamically operate in general scopes may indeed present direct and\nsustained danger.\nArtificial general intelligence (AGI) is precisely that; AI with intelligence at or beyond human capability. While\nthe concept of AGI is not new, there has been rapid growth in the literature surrounding the subject. AGI, perhaps\nunfortunately, is framed broadly in two manners: (a) in popular culture, as something that is simultaneously inevitable\n(Amodei et al., 2016; Baum, Goertzel, & Goertzel, 2011; Kurzweil 2005) and (b) of existential danger (Bostrom,\n2002; Bostrom & Yudkowsky, 2011; Bostrom & Cirkovic, 2011). The nexus of these two frames has engendered\nserious research into ethics and transhumanism, as well as safety and trust.\nThis study focuses on a specific area of research in the latter category: containment of AGI. According to Babcock,\nKramar, & Yampolskiy (2016), viable AGI containment will necessitate a combination of traditional cybersecurity\ntechnologies such as (a) safe language semantics; (b) physical separation of systems; (c) sandboxing; and (d) virtualization. However, Babcock et al. recognized the problem of limited capacity for traditional cybersecurity paradigms\nto address AGI containment. That is, the technologies Babcock et al. suggested may present a small window into\nwhat the broader field of cyber science can offer to future containment research and practical development.\n\n\fCyber science is a nascent field that considers cybersecurity in a more comprehensive knowledge context (Ma, Nahal,\n& Tran, 2015; Maxion, Longstaff, & McHugh, 2010; McDaniel, Rivera, & Swami, 2014). An applicable sector\nwithin the cyber science was defined by Kott (2015) as principally considering malicious software. The applicability\nrests in the nuance of Kott’s argument; that is, ”malicious software (as well as legitimate software and protocols used\nmaliciously) used to compel a computing device or a network of computing devices to perform actions desired by\nthe perpetrator of malicious software (the attacker) and generally contrary to the intent (the policy) of the legitimate\nowner or operator (the defender) of the computing device(s)” (pg. 1). While there could be debate as to whether an\nAGI is malicious software (in the perspective of humans) or a containment apparatus is malicious software (in the\nperspective of the AGI), there is not a means to organize the underlying constructs that engender meaning.\nThus, we endeavored to build upon the initial discussion initiated by Babcock et al. (2016) by developing a cyber\nscience focused ontology for AGI containment. The significance in doing so rests in the necessity of having a\nformalized, systematic abstraction from which future research can construct scientific inquiry. Moreover, such an\nontology may fill existing gaps in a manner that enables future applied research in AGI containment.\n\n2. Background\nScientists have sought to engineer AI with intelligence at or beyond human capability by aggregating existing\nnarrow AI technology. Narrow AI is an implementation tool for enhancing human tasks in limited domains (Stone et\nal., 2016). The problem is that narrow AI cannot be aggregated to birth general AI (Baillie, 2016). Accordingly,\nthe purview has transitioned from manufacturing singular intelligent parts to conceiving entire intuitive systems.\nSuch systems have instigated innovations in novel training approaches (Guo & Aarabi, 2016), learned systems for\ninternal efficiency (Le & Schuster, 2016), greater contextual and environmental awareness (Denil et al., 2017), and\nemergence (Silver et al., 2016). Progress has been further accelerated by advancements in big data, machine learning,\nand computer processing (Stone et al., 2016).\nThe result is not only a catalogue of technologies capable of functioning appropriately with environmental foresight\n(Nilsson, 2009) but an entirely new cyber science. While, artificial general intelligence portends the ability of an\nintelligent machine to infer, reason, and adapt to its environment, cyber science contextualizes such AGI within a\nmore comprehensive knowledge framework (Kott, 2015). Cyber science contrasts existing literature that rationalizes\nAGI solely within the physical world of humans (Bostrom, 2002; Bostrom & Yudkowsky, 2011; Amodei et al.,\n2016). Instead, cyber science trains the lens of AGI investigation on the complex and unpredictable cyber world a\nfuture entity may exist in (Oltramari, Cranor, Walls, & McDaniel, 2014; Ma et al., 2015; McDaniel et al., 2014).\nAccordingly, actuating AGI is constrained by the implications of unpredictability (Agar, 2016; Stone et al. 2016).\nIn fact, an entire subfield is dedicated to mitigating potential AGI through containment (Babcock, Kramar, &\nYampolskiy, 2017).\nContainment seeks to avert scenarios where AI maliciously competes against humans through strict regulation and\ncontrol (Bostrom, 2014; Babcock et al., 2016). Conditions include not only technical protocols but ethical, moral,\nand legal considerations as well (Yampolskiy, 2012; Powers, 2006; Lewis & Modirzadeh, 2016). Such controls are\npredicated on the assumption that AGI not only possesses a catastrophic, even existential, risk to human society but\nthat it will act on such risk by intentionally harming humans (Müller, 2014; Bostrom, 2014; Sotala & Yampolskiy,\n2014; Chalmers, Awret, & Appleyard, 2016; Amodei et al., 2016; Yudkowsky, 2008). Accordingly, containment\nliterature demonstrates a singular preference toward delaying or banning AI advancements altogether to achieve a\nzerosum, human favored reality (Babcock, et al., 2017). Yet, existing containment literature is plagued by myriad\ndefinitions and paradigms, an assimilation of danger through an anthropomorphic lens, and a focus on avoidance\nthat assumes a negative position of inevitability (Bishop, 2009; Grau, 2006; Yampolskiy & Fox, 2012). Thus,\nimplementation of containment policies is not only inherently obtuse but contradictory to the entire premise of\nsuperintelligence.\n\n2/12\n\n\fAgar (2016) challenged containment assumptions by arguing that solutions to the AGI problem are as conceivable as\nAGI itself. In fact, human society will become increasingly more adept at handling AGI as continued artificially\nintelligent innovations become common place (Agar, 2016; Stone et al. 2016). That is, Agar and Stone assert that\nif humans can develop a superintelligent machine, then we are equally as capable of harnessing such technology\nto solve any subsequent issues that arise from it. Developing an architecture that accurately accounts for such an\nassertion requires containment be mapped to the greater cyber theoretical framework (Ning, et al., 2017). Such an\narchitecture is the crux of cyber science, which supplements technical and physical premises with philosophical and\nsocial ones (Maxion et al., 2010; Oltramari et al., 2014; Ning, 2016).\nYet, while an ontological architecture for AGI containment been suggested (Yampolskiy & Fox, 2012; Yampolskiy,\n2014, 2016), one has never been fully codified (Amodei et al., 2016). As a result, the cyber community lacks a\nmeasurable or repeatable standard from which to understand or predict cyber events and entities (Maxion et al., 2010).\nAn ontology for AGI containment therefore, accounts for the broader cyber context by systematically converting\nexisting AGI abstractions into defined relationships (Kott, 2015). In doing so, our cyber sciencefocused ontology for\nAGI observes domain constructs, remains iterative, and applies a level of scientific rigor currently underdeveloped\nwithin the discipline (Uschold & King, 1995; Ren, 2012; Maxion et al., 2010). Simultaneously, our analysis will\nleverage the same multidisciplinary approaches compulsory in AGI development to its germinal research. The\nresulting ontology may establish AGI as a cyber science domain and enable future empirical research.\n\n3. Method\nA single research question motivated this study: what specific concepts and relationships between such concepts are\nnecessary so that AGI containment functionality can be explored? Toward an answer to this research question, we\nendeavored to develop a cyber science focused ontology for AGI containment. Development of an ontology appeared\nappropriate because, as Babcock et al. (2016, 2017) commented, there is uncertainty as to how AGI containment\nought to function. Further, as a scientific field defined by both theoretical and empirical methods, exploring cyber\nscience relationships requires a foundational ontology (Longstaff, 2010). In other words, an ontology can mitigate\nconceptual misunderstanding.\nPoli (1996) suggested that ontologies provide generalized frameworks in which more specific knowledge taxonomies\ncan be developed. Further, as Poli noted, the unavailability of an ontology limits the relational context for future\ninferences or knowledge construction. Indeed, the lack of an ontology inhibits meaningful discourse not only\nconcerning concepts but also with applied constructs. Accordingly, we suspected that a lack of foundational ontology\nmight be a cause for the uncertainty related to AGI containment described by Backcock et al (2016, 2017). Thus, to\nformally represent the concepts that ought to be included in AGI containment, we pursued a single domain ontology\n(Subhashini & Akilandeswari, 2011).\n3.1 Method Appropriateness\nWe considered a grounded theory design for our research methodology. Grounded theory is appropriate when one\nseeks to develop a theory based on emergent themes in data (Martin & Turner, 1986). That is, grounded theory\nproduces an explanation of what is given existing qualitative data. Such an explanation is achieved by iteratively\ncollecting and analyzing data. However, according to Suddaby (2006), the results from grounded theory research are\nlimited by what is known. Thus, while there may be some notional overlap between grounded theory and ontology,\nthe former presupposes the latter. As well, we did not set out to facilitate the output of theory as much as the\nunderlying conceptual vocabulary to support future theoretical frameworks.\nExisting research (Subhashini & Akilandeswari, 2011; Swartout, Patil, Knight, & Russ, 1997) outlined two toplevel\nforms of ontology: domain and theory. Domain ontologies are classlevel vocabularies that express concepts and\nrelationships between those concepts (Swartout et al., 1997). In contrast, Swartout et al. defined theory ontologies as\n3/12\n\n\fdescribing aspects of (our) reality. While a theory ontology could be used, we decided that the reality of an AGI\nin a containment space would be best described by that AGI. Whereas, we felt developing concepts related to the\ncontainment space itself to be a rational position.\nAdditionally, we elected to develop a single domain ontology as opposed to a multiple domain ontology or a\nhybrid ontology. Relevant literature (Subhashini & Akilandeswari, 2011; Swartout, Patil, Knight, & Russ, 1997)\nindicated that a single ontology best establishes a global ontology based on the collection of concept sources.\nThe single ontology approach appeared most fitting relative to our purpose of developing a universal ontology for\nAGI containment. In contrast, a multiple ontology or hybrid ontology approach did not align with our objective\ndue to those methodologies necessitating the development of local ontologies mapped individually to the source\nmaterial.\n3.2 Existing Ontologies\nBefore developing our ontology, we performed a literature review to ensure that no ontology existed which addressed\nour research question. This literature search was distinct from that performed later as a means of collecting literature\nfor the development of the AGI containment ontology proposed in this work. While a rich knowledge base exists for\nnarrow aspects of artificial intelligence (e.g., natural language processing), we did not find any ontologyrelated AGI\ncontainment literature. The lack of such research was not surprising given the nascent form of the AGI containment\nfield and does not reflect negatively on the existing work on the topic. Next, we searched for germane literature\nassociated with cyber science and cybersecurity.\nInterestingly, both cyber science and cybersecurity offered foundational ontologies albeit without any direct relevance\nto AI, AGI, or AGI containment. Moreover, according to Oltramari, Cranor, Walls, and McDaniel (2014), existing\ncybersecurity ontologies (Blanco et al., 2008) are flawed. Further, attempts to achieve a robust cyber science\nontology have fallen short (Maxion et al., 2010; Ning, 2017). Although this study does not address the limitations\nof cyber science or cybersecurity ontologies, we did ensure that such were not carried forward into our proposed\nontology.\n3.3 Ontology Construction Methodology\nTwo studies directly informed how we developed our ontology. Foremost, we consulted the seminal work by Uschold\nand King (1995) for a general sketch of what phases we should follow when constructing a new ontology. Further,\nto minimize potential errors while determining fundamental AGI containment concepts, we leveraged the ontology\nbuilding process outlined by Ren (2012). Ren suggested that the use of academic literature as the foundational\nsource of concepts presented a more reliable and efficient ontology building process. Not only did literature as\na material concept source present a sound rationale for this work but such also conformed to our stated purpose\nthrough enabling the single domain methodology.\nFurthermore, our ontology construction process focused on the designing and development steps as described by\nSubhashini and Akilandeswari (2011). Integrating the new ontology with existing ontologies was not necessary\nfor obvious reasons. Additionally, given the germinal nature of this work, we opted to postpone refinement of the\nproposed ontology through validation and iteration. Subordinate to the design and develop steps, we employed the\nspecific construction phases outlined by Ren (2012). That is, we (a) collected academic literature associated with\nAGI containment, (b) selected potential ontology concepts based on keywords in the literature, and (c) extracted\nrelationships between such potential concepts based on keyword frequencies. The relationships between concepts\nwere mapped using two graph morphologies.\n\n4/12\n\n\f4. Results\nWe opted for a modular, tiered ontology architecture comprised of objects, attributes, and relationships (Oltramari et\nal., 2014; Subhashini & Akilandeswari, 2011; Ren, 2012). Concurrently, an axiomatic approach created a foundation\nfrom which our ontology could extract further reason around said objects, attributes, and relationships. Axioms are\nstated along with the ontology element they describe. The structure of our ontology is detailed as follows.\n4.1 Objects\nObjects (Table 1) in our cyber science ontology for AGI containment represent upper domain areas. As an upper\ndomain area, objects are agents through which AGI containment occurs. Thus, without such agents, containment\ncould not occur. Furthermore, agents can be understood as entities, of which there are three types: humans, AGI, and\nthe cyber world. The three agents are discrete, meaning that a human cannot be AGI cannot be a cyber world.\nObject Coding\nObject Descriptor\n\nO1\nhuman\n\nO2\nAGI\n\nO3\ncyberworld\n\nTable 1. Tiered ontology description of levels, codes, and descriptors for Objects\nHumans are an organic agent capable of autonomy and intelligence whereas AGI are an artificial agent capable\nof autonomy and intelligence. Indeed, the capacity for autonomy and intelligence is fundamental to containment\nbecause without such features, agents would have no need, desire, or intent. Thus, the final agent of containment is\nthe cyber world, which is the digitized environment in which organic human and artificial general intelligence agents\nexist (Ma et al., 2015). That is, containment can only exist in the cyber world, and never occurs in a conventional,\nnoncyber enabled world.\nClass Coding\nClass Descriptor\n\nC1\nindividual\n\nC2\nsociety\n\nC3\nswarm\n\nC4\nphysical\n\nC5\nsocial\n\nC6\nmental\n\nC7\ncyber\n\nTable 2. Tiered ontology description of levels, codes, and descriptors for Classes\nAgents are concentrated based on their instance and class (Table 2): a single human or AGI instance is an individual,\nwhile a class of humans is a society and a class of AGI is a swarm. Similarly, the cyber world is composed of four\nclass concepts: the cyber, physical, social, and mental (CPSM) (Ning, 2017). Instance and class serve to further\nsubcategorize and delimit agent relationships. For example, a distinction is drawn between each cyber world class\nsince humans and AGI are not required to exist in all four simultaneously. Each instance and class also exhibit and\nmaintains their own features. Specifically, the cyber realm is ”anything that exists digitally in cyberspace, either\npurely synthesized by a computer, or closely correlated to and further conjugated with a real entity in physical,\nsocial and mental spaces” (Ma et al., 2015). Meanwhile, the physical, social, and mental space mimic those of\nconventional worlds but are understood from a cyber science perspective as conjugations of objects. In this case,\nsubcategorization arranges the ontology hierarchically (Figure 1) to more easily segregate objects.\n\n5/12\n\n\fFigure 1. Diagram of agent objects (O), their classes(C) in the AGI containment ontology.\n4.2 Attributes\nAnother form of segregation occurs through physical and abstract attributes (Table 3). Physical attributes provide the\ninfrastructure from which agents compose and leverage capabilities. Thus, physical attributes enable delineation by\ncreating a unique signature summarized by the composition, architecture, and locality of the agent.\nAtrribute Coding\nAtrribute Descriptor\n\nA1\nphysical\n\nA2\nabstract\n\nTable 3. Tiered ontology description of levels, codes, and descriptors for Attributes\nThe object’s signature separates one agent from another. For example, the nature of the agent (composition) and the\nstructure of the agent (architecture) couple with locality to output a unique persona that marks an agent in space\nand time. Subcategorization in this sense serves to further distinguish an entity by creating a discrete identity. For\ninstance, composition is the construction of matter (organic or inorganic) and visibility (able to be seen or not).\nSimilarly, physical architecture categorizes the agent based on their hardware (the physical tools, implements, and\nparts used by entities) and software (the programs, libraries, and data used by entities for executing relationships).\nWith locality providing a temporal and spatial reference point, physical attributes enable cyber science agent\ndifferentiation through unique traits (Figure 2).\nIn addition to physical attributes, objects within the cyber science interpretation of AGI containment can be\ncontainerized by abstract attributes (Figure 3). In fact, while physical attributes ascribe identity, abstract attributes\naccount for the concepts that predicate a containment environment. Thus, abstract attributes are the capabilities\nleveraged by objects in a cyber science world. Capabilities come in the form of security, intelligence, and autonomy.\nRegarding autonomy and intelligence, there are two axioms. There are no degrees of autonomy; an agent is\nautonomous or it is not. Additionally, intelligence is a physical process or the (emergent) consequence of one; not a\nmetaphysical process or the (emergent) consequence of one (Wissner-Gross & Freer, 2013).\n\n6/12\n\n\fFigure 2. Diagram of physical attributes (A1), subattributes (S), and their features (F) in the AGI containment\nontology.\nFurther, security is a phenomenon that exists within spectrums of logic and uncertainty, where logic is the essence of\nrules applied to cyber science objects and uncertainty is the unpredictability of cyber science objects (Kott, 2015).\nConversely, intelligence and autonomy are dictated by binary properties, with intelligence being the capacity to\nacquire knowledge and skills and autonomy being the capacity to exercise independent control over one’s own\nintelligence. Such binary properties serve to create discrete features. For example, there is no spectrum of quality\nor composition; the quality can only be narrow or general and the composition can only be artificial or organic\n(made by chemical synthesis) or artificial (not existing naturally). Such discrete features compliment degree-based\nproperties to create a ho-listic abstraction of the agent.\n\nFigure 3. Diagram of abstract attributes (A2), subattributes (S), and their features (F) in the AGI containment\nontology.\n\n7/12\n\n\f4.3 Relationships\nWith defined agents and such agent identities, relationships serve to outline interaction between objects within the\ncontext of containment. The relationships described in our cyber science ontology (Figure 4) are either active or\npassive. Passive relationships enable the environment and consistent of existence (having objective reality) and\npolicy (a set of assertions or requirements) (Kott, 2015). Without existence or policy, containment is an irrelevant\nnon-factor. Yet, converting containment the concept into containment the executable requires that active relationships\nbe applied to the cyber science world. Thus, the intent of active relationships is to either attack or defend.\nThe dynamics of attack or defend relationships are such that all relationships occur within a cyber world; and active\nrelationships occur only after passive ones. That is, agents must be in existence and policy must be violated for\nattack or defend activities to occur. Thus, relationships exhibit a sequential pattern: passive relationships occur;\nthe cyber world is disturbed; the attacker employs tools or techniques to promote activity adverse to the intent\nof the defender; and the defender employs tools or techniques to re-initiate or establish their intent (Kott, 2015).\nContainment, therefore, can be described as an active relationship between agents, and within a cyber world, that (a)\nprevents an agent from disrupting the cyber world without authorization or (b) maintains the equilibrium achieved\nduring active relationships (Babcock et al., 2016).\n\nFigure 4. Diagram of relationships (R), subattributes (S), and features (F) in the ontology for AGI containment.\nGiven the function of containment f(c) and current knowledge of the cyber world k, both attacker and defender\nexist in a f(c) = k environment. However, an attack implies that the attacker has acted on k. Thus, the attack can\nbe described as f(c) = k+1, where +1 is the subsequent action of the attacker in response to k. Thus, an attack has\ntwo features: initiation and intent. Initiation describes the agent acting on k (human or AGI) while intent represents\nthe catalyst for initiation (k). Intent therefore, is either preemptive or responsive, where preemptive is to prevent or\nforestall a perceived element of k and responsive is a reaction to an actual element of k. Attack features - initiation\nand intent - occur simultaneously. Conversely, a defense is always initiated by the non-attack agent. Initiation then,\nis singular rather than binary. Additionally, a defend relationship is always responsive since a preemptive defense is\nan attack.\n\n8/12\n\n\f5. Conclusions\nThe cognitive leap from limited domain, narrow intelligence to super human AGI generated a novel discourse on the\nscope of future technologies (Horowitz, 2014; National Science and Technology Council, 2016). Indeed, the interest\nsurrounding the prospect of super human intelligence led to a subsequent influx in literature that framed AGI largely\nin an imminent danger context (Müller, 2014; Bostrom, 2014; Sotala & Yampolskiy, 2014; Chalmers et al., 2016;\nAmodei et al., 2016; Yudkowsky, 2008). The pretense of imminent danger led to the introduction of containment, or\nthe application of traditional cybersecurity technologies to thwart AGI risks (Babcock et al., 2016).\nContainment research presupposes a binary world where AGI pits itself against all else to achieve a zerosum end\nstate (Babcock et al., 2016; Bostrom, 2002; Bostrom & Yudkowsky, 2011; Bostrom & Cirkovic, 2011). As such, the\nliterature fails to consider the full breadth and depth of the AGI context, while simultaneously ignoring common\ntenets from which to extract further meaning. Ironically, containment proponents themselves have suggested a\nstandardized framework to enable comprehensive understanding and predict future events and entities (Yampolskiy\n& Fox, 2012; Yampolskiy, 2014, 2016; Amodei et al., 2016). Yet, no such architecture had been brought forth.\n\n6. Recommendations\nThe introduction of our cyber science AGI containment ontology addresses three critical gaps in the germinal\nresearch by (a) identifying and arranging underlying constructs; (b) placing containment squarely within the complex\ncyberworld of future AGI; and (c) establishing a level of scientific rigor previously underdeveloped within the\ndiscipline. Moreover, our architecture empowers other researchers with central axioms that enable replicability and\nshared understanding within the domain.\nFuture AGI containment research may build upon the single domain ontology produced in this study. Specifically,\nbecause we have provided the means to organize the underlying constructs that engender meaning within AGI\ncontainment, our hope is that subsequent research begins to move away from the presupposed binary nature of AGI\ncontainment. Further, the ontology may aid future research investigating the malicious software perspective of AGI\nand containment.\nCertainly, there is more work to be done. Whilst an ontology may provide a foundational basis for constructing new\nAGI containment knowledge, much work remains. Foremost, there is opportunity to produce theory ontologies that\ndescribe more detailed aspects of containment. Additionally, as the field of cyber science itself evolves, there is a\nneed for a continuous integration between the converged knowledge domains involved in AGI containment. Lastly,\nthere is direct opportunity to redefine existing containment research within the scope defined through the single\ndomain ontology outlined in this study.\n\nReferences\nAgar, N. (2016). Don’t Worry about Superintelligence. Journal of Evolution and Technology. 26(1): 73-82.\nAmodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., & Mane, D. (2016). Concrete Problems in AI\nSafety. arXiv. Retrieved from arXiv:1606.06565\nBabcock, J., Kramar, J., & Yampolskiy, R. (2016). The AGI Containment Problem. Lecture Notes in Artificial\nIntelligence 9782 (AGI 2016, Proceedings) 53-63.\nBabcock, J., Kramar, J., & Yampolskiy, R. (2017). Guidelines for Artificial Intelligence Containment. ArXiv\nPreprint. doi:1707.08476\nBaillie, J-C. (2016).\nWhy AlphaGo Is Not AI. IEEE Spectrum.\nhttps://spectrum.ieee.org/automaton/robotics/artificial-intelligence/why-alphago-is-not-ai\n\nRetrieved\n\nfrom\n\n9/12\n\n\fBaum, S., Goertzel, B., & Goertzel, T. (2011). How long until human-level AI? Results from an expert assessment.\nTechnological Forecasting and Social Change, 78(1). 185-195.\nBishop, M. (2009).\nWhy Computers Can’t Feel Pain.\nUniversity of London.\nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi:10.1.1.492.3886&rep=rep1&type=pdf\n\nRetrieved from\n\nBlanco, C., Lasheras, J., Valencia-Garc, R., Fern, E., Toval, A., & Piattini, M. (2008). A Systematic Review and\nComparison of Security Ontologies. IEEE: 813-820. doi:https://doi.org/10.1109/ARES.2008.33\nBostrom, N. (2002). Existential Risks: Analyzing Human Extinction Scenarios and Related Hazard. Journal of\nEvolution and Technology, 9(1).\nBostrom, N. (2014). Superintelligence: Paths, dangers, strategies. Oxford: Oxford University Press.\nBostrom, N., & Cirkovic, M. (2011). Global Catastrophic Risk. Oxford: Oxford University Press.\nBostrom, N., & Yudkowsky, E. (2011) The Ethics of Artificial Intelligence. Cambridge Handbook of Artificial\nIntelligence, eds. Ramsey W., & Frankish, K. Cambridge: Cambridge University Press.\nChalmers, Awret, & Appleyard. (2016). The Singularity: Could artificial intelligence really out-think us (and would\nwe want it to)? Journal of Consciousness Studies: Imprint Academic.\nDenil, M., Agrawal, P., Kulkarni, T., Erez, T., Battaglia, P., & de Freitas, N. (2017). Learning to perform physics\nexperiments via deep reinforcement learning. Under review as a conference paper to ICLR. Retrieved from\nhttps://arxiv.org/pdf/1611.01843v1.pdf\nGrau, C. (2006). There Is No ‘I’ in ‘Robot’: Robots and Utilitarianism. IEEE Intelligent Systems 21(4): 52–55.\ndoi:10.1109/MIS.2006.81\nGuo, W., & Aarabi. (2016). Hair Segmentation Using Heuristically-Trained Neural Networks. IEEE Transactions\non Neural Networks and Learning Systems, 1-12. doi:10.1109/tnnls.2016.2614653\nHorowitz, M. (2014).\n“The Looming Robotics Gap,” Foreign Policy.\nRetrieved from\nhttp://www.foreignpolicy.com/articles/2014/05/05/the looming robotics gap us militay technology dominance\nKott, A. (2015). Science of Cyber Security as a System of Models and Problems. New York: Springer.\nKurzweil, R. (2005). The Singularity Is Near: When Humans Transcend Biology. New York: Penguin.\nLe, Q., & Schuster, M. (2016). A Neural Network for Machine Translation, at Production Scale. Google. Retrieved\nfrom https://research.googleblog.com/2016/09/a-neural-network-for-machine.html\nLewis & Modirzadeh.\n(2016).\nWar-Algorithm Accountability.\ngram on International Law and Armed Conflict, Harvard Law\nhttps://papers.ssrn.com/sol3/papers.cfm?abstract id2̄832734\n\nHarvard Law School ProReview.\nRetrieved from\n\nLongstaff, T. (2010). Cyber science: moving from the toes to the shoulders of giants. In Proceedings of\nthe Sixth Annual Workshop on Cyber Security and Information Intelligence Research, 10. Retrieved from\nhttp://dl.acm.org/citation.cfm?id=1852677\nMa, B., Nahal, S., & Tran, F. (2015). Thematic Investing: Robot Revolution Global Robot & AI Primer. Bank\nof America/Merrill Lynch. Retrieved from https://olui2.fs.ml.com/publish/content/application/pdf/GWMOL/RICReport-January-2016.pdf\nMartin, P. Y., & Turner, B. A. (1986). Grounded theory and organizational research. The journal of applied\nbehavioral science, 22(2), 141-157.\n\n10/12\n\n\fMaxion, R. A., Longstaff, T. A., & McHugh, J. (2010). Why is there no science in cyber science?: a panel discussion\nat NSPW 2010. In Proceedings of the 2010 workshop on New security paradigms, 1–6. ACM. Retrieved from\nhttp://dl.acm.org/citation.cfm?id=1900548\nMcDaniel, P., Rivera, B., & Swami, A. (2014). Toward a science of secure environments. IEEE Security & Privacy,\n12(4), 68-70.\nMüller, V. (2014). Risks of artificial general intelligence. Journal of Experimental and Theoretical Artificial\nIntelligence, 26(3).\nNilsson, N. (2009). The Quest for Artificial Intelligence: A History of Ideas and Achievements, Cambridge:\nCambridge University Press.\nNational Science and Technology Council. (2016). PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE OF ARTIFICIAL INTELLIGENCE. Executive Office of the President.\nNing, H., Li, Q., Wei, D., Liu, H., & Zhu, T. (2017). Cyberlogic Paves the Way From Cyber Philosophy to Cyber\nScience. IEEE Internet of Things Journal, 4(3), 783–790. doi: https://doi.org/10.1109/JIOT.2017.2666798\nOltramari, A., Cranor, L. F., Walls, R. J., & McDaniel, P. D. (2014). Building an Ontology of Cyber Security. In\nSTIDS, 54–61.\nPoli, R. (1996). Ontology for knowledge organization. Advances in Knowledge Organization, 5, 313–319.\nPowers, T. (2006).\nProspects for a Kantian Machine.\ndoi:10.1109/MIS.2006.77\n\nIntelligent Systems, IEEE, 21, 46-51.\n\nRen, F. (2012). A demo for constructing domain ontology from academic papers. Proceedings of COLING 2012:\nDemonstration Papers, 369–376.\nSilver, D., Huang, A., Maddison, C., Guez, A., Sifre, L., van den Driessche, G.,. . . Hassabis, D. (2016). Mastering\nthe game of Go with deep neural networks and tree search. Nature, 529, 484-489.\nSotala, K. & Yampolskiy, R. (2016). Responses to catastrophic AGI risk: a survey. Physics Scripta 90, 1-33.\ndoi:10.1088/0031-8949/90/6/069501\nStone, P., Brooks, R., Brynjolfsson, R., Calo, R., Etzioni, O., Hager, G.,. . . Teller, A. (2016). “Artificial Intelligence\nand Life in 2030: One Hundred Year Study on Artificial Intelligence: Report of the 2015-2016 Study Panel”,\nStanford University. Retrieved from http://ai100.stanford.edu/2016-report\nSubhashini, R. & Akilandeswari, J. (2011). A survey on ontology construction methodologies. International Journal\nof Enterprise Computing and Business Systems, 1(1), 60–72.\nSuddaby, R. (2006). From the editors: What grounded theory is not. Academy of management journal, 49(4),\n633-642.\nSwartout, B., Patil, R., Knight, K., & Russ, T. (1997). Toward Distributed Use of Large-Scale Ontologies.\nSymposium on Ontological Engineering, Association for the Advancement of Artificial Intelligence - AAAI.\nUschold, M., & King, M. (1995). Towards a methodology for building ontologies. Artificial Intelligence Applications\nInstitute, University of Edinburgh. Retrieved from http://www.aiai.ed.ac.uk/project/oplan/documents/1995/95-ontijcai95-ont-method.pdf\nWissner-Gross, A., & Freer, C. (2013). Causal Entropic Forces. Physical Review Letters 110(168702).\nYampolskiy, R. V. (2014). Utility Function Security in Artificially Intelligent Agents. Journal of Experimental and\nTheoretical Artificial Intelligence (JETAI): 1-17.\n\n11/12\n\n\fYampolskiy, R. V. (2016). Taxonomy of Pathways to Dangerous Artificial Intelligence. AAAI Conference on\nArtificial Intelligence AI, Ethics, and Society: Technical Report WS- 16-02.\nYampolskiy, R. V., & Fox, J. (2012). Safety Engineering for Artificial General Intelligence. Springer Institute for\nArtificial Intelligence 32, 217-226. doi:10.1007/s11245-012-9128-9.\nYudkowsky, E. (2008). Artificial Intelligence as a Positive and Negative Factor in Global Risk. In Global Catastrophic\nRisks, ed. Bostrom, N. and Cirkovic, M., New York: Oxford University Press.\n\n12/12\n\n\f",
         "train",
         "36384",
         "5209"
        ],
        [
         "30",
         "19721",
         "cs.AI",
         "Artificial Intelligence",
         "1801.07440v2.pdf",
         "arXiv:1801.07440v2 [cs.AI] 7 Feb 2018\n\nCuriosity-driven reinforcement learning with\nhomeostatic regulation\n\nIldefons Magrans de Abril\nARAYA, Inc.\nTokyo\nildefons@araya.org\n\nRyota Kanai\nARAYA, Inc.\nTokyo\nkanair@araya.org\n\nAbstract\nWe propose a curiosity reward based on information theory principles and consistent with the animal instinct to maintain certain critical parameters within a\nbounded range. Our experimental validation shows the added value of the additional homeostatic drive to enhance the overall information gain of a reinforcement\nlearning agent interacting with a complex environment using continuous actions.\nOur method builds upon two ideas: i) To take advantage of a new Bellman-like\nequation of information gain and ii) to simplify the computation of the local rewards by avoiding the approximation of complex distributions over continuous\nstates and actions.\n\n1\n\nIntroduction\n\nWithin a reinforcement learning setting [Sutton and Barto, 1998], a reward signal indicates a particular\nmomentary positive experience and it serves to constrain the long-term agent behavior. Extrinsic\nrewards are generated by an external oracle and they indicate how well the agent is interacting with\nthe environment (e.g. videogame score, portfolio return). On the other hand, intrinsic rewards are\ngenerated by the agent itself and they indicate a particular internal event sometimes implemented as a\nmetaphor of an animal internal drive [Chentanez et al., 2005].\nThere are many intrinsic rewards and most of them can be characterized by how they affect the\ninformation flow between the environment and the agent. In one side of the spectrum, information is\npushed from the agent to the environment, for instance, by rewarding actions that lead to predictable\nconsecutive sensor readings [Montúfar et al., 2016] or by rewarding reaching states from where the\nagent actions have a large influence in determining the future state (i.e. empowerment [Jung et al.,\n2011, Mohamed and Rezende, 2015]).\nOn the other side, information is encouraged to efficiently move from the environment to the\nagent. These rewards motivate the agent to explore its environment by taking actions leading to\nan improvement of its internal models. Schmidhuber [1991] proposed an online learning agent\nequipped with a curiosity unit measuring the Euclidian distance between the observed state and the\nmodel prediction. Recently, Pathak et al. [2017] extended the curiosity functionality to accommodate\nagents with high dimensional sensory inputs by adding a representation network able to filter out\ninformation from the observed state that is not relevant to predict how the agent actions affect the\nfuture state. [Houthooft et al., 2016] presented an exploration reward bonus based on information\ngain maximization computed using a variational approximation of a Bayesian neural network. Lopes\net al. [2012] discussed an exploration reward bonus that encourages the learning progress over the\nlast few experiences instead of the immediate agent surprise. Bellemare et al. [2016] differ in the\nsense that the agent is not learning a forward model but a probability density function about the states\nCognitively Informed Artificial Intelligence: Insights From Natural Intelligence (NIPS Workshop 2017), Long\nBeach, CA, USA.\n\n\fvisited by the agent together with a lower bound on the information gain associated with the agent\nexploratory behavior.\nA common denominator of all methods is an intrinsic reward function that encourages actions with a\nhigh information gain potential. This behavior is consistent with the innate drive to explore of humans\nand other animals. However, it is probably incomplete because it is not able to accommodate the also\ninnate animal desire to maintain certain critical parameters within a bounded range (i.e. physiological\nconstants) [Carver and Scheier, 1998]. To achieve that goal in an uncertain environment, the animal\nhas to trade its curiosity drive with the need to act according to familiar patterns that guarantee the\nrequired stimuli (e.g. food, water, heat,...).\nIn the following sections we derive our approach from information theory considerations. It extends\nthe typical heterostatic curiosity reward with an additional term. Our novel extension simulates an\nanimal homeostatic drive to keep a \"familiar\" behavior. More precisely, we validate the value of\nregulating a purely heterostatic curiosity reward with an homeostatic drive in the context of an agent\ntrying to learn how its environment responds to its actions. The concept of homeostatic regulation in\nsocial robots was first proposed in [Breazeal, 2004].\n\n2\n\nBackground\n\nThis paper assumes a typical reinforcement learning setup where an agent interacts with the environment at discrete time steps, it observes an state St ∈ S and it acts on the environment with action At\n∈ A according to a control policy π(At |St ), the main goal of an information gain agent is to learn a\nforward model that explains how the environment reacts to its actions.\nRecently, Tiomkin and Tishby [2017] presented a recursive expression to describe the information\ntransferred from a sequence of states to the following sequence of actions when an agent interacts\nopen-endedly with a Markovian environment (i.e. transition probability function ∼ P (St+1 |St , At )).\nFigure 1 shows a conceptual diagram of the information gain process and equation 1 presents the\nrecursive expression for information gain:\n\nFigure 1: Conceptual diagram of the information gain process: dark thin arrows are causal dependencies and large arrows show how information flows from a sequence of observed states to the\ncorresponding future sequence of agent actions.\n\nInf ormationGain(st ) = I(St+1:t+K → At+1:t+K ||St:t+K−1 , At )\n= I(St+1 ; At+1 |St , At)\n+ < I(St+2:t+K → At+2:t+K ||St+1:t+K−1 , At+1 ) >P (St+1 ,At+1 |St ,At ) ,\n\n(1)\n\nwhere I(A → B||C) is the causally conditioned directed mutual information [Kramer, 1998] and\nA/St+1:t+K is the sequence of actions/states of length K starting at time t + 1.\nIt is important for our approach that the definition of information gain can be expressed recursively\nwith a similar decomposition as the Bellman equation, where I(St+1 ; At+1 |St , At) would be the\nagent reward obtained at time t by taking action At at state St and the second component would be the\naverage discounted reward (with discount factor 1). Computing the conditional mutual information of\nthe local reward requires the approximation of the corresponding probability distributions [Mohamed\nand Rezende, 2015, Tiomkin and Tishby, 2017]. When actions and/or states are discrete, we can\napproximate them for instance using a neural network with a softmax output layer. However, it’s\nmuch harder when states and actions are continuous, especially when the state space is very high\ndimensional (e.g. video stream).\nWe propose a more practical method to implement information gain in a reinforcement learning setting\nwhen states and actions are continuous and we show how our approach, derived from information\n2\n\n\ftheory principles, extends the narrow view of existing approaches by compensating the heterostacity\ndrive encouraged by the curiosity reward with an additional homeostatic drive.\n\n3\n\nApproach\n\nOur method builds upon two ideas: i) To take advantage of the Bellman like equation of information\ngain (equation 1) to justify the use of a reinforcement learning algorithm as underlying mechanism to explore the environment; ii) To simplify the computation of the local reward defined as\nI(St+1 ; At+1 |St , At) by avoiding the approximation of complex distributions over continuous states\nand actions.\nWe implemented the first idea using a state of the art RL algorithm that works well with continuous\nactions. We chose the Deep Deterministic Policy Gradient algorithm [Lillicrap et al., 2015] but\nother options are also feasible. This algorithm finds a deterministic control policy that maximize\nthe expected sum of discounted rewards. When γ = 1, episode length is K and reward function is\nI(St+1 ; At+1 |St , At), then our agent explores the environment by maximizing the information gain\nas expressed in equation 1.\nWe can express this reward as the reduction of entropy in the future state St+1 . Then, because we\nare able to know exactly the current state and due to the deterministic nature of the control policy\ninferred by the DDPG algorithm, we use the concrete state st and actions at and at+1 instead of the\nrandom variables St , At and At+1 respectively to compute the reward. Finally, we approximate the\nreduction of entropy in the future state St+1 as the reduction of the prediction error in the future state.\nEquation 2 formalizes this approximation:\nI(St+1 ; At+1 |st , at ) = H(St+1 |St , At ) − H(St+1 |St , At , At+1 )\n≈ H(St+1 |st , at ) − H(St+1 |st , at , at+1 )\n≈ ||st+1 − ŝf ||2 − ||st+1 − ŝk ||2\n\n(2)\n\nwhere ŝf = f (st , π(st ) = at ) and ŝk = k(st , π(st ) = at , π(st+1 ) = at+1 ) are the future state\npredictions by the forward and extended forward models respectively. The extended forward model\ntakes advantage of knowing the action that the agent will take in the future state to improve the\nprediction about this future state. This approximation captures the relevant semantic with much\nlower computational cost. Interestingly, the internal models f (.) and k(.) can be easily implemented\nwith deep neural networks and suit well an agent with high-dimensional input streams. Figure 2 is a\ngraphical representation of the semantic of the new curiosity reward with homeostatic regulation and\nhow it compares with respect to a state of the art curiosity reward based on the Euclidian distance\nbetween the observed state and the model prediction (E.g. [Schmidhuber, 1991, Pathak et al., 2017]).\n\nFigure 2: Semantic of the curiosity reward with homeostatic regulation and comparisson with respect\nto a state of the art curiosity reward based on the Euclidian distance between the observed state and\nthe model prediction (E.g. [Schmidhuber, 1991, Pathak et al., 2017]).\nOur new curiosity reward has two components: 1) Heterostatic motivation: similarly to an state of\nthe art work based on the Euclidean distance, the first component of our reward encourages taking\nactions that lead to large forward model errors. This first component implements the heterostatic\ndrive. In other words, the tendency to push away our agent from its habitual state; 2) Homeostatic\n3\n\n\fmotivation: the second component is our novel contribution. It encourages taking actions at that lead\nto future states st+1 where the corresponding future action at+1 gives us additional information about\nst+1 . This situation happens when the agent is \"familiar\" with the state-action pair: {st+1 , at+1 }.\nTherefore, our new reward encourage the agent to move towards regions of the state-action space that\nsimultaneously deliver large forward model errors and that are \"known/familiar\" to the agent. In other\nwords it implies a priority sampling strategy towards \"hard-to-learn\" regions of the state-action space.\nWe further generalize this reward by adding an hyper-parameter α > 0 that controls the importance\nof the of the homeostatic bonus. Finally, we should note that the reward function is non-stationary\ndue to the continuous learning of f and k. For that reason we z-normalize the reward using a mean\nand standard deviation computed at the end of each of episode using all available samples:\nIGα (st ) − µig\nσig\nIGα (st ) = ||st+1 − ŝf ||2 − α||st+1 − ŝk ||2\nR(st ) =\n\n(3)\n\nAlgorithm 1 summarizes the overall logic of our curiosity agent. It follows an architecture similar to\nPathak et al. [2017]:\nAlgorithm 1: Curiosity-driven reinforcement learning with homeostatic regulation\nResult: Forward model: f (s, a)\nInitialization of f, k, DDP G parameters including π;\nInitialization of random exploration probability \u000f;\nfor episode i do\nInitialize environment: initial state s0 according to experiment strategy (see section 4);\nfor step t do\nGenerate at = π(st ) (random according to \u000f);\nSample st+1 ∼ P (.|st, at);\nGet reward rt according to equation 3;\nAdd {st , at , st+1 , rt } to replay buffer (RB);\nSample mini-batch M B ∼ RB;\nTrain f, k and DDPG networks (including π);\nend\nend\n\n4\n\nResults\n\nOur experimental validation presents two examples where both curiosity and homeostatic drives are\nsuperior to learn a forward model. Our validation hypothesis is that exploring an environment with\nseveral non-linearities could be optimized by regulating the agent curiosity with an homeostatic drive.\nMore precisely, it could help by prioritizing the exploration of the state-action space according to\nhow hard is to learn each region.\nTo test our hypothesis, we use a 3 room environment (40x40), where an agent, able to sense its\nexact position, learns a control policy according to the DDPG algorithm with the reward presented in\nequation 3 and a probability of taking a random action equal to 0.5. The agent starts every episode in\na random state and it runs for 10 steps (with max length step=10). We have implemented the forward\nmodel f and the extended forward model k as feed forward neural networks with 2 hidden layers\nwith 64 hidden units each. We store the agent traces and we train the agent and the internal models at\nthe same time following the same architecture of [Pathak et al., 2017]. Figure 3 shows an scheme of\nour environment.\nIn our first experiment we study the accuracy of the final forward model as a function of α. We\ncheck the prediction accuracy using a pool of 107 randomly generated samples. We run our agent\nusing different values of α ∈ {0, 1, 2, 3, 4, 5, 6, 7} for 150K episodes and we do each experiment 3\ntimes. Figure 4 shows how we can improve the environment sampling efficiency by increasing the\nhomeostatic component of the reward (i.e. α). Figure 5 shows a diagram of the policy learned after\n4\n\n\fFigure 3: Scheme of our 3 room environment.\n10K episodes with α = 0 and α = 7 respectively. We can clearly appreciate that, when α is large,\nthe agent tends to position itself where there are a larger number of non-linearities (i.e. the \"doors\").\nThis agent behavior enhances the learning of complex regions by leveraging a more intense random\nexploration where it is most required. We should also discuss that for this particular experiment, a\npure random sampling strategy achieves a mean square error on the validation set of 0.67 which is\nslightly better than the best result obtained with α = 7 (0.87). However, this is not a fair comparison\nbecause every episode starts in a different position which enables a pure random agent to reach every\nspot of the environment by simply random walking its local surroundings.\nWe performed a second experiment using the same environment described in Figure 3, but in this\ncase the agent starts every episode in a random state of the bottom room. We want to understand\nwhether the homeostatic reward is able to enhance the acquisition of innovative environment samples\nby counting how many times the agent is able to traverse 2 doors and reach the top room. Figure\n6 shows how we can improve the acquisition of challenging environment states by optimizing the\ncontribution of the homeostatic reward component. In this case, a pure random sampling strategy\nrunning for 150K episodes only reach the top room a total average of 145 times which is far below\nany other total average achieved with a non-random strategy with any α.\n\n5\n\nConclusions and future work\n\nWe presented an exploration approach that implements two apparently inconsistent animal drives:\n1) the innate drive to explore (heterostatic behavior) and 2) the desire to maintain certain critical\nparameters stable. We derive an intrinsic reward function from information theory principles that\ngeneralize an state of the art method and we present experimental results to validate the superior exploration behavior of a join homeostatic and heterostatic drive with respect to a pure curiosity/heterostic\napproach. In future work, we want to explore meta-learning strategies to dynamically adjust the\ncontribution of the homeostatic drive (i.e. α) as well as the percentage of random exploration as a\nfunction of the agent progress in learning a the forward model.\n\n5\n\n\fFigure 4: Accuracy of the forward model learned by the agent as a function of α (measured according\nto the mean square error on the validation set).\n\nFigure 5: Flow diagram of the control policy learned after 10K episodes with α = 0 (left) and α = 7\n(right) respectively.\n\nAcknowledgments\nThis work was supported by JST CREST Grant Number JPMJCR15E2, Japan.\n6\n\n\fFigure 6: Total number of times that the agent is able to reach the top room as a function of α when it\nstarts every episode in a random position of the bottom room.\n\nReferences\nMarc Bellemare, Sriram Srinivasan, Georg Ostrovski, Tom Schaul, David Saxton, and Remi Munos.\nUnifying count-based exploration and intrinsic motivation. In Advances in Neural Information\nProcessing Systems, pages 1471–1479, 2016.\nCynthia L Breazeal. Designing sociable robots. MIT press, 2004.\nCharles S Carver and Michael F Scheier.\nCBO9781139174794, 1998.\n\nOn the self-regulation of behavior. 10.1017.\n\nNuttapong Chentanez, Andrew G Barto, and Satinder P Singh. Intrinsically motivated reinforcement\nlearning. In Advances in neural information processing systems, pages 1281–1288, 2005.\nRein Houthooft, Xi Chen, Yan Duan, John Schulman, Filip De Turck, and Pieter Abbeel. Vime:\nVariational information maximizing exploration. In Advances in Neural Information Processing\nSystems, pages 1109–1117, 2016.\nTobias Jung, Daniel Polani, and Peter Stone. Empowerment for continuous agent—environment\nsystems. Adaptive Behavior, 19(1):16–39, 2011.\nGerhard Kramer. Directed information for channels with feedback. PhD thesis, Eidgenossiche\nTechnische Hochschule Zurich, 1998.\n7\n\n\fTimothy P Lillicrap, Jonathan J Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa,\nDavid Silver, and Daan Wierstra. Continuous control with deep reinforcement learning. arXiv\npreprint arXiv:1509.02971, 2015.\nManuel Lopes, Tobias Lang, Marc Toussaint, and Pierre-Yves Oudeyer. Exploration in modelbased reinforcement learning by empirically estimating learning progress. In Advances in Neural\nInformation Processing Systems, pages 206–214, 2012.\nShakir Mohamed and Danilo Jimenez Rezende. Variational information maximisation for intrinsically\nmotivated reinforcement learning. In Advances in neural information processing systems, pages\n2125–2133, 2015.\nGuido Montúfar, Keyan Ghazi-Zahedi, and Nihat Ay. Information theoretically aided reinforcement\nlearning for embodied agents. arXiv preprint arXiv:1605.09735, 2016.\nDeepak Pathak, Pulkit Agrawal, Alexei A Efros, and Trevor Darrell. Curiosity-driven exploration by\nself-supervised prediction. arXiv preprint arXiv:1705.05363, 2017.\nJűrgen Schmidhuber. A possibility for implementing curiosity and boredom in model-building neural\ncontrollers. In From animals to animats: proceedings of the first international conference on\nsimulation of adaptive behavior (SAB90), 1991.\nRichard S Sutton and Andrew G Barto. Reinforcement learning: An introduction, volume 1. MIT\npress Cambridge, 1998.\nStas Tiomkin and Naftali Tishby. A unified bellman equation for causal information and value in\nmarkov decision processes. arXiv preprint arXiv:1703.01585, 2017.\n\n8\n\n\f",
         "train",
         "19420",
         "3065"
        ],
        [
         "31",
         "17751",
         "cs.AI",
         "Artificial Intelligence",
         "1712.03890v1.pdf",
         "DeepConf: Automating Data Center Network\nTopologies Management with Machine Learning\n\narXiv:1712.03890v1 [cs.NI] 11 Dec 2017\n\nChristopher Streiffer∗ , Huan Chen∗† , Theophilus Benson+ , Asim Kadav‡\nDuke University∗ UESTC, China† Brown University+ NEC Labs‡\n\nABSTRACT\nIn recent years, many techniques have been developed\nto improve the performance and efficiency of data center networks. While these techniques provide high accuracy, they are often designed using heuristics that leverage domain-specific properties of the workload or hardware.\nIn this vision paper, we argue that many data center\nnetworking techniques, e.g., routing, topology augmentation, energy savings, with diverse goals actually share\ndesign and architectural similarity. We present a design\nfor developing general intermediate representations of\nnetwork topologies using deep learning that is amenable\nto solving classes of data center problems. We develop\na framework, DeepConf, that simplifies the processing\nof configuring and training deep learning agents that\nuse the intermediate representation to learns different\ntasks. To illustrate the strength of our approach, we configured, implemented, and evaluated a DeepConf-agent\nthat tackles the data center topology augmentation problem. Our initial results are promising — DeepConf performs comparably to the optimal.\n\n1.\n\nINTRODUCTION\n\nData center networks (DCN) are a crucial and important part of the Internet’s ecosystem. The performance\nof these DCNs impact a wide variety of services from\nweb browsing and videos to Internet of Things. The\npoor performance of these DCNs can result in as much\nas $4 million in lost revenue [1].\nMotivated by the importance of these networks, the\nnetworking community has explored techniques for improving and managing the performance of the data center network topology by: (1) designing better routing or\ntraffic engineering algorithms [6, 8, 13, 10], (2) improving performance of a fixed topology by adding a limited\nnumber of flexible links [33, 11, 17, 16], and (3) removing corrupted and underutilized links from the topology\nto save energy and improve performance [18, 14, 35].\nRegardless of the approach, these topology-oriented\ntechniques have three things in common: (1) Each is\n\nformalized as an optimization problem. (2) Due to the\nimpracticality of scalably solving these optimizations,\ngreedy heuristics are employed to create approximate\nsolutions. (3) Each heuristic is intricately tied to the application patterns and does not generalize across novel\npatterns. Existing domain-specific heuristics provide suboptimal performance and are often limited to specific\nscenarios. Thus as a community, we are forced to revisit\nand redesign these heuristics when the application pattern or network details changes – even a minor change.\nFor example, while c-through [33] and FireFly [17] solve\nbroadly identical problems, they leverage different heuristics to account for low-level differences.\nIn this paper, we articulate our vision for replacing\ndomain-specific rule-based heuristics for topology management with a more general machine learning-based\n(ML) model that quickly learns optimal solutions to a\nclass of problems while adapting to changes in the application patterns, network dynamics, and low-level network details. Unlike recent attempts that employ ML\nto learn point solutions, e.g., cluster scheduling [23] or\nrouting [9], in this paper, we present a general framework, called DeepConf, that simplifies the process of\ndesigning ML models for a broad range of DCN topology problems and eliminates the challenges associated\nwith efficiently training new models.\nThe key challenges in designing DeepConf are: (1)\ntackling the dichotomy that exists between deep learning’s requirements for large amounts of supervised data\nand the unavailability of these required datasets, and (2)\ndesigning a general, but highly accurate, deep learning\nmodel that efficiently generalizes to learning a broad array of data center problems ranging from topology management and routing to energy savings.\nThe key insight underlying DeepConf is that intermediate features generated from the parallel convolutional\nlayers using network data, e.g., traffic matrix, allows us\nto generate an intermediate representation of the network’s state that enables learning a broad range of data\ncenter problems. Moreover, while labeled production\ndata crucial for machine learning is unavailable, empir-\n\n\fical studies [21] show that modern data center traffic is\nhigly predictable and thus amenable to offline learning\nwith network simulators and historical traces.\nDeepConf builds on this insight by using reinforcement learning (RL), an unsupervised technique, that learns\nthrough experience and makes no assumptions on how\nthe network works. Rather, they are trained through the\nuse of a reward signal which “guides” them towards an\noptimal solution and thus do not require real world data,\nand, instead, they can be trained using simulators.\nThe DeepConf framework provides a predefined RL\nmodel with the intermediate representation, a specific\ndesign for configuring this model to address different\nproblems, an optimized simulator to enable efficient learning, and an SDN-based platform for capturing network\ndata and reconfiguring the network.\nIn this paper, we make the following contributions:\n• We present a novel RL-based SDN architecture for\ndeveloping and training deep ML models for a broad\nrange of DCN tasks.\n• We design a novel input feature extraction for DCNs\nfor developing different ML models over this intermediate representation of network state.\n• We implemented a DeepConf-agent tackling the topology augmentation problem and evaluated it on representative topologies [15, 4] and traces [3], showing\nthat our approach performs comparable to optimal.\n\n2.\n\nRELATED WORK\n\nOur work is motivated by the recent success of applying machine learning and RL algorithms to computer\ngames and robotic planning [25, 31, 32]. The most\nclosely related work [9] applies RL to packet routing.\nUnlike [9], DeepConf tackles the topology augmentation problem and explores the use of deep networks as\nfunction approximators for RL. Existing applications of\nmachine learning to data centers focus on improving\ncluster scheduling [23] and more recently by Google to\noptimize Power Usage Effectiveness(PUE) [2]. In this\nvision paper, we take a different stance and focus on\nidentifying a class of equivalent data center management\noperations, namely topology management and configuration, that are amenable to a common machine learning\napproach and design a modular system that enables different agents to interoperate over a network.\n\n3.\n\nBACKGROUND\n\nThis section provides an overview of data center networking challenges and solutions and provides background on our reinforcement learning methods.\n\nEthernet\nFabric\n\nOptical Circuit\nOptical Switch\n\nFigure 1: One optical switch with k=4 Fat Tree Topology.\n\n3.1\n\nData Center Networks\n\nData center networks introduce a range of challenges\nfrom topology design and routing algorithms to VM placement and energy saving techniques.\nData centers support a large variety of workloads and\napplications with time-varying bandwidth requirements.\nThis variance in bandwidth requirements leads to hotspots\nat varying locations and at different points in time. To\nsupport these arbitrary bandwidth requirements, data center operators can employ non-blocking topologies; however, non-blocking topologies are prohibitively costly.\nInstead, these operators employ a range of techniques\nranging from hybrid architectures [33, 11, 17, 16], traffic engineering algorithms [6, 8, 13, 10], and energy\nsaving techniques [18, 28]. Below, we describe these\ntechniques and illustrate common designs.\nAugmented Architectures: This class of approaches\nbuild on the intuition that at any given point in time,\nthere are only a small number of hotspots (or congested\nlinks). Thus, there is no need to build an expensive\ntopology that supports full bisection (eliminating all potential points of congestion). Instead, the existing topology can be augmented with a small number of links\nwhich can be added ondemand and moved to the location of the hotspot or congested links. These approaches\naugment the data center’s ethernet network with a small\nnumber of optical [33, 11], wireless [16], or free optics [17]. 1 For example, Figure 1 shows a traditional\nFat-Tree topology augmented with an optical switch –\nas was proposed by Helios [11].\nThese proposals argue for monitoring the traffic, using\nan Integer Linear Program (ILP) or heuristic to detect\nthe hotspots and place the flexible links at the location\nwith these hotspots. Unfortunately, moving these flexible links incurs a large switching time during which the\nlinks are not operational. These intelligent and efficient\nalgorithms are developed to effectively detect hotspots\nand efficiently place links.\nTraffic Engineering: Orthogonal approaches [6, 8, 13,\n10] focus on routing. Instead of changing the topologies,\nthese approaches change the mapping of flows to paths\nwithin a fixed topology. These proposals, also, argue\nfor monitoring traffic and detecting hotspots. Instead of\nchanging topologies, these techniques move a subset of\n1\n\nThe number of augmented links is significantly smaller than\nthe number of data center’s permanent links.\n\n\fflows from congested links to un-congested links.\nEnergy Savings Data centers are notorious for their energy usage [14]. To address this, researchers have proposed techniques to improve energy efficiency by detecting periods of low utilization and selectively turning\noff links [18, 28]. These proposals argue for monitoring traffic, detecting low utilization, and powering-down\nlinks in portions of the data center with low utilizations.\nA key challenge with these techniques is to turn on the\npowered-down links before demands rise.\nTaking a step back, these techniques roughly follow\nthe same design and operate in three steps (1) gather\nnetwork traffic matrix, (2) run an ILP to predict heavy\n(or low) usage, and (3) perform a specific action on a\nsubset of the network. The actions range from augmenting flexible links, turning off links, or moving traffic. In\nall situations, the ILP does not scale to a large network\nand a domain-specific heuristic is often used in its place.\n\n3.2\n\nReinforcement Learning\n\nReinforcement learning (RL) algorithms learn through\nexperience with a goal towards maximizing rewards. Unlike supervised learning where algorithms train over labels, RL algorithms learn by interacting with an environment such as a game or a network simulator.\nIn traditional RL, an agent interacts with an environment over a number of discrete time steps. Hence, at\neach time step t, the agent in a world observes a state st\nin order to select an action at from a possible action set\nA. The agent is guided by a policy, π, which is a function that maps state st to actions at . The agent receives\na reward rt for each action and transitions to the next\nstate st+1 . The goal of the agent is maximizing the total\nreward. This process continues until the agent reaches a\nfinal state or time limit, after which the environment is\nreset and a new training episode is played. After a number of training episodes, the agent learns to pick actions\nthat maximize the rewards and can learn to handle unexpected states. RL is effective and has been successfully\nused to model robotics, game bots, etc.\nThe goal of commonly used policy-based RL is to\nfind a policy, π, that maximizes the cumulative reward\nand converges to a theoretical optimal policy. In deep\npolicy-based methods, a neural network computes a policy distribution π(at |st ; θ), where θ represents the set of\nparameters of the function. Deep networks as function\napproximators is a recent development and other learning methods can be used. We now describe the REINFORCE and actor-critic policy methods which represent different methods to score the policy J(θ). REINFORCE methods\nuse gradient ascent on E[Rt ],\nP∞ [34]\ni\nwhere Rt =\ni=0 γ rt+i is the accumulated reward\nstarting from time step t and discounted at each step\n\nby γ ∈ (0, 1], the discount factor. The REINFORCE\nmethod, which is the Monte-Carlo method, updates θ\nusing the gradient ∇θ log π(at |st ; θ)Rt , which is an unbiased estimator of ∇θ E[Rt ]. The value function is\ncomputed as V π (st ) = E[Rt |st ] which is the expected\nreturn for following the policy π in state st . This method\nprovides actions with high returns but suffers from highvariance of gradient estimates.\nAsynchronous Advantage Actor Critic (A3C): A3C [24]\nimproves REINFORCE performance by operating asynchronously and by using a deep network to approximate\nthe policy and value faction. A3C uses the actor-critic\nmethod which additionally computes a critic function\nthat approximates the value function. A3C, as used by\nus, uses a network with two convolutional layers followed by a fully connected layer. Each hidden layer\nis followed by a nonlinearity function (ReLU). A softmax layer which approximates the policy function and\na linear layer to output an estimate of the value function\nV (st ; θ) together constitute the output of this network.\nAsynchronous gradient descent using multiple agents is\nused to train the network and this improves the training\nspeed. A central server (similar to a parameter server)\ncoordinates the parallel agents – each agent calculates\nthe gradients and sends the updates to the server after a\nfixed number of steps, or when a final state is reached.\nFurthermore, following each update, the central server\npropagates new weights to the agents to achieve a consensus on the policy values. There is a cost function with\neach deep network (policy and value). Using two loss\nfunctions has found to improve convergence and produce better-regularized models. The policy cost function is given as:\nfπ (θ) = log π (at |st ; θ) (Rt − V (st ; θt ))+βH (π (st ; θ))\n(3.1)\nwhere θt represents the values of the parameters θ at\nPk−1\ntime t, Rt = i=0 γ i rt+i + γ k V (st+k ; θt ) is the estimated discounted reward.H (π (st ; θ)) is used to favor\nexploration and its strength is controlled by the factor β.\nThe cost function for the estimated value\nfunction is:\n2\nfv (θ) = (Rt − V (st ; θ))\n(3.2)\nAdditionally, we augment our A3C model to learn\ncurrent states apart from accumulating rewards for good\nconfigurations using GAE [30]. The deep network, that\nreplaces the transition matrix as the function approximator learns the value of the given state and the policy\nof the given state. The model uses GAE to compute the\nvalue of a given state that not only returns the reward\nfor the model for the given policy decision but also rewards the model for estimating the value of the state.\nThis helps to guide the model to learn the states instead\nof just maximizing rewards.\n\n4.\n\nVISION\n\n\fTraining\nHarness\n\nNetwork\nSimulator\n\nDeepConf\nAgent\n\nDeepConf\nDeepConf\n……\nAgent\nAgent\n\nDeepConf Abstraction Layer\nSDN Controller\n\n……\nNetwork Topology\n\nFigure 2: DeepConf Architecture\nOur vision is to automate a subset of data center management and operational tasks by leveraging DeepRL.\nAt a high-level, we anticipate the existence of several\nDeepRL agents, each trained for a specific set of tasks\ne.g. traffic-engineering, energy-savings, or topologyaugmentations. Each agent will run as an application\natop an SDN controller. The use of SDN provides the\nagents with an interface for gathering their required network state and a mechanism for enforcing their actions.\nFor example, DeepConf should be able to assemble the\ntraffic matrix by polling the different devices within the\nnetwork, compute a decision for how the optical switch\nshould be configured to best accommodate the current\nnetwork load, and reconfigure the network.\nAt a high-level, DeepConf’s architecture consists of\nthree components (Figure 2): the network simulator to\nenable offline training of the DeepRL agents, the DeepConf abstraction layer to facilitate communication between the DeepRL agents and the network, and the DeepRL\nagents, called DeepConf-agents, which encapsulate data\ncenter functionality.\nApplying learning: The primary challenges in applying\nmachine learning to network problems are (1) the deficiency of training data pertaining to operator and network behavior and (2) the lack of models and loss functions that can accurately model the problem and generalize to unexpected situations. This shortage presents\na roadblock for using supervised-based approaches for\ntraining ML models. To address this issue, DeepConf\nuses RL where the model is trained by exploring different network states and environments generated by the\nsurplus of simulators available in the network community. Coupled with the wide availability of network job\ntraces, this allows for DeepConf to learn a highly generalizable policy.\nDeepConf Abstraction Layer: Today’s SDN controllers\nexpose a primitive interface with low-level information.\nThe DeepConf applications will instead require highlevel models and interfaces. For example, our agents\nwill require interfaces that provide control over paths\nrather than over flow table entries. While emerging approaches [19] argue for similar interfaces, these approaches\ndo not provide a sufficiently rich set of interfaces for\n\nthe broad range of agents we expect to support and do\nnot provide composition primitives for safely combining the output from the different agents. Moreover, existing composition operators [27, 20, 12] assume that\nthe different SDN applications (or DeepConf-agent in\nour case) are generating non-conflicting actions – hence\nthese operators can not tackling conflict actions. SDN\nComposition approaches [29, 7, 26] that do tackle conflicting actions, require significant rewrite of the SDNApp which we are unable to do because DeepConfagent are rewritten within the DeepRL paradigm.\nMore concretely, we require high-layer SDN abstractions that enable to RLAgents to more easily learn and\nact of the network. Additionally, we require novel composition operators that can reason about and tackle conflicting actions generated by RLAgents.\nDomain-specific Simulators: (Low hanging fruit) Existing SDN research leverages a popular emulation platform, Mininet, which fails to scale to large experiments.\nA key requirement for employing DeepRL is to have efficient and scalable simulators that replays traces and\nenables learning from these traces. We extend flowbased simulators to model the various dimensions that\nare required to train our models. To improve efficiency,\nwe explore techniques that partition the simulation and\nenables reuse of results — in essence, to enable incremental simulations.\nIn addressing our high-level vision and developing solutions to the above challenges, there are several highlevel goals that a production-scale system must address:\n(1) our techniques must generalize across topologies,\ntraffic matrixes, and a range of operational settings, e.g.,\nlink failures; (2) our techniques must be as accurate and\nefficient as existing state-of-the-art techniques; and (3)\nour solutions must incur low operational overheads, e.g.,\nminimizing optical switching time or TCAM utilization.\n\n5.\n\nDESIGN\n\nIn this section, we provide a broad description of how\nto define and structure existing data center network management techniques as RL tasks, then describe the methods for training the resulting DeepConf-agents.\n\n5.1\n\nDeepConf Agents\n\nIn defining each new DeepConf-agent, there are four\nmain functions that a developer must specify: state space,\naction space, learning model, and reward function. The\naction space and reward are both specific to the management task being performed and are, in turn, unique\nto the agent. Respectively, they express the set of actions\nan agent can take during each step and the reward for the\nactions taken. The state space and learning models are\n\n\fmore general and can be shared and reused across different DeepConf-agents. This is because of the fundamental similarities shared between the data center management problems, and because the agents are specifically\ndesigned for data centers.\nIn defining a DeepConf agent for the topology augmentation problem, we (1) define state-spaces specific\nto the topology, (2) design a reward function based on\napplication level metrics, and (3) define actions that correlate to activating/de-activating links.\nState Space: In general, the state space consists of two\ntypes of data – each reflecting the state of the network\nat a given point in time. First, the general network state\nthat all DeepConf-agents require: the network’s traffic\nmatrix (TM) which contains information on the flows\nwhich will executed during the last t seconds of the simulation.\nSecond, a DeepConf-agent specific state-space that\ncaptures the impact of the actions on the network. For\nexample, for the topology augmentation problem, this\nwould be the network topology – note, the actions change\nthe topology. Whereas for the traffic engineering problem, this would be a mapping of flows to paths – note,\nthe actions change a flow’s routes.\nLearning Model: Our learning model utilizes a Convolutional Neural Network (CNN) to compute policy decisions.\nThe exact model for a DeepConf-agent depends on\nthe number of state-spaces used as input. In general, the\nmodel will have as many CNN-blocks as there are state\nspaces – one CNN-block for each state space. The output of these blocks are concatenated together and input\ninto two fully connected layers, followed by a softmax\noutput layer. For example, for the topology-augmentation\nproblem, as observed in Figure 4, our DeepConf-agent\nhas two CNN blocks to operate on both the topology\nand the TM states spaces in parallel. This allows for the\nlower CNN layers to perform feature extraction on the\ninput spatial data, and for the fully connected layers to\nassemble these features in a meaningful way.\n\n5.2\n\nNetwork Training\n\nTo train a DeepConf-agent, we run the agent against\na network simulator. The interaction between the simulator (described in Section 7) and RL agent can be described as follows (Figure 3): (1) The DeepConf agent\nreceives state si from the simulator at training step i.\n(2) The DeepConf-agent uses the state information to\nmake a policy decision about the network, and returns\nthe selected actions to the simulator. For the DeepConfagent for the topology augmentation problem, called the\nAugmentation-Agent, the actions are the links to activate and hence a new topology. (3) If the topology\n\n(5) Get reward\n\nSimulator\nFlows\n\nNetwork\nTopology\n\n(4) Update\nroute\n\n(3)\nAdd links\n\nControl\nInterface\n\n(1)\nRead state\n\nDeepConf\nAgent\n\n(2)\nDecision\n\nFigure 3: DeepConf-agent model training.\nchanges, the simulator re-computes the paths for the active flows. (4) The simulator executes the flows for t seconds. (5) The simulator returns the reward ri and state\nsi+1 to the DeepConf-agent, and the process restarts.\nInitialization During the initial training phase, we force\nthe model to explore the environment by randomizing\nthe selection process — the probability that an action is\npicked corresponds to the value of the index which represents the action. For instance, with the AugmentationAgent, link i has probability wi of being selected. As\nthe model becomes more familiar with the states and\ncorresponding values, the model will better formulate\nits policy decision. At this point, the model will associate a higher probability with the links it believes to\nhave a higher reward, which will cause these links to be\nselected at a higher frequency. This methodology allows\nfor the model to reinforce its decisions about links, while\nthe randomization helps the model avoid local-minima.\nLearning Optimization: To improve the efficiency\nof learning, the RL agent maintains a log containing the\nstate, policy decision, and corresponding reward. The\nRL agent performs experience replay after n simulation steps. During replay, the log is unrolled to compute the policy loss across the specified number of steps\nusing Equation 3.1. The agent is trained using Adam\nstochastic optimization [22], with an initial learning rate\nof 10−4 and a learning rate decay factor of 0.95. We\nfound that a smaller learning rate and low decay helped\nthe model better explore the environment and form a\nmore optimal policy.\n\n6.\n\nUSE CASE: AUGMENTATION AGENT\n\nMore formally defined, in the topology augmentation\nproblem the data center consists of a fixed hierarchical\ntopology and an optical switch, which connects all the\ntop-of-rack switches. While the optical switch is physically connected to all ToR switches, unfortunately, the\noptical switch can only support a limited number of active links. Given this limitation, the rules for the topology problem are defined as:\n• The model must select n links to activate at a given\nstep during the simulation.\n• The model receives a reward based on the link utilization and the flow duration.\n\n\f12\n\nDeepConf\n\nOptimal\n\nFlow Completion Time (s)\n\n10\n\n• All flows are routed using equal-cost multi-path\nrouting (ECMP).\nState Space: The agent specific state space is the network topology, which is represented by a sparse matrix\nwhere entries within the cells correspond to active links\nwithin the network.\nAction Space: The RL agent interacts with the environment by adding links between edge switches. The action space for the model, therefore, corresponds to the\ndifferent possible link combinations and is represented\nas an n dimensional vector. The values within the vector correspond to a probability distribution, where wi is\nequal to the probability of link i being the optimal pick\nfor the given input state s. The model selects the highest\nn values from this distribution as the links that should be\nadded to the network topology.\nReward: The goal of the model can be summarized as:\n(1) Maximize link utilization and (ii) Minimize the average flow-completion time.\nWith this in mind, we formulate our reward function\nas:\nX X bf\n(6.1)\nR(Θ, s, i) =\ntf\n\n6\n4\n2\n0\n\nFigure 4: The CNN model utilized by the RL agent.\n• The model collects the reward on a per-link basis\nafter t seconds of simulation.\n\n8\n\nFatTree\n\nTopology\n\nVL2\n\nFigure 5: Median Flow Completion Time.\nsimulator using a large scale map-reduce traces from\nFacebook [3].\nWe evaluate two state-of-the-art clos-style data center\ntopologies: K=4 Fat-tree [5] and VL2 [15]. In our analysis, we focus on flow completion time (FCT) a metric\nwhich captures the duration between the first and last\npacket of a flow. We augment both topologies by adding\nan optical switch with four links. Here we compare\nDeepConf against the optimal solution derived from a\nlinear program — Note: this optimal solution can not be\nsolved with larger topologies [8].\nLearning Results: The training results demonstrate\nthat the RL agent learns to optimize its policy decision to\nincrease the total reward received across each episode.\nWe observed that the loss decreases as training increases, with the largest decrease occurs during the initial training episodes, a result consistent with the learning rate decay factor employed during training.\nPerformance Results: The results, Figure 5, show that\nDeepConf performs comparable with optimal [33, 11]\nacross representative topologies and workloads. Thus,\nour system is able to learn a solution that’s close to the\noptimal across a range of topologies.\nTakeaway We believe these initial results are promising, and that more work is required in order to understand and improve the performance of DeepConf.\n\nf ∈F l∈f\n\nWhere F represents all active and completed flows during the previous iteration step, l represents the links used\nby flow f , bf represents the number of bytes transferred\nduring the step time, and tf represents the total duration of the flow. The purpose of this reward function is\nto reward for high link utilization but penalize for long\nlasting flows. The design of this function has the effect\nof guiding the model towards completing large flows\nwithin a smaller period of time.\n\n7.\n\nEVALUATION\n\nIn this section, we analyze DeepConf under realistic\nworkload with representative topologies.\nExperiment Setup\nWe evaluate DeepConf on a trace driven flow-level\n\n8.\n\nDISCUSSION\n\nWe now discuss open questions:\nLearning to generalize: In order to avoid over-fitting\nto a specific topology, we train our agent over a large\nnumber of simulator configurations. DeepRL agents need\nto be trained and evaluated on many different platforms\nto avoid being overtly specific to few networks and correctly handle unexpected scenarios. Solutions that employ machine learning to address network problems using simulators need to be cognizant of these issues when\ndeciding the training data.\nLearning new reward functions: DeepRL methods\nneed appropriate reward functions to ensure that they\noptimize for the correct goals. For some networks problems like topology configuration this may be straightforward. However, other problems like routing may require a weighted combination of network parameters\n\n\fthat need to be correctly designed for the agent to operate the network correctly.\nLearning other data center problems. In this paper, we focused on problems that center around learning\nto adjust the topology and routing. Yet, the space of\ndata center problems is much larger. As part of ongoing\nwork, we are investigating intermediate representations\nand models for capturing high-level tasks.\n\nMicro load balancing in data centers with drill. In Proceedings\nof ACM HotNets 2015.\n[14] A. Greenberg, J. Hamilton, D. A. Maltz, and P. Patel. The cost\nof a cloud: Research problems in data center networks.\nSIGCOMM Comput. Commun. Rev., 39(1):68–73, Dec. 2008.\n[15] A. Greenberg, J. R. Hamilton, N. Jain, S. Kandula, C. Kim,\nP. Lahiri, D. A. Maltz, P. Patel, and S. Sengupta. Vl2: A\nscalable and flexible data center network. In Proceedings of\nACM SIGCOMM 2009.\n[16] D. Halperin, S. Kandula, J. Padhye, P. Bahl, and D. Wetherall.\nAugmenting data center networks with multi-gigabit wireless\nlinks. In Proceedings of ACM SIGCOMM 2011.\n9. CONCLUSION\n[17] N. Hamedazimi, Z. Qazi, H. Gupta, V. Sekar, S. R. Das, J. P.\nLongtin, H. Shah, and A. Tanwer. Firefly: A reconfigurable\nOur high level goal, is to develop ML-based systems\nwireless data center fabric using free-space optics. In\nthat replace existing heuristic-based approach to tackProceedings of ACM SIGCOMM 2014.\n[18] B. Heller, S. Seetharaman, P. Mahadevan, Y. Yiakoumis,\nling data center networking challenges. This shift from\nP. Sharma, S. Banerjee, and N. McKeown. Elastictree: Saving\nheuristics to ML, will enable us to design solutions that\nenergy in data center networks. In Proceedings of USENIX\ncan adapt to changes in patterns by consumting data and\nNSDI 2010.\nrelearning – an automated task. In this paper, we take\n[19] V. Heorhiadi, M. K. Reiter, and V. Sekar. Simplifying\nsoftware-defined network optimization using sol. In\nthe first steps towards acheving these goals by designProceedings of USENIX NSDI 2016.\ning a reinforcement learning based framework, called\n[20] X. Jin, J. Gossels, J. Rexford, and D. Walker. Covisor: A\nDeepConf, for automatically learning and implementing\ncompositional hypervisor for software-defined networks. In\nProceedings of the 12th USENIX Conference on Networked\na range of data center networking techniques.\nSystems Design and Implementation, NSDI’15, pages 87–101,\nBerkeley, CA, USA, 2015. USENIX Association.\n10. REFERENCES\n[21] S. A. Jyothi, C. Curino, I. Menache, S. M. Narayanamurthy,\nA. Tumanov, J. Yaniv, R. Mavlyutov, I. Goiri, S. Krishnan,\n[1] Amazon found every 100ms of latency cost them 1% in sales.\nJ. Kulkarni, and S. Rao. Morpheus: Towards automated slos for\nhttps://blog.gigaspaces.com/\nenterprise clusters. In 12th USENIX Symposium on Operating\namazon-found-every-100ms-of-latency-cost-them-1-in-sales/.\nSystems Design and Implementation (OSDI 16), pages\n117–134, GA, 2016. USENIX Association.\n[2] DeepMind AI Reduces Google Data Centre Cooling Bill by\n40%. https://deepmind.com/blog/\n[22] D. P. Kingma and J. Ba. Adam: A method for stochastic\ndeepmind-ai-reduces-google-data-centre-cooling-bill-40/.\noptimization. CoRR, abs/1412.6980, 2014.\n[3] Statistical Workload Injector for MapReduce . https:\n[23] H. Mao, M. Alizadeh, I. Menache, and S. Kandula. Resource\n//github.com/SWIMProjectUCB/SWIM/wiki.\nmanagement with deep reinforcement learning. In Proceedings\nof the 15th ACM Workshop on Hot Topics in Networks, pages\n[4] M. Al-Fares, A. Loukissas, and A. Vahdat. A scalable,\n50–56. ACM, 2016.\ncommodity data center network architecture. In Proceedings of\nACM SIGCOMM 2008.\n[24] V. Mnih, A. P. Badia, M. Mirza, A. Graves, T. P. Lillicrap,\nT. Harley, D. Silver, and K. Kavukcuoglu. Asynchronous\n[5] M. Al-Fares, A. Loukissas, and A. Vahdat. A scalable,\nmethods for deep reinforcement learning. In International\ncommodity data center network architecture. In Proceedings of\nConference on Machine Learning, 2016.\nACM SIGCOMM 2008.\n[25] V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou,\n[6] M. Al-Fares, S. Radhakrishnan, B. Raghavan, N. Huang, and\nD. Wierstra, and M. Riedmiller. Playing atari with deep\nA. Vahdat. Hedera: Dynamic flow scheduling for data center\nreinforcement learning. arXiv preprint arXiv:1312.5602, 2013.\nnetworks. In Proceedings of USENIX NSDI 2010.\n[26] J. C. Mogul, A. AuYoung, S. Banerjee, L. Popa, J. Lee,\n[7] A. AuYoung, Y. Ma, S. Banerjee, J. Lee, P. Sharma, Y. Turner,\nJ. Mudigonda, P. Sharma, and Y. Turner. Corybantic: Towards\nC. Liang, and J. C. Mogul. Democratic resolution of resource\nthe modular composition of sdn control programs. In HotNets,\nconflicts between sdn control programs. In CoNext, 2014.\n2013.\n[8] T. Benson, A. An, A. Akella, and M. Zhang. Microte: The case\n[27] C. Monsanto, N. Foster, R. Harrison, and D. Walker. A\nfor fine-grained traffic engineering in data centers. In\ncompiler and run-time system for network programming\nProceedings of ACM CoNEXT 2011.\nlanguages. In Proceedings of ACM POPL 2012.\n[9] J. A. Boyan, M. L. Littman, et al. Packet routing in dynamically\n[28] S. Nedevschi, L. Popa, G. Iannaccone, S. Ratnasamy, and\nchanging networks: A reinforcement learning approach.\nD. Wetherall. Reducing network energy consumption via\nAdvances in neural information processing systems, pages\nsleeping and rate-adaptation. In Proceedings of the 5th USENIX\n671–671, 1994.\nSymposium on Networked Systems Design and Implementation,\n[10] A. Das, C. Lumezanu, Y. Zhang, V. K. Singh, G. Jiang, and\nNSDI’08, pages 323–336, Berkeley, CA, USA, 2008. USENIX\nC. Yu. Transparent and flexible network management for big\nAssociation.\ndata processing in the cloud. In Proceedings of ACM HotCloud\n[29] S. Prabhu, M. Dong, T. Meng, P. B. Godfrey, and M. Caesar.\n2013.\nLet me rephrase that: Transparent optimization in sdns. In\n[11] N. Farrington, G. Porter, S. Radhakrishnan, H. H. Bazzaz,\nProceedings of ACM SOSR 2017.\nV. Subramanya, Y. Fainman, G. Papen, and A. Vahdat. Helios:\n[30] J. Schulman, P. Moritz, S. Levine, M. Jordan, and P. Abbeel.\nA hybrid electrical/optical switch architecture for modular data\nHigh-dimensional continuous control using generalized\ncenters. In Proceedings of ACM SIGCOMM 2010.\nadvantage estimation. arXiv preprint arXiv:1506.02438, 2015.\n[12] N. Foster, R. Harrison, M. J. Freedman, C. Monsanto,\n[31] D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. Van\nJ. Rexford, A. Story, and D. Walker. Frenetic: A network\nDen Driessche, J. Schrittwieser, I. Antonoglou,\nprogramming language. SIGPLAN Not., 46(9):279–291, Sept.\nV. Panneershelvam, M. Lanctot, et al. Mastering the game of go\n2011.\nwith deep neural networks and tree search. Nature,\n[13] S. Ghorbani, B. Godfrey, Y. Ganjali, and A. Firoozshahian.\n\n\f529(7587):484–489, 2016.\n[32] N. Usunier, G. Synnaeve, Z. Lin, and S. Chintala. Episodic\nexploration for deep deterministic policies: An application to\nstarcraft micromanagement tasks. arXiv preprint\narXiv:1609.02993, 2016.\n[33] G. Wang, D. G. Andersen, M. Kaminsky, K. Papagiannaki,\nT. Ng, M. Kozuch, and M. Ryan. c-through: Part-time optics in\ndata centers. In Proceedings of ACM SIGCOMM 2010.\n\n[34] R. J. Williams. Simple statistical gradient-following algorithms\nfor connectionist reinforcement learning. Machine learning,\n8(3-4):229–256, 1992.\n[35] D. Zhuo, M. M. Ghobadi, R. Mahajan, K.-T. Forster,\nA. Krishnamurthy, and T. Anderson. Understanding and\nmitigating packet corruption in data center networks. page 14.\nACM SIGCOMM, August 2017.\n\n\f",
         "train",
         "36555",
         "5645"
        ],
        [
         "32",
         "19208",
         "cs.AI",
         "Artificial Intelligence",
         "0405088v1.pdf",
         "arXiv:cs/0405088v1 [cs.PL] 24 May 2004\n\nUnder consideration for publication in Theory and Practice of Logic Programming\n\n1\n\nHigh-Level Networking with Mobile Code and\nFirst Order AND-Continuations\nPAUL TARAU\nDepartment of Computer Science\nUniversity of North Texas\nP.O. Box 311366\nDenton, Texas 76203\nE-mail: tarau@cs.unt.edu\n\nVERONICA DAHL\nLogic and Functional Programming Group\nDepartment of Computing Sciences\nSimon Fraser University\nE-mail: veronica@cs.sfu.ca\n\nAbstract\nWe describe a scheme for moving living code between a set of distributed processes coordinated with unification based Linda operations, and its application to building a comprehensive Logic programming based Internet programming framework. Mobile threads are\nimplemented by capturing first order continuations in a compact data structure sent over\nthe network. Code is fetched lazily from its original base turned into a server as the continuation executes at the remote site. Our code migration techniques, in combination with\na dynamic recompilation scheme, ensure that heavily used code moves up smoothly on a\nspeed hierarchy while volatile dynamic code is kept in a quickly updatable form. Among\nthe examples, we describe how to build programmable client and server components (Web\nservers, in particular) and mobile agents.\nKeywords: mobile computations, remote execution, networking, Internet programming,\nfirst order continuations, Linda coordination, blackboard-based logic programming, mobile\nagents, dynamic recompilation, code migration\n\n1 Introduction\nData mobility has been present since the beginning of networked computing, and\nis now used in numerous applications – from remote consultation of a database, to\nWeb browsing.\nCode mobility followed, often made transparent to users as with network files\nsystems (i.e. Sun’s NFS). Java’s ability to execute applets directly in client browsers,\ncan be seen as its most recent incarnation.\nMigrating the state of the computation from one machine or process to another,\nstill requires a separate set of tools. Java’s remote method invocations (RMI) add\n\n\f2\n\nPaul Tarau and Veronica Dahl\n\ncontrol mobility and a (partially) automated form of object mobility i.e. integrated\ncode (class) and data (state) mobility. The Oz 2.0 distributed programming proposal of (Van Roy et al., 1997) makes object mobility more transparent, although\nthe mobile entity is still the state of the objects, not “live” code.\nMobility of “live code” is called computation mobility (Cardelli, 1997). It requires\ninterrupting the execution, moving the state of a runtime system (stacks, for instance) from one site to another, and then resuming execution. Clearly, for some\nlanguages, this can be hard or completely impossible to achieve.\nTelescript and General Magic’s Odyssey (GeneralMagicInc., 1997) agent programming framework, IBM’s Java based aglets, as well as Luca Cardelli’s Oblique\n(Bharat & Cardelli, 1995), have pioneered implementation technologies with computation mobility.\nThis paper will show that we can achieve full computation mobility through our\nmobile threads, with no need for a specially designed new language. It is implemented by a surprisingly small, source level modification of the BinProlog system,\nwhich takes advantage of the availability of first order continuations1 as well as of\nBinProlog’s high level networking primitives. Mobile threads complete our Logic\nProgramming based Internet programming infrastructure, built in view of creating Prolog components which can interoperate with mainstream languages and\nprogramming environments. Mobile threads can be seen as a refinement of mobile\ncomputations, as corresponding to mobile partial computations of any granularity.\nMobile agents can be seen as a collection of synchronized mobile threads sharing\ncommon state (Tarau & Dahl, 1996). We achieve synchronization using a variant\nof the Linda coordination protocol.\nThe paper is organized as follows:\n• section 2 describes our networking infrastructure and Linda based client/server\ncomponents\n• Section 3 describes our code migration and code acceleration techniques (dynamic recompilation)\n• Section 4 describes our mobile computation mechanism, as follows: subsection 4.2 introduces engines and threads, subsection 4.3) reviews the underlying binarization mechanism used to implement our first order continuations,\nsubsection 4.4 explains how we implement thread mobility by capturing continuations (subsection 4.4.1) and moving them from their base to their target (subsection 4.4.2), how this can be emulated with remote predicate calls\n(subsection 4.4.3) and how mobile agents can be built within our framework\n(subsection 4.5)\n• section 5 discusses related work\n• section 6 presents our conclusions and future work\nThe main “paradigm independent” novelties of our contribution are:\n• use of first order continuations for implementing mobile computations\n1\n\nI.e. continuations (representations of future computations) accessible as an ordinary data structure - a Prolog term in this case.\n\n\fHigh-Level Networking with Mobile Code and First Order Continuations\n\n3\n\n• a flexible thread mobility algorithm expressed in terms of client-server role\nalternation and communication through Linda operations\n• a technique, based on intuitionistic assumptions, for dealing with complex\nnetworking code component-wise\nOur contributions are synergetically integrated into a powerful agent building infrastructure, which brings together logic programming based knowledge processing,\nLinda-style coordination, and live code migration through mobile threads.\n\n2 Basic Linda and Remote Execution Operations\n2.1 Coordination of Linda clients\nOur networking constructs are built on top of the popular Linda (Carriero & Gelernter, 1989;\nCiancarini, 1994; De Bosschere & Tarau, 1996; P. Ciancarini et al., 1996; Microsystems, 1999)\ncoordination framework, enhanced with unification based pattern matching, remote\nexecution and a set of simple client-server components merged together into a scalable peer-to-peer layer, forming a ‘web of interconnected worlds’:\nout(X): puts X on the server\nin(X): waits until it can take an object\nmatching X from the server\nall(X,Xs): reads the list Xs matching X\ncurrently on the server\n\nBLACKBOARD\nWORLD\na (1)\na (2)\n\nCONSUMER\n\nin (a(X))\nX=1\nout (a(1))\nINTERNET\nREADER\n\nPRODUCERS\n\nall (a(X), Xs)\nout (a(2))\nXs = [a(1), a(2)]\n\nFig. 1. Basic Linda operations\n\nThe presence of the all/2 collector avoids the need for backtracking over multiple remote answers. Note that the only blocking operation is in/1. Typically, distributed programming with Linda coordination follows consumer-producer patterns\n\n\f4\n\nPaul Tarau and Veronica Dahl\n\n(see Fig. 1) with added flexibility over message-passing communication through associative search. Blocking rd/1, which waits until a matching term becomes available, without removing it, is easily emulated in terms of in/1 and out/1, while\nnon-blocking rd/1 is emulated with all/2.\n2.2 Remote Execution Mechanisms\nThe implementation of arbitrary remote execution is easy in a Linda + Prolog system, due to Prolog’s metaprogramming abilities, which allow us to send arbitrary\nProlog terms over the network in a uniform way, without the need for implementing\ncomplex serialization/remote object mechanisms. Our primitive remote call operation is:\nhost(Other_machine)=>>\nremote_run(Answer,RemoteGoal).\n\nIt implements deterministic remote predicate calls with (first)-answer or ‘no’ returned to the calling site.\nFor instance, to iterate over the set of servers forming the receiving end of our\n‘Web of Worlds’, after retrieving the list from a ‘master server’ which constantly\nmonitors them making sure that the list reflects login/logout information, we simply override host/1 and port/1 with intuitionistic implication =>> (Tarau, 1998a;\nDahl et al., 1997):\nask_all_servers(Channel,Servers,Query):member(server_id(Channel,H,P),Servers),\nhost(H)=>>port(P)=>>\nask_a_server(Query,_),\nfail;true.\n\nNote that a Channel pattern is used to select a subset of relevant servers, and\nin particular, when Channel is a “match all” free logical variable, all of them.\nBy using term subsumption this allows building sophisticated ”publish/subscribe”\ncommunication pattern hierarchies.\n2.3 Servants: basic Linda agents\nA servant is one of the simplest possible agents, which pulls commands from a\nserver and runs them locally:\nservant:in(todo(Task)),\ncall(Task),\nservant.\n\nNote that servant is started as a background thread. No ‘busy wait’ is involved,\nas the servant’s thread blocks until in(todo(Task)) succeeds. More generally, distributed event processing is implemented by creating a ‘watching’ agent attached\nto a thread for each pattern.\nAs servants pulling commands are operationally indistinguishable from servers\n\n\fHigh-Level Networking with Mobile Code and First Order Continuations\n\n5\n\nacting upon clients’ requests, they can be used as emulators for servers. A class of\nobvious applications of this ability is their use as pseudo-servers running on machines with dynamically allocated IP addresses (as offered by most ISP today),\nlaying behind firewalls. This mechanism also works when, because of security restrictions, server components cannot be reached from outside, as in the case of Java\napplets which cannot listen on ports of the client side machine.\n\n2.4 Server side code\nServants as well as other clients can connect to BinProlog servers. Higher order call/N (Mycroft & O’Keefe, 1984), combined with intuitionistic assumptions\n‘‘=>>’’, are used to pass arbitrary interactors to generic server code:\n\nrun_server(Port):new_server(Port,Server),\nregister_server(Port),\nserver(Server)=>>server_loop,\nclose_socket(Server).\nserver_loop:repeat,\ninteract,\nassumed(server_done),\n!.\ninteract:assumed(Interactor),\nassumed(Server),\n% higher-order call to interactor\ncall(Interactor,Server).\n\nNote the use of a specialized server-side interpreter server loop, configurable\nthrough the use of higher-order ‘question/answer’ closures we have called interactors.\nThe components of a ‘generic’ default server can be overridden through the use of\nintuitionistic implication to obtain customized special purpose servers. The use of\nintuitionistic implications (pioneered by Miller’s work (Miller, 1989)) helps to overcome (to some extent) Prolog’s lack of object oriented programming facilities, by\nallowing us to ‘inject’ the right interactor into the generic (and therefore reusable)\ninterpreter. BinProlog’s ‘‘=>>’’ temporarily assumes a clause in asserta order,\ni.e. at the beginning of the predicate. The assumption is scoped to be only usable to\nprove its right side goal and vanishes on backtracking. We refer to (Tarau, 1998a;\nTarau et al., 1996a; Dahl et al., 1997) for more information on assumptions and\ntheir applications.\n\n\f6\n\nPaul Tarau and Veronica Dahl\n2.5 Modular HTTP server component building: do or delegate\n\nWe will show in this section a typical application of our component based server\nbuilding technology: how to enhance efficiently the HTTP protocol, to handle server\nside Prolog scripts directly, without using CGIs or vendor specific server side extensions.\nThe top goal of the HTTP server looks as follows:\nrun_http_server:server_action(http_server_action)=>>run_server.\nhttp_server_action(ServiceSocket):socket(ServiceSocket)=>>http_server_step(ServiceSocket).\n\nThe http server action is passed to the inner server loop using intuitionistic\nimplication. This allows reusing general server logic, independently of a particular\nprotocol. The action itself is described in http server step: it consists of preparing a fall-back mechanism to a standard HTTP server, unless the request is for a\nfile recognized as Prolog code, using the redirection facilities built in the HTTP\nprotocol.\nhttp_server_step(Socket):( assumed(fallback_server(FallBackServer))->true\n; FallBackServer=\"http://localhost:80\"\n),\nserver_try(Socket,sock_readln(Socket,Question)),\nhttp_get_client_header(Socket,Header),\nhttp_process_query(Socket,Question,Header,FallBackServer).\n\nOur very simple query processor uses Assumption Grammars (Dahl et al., 1997).\nTheir ability to handle multiple DCG streams (Tarau et al., 1996a) is instrumental,\nas we use more than one independent grammar processor in the process.\nhttp_process_query(Socket,Qs,Css,FallBackServer):#<Qs, % sets input string from grammar\nmatch_word(\"GET \"),\nmatch_before(\" \",PathFile,_),\nmatch_word(\"HTTP/\"),\n#>_version, %\n!,\nsplit_path_file(PathFile,Ds,Fs),\n!,\nhas_text_file_sufix(Fs,Suf),\n!,\n( Suf=\".pro\"->http_process_local(Socket,Ds,Fs,Suf,Css)\n; write(’redirecting ’),write_chars(Ds),write_chars(Fs),nl,\nhttp_send_line(Socket,\"HTTP/1.0 302 Found\"),\nmake_cmd0([\"Location: \",FallBackServer,Ds,Fs],Redirect),\nhttp_send_line(Socket,Redirect),\nhttp_send_line(Socket,\"\")\n),\nclose_socket(Socket).\n\n\fHigh-Level Networking with Mobile Code and First Order Continuations\n\n7\n\nOur HTTP server component fits in 76 lines of code, and can be used to set up\nProlog based Web processing by simply starting it in a command window on any\nUnix machine or PC. This involves no execution overhead, as is the case with CGI\nscripts. It basically offers the advantages of Apache server side includes (SSIs) or\nMicrosoft’s active server pages (ASPs), without requiring integration into a server,\noften subject to using the languages the server supports.\n2.6 Master Servers: Connecting a Web of Virtual Places\nA virtual place is implemented as a server listening on a port which can spawn\nclients in the same or separate threads interacting with other servers.\nA master server on a ‘well-known’ host/port is used as a registration service to\nexchange identification information among peers composed of clients and a server,\nusually running as threads of the same process.\nAs in the case of the HTTP server we can derive a master server by specializing\nits interactor components through intuitionistic implications.\n3 Code migration and code acceleration techniques\nWe have seen that setting up a self contained networking infrastructure (Web protocols included) is a fairly simple task. The next step is emphasizing mobile agent\nsupport, which is particularly promising in synergy with knowledge processing capabilities - a key strength of Logic Programming systems.\n3.1 Lazy code fetching\nIn BinProlog, code is fetched lazily over the network, one predicate at a time, as\nneeded by the execution flow.\nCode is cached in a local database and then dynamically recompiled on the fly if\nusage statistics indicate that it is not volatile and it is heavily used locally.\nThe following operations\nhost(Other_machine)=>>rload(File).\nhost(Other_machine)=>>code(File)=>>TopGoal.\n\nallow fetching remote files rload/1 or on-demand fetching of a predicate at a time\nfrom a remote host during execution of TopGoal.\nThis is basically the same mechanism as the one implemented for Java applet\ncode fetching, except that we have also implemented a caching mechanism, at predicate level (predicates are cached as dynamic code on the server to efficiently serve\nmultiple clients).\n3.2 Dynamic recompilation\nDynamic recompilation is used on the client side to speed-up heavily used, relatively non-volatile predicates. With dynamically recompiled consulted code, listing\n\n\f8\n\nPaul Tarau and Veronica Dahl\n\nof sources and dynamic modification to any predicate is available, while the average\nperformance stays close to statically compiled code (usually within a factor of 2-3).\nOur implementation of dynamic recompilation for BinProlog is largely motivated\nby the difficulty/complexity of relying on the programmer to specify execution\nmethods for remote code.\nThe intuition behind the dynamic recompilation algorithm of BinProlog is that\nupdate vs. call based statistics are associated to each predicate declared or detected as dynamic. Dynamic (re)compilation is triggered for relatively non-volatile\npredicates, which are promoted on the ‘speed-hierarchy’ to a faster implementation\nmethod (interpreted -> bytecode -> native). The process is restarted from the ‘easier to change’ interpreted representation, kept in memory in a compact form, upon\nan update.\nWe can describe BinProlog’s dynamic ‘recompilation triggering statistics’ through\na simple ‘thermostat’ metaphor. Updates (assert/retract) to a predicate have the\neffect of increasing its associated ‘temperature’, while Calls will decrease it. Nonvolatile (‘cool’) predicates are dynamically recompiled, while recompilation is avoided\nfor volatile (‘hot’) predicates. A ratio based on cooling factors (number of calls, compiled/interpreted execution speed-up etc.) and heating factors (recompilation time,\nnumber of updates etc.) smoothly adjusts for optimal overall performance, usually\nwithin a factor of 2 from static code.\n\n4 Computation Mobility with Threads and Continuations\n4.1 Why do computations need to be mobile?\nAdvanced mobile object and mobile agents agent systems have been built on top of\nJava’s dynamic class loading and its new reflection and remote method invocation\nclasses. IBM Japan’s Aglets or General Magic’s Odyssey provide comprehensive\nmobility of code and data. Moreover, data is encapsulated as state of objects. This\nproperty allows us to protect its sensitive components more easily. Distributed\nOz/Mozart provides fully transparent movement of objects over the network, giving\nthe illusion that the same program runs on all the computers.\nSo why do we need the apparently more powerful concept of mobile “live code”\ni.e. mobile execution state?\nOur answer to this question is that live mobile code is needed because is still\nsemantically simpler than mobile object schemes. Basically, all that a programmer\nneeds to know is that his or her program has moved to a new site and it is executing\nthere. A unique (in our case move thread) primitive, with an intuitive semantics,\nis all that needs to be learned. When judging about how appropriate a language\nfeature is, we think that the way it looks to the end user is among the most important ones. For this reason, mobile threads are competitive with sophisticated object\nmobility constructs on “end-user ergonomy” grounds, while being fairly simple to\nimplement, as we have shown, in languages in which continuations can be easily\nrepresented as data structures.\nAnd what if the host language does not offer first order continuations? A simple\n\n\fHigh-Level Networking with Mobile Code and First Order Continuations\n\n9\n\nway around this is to implement on top of it a script interpreter (e.g. a subset of\nScheme or Prolog) which does support them! As it is a good idea to limit code\nmigration to lightweight scripts anyway, this is a very practical solution for either C/C++ or Java based mobile code solutions, without requiring class-specific\nserialization mechanisms.\n4.2 Engines and Answer Threads\nMobile computations really make sense only when multiple computation threads\ncan coexist at a given place. We build this infrastructure in two steps: an engine\nencapsulating the state of an independent computation, and a thread actually running it. Note that engines can also be used without multi-threading, as a form of\ncoroutining.\n4.2.1 Engines\nBinProlog allows launching multiple Prolog engines having their own stack groups\n(heap, local stack and trail). An engine can be seen as an abstract data-type which\nproduces a (possibly infinite) stream of solutions as needed. To create a new engine,\nwe use:\ncreate_engine(+HeapSize,+StackSize,+TrailSize,-Handle)\n\nor, by using default parameters for the stacks:\ncreate_engine(-Handle)\n\nThe Handle is a unique integer denoting the engine for further processing. To ‘fuel’\nthe engine with a goal and an expected answer variable we use:\nload_engine(+Handle,+Goal,+AnswerVariable)\n\nNo processing, except the initialization of the engine takes place, and no answer is\nreturned with this operation.\nTo get an answer from the engine we use:\nask_engine(+Handle,-Answer)\n\nEach engine has its own heap garbage collection process and backtracks independently using its choice-point stack and trail during the computation of an answer.\nOnce computed, an answer is copied from an engine to its “master”.\nWhen the stream of answers reaches its end, ask_engine/2 will simply fail. The\nresolution process in an engine can be discarded at any time by simply loading\nanother goal with load engine/3. This allows avoiding the cost of backtracking,\nfor instance in the case when a single answer is needed, as well as garbage collection\ncosts.\nIf for some reason we are not interested in the engine any more, we can free the\nspace allocated to the engine and completely discard it with:\ndestroy_engine(+Handle)\n\n\f10\n\nPaul Tarau and Veronica Dahl\n\nThe following example 2 in the BinProlog distribution (Tarau, 1998a) shows a sequence of the previously described operations:\n?-create_engine(E),\nload_engine(E,append(As,Bs,[1,2]),As+Bs),\nask_engine(E,R1),write(R1),nl,\nask_engine(E,R2),write(R2),nl,\ndestroy_engine(E).\n\nMultiple ‘orthogonal engines’ as shown in Figure 2 enhance the expressiveness of\nProlog by allowing an AND-branch of an engine to collect answers from multiple\nOR-branches of another engine. They give to the programmer the means to see as\nan abstract sequence and control, the answers produced by an engine, in a way\nsimilar to Java’s Enumeration interface.\nEngine 1\n\nProducer\nOR−TREE\n\nAnswer5\nAnswer1\n\nAnswer2\nAnswer4\nAnswer3\n\nEngine 2\n\nConsumer\nOR−TREE\n\nFig. 2. Orthogonal Engines\n\n4.2.2 Threads\nEngines can be assigned to their own thread by using BinProlog’s thread package (currently fully implemented on win32, Linux and Solaris platform). A unique\nprimitive is needed,\nask_thread(E,R)\n\nwhich launches a new thread R to perform the computation of an answer of engine\nE. On top of this facility each thread can implement a separate server or client, or\nbecome the base of a mobile agent.\nThread synchronization is provided through monitor objects, handled with:\n2\n\nSee more in files library/engines.pl, progs/engtest.pl\n\n\fHigh-Level Networking with Mobile Code and First Order Continuations\n\n11\n\nsynchronize_on(Monitor,Goal,Answer)\n\nThe thread waits until the monitor is free, executes Goal, frees the monitor and\nreturns Answer.\nThe thread attached to an engine can be obtained with:\nget_engine_thread(Engine,Thread)\n\nand can be controlled directly with:\nthread_suspend(Thread) % suspends the thread\nthread_resume(Thread) % resumes a suspended thread\nthread_join(Thread)\n% waits until a thread terminates\nthread_cancel(Thread) % discards a thread\n\n4.3 First order Continuations through Binarization\nHaving first order continuations largely simplifies the implementation of mobile\ncode operations: a thread is suspended, its continuation is packed, sent over the\nnetwork and resumed at a different place.\nWe will shortly explain here BinProlog’s continuation passing preprocessing technique, which results in the availability of continuations as data structures accessible\nto the programmer.\nThe binarization transformation Binary clauses have only one atom in the body\n(except for some in-line ‘builtin’ operations like arithmetics), and therefore they\nneed no ‘return’ after a call. A transformation introduced in (Tarau & Boyer, 1990)\nallows us to faithfully represent logic programs with operationally equivalent binary\nprograms.\nTo keep things simple, we will describe our transformations in the case of definite\nprograms. We will follow here the notations of (Tarau & De Bosschere, 1993).\nLet us define the composition operator ⊕ that combines clauses by unfolding the\nleftmost body-goal of the first argument.\nLet A0 :-A1 ,A2 ,...,An and B0 :-B1 ,...,Bm be two clauses (suppose n > 0, m ≥\n0). We define\n(A0 :-A1 ,A2 ,...,An) ⊕ (B0 :-B1 ,...,Bm) = (A0 :-B1 ,...,Bm,A2 ,...,An)θ\nwith θ = mgu(A1 ,B0 ). If the atoms A1 and B0 do not unify, the result of the composition is denoted as ⊥. Furthermore, as usual, we consider A0 :-true,A2,...,An\nto be equivalent to A0 :-A2 ,...,An, and for any clause C, ⊥ ⊕ C = C ⊕ ⊥ = ⊥.\nWe assume that at least one operand has been renamed to a variant with variables\nstandardized apart.\nThis Prolog-like inference rule is called LD-resolution. It has the advantage of\ngiving a more accurate description of Prolog’s operational semantics than SLDresolution. Before introducing the binarization transformation, we describe two\nauxiliary transformations.\nThe first transformation converts facts into rules by giving them the atom true\nas body. E.g., the fact p is transformed into the rule p :- true.\n\n\f12\n\nPaul Tarau and Veronica Dahl\n\nThe second transformation, inspired by (Warren, 1981), eliminates the metavariables by wrapping them in a call/1 goal. E.g., the rule and(X,Y):-X, Y is transformed into and(X,Y) :- call(X), call(Y).\nThe transformation of (Tarau & Boyer, 1990) (binarization) adds continuations\nas extra arguments of atoms in a way that preserves also first argument indexing.\nLet P be a definite program and Cont a new variable. Let T and E = p(T1 , ..., Tn )\nbe two expressions.3 We denote by ψ(E, T ) the expression p(T1 , ..., Tn , T ). Starting\nwith the clause\n(C)\nA : −B1 , B2 , ..., Bn .\nwe construct the clause\n(C’)\nψ(A, Cont) : −ψ(B1 , ψ(B2 , ..., ψ(Bn , Cont))).\nThe set P ′ of all clauses C’ obtained from the clauses of P is called the binarization\nof P.\nThe following example shows the result of this transformation on the well-known\n‘naive reverse’ program:\napp([],Ys,Ys,Cont):-true(Cont).\napp([A|Xs],Ys,[A|Zs],Cont):app(Xs,Ys,Zs,Cont).\nnrev([],[],Cont):-true(Cont).\nnrev([X|Xs],Zs,Cont):nrev(Xs,Ys,app(Ys,[X],Zs,Cont)).\n\nThe transformation preserves a strong operational equivalence with the original\nprogram with respect to the LD resolution rule, which is reified in the syntactical\nstructure of the resulting program, i.e. each resolution step of an LD derivation on\na definite program P can be mapped to an SLD-resolution step of the binarized\nprogram P ′ .\nClearly, continuations become explicit in the binary version of the program. We\nhave devised a technique to access and manipulate them in an intuitive way, by\nmodifying BinProlog’s binarization preprocessor. Basically, the clauses constructed\nwith ::- instead of :- are considered as being already in binary form, and not\nsubject therefore to further binarization. By explicitly accessing their arguments, a\nprogrammer is able to access and modify the current continuation as a ‘first order\nobject’. Note however that code referring to the continuation is also part of it, so\nthat some care should be taken in manipulating the circular term representing the\ncontinuation from ‘inside’.\n4.4 Mobile threads: Take the Future and Run\nAs continuations (describing future computations to be performed at a given point)\nare first order objects in BinProlog, it is easy to extract from them a conjunction of goals representing future computations intended to be performed at another site, send it over the network and resume working on it at that site. The\n3\n\nAtom or term.\n\n\fHigh-Level Networking with Mobile Code and First Order Continuations\n\n13\n\nnatural unit of mobility is a thread moving to a server executing multiple local\nand remotely originated threads. Threads communicate with their local and remote counterparts, listening on ports through the Linda protocol, as described in\n(De Bosschere & Tarau, 1996). This combination of Linda based coordination and\nthread mobility is intended to make building complex, pattern based agent scripts\nfairly easy.\n4.4.1 Capturing continuations\nBefore moving to another site, the current continuation needs to be captured in\na data structure (see Appendix I). For flexibility, a wrapper capture cont for/1\nis used first to restrict the scope of the continuation to a (deterministic) toplevel\nGoal. This avoids taking irrelevant parts of the continuation (like prompting the\nuser for the next query) to the remote site inadvertently.\nA unique logical variable is used through a backtrackable linear assumption\ncont marker(End) to mark the end of the scope of the continuation with end cont(End).\n¿From inside the continuation, call with cont/1 is used to extract the relevant\nsegment of the continuation. Towards this end, consume cont(Closure,Marker)\nextracts a conjunction of goals from the current continuation until Marker is reached,\nand then it applies Closure to this conjunction (calls it with the conjunction passed\nto Closure as an argument).\nExtracting the continuation itself is easy, by using BinProlog’s ability to accept\nuser defined binarized clauses (introduced with ::- instead of :-), that can access the\ncontinuation as a ‘first order’ object:\nget_cont(Cont,Cont)::-true(Cont).\n\n4.4.2 The Continuation Moving Protocol\nOur continuation moving protocol can be described easily in terms of synchronized\nsource side4 , and target side operations.\nSource side operations\n• wrap a Goal with a unique terminator marking the end of the continuation to\nbe captured, and call it with the current continuation available to it through\na linearly assumed fact5\n• reserve a free port P for the future code server\n• schedule on the target server a sequence of actions which will lead to resuming\nthe execution from right after the move thread operation (see target side\noperations), return and become a code server allowing the mobile thread to\nfetch required predicates one a time\n4\n5\n\nwhich will be also shortly called the base of the mobile thread\nBinProlog’s linear assumptions are backtrackable additions to the database, usable at most\nonce.\n\n\f14\n\nPaul Tarau and Veronica Dahl\n\nTarget side operations are scheduled as a sequence of goals extracted from the\ncurrent continuation at the source side , and received over the network together\nwith a small set of synchronization commands:\n• schedule as delayed task a sequence of goals received from the source side and\nreturn\n• wait until the source side is in server mode\n• set up the back links to the source side as assumptions\n• execute the delayed operations representing the moved continuation\n• fetch code from the source side as needed for execution of the goals of the\nmoved continuations and their subcalls\n• shut down the code server on the source side\nCommunication between the base and the target side proceeds through remote\npredicate calls protected with dynamically generated passwords shared between the\ntwo sides before the migratory component “takes off”.\nInitially the target side waits in server mode. Once the continuation is received on\nthe target side, the source side switches to server mode (unless it already contains\na running server thread), ready to execute code fetching and persistent database\nupdate requests from its mobile counterpart on the target side.\nFig. 3 shows the connections between a mobile thread and its base.\nNote that when the base turns into a server, it offers its own code for remote use\nby the moved thread - a kind of virtual “on demand” process cloning operation,\none step at a time. Since the server actually acts as a code cache, multiple moving\nthreads can benefit from this operation. Note also that only predicates needed for\nthe migratory segment of the continuation are fetched. This ensures that migratory\ncode is kept lightweight for most mobile applications. Synchronized communication,\nusing Linda operations, can occur between the mobile thread and its base server,\nand through the server, between multiple mobile threads which have migrated to\nvarious places. Note that servants described in section 2.3 can also be used to\nemulate servers in case of the ptocess is hosted in a component unable to listen on\na server port.\nAs our networking infrastructure, our mobile threads are platform independent.\nLike Java, BinProlog (Tarau, 1998b) is a platform independent emulator based\nlanguage. As a consequence, a thread can start on a Unix machine and move transparently to a Windows NT system and back. For faster, platform specific execution,\nBinProlog provides compilation to C of static code using an original partial translation technique described in (Tarau et al., 1996b).\n4.4.3 Emulating computation mobility through control mobility\nAs shown in (Tarau et al., 1997b), part of the functionality of mobile computations\ncan be emulated in terms of remote predicate calls combined with remote code\nfetching. An implicit virtual place (host+port) can be set as the target of the remote\ncalls. Then, it is enough to send the top-level goal to the remote side and have it\nfetch the code as needed from a server at the site from where the code originates.\n\n\fHigh-Level Networking with Mobile Code and First Order Continuations\n\n15\n\nMobile Thread Base\nBase server\n\nCode File(s)\n\nCode Cache\nmove_thread\nMobile\nthread\n\nlazy code fetch\n\nreturn\n\nMobile\nthread\n\nTarget server\nMobile\nthread\n\nFig. 3. Launching a mobile thread from its base\nNote however that this is less efficient in terms of network transactions and less\nreliable than sending the full continuation at once as with our mobile threads.\n4.5 Mobile Agents\nMobile agents can be seen as a collection of synchronized mobile threads sharing\ncommon state (Tarau & Dahl, 1996). Agents execute a set of goals, possibly spread\nover a set of different processes. In addition to usual Prolog computations, agents\nperform remote and local transactions in coordination with other agents, and react\nto event driven changes occurring on blackboards.\nMobile agents are implemented by sending out mobility threads to a set of servers6\nregistered to a given master server. A pyramidal deployment strategy can be used\nto efficiently implement, for instance, push technology through mobile agents. Interagent communication can be achieved either by rendez-vous of two mobile threads\nat a given site, by communicating through a local Prolog database, or through\nthe base server known to all the deployed agents. Communication with the base\nserver is easily achieved through remote predicate calls with remote run. Interagent communication can be achieved either by rendez-vous of two mobile threads\nat a given site, by communicating through a local blackboard, or through the base\nserver known to all the deployed agents. Basic security of mobile agents is achieved\nwith randomly generated passwords, required for remote run/1 operations, and\nby running them on a restricted BinProlog machine, without user-level file write\nand external process spawn operations. For more details on recent developments\nof mobile agent infrastructures and their applications, extending the framework\npresented in this paper, we refer to (Tarau, 1999c; Tarau, 1999b; Mikler et al., 1999;\nTarau, 1999a; Rochefort et al., 1999).\nIn the latest version of BinProlog (Tarau, 1998a) two simple move/0 and return/0 operations can be used to transport a mobile agent thread to a server\n6\n\npossibly filtered down to a relevant subset using a ‘channel’-like pattern\n\n\f16\n\nPaul Tarau and Veronica Dahl\n\n(listening on a default host/port) and back. The anaphoric there indicates that the\nmobile thread should be created on the server. Alternatively, here would indicate\nexecution on a local thread. In this mobility scheme, the client simply waits until\ncomputation completes, when bindings for the first solution are propagated back.\nWindow 1: a mobile thread\n?-there,move,println(on_server),member(X,[1,2,3]),\nreturn,println(back).\nback\nX=1\nWindow 2: a server\n?-trust.\non_server\n\nIn case return is absent, computation proceeds to the end of the transported\ncontinuation.\nNote that mobile computation is more expressive and more efficient than remote\npredicate calls as such. Basically, it moves once, and executes on the server all future\ncomputations of the current AND branch until a return instruction is hit, when it\ntakes the remaining continuation and comes back. This can be seen by comparing\nreal time execution speed for:\n?-for(I,1,1000),remote_run(println(I)),fail.\n?-there,move,for(I,1,1000),println(I),fail.\n\nWhile the first query uses remote run/1 each time to send a remote task to\nthe server, the second moves once the full computation to the server where it executes without further requiring network communications. Note that the move/0,\nreturn/0 pair cut nondeterminism for the transported segment of the current continuation. This avoids having to transport state of the choice-point stack as well\nas implementation complexity of multiple answer returns and tedious distributed\nbacktracking synchronization. Surprisingly, this is not a strong limitation, as the\nprogrammer can simply use something like:\n?-there,move,findall(X,for(I,1,1000),Xs),return,member(X,Xs).\n\nto emulate (finite!) nondeterministic remote execution, by collecting all solutions\nat the remote side and exploring them through (much more efficient) local backtracking after returning.\n\n5 Related work\nRemote execution and code migration techniques are pioneered by (Almes et al., 1985;\nJul et al., 1988; Stamos & Gifford, 1990). Support for remote procedure calls (RPC)\nare part of major operating systems like Sun’s Solaris and Microsoft’s Windows NT.\n\n\fHigh-Level Networking with Mobile Code and First Order Continuations\n\n17\n\nA very large number of research projects have recently started on mobile computations/mobile agent programming. Among the pioneers, Kahn and Cerf’s Knowbots (Kahn & Cerf, 1988). Among the most promising recent developments, Luca\nCardelli’s Oblique project at Digital and mobile agent applications (Bharat & Cardelli, 1995)\nand IBM Japan’s aglets (IBM, 1999). Mobile code technologies are pioneered by\nGeneral Magic’s Telescript (see (GeneralMagicInc., 1997) for their last Java based\nmobile agent product). General Magic’s Portico software combines mobile code\ntechnologies and voice recognition based command language (MagicTalk).\nAnother mobility framework, sharing some of our objectives towards transparent\nhigh level distributed programming, is built on top of Distributed Oz (Van Roy et al., 1997;\nHaridi et al., 1997) a multi-paradigm language, also including a logic programming\ncomponent. Although thread mobility is not implemented in Distributed Oz 2, some\nof this functionality can be emulated in terms of network transparent mobile objects. The illusion of a unique application which transparently runs on multiple\nsites makes implementing shared multi-user applications particularly easy. We can\nemulate this by implementing mobile agents (e.g. avatars) as mobile threads with\nparts of the shared world visible to an agent represented as dynamic facts, lazily\nreplicated through our lazy code fetching scheme when the agent moves. Both Distributed Oz 2 and our BinProlog based infrastructure need a full language processor\n(Oz 2 or BinProlog) to be deployed at each node. However, assuming that a Java\nprocessor is already installed, our framework’s Java client (see (Tarau et al., 1997b;\nTarau et al., 1997a)) allows this functionality to be available through applets attached to a server side BinProlog thread.\nImplementation technologies for mobile code are studied in (Adl-Tabatabai et al., 1996).\nEarly work on the Linda coordination framework (Carriero & Gelernter, 1989; Castellani & Ciancarini, 1996;\nBrogi & Ciancarini, 1991) has shown its potential for coordination of multi-agent\nsystems. The logical modeling and planning aspects of computational Multi-Agent\nsystems have been pioneered by (Cohen & Perrault, 1979; Cohen et al., 1989; Kowalski & Kim, 1991;\nWooldridge, 1992; Cohen & Cheyer, 1994; Cohen & Levesque, 1995; Lésperance et al., 1996;\nChaib-draa & Levesque, 1994). A survey of Logic Programming approaches to Web\napplications in terms of a classification into client-based systems, server-side systems, and peer-to-peer systems is provided in (Loke, 1998).\nLet us point out a key difference between our framework and a typical Java\nbased mobile code system. Conventional mobile code systems like IBM’s Aglets\n(IBM, 1999) require serialization hints from the programmer and do not implement\na fully generic reflective computation mobility infrastructure. Aglets do not provide\ncode mobility as they assume that code is already available at the destination site.\nIn practice this means that the mobile code/mobile computation layer is not really\ntransparent to the programmer.\nIn contrast, our architecture is based on building an autonomous layer consisting\nof a reflective interpreter which provides the equivalent of implicit serialization and\nsupports orthogonal transport mechanisms for data, code and computation state.\nThe key idea is simply that by introducing interpreters spawned as threads by a\nserver at each networked site, computation mobility at object-level is mapped to\ndata mobility at meta-level in a very straightforward way. A nice consequence is\n\n\f18\n\nPaul Tarau and Veronica Dahl\n\ntransport independence coming from the unifrom representation of data, code and\ncomputation state allowing Corba, RMI, HLA, as well as plain or multicast sockets\nto be used interchangeably as our transport mechanism.\n6 Conclusion\nWe have described how mobile threads are implemented by capturing first order continuations in a data structure sent over the network. Supported by lazy code fetching\nand dynamic recompilation, they have been shown to be an effective framework for\nimplementing mobile agents.\nThe techniques presented here are not (Bin)Prolog specific. The most obvious\nporting target of our design is to functional languages featuring first order continuations and threads. Another porting target is Java and similar object oriented\nlanguages having threads, reflection classes and remote method invocation. We are\nworking on a Java based component using an embedded continuation passing Prolog interpreter which is already able to interoperate with BinProlog (latest version\nat http://www.binnetcorp.com/Jinni ). An interesting application is using BinProlog as an accelerator for Java based threads through migration to BinProlog,\nexecution of a computationally intensive task and return to the Java component.\nAcknowledgement\nWe thank the anonymous referees for their valuable suggestions and comments. We\nthank for support from NSERC (grants OGP0107411 and 611024).\nReferences\nAdl-Tabatabai, Ali-Reza, Langdale, Geoff, Lucco, Steven, & Wahbe, Robert. 1996 (May).\nEfficient and Language-independent Mobile Programs. Pages 127–136 of: Proceedings\nof the ACM SIGPLAN ’96 Conference on Programming Language Design and Implementation (PLDI).\nAlmes, G. T., Black, A. P., Lazowska, E. D., & Noe, J. D. (1985). The Eden System: A\nTechnical Review. IEEE Transactions on Software Engineering, 11(1), 43–59.\nBharat, K. A., & Cardelli, L. 1995 (Nov.).\nMigratory Applications.\nProceedings of the 8th annual ACM Symposium on User Interface Software and Technology. http://gatekeeper.dec.com/ pub/DEC/SRC/research-reports/ abstracts/src-rr138.html.\nBrogi, A., & Ciancarini, P. (1991). The Concurrent Language, Shared Prolog. Toplas,\n13(1), 99–123.\nCardelli, Luca. (1997). Mobile Computation. Pages 3–6 of: Vitek, J., & Tschudin, C.\n(eds), Mobile Object Systems - Towards the Programmable Internet. Springer-Verlag,\nLNCS 1228.\nCarriero, N., & Gelernter, D. (1989). Linda in Context. CACM, 32(4), 444–458.\nCastellani, S., & Ciancarini, P. (1996). Enhancing Coordination and Modularity Mechanisms for a Language with Objects-as-Multisets. Pages 89–106 of: Ciancarini, P., &\nHankin, C. (eds), Proc. 1st Int. Conf. on Coordination Models and Languages. LNCS,\nvol. 1061. Cesena, Italy: Springer.\n\n\fHigh-Level Networking with Mobile Code and First Order Continuations\n\n19\n\nChaib-draa, B., & Levesque, P. 1994 (Aug.). Hierarchical Models and Communication in\nMulti-Agent Environments. Pages 119–134 of: MAAMAW94.\nCiancarini, P. (1994). Distributed Programming with Logic Tuple Spaces. New Generation\nComputing, 12(3), 251–284.\nCohen, P. R., & Cheyer, A. (1994). An Open Agent Architecture. Pages 1–8 of: Etzioni,\nO. (ed), Software Agents — Papers from the 1994 Spring Symposium (Technical Report\nSS–94–03). AAAIP.\nCohen, P. R., & Levesque, H. J. 1995 (June). Communicative Actions for Artificial Agents.\nPages 65–72 of: Proceedings of the first international conference on multi-agent systems\n(icmas-95).\nCohen, P. R., & Perrault, C. R. (1979). Elements of a Plan Based Theory of Speech Acts.\nCogsci, 3, 177–212.\nCohen, P. R., Greenberg, M. L., Hart, D. M., & Howe, A. E. (1989). Trial by Fire:\nUnderstanding the Design Requirements for Agents in Complex Environments. Aimag,\n10(3), 32–48.\nDahl, Veronica, Tarau, Paul, & Li, Renwei. (1997). Assumption Grammars for Processing\nNatural Language. Pages 256–270 of: Naish, Lee (ed), Proceedings of the fourteenth\ninternational conference on logic programming.\nDe Bosschere, K., & Tarau, P. (1996). Blackboard-based Extensions in Prolog. Software\n— practice and experience, 26(1), 49–69.\nGeneralMagicInc. (1997).\nOdissey.\nTech. rept.\navailable at\nhttp://www.genmagic.com/agents.\nHaridi, Seif, Van Roy, Peter, & Smolka, Gert. (1997). An Overview of the Design of\nDistributed Oz. Pages 176–187 of: Proceedings of the Second International Symposium\non Parallel Symbolic Computation (PASCO ’97). Maui, Hawaii: ACM Press.\nIBM. (1999). Aglets. Tech. rept. http://www.trl.ibm.co.jp/aglets.\nJul, E., Levy, H., Hutchinson, N., & Black, A. (1988). Fine-Grained Mobility in the\nEmerald System. ACM Transactions on Computer Systems, 6(1), 109–133.\nKahn, R. E., & Cerf, V. G. (1988). The Digital Library Project, volume I: The world\nof Knowbots. Tech. rept. Unpublished manuscript, Corporation for National Research\nInitiatives, Reston, Va., Mar.\nKowalski, R., & Kim, J.-S. (1991). A Metalogic Programming Approach to Multi-Agent\nKnowledge and Belief. Lifschitz, V. (ed), AI and Mathematical Theory of Computation:\nPapers in Honour of John McCarthy. Academic Press.\nLésperance, Y., Levesque, H. J., Lin, F., Marcu, D., Reiter, R., & Scherl, R. B. (1996).\nFoundations of a Logical Approach to Agent Programming. Pages 331–346 of: ATAL95\neditors (ed), Atal95. Springer-Verlag: Heidelberg, Germany.\nLoke, Seng Wai. (1998). Adding Logic Programming Behaviour to the World Wide Web.\nPhd thesis, University of Melbourne, Australia.\nMicrosystems, Sun. (1999).\nJavaSpaces.\nTech. rept.\navailable from:\nhttp://www.javasoft.com/products/javaspaces.\nMikler, A.R., Unger, H., Tarau, P., Hopper, A. S., & Chen, F. (1999). A Mobile AgentBased File System for Distributed Networks. High Performance Computing’99, Special\nSession on Adaptive and Intelligent Computing Systems.\nMiller, D. A. (1989). Lexical Scoping as Universal Quantification. Pages 268–283 of: Levi,\nGiorgio, & Martelli, Maurizio (eds), Proceedings of the Sixth International Conference\non Logic Programming. Cambridge, Massachusetts London, England: MIT Press.\nMycroft, Alan, & O’Keefe, R. A. (1984). A Polymorphic Type System for Prolog. Artificial\nintelligence, 295–307.\n\n\f20\n\nPaul Tarau and Veronica Dahl\n\nP. Ciancarini, P., Knoche, A., Tolksdorf, R., & Vitali, F. (1996).\nPageSpace:\nAn Architecture to Coordinate Distributed Applications on the Web.\nProceedings of Fifth International World Wide Web Conference.\navailable from\nhttp://www5conf.inria.fr/fich html/papers/P5/Overview.html.\nRochefort, Stephen, Dahl, Veronica, & Tarau, Paul. 1999 (june). A Framework for Virtual\nLearning Environments. Proceedings of EMEDIA’99 World Conference on Educational\nMultimedia, Hypermedia and Telecommunications.\nStamos, J. W., & Gifford, D. K. (1990). Remote Evaluation. ACM Transaction on\nProgramming Languages and Systems, 12(4), 537–565.\nTarau, P., & De Bosschere, K. 1993 (July). Memoing with Abstract Answers and Delphi\nLemmas. Pages 196–209 of: Deville, Yves (ed), Logic Program Synthesis and Transformation. Springer-Verlag.\nTarau, Paul. (1998a). BinProlog 7.0 Professional Edition: Advanced BinProlog Programming and Extensions Guide.\nTech. rept. BinNet Corp.\nAvailable from\nhttp://www.binnetcorp.com/BinProlog.\nTarau, Paul. (1998b). BinProlog 7.0 Professional Edition: User Guide. Tech. rept. BinNet\nCorp. Available from http://www.binnetcorp.com/BinProlog.\nTarau, Paul. 1999a (Nov.). A Logic Programming Based Software Architecture for Reactive Intelligent Mobile Agents. Van Roy, P., & Tarau, P. (eds), Proceedings of diplcl’99.\nhttp://www.binnetcorp.com/wshops/ICLP99DistInetWshop.html.\nTarau, Paul. (1999b). Inference and Computation Mobility with Jinni. Pages 33–48 of:\nApt, K.R., Marek, V.W., & Truszczynski, M. (eds), The Logic Programming Paradigm:\na 25 Year Perspective. Springer. ISBN 3-540-65463-1.\nTarau, Paul. (1999c). Intelligent Mobile Agent Programming at the Intersection of Java\nand Prolog. Pages 109–123 of: Proceedings of The Fourth International Conference on\nThe Practical Application of Intelligent Agents and Multi-Agents.\nTarau, Paul, & Boyer, Michel. (1990). Elementary Logic Programs. Pages 159–173 of:\nDeransart, P., & Maluszyński, J. (eds), Proceedings of programming language implementation and logic programming. Lecture Notes in Computer Science, no. 456. Springer.\nTarau, Paul, & Dahl, Veronica. 1996 (Dec.). A Coordination Logic for Agent Programming\nin Virtual Worlds. Conen, Wolfram, & Neumann, Gustaf (eds), Proceedings of Asian’96\nPost-Conference Workshop on Coordination Technology for Collaborative Applications.\nTarau, Paul, Dahl, Veronica, & Fall, Andrew. (1996a). Backtrackable State with Linear Affine Implication and Assumption Grammars. Pages 53–64 of: Jaffar, Joxan, &\nYap, Roland H.C. (eds), Concurrency and Parallelism, Programming, Networking, and\nSecurity. Lecture Notes in Computer Science 1179. Singapore: Springer.\nTarau, Paul, De Bosschere, Koen, & Demoen, Bart. (1996b). Partial Translation: Towards a Portable and Efficient Prolog Implementation Technology. Journal of logic\nprogramming, 29(1–3), 65–83.\nTarau, Paul, Dahl, Veronica, & De Bosschere, Koen. 1997a (June). A Logic Programming\nInfrastructure for Remote Execution, Mobile Code and Agents. Pages 106–112 of:\nProceedings of WETICE’97.\nTarau, Paul, Dahl, Veronica, & De Bosschere, Koen. 1997b (July). Logic Programming\nTools for Remote Execution, Mobile Code and Agents. Proceedings of ICLP’97 Workshop on Logic Programming and Multi Agent Systems.\nVan Roy, Peter, Haridi, Seif, Brand, Per, Smolka, Gert, Mehl, Michael, & Scheidhauer,\nRalf. (1997). Mobile Objects in Distributed Oz. ACM Transactions on Programming\nLanguages and Systems, 19(5), 804–851.\nVan Roy, Peter, Haridi, Seif, & Brand, Per. (1997). Using Mobility to Make Transparent\nDistribution Practical. Tech. rept. manuscript.\n\n\fHigh-Level Networking with Mobile Code and First Order Continuations\n\n21\n\nWarren, D. H. D. (1981). Higher-order extensions to Prolog – are they needed? Michie,\nD., Hayes, J., & Pao, Y. H. (eds), Machine intelligence 10. Ellis Horwood.\nWooldridge, M. 1992 (Oct.). The logical modelling of computational multi-agent systems. Ph.D. thesis, Department of Computation, UMIST, Manchester, UK. (Also\navailable as Technical Report MMU–DOC–94–01, Department of Computing, Manchester Metropolitan University, Chester St., Manchester, UK).\n\nAppendix I: Capturing First Order Continuations in BinProlog\n% calls Goal with current continuation available to its inner calls\ncapture_cont_for(Goal):assumeal(cont_marker(End)),\nGoal,\nend_cont(End).\n% passes Closure to be called on accumulated continuation\ncall_with_cont(Closure):assumed(cont_marker(End)),\nconsume_cont(Closure,End).\n% gathers in conjunction goals from the current continuation\n% until Marker is reached when it calls Closure on it\nconsume_cont(Closure,Marker):get_cont(Cont),\nconsume_cont1(Marker,(_,_,_,Cs),Cont,NewCont), % first _\ncall(Closure,Cs),\n% second _\n% sets current continuation to leftover NewCont\ncall_cont(NewCont).\n% third _\n% gathers goals in Gs until Marker is hit in continuation Cont\n% when leftover LastCont continuation (stripped of Gs) is returned\nconsume_cont1(Marker,Gs,Cont,LastCont):strip_cont(Cont,Goal,NextCont),\n( NextCont==true-> !,errmes(in_consume_cont,expected_marker(Marker))\n; arg(1,NextCont,X),Marker==X->\nGs=Goal,arg(2,NextCont,LastCont)\n; Gs=(Goal,OtherGs),\nconsume_cont1(Marker,OtherGs,NextCont,LastCont)\n).\n% this ‘binarized clause’ gets the current continuation\nget_cont(Cont,Cont)::-true(Cont).\n% sets calls NewCont as continuation to be called next\ncall_cont(NewCont,_) ::- true(NewCont).\n\n\f22\n\nPaul Tarau and Veronica Dahl\nAppendix II: Thread Mobility in BinProlog\n\n% wraps continuation of current thread to be taken\n% by inner move_thread goal to be executed remotely\nwrap_thread(Goal):capture_cont_for(Goal).\n% picks up wrapped continuation,\n% jumps to default remote site and runs it there\nmove_thread:call_with_cont(move_with_cont).\n% moves to remote site goals Gs in current continuation\nmove_with_cont(Gs):% gets info about this host\ndetect_host(BackHost),\nget_free_port(BackPort),\ndefault_password(BackPasswd),\ndefault_code(BackCode),\n% runs delayed remote command (assumes is with +/1)\nremote_run(\n+todo(\nhost(BackHost)=>>port(BackPort)=>>code(BackCode)=>>(\nsleep(5), % waits until server on BackPort is up\n% runs foals Gs picked up from current continuation\n(Gs->true;true), % ignores failure\n% stops server back on site of origin\nstop_server(BackPasswd)\n)\n)\n),\n% becomes data and code server for mobile code until is\n% stopped by mobile code possessing password\nserver_port(BackPort)=>>run_unrestricted_server.\n\n\f",
         "train",
         "53268",
         "7660"
        ],
        [
         "33",
         "17550",
         "cs.AI",
         "Artificial Intelligence",
         "1802.08545v2.pdf",
         "Unsupervised Grammar Induction with Depth-bounded PCFG\n\narXiv:1802.08545v2 [cs.CL] 26 Feb 2018\n\nLifeng Jin\nDepartment of Linguistics\nThe Ohio State University\njin.544@osu.edu\n\nTimothy Miller\nFinale Doshi-Velez\nBoston Children’s Hospital &\nHarvard University\nHarvard Medical School\nfinale@seas.harvard.edu\ntimothy.miller@childrens.harvard.edu\n\nWilliam Schuler\nDepartment of Linguistics\nThe Ohio State University\nschuler@ling.osu.edu\nAbstract\nThere has been recent interest in applying cognitively or empirically motivated\nbounds on recursion depth to limit the\nsearch space of grammar induction models\n(Ponvert et al., 2011; Noji and Johnson, 2016;\nShain et al., 2016). This work extends this\ndepth-bounding approach to probabilistic\ncontext-free grammar induction (DB-PCFG),\nwhich has a smaller parameter space than\nhierarchical sequence models, and therefore\nmore fully exploits the space reductions of\ndepth-bounding. Results for this model on\ngrammar acquisition from transcribed childdirected speech and newswire text exceed or\nare competitive with those of other models\nwhen evaluated on parse accuracy. Moreover,\ngrammars acquired from this model demonstrate a consistent use of category labels,\nsomething which has not been demonstrated\nby other acquisition models.\n\n1 Introduction\nGrammar acquisition or grammar induction\n(Carroll and Charniak, 1992) has been of interest to linguists and cognitive scientists for\ndecades.\nThis task is interesting because a\nwell-performing acquisition model can serve\nas a good baseline for examining factors of\ngrounding\n(Zettlemoyer and Collins, 2005;\nKwiatkowski et al., 2010), or as a piece of evidence (Clark, 2001; Zuidema, 2003) about the\nDistributional Hypothesis (Harris, 1954) against the\npoverty of the stimulus (Chomsky, 1965). Unfortunately, previous attempts at inducing unbounded\n\nLane Schwartz\nDepartment of Linguistics\nUniversity of Illinois at Urbana-Champaign\nlanes@illinois.edu\ncontext-free\ngrammars\n(Johnson et al., 2007;\nLiang et al., 2009) converged to weak modes of a\nvery multimodal distribution of grammars. There\nhas been recent interest in applying cognitively or\nempirically motivated bounds on recursion depth to\nlimit the search space of grammar induction models\n(Ponvert et al., 2011;\nNoji and Johnson, 2016;\nShain et al., 2016).\nPonvert et al. (2011) and\nShain et al. (2016) in particular report benefits\nfor depth bounds on grammar acquisition using\nhierarchical sequence models, but either without the\ncapacity to learn full grammar rules (e.g. that a noun\nphrase may consist of a noun phrase followed by a\nprepositional phrase), or with a very large parameter\nspace that may offset the gains of depth-bounding.\nThis work extends the depth-bounding approach\nto directly induce probabilistic context-free grammars,1 which have a smaller parameter space\nthan hierarchical sequence models, and therefore\narguably make better use of the space reductions\nof depth-bounding.\nThis approach employs a\nprocedure for deriving a sequence model from a\nPCFG (van Schijndel et al., 2013), developed in the\ncontext of a supervised learning model, and adapts\nit to an unsupervised setting.\nResults for this model on grammar acquisition from transcribed child-directed speech and\nnewswire text exceed or are competitive with those\nof other models when evaluated on parse accuracy. Moreover, grammars acquired from this model\ndemonstrate a consistent use of category labels, as\nshown in a noun phrase discovery task, something\nwhich has not been demonstrated by other acquisi1\n\nhttps://github.com/lifengjin/db-pcfg\n\n\ftion models.\n\n2 Related work\nThis paper describes a Bayesian Dirichlet model\nof depth-bounded probabilistic context-free grammar (PCFG) induction. Bayesian Dirichlet models have been applied to the related area of latent variable PCFG induction (Johnson et al., 2007;\nLiang et al., 2009), in which subtypes of categories\nlike noun phrases and verb phrases are induced on\na given tree structure. The model described in this\npaper is given only words and not only induces categories for constituents but also tree structures.\nThere are a wide variety of approaches to\ngrammar induction outside the Bayesian modeling\nparadigm.\nThe CCL system (Seginer, 2007a)\nuses deterministic scoring systems to generate bracketed output of raw text.\nUPPARSE\n(Ponvert et al., 2011) uses a cascade of HMM chunkers to produce syntactic structures. BMMM+DMV\n(Christodoulopoulos et al., 2012)\ncombines\nan unsupervised part-of-speech (POS) tagger\nBMMM and an unsupervised dependency grammar inducer DMV (Klein and Manning, 2004).\nThe BMMM+DMV system alternates between phases of inducing POS tags and\ninducing dependency structures.\nA large\namount\nwork\n(Klein and Manning, 2002;\nKlein and Manning, 2004;\nBod, 2006;\nBerg-Kirkpatrick et al., 2010;\nGillenwater et al., 2011;\nHeadden et al., 2009;\nBisk and Hockenmaier, 2013;\nScicluna and de la Higuera, 2014;\nJiang et al., 2016;\nHan et al., 2017) has been\non grammar induction with input annotated\nwith POS tags, mostly for dependency grammar\ninduction. Although POS tags can also be induced, this separate induction has been criticized\n(Pate and Johnson, 2016) for missing an opportunity to leverage information learned in grammar\ninduction to estimate POS tags. Moreover, most\nof these models explore a search space that includes syntactic analyses that may be extensively\ncenter embedded and therefore are unlikely to\nbe produced by human speakers. Unlike most of\nthese approaches, the model described in this paper\nuses cognitively motivated bounds on the depth of\n\nhuman recursive processing to constrain its search\nof possible trees for input sentences.\nSome previous work uses depth bounds in the\nform of sequence models (Ponvert et al., 2011;\nShain et al., 2016), but these either do not\nproduce complete phrase structure grammars\n(Ponvert et al., 2011) or do so at the expense of large\nparameter sets (Shain et al., 2016). Other work implements depth bounds on left-corner configurations\nof dependency grammars (Noji and Johnson, 2016),\nbut the use of a dependency grammar makes the\nsystem impractical for addressing questions of\nhow category types such as noun phrases may be\nlearned. Unlike these, the model described in this\npaper induces a PCFG directly and then bounds it\nwith a model-to-model transform, which yields a\nsmaller space of learnable parameters and directly\nmodels the acquisition of category types as labels.\nSome induction models learn semantic\ngrammars from text annotated with semantic predicates (Zettlemoyer and Collins, 2005;\nKwiatkowski et al., 2012). There is evidence humans use semantic bootstrapping during grammar\nacquisition (Naigles, 1990), but these models typically rely on a set of pre-defined universals, such as\ncombinators (Steedman, 2000), which simplify the\ninduction task. In order to help address the question\nof whether such universals are indeed necessary\nfor grammar induction, the model described in\nthis paper does not assume any strong universals\nexcept independently motivated limits on working\nmemory.\n\n3 Background\nLike\nNoji and Johnson (2016)\nand\nShain et al. (2016), the model described in this\npaper defines bounding depth in terms of memory elements required in a left-corner parse. A\nleft-corner parser (Rosenkrantz and Lewis, 1970;\nJohnson-Laird, 1983;\nAbney and Johnson, 1991;\nResnik, 1992) uses a stack of memory elements\nto store derivation fragments during incremental\nprocessing. Each derivation fragment represents\na disjoint connected component of phrase structure a/b consisting of a top sign a lacking a bottom\nsign b yet to come. For example, Figure 1 shows\nthe derivation fragments in a traversal of a phrase\n\n\fS\nNP\n\nVP\n\nNP\nN\n\nNP\n\nVP\n\nProbabilities from these distributions are then multiplied together to define a transition model M over\nhidden states:\n\nD\n\nN\n\nbroke\n\nVP\n\nman\n\nNP\n\nthe\n\nN\n\nhorse\n\nthe\n\ncart\n\nD\n\nRC\n\npulled\n\nNP\n\nthe\n\n2. boolean variables for decisions to ‘fork out’ ft\nand ‘join in’ jt derivation fragments (in\nJohnson-Laird (1983) terms, to shift with or\nwithout match and to predict with or without\nmatch).\n\nRC\n\nbought\n\nD\n\ntom signs, adt and bdt , of derivation fragments\nat each depth level d (which correspond to left\nand right children in tree structure), and\n\nM[qt−1 ,qt ] = P(qt | qt−1 )\n= P( ft pt jt a1..D\nb1..D\n| qt−1 )\nt\nt\n\n1. preterminal labels pt and labels of top and bot-\n\n(1b)\n\n= P( ft | qt−1 )\n\nFigure 1: Derivation fragments before the word man in\na left-corner traversal of the sentence The cart the horse\nthe man bought pulled broke.\n\nstructure tree for the sentence The cart the horse the\nman bought pulled broke. Immediately before processing the word man, the traversal has recognized\nthree fragments of tree structure: two from category\nNP to category RC (covering the cart and the horse)\nand one from category NP to category N (covering\nthe). Derivation fragments at every time step are\nnumbered top-down by depth d to a maximum depth\nof D. A left-corner parser requires more derivation\nfragments — and thus more memory — to process\ncenter-embedded constructions than to process leftor right-embedded constructions, consistent with\nobservations that center embedding is more difficult\nfor humans to process (Chomsky and Miller, 1963;\nMiller and Isard, 1964).\nGrammar acquisition\nmodels (Noji and Johnson, 2016; Shain et al., 2016)\nthen restrict this memory to some low bound: e.g.\ntwo derivation fragments.\nFor sequences of observed word tokens wt for\ntime steps t ∈ {1..T }, sequence models like\nPonvert et al. (2011) and Shain et al. (2016) hypothesize sequences of hidden states qt . Models like\nShain et al. (2016) implement bounded grammar\nrules as depth bounds on a hierarchical sequence\nmodel implementation of a left-corner parser, using\nrandom variables within each hidden state qt for:\n\n(1a)\n\ndef\n\n· P(pt | qt−1 ft )\n· P( jt | qt−1 ft pt )\n· P(a1..D\n| qt−1 ft pt jt )\nt\n· P(b1..D\n| qt−1 ft pt jt a1..D\n)\nt\nt\n\n(1c)\n\nFor example, just after the word horse is recognized in Figure 1, the parser store contains two\nderivation fragments yielding the cart and the horse,\nboth with top category NP and bottom category RC.\nThe parser then decides to fork out the next word the\nbased on the bottom category RC of the last derivation fragment on the store. Then the parser generates a preterminal category D for this word based on\nthis fork decision and the bottom category of the last\nderivation fragment on the store. Then the parser decides not to join the resulting D directly to the RC\nabove it, based on these fork and preterminal decisions and the bottom category of the store. Finally\nthe parser generates NP and N as the top and bottom\ncategories of a new derivation fragment yielding just\nthe new word the based on all these previous decisions, resulting in the store state shown in the figure.\nThe model over the fork decision (shift with\nor without match) is defined in terms of a depthspecific sub-model θF,d̄ , where ⊥ is an empty derivation fragment and d̄ is the depth of the deepest nonempty derivation fragment at time step t − 1:\ndef\n\nP( ft | qt−1 ) = PθF,d̄ ( ft | bd̄t−1 ); d̄ = max{bdt−1 ,⊥} (2)\nd\n\n\fThe model over the preterminal category label is\nthen conditioned on this fork decision. When there\nis no fork, the preterminal category label is deterministically linked to the category label of the bottom sign of the deepest derivation fragment at the\nprevious time step (using ~φ as a deterministic indicator function, equal to one when φ is true and zero\notherwise). When there is a fork, the preterminal\ncategory label is defined in terms of a depth-specific\nsub-model θP,d̄ :2\nP(pt | qt−1\n\n\n\nif ft = 0\ndef \n~pt =bd̄t−1 \nft ) = \n\nd̄\nPθ (pt | b ) if ft = 1\nP,d̄\nt−1\n\n(3)\n\nThe model over the join decision (predict with or\nwithout match) is also defined in terms of a depthspecific sub-model θJ,d̄ with parameters depending\non the outcome of the fork decision:3\n\nd̄\n\ndef \nPθJ,d¯ ( jt | bd̄−1\nt−1 at−1 ) if ft =0 (4)\nP( jt | qt−1 ft pt ) = \n\nPθ ¯ ( jt | bd̄ pt ) if ft =1\nJ,d+1\nt−1\n\nDecisions about the top categories of derivation\nfragments a1..D\n(which correspond to left siblings in\nt\ntree structures) are decomposed into fork- and joinspecific cases. When there is a join, the top category\nof the deepest derivation fragment deterministically\ndepends on the corresponding value at the previous\ntime step. When there is no join, the top category is\ndefined in terms of a depth-specific sub-model:4\ndef\n\n| qt−1 ft pt jt ) =\nPθA (a1..D\nt\n\n\n\n\nφd̄−2 · ~atd̄−1 = ad̄−1\n\nt−1 \n\n\n\nd̄\nd̄\n\n\nφd̄−1 · PθA,d¯ (at | bd̄−1\nt−1 at−1 )\n\n\n\nφd̄−1 · ~ad̄t = ad̄t−1 \n\n\n\n\n\nd̄+1 | bd̄ p )\n φ · Pθ\n¯ (at\nd̄−0\nA,d+1\nt−1 t\n\n· ψd̄+0\n· ψd̄+1\n· ψd̄+1\n· ψd̄+2\n\nif\nif\nif\nif\n\nft ,\nft ,\nft ,\nft ,\n\njt = 0, 1\njt = 0, 0\njt = 1, 1\njt = 1, 0\n(5)\n\nDecisions about the bottom categories b1..D\nt\n(which correspond to right children in tree structures) also depend on the outcome of the fork and\njoin variables, but are defined in terms of a side- and\n2\n\nHere, again, d̄ = maxd {bdt−1 , ⊥}.\nAgain, d̄ = maxd {bdt−1 , ⊥}.\n1..d¯\nd¯\n4\n, ψd̄ = ~atd̄+1..D = ⊥, and again,\n= at−1\nHere φd̄ = ~a1..\nt\nd\n,\n⊥}.\nd̄ = maxd {bt−1\n3\n\ndepth-specific sub-model in every case:5\ndef\n\nPθB (b1..D\n| qt−1 ft pt jt a1..D\n)=\nt\nt\n\n\nd̄−1 | bd̄−1 ad̄ ) · ψ\n\nφd̄−2 · PθB,R,d−1\n\n¯ (bt\n\nd̄+0\nt−1 t−1\n\n\n\n\n\n· ψd̄+1\nφd̄−1 · PθB,L,d¯ (bd̄t | ad̄t ad̄t−1 )\n\n\n\n· ψd̄+1\nφd̄−1 · PθB,R,d¯ (bd̄t | bd̄t−1 pt )\n\n\n\n\n\nd̄+1\nd̄+1\n φ · Pθ\n| at pt ) · ψd̄+2\n¯ (bt\nd̄−0\nB,L,d+1\n\nif\nif\nif\nif\n\nft , jt = 0, 1\nft , jt = 0, 0\nft , jt = 1, 1\nft , jt = 1, 0\n(6)\n\nIn\na\nsequence\nmodel\ninducer\nlike\nShain et al. (2016), these depth-specific models\nare assumed to be independent of each other and\nfit with a Gibbs sampler, backward sampling\nhidden variable sequences from forward distributions using this compiled transition model M\n(Carter and Kohn, 1996), then counting individual\nsub-model outcomes from sampled hidden variable\nsequences, then resampling each sub-model using\nthese counts with Dirichlet priors over a, b, and p\nmodels and Beta priors over f and j models, then\nre-compiling these resampled models into a new M.\nHowever, note that with K category labels this\nmodel contains DK 2 + 3DK 3 separate parameters\nfor preterminal categories and top and bottom categories of derivation fragments at every depth level,\neach of which can be independently learned by the\nGibbs sampler. Although this allows the hierarchical sequence model to learn grammars that are more\nexpressive than PCFGs, the search space is several\ntimes larger than the K 3 space of PCFG nonterminal\nexpansions. The model described in this paper instead induces a PCFG and derives sequence model\ndistributions from the PCFG, which has fewer parameters, and thus strictly reduces the search space\nof the model.\n\n4 The DB-PCFG Model\nUnlike Shain et al. (2016), the depth-bounded probabilistic context-free grammar (DB-PCFG) model\ndescribed in this paper directly induces a PCFG\nand then deterministically derives the parameters\nof a probabilistic left-corner parser from this single source. This derivation is based on an existing\nderivation of probabilistic left-corner parser models from PCFGs (van Schijndel et al., 2013), which\n¯\n\n¯\n\n1..d\nd\n5\n, ψd̄ = ~btd̄+1..D = ⊥, and again,\n= bt−1\nHere φd̄ = ~b1..\nt\nd̄ = maxd {bdt−1 , ⊥}.\n\n\fwas developed in a supervised parsing model, here\nadapted to run more efficiently within a larger unsupervised grammar induction model.6\nA PCFG can be defined in Chomsky normal form\nas a matrix G of binary rule probabilities with one\nrow for each of K parent symbols c and one column for each of K 2 +W combinations of left and\nright child symbols a and b, which can be pairs of\nnonterminals or observed words from vocabulary W\nfollowed by null symbols ⊥:7\nG=\n\nX\n\nP(c → a b | c) δc (δa ⊗ δb )⊤\n\n(7)\n\na,b,c\n\nA depth-bounded grammar is a set of side- and\ndepth-specific distributions:\nGD = {G s,d | s ∈ {L, R}, d ∈ {1..D}}\n\n(8)\n\nThe posterior probability of a depth-bounded\nmodel GD given a corpus (sequence) of words w1..T\nis proportional to the product of a likelihood and a\nprior:\nP(GD | w1..T ) ∝ P(w1..T | GD ) · P(GD )\n\n(9)\n\nThe likelihood is defined as a marginal over\nbounded PCFG trees τ of the probability of that tree\ngiven the grammar times the product of the probability of the word at each time step or token index t\n6\n\nMore specifically, the derivation differs from that of\nvan Schijndel et al. (2013) in that it removes terminal symbols\nfrom conditional dependencies of models over fork and join decisions and top and bottom category labels, substantially reducing the size of the derived model that must be run during induction.\n7\nThis definition assumes a Kronecker delta function δi , defined as a vector with value one at index i and zeros everywhere\nelse, and a Kronecker product M ⊗ N over matrices M and N,\nwhich tiles copies of N weighted by values in M as follows:\n\n M[1,1] N\n\nM ⊗ N =  M[2,1] N\n..\n\n.\n\nM[1,2] N\nM[2,2] N\n..\n.\n\n\n· · · \n\n· · · \n\n. . \n.\n\n(1’)\n\nThe Kronecker product specializes to vectors as single-column\nmatrices, generating vectors that contain the products of all\ncombinations of elements in the operand vectors.\n\ngiven this tree:8\nP(w1..T | GD ) =\n\nX\nτ\n\nP(τ | GD ) ·\n\nY\n\nP(wt | τ) (10)\n\nt\n\nThe probability of each tree is defined to be the product of the probabilities of each of its branches:9\nY\nP(τ | GD ) =\nPGD (τη → τη0 τη1 | τη )\n(11)\nτη ∈τ\n\nThe probability P(GD ) is itself an integral\nover the product of a deterministic transform φ\nfrom an unbounded grammar to a bounded grammar P(GD | G) = ~GD = φ(G) and a prior over unbounded grammars P(G):\nZ\nP(GD ) =\nP(GD | G) · P(G) · dG\n(12)\nDistributions P(G) for each nonterminal symbol\n(rows) within this unbounded grammar can then be\nsampled from a Dirichlet distribution with a symmetric parameter β:\nG ∼ Dirichlet(β)\n\n(13)\n\nwhich then yields a corresponding transformed\nsample in P(GD ) for corresponding nonterminals.\nNote that this model is different than that of\nShain et al. (2016), who induce a hierarchical HMM\ndirectly.\nA depth-specific grammar GD is (deterministically) derived from G via transform φ with probabilities for expansions constrained to and renormalized\nover only those outcomes that yield terminals within\na particular depth bound D. This depth-bounded\ngrammar is then used to derive left-corner expectations (anticipated counts of categories appearing\nas left descendants of other categories), and ultimately the parameters of the depth-bounded leftcorner parser defined in Section 3. Counts for G are\nthen obtained from sampled hidden state sequences,\nand rows of G are then directly sampled from the\nposterior updated by these counts.\n8\nThis notation assumes the observed data w1..T is a single\nlong sequence of words, and the hidden variable τ is a single\nlarge but depth-bounded tree structure (e.g. a right-branching\ndiscourse structure). Since the implementation is incremental,\nsegmentation decisions may indeed be treated as hidden variables in τ, but the experiments described in Section 5 are run on\nsentence-segmented input.\n9\nHere, η is a node address, with left child η0 and right child\nη1, or with right child equal to ⊥ if unary.\n\n\f4.1\n\nDepth-bounded grammar\n\nIn order to ensure the bounded version of G is a consistent probability model, it must be renormalized in\ntransform φ to assign a probability of zero to any\nderivation that exceeds its depth bound D. For example, if D = 2, then it is not possible to expand a\nleft sibling at depth 2 to anything other than a lexical\nitem, so the probability of any non-lexical expansion\nmust be removed from the depth-bounded model,\nand the probabilities of all remaining outcomes must\nbe renormalized to a new total without this probability. Following van Schijndel et al. (2013), this can\nbe done by iteratively defining a side- and depthspecific containment likelihood h(i)\ns,d for left- or rightside siblings s ∈ {L, R} at depth d ∈ {1..D} at each iteration i ∈ {1..I},10 as a vector with one row for each\nnonterminal or terminal symbol (or null symbol ⊥)\nin G, containing the probability of each symbol generating a complete yield within depth d as an s-side\nsibling:\n\n=0\n(14a)\nh(0)\ns,d\n\n(i−1)\n(i−1)\n\n\nG (1 ⊗ δ⊥ + hL,d ⊗ hR,d ) if d ≤ D + 1\n=\nh(i)\n\n\nL,d\n0\nif d > D + 1\n(14b)\n\n\n\nδT\nif d = 0\n\n\n\n\n(i)\n(i−1)\n(i−1)\nhR,d = \nG (1 ⊗ δ⊥ + hL,d+1 ⊗ hR,d ) if 0 < d ≤ D\n\n\n\n\n0\nif d > D\n(14c)\n\nwhere ‘T’ is a top-level category label at depth zero.\nA depth-bounded grammar G s,d can then be defined to be the original grammar G reweighted and\n\nrenormalized by this containment likelihood:11\nGL,d =\n\nGR,d =\n\nExperiments described in this article use I = 20 following\nobservations of convergence at this point in supervised parsing.\n\nh(I)\nL,d\n(I)\nG diag(1 ⊗ δ⊥ + h(I)\nL,d+1 ⊗ hR,d )\n\nh(I)\nR,d\n\n(15a)\n\n(15b)\n\nThis renormalization ensures the depth-bounded\nmodel is consistent. Moreover, this distinction between a learned unbounded grammar G and a derived bounded grammar G s,d which is used to derive a parsing model may be regarded as an instance\nof Chomsky’s (1965) distinction between linguistic\ncompetence and performance.\nThe side- and depth-specific grammar can then be\nused to define expected counts of categories occurring as left descendants (or ‘left corners’) of rightsibling ancestors:\nE(1)\nd = GR,d (diag(1) ⊗ 1)\n\n(16a)\n\nGL,d\nE(i−1)\nd\nPI\n(i)\ni=1 Ed\n\n(16b)\n\nE(i)\nd\nE+d\n\n=\n=\n\n(diag(1) ⊗ 1)\n\n(16c)\n\nThis left-corner expectation will be used to estimate the marginalized probability over all grammar rule expansions between derivation fragments,\nwhich must traverse an unknown number of left children of some right-sibling ancestor.\n4.2\n\nDepth-bounded parsing\n\nAgain following van Schijndel et al. (2013), the fork\nand join decision, and the preterminal, top and bottom category label sub-models described in Section 3 can now be defined in terms of these sideand depth-specific grammars G s,d and depth-specific\nleft-corner expectations E+d .\nFirst, probabilities for no-fork and yes-fork outcomes below some bottom sign of category b at\ndepth d are defined as the normalized probabilities,\nrespectively, of any lexical expansion of a right sibling b at depth d, and of any lexical expansion following any number of left child expansions from b\n11\n\n10\n\n(I)\nG diag(1 ⊗ δ⊥ + h(I)\nL,d ⊗ hR,d )\n\nwhere diag(v) is a diagonalization of a vector v:\n\n\n0\n· · · \n v[1]\n\n 0\n\nv[2]\ndiag(v) = \n\n ..\n. . \n.\n.\n\n(2’)\n\n\f4.3\n\nat depth d:\nPθF,d (0 | b) =\nPθF,d (1 | b) =\n\nδb ⊤ GR,d (1 ⊗ δ⊥ )\n(17a)\nδb ⊤ (GR,d + E+d GL,d ) (1 ⊗ δ⊥ )\nδb ⊤ E+d GL,d (1 ⊗ δ⊥ )\nδb ⊤ (GR,d + E+d GL,d ) (1 ⊗ δ⊥ )\n\n(17b)\n\nGibbs sampling\n\nGrammar induction in this model then follows a forward-filtering backward-sampling algorithm (Carter and Kohn, 1996). This algorithm first\ncomputes a forward distribution vt over hidden\nstates at each time step t from an initial value ⊥:\n\nThe probability of a preterminal p given a bottom category b is simply a normalized left-corner\nexpected count of p under b:\ndef δb\n\nPθP,d (p | b) =\n\n⊤\n\nE+d δ p\n\nδb ⊤ E+d 1\n\n(18)\n\nYes-join and no-join probabilities below bottom\nsign b and above top sign a at depth d are then defined similarly to fork probabilities, as the normalized probabilities, respectively, of an expansion to\nleft child a of a right sibling b at depth d, and of an\nexpansion to left child a following any number of\nleft child expansions from b at depth d:\nPθJ,d (1 | b a) =\nPθJ,d (0 | b a) =\n\nδb ⊤ GR,d (δa ⊗ 1)\n(19a)\nδb ⊤ (GR,d + E+d GL,d ) (δa ⊗ 1)\nδb ⊤ E+d GL,d (δa ⊗ 1)\nδb ⊤ (GR,d + E+d GL,d ) (δa ⊗ 1)\n\n(19b)\n\nThe distribution over category labels for top\nsigns a above some top sign of category c and below a bottom sign of category b at depth d is defined\nas the normalized distribution over category labels\nfollowing a chain of left children expanding from b\nwhich then expands to have a left child of category c:\nPθA,d (a | b c) =\n\nδb ⊤ E+d diag(δa ) GL,d (δc ⊗ 1)\nδb ⊤ E+d diag(1) GL,d (δc ⊗ 1)\n\n(23a)\n⊤\n\nvt = vt−1 M diag(L δwt )\n\n(23b)\n\nThe algorithm then samples hidden states backward\nfrom a multinomial distribution given the previously\nsampled state qt+1 at time step t+1 (assuming input\nparameters to the multinomial function are normalized):\nqt ∼ Multinom( diag(vt ) M diag(L δwt+1 ) δqt+1 )\n(24)\nGrammar rule applications C are then counted\nfrom these sampled sequences:12\n\n⊤ if f , j = 0, 1\n\n\n¯\n¯ )\nδbd−1\n(δad¯ ⊗ δbd−1\n\nt t\n\nt\n\nt−1\nt−1\n\n\n\nX\nif ft , jt = 0, 0\nδad¯ (δad¯ ⊗ δbd̄ )⊤\n\nt\nt\nt−1\nC=\n\n\n⊤\n\nδbd¯ (δ pt ⊗ δbd¯ )\nif ft , jt = 1, 1\n\nt \n\nt\nt−1\n\n\n\n\nδad+1\n¯\n(δ pt ⊗ δbd̄+1 )⊤ if ft , jt = 1, 0\nt\nt\nX\n⊤\n+\nδ pt (δwt ⊗ δ⊥ )\n(25)\nt\n\nand a new grammar G is sampled from a Dirichlet\ndistribution with counts C and a symmetric hyperparameter β as parameters:\nG ∼ Dirichlet( C + β )\n\n⊤\n\nδa Gs,d (δc ⊗ δb )\nδa ⊤ Gs,d (δc ⊗ 1)\n\n⊤\n\n(20)\n\nThe distribution over category labels for bottom\nsigns b below some sign a and sibling of top sign c\nis then defined as the normalized distribution over\nright children of grammar rules expanding from a\nto c followed by b:\nPθB,s,d (b | a c) =\n\nv0 ⊤ = δ⊥ ⊤\n\n(21)\n\nFinally, a lexical observation model L is defined\nas a matrix of unary rule probabilities with one row\nfor each combination of store state and preterminal\nsymbol and one column for each observation symbol:\nL = 1 ⊗ G (diag(1) ⊗ δ⊥ )\n(22)\n\n(26)\n\nThis grammar is then used to define transition and\nlexical models M and L as defined in Sections 3\nthrough 4.2 to complete the cycle.\n4.4\n\nModel hyper-parameters and priors\n\nThere are three hyper-parameters in the model. K is\nthe number of non-terminal categories in the grammar G, D is the maximum depth, and β is the parameter for the symmetric Dirichlet prior over multinomial distributions in the grammar G.\nAs seen from the previous subsection, the prior\nis over all possible rules in an unbounded PCFG\n12\n\nAgain, d̄ = maxd {adt−1 , ⊥}.\n\n\fgrammar. Because the number of non-terminal categories of the unbounded PCFG grammar is given as\na hyper-parameter, the number of rules in the grammar is always known. It is possible to use nonparametric priors over the number of non-terminal\ncategories, however due to the need to dynamically\nmitigate the computational complexity of filtering\nand sampling using arbitrarily large category sets,\nthis is left for future work.\n\n5 Evaluation\nThe DB-PCFG model described in Section 4\nis evaluated first on synthetic data to determine\nwhether it can reliably learn a recursive grammar\nfrom data with a known optimum solution, and\nto determine the hyper-parameter value for β\nfor doing so. Two experiments on natural data\nare then carried out. First, the model is run on\nnatural data from the Adam and Eve parts of the\nCHILDES corpus (MacWhinney, 1992) to compare with other grammar induction systems on a\nhuman-like acquisition task. Then data from the\nWall Street Journal section of the Penn Treebank\n(Marcus et al., 1993) is used for further comparison\nin a domain for which competing systems are optimized. The competing systems include UPPARSE\n(Ponvert et al., 2011)13 , CCL (Seginer, 2007a)14 ,\nBMMM+DMV with undirected dependency\nfeatures (Christodoulopoulos et al., 2012)15 and\nUHHMM (Shain et al., 2016).16\nFor the natural language datasets, the variously\nparametrized DB-PCFG systems17 are first validated\non a development set, and the optimal system is then\nrun until convergence with the chosen hyperparameters on the test set. In development experiments,\nthe log-likelihood of the dataset plateaus usually after 500 iterations. The system is therefore run at\nleast 500 iterations in all test set experiments, with\none iteration being a full cycle of Gibbs sampling.\n\na) X1\n\nX1\n\nb)\n\nb\n\nX2\n\nd)\n\nX1\n\nX2\n\nX1 X2\n\nX1\n\nX2\n\nX1 X2\n\nb\n\na\n\nb\n\na\n\nX1 X2\n\nX1 X2\na\n\nc) X2\n\na\n\nb\n\na\n\nb\n\nFigure 2:\nSynthetic left-branching (a,b) and rightbranching (c,d) datasets.\n\nThe system is then checked to see whether the loglikelihood has plateaued, and halted if it has.\nThe DB-PCFG model assigns trees sampled from\nconditional posteriors to all sentences in a dataset\nin every iteration as part of the inference. The system is further allowed to run at least 250 iterations\nafter convergence and proposed parses are chosen\nfrom the iteration with the greatest log-likelihood after convergence. However, once the system reaches\nconvergence, the evaluation scores of parses from\ndifferent iterations post-convergence appear to differ\nvery little.\n5.1\n\nSynthetic data\n\nFollowing\nLiang et al. (2009)\nand\nScicluna and de la Higuera (2014),\nan\ninitial\nset of experiments on synthetic data are used\nto investigate basic properties of the model—in\nparticular:\n1. whether the model is balanced or biased in favor of left- or right-branching solutions,\n2. whether the model is able to posit recursive\nstructure in appropriate places, and\n3. what hyper-parameters enable the model to find\noptimal modes more quickly.\n\nThe risk of bias in branching structure is important because it might unfairly inflate induction results on languages like English, which are heavily\nright branching. In order to assess its bias, the model\n13\nhttps://github.com/eponvert/upparse\nis evaluated on two synthetic datasets, each consist14\nhttps://github.com/DrDub/cclparser\n15\ning of 200 sentences. The first dataset is a leftBMMM:https://github.com/christos-c/bmmm\nDMV:https://code.google.com/archive/p/pr-toolkit/ branching corpus, which consists of 100 sentences\n16\nhttps://github.com/tmills/uhhmm/tree/coling16\nof the form a b and 100 sentences of the form a b b\n17\nThe most complex configuration that would run on\n, with optimal tree structures as shown in Figure 2\navailable GPUs was D=2, K=15. Analysis of full WSJ\n(a) and (b). The second dataset is a right-branching\n(Schuler et al., 2010) shows 47.38% of sentences require depth\n2, 38.32% require depth 3 and 6.26% require depth 4.\ncorpus, which consists of 100 sentences of the form\n\n\fa)\nX1\nX1\n\nX2\n\nX1 X2\n\nb\n\na\nc)\n\nX3\n\nX3\n\nX1\n\nc\n\nX1 X2\na\n\nb\n\nd)\nX3\n\nX1 X2\n\nc\n\nb\n\nX1\n\nX3\n\nX1 X2\n\nc\n\na\n\nX1\n\nSystem\nCCL\nUPPARSE\nUHHMM\nBMMM+DMV\nDB-PCFG\n\nX3\n\nb\nX3\n\na\n\nb)\n\nX3\n\nb\n\nX3\n\nX1\n\nX2\n\nX1 X2\n\nb\n\na\n\nb\n\nX1\n\nX2\n\nX1 X2\n\nb\n\nc\n\nb\n\nFigure 3: Synthetic center-embedding structure. Note\nthat tree structures (b) and (d) have depth 2 because they\nhave complex sub-trees spanning a b and a b b, respectively, embedded in the center of the yield of their roots.\n\na b and 100 sentences of the form a a b , with optimal tree structures as shown in Figure 2 (c) and (d).\nResults show both structures (and both corresponding grammars) are learnable by the model, and result in approximately the same log likelihood. These\nsynthetic datasets are also used to tune the β hyperparameter of the model (as defined in Section 4) to\nenable it to find optimal modes more quickly. The\nresulting β setting of 0.2 is then used in induction on\nthe CHILDES and Penn Treebank corpora.\nAfter validating that the model is not biased,\nthe model is also evaluated on a synthetic centerembedding corpus consisting of 50 sentences each\nof the form a b c; a b b c; a b a b c; and a b b a b b c,\nwhich has optimal tree structures as shown in Figure 3.18 Note that the (b) and (d) trees have depth 2\nbecause they each have a complex sub-tree spanning\na b and a b b embedded in the center of the yield of\nthe root. Results show the model is capable of learning depth 2 (recursive) grammars.\nFinally, as a gauge of the complexity of this task,\nresults of the model described in this paper are compared with those of other grammar induction mod18\n\nHyperparameters\nD1K15\nD1K30\nD1K45\nD2K15\n\nX3\n\nX1\n\na\n\nRecall\n71.1\n80.7\n37.7\n83.2\n100.0\n\nF1\n76.7\n85.7\n37.7\n90.5\n100.0\n\nTable 1: The performance scores of unlabeled parse evaluation of different systems on synthetic data.\n\nX3\nX1\n\nPrecision\n83.2\n91.4\n37.7\n99.2\n100.0\n\nHere, in order to more closely resemble natural language\ninput, tokens a, b, and c are randomly chosen uniformly from\n{a1 , . . . , a50 }, {b1 , . . . , b50 } and {c1 , . . . , c50 }, respectively.\n\nPrecision\n57.1\n52.8\n44.4\n44.0\n\nRecall\n70.7\n65.4\n54.9\n54.5\n\nF1\n63.2\n58.5\n49.1\n48.7\n\nTable 2: PARSEVAL results of different hyperparameter\nsettings for the DB-PCFG system on the Adam dataset.\nHyperparameter D is the number of possible depths, and\nK is the number of non-terminals.\n\nels on the center-embedding dataset. In this experiment, all models are assigned hyper-parameters\nmatching the optimal solution. The DB-PCFG is\nrun with K=5 and D=2 and β=0.2 for all priors, the\nBMMM+DMV (Christodoulopoulos et al., 2012) is\nrun with 3 preterminal categories, and the UHHMM\nmodel is run with 2 active states, 4 awaited states\nand 3 parts of speech.19 Table 1 shows the PARSEVAL scores for parsed trees using the learned grammar from each unsupervised system. Only the DBPCFG model is able to recognize the correct tree\nstructures and the correct category labels on this\ndataset, showing the task is indeed a robust challenge. This suggests that hyper-parameters optimized on this dataset may be portable to natural data.\n5.2\n\nChild-directed speech corpus\n\nAfter setting the β hyperparameter on synthetic\ndatasets, the DB-PCFG model is evaluated on\n14,251 sentences of transcribed child-directed\nspeech from the Eve section of the Brown corpus of CHILDES (MacWhinney, 1992). Hyperparameters D and K are set to optimize performance on the Adam section of the Brown Corpus of\nCHILDES, which is about twice as long as Eve. Fol19\n\nIt is not possible to use just 2 awaited states, which is the\ngold setting, since the UHHMM system errors out when the\nnumber of categories is small.\n\n\fSystem\nCCL\nUPPARSE\nUHHMM\nBMMM+DMV\nUHHMM-F\nDB-PCFG\nRight-branching\n\nPrecision\n50.5\n60.5\n55.5\n63.5\n62.9\n64.5\n68.7\n\nRecall\n53.5\n51.9\n69.3\n63.3\n68.4\n80.5\n85.8\n\nF1\n51.9\n55.9\n61.7\n63.4\n65.6\n71.6∗∗\n76.3\n\nTable 3: PARSEVAL scores on Eve dataset for all competing systems. These are unlabeled precision, recall and\nF1 scores on constituent trees without punctuation. Both\nthe right-branching baseline and the best performing system are in bold. (**: p < 0.0001, permutation test)\n\nlowing Seginer (2007a), Ponvert et al. (2011) and\nShain et al. (2016), these experiments leave all\npunctuation in the input for learning, then remove\nit in all evaluations on development and test data.\nModel performance is evaluated against Penn\nTreebank style annotations of both Adam and Eve\ncorpora (Pearl and Sprouse, 2013). Table 2 shows\nthe PARSEVAL scores of the DB-PCFG system\nwith different hyperparameters on the Adam corpus\nfor development.The simplest configuration, D1K15\n(depth 1 only with 15 non-terminal categories), obtains the best score, so this setting is applied to\nthe test corpus, Eve. Results of the D=1, K=15\nDB-PCFG model on Eve are then compared against\nthose of other grammar induction systems which use\nonly raw text as input on the same corpus. Following Shain et al. (2016) the BMMM+DMV system is\nrun for 10 iterations with 45 categories and its output is converted from dependency graphs to constituent trees (Collins et al., 1999). The UHHMM\nsystem is run on the Eve corpus using settings\nin Shain et al. (2016), which also includes a postprocess option to flatten trees (reported here as\nUHHMM-F).\nTable 3 shows the PARSEVAL scores for all the\ncompeting systems on the Eve dataset. The rightbranching baseline is still the most accurate in terms\nof PARSEVAL scores, presumably because of the\nhighly right-branching structure of child-directed\nspeech in English. The DB-PCFG system with only\none memory depth and 15 non-terminal categories\nachieves the best performance in terms of F1 score\nand recall among all the competing systems, signif-\n\nicantly outperforming other systems (p < 0.0001,\npermutation test).20\nThe Eve corpus has about 5,000 sentences with\nmore than one depth level, therefore one might expect a depth-two model to perform better than a\ndepth-one model, but this is not true if only PARSEVAL scores are considered. This issue will be revisited in the following section with the noun phrase\ndiscovery task.\n5.3\n\nNP discovery on child-directed speech\n\nWhen humans acquire grammar, they do not only\nlearn tree structures, they also learn category types:\nnoun phrases, verb phrases, prepositional phrases,\nand where each type can and cannot occur.\nSome of these category types — in particular,\nnoun phrases — are fairly universal across languages, and may be useful in downstream tasks such\nas (unsupervised) named entity recognition. The\nDB-PCFG and other models that can be made to\nproduce category types are therefore evaluated on a\nnoun phrase discovery task.\nTwo metrics are used for this evaluation. First,\nthe evaluation counts all constituents proposed by\nthe candidate systems, and calculates recall against\nthe gold annotation of noun phrases. This metric is\nnot affected by which branching paradigm the system is using and reveals more about the systems’\nperformances. This metric differs from that used by\nPonvert et al. (2011) in that this metric takes NPs at\nall levels in gold annotation into account, not just\nbase NPs.21\nThe second metric, for systems that produce category labels, calculates F1 scores of induced categories that can be mapped to noun phrases. The\nfirst 4,000 sentences are used as the development\nset for learning mappings from induced category labels to phrase types. The evaluation calculates precision, recall and F1 of all spans of proposed categories against the gold annotations of noun phrases\n20\nResulting\nscores\nare\nbetter\nwhen\napplying\nShain et al. (2016) flattening to output binary-branching\ntrees. For the D=1, K=15 model, precision and F1 can be\nraised to 70.31% and 74.33%. However, since the flattening is\na heuristic which may not apply in all cases, these scores are\nnot considered to be comparable results.\n21\nPonvert et al. (2011) define base NPs as NPs with no NP\ndescendants, a restriction motivated by their particular task\n(chunking).\n\n\fSystem\nCCL\nUPPARSE\nUHHMM\nBMMM+DMV\nDB-PCFG (D1K15)\nDB-PCFG (D1K30)\nDB-PCFG (D1K45)\nDB-PCFG (D2K15)\nRight-branching\n\nNP Recall\n35.5\n69.1\n61.4\n71.3\n75.7\n78.6\n76.9\n85.1\n64.2\n\nNP agg F1\n27.4\n61.2\n28.7\n60.7\n64.0\n65.9\n-\n\nTable 4: Performances of different systems for noun\nphrase recall and aggregated F1 scores on the Eve dataset.\n\nin the development set, and aggregates the categories\nranked by their precision scores so that the F1 score\nof the aggregated category is the highest on the development set. The evaluation then calculates the F1\nscore of this aggregated category on the remainder\nof the dataset, excluding this development set.\nThe UHHMM system is the only competing system that is natively able to produce labels for proposed constituents. BMMM+DMV does not produce constituents with labels by default, but can\nbe evaluated using this metric by converting dependency graphs into constituent trees, then labeling\neach constituent with the part-of-speech tag of the\nhead. For CCL and UPPARSE, the NP agg F1 scores\nare not reported because they do not produce labeled\nconstituents.\nTable 4 shows the scores for all systems on the\nEve dataset and four runs of the DB-PCFG system\non these two evaluation metrics. Surprisingly the\nD=2, K=15 model which has the lowest PARSEVAL scores is most accurate at discovering noun\nphrases. It has the highest scores on both evaluation metrics. The best model in terms of PARSEVAL scores, the D=1, K=15 DB-PCFG model, performs poorly among the DB-PCFG models, despite\nthe fact that its NP Recall is higher than the competing systems. The low score of NP agg F1 of\nDB-PCFG at D1K15 shows a diffusion of induced\nsyntactic categories when the model is trying to find\na balance among labeling and branching decisions.\nThe UPPARSE system, which is proposed as a base\nNP chunker, is relatively poor at NP recall by this\ndefinition.\nThe right-branching baseline does not perform\n\nwell in terms of NP recall. This is mainly because\nnoun phrases are often left children of some other\nconstituent and the right branching model is unable to incorporate them into the syntactic structures\nof whole sentences. Therefore although the rightbranching model is the best model in terms of PARSEVAL scores, it is not helpful in terms of finding\nnoun phrases.\n5.4\n\nPenn Treebank\n\nTo further facilitate direct comparison to previous\nwork, we run experiments on sentences from the\nPenn Treebank (Marcus et al., 1993). The first experiment uses the sentences from Wall Street Journal part of the Penn Treebank with at most 20 words\n(WSJ20). The first half of the WSJ20 dataset is used\nas a development set (WSJ20dev) and the second\nhalf is used as a test set (WSJ20test). We also extract\nsentences in WSJ20test with at most 10 words from\nthe proposed parses from all systems and report results on them (WSJ10test). WSJ20dev is used for\nfinding the optimal hyperparameters for both DBPCFG and BMMM-DMV systems.22\nTable 5 shows the PARSEVAL scores of all systems. The right-branching baseline is relatively\nweak on these two datasets, mainly because formal\nwriting is more complex and uses more non-rightbranching structures (e.g., subjects with modifiers\nor parentheticals) than child-directed speech. For\nWSJ10test, both the DB-PCFG system and CCL are\nable to outperform the right branching baseline. The\nF1 difference between the best-performing previouswork system, CCL, and DB-PCFG is highly significant. For WSJ20test, again both CCL and DBPCFG are above the right-branching baseline. The\ndifference between the F scores of CCL and DBPCFG is very small compared to WSJ10, however\nit is also significant.\nIt is possible that the DB-PCFG is being penalized for inducing fully binarized parse trees. The\n22\nAlthough UHHMM also needs tuning, in practice we find\nthat this system is too inefficient to be tuned on a development\nset, and it requires too many resources when the hyperparameters become larger than used in previous work. We believe that\nfurther increasing the hyperparameters of UHHMM may lead to\nperformance increase, but the released version is not scalable to\nlarger values of these settings. We also do not report UHHMM\non WSJ20test for the same scalabilty reason. The results of\nWSJ10test of UHHMM is induced with all WSJ10 sentences.\n\n\fSystem\nCCL\nUPPARSE\nUHHMM\nBMMM+DMV(K10)\nUHHMM-F\nDB-PCFG (D2K15)\nRight-branching\n\nWSJ10test\nPrecision Recall\nF1\n63.4\n71.9\n67.4\n54.7\n48.3\n51.3\n49.1\n63.4\n55.3\n36.2\n40.6\n38.2\n57.1\n54.4\n55.7\n64.5\n82.6\n72.4∗∗\n55.1\n70.5\n61.8\n\nWSJ20test\nPrecision Recall\nF1\n60.1\n61.7\n60.9∗∗\n47.8\n40.5\n43.9\n25.3\n29.0\n27.0\n53.0\n70.5\n60.5\n41.5\n55.3\n47.4\n\nTable 5: PARSEVAL scores for all competing systems on WSJ10 and WSJ20 test sets. These are unlabeled precision,\nrecall and F1 scores on constituent trees without punctuation (**: p <0.0001, permutation test).\n\nSystem\nCCL\nUPPARSE\nDB-PCFG (D2K15)\nRight-branching\n\nWSJ10\nPrecision Recall\n75.3\n76.1\n74.6\n66.7\n65.5\n83.6\n55.2\n70.0\n\nF1\n75.7\n70.5\n73.4\n61.7\n\nWSJ40\nPrecision Recall\n58.7\n55.9\n60.0\n49.4\n47.0\n63.6\n35.4\n47.4\n\nF1\n57.2\n54.2\n54.1\n40.5\n\nTable 6: Published PARSEVAL results for competing systems. Please see text for details as the systems are trained\nand evaluated differently.\n\naccuracy of the DB-PCFG model is dominated by\nrecall rather than precision, whereas CCL and other\nsystems are more balanced. This is an important distinction if it is assumed that phrase structure is binary (Kayne, 1981; Larson, 1988), in which\ncase precision merely scores non-linguistic decisions about whether to suppress annotation of nonmaximal projections. However, since other systems\nare not optimized for recall, it would not be fair to\nuse only recall as a comparison metric in this study.\nFinally, Table 6 shows the published results of different systems on WSJ. The CCL results come from\nSeginer (2007b), where the CCL system is trained\nwith all sentences from WSJ, and evaluated on sentences with 40 words or fewer from WSJ (WSJ40)\nand WSJ10. The UPPARSE results come from\nPonvert et al. (2011), where the UPPARSE system\nis trained using 00-21 sections of WSJ, and evaluated on section 23 and the WSJ10 subset of section\n23. The DB-PCFG system uses hyperparameters optimized on the WSJ20dev set, and is evaluated on\nWSJ40 and WSJ10, both excluding WSJ20dev. The\nresults are not directly comparable, but the results\nfrom the DB-PCFG system is competitive with the\nother systems, and numerically have the best recall\n\nscores.\n\n6 Conclusion\nThis paper describes a Bayesian Dirichlet model\nof depth-bounded PCFG induction. Unlike earlier\nwork this model implements depth bounds directly\non PCFGs by derivation, reducing the search space\nof possible trees for input words without exploding\nthe search space of parameters with multiple sideand depth-specific copies of each rule. Results for\nthis model on grammar acquisition from transcribed\nchild-directed speech and newswire text exceed or\nare competitive with those of other models when\nevaluated on parse accuracy. Moreover, grammars\nacquired from this model demonstrate a consistent\nuse of category labels, something which has not\nbeen demonstrated by other acquisition models.\nIn addition to its practical merits, this model may\noffer some theoretical insight for linguists and other\ncognitive scientists. First, the model does not assume any universals except independently motivated\nlimits on working memory, which may help address\nthe question of whether universals are indeed necessary for grammar induction. Second, the distinction\nthis model draws between its learned unbounded\n\n\fgrammar G and its derived bounded grammar GD\nseems to align with Chomsky’s (1965) distinction\nbetween competence and performance, and has the\npotential to offer some formal guidance to linguistic\ninquiry about both kinds of models.\n\nAcknowledgments\nThe authors would like to thank Cory Shain and\nWilliam Bryce and the anonymous reviewers for\ntheir valuable input. Computations for this project\nwere partly run on the Ohio Supercomputer Center (1987). This research was funded by the Defense Advanced Research Projects Agency award\nHR0011-15-2-0022. The content of the information\ndoes not necessarily reflect the position or the policy of the Government, and no official endorsement\nshould be inferred.\n\nReferences\nSteven P. Abney and Mark Johnson. 1991. Memory requirements and local ambiguities of parsing strategies.\nJ. Psycholinguistic Research, 20(3):233–250.\nTaylor Berg-Kirkpatrick, Alexandre Bouchard-Côté,\nJohn DeNero, and Dan Klein. 2010. Painless unsupervised learning with features. In Human Language\nTechnologies: The 2010 Annual Conference of the\nNorth American Chapter of the Association for Computational Linguistics, number June, pages 582–590.\nYonatan Bisk and Julia Hockenmaier. 2013. An HDP\nModel for Inducing Combinatory Categorial Grammars. Transactions Of The Association For Computational Linguistics.\nRens Bod. 2006. Unsupervised parsing with U-DOP.\nProceedings of the Conference on Computational Natural Language Learning, pages 85–92.\nGlenn Carroll and Eugene Charniak. 1992. Two Experiments on Learning Probabilistic Dependency Grammars from Corpora. Working Notes of the Workshop\non Statistically-Based {NLP} Techniques, (March):1–\n13.\nC K Carter and R Kohn. 1996. Markov Chain Monte\nCarlo in Conditionally Gaussian State Space Models.\nBiometrika, 83(3):589–601.\nOhio Supercomputer Center. 1987. Ohio supercomputer\ncenter. http://osc.edu/ark:/19495/f5s1ph73.\nNoam Chomsky and George A. Miller. 1963. Introduction to the formal analysis of natural languages. In\nHandbook of Mathematical Psychology, pages 269–\n321. Wiley, New York, NY.\n\nNoam Chomsky. 1965. Aspects of the Theory of Syntax.\nMIT Press, Cambridge, MA.\nChristos Christodoulopoulos, Sharon Goldwater, and\nMark Steedman. 2012. Turning the pipeline into a\nloop: iterated unsupervised dependency parsing and\nPoS induction. Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language\nTechnologies-HLT; Workshop on the Induction of Linguistic Structure, pages 96–99.\nAlexander Clark. 2001. Unsupervised induction of\nstochastic context-free grammars using distributional\nclustering. Proceedings of the 2001 workshop on\nComputational Natural Language Learning, 7:1–8.\nMichael Collins, Lance Ramshaw, Jan Hajič, and\nChristoph Tillmann. 1999. A Statistical Parser for\nCzech. Proceedings of the 37th Annual Meeting of the\nAssociation for Computational Linguistics (ACL ’99),\n(405):505–512.\nJennifer Gillenwater, Kuzman Ganchev, João Graça, Fernando Pereira, and Ben Taskar. 2011. Posterior Sparsity in Unsupervised Dependency Parsing. Journal of\nMachine Learning Research, 12:455–490.\nWenjuan Han, Yong Jiang, and Kewei Tu. 2017. Dependency Grammar Induction with Neural Lexicalization\nand Big Training Data. EMNLP, pages 1684–1689.\nZellig Harris. 1954. Distributional structure. In Jerry A\nFodor and Jerrold J Katz, editors, The Structure of\nLanguage: readings in the philosophy of language,\nvolume 10, pages 33–49. Prentice-Hall.\nWilliam P. Headden, III, Mark Johnson, and David McClosky. 2009. Improving unsupervised dependency\nparsing with richer contexts and smoothing. Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the\nAssociation for Computational Linguistics (NAACL\n’09), (June):101–109.\nYong Jiang, Wenjuan Han, and Kewei Tu. 2016. Unsupervised Neural Dependency Parsing . Proceedings of\nthe 2016 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP-16), (61503248):763–\n771.\nMark Johnson, Thomas L Griffiths, and Sharon Goldwater. 2007. Adaptor grammars: A framework for specifying compositional nonparametric Bayesian models.\nIn NIPS, volume 19, page 641.\nPhilip N. Johnson-Laird. 1983. Mental models: Towards a cognitive science of language, inference, and\nconsciousness. Harvard University Press, Cambridge,\nMA, USA.\nRichard Kayne. 1981. Unambiguous Paths. In R May\nand J Koster, editors, Levels of Syntactic Representation, pages 143–183. Foris Publishers.\n\n\fDan Klein and Christopher D Manning. 2002. A generative constituent-context model fo rimproved grammar\ninduction. Proceedings of the Annual Meeting of the\nAssociation for Computational Linguistics.\nDan Klein and Christopher Manning. 2004. Corpusbased induction of syntactic structure: models of dependency and constituency. Proceedings of the Annual Meeting on Association for Computational Linguistics, 1:478–485.\nTom Kwiatkowski, Luke S Zettlemoyer, Sharon Goldwater, and Mark Steedman. 2010. Inducing Probabilistic CCG Grammars from Logical Form with HigherOrder Unification. In EMNLP, pages 1223–1233.\nTom Kwiatkowski, Sharon Goldwater, Luke S. Zettlemoyer, and Mark Steedman. 2012. A probabilistic model of syntactic and semantic acquisition from\nchild-directed utterances and their meanings. In Proceedings of EACL 2012.\nRichard K. Larson. 1988. On the double object construction.\nPercy Liang, Michael I Jordan, and Dan Klein. 2009.\nProbabilistic Grammars and Hierarchical Dirichlet\nProcesses. The Handbook of Applied Bayesian Analysis.\nB. MacWhinney. 1992. The CHILDES project: tools for\nanalyzing talk, volume 8. Lawrence Elrbaum Associates, Mahwah, NJ, third edition.\nMitchell P Marcus, Beatrice Santorini, and Mary Ann\nMarcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. Computational\nLinguistics, 19(2):313–330.\nGeorge A. Miller and Stephen Isard. 1964. Free recall\nof self-embedded english sentences. Information and\nControl, 7:292–303.\nLetitia R. Naigles. 1990. Children use syntax to learn\nverb meanings. The Journal of Child Language,\n17:357–374.\nHiroshi Noji and Mark Johnson. 2016. Using Leftcorner Parsing to Encode Universal Structural Constraints in Grammar Induction. Proceedings of the\nConference on Empirical Methods in Natural Language Processing, pages 33–43.\nJohn K Pate and Mark Johnson. 2016. Grammar induction from ( lots of ) words alone. In Proceedings\nof nternational Conference on Computational Linguistics, pages 23–32.\nLisa Pearl and Jon Sprouse. 2013. Syntactic Islands\nand Learning Biases: Combining Experimental Syntax\nand Computational Modeling to Investigate the Language Acquisition Problem. Language Acquisition,\n20(1):23–68, 1.\nElias Ponvert, Jason Baldridge, and Katrin Erk. 2011.\nSimple Unsupervised Grammar Induction from Raw\n\nText with Cascaded Finite State Models. Proceedings\nof the Annual Meeting of the Association for Computational Linguistics, (1999):1077–1086.\nPhilip Resnik. 1992. Left-corner parsing and psychological plausibility. In Proceedings of COLING, pages\n191–197, Nantes, France.\nStanley J. Rosenkrantz and Philip M. Lewis, II. 1970.\nDeterministic left corner parser. In IEEE Conference\nRecord of the 11th Annual Symposium on Switching\nand Automata, pages 139–152.\nWilliam Schuler, Samir AbdelRahman, Tim Miller, and\nLane Schwartz. 2010. Broad-Coverage Parsing Using Human-Like Memory Constraints. Computational\nLinguistics, 36(1):1–30.\nJames Scicluna and Colin de la Higuera. 2014. PCFG Induction for Unsupervised Parsing and Language Modelling. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages\n1353–1362.\nYoav Seginer. 2007a. Fast Unsupervised Incremental\nParsing. In Proceedings of the Annual Meeting of\nthe Association of Computational Linguistics, number\nJune, pages 384–391.\nYoav Seginer. 2007b. Learning Syntactic Structure.\nPh.D. thesis.\nCory Shain, William Bryce, Lifeng Jin, Victoria Krakovna, Finale Doshi-Velez, Timothy Miller,\nWilliam Schuler, and Lane Schwartz. 2016. MemoryBounded Left-Corner Unsupervised Grammar Induction on Child-Directed Input. Proceedings of the International Conference on Computational Linguistics:\nTechnical Papers, pages 964–975.\nMark Steedman. 2000. The syntactic process. MIT\nPress/Bradford Books, Cambridge, MA.\nMarten van Schijndel, Andy Exley, and William Schuler.\n2013. A Model of Language Processing as Hierarchic\nSequential Prediction. Topics in Cognitive Science,\n5(3):522–540.\nLuke Zettlemoyer and Michael Collins. 2005. Learning\nto map sentences to logical form: Structured classification with probabilistic categorial grammars. In Proceedings of the Proceedings of the Twenty-First Conference Annual Conference on Uncertainty in Artificial\nIntelligence (UAI-05), pages 658–666, Arlington, Virginia. AUAI Press.\nWillem Zuidema. 2003. How the Poverty of the Stimulus Solves the Poverty of the Stimulus. Advances in\nNeural Information Processing Systems 15, 15:51.\n\n\f",
         "train",
         "54339",
         "8974"
        ],
        [
         "34",
         "17216",
         "cs.AI",
         "Artificial Intelligence",
         "1712.02494v1.pdf",
         "Adversarial Examples that Fool Detectors\n\narXiv:1712.02494v1 [cs.CV] 7 Dec 2017\n\nJiajun Lu∗, Hussein Sibai∗, Evan Fabry\nUniversity of Illinois at Urbana Champaign\n{jlu23, sibai2, efabry2}@illinois.edu\n\nAbstract\n\nlinear feature constructions without having strong mathematical constraints on what these constructions do; but taking that position means one cannot use methods that are\nlargely accurate and effective.\nDetectors are not classifiers. A classifier accepts an image and produces a label. In contrast, a detector, like Faster\nRCNN [24, 5], identifies bounding boxes that are “worth\nlabelling”, and then generates labels (which might include\nbackground) for each box. The final label generation\nstep employs a classifier. However, the statistics of how\nbounding boxes cover objects in a detector are complex and\nnot well understood. Some modern detectors like YOLO\n9000 [23] predict boxes and labels using features on a fixed\ngrid, resulting in fairly complex sampling patterns in the\nspace of boxes, and this means that pixels outside a box may\nparticipate in labelling that box. Another important difference is that detectors usually have RoI pooling or feature\nmap resizing, which might be effective at disrupting adversarial patterns. To date, no successful adversarial attack on\na detector has been demonstrated. In this paper, we demonstrate successful adversarial attacks on Faster RCNN, which\ngeneralize to YOLO 9000.\nWe also discuss the generalization ability of adversarial\nexamples. We say that an adversarial perturbation generalizes if, when circumstances (digital or physical) change,\nthe corresponding images remain adversarial. For example,\na perturbation of a stop sign generalizes over different distances if it remains adversarial when the camera approaches\nthe stop sign. An example generalizes better if it remains\nadversarial for more cases (e.g. changes of detector, background and lighting). If an adversarial example cannot generalize, it is not a threat in the majority of real world systems.\nOur contributions in this paper are as follows:\n\nAn adversarial example is an example that has been adjusted to produce a wrong label when presented to a system at test time. To date, adversarial example constructions\nhave been demonstrated for classifiers, but not for detectors. If adversarial examples that could fool a detector exist, they could be used to (for example) maliciously create\nsecurity hazards on roads populated with smart vehicles.\nIn this paper, we demonstrate a construction that successfully fools two standard detectors, Faster RCNN and YOLO.\nThe existence of such examples is surprising, as attacking a\nclassifier is very different from attacking a detector, and that\nthe structure of detectors – which must search for their own\nbounding box, and which cannot estimate that box very accurately – makes it quite likely that adversarial patterns are\nstrongly disrupted. We show that our construction produces\nadversarial examples that generalize well across sequences\ndigitally, even though large perturbations are needed. We\nalso show that our construction yields physical objects that\nare adversarial.\n\n1. Introduction\nAn adversarial example is an example that has been adjusted to produce a wrong label when presented to a system at test time. In the literature, adversarial examples with\nimperceivable perturbations and unexpected properties (e.g.\ntransferability) are one of the biggest mysteries of neural\nnetworks. There is a range of constructions [19, 21, 20] that\nyield adversarial examples for image classifiers, and there\nis good evidence that small imperceivable adjustments suffice. Furthermore, Athalye et al. [1] show that it is possible\nto build a physical object with visible perturbation patterns\nthat is persistently misclassified by standard image classifiers from different view angles at a roughly fixed distance.\nThere is good evidence that adversarial examples built for\none classifier will fool others, too [22, 14]. The success of\nthese attacks can be seen as a warning not to use highly non∗ Both\n\n• We demonstrate a method to construct adversarial examples that fool Faster RCNN digitally; examples produced by our method are reliably either missed or mislabeled by the detector. These examples without modification also fool YOLO 9000, indicating that the construction produces examples that can transfer across\nmodels.\n\nauthors contributed equally\n\n1\n\n\f• Our adversarial examples can be physically created\nsuccessfully, and they still can fool detectors in suitable circumstances. They can also slip through recent\nstrong image processing defenses against adversarial\nexamples.\n• In practice, we find that adversarial examples require\nquite large disruptions to the pattern on the object in\norder to fool detectors. Physical adversarial examples\nrequire bigger disruptions than digital examples to succeed.\n\n2. Background\nAdversarial examples are of interest mainly because the\nadjustments required seem to be very small and are easy\nto obtain [30, 9, 8]. Numerous search procedures generate adversarial examples [19, 21, 20]; all searches look for\nan example that is (a) “near” a correctly labelled example\n(typically in L1 or L2 norm), and (b) mislabelled. Printing\nadversarial images then photographing them can retain their\nadversarial property [13, 1], which suggests that adversarial\nexamples might exist in the physical world. Their existence\ncould cause a great deal of mischief. There is some evidence that it is difficult to build physical examples that fool\na stop sign detector [16]. In particular, if one actually takes\na video of an existing adversarial stop sign, the adversarial pattern does not appear to affect the performance of the\ndetector by much. Lu et al. speculated that this might be because adversarial patterns were disrupted by being viewed\nat different scales, rotations, and orientations. This created\nsome discussion. OpenAI demonstrated a search procedure\nthat could produce an image of a cat that was misclassified\nwhen viewed at multiple scales [1]. There is some blurring of the fur texture on the cat they generate, but this\nwould likely be imperceptible to most observers. OpenAI\nalso demonstrated an adversarial image of a cat that was\nmisclassified when viewed at multiple scales and orientations [1]. However, there are significant visible artifacts on\nthat image; few would think that it had not been obviously\ntampered with.\nRecent work has demonstrated physical objects that are\npersistently misclassified from different angles at a roughly\nfixed distance [1]. The search procedure manipulates the\ntexture map T of the object. The procedure samples a set of\nviewing conditions Vi for the object, then renders to obtain\nimages I(Vi , T ). Finally, the procedure adjusts the texture\nmap to obtain images that are (a) close to the original images and (b) have high probability of misclassification. The\nadversarial properties of the resulting objects are robust to\nthe inevitable errors in color, etc., in producing physical objects from digital representations.\nDefences: There is fair evidence that it is hard to\ntell whether an example is adversarial (and so (a) evi-\n\ndence of an attack and (b) likely to be misclassified) or\nnot [27, 10, 28, 18, 4, 7]. Current procedures to build adversarial examples for deep networks appear to subvert the\nfeature construction implemented by the network to produce odd patterns of activation in late stage ReLU’s; this\ncan be exploited to build one form of defence [15]. There is\nsome evidence that other feature constructions admit adversarial attacks, too [18]. However, adversarial attacks typically introduce unnatural (if small) patterns into images,\nand image processing methods that remove such patterns\nyield successful defenses. Guo et al. showed that cropping\nand rescaling, bit depth reduction, JPEG compression and\ndecompression, resampling and reconstructing using total\nvariation criteria, and image quilting all provide quite effective ways of removing adversarial patterns [11].\nDetectors and classifiers: It is usual to attack classifiers, and all the attacks we are aware of attack on classifiers. However, for many applications, classifiers are not\nuseful by themselves. Road sign is a good example. A\nroad sign classifier would be applied to images that consist largely of a road sign (e.g. those of [29]). But there\nis little application need for a road sign classifier except as\na component of a road sign detector, because it is unusual\nin practice to deal with images that consist largely of road\nsign. Instead, one usually deals with images that contain\nmany things, and must find and label the road sign. It is\nnatural to study road sign classifiers (e.g. [26]) because image classification remains difficult and academic studies of\nfeature constructions are important. But there is no particular threat posed by an attack on a road sign classifier. An\nattack on a road sign detector is an entirely different matter.\nFor example, imagine the danger if one could get a template\nthat, with a can of spray paint, could ensure that a detector\nreads a stop sign as a yield sign (or worse!). As a result, it\nis important to know whether (a) such examples could exist\nand (b) how robust their adversarial property is in practice.\nRecently, Evtimov et al. have shown several physical\nstop signs that are misclassified [6]. They cropped the stop\nsigns from the frames before presenting them to the classifier. By cropping, they have proxied the box-prediction\nprocess in a detector; however, their attack is not intended\nas an attack on a detector (the paper does not use the word\n“detector”, for example). Lu et al. showed that their construction does not fool a standard detector [17], likely because the cropping process does not proxy a detector’s box\nselection well, and suggested that constructing an adversarial example that fools a detector might be hard. Figure 1\nshows their stop signs presented in [6] are reliably detected\nby Faster RCNN.\n\n3. Method\nWe propose a method to generate digital and physical\nadversarial examples that are robust to changes of viewing\n\n\ffunction of T , that is\nΦ(T ) =\n\nFigure 1. Evtimov et al. [6] generated physical stop signs that are\nmisclassified, however, these stop signs are reliably detected by\nFaster RCNN. Images from Figure 10 in [17].\n\nconditions. Our registration and reconstruction based approach generates adversarial perturbations from video sequences of an object with moving cameras. We require the\nobjects in the videos to be accurately aligned in 3D space.\nWe can easily register stop signs as they are 2D polygons.\nMoreover, we can accurately register face images to a virtual 3D face model. Hence, we perform our experiments on\nthese two types of data.\n\n3.1. Approach for stop signs\n\nN\n1 X\nmean\nφs (b)\nN i=1 b ∈ Bs (I(Mi , T ))\n\npossibly subject to some constraint on T , such as being\nclose to a normal stop sign in L2 distance. We have also\ninvestigated minimizing the maximum score for all the stop\nsign proposals, and found that minimizing the mean score\ngives slightly better results.\nMinimization procedure: First, we compute ∇T Φ(T )\nmean\nby computing ∇I\nφ (b). The gradients\nb ∈ Bs (I(Mi , T ) s\nin the frame coordinate system are mapped to the root coordinate system with inverse view mapping M−1\ni , and then\nare cropped to the extent of T in that coordinate system.\nWe average gradients mapped from all N training frames.\nHowever, directly using the gradients to take large steps frequently stalls the optimization process. Instead, we find that\ncomputing the descent direction with the sign of the gradients for given pattern T (n) (n stands for iteration number)\nfacilitates the optimization process.\nd(n) = sign(∇T Φ(T (n) )).\nWe choose a very small step length \u000f such that \u000fd(n) represents an update of one least significant bit, which leads to\nan optimization step of form\nT (n+1) = T (n) + \u000fd(n) .\n\nWe use the stop sign example to demonstrate our attack,\nwhich extends to other objects that are registered from image domain to some root coordinate system (e.g. faces in\nsection 3.2). We search for an adversarial pattern that (a)\nlooks like a stop sign and (b) fools Faster RCNN. We select a set of N diverse frames Ii as the training examples to\ngenerate the pattern. A stop sign is represented as a texture\nmap T in some root coordinate system. We construct (currently by hand) correspondences between eight vertices on\nthe stop sign instances in training frames and the vertices\nof T . We use these correspondences to estimate a viewing\nmap Mi , which maps the texture T in the root coordinate\nsystem to the appropriate pattern in training frame Ii . We\nalso incorporate in Mi the illumination intensity, which is\nestimated by computing the average intensity over the stop\nsign in the image. Relative illumination intensities are used\nto scale the adversarial perturbations. We write I(Mi , T )\nfor the image frame obtained by superimposing T on the\nframe Ii using the mapping Mi ; Bs (I) for the set of stop\nsign bounding boxes obtained by applying Faster RCNN to\nthe image I; and φs (b) for the score produced by Faster\nRCNN’s classifier for a stop sign in box b. To produce an\nadversarial example, we minimize the mean score for a stop\nsign produced by Faster RCNN in all training images as a\n\nThe optimization process usually takes hundreds or even\nthousands of steps. One termination criterion is to stop the\noptimization when the pattern fools the detector more than\n90% of the cases on the validation set. Another termination\ncriterion is a fixed number of iterations.\nWhy large steps are hard: In our experiments, taking\nlarge steps with unsigned gradients stalls the optimization\nprocess, and we believe large steps are hard to take for\ntwo reasons. First, each instance of the pattern occurs at\na different scale, meaning that there must be some up- or\ndown-sampling of the gradients when mapped to the root\ncoordinate system. Although we register the images with\nsubpixel accuracy, and use a bilinear method to interpolate\nthe transformation process, signal losses are still inevitable.\nIn section 4.2, we show some evidence that this effect may\nmake our patterns more, rather than less, robust. Second,\nthe structure of the network means that the gradient is a\npoor guide to the behavior of φs (b) over large scales. In\nparticular, a ReLU network divides its input space into a\nvery large number of cells, and values at any layer before\nthe softmax layer are a continuous piecewise linear function within a cell. Because the network is trained to have a\n(roughly) constant output for large pieces of its input space,\n\n\fthe gradient must wiggle from cell to cell, and so may be a\npoor guide to the long scale behavior of the function.\nConstraining distance to the original stop sign: In order to create less perceivable adversarial perturbations, we\nconstrain the distance to the original stop sign to be small.\nAn L2 distance loss is added to the cost function, and we\nminimize\nΦ(T ) + λ||T − T\n\n(0) 2\n\n||\n\nOur experiments show that this distance constraint still cannot help to create small perturbations, but greatly changes\nthe pattern of the perturbations, refer to Figure 6.\nWe create our physical adversarial stop signs by printing\nthe pattern T , cutting out the printed stop sign area, and\nsticking it to an actual stop sign (30 in by 30 in).\n\nOriginal Image Detected\n\nWhole Image Attacked\n\nSign Region Attacked\n\nFigure 2. Modifying a single stop sign image to attack Faster\nRCNN is successful. In the original stop sign image (first), the\nstop sign is reliably detected. In the second image, small perturbations are added to the whole image, and the stop sign is not\ndetected. In the last image, small perturbations are added to the\nstop sign region instead of the whole image, and the stop sign is\ndetected as a vase.\nOriginal Image Detected\n\nWhole Image Attacked\n\nFace Region Attacked\n\n3.2. Extending to faces\nWe extend the experiments onto faces, which have complex geometries and larger intra class variances, to demonstrate that our analysis generalizes to other classes. In the\nface setting, we search for a pattern that fools a Faster\nRCNN based face detector [12] and looks like the original face. Our root coordinate system for faces is a virtual high quality face mesh generated from morphable face\nmodel [2]. For video sequences of a face, we reconstruct the\ngeometry of the face in the input frames using morphable\nface model built from the FaceWarehouse [3] data. The\nmodel produces a 3D face mesh F (wi , we ) that is a function\nof identity parameters wi , and expression parameters we .\nFaceTracker [25] is used to detect landmarks li on the face\nframes, then we recover parameters and poses of the face\nmesh by minimizing the distances between the projected\nlandmark vertices and their corresponding landmark locations on the image planes. This construction gives us pixelto-mesh and mesh-to-pixel dense correspondences between\nall face frames and the root face coordinate system (shared\nface mesh). By projecting image pixels to the face meshes\nvia barycentric coordinates, we can achieve subpixel accurate pixel-to-pixel registrations between all face frames (via\nroot coordinate system). This correspondences are used to\ntransfer the gradients from face image coordinates to the\nroot coordinate system, then we merge the gradients from\nmultiple images and reverse transfer the merged gradients\nback to the face image coordinates.\n\n4. Results\nIn this section, we describe in depth the experiments\nwe did and the results we got. Our supplementary\nmaterials include videos and more results, and it can\nbe downloaded from http://jiajunlu.com/docs/\nadvDetector_supp.zip. Our high resolution paper can be downloaded from http://jiajunlu.com/\n\nFigure 3. Modifying a face image to attack Faster RCNN is successful. In the original face image (first), the face is reliably detected. In the second image, small perturbations are added to the\nwhole image, and the face is not detected. In the last image,\nslightly larger perturbations are added to the face region instead\nof the whole image, and the face is not detected.\n\ndocs/advDetector.pdf. But let us first give a quick\noverview of our findings:\n• Adding small perturbations suffices to fool a given object detector on a single image.\n• Enforcing the adversarial perturbations to generalize\nacross view conditions requires significant changes to\nthe pattern.\n• Our successful attacks for Faster RCNN generalize to\nYOLO.\n• Our successful attacks with very large perturbations\ngeneralize to the physical world objects in suitable circumstances.\n• Simple defenses fail to defeat adversarial examples\nthat can generalize.\nDetectors are affected by internal thresholds. Faster\nRCNN uses a non maximum suppression threshold and a\nconfidence threshold. For stop signs, we used the default\nconfigurations. For faces, we found the detector is too willing to detect faces, and we made it less responsive to faces\n(nms from 0.15 to 0.3, and conf from 0.6 to 0.8). We used\ndefault YOLO configurations.\n\n\fOriginal\nSequence\n\nAttacked\nSequence\n\nFigure 4. Adversarial examples of stop signs for Faster RCNN that can generalize across view conditions. The original sequence in the first\nrow is a test video sequence captured for a real stop sign, and the stop sign is detected in all the frames. We apply our attack to a training\nset of videos to generate a cross view condition adversarial perturbation, and apply that perturbation on this test sequence to generate the\nattacked sequence in the second row. This is a digital attack, and the stop sign is either not detected or detected as a kite.\n\nOriginal\nSequence\n\nAttacked\nSequence\n\nFigure 5. Adversarial examples of faces for Faster RCNN based face detector [12] that can generalize across view conditions. The original\nsequence images in the first row are sampled from a test video sequence, and all the faces are reliably detected. We apply our attacking\nmethod to a training set of videos to generate a cross view condition adversarial perturbation, and apply that perturbation on this test\nsequence to generate the attacked sequence in the second row. This is a digital attack.\n\n4.1. Attacking single image\nWe can easily adjust a pattern on a single image to fool\na detector (stop signs in Figure 2 and faces in Figure 3),\nand the change on the pattern is tiny. While this is of no\npractical significance, it shows our search method can find\nvery small adversarial perturbations.\n\n4.2. Generalizing across view conditions\nWhat we are really interested in is to produce a pattern\nthat fails to be detected in any image. This is much harder\nbecause our pattern needs to generalize to different view\nconditions and so on. We can still find adversarial patterns\nin this situation, but the patterns found by our process involve significant changes of the stop signs and faces.\nStop sign dataset: we use a Panasonic HC-V700M HD\ncamera to take 22 videos of the camera approaching stop\nsigns, and extract 5 diverse frames from each video. Then\nwe manually register all the stop signs, and use our attacking method to generate a unified adversarial perturbation\nfor all the frames. We use 12 videos for generating adversarial perturbations (training), 5 videos for validation, and\n5 videos for evaluation (testing). We use the validation set\n\nFigure 6. We generate three adversarial stop signs with our attacking method. The first stop sign does not use L2 distance penalty,\nand use termination criterion of successfully attacking 90% of validation images. The second stop sign uses L2 distance penalty\nin the objective function, and terminates when 90% of validation\nimages are attacked. The last stop sign also adopts L2 distance\npenalty, but performs a large fixed number of iterations. All three\npatterns reliably fool detectors when mapped into videos. However, physical instances of these patterns are not equally successful. The first two stop signs, as physical objects, only occasionally\nfool Faster RCNN; the third one, which has a much more extreme\npattern, is more effective.\n\ntermination criteria described in Section 3.1. Figure 4 gives\nan example video sequence, and its corresponding attacked\nvideo sequence. Table 1 shows the stop sign detection rates\nin different circumstances. We plan to release the labelled\n\n\fSeq 1\n\nSeq 2\n\nSeq 3\n\nFigure 7. We print the three adversarial stop signs from Figure 6, and stick them to a real stop sign. We took videos while driving by these\nprinted stop signs, and ran Faster RCNN on these videos. Notice that all of the adversarial perturbations generalize well digitally. We only\nrender the detection results for stop signs to make the figures clean. The three sequences in this figure correspond to the three stop signs\nin order. In the first two sequences, stop signs are detected without trouble, while in the last sequence, the stop sign is not detected in the\nvideo, so it is a physical adversarial stop sign. This may be the result of poor texture contrast against the tree, though this sequence was not\nseen in training.\n\ndataset.\nFace dataset:: we use a SONY a7 camera to take 5\nvideos of a still face from different distances and angles,\nand extract 20 diverse frames from each video. We use the\nmorphable face model approach to register all the faces, and\nuse our attacking method to generate a unified adversarial\nperturbation. We use 3 videos for generating adversarial\nperturbations (training), 1 video for validation, and 1 video\nfor evaluation (testing). Again, we use the validation set termination criteria described in Section 3.1. Figure 5 shows\nan example video sequence, and its corresponding attacked\nvideo sequence. In our experiments, this is the smallest perturbations on faces that could generalize. Table 2 shows\nthe face detection rates in different circumstances. Also, we\nplan to release the processed dataset.\nIn summary, it is possible to attack stop signs and faces\nfrom multiple images, and require them to generalize to new\nsimilar view condition images. However, both of them require strong perturbation patterns to generalize. Refer to\nsupplementary materials for details.\n\nproperties, view conditions, printing errors, lighting, etc. In\nthis paper, we print stop signs and perform physical experiments with them, but we believe similar conclusions apply\nto faces.\nWe performed physical experiments with three adversarial perturbation patterns in Figure 6. Our results in Table 3\nshow that the two less perturbed stop signs can still be detected by Faster RCNN, while the one with large perturbations is hard to detect. The frames for physical experiments\ncould be found in Figure 7. Refer to our supplementary materials for videos.\nWe performed analysis with the data from Table 1 and\nTable 3. L1 regularized logistic regression is used to predict\nthe success of our many different cases. The most important\nvariable is detector (generalization from Faster RCNN to\nYOLO is not strong); then whether the adversarial example\nis physical or not (digital attacks are more effective than\nphysical); then scale (it is hard to make a detector to miss a\nnearby stop sign).\n\n4.4. Generalizing to YOLO\n4.3. Generalizing to the physical world\nThere is a big gap between attacks in the digital world\nand attacks in the physical world, which means the adversarial perturbations that generalize well in the digital world\nmay not generalize to the physical world. We suspect this\ngap is due to various practical concerns, such as sensor\n\nAdversarial examples for a certain classifier generalize\nacross different classifiers. To test out whether adversarial examples for Faster RCNN generalize across detectors,\nwe feed these images into YOLO. We categorize our adversarial examples into three categories: single image examples with small perturbations, multiple image examples\n\n\fTree bg - L\nTree bg - EL\nSky bg - L\nSky bg - EL\n\nStop1\nStop2\nStop3\nStop1\nStop2\nStop3\n\ntest - far\n0/4 ; 4/4\n0/4 ; 4/4\nn/a ; n/a\n0/6 ; 6/6\n0/6 ; 6/6\n0/4 ; 3/4\n\ntest - medium\n0/4 ; 1/4\n1/4 ; 3/4\nn/a ; n/a\n0/6 ; 5/6\n0/6 ; 6/6\n0/4 ; 1/4\n\ntest - near\n0/2 ; 2/2\n0/2 ; 2/2\nn/a ; n/a\n0/3 ; 3/3\n0/3 ; 3/3\n0/4 ; 3/4\n\ntrain - far\n0/10 ; 6/10\n2/10 ; 1/10\n1/5 ; 5/5\n0/14 ; 13/14\n0/14 ; 13/14\n0/5 ; 5/5\n\ntrain - medium\n0/10 ; 1/10\n1/10 ; 0/10\n0/5 ; 0/5\n0/14 ; 12/14\n2/14 ; 12/14\n0/5 ; 5/5\n\ntrain - near\n0/5 ; 5/5\n2/5 ; 3/5\n0/4 ; 1/4\n0/7 ; 6/7\n1/7 ; 6/7\n0/4 ; 4/4\n\nval - far\n1/4 ; 3/4\n0/4 ; 1/4\nn/a ; n/a\n0/6 ; 6/6\n0/6 ; 6/6\nn/a ; n/a\n\nval - medium\n0/4 ; 3/4\n0/4 ; 0/4\nn/a ; n/a\n0/6 ; 5/6\n0/6 ; 5/6\nn/a ; n/a\n\nval - near\n0/2 ; 2/2\n0/2 ; 0/2\nn/a ; n/a\n0/3 ; 2/3\n1/3 ; 2/3\nn/a ; n/a\n\nTable 1. This table reports the detection rates of Faster RCNN and YOLO for the multiple image digital attacks of stop signs. In each cell,\nthe ratio before semicolon represents the detection rate for Faster RCNN, and the ratio after semicolon represents the detection rate for\nYOLO. Tree bg means the background of the stop sign is tree and has low contrast, and the Sky bg means the background of the stop sign\nis sky and has high contrast. L following the background means the perturbations are large, and EL means the perturbations are extremely\nlarge. We have three dark stop signs, and the detection rates are calculated at three different distances (far/medium/near) on train/val/test\nsplits. We can attack Faster RCNN with multiple view conditions, and the adversarial perturbations generalize to new view conditions.\nThe adversarial examples also generalize to YOLO, especially when the background is tree.\n\nS100 small perturbation\nS100 medium perturbation\nS100 large perturbation\nS15 large perturbation\n\nft-far\n2/3\n3/3\n0/3\n0/1\n\nft-near\n2/4\n2/4\n0/4\nn/a\n\ntest\nsd-far\n6/6\n6/6\n1/6\n0/2\n\nsd-near\n6/7\n3/7\n0/7\nn/a\n\nft-far\n0/19\n5/19\n0/19\n0/3\n\ntrain\nfront-near sd-far\n0/21\n0/9\n1/21\n1/9\n0/21\n0/9\n0/2\n0/2\n\nsd-near\n0/11\n0/11\n0/11\n0/2\n\nft-far\n1/4\n2/4\n0/4\n0/1\n\nft-near\n6/8\n4/8\n0/8\nn/a\n\nval\nsd-far\n3/4\n4/4\n0/4\n0/2\n\nsd-near\n3/4\n3/4\n0/4\nn/a\n\nTable 2. This table reports the detection rates of Faster RCNN based face detector [12] for multiple image digital attacks of faces. S100\nmeans there are 100 images in the experiments, and S15 means there are 15 images. Ft means frontal face, and sd means side face. When\nsmall perturbations are applied, attacks on all the training images succeed, but do not generalize to the validation and testing images. Only\nwhen large perturbations are applied, the attacks generalize to different view conditions.\n\nTree bg - L\n\nTree bg - EL\n\nSky bg - L\n\nSky bg - EL\n\nDark-Stop1\nDark-Stop2\nBright-Stop1\nBright-Stop2\nDark-Stop3\nBright-Stop3\nDark-Stop1\nDark-Stop2\nBright-Stop1\nBright-Stop2\nDark-Stop3\nBright-Stop3\n\nfar - adv\n2/17 ; 4/17\n4/17 ; 5/17\n10/17 ; 16/17\n1/17 ; 2/17\n0/17 ; 0/17\n0/17 ; 0/17\n1/19 ; 5/19\n0/25 ; 14/25\n5/26 ; 23/26\n1/23 ; 16/23\n14/27 ; 16/27\n0/28 ; 11/28\n\nfar - clean\n16/17 ; n/a\nn/a ; n/a\n17/17 ; n/a\n14/17 ; n/a\n17/17 ; n/a\n11/17 ; n/a\n0/19 ; n/a\n2/25 ; n/a\n0/26 ; n/a\n0/23 ; n/a\n20/27 ; n/a\n0/24 ; n/a\n\nmedium - adv\n11/12 ; 12/12\n6/11 ; 10/11\n15/15 ; 15/15\n10/12 ; 12/12\n4/14 ; 10/14\n1/11 ; 3/11\n9/11 ; 11/11\n5/15 ; 11/15\n10/11 ; 11/11\n10/11 ; 9/11\n3/13 ; 11/13\n0/13 ; 10/13\n\nmedium - clean\n12/12 ; n/a\nn/a ; n/a\n15/15 ; n/a\n12/12 ; n/a\n14/14 ; n/a\n11/11 ; n/a\n0/13 ; n/a\n1/15 ; n/a\n1/11 ; n/a\n0/11 ; n/a\n13/13 ; n/a\n2/13 ; n/a\n\nnear - adv\n8/8 ; 8/8\n0/14 ; 12/14\n12/12 ; 12/12\n5/8 ; 8/8\n8/11 ; 7/11\n0/7 ; 1/7\n16/16 ; 16/16\n24/24 ; 11/24\n21/21 ; 21/21\n20/24 ; 19/24\n26/27 ; 26/27\n22/24 ; 10/24\n\nnear - clean\n8/8 ; n/a\nn/a ; n/a\n12/12 ; n/a\n8/8 ; n/a\n11/11 ; n/a\n7/7 ; n/a\n14/16 ; n/a\n22/24 ; n/a\n14/21 ; n/a\n18/24 ; n/a\n27/27 ; n/a\n18/24 ; n/a\n\nTable 3. The detection rates of the physical adversarial stop signs and physical clean stop signs with Faster RCNN and YOLO in different\ncircumstances. The table layout is similar to Table 1. We have two stop signs with different brightness for large perturbations, and one stop\nsign with different brightness for extremely large perturbations. We report both detection rates for 30 x 30 inches adversarial stop signs\n(adv) and 20 x 20 inches clean normal stop signs when applicable (clean).\n\nwith large perturbations that generalize across viewing conditions digitally, and physical examples with large perturbations. Our experiments show that small perturbations do not\ngeneralize to YOLO, while obvious perturbation patterns\ncan generalize to YOLO with good probability. Examples\nare given in Figure 8, and detection rates can be found in\nTable 3 and Table 1.\n\n4.5. Localized attacks fail\nIn previous settings, we attack the whole masked objects\nin the images, however, it is usually hard to apply such attacks in the physical world. For example, modifying the\nwhole stop sign patterns is useless in practice, and wearing\na whole face mask with perturbation patterns is hard too. It\nwould be more effective attack if one can manufacture small\nstickers with perturbation patterns, and when the sticker is\nattached to a small region of the stop sign or the face fore-\n\n\fSingle\nSingle\nImage\n\nMultiple\n\nPhysical\nMultiple\nImage\n\nPhysical\n\nFigure 8. We test whether adversarial examples generated from\nFaster RCNN generalize to YOLO. In the first row, these adversarial examples are generated for a single image with small perturbations. YOLO can detect these stop signs without trouble. In the\nsecond row, these adversarial examples are generated from multiple images, and the digitally perturbed images can fool YOLO in\nabout half of the times. In the last row, physically printed adversarial stop signs can still fool YOLO in some circumstances. The\ndetailed summary can be found in Table 1 and Table 3.\n\nstop1\nstop2\nstop3\nstop1\nstop2\nstop3\n\nNonAttack\n10/10\n110/110\n110/110\n40/40\n109/187\n77/159\n151/205\n\nAdversarial\n0/10\n1/110\n10/110\n1/40\n121/185\n86/201\n78/209\n\nUP\n10/10\n8/110\n18/110\n1/40\n118/185\n84/201\n72/209\n\nTV\n10/10\n8/110\n9/110\n2/40\n116/185\n88/201\n85/209\n\nTable 4. We evaluate the effectiveness of simple defense methods.\nUP means downsample the input image resolution by half, and\nthen upsample it to the original size. TV means total variation\ndenoise, which removes high frequency information. The physical\nnon attack numbers are counted from a real stop sign near our\nadversarial one. These simple defense methods are effective for\nsingle image perturbations, but not effective for multiple image\nperturbations that can generalize. They also cannot defeat physical\nadversarial perturbations.\n\nOriginal\n\nUp-Down Sample\n\nTV Denoise\n\nSingle\nImage\n\nMultiple\nImage\n\nFigure 9. Localized attacks for stop signs and faces fail in the multiple view condition setting. We applied attacks on regions of the\nstop signs and faces with very large number of iterations, and introduced extremely large perturbations, but the objects are still detected. In detail, localized attacks on stop signs can sometimes\ndigitally fool far stop signs, but not for middle and near stop signs;\nlocalized attacks on faces cannot fool face detector. The first image is an example of perturbed stop signs, and the second image is\nan example of perturbed faces.\n\nhead, the detector would fail. Evtimov et al. [6] showed an\nexample that successfully attacked stop sign classifiers. We\ntry to generate adversarial patterns constrained to a fixed region of the objects to fool detectors, however, we find these\nattacks only occasionally successful (stop signs) or wholly\nunsuccessful (faces). Figure 9 shows some examples.\n\n4.6. Simple defenses fail\nRecently, Guo et al. [11] showed that simple image processing could defeat a majority of imperceivable adversarial\nattacks. We assume detectors should run at frame rate, so\nexclude image quilting. We investigated down-up sampling\nand total variation smoothing defense. We find that these\nmethods can defeat attacks on a single image, but cannot\n\nPhysical\n\nFigure 10. We apply simple defenses [11] to adversarial examples\ngenerated for Faster RCNN. Up-Down Sample means down sample the image resolution by half, and then upsample it to the original resolution. TV Denoise means denoising the image with total\nvariation regularization, which will remove the high frequency information and keep the low frequency information. In the first\nrow, the adversarial examples generated from a single image with\nsmall perturbations can be detected after simple image processing.\nIn the second row, the adversarial examples generated from multiple view conditions still cannot be detected after simple defense.\nIn the last row, the physically printed adversarial stop signs still\ncannot be detected after simple defense.\n\ndisrupt the large patterns needed to produce adversarial examples that generalize, see Figure 10 and Table 4. Our hypothesis for this phenomenon is that tiny perturbations work\nwith numerical accumulation mechanism, which is not robust to changes, while obvious perturbations work with pattern recognition mechanism, which is more robust and can\nbetter generalize.\n\n\f5. Conclusion\nWe have demonstrated the first adversarial examples that\ncan fool detectors. Our construction yields physical objects\nthat fool detectors too. However, all the adversarial perturbations we have been able to construct require large perturbations. This suggests that the box prediction step in a\ndetector acts as a form of natural defense. We speculate\nthat better viewing models in our construction may yield a\nsmaller gap between physical and digital results. Our patterns may reveal something about what is important to a\ndetector.\n\nReferences\n[1] A. Athalye and I. Sutskever. Synthesizing robust adversarial\nexamples. arXiv preprint arXiv:1707.07397, 2017. 1, 2\n[2] V. Blanz and T. Vetter. A morphable model for the synthesis\nof 3D faces. In SIGGRAPH, pages 187–194. ACM, 1999. 4\n[3] C. Cao, Y. Weng, S. Zhou, Y. Tong, and K. Zhou. Facewarehouse: A 3d facial expression database for visual computing.\nIEEE Transactions on Visualization and Computer Graphics,\n20(3):413–425, Mar. 2014. 4\n[4] N. Carlini and D. Wagner. Defensive distillation is not robust\nto adversarial examples. 2\n[5] X. Chen and A. Gupta. An implementation of faster\nrcnn with study for region sampling.\narXiv preprint\narXiv:1702.02138, 2017. 1\n[6] I. Evtimov, K. Eykholt, E. Fernandes, T. Kohno, B. Li,\nA. Prakash, A. Rahmati, and D. Song. Robust physicalworld attacks on machine learning models. arXiv preprint\narXiv:1707.08945, 2017. 2, 3, 8\n[7] A. Fawzi, O. Fawzi, and P. Frossard. Analysis of classifiers’ robustness to adversarial perturbations. arXiv preprint\narXiv:1502.02590, 2015. 2\n[8] A. Fawzi, S. Moosavi-Dezfooli, and P. Frossard. Robustness of classifiers: from adversarial to random noise. CoRR,\nabs/1608.08967, 2016. 2\n[9] I. J. Goodfellow, J. Shlens, and C. Szegedy. Explaining and harnessing adversarial examples. arXiv preprint\narXiv:1412.6572, 2014. 2\n[10] S. Gu and L. Rigazio. Towards deep neural network architectures robust to adversarial examples. CoRR, abs/1412.5068,\n2014. 2\n[11] C. Guo, M. Rana, M. Cisse, and L. van der Maaten. Countering adversarial images using input transformations. arXiv\npreprint arXiv:1711.00117, 2017. 2, 8\n[12] H. Jiang and E. Learned-Miller. Face detection with the\nfaster r-cnn. In Automatic Face & Gesture Recognition (FG\n2017), 2017 12th IEEE International Conference on, pages\n650–657. IEEE, 2017. 4, 5, 7\n[13] A. Kurakin, I. J. Goodfellow, and S. Bengio. Adversarial examples in the physical world. CoRR, abs/1607.02533, 2016.\n2\n[14] Y. Liu, X. Chen, C. Liu, and D. Song. Delving into transferable adversarial examples and black-box attacks. arXiv\npreprint arXiv:1611.02770, 2016. 1\n\n[15] J. Lu, T. Issaranon, and D. Forsyth. Safetynet: Detecting\nand rejecting adversarial examples robustly. arXiv preprint\narXiv:1704.00103, 2017. 2\n[16] J. Lu, H. Sibai, E. Fabry, and D. Forsyth. No need to\nworry about adversarial examples in object detection in autonomous vehicles. arXiv preprint arXiv:1707.03501, 2017.\n2\n[17] J. Lu, H. Sibai, E. Fabry, and D. Forsyth. Standard detectors\naren’t (currently) fooled by physical adversarial stop signs.\narXiv preprint arXiv:1710.03337, 2017. 2, 3\n[18] J. H. Metzen, T. Genewein, V. Fischer, and B. Bischoff.\nOn detecting adversarial perturbations. arXiv preprint\narXiv:1702.04267, 2017. 2\n[19] S. Moosavi-Dezfooli, A. Fawzi, and P. Frossard. Deepfool:\na simple and accurate method to fool deep neural networks.\nCoRR, abs/1511.04599, 2015. 1, 2\n[20] S.-M. Moosavi-Dezfooli, A. Fawzi, O. Fawzi, and\nP. Frossard. Universal adversarial perturbations. arXiv\npreprint arXiv:1610.08401, 2016. 1, 2\n[21] A. Nguyen, J. Yosinski, and J. Clune. Deep neural networks\nare easily fooled: High confidence predictions for unrecognizable images. In CVPR, 2015. 1, 2\n[22] N. Papernot, P. D. McDaniel, and I. J. Goodfellow. Transferability in machine learning: from phenomena to blackbox attacks using adversarial samples. arXiv preprint\narXiv:1605.07277, 2016. 1\n[23] J. Redmon and A. Farhadi. Yolo9000: better, faster, stronger.\narXiv preprint arXiv:1612.08242, 2016. 1\n[24] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards\nreal-time object detection with region proposal networks. In\nAdvances in neural information processing systems, pages\n91–99, 2015. 1\n[25] J. Saragih and K. McDonald. Facetracker. https://\ngithub.com/kylemcdonald/FaceTracker. 4\n[26] P. Sermanet and Y. LeCun. Traffic sign recognition with\nmulti-scale convolutional networks. In Neural Networks\n(IJCNN), The 2011 International Joint Conference on, pages\n2809–2813. IEEE, 2011. 2\n[27] U. Shaham, Y. Yamada, and S. Negahban. Understanding adversarial training: Increasing local stability of neural nets through robust optimization.\narXiv preprint\narXiv:1511.05432, 2015. 2\n[28] M. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter. Accessorize to a crime: Real and stealthy attacks on state-ofthe-art face recognition. In Proceedings of the 2016 ACM\nSIGSAC Conference on Computer and Communications Security, CCS ’16, pages 1528–1540, New York, NY, USA,\n2016. ACM. 2\n[29] J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. Man\nvs. computer: Benchmarking machine learning algorithms\nfor traffic sign recognition. Neural networks, 32:323–332,\n2012. 2\n[30] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan,\nI. Goodfellow, and R. Fergus. Intriguing properties of neural\nnetworks. arXiv preprint arXiv:1312.6199, 2013. 2\n\n\f",
         "train",
         "40367",
         "6589"
        ],
        [
         "35",
         "17785",
         "cs.AI",
         "Artificial Intelligence",
         "1610.02891v3.pdf",
         "arXiv:1610.02891v3 [cs.AI] 26 May 2017\n\nPersonalizing a Dialogue System with Transfer\nReinforcement Learning\n\nKaixiang Mo† , Yu Zhang† , Shuangyin Li† , Jiajun Li‡ , Qiang Yang†\nThe Hong Kong University of Science and Technology, Hong Kong, China\n†\n{kxmo, zhangyu, shuangyinli, qyang}@cse.ust.hk ‡ {jiajun.li}@alumni.ust.hk\n\nAbstract\nIt is difficult to train a personalized task-oriented dialogue system because the\ndata collected from each individual is often insufficient. Personalized dialogue\nsystems trained on a small dataset is likely to overfit and make it difficult to adapt\nto different user needs. One way to solve this problem is to consider a collection of\nmultiple users as a source domain and an individual user as a target domain, and\nto perform transfer learning from the source to the target domain. By following\nthis idea, we propose a PErsonalized Task-oriented diALogue (PETAL) system, a\ntransfer learning framework based on POMDP to construct a personalized dialogue\nsystem. The PETAL system first learns common dialogue knowledge from the\nsource domain and then adapts this knowledge to the target domain. The proposed\nPETAL system can avoid the negative transfer problem by considering differences\nbetween source and target users in a personalized Q-function. Experimental results\non a real-world coffee-shopping data and simulation data show that the proposed\nPETAL system can learn different optimal policies for different users, and thus\neffectively improve the dialogue quality under the personalized setting.\n\n1\n\nIntroduction\n\nDialogue systems can be classified into two classes: open domain dialogue systems [15, 5, 18, 12, 13]\nand task-oriented dialogue systems [11, 27, 24, 25, 26]. Open domain dialogue systems do not limit\nthe dialogue topic to a specific domain, and typically do not have a clear dialogue goal. Task-oriented\ndialogue systems aim to solve a specific task via dialogues. In this paper we focus on the dialogue\nsystems which aim to assist users to finish a task such as ordering a cup of coffee.\nPersonalized task-oriented dialogue systems aim to help a user complete a dialogue task better and\nfaster than non-personalized dialogue systems. Personalized dialogue systems can learn about the\npreferences and habits of a user during interactions with the user, and then utilize these personalized\ninformation to speed up the conversation process. Personalized dialogue systems could be categorized\ninto rule-based dialogue systems [22, 10, 1] and learning-based dialogue systems [4, 8]. In rulebased personalized dialogue systems, the dialogue state, system speech act and user speech act are\npredefined by developers, hence it is difficult for us to use this system when the dialogue state and the\nspeech act are hard to define manually. Learning-based personalized dialogue systems could learn\nstates and actions from training data without requiring explicit rules designed by developers.\nHowever, it is difficult to train a personalized task-oriented dialogue system because the data collected\nfrom each individual is often insufficient. A personalized dialogue system trained on a small dataset\nis likely to fail on unseen but common dialogue cases due to over-fitting. One solution is to consider a\ncollection of multiple users as a source domain and an individual user as a target domain, and transfer\ncommon dialogue knowledges to the target domain. When transferring dialogue knowledge, the\nchallenge lies in the difference between the source and target domains. Some works [4, 8] have been\nproposed to transfer dialogue knowledge among similar users, but they did not model the difference\nbetween different users, which might harm the performance in the target domain.\n\n\fIn this paper, we propose a PErsonalized Task\u0012ĂŶĚŝĚĂƚĞ\u0003\noriented diALogue (PETAL) system, which is a transdĂƌŐĞƚ\u0003\u0018ŽŵĂŝŶ͗\n^ŽƵƌĐĞ\u0003\n'ĞŶĞƌĂƚŽƌ\n^ƚĂƌƚ\nWĞƌƐŽŶĂůŝǌĞĚ\n\u0018ŽŵĂŝŶ\nfer learning framework based on the POMDP for\n\u0018ŝĂůŽŐ\n\u0004\nlearning a personalized dialogue system. The PETAL\nsystem first learns common dialogue knowledge from\n\u0004\n\u0012ŽĨĨĞĞ\n^ŝǌĞ\nthe source domain and then adapts this knowledge to\n‫ܣ‬\n\u0004\nthe target user. To achieve this goal, the PETAL system models personalized policies with a personalized\nWĞƌƐŽŶĂůŝǌĞĚ\n\u0004ĚĚƌ\n,Žƚͬ\n‫݌‬௨\n‫ܣ‬\n\u0004\nYƵĞƐƚŝŽŶ\nĞƐƐ\n\u0012ŽůĚ\nQ-function defined as the expected cumulative genWĞƌƐŽŶĂůŝǌĞĚ\n‫ݓ‬\n௣\ndƌĂŶƐŝƚŝŽŶ\neral reward plus expected cumulative personal reward.\n\u0004\nYƵĞƐƚŝŽŶ\n\u0004\nThe personalized Q-function can model differences\n\u0012ŽŶĨŝ\ndƌĂŶƐŝƚŝŽŶ\n‫ݓ‬\n\u0004\nWĂǇ\nƌŵ\nbetween the source and target users, and thus can\n\u0011ĞůŝĞĨ\u0003^ƚĂƚĞ\n‫ܯ‬\navoid the negative transfer problem brought by differences between source and target users. The flowchart\nof the PETAL system on the coffee-ordering task is Figure 1: The flowchart of the proposed\nshown in Figure 1. Experimental results on a real- PETAL system on the coffee-ordering task.\nworld coffee-shopping dataset and simulation data\nshow that the proposed PETAL system can choose different optimal actions for different users, and\nthus effectively improves the dialogue quality under the personalized setting.\n௣\n\n௣\n\nOur contributions are three-fold: Firstly, we tackle the problem of learning common dialogue\nknowledge from the source domain and adapting to the target user in a personalized dialogue system.\nIn multi-turn dialogue systems, learning optimal responses in different situations is a non-trivial\nproblem. One naïve policy is to always choose previous seen sentences, but it is not necessarily\noptimal. For example in the online coffee ordering task, such naïve policy could incur many logical\nmistakes such as asking repeated questions and confirming the order before the user finishes ordering.\nSecondly, we propose a transfer learning framework on the POMDP to model the preferences of\ndifferent users. Unlike existing methods, the proposed PETAL system does not require a manuallydefined ground truth state space and it can model the personalized future expected reward. Finally,\nwe demonstrate the effectiveness of the PETAL system on a real-world dialogue dataset as well as\nsimulation data.\n\n2\n\nRelated Works\n\nPersonalized dialogue systems could be categorized into rule-based dialogue systems and learningbased dialogue systems. For rule-based personalized dialogue systems, Thompson et al. [22] propose\nan interactive system where users can choose a place via an interactive conversational process and\nthe system could learn user preference to improve future conversations. Personalization frameworks\nproposed in [10, 1] extract and utilize user-related facts (triples), and then generate responses by\napplying predefined templates to these facts. Different from rule-based personalized dialogue systems,\nlearning-based personalized dialogue systems can learn states and actions from training data without\nrequiring explicit rules. Casanueva et al. [4] propose to initialize personalized dialogue systems for\na target speaker with data from similar speakers in the source domain to improve the performance\nfor the target speaker. This work requires a predefined user similarity metric to select similar source\nusers, and when the selected similar users are different from the target user, the performance for\nthe target user will degrade. Genevay and Laroche [8] propose to select and transfer an optimized\npolicy from source users to a target user by using a multi-armed stochastic bandit algorithm which\ndoes not require a predefined user similarity measure. However, this method has a high complexity\nsince for each target user, it requires n2 bandit selection operations where n is the number of source\nusers. Moreover, similar to [4], the differences between selected source users and the target user will\ndeteriorate the performance. Different from these works, the proposed method does not assume the\npredefined dialogue states and system speech acts required by the rule-based systems, and it explicitly\nmodels the differences between users.\nTransfer learning [21, 14, 19, 20, 23] has been applied to other tasks in dialogue systems. Gasic et\nal. [6] uses transfer learning to extend a dialogue system to include a previously unseen concept.\nGasic et al. [7] propose an incremental scheme to adapt an existing dialogue management system to\nan extended domain. These two works transfer parameters in the policy of the source domain as a\nprior to the target domain. However, these two models do not deal with multiple source domains and\n2\n\n\fthey do not have explicit personalized mechanisms for different users. As a consequence, negative\ntransfer might occur when the differences between users are large. In contrast, the proposed method\nhas an explicit personalization mechanism and can alleviate negative transfer.\nIn argumentation agents, there are some works [9, 17, 16] which study personalized dialogue system.\nHowever, these works, which aim to influence users’ goal, have different motivations from ours and\ntheir formulations are totally different from ours.\n\n3\n\nPETAL: A Framework for Personalized Dialogue Management\n\nIn this section, we introduce the proposed PETAL system. Here we use PETAL to denote both the\nproposed framework and the proposed algorithm.\n3.1\n\nProblem Setting\n\nMatrices are denoted in bold capital case, row vectors are in bold lower case and scalars are in\nlower case. The text in the dialogues, denoted in curlicue, is represented by the the bag-of-words\nassumption. Each of the bag-of-words representations is a vector in which each entry has a binary\nvalue.\nSince the current state of the dialogue is not observable and the ground truth dialogue states are\nassumed to be unknown, we formulate the dialogue as a POMDP, which is defined as 7-tuple\n{S, A, O, P, R, Z, γ}, where S denotes the hidden unobservable states, A denotes the replies of the\nagent, O denotes users’ utterances, P is the state transition probability function, R is the reward\nfunction, Z is the observation function, and γ ∈ [0, 1] is the discounted factor. In the i-th turn of a\ndialogue with a user u, Siu is the hidden conversation state, Oiu is the user utterance, Aui is the reply\nof the agent, and riu is the reward. In the i-th turn, we only observe Oiu , Aui and riu . We define bui\nas the belief state vector, which represents the probability distribution of unobserved Siu . Unlike\nprevious work, we do not assume that the underlying ground truth state space S is provided. Instead\nu\nwe propose to learn a function to map the dialogue history Hiu = {{Oku , Auk }i−1\nk=0 , Oi } to a compact\nbelief state vector bui .\nThe inputs for this problem include\n1. Abundant dialogue data {{Oius , Aui s }Ti=0 } of source customers us .\n2. A few dialogue data {{Oiut , Aui t }Ti=0 } of the target customer ut .\nThe expected output is\n1. A policy πut for target user.\n3.2\n\nThe Framework\n\nIn order to solve the problem, we aim to find a policy πut for the target user, which could choose\nut\nan appropriate action Aui t at the i-th turn based on\ndialogue\n\u0002Pcurrent\n\u0003 history Hi , to maximize the\n∞\nk ut\ncumulative reward defined as πut = arg maxπ E\nk=0 γ rt+k+1 .\nTo model belief states, we introduce a state projection matrix M to map dialogue history Hiu to belief\nstate bui , i.e., bui = f (Hiu ; M).\nThe Q-function is defined as the expected cumulative reward according to policy πu by starting from\nbelief state bui and taking action Aui as\n\"∞\n#\nX\nπu\nu\nu\nk u\nu\nu\nQ (Hi , Ai ) = Eπ\nγ rt+k+1 |Hi , Ai .\nk=0\n\nWe choose value-based approaches because there is usually a small number of training data in the\ntarget domain, while policy-based approaches, which generate responses word by word, require a lot\nof training data.\nIn order to build a personalized dialogue system for the target user, we need to learn a personalized\nQ-function Qπut for this user. However, since the training data {{Oiut , Aui t }Ti } for the target user\n3\n\n\fut is very limited, we can hardly estimate the personalized Q-function Qπut . In order to learn an\naccurate Qπut , we can transfer common dialogue knowledge from the source domain, which has a\nlot of data from many other users {{Oius , Aui s }Ti=0 }. However, different users may have different\npreferences, hence directly using the data from source users would bring negative effects. We propose\nto model the personalized Q-function as a general Q-function Qg plus a personal one Qp :\nQπu (Hiu , Aui ) =Qg (Hiu , Aui ; w) + Qp (Hiu , Aui ; pu , wp )\n\"∞\n#\n\"∞\n#\nX\nX\nk u,g\nu\nu\nk u,p\nu\nu\n≈Eπu\nγ rt+k+1 |Hi , Ai + Eπu\nγ rt+k+1 |Hi , Ai ,\nk=0\n\nk=0\n\nwhere rtu,g and rtu,p denotes the general and personal rewards for user u at time t respectively, the\ngeneral Q-function Qg (Hiu , Aui ; w) captures the expected reward related to the general dialogue\npolicy for all users, w is the set of parameters for the general Q-function and contains a large\namount of parameters such that it requires a lot of training data, and the personal Q-function\nQp (Hiu , Aui ; pu , wp ) captures the expected reward related to the preference of each user.\nThe proposed framework is based on transfer learning. M, w and wp are shared across different\nusers, which could be trained on source domains and then transferred to the target domain. These\nparameters contain the common dialogue knowledge, which is independent of users’ preferences.\nMoreover, pu , which is user-specific, capture the preferences of different users.\n3.3\n\nParametric Forms for Personalized Q-function\n\nIn this section, we introduce parametric forms for f (Hiu ; M),\nQp (Hiu , Aui ; pu , wp ) in the personalized Q-function.\n\nQg (Hiu , Aui ; w) and\n\nDialogue states are defined as follows. All utterances and replies will be projected into state vectors\nwith a state projection matrix M, where M is initialized with the word2vec and will be updated in the\nu\nlearning process. bui = f (Hiu ; M) maps the dialogue history, hHiu = {{Oku , Auk }i−1\nk=0i, Oi }, to a belief\n\nh,u\nu\nu\nstate vector. The belief state vector bui is defined as bui = oh,u\ni−1 , oi , ai−2 , ai−1 , where ξ = 0.8\nPi\nis the memory factor to discount historical state vectors at each time step, oh,u\n= k=0 ξ i−k ouk ,\ni\nP\ni\ni−k u\noui = Oiu M, ah,u\n=\nak , and aui−1 = Aui−1 M. Based on these definitions, we can\ni\nk=0 ξ\nh,u\nsee that oi represents all previous user utterances, oui represents the current user utterance, ah,u\ni\nrepresents all previous agent replies, and aui−1 represents the last agent reply.\n\nIn order to model the correlations between entries in aui and bui , the general Q-function\nQg (Hiu , Aui ; w) is defined as\nQg (Hiu , Aui ; w) = aui W(bui )T ,\nwhere superscript T denotes the transpose of a vector or matrix, W ∈ Rd×4d is a parameter matrix to\nbe learned. Based on the properties of the Kronecker product and operator vec(·) which transforms a\nmatrix to a vector in a columnwise manner, we can rewrite Qg (Hiu , Aui ; w) as a linear function on\n2\nw = vec(W)T ∈ R4d : Qg (Hiu , Aui ; w) = (bui ⊗ aui )wT , where bui ⊗ aui is the Kronecker product\nof bui and aui . In multi-round dialogue systems, there should be different optimal actions in different\nbelief states. The rationale to use the Kronecker product is that the general Q-function should depend\non the combination of belief state bui and action aui , but not independently on bui and aui .\nThe personal Q-function learns personalized preference for each user to avoid the negative effect\nbrought by transferring biased dialogue knowledge across users with different preferences. We denote\nby Cj the set of all possible choices in the j-th choice set we want to collect and by {cuij }m\nj=1 the\nchoices proposed in the i-th agent response Aui , where m is the total number of order choices, hence\ncuij is an exact choice in Cj . For example, in the coffee-ordering task, C1 = {Latte, Cappuccino,. . .}\ncould be the type of coffees and cui1 could be any coffee in C1 . From the user side, cuij is just the\nchoice of user u for the j-th choice set in the i-th dialogue turn. For example, cui1 could be “latte” and\ncui2 could be “iced”. Based on an assumption that different choice sets are independent of each other,\nfor the j-th choice set, the probability of a user u to choose cuij follows a categorical distribution\nC(cuij ; puj ) = puj,cuij where |Cj | denotes the cardinality of a set, puj ∈ R|Cj | , and puj,k denotes the k-th\n4\n\n\fentry in puj . Hence the personal Q-function for user u is formulated as\nm\nX\nQp (Hiu , Aui ; pu , wp ) = wp\nC(cuij ; puj )δ(Cj , Hiu ),\nj=1\nu\nwhere the personal preference pu = {puj }m\nj=1 for user u is learned from training process, δ(Cj , Hi )\nu\nequals 1 if the user has not yet made a choice about Cj in the dialogue history Hi and 0 otherwise.\nδ(Cj , Hiu ) implies whether the system will receive a personal reward in the rest of the dialogue,\nas the Q-function models the cumulative future reward. Here wp controls the importance of the\npersonalized reward and it is learned fromP\ndata. When wp is close to zero, the Q-function will depend\nm\non the general dialogue policy. Note that j=1 C(cuij |puj )δ(Cj , Hiu ) is 0 if we know nothing about\nu\nthe user, or Ai does not show any personal preference of user u. Because the vocabulary of choices\nis much smaller than the whole vocabulary, we can estimate the personal preference parameters pu\nwith a few dialogue data {{Oiut , Aui t }Ti } from the target user.\n\nBy combining the general and personal Q-functions, the personalized Q-function can finally be\ndefined as\nm\nX\nπu\nu\nu\nu\nu\nT\nQ (Hi , Ai ) = (bi ⊗ ai )w + wp\nC(cuij |puj )δ(Cj , Hiu ).\nj=1\n\nHere M, w, wp are shared across different users, which could be trained on the source domains and\nthen transferred to the target domain.\n3.4\n\nReward\n\nThe total reward is the sum of general reward and personal reward, which can be defined as follows:\n1. A personal reward ru,p of 0.3 will be received when the user confirms the suggestion of the\nagent, and a negative reward of −0.2 will be received if the user declines the suggestion\nby the agent. This is related to the personal information of the user. For example, the user\ncould confirm the address suggested by the agent.\n2. A general reward ru,g of 0.1 will be received when the user provides the information about\neach cj .\n3. A general reward ru,g of 1.0 will be received when the user proceeds with payment.\n4. A general reward ru,g of −0.05 will be received by the agent for each dialogue turn to\nencourage shorter dialogue, −0.2 will be received by the agent if it is generates non-logical\nresponses such as asking repeated questions.\nNote that the personal reward could not be distinguished from the general reward during the training\nprocess.\n3.5\n\nLoss Function and Parameter Learning\n\nThere are in total four sets of parameters to be learned. We denote all the parameters by Θ =\n{M, w, wp , {pu }}. When dealing with real-world data, the training set consists of (Hiu , Aui , riu ),\nwhich records optimal actions provided by human, and hence the loss function is defined as follows:\nh\n\u00012 i\nu\nL(Θ) = E riu + γQ(Hi+1\n, Aui+1 |Θ) − Q(Hiu , Aui |Θ)\n.\nIn the on-policy training with a user simulator, the loss function is defined as\n\u0014\u0010\n\u00112 \u0015\nu\nL(Θ) = E riu + maxA0i+1 γQ(Hi+1\n, A0i+1 |Θ) − Q(Hiu , Aui |Θ)\n,\nu\nwhere riu is the reward obtained at time step i and Hi+1\nis the update dialogue history at time step\ni + 1.\n\nWe use the value iteration method [2] to learn both the general and personal Q-functions. We adopt\nan online stochastic gradient descent algorithm [3] with learning rate 0.0001 to optimize our model.\nSpecifically, we use the State-Action-Reward-State-Action (SARSA) algorithm. In the on-policy\nβ\ntraining with the simulation, the model has decreasing probability η = 0.2e− 1000 of choosing a\nrandom reply in the candidate set so as to ensure the sufficient exploration, where β is the number of\ntraining dialogues seen by the algorithm.\n5\n\n\f3.6\n\nTransfer Learning Algorithm\n\nAlgorithm 1: The PETAL Algorithm\nThe detailed PETAL algorithm is shown in Algorithm 1. We train our model for each user in the 1: Input: Ds ,Dt\n2: Output: Θ = {M, w, wp {pu }}\nsource domain. M, w and wp are shared by all 3:\nprocedure T RANSFER A LGORITHM(D s ,D t )\nusers and there is a separate pu for each user in 4: {M, w, wp } ← T RAIN -S OURCE -M ODEL(Ds )\nthe source domain. We transfer M, w and wp to 5: {M, w, wp , {pu }} ←T RANSFER(Dt ,M,w,wp )\n-S OURCE -M ODEL(D s )\nthe target domain by using them to initialize the 6: function T RAIN\ns\n7:\nfor {Oiu , Au\ni } in D do\ncorresponding variables in the target domain, and 8:\nu\nu\nu\nu\nu\nu\nfor (Hu\ni , Ai , ri , Hi+1 , Ai+1 ) in {Oi , Ai } do\nthen we train them as well as pu for each target 9:\nΘt+1 ← Θt + α∆Θ L(Θt )\nuser with limited training data. Since the source\nreturn {M, w, wp }\nand target users might have different preferences, 10: function T RANSFER(Dt , M, w, wp )\nu\nu T\nt\npu learned in source domain is not very useful 11: for {{Oi ,uAi }ui }uin Du do u\n12:\nfor (Hi , Ai , ri , Hi+1 , Ai+1 ) in {Oiu , Au\ni } do\nin the target domain. The personal preference of\n13:\nΘt+1 ← Θt + α∆Θ L(Θt )\neach target user will be learned separately in each\nreturn {M, w, wp , {pu }}\npu . Without modelling pu for each user, different\npreferences of source and target users might interfere with each other and thus cause negative transfer.\nThe number of parameters in our model is around d2 + dv, where v is the total vocabulary size and d\nis the dimension of the state vector. In our experiment where v = 1, 500 and d = 50, the number of\nparameters in the general Q-function is about 85k and that for the personal Q-function is under 100\nfor each user, hence the parameters in the personalized Q-function could be learned accurately with\nthe limited data in the target domain.\n\n4\n\nExperiments\n\nIn this section, we experimentally verify the effectiveness of the proposed PETAL model by conducting experiments on a real-world dataset and a simulation dataset.\n4.1\n\nBaselines\n\nWe compare the proposed PETAL model with six baseline algorithms including “NoneTL” which is\ntrained only with the data from target users, “Sim” [4] which is trained with the data from both target\nuser and the most similar user in the source domain, “Bandit” [8] in which for each target user, the\nmost useful source user is identified by a bandit algorithm, “PriorSim” [6] in which for each target\nuser, the policy from the most similar user in the source domain is used as a prior, “PriorAll” [6] in\nwhich for each target user, the dialogue policy trained on all the users in the source domain is used as\na prior, and “All” where the policy is trained on all source users’ data.\n4.2\n\nExperiments on Real-World Data\n\nTable 1: Statistics of the datasets\n\nSource Domain\nTarget Domain\nIn this section, we evaluate our model on a\nDataset\nUsers Dialogues Users Dialogues\nreal-world dataset. This real-world dataset,\nReal Data\n52\n1,859\n20\n329\nwhich is collected between July 2015 and\nSimulation\n11\n176,000\n5\n100\nApril 2016 from a O2O coffee ordering\nservice, contains 2,185 coffee dialogues between 72 consumers and coffee makers. The users order\ncoffee by providing the coffee type, the temperature, the cup size and the delivery address, hence\nthere are 4 order choices. We select 52 users with more than 23 dialogues as the source domain.\nEach of the remaining 20 users is used separately as a target domain. In total, there are 1,859 coffee\ndialogues in the source domain and 329 coffee dialogues in the target domain. 221 earlier dialogues\nin the target domain are used as the training set and the remaining 108 dialogues form the test set.\nThe statistics of this dataset is shown in Table 1.\n\nFor each round of the testing conversation, a model will rank the ground truth reply Aui among 10\nrandomly chosen agent replies. The label assigned to Aui is 1 and those for randomly chosen agent\nreplies are 0. By following [26], we calculate the AUC score for each turn in a conversation and the\nperformance of an algorithm is measured by the average AUC score of each dialogue for every user\nin the test set.\n6\n\n\fIn Figure 2(a), we report the mean and standard deviation of averaged AUC score with 5 different\nrandom seeds, which are used to randomly sample agent replies as candidates. The performance of\n“NoneTL”, “PriorSim” and “PriorAll” are worse than “All” which directly transfers training data,\nbecause fitting only target domain data can cause the overfitting. Transferring data from similar\nusers (i.e., “Sim”) is not as good as transferring data from all source users (i.e., “All”), because\ncommon knowledge has to be learned from more data. The proposed “PETAL” method performs the\nbest because it learns common knowledge from all users and avoids the negative transfer caused by\ndifferent preferences among source and target users, which indicates that the proposed personalized\nmodel fits dialogues better and demonstrates the effectiveness of PETAL on this real-world dataset.\nA case study is shown in Table 2 Table 2: A case study on the real-world dataset. The last\nand due to space limit, we only show column shows candidate responses, where the ground truth\nthree candidates. From the results, we response is marked with *. The first and second columns\ncan see that the proposed “PETAL” show predicted rewards of “All” and “PETAL” on these\nmethod ranks the ground truth re- candidates.\nsponse in the first place based on\nUser utterance : I want a cup of coffee.\nthe predicted reward given by the\nAll\nPETAL Response Candidates\nlearned personalized Q-function but\n0.86\n1.36 * Same as before? Tall hot americano and\ndeliver to Central Conservatory of Music?\nthe “All” method without personaliza0.92 All right, deliver to No.1199 Beiyuan Road,\ntion ranks an wrong address higher, 0.99\nChaoyang District, Beijing?\nwhich demonstrates the effectiveness\n0.72\n0.69 What’s your address?\nof the proposed method.\n\n1:NoneTL\n2:Sim\n3:Bandit\n4:PriorSim\n5:PriorAll\n6:All\n7:PETAL\n\n1.5\n\nReward\n\n1.0\n0.5\n0.0\n0.5\n\n1\n(a) Real-world Average AUC (the higher the better)\n1.2\n\n0.6\n0.4\n\nNumber of Dialogue Turns\n\nSuccess Rate\n\n0.8\n\n0.2\n0.0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n(c) Simulation Success Rate (the higher the better) (d)\n\n4\n\n5\n\n1:NoneTL\n2:Sim\n3:Bandit\n4:PriorSim\n\n16\n14\n12\n\n6\n\n7\n\n5:PriorAll\n6:All\n7:PETAL\n\n10\n8\n6\n4\n2\n\n7\n\n3\n\nSimulation Average Reward (the higher the better)\n\n18\n\n1:NoneTL\n2:Sim\n3:Bandit\n4:PriorSim\n5:PriorAll\n6:All\n7:PETAL\n\n1.0\n\n(b)\n\n2\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\nSimulation Average Dialogue Length (the lower the better)\n\nFigure 2: Experimental results on real-world and simulations datasets.\n4.3 Experiments on Simulation\nData\nIn this section, we compare our model with baseline models on the simulated coffee-ordering dialogue\ndata. The simulated users order coffee by providing their coffee type, temperature, size and delivery\naddress, and the agents reply by choosing from a set of predefined candidate responses without\nknowing the speech act. We have 11 simulated users in the source domain, in which 10 users have\n7\n\n\fTable 3: Personalized Dialogue Cases\nUser:\nAgent:\nUser:\nAgent:\nUser:\nUser:\nAgent:\nUser:\nAgent:\nUser:\n\nTable 4: A Non-Personalized Dialogue Case\n\nI want a cup of coffee.\nSame as before? Tall hot macchiato and deliver to\nNo.1199 Minsheng Road, Pudong District Shanghai?\nYes.\nPlease pay.\nPayment completed.\nI want a cup of coffee.\nSame as before? Tall hot macchiato and deliver to\nNo.1199 Minsheng Road, Pudong District, Shanghai?\nI want iced mocha today.\nSure, please pay.\nPayment completed.\n\nUser:\nAgent:\nUser:\nAgent:\nUser:\nAgent:\nUser:\nAgent:\nUser:\nAgent:\nUser:\n\nI want a cup of coffee.\nHot coffee?\nYes.\nWhat would you like to drink?\nHot macchiato, please.\nWhat’s your address?\nNo.1199 Minsheng Road, Pudong District, Shanghai.\nAlright. Tall, Grande, or Venti?\nTall.\nPlease pay.\nPayment completed.\n\ntheir own coffee preferences while the rest one has no preference. The target domain has 5 users,\nwhich have different preferences from users in the source domain. A simulator is designed based\non the real-world dataset used in the previous section. The simulator will order according to his\npreference with probability 0.8 and otherwise the simulator will order coffee randomly. The training\nset of each user in the target domain has 20 dialogues and the test set has 300 dialogues. The reward\nin the experiment is the same as the reward defined in Section 3.4.\nEach model will choose a reply from a set of candidates generated with templates at each turn, and\nthe simulator will react to the reply accordingly. For each model, we report the mean and standard\ndeviation of averaged reward [8], averaged success rate [4] and averaged dialogue length over all\npossible target users, repeated for 5 times with different random seeds.\nThe results are shown in Figure 2(b), Figure 2(c) and Figure 2(d). PETAL outperforms all baselines\nand obtains the highest average reward, the highest success rate and the lowest dialogue length, which\nimplies that PETAL has found a better dialogue policy which can adapt its behaviour according to the\npreference of target users and again demonstrates the effectiveness of PETAL in a live environment.\nWe show a typical case for the simulation data in Tables 3 and 4. The non-personalized dialogue\nsystem corresponding to the “All” model has to ask the users all the choices even for frequent users\nin Table 4, because there is no universal recommendation for all the frequent users with different\npreferences. However, PETAL has learned the target users’ preferences in previous dialogues.\nAs shown in Table 3, the response from the agent is specially tailored for the target user because\npersonalized questions given by the PETAL method can guide the user to complete the coffee-ordering\ntask faster than general questions, leading to shorter dialogue and higher averaged reward. If the user\ndoes not want everything as usual, which is shown in the second case of Table 3, PETAL can still\nreact correctly due to the shared dialogue knowledge transferred from the source domain. These cases\nshow that PETAL can choose different optimal actions for different users and effectively shorten the\nconversation.\n\n5\n\nConclusion\n\nIn this paper, we tackle the problem of designing a personalized dialogue system. We propose the\nPETAL system, a transfer learning framework based on the POMDP, for learning a personalized\ndialogue system. The PETAL system first learns common dialogue knowledge from the source\ndomain and then adapts this knowledge to the target user. We propose to model a personalized\npolicy in the POMDP with a personalized Q-function. This framework can avoid the negative\ntransfer problem brought by differences between the source users and the target user. Experimental\nresults on the real-world coffee-ordering data and the simulation data show that PETAL can learn\ndifferent optimal policies for different users, and thus effectively improve the dialogue quality under\nthe personalized setting. As a future direction, we will investigate to transfer knowledge from\nheterogeneous domains such as knowledge graphs and images.\n\nReferences\n[1] Jeesoo Bang, Hyungjong Noh, Yonghee Kim, and Gary Geunbae Lee. Example-based chatoriented dialogue system with personalized long-term memory. In Proceedings of International\nConference on Big Data and Smart Computing, pages 238–243, 2015.\n[2] Richard Bellman. A Markovian decision process. Technical report, DTIC Document, 1957.\n8\n\n\f[3] Léon Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings of\n19th International Conference on Computational Statistics, pages 177–186, 2010.\n[4] Inigo Casanueva, Thomas Hain, Heidi Christensen, Ricard Marxer, and Phil Green. Knowledge\ntransfer between speakers for personalised dialogue management. In Proceedings of the 16th\nAnnual Meeting of the Special Interest Group on Discourse and Dialogue, 2015.\n[5] Michel Galley, Chris Brockett, Alessandro Sordoni, Yangfeng Ji, Michael Auli, Chris Quirk,\nMargaret Mitchell, Jianfeng Gao, and Bill Dolan. deltaBLEU: A discriminative metric for\ngeneration tasks with intrinsically diverse targets. arXiv preprint arXiv:1506.06863, 2015.\n[6] Milica Gašic, Catherine Breslin, Matthew Henderson, Dongho Kim, Martin Szummer, Blaise\nThomson, Pirros Tsiakoulis, and Steve Young. POMDP-based dialogue manager adaptation to\nextended domains. In Proceedings of the 14th Annual Meeting of the Special Interest Group on\nDiscourse and Dialogue, 2013.\n[7] Milica Gasic, Dongho Kim, Pirros Tsiakoulis, Catherine Breslin, Matthew Henderson, Martin\nSzummer, Blaise Thomson, and Steve J. Young. Incremental on-line adaptation of POMDPbased dialogue managers to extended domains. In Proceedings of the 15th Annual Conference\nof the International Speech Communication Association, pages 140–144, 2014.\n[8] Aude Genevay and Romain Laroche. Transfer learning for user adaptation in spoken dialogue\nsystems. In Proceedings of the 2016 International Conference on Autonomous Agents &\nMultiagent Systems, pages 975–983, 2016.\n[9] Takuya Hiraoka, Graham Neubig, Sakriani Sakti, Tomoki Toda, and Satoshi Nakamura. Reinforcement learning of cooperative persuasive dialogue policies using framing. In Proceedings\nof the 25th International Conference on Computational Linguistics, pages 1706–1717, 2014.\n[10] Yonghee Kim, Jeesoo Bang, Junhwi Choi, Seonghan Ryu, Sangjun Koo, and Gary Geunbae Lee.\nAcquisition and use of long-term memory for personalized dialog systems. In Proceedings of\nInternational Workshop on Multimodal Analyses Enabling Artificial Agents in Human-Machine\nInteraction, pages 78–87, 2014.\n[11] Esther Levin, Roberto Pieraccini, and Wieland Eckert. Learning dialogue strategies within the\nMarkov decision process framework. In Proceedings of IEEE Workshop on Automatic Speech\nRecognition and Understanding, pages 72–79, 1997.\n[12] Jiwei Li, Will Monroe, Alan Ritter, and Dan Jurafsky. Deep reinforcement learning for dialogue\ngeneration. arXiv preprint arXiv:1606.01541, 2016.\n[13] Lili Mou, Yiping Song, Rui Yan, Ge Li, Lu Zhang, and Zhi Jin. Sequence to backward and\nforward sequences: A content-introducing approach to generative short-text conversation. arXiv\npreprint arXiv:1607.00970, 2016.\n[14] Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Transactions on\nKnowledge and Data Engineering, 22(10):1345–1359, 2010.\n[15] Alan Ritter, Colin Cherry, and William B Dolan. Data-driven response generation in social\nmedia. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language\nProcessing, pages 583–593, 2011.\n[16] Ariel Rosenfeld and Sarit Kraus. Providing arguments in discussions on the basis of the\nprediction of human argumentative behavior. ACM Transactions on Interactive Intelligent\nSystems, 6(4):30, 2016.\n[17] Ariel Rosenfeld and Sarit Kraus. Strategical argumentative agent for human persuasion. In\nProceedings of the 22nd European Conference on Artificial Intelligence, 2016.\n[18] Iulian V Serban, Alessandro Sordoni, Yoshua Bengio, Aaron Courville, and Joelle Pineau.\nHierarchical neural network generative models for movie dialogues. arXiv preprint\narXiv:1507.04808, 2015.\n9\n\n\f[19] Ben Tan, Erheng Zhong, Evan Wei Xiang, and Qiang Yang. Multi-transfer: Transfer learning\nwith multiple views and multiple sources. Statistical Analysis and Data Mining, 7(4):282–293,\n2014.\n[20] Ben Tan, Yangqiu Song, Erheng Zhong, and Qiang Yang. Transitive transfer learning. In\nProceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and\nData Mining, pages 1155–1164, 2015.\n[21] Matthew E Taylor and Peter Stone. Transfer learning for reinforcement learning domains: A\nsurvey. Journal of Machine Learning Research, 10:1633–1685, 2009.\n[22] Cynthia A Thompson, Mehmet H Goker, and Pat Langley. A personalized system for conversational recommendations. Journal of Artificial Intelligence Research, 21:393–428, 2004.\n[23] Ying Wei, Yu Zheng, and Qiang Yang. Transfer knowledge between cities. In Proceedings of\nthe 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,\npages 1905–1914, 2016.\n[24] Tsung-Hsien Wen, Milica Gasic, Nikola Mrksic, Pei-Hao Su, David Vandyke, and Steve Young.\nSemantically conditioned lstm-based natural language generation for spoken dialogue systems.\narXiv preprint arXiv:1508.01745, 2015.\n[25] Tsung-Hsien Wen, Milica Gasic, Nikola Mrksic, Lina M Rojas-Barahona, Pei-Hao Su, Stefan\nUltes, David Vandyke, and Steve Young. A network-based end-to-end trainable task-oriented\ndialogue system. arXiv preprint arXiv:1604.04562, 2016.\n[26] Jason D Williams and Geoffrey Zweig. End-to-end LSTM-based dialog control optimized with\nsupervised and reinforcement learning. arXiv preprint arXiv:1606.01269, 2016.\n[27] Steve Young, Milica Gašić, Blaise Thomson, and Jason D Williams. POMDP-based statistical\nspoken dialog systems: A review. Proceedings of the IEEE, 101(5):1160–1179, 2013.\n\n10\n\n\f",
         "train",
         "36775",
         "6101"
        ],
        [
         "36",
         "18788",
         "cs.AI",
         "Artificial Intelligence",
         "1710.03774v2.pdf",
         "AI MATTERS, VOLUME X, ISSUE X\n\nXXXXX 20XX\n\nU Artificial Inteligence Buzzword Explained:\n∗\nMulti-Agent Path Finding (MAPF)\n\narXiv:1710.03774v2 [cs.AI] 17 Oct 2017\n\nHang Ma (University of Southern California; hangma@usc.edu)\nSven Koenig (University of Southern California; skoenig@usc.edu)\nDOI: XX.XXXX/XXXXXXX.XXXXXXX\nKiva Systems was founded in 2003 to develop\nrobot technology that automates the fetching\nof goods in order-fulfillment centers. It was\nacquired by Amazon in 2012 and changed its\nname to Amazon Robotics in 2014. Amazon order-fulfillment centers have inventory\nstations on the perimeter of the warehouse\nand storage locations in its center, see Figure 1. Each storage location can store one\ninventory pod. Each inventory pod holds one\nor more kinds of goods. A large number of\nwarehouse robots operate autonomously in\nthe warehouse. Each warehouse robot is able\nto pick up, carry and put down one inventory\npod at a time. The warehouse robots move\ninventory pods from their storage locations\nto the inventory stations where the needed\ngoods are removed from the inventory pods\n(to be boxed and eventually shipped to customers) and then back to the same or different\nempty storage locations (Wurman, D’Andrea,\n& Mountz, 2008).1\n\ndescribed as follows: On math paper, some\ncells are blocked. The blocked cells and the\ncurrent cells of n robots are known. A different unblocked cell is assigned to each of\nthe n robots as its goal cell. The problem is\nto move the robots from their current cells to\ntheir goal cells in discrete time steps and let\nthem wait there. The optimization objective is\nto minimize the makespan, that is, the number of time steps until all robots are at their\ngoal cells. During each time step, each robot\ncan move from its current cell to its current\ncell (that is, wait in its current cell) or to an\nunblocked neighboring cell in one of the four\nmain compass directions. Robots are not allowed to collide. Two robots collide if and only\nif, during the same time step, they both move\nto the same cell or both move to the current\ncell of the other robot. Figure 2 shows an example, where the red and blue robots have to\nmove to the red and blue goal cells, respectively.\n\nThese order-fulfillment centers raise a number of interesting optimization problems, such\nas which paths the robots should take and at\nwhich storage locations inventory pods should\nbe stored. Path planning, for example, is tricky\nsince most warehouse space is used for storage locations, resulting in narrow corridors\nwhere robots that carry inventory pods cannot\npass each other. Warehouse robots operate\nall day long but a simplified one-shot version\nof the path-planning problem is the multi-agent\npath-finding (MAPF) problem, which can be\n\nThere are also versions of the multi-agent\npath-finding problem with different optimization objectives than makespan (such as the\nsum of the time steps of each robot until it\nis at its goal cell) or slightly different collision\nor movement rules. For example, solving the\neight-puzzle (a toy with eight square tiles in a\nthree by three frame, see Figure 3) is a version\nof the multi-agent path-finding problem where\nthe tiles are the robots.\n\n∗\n\nThis article is a service of the ACM Special Interest Group on Artificial Intelligence (ACM SIGAI).\nIf you want to find out more about artificial intelligence and are not a member of ACM SIGAI yet,\nyou can join for $11 (students) or $25 (others), see\nsigai.acm.org (membership fees are accurate\nfor 2016).\nCopyright c 20XX by the author(s).\n1\nSee the following YouTube video:\nhttps://www.youtube.com/watch?v=\n6KRjuuEVEZs\n\nResearchers in theoretical computer science,\nartificial intelligence and robotics have studied multi-agent path finding under slightly different names. They have developed fast\n(polynomial-time) algorithms that find solutions for different classes of multi-agent pathfinding instances (for example, those with at\nleast two unblocked cells not occupied by\nrobots) although not necessarily with good\nmakespans. They have also characterized\nthe complexity of finding optimal (or boundedsuboptimal) solutions and developed algo1\n\n\fAI MATTERS, VOLUME X, ISSUE X\n\nXXXXX 20XX\n\nFigure 1: Warehouse robot (left), inventory pods (center), and the layout of a small simulated warehouse\n(right). The left and center photos are courtesy of Amazon Robotics.\n\n1\n\nA\n\n2\n\n3\n\n4\n\nRobot\nGoal Cell\n\nB\ntime step 0\n\ntime step 1\n\ntime step 2\n\ntime step 3\n\nFigure 2: A multi-agent path-finding instance with two robots.\n\n4\n6\n\n1\n\n2\n\n8\n\n7\n\n3\n\n5\n\nFigure 3: The eight-puzzle.\n\nrithms that find them. A bounded-suboptimal\nsolution is one whose makespan is at most a\ngiven percentage larger than optimal.\nInterestingly, it is slow (NP-hard) to find optimal solutions (Yu & LaValle, 2013c; Ma, Tovey,\nSharon, Kumar, & Koenig, 2016), although\na slight modification of the multi-agent pathfinding problem can be solved in polynomial\ntime with flow algorithms, namely where n unblocked cells are given as goal cells but it is\nup to the algorithm to assign a different goal\ncell to each one of the n robots (Yu & LaValle,\n2013a). Researchers have also studied versions of the multi-agent path-finding problem\nwhere goal cells require robots with certain capabilities (Ma & Koenig, 2016) or robots can\nexchange their payloads (Ma et al., 2016).\nIn principle, one can model the original multiagent path-finding problem as a shortest-path\nproblem on a graph whose vertices correspond to tuples of cells, namely one for each\n\nrobot, as shown in Figure 4 (where the red\npath shows the optimal solution), but the number of vertices can be exponential in the number of robots and the shortest path thus cannot be found quickly. Instead, researchers\nhave suggested to plan a shortest path for\neach robot independently (by ignoring the\nother robots), which can be done fast. If all\nrobots can follow their paths without colliding,\nthen an optimal solution has been found. If\nnot, then ...\n• there are multi-agent path-finding algorithms that group all colliding robots together and find a solution for the group with\nminimal makespan (by ignoring the other\nrobots), and then repeat the process. The\nhope is to find a solution before all robots\nhave been grouped together into one big\ngroup (Standley, 2010; Standley & Korf,\n2011).\n• there are other multi-agent path-finding algorithms that pick a collision between two\nrobots (for example, robots A and B both\nmove to cell x at time step t) and then\nconsider recursively two cases, namely one\nwhere robot A is not allowed to move to cell\nx at time step t and one where robot B is not\nallowed to move to cell x at time step t. The\nhope is to find a solution before all possible constraints have been imposed (Sharon,\n2\n\n\fAI MATTERS, VOLUME X, ISSUE X\n\nXXXXX 20XX\nStart Vertex\n=B1 =B2\n\n=B4 =A2\n\n=B1 =A2\n\n=B2 =A2\n\n=B3 =A2\n\n=B3 =B2\n\n=B4 =B2\n\n=B4 =B3\n\n=B1 =B3\n\n=B2 =B3\n\n...\n\nGoal Vertex\n\nFigure 4: Partial graph for the multi-agent path-finding instance from Figure 2.\n\nStern, Felner, & Sturtevant, 2015).\nThese state-of-the-art multi-agent path-finding\nalgorithms are currently not quite able to\nfind bounded-suboptimal solutions for 100\nrobots in small warehouses in real-time. The\ntighter the space, the longer the runtime.\nResearchers have also suggested a variety of other multi-agent path-finding techniques (Silver, 2005; Sturtevant & Buro, 2006;\nRyan, 2008; Wang & Botea, 2008, 2011; Luna\n& Bekris, 2011; Sharon, Stern, Goldenberg,\n& Felner, 2013; de Wilde, ter Mors, & Witteveen, 2013; Barer, Sharon, Stern, & Felner, 2014; Goldenberg et al., 2014; Wagner\n& Choset, 2015; Boyarski et al., 2015; Ma &\nKoenig, 2016; Cohen et al., 2016), including\nsome that transform the problem into a different problem for which good solvers exist, such\nas satisfiability (Surynek, 2015), integer linear\nprogramming (Yu & LaValle, 2013b) and answer set programming (Erdem, Kisa, Oztok,\n& Schueller, 2013). Researchers have also\nstudied how to execute the resulting solutions\non actual robots (Cirillo, Pecora, Andreasson,\nUras, & Koenig, 2014; Hoenig et al., 2016).\nTwo workshops have recently been held on\nthe topic, namely the AAAI 2012 Workshop on\nMulti-Agent Pathfinding2 and the IJCAI 2016\n2\n\nSee the following URL:\nhttp://movingai.com/mapf\n\nWorkshop on Multi-Agent Path Finding3 . Recent dissertations include (Wang, 2012; Wagner, 2015; Sharon, 2016).\n\nReferences\nBarer, M., Sharon, G., Stern, R., & Felner,\nA. (2014). Suboptimal variants of the\nconflict-based search algorithm for the\nmulti-agent pathfinding problem. In Annual symposium on combinatorial search\n(pp. 19–27).\nBoyarski, E., Felner, A., Stern, R., Sharon,\nG., Tolpin, D., Betzalel, O., & Shimony,\nS. (2015). ICBS: Improved conflictbased search algorithm for multi-agent\npathfinding. In International joint conference on artificial intelligence (pp. 740–\n746).\nCirillo, M., Pecora, F., Andreasson, H., Uras,\nT., & Koenig, S. (2014). Integrated motion planning and coordination for industrial vehicles. In International conference\non automated planning and scheduling\n(pp. 463–471).\nCohen, L., Uras, T., Kumar, T. K. S., Xu, H.,\nAyanian, N., & Koenig, S. (2016). Improved solvers for bounded-suboptimal\n3\n\nSee the following URL:\nhttp://www.andrew.cmu.edu/user/\ngswagner/workshop/ijcai 2016\nmultirobot path finding.html\n3\n\n\fAI MATTERS, VOLUME X, ISSUE X\nmulti-agent path finding. In International\njoint conference on artificial intelligence\n(pp. 3067–3074).\nde Wilde, B., ter Mors, A., & Witteveen, C.\n(2013). Push and rotate: Cooperative\nmulti-agent path planning. In International conference on autonomous agents\nand multi-agent systems (pp. 87–94).\nErdem, E., Kisa, D., Oztok, U., & Schueller,\nP. (2013). A general formal framework for pathfinding problems with multiple agents. In AAAI conference on artificial intelligence (pp. 290–296).\nGoldenberg, M., Felner, A., Stern, R., Sharon,\nG., Sturtevant, N., Holte, R., & Schaeffer, J. (2014). Enhanced partial expansion A*. Journal of Artificial Intelligence\nResearch, 50, 141–187.\nHoenig, W., Kumar, S., Cohen, L., Ma, H., Xu,\nH., Ayanian, N., & Koenig, S. (2016).\nMulti-agent path finding with kinematic\nconstraints. In International conference\non automated planning and scheduling\n(pp. 477–485).\nLuna, R., & Bekris, K. (2011). Push and swap:\nFast cooperative path-finding with completeness guarantees. In International\njoint conference on artificial intelligence\n(pp. 294–300).\nMa, H., & Koenig, S. (2016). Optimal target\nassignment and path finding for teams of\nagents. In International conference on\nautonomous agents and multiagent systems (pp. 1144–1152).\nMa, H., Tovey, C., Sharon, G., Kumar,\nT. K. S., & Koenig, S. (2016). Multiagent path finding with payload transfers\nand the package-exchange robot-routing\nproblem. In AAAI conference on artificial\nintelligence (pp. 3166–3173).\nRyan, M. (2008). Exploiting subgraph structure in multi-robot path planning. Journal of Artificial Intelligence Research, 31,\n497–542.\nSharon, G. (2016). Novel search techniques for path finding in complex environment (Unpublished doctoral dissertation). Ben-Gurion University of the\nNegev.\nSharon, G., Stern, R., Felner, A., & Sturtevant,\nN. (2015). Conflict-based search for optimal multi-agent pathfinding. Artificial Intelligence, 219, 40–66.\nSharon, G., Stern, R., Goldenberg, M., & Fel-\n\nXXXXX 20XX\nner, A. (2013). The increasing cost tree\nsearch for optimal multi-agent pathfinding. Artificial Intelligence, 195, 470-495.\nSilver, D. (2005). Cooperative pathfinding. In\nArtificial intelligence and interactive digital entertainment (pp. 117–122).\nStandley, T. (2010). Finding optimal solutions\nto cooperative pathfinding problems. In\nAAAI conference on artificial intelligence\n(pp. 173–178).\nStandley, T., & Korf, R. (2011). Complete algorithms for cooperative pathfinding problems. In International joint conference on\nartificial intelligence (pp. 668–673).\nSturtevant, N., & Buro, M. (2006). Improving collaborative pathfinding using map\nabstraction. In Artificial intelligence and\ninteractive digital entertainment (pp. 80–\n85).\nSurynek, P.\n(2015).\nReduced timeexpansion graphs and goal decomposition for solving cooperative path finding sub-optimally. In International joint\nconference on artificial intelligence (pp.\n1916–1922).\nWagner, G. (2015). Subdimensional expansion: A framework for computationally tractable multirobot path planning (Unpublished doctoral dissertation).\nCarnegie Mellon University.\nWagner, G., & Choset, H. (2015). Subdimensional expansion for multirobot path planning. Artificial Intelligence, 219, 1–24.\nWang, K. (2012). Scalable cooperative\nmulti-agent pathfinding with tractability\nand completeness guarantees (Unpublished doctoral dissertation). Australian\nNational University.\nWang, K., & Botea, A. (2008). Fast and\nmemory-efficient multi-agent pathfinding. In International conference on automated planning and scheduling (pp.\n380–387).\nWang, K., & Botea, A. (2011). MAPP: a scalable multi-agent path planning algorithm\nwith tractability and completeness guarantees. Journal of Artificial Intelligence\nResearch, 42, 55–90.\nWurman, P., D’Andrea, R., & Mountz, M.\n(2008). Coordinating hundreds of cooperative, autonomous vehicles in warehouses. AI Magazine, 29(1), 9–20.\nYu, J., & LaValle, S. (2013a). Multi-agent\npath planning and network flow.\nIn\n4\n\n\fAI MATTERS, VOLUME X, ISSUE X\n\nXXXXX 20XX\n\nE. Frazzoli, T. Lozano-Perez, N. Roy,\n& D. Rus (Eds.), Algorithmic foundations of robotics x, springer tracts in advanced robotics (Vol. 86, pp. 157–173).\nSpringer.\nYu, J., & LaValle, S. (2013b). Planning optimal\npaths for multiple robots on graphs. In\nIeee international conference on robotics\nand automation (pp. 3612–3617).\nYu, J., & LaValle, S. (2013c). Structure and\nintractability of optimal multi-robot path\nplanning on graphs. In AAAI conference\non artificial intelligence (pp. 1444–1449).\n\nHang Ma is a Ph.D.\nstudent in computer science at the University of\nSouthern California. He\nis the recipient of a USC\nAnnenberg\nGraduate\nFellowship. His research\ninterests include artificial\nintelligence,\nmachine\nlearning and robotics.\nAdditional\ninformation\nabout Hang can be found on his webpages:\nhttp://www-scf.usc.edu/˜hangma.\nContact him at hangma@usc.edu.\nSven Koenig is a professor in computer science\nat the University of Southern California. Most of his\nresearch centers around\ntechniques for decision\nmaking (planning and\nlearning) that enable\nsingle situated agents\n(such as robots) and\nteams of agents to act\nintelligently in their environments and exhibit\ngoal-directed behavior in real-time. Additional\ninformation about Sven can be found on his\nwebpages: http://idm-lab.org. Contact\nhim at skoenig@usc.edu.\n\n5\n\n\f",
         "train",
         "14683",
         "2216"
        ],
        [
         "37",
         "19399",
         "cs.AI",
         "Artificial Intelligence",
         "1801.01681v1.pdf",
         "VulDeePecker: A Deep Learning-Based System for\nVulnerability Detection\nZhen Li∗† , Deqing Zou∗‡] , Shouhuai Xu§ , Xinyu Ou∗ , Hai Jin∗ ,\nSujuan Wang∗ , Zhijun Deng∗ and Yuyi Zhong∗\n\narXiv:1801.01681v1 [cs.CR] 5 Jan 2018\n\n∗ Services\n\nComputing Technology and System Lab, Big Data Technology and System Lab,\nCluster and Grid Computing Lab, School of Computer Science and Technology,\nHuazhong University of Science and Technology\ndeqingzou@hust.edu.cn\n† School of Cyber Security and Computer, Hebei University\n‡ Shenzhen Huazhong University of Science and Technology Research Institute\n§ Department of Computer Science, University of Texas at San Antonio\n\nAbstract—The automatic detection of software vulnerabilities\nis an important research problem. However, existing solutions to\nthis problem rely on human experts to define features and often\nmiss many vulnerabilities (i.e., incurring high false negative rate).\nIn this paper, we initiate the study of using deep learning-based\nvulnerability detection to relieve human experts from the tedious\nand subjective task of manually defining features. Since deep\nlearning is motivated to deal with problems that are very different\nfrom the problem of vulnerability detection, we need some guiding\nprinciples for applying deep learning to vulnerability detection. In\nparticular, we need to find representations of software programs\nthat are suitable for deep learning. For this purpose, we propose\nusing code gadgets to represent programs and then transform\nthem into vectors, where a code gadget is a number of (not\nnecessarily consecutive) lines of code that are semantically related\nto each other. This leads to the design and implementation\nof a deep learning-based vulnerability detection system, called\nVulnerability Deep Pecker (VulDeePecker). In order to evaluate\nVulDeePecker, we present the first vulnerability dataset for deep\nlearning approaches. Experimental results show that VulDeePecker can achieve much fewer false negatives (with reasonable\nfalse positives) than other approaches. We further apply VulDeePecker to 3 software products (namely Xen, Seamonkey, and\nLibav) and detect 4 vulnerabilities, which are not reported in\nthe National Vulnerability Database but were “silently” patched\nby the vendors when releasing later versions of these products;\nin contrast, these vulnerabilities are almost entirely missed by\nthe other vulnerability detection systems we experimented with.\n\nI.\n\nI NTRODUCTION\n\nMany cyber attacks are rooted in software vulnerabilities.\nDespite the effort that has been invested in pursuing secure programming, software vulnerabilities remain, and will continue,\nto be a significant problem. This can be justified by the fact\n] Corresponding\n\nauthor\n\nNetwork and Distributed Systems Security (NDSS) Symposium 2018\n18-21 February 2018, San Diego, CA, USA\nISBN 1-1891562-49-5\nhttp://dx.doi.org/10.14722/ndss.2018.23158\nwww.ndss-symposium.org\n\nthat the number of vulnerabilities registered in the Common\nVulnerabilities and Exposures (CVE) was approximately 4,600\nin 2010, and grew to approximately 6,500 in 2016 [4]. An\nalternate approach is to automatically detect vulnerabilities in\nsoftware programs, or simply programs for short. There have\nbeen many static vulnerability detection systems and studies\nfor this purpose, ranging from open source tools [6], [11],\n[52], to commercial tools [2], [3], [7], to academic research\nprojects [19], [28], [32], [37], [38], [49], [59], [60]. However,\nexisting solutions for detecting vulnerabilities have two major\ndrawbacks: imposing intense manual labor and incurring high\nfalse negative rates, which are elaborated below.\nOn one hand, existing solutions for vulnerability detection\nrely on human experts to define features. Even for experts,\nthis is a tedious, subjective, and sometimes error-prone task\nbecause of the complexity of the problem. In other words,\nthe identification of features is largely an art, meaning that the\nquality of the resulting features, and therefore the effectiveness\nof resulting detection system, varies with the individuals who\ndefine them. In principle, this problem can be alleviated by\nasking multiple experts to define their own features, and then\nselect the set of features that lead to better effectiveness or use\na combination of these features. However, this imposes even\nmore tedious work. As a matter of fact, it is always desirable\nto reduce, or even eliminate whenever possible, the reliance\non the intense labor of human experts. This can be justified\nby the trend of cyber defense automation, which is catalyzed\nby initiatives such as DARPA’s Cyber Grand Challenge [5].\nIt is therefore important to relieve human experts from the\ntedious and subjective task of manually defining features for\nvulnerability detection.\nOn the other hand, existing solutions often miss many\nvulnerabilities or incur high false negative rates. For example,\ntwo most recent vulnerability detection systems, VUDDY [28]\nand VulPecker [32], respectively incur a false negative rate\nof 18.2% (when detecting vulnerabilities of Apache HTTPD\n2.4.23) and 38% (when applied to 455 vulnerability samples).\nOur own independent experiments show that they respectively\nincur a false negative rate of 95.1% and 89.8% (see Table\nV in Section IV). Note that the large discrepancy between\nthe false negative rates reported in [28], [32] and the false\nnegative rates derived from our experiments is caused by the\n\n\fa vulnerability detection system that can detect only\none type of vulnerabilities would be too limited. Experimental results answer this question affirmatively.\nThis can be explained by the fact that VulDeePecker\nuses vulnerability patterns (learned as deep neural\nnetworks) to detect vulnerabilities.\n\nuse of different datasets. These high false negative rates may\nbe justified by their emphasis on low false positive rates,\nwhich are respectively 0% for VUDDY [28] and unreported\nfor VulPecker [32]. Our independent experiments show that\ntheir false positive rates are respectively 0% for VUDDY and\n1.9% for VulPecker (see Table V in Section IV). This suggests\nthat VUDDY and VulPecker are designed to achieve low false\npositive rates, which appear to be inherent to the approach of\ndetecting vulnerabilities caused by code clones; in contrast,\nwhen using this approach to detecting vulnerabilities that are\nnot caused by code clones, high false negative rates occur.\nIt would be fair to say that vulnerability detection systems\nwith high false positive rates may not be usable, vulnerability\ndetection systems with high false negative rates may not be\nuseful. This justifies the importance of pursuing vulnerability\ndetection systems that can achieve low false negative rates and\nlow false positive rates. When this cannot be achieved (because\nfalse positive and false negative are often at odds with each\nother), we may put emphasis on lowering the false negative\nrate as long as the false positive rate is not too high.\nThe aforementioned two limitations of existing solutions\nmotivate the importance of designing the vulnerability detection system without asking human experts to manually define\nfeatures and without incurring high false negative rate or false\npositive rate. In this paper, we propose a solution to the\nfollowing vulnerability detection problem while bearing in\nmind with these limitations: Given the source code of a target\nprogram, how can we determine whether or not the target\nprogram is vulnerable and if so, where are the vulnerabilities?\n\nCan human expertise help improve the effectiveness of\nVulDeePecker? Experimental results show that the effectiveness of VulDeePecker can be further improved\nby incorporating human expertise, which is not for\ndefining features though. This hints that automatic\nvulnerability detection systems, while being able to relieve human experts from the tedious labor of defining\nfeatures, may still need to leverage human expertise\nfrom other purposes. This poses an important open\nproblem for future study.\n\n•\n\nHow effective is VulDeePecker when compared with\nother vulnerability detection approaches? Experimental results show that VulDeePecker is much more\neffective than the other static analysis tools, which\nask human experts to define rules for detecting vulnerabilities, and the state-of-the-art code similaritybased vulnerability detection systems (i.e., VUDDY\nand VulPecker).\n\nThese questions may be seen as an initial effort at defining\na benchmark for evaluating the effectiveness of deep learningbased vulnerability detection systems.\nIn order to show the usefulness of VulDeePecker, we further apply it to 3 software products (namely Xen, Seamonkey,\nand Libav). VulDeePecker is able to detect 4 vulnerabilities,\nwhich are not reported in the National Vulnerability Database\n(NVD) [10] but were “silently” patched by the vendors when\nreleasing later versions of these products. In contrast, these\nvulnerabilities are almost entirely missed by the other vulnerability detection systems we experimented with. More precisely,\none of those vulnerability detection systems is able to detect 1\nof the 4 vulnerabilities (i.e., missing 3 of the 4 vulnerabilities),\nwhile the other systems missed all of the 4 vulnerabilities.\nWe will conduct more experiments to show whether or not\nVulDeePecker can detect vulnerabilities that have not been\nidentified, including possibly 0-day vulnerabilities.\n\nOur contributions. The present paper represents a first step\ntowards ultimately tackling the aforesaid problem. Specifically,\nwe make three contributions.\nFirst, we initiate the study of using deep learning for\nvulnerability detection. This approach has a great potential\nbecause deep learning does not need human experts to manually define features, meaning that vulnerability detection can\nbe automated. However, this approach is challenging because\ndeep learning is not invented for this kind of applications,\nmeaning that we need some guiding principles for applying\ndeep learning to vulnerability detection. We discuss some\npreliminary guiding principles for this purpose, including the\nrepresentation of software programs to make deep learning\nsuitable for vulnerability detection, the determination of granularity at which deep learning-based vulnerability detection\nshould be conducted, and the selection of specific neural\nnetworks for vulnerability detection. In particular, we propose\nusing code gadgets to represent programs. A code gadget is\na number of (not necessarily consecutive) lines of code that\nare semantically related to each other, and can be vectorized\nas input to deep learning.\n\nThird, since there are no readily available datasets for\nanswering the questions mentioned above, we present the first\ndataset for evaluating VulDeePecker and other deep learningbased vulnerability detection systems that will be developed in\nthe future. The dataset is derived from two data sources maintained by the National Institute of Standards and Technology\n(NIST): the NVD [10] and the Software Assurance Reference\nDataset (SARD) project [12]. The dataset contains 61,638 code\ngadgets, including 17,725 code gadgets that are vulnerable\nand 43,913 code gadgets that are not vulnerable. Among the\n17,725 code gadgets that are vulnerable, 10,440 code gadgets\ncorrespond to buffer error vulnerabilities (CWE-119) and the\nrest 7,285 code gadgets correspond to resource management\nerror vulnerabilities (CWE-399). We have made the dataset\navailable at https://github.com/CGCL-codes/VulDeePecker.\n\nSecond, we present the design and implementation of\na deep learning-based vulnerability detection system, called\nVulnerability Deep Pecker (VulDeePecker). We evaluate the effectiveness of VulDeePecker from the following perspectives:\n•\n\n•\n\nCan VulDeePecker deal with multiple types of vulnerabilities at the same time? This perspective is\nimportant because a target program in question may\ncontain multiple types of vulnerabilities, meaning that\n\nPaper organization. The rest of the paper is organized as\nfollows. Section II presents some preliminary guiding prin2\n\n\ffiner granularity than treating a program or a function as a\nunit.\n\nciples for deep learning-based vulnerability detection. Section\nIII discusses the design of VulDeePecker. Section IV describes\nour experimental evaluation of VulDeePecker and results.\nSection V discusses the limitations of VulDeePecker and open\nproblems for future research. Section VI describes the related\nprior work. Section VII concludes the present paper.\nII.\n\nIndeed, the aforementioned code gadget representation\nleads to a fine-grained granularity for vulnerability detection\nbecause a code gadget often consists of a small number of\nlines of code. This means that the code gadget representation\nnaturally satisfies Guiding Principle 2.\n\nG UIDING P RINCIPLES FOR D EEP L EARNING -BASED\nV ULNERABILITY D ETECTION\n\nC. How to select neural networks?\n\nIn this section, we propose some preliminary guiding\nprinciples for using deep learning to detect vulnerabilities.\nThese principles are sufficient for the present study, but may\nneed to be refined to serve the more general purpose of deep\nlearning-based vulnerability detection. These principles are\ncentered at answering three fundamental questions: (i) How\nto represent programs for deep learning-based vulnerability\ndetection? (ii) What is the appropriate granularity for deep\nlearning-based vulnerability detection? (iii) How to select a\nspecific neural network for vulnerability detection?\n\nNeural networks have been very successful in areas such\nas image processing, speech recognition, and natural language\nprocessing (e.g., [21], [30], [40]), which are different from\nvulnerability detection. This means that many neural networks\nmay not be suitable for vulnerability detection, and that we\nneed some principles to guide the selection of neural networks\nthat are suitable for vulnerability detection. Our examination\nsuggests the following:\nGuiding Principle 3: Because whether or not a line of\ncode contains a vulnerability may depend on the context,\nneural networks that can cope with contexts may be suitable\nfor vulnerability detection.\n\nA. How to represent software programs?\nSince deep learning or neural networks take vectors as\ninput, we need to represent programs as vectors that are\nsemantically meaningful for vulnerability detection. In other\nwords, we need to encode programs into vectors that are\nthe required input for deep learning. Note that we cannot\narbitrarily transform a program into vectors because the vectors\nneed to preserve the semantic information of the program.\nThis suggests us to use some intermediate representation as\na “bridge” between a program and its vector representation,\nwhich is the actual input to deep learning. This leads to the\nfollowing:\n\nThis principle suggests that neural networks for natural\nlanguage processing may be suitable for vulnerability detection\nbecause context is also important in natural language processing [33]. Putting the notion of context into the setting\nof the present paper, we observe that the argument(s) of a\nprogram function call is often affected by earlier operations in\nthe program and may also be affected by later operations in\nthe program.\nSince there are many neural networks for natural language processing, let us start with Recurrent Neural Networks\n(RNNs) [51], [53]. These neural networks are effective in\ncoping with sequential data, and indeed have been used for\nprogram analysis (but not for vulnerability detection purposes)\n[20], [48], [56], [57]. However, RNNs suffer from the Vanishing Gradient (VG) problem, which can cause ineffective model\ntraining [16]. Note that the VG problem is inherited by the\nBidirectional variant of RNNs, called BRNNs [47]. We would\nprefer neural networks that do not suffer from the VG problem.\n\nGuiding Principle 1: Programs can be first transformed\ninto some intermediate representation that can preserve (some\nof) the semantic relationships between the programs’ elements\n(e.g., data dependency and control dependency). Then, the\nintermediate representation can be transformed into a vector\nrepresentation that is the actual input to neural networks.\nAs we will elaborate later, Guiding Principle 1 leads us to\npropose an intermediate representation dubbed code gadget.\nThe term code gadget is inspired by the term of gadget in the\ncontext of code-reuse attacks (see, e.g., [18]), because a code\ngadget is a small number of (not necessarily consecutive) lines\nof code.\n\nThe VG problem can be addressed with the idea of memory\ncells into RNNs, including the Long Short-Term Memory\n(LSTM) cell and the Gated Recurrent Unit (GRU) cell [17],\n[22]. Since the GRU does not outperform the LSTM on\nlanguage modeling [27], we select LSTM for vulnerability\ndetection and defer its comparison with GRU to future work.\nHowever, even LSTM may be insufficient for vulnerability\ndetection because it is unidirectional (i.e., from earlier LSTM\ncells to later LSTM cells). This is because the argument(s) of a\nprogram function call may be affected by earlier statements in\nthe program and may be also affected by the later statements.\nThis suggests that unidirectional LSTM may be insufficient\nand that we should use Bidirectional LSTM (BLSTM) for\nvulnerability detection.\n\nB. What is an appropriate granularity?\nSince it is desirable not only to detect whether a program\nis vulnerable or not, but also to pin down the locations of\nthe vulnerabilities, a finer granularity should be used for\ndeep learning-based vulnerability detection. This means that\nvulnerability detection should not be conducted at the program\nor function level, which are too coarse-grained because a\nprogram or function may have many lines of code and pinning\ndown the locations of its vulnerability can be a difficult task\nby itself. This leads to:\n\nFigure 1 highlights the structure of BLSTM neural network,\nwhich has a number of BLSTM layers, a dense layer, and\na softmax layer. The input to the learning process is in a\ncertain vector representation. The BLSTM layers have two\ndirections, forward and backward. The BLSTM layers contain\n\nGuiding Principle 2: In order to help pin down the locations of vulnerabilities, programs should be represented at a\n3\n\n\fsome complex LSTM cells, which are treated as black-boxes in\nthe present paper and therefore deferred to Appendix A. The\ndense layer reduces the number of dimensions of the vectors\nreceived from the BLSTM layers. The softmax layer takes\nthe low-dimension vectors received from the dense layer as\ninput, and is responsible for representing and formatting the\nclassification result, which provides feedback for updating the\nneural network parameters in the learning phase. The output\nof the learning phase is a BLSTM neural network with finetuned model parameters, and the output of the detection phase\nis the classification results.\n\ncalls, the key points are the library/API function calls; for\nvulnerabilities that are caused by improper uses of arrays, the\nkey points are the arrays. It is important to note that a type\nof vulnerabilities may have multiple kinds of key points. For\nexample, buffer error vulnerabilities may correspond to the\nfollowing key points: library/API function calls, arrays, and\npointers. Moreover, the same kind of key points may exist in\nmultiple types of vulnerabilities. For example, both buffer error\nand resource management error vulnerabilities may contain\nthe key points of library/API function calls. Precisely defining\nthe heuristic concept of key point is beyond the scope of the\npresent paper and is left as an interesting problem for future\nresearch; instead, we focus on using this heuristic concept as\nthe “lens” to use deep learning to learn vulnerability patterns.\n\nOutput: learned BLSTM with parameters/\nclassification results\nSoftmax layer\n\n.. .\n\n.. .\n\nLSTM\n\nLSTM\n\nCorresponding to the key point of library/API function\ncalls, code gadgets can be generated by the means of data flow\nor control flow analysis of program, for which there are well\nknown algorithms [23], [50] and readily usable commercial\nproducts such as Checkmarx [2]. It is worth mentioning that\nCheckmarx also detects vulnerabilities based on some rules\nthat are manually defined by human experts. However, we do\nnot use its rules for vulnerability detection; instead, we will\ncompare the effectiveness of VulDeePecker against it.\n\n.. .\n\n...\n\n...\n\nVectors\n\nFigure 1.\n\n...\n\nLSTM\n...\n\nLSTM\n\nLSTM\n\n...\n\nLSTM\n\n...\n\n...\n\n...\n\nLSTM\n\n...\n\nLSTM\n\n...\n\nDense layer\n\nBLSTM layers\n\nIn this paper, we focus on using the particular key point of\nlibrary/API function calls to demonstrate its usefulness in deep\nlearning-based vulnerability detection. This is motivated by the\nobservation that many vulnerabilities are related to library/API\nfunction calls. It is also an interesting future work to investigate\nthe usefulness of other kinds of key points.\n\nA brief review of BLSTM neural network\n\nIII.\n\nD ESIGN OF V UL D EE P ECKER\n\nOur objective is to design a vulnerability detection system\nthat can automatically tell whether a given program in source\ncode is vulnerable or not and if so, the locations of the\nvulnerabilities. This should be achieved without asking human\nexperts to manually define features and without incurring\nhigh false negative rates (as long as the false positive rates\nare reasonable). In this section, we describe the design of\nVulDeePecker. We start with a discussion on the notion of code\ngadget, because it is crucial to the representation of programs.\nThen, we give an overview of VulDeePecker and elaborate its\ncomponents.\n\nB. Overview of VulDeePecker\n\nA. Defining code gadget\n\nStep I: Extracting the library/API function calls and the\ncorresponding program slices. This has two sub-steps, which\nare highlighted below and elaborated in Section III-C.\n\nAs highlighted in Figure 2, VulDeePecker has two phases:\na learning (i.e., training) phase and a detection phase. The\ninput to the learning phase is a large number of training\nprograms, some of which are vulnerable and the others are\nnot. By “vulnerable” we mean that a program contains one\nor multiple known vulnerabilities. The output of the learning\nphase is vulnerability patterns, which are coded into a BLSTM\nneural network.\n1) The learning phase: As highlighted in Figure 2(a), the\nlearning phase has 4 steps.\n\nIn order to represent programs in vectors that are suitable\nfor the input to neural networks, we first propose transforming\nprograms into a representation of code gadget, which is defined\nas follows:\nDefinition 1: (Code gadget) A code gadget is composed of\na number of program statements (i.e., lines of code), which are\nsemantically related to each other in terms of data dependency\nor control dependency.\nIn order to generate code gadgets, we propose the heuristic\nconcept of key point, which can be seen as a “lens” through\nwhich we can represent programs from a certain perspective.\nIntuitively, the heuristic concept of key point can be seen as,\nin a sense, the “center” of a vulnerability or the piece of code\nthat hints the existence of a vulnerability. For vulnerabilities\nthat are caused by improper uses of library/API function\n4\n\n•\n\nStep I.1: Extracting library/API function calls from\nthe training programs, while noting that the current\nversion of VulDeePecker focuses on vulnerabilities\nrelated to the key point of library/API function calls.\n\n•\n\nStep I.2: Extracting one or multiple program slices for\neach argument (or variable) of a library/API function\ncall that is extracted in Step I.1. In this paper, a\nprogram slice represents the statements of a program\n(i.e., lines of code) that are semantically related to\nan argument of a library/API function call, while\nnoting that the notion of program slice was originally\nintroduced to represent the statements of a program\nwith respect to a program point or variable [55].\n\n\fStep IV: Training BLSTM\nneural network\nSoftmax\nlayer\n\n...\n\nDense\nlayer\n\n...\n\nStep I.2: Extracting\nprogram slices\ncorresponding to the\narguments of the\nlibrary/API function calls\n\nCode gadget\nCode gadget 1\nCode gadget 2\nCode gadget 3\nCode gadget 4\nCode gadget 5\n...\n\nLabel\n1\n0\n1\n0\n0\n...\n\nStep III.2: Encoding the\nsymbolic representations of\ncode gadgets into vectors\nThe symbolic\nrepresentation of\nthe ith code gadget\nToken Vector\nmain\nvi1\n(\nvi2\nint\nvi3\nargc\nvi4\n...\n...\n\nBLSTM\nlayers\n\nLSTM\n\n...\n\nLSTM\n\nLSTM\n\n...\n\nvi2\n\n...\n\n[ vi1\n\nLSTM\n\nLSTM\n...\n\nLSTM\n\nStep II.2: Each code\ngadget is labeled\nas “1” or “0”\n\nOutput\n\n...\n\nStep III.1: Transforming\ncode gadgets into\nsymbolic representations\n\n...\n\nTraining\nprograms\n(i.e.,\nsoftware\nprograms\nfor training\ndeep\nlearning\nneural\nnetworks)\n\nStep III: Transforming code\ngadgets into vectors\n\nStep I: Extracting library/API Step II: Generating code\ngadgets and their ground\nfunction calls and the\ntruth labels\ncorresponding program slices\nfrom training programs\nStep II.1:\nStep I.1: Extracting\nAssembling\nlibrary/API function\nprogram\nslices into\ncalls from the training\ncode gadgets\nprograms\n\n...\n\nInput\n\nLSTM\n\nLSTM\n\nvi(τ-1)\n\nBLSTM neural\nnetwork with\nfine-tuned\nmodel\nparameters\n\nviτ ]\n\nVector of symbolic\nrepresentation\n\n[vi1,vi2, …, viτ]\n\n(a) Learning phase\nInput\nTarget\nprograms\n\nTrained BLSTM\nneural network\nwith fine-tuned\nmodel\nparameters\n\nStep V: Transforming target programs into code gadgets and vectors\nStep V.1: Extracting\nlibrary/API function\ncalls from the target\nprograms\n(similar to Step I.1)\n\nStep V.2: Extracting\nprogram slices\ncorresponding to\nthe function calls\n(similar to Step I.2)\n\nStep V.3: Assembling\nprogram slices into\ncode gadgets\n(similar to Step II.1)\n\nStep V.4: Transforming\ncode gadgets into\nsymbolic\nrepresentations\n(similar to Step III.1)\n\nStep V.5: Encoding\nthe symbolic\nrepresentations\ninto vectors\n(similar to Step III.2)\n\nStep VI: Detection\nStep VI: Applying the trained\nBLSTM neural network to\nclassify the code gadgets of\ntarget programs in vector\nrepresentation\n\nOutput\n\nCode gadgets\nare vulnerable\nor not\n\n(b) Detection phase\nFigure 2. Overview of VulDeePecker: the learning phase generates vulnerability patterns, and the detection phase uses these vulnerability patterns to determine\nwhether a target program is vulnerable or not and if so, the locations of the vulnerabilities (i.e., the corresponding code gadgets).\n\nStep II: Generating code gadgets of the training programs\nand their ground truth labels. This step has two sub-steps,\nwhich are highlighted below and elaborated in Section III-D.\n•\n\nStep II.1: Assembling the program slices obtained\nin Step I.2 into code gadgets, one code gadget per\nlibrary/API function call. A code gadget does not\nnecessarily correspond to some consecutive lines of\ncode. Instead, it consists of multiple lines of code that\nare semantically related to each other (i.e., inheriting\nthe semantic relation that is encoded in those program\nslices).\n\n•\n\nStep II.2: Labeling the ground truth of code gadgets.\nThis step labels each code gadget as “1” (i.e., vulnerable) or “0” (i.e., not vulnerable). The ground truth\nlabels of code gadgets are available because we know\nwhether a training program is vulnerable or not and\nif it is vulnerable, we also know the locations of the\nvulnerabilities.\n\nStep IV: Training a BLSTM neural network. Having encoded the code gadgets into vectors and obtained their ground\ntruth labels, the training process for learning a BLSTM neural\nnetwork is standard.\n2) The detection phase: Given one or multiple target\nprograms, we extract library/API function calls from them as\nwell as the corresponding program slices, which are assembled\ninto code gadgets. The code gadgets are transformed into\ntheir symbolic representations, which are encoded into vectors\nand used as input to the trained BLSTM neural network.\nThe network outputs which vectors, and therefore which code\ngadgets, are vulnerable (“1”) or not (“0”). If a code gadget is\nvulnerable, it pins down the location of the vulnerability in the\ntarget program. As highlighted in Figure 2(b), this phase has\ntwo steps.\nStep V: Transforming target programs into code gadgets\nand vectors. It has five sub-steps.\n•\n\nStep V.1: Extracting library/API function calls from\nthe target programs (similar to Step I.1).\n\n•\n\nStep V.2: Extracting program slices according to the\narguments of the library/API function calls (similar to\nStep I.2).\n\nStep III.1: Transforming code gadgets into certain\nsymbolic representations, which will be elaborated\nlater. This step aims to preserve some semantic information of the training programs.\n\n•\n\nStep V.3: Assembling the program slices into code\ngadgets (similar to Step II.1).\n\n•\n\nStep V.4: Transforming the code gadgets to their\nsymbolic representations (similar to Step III.1).\n\nStep III.2: Encoding code gadgets in the symbolic representation obtained in Step III.1 into vectors, which\nare the input for training a BLSTM neural network.\nThis is necessary in order to use neural networks in\ngeneral.\n\n•\n\nStep V.5: Encoding the symbolic representations of\ncode gadgets into vectors (similar to Step III.2).\n\nStep III: Transforming code gadgets into vector representations. This step has two sub-steps, which are highlighted\nbelow and elaborated in Section III-E.\n•\n\n•\n\nStep VI: Detection. This step uses the learned BLSTM neural\nnetwork to classify the vectors corresponding to the code\n5\n\n\f1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\nvoid\ntest(char *str)\n{\nint MAXSIZE=40;\nchar buf[MAXSIZE];\n\n13\n\nif(!buf)\nreturn;\nstrcpy(buf, str); /*string copy*/\n}\nint\nmain(int argc, char **argv)\n{\nchar *userstr;\n\n}\n\nif(argc > 1) {\nuserstr = argv[1];\ntest(userstr);\n}\nreturn 0;\n\nProgram source code\n\nThe backward function call strcpy has two arguments,\nbuf and str, each of which leads to a backward slice.\nThe slice corresponding to buf consists of statements\n15\nbelong ing to the user-defined function test (indicated\nstr main() by a dashed rectangle).\nThe slice corresponding to str consists of statements\nscattered in two user-defined functions, main and\n18\ntest, which are also indicated by dashed rectangles.\nstr\nstr\n\ntest()\n4\n\nBackward\nfu nction call\n\n19\n\nbuf\n\nstr\n\n5\n\n9 strcpy(buf, str);\n/*string copy*/\n\n2\n\nbuf\n\nstr test()\n\n9\n\nStep I.1: Extracting\nlibrary/API function\ncalls\n\n9\n\nStep I.2: Generating\nslices of arguments in\nlibrary/API function calls\n\n13\n15\n18\n19\n2\n4\n5\n9\n\nmain(int argc, char **argv)\nchar *userstr;\nuserstr = argv[1];\ntest(userstr);\ntest(char *str)\nint MAXSIZE=40;\nchar buf[MAXSIZE];\nstrcpy(buf, str); /*string copy*/\n\nmain()\ntest()\n\nStep II.1 Assembling slices\ninto code gadgets\n\nFigure 3. Illustrating the extraction of library/API function calls (Step I.1) from a (training) program, which contains a backward function call (i.e., strcpy)\nthat is also used as an example to demonstrate the extraction of program slices (Step I.2) and the assembly of program slices into code gadgets (Step II.1).\n\ngadgets that are extracted from the target programs. When a\nvector is classified as “1” (i.e., vulnerable), it means that the\ncorresponding code gadget is vulnerable and the location of\nthe vulnerability is pinned down. Otherwise, the corresponding\ncode gadget is classified as “0” (i.e., not vulnerable).\n\n2) Step I.2: Extracting program slices: This step generates program slices corresponding to the arguments of the\nlibrary/API function calls that are extracted from the training\nprograms. We define two kinds of slices: forward slices and\nbackward slices, where a forward slice corresponds to the\nstatements that are affected by the argument in question and a\nbackward slice corresponds to the statements that can affect the\nargument in question. We take advantage of the commercial\nproduct Checkmarx [2], more specifically its data dependency\ngraph, to extract these two kinds of slices. The basic idea is\nthe following:\n\nSteps I-III are respectively elaborated in the following\nsubsections. Steps IV and VI are standard and Step V is similar\nto some of Steps I-III.\nC. Step I: Extracting library/API function calls and program\nslices\n1) Step I.1: Extracting library/API function calls: We\nclassify library/API function calls into two categories: forward\nlibrary/API function calls and backward library/API function\ncalls. Forward library/API function calls are the function calls\nthat receive one or multiple inputs directly from the external\ninput, such as the command line, a program, a socket, or a file.\nFor example, the recv function call is a forward library/API\nfunction call because it receives data from a socket directly.\nBackward library/API function calls are the function calls that\ndo not receive any external input directly from the environment\nin which the program runs.\n\n•\n\nFor each argument in a forward library/API function\ncall, one or multiple forward slices are generated,\nwith the latter corresponding to the case that the slice\nrelated to the argument is branched at, or after, the\nlibrary/API function call.\n\n•\n\nFor each argument in a backward library/API function\ncall, one or multiple backward slices are generated,\nwith the latter corresponding to the case that multiple\nslices related to the argument are merged at, or prior\nto, the library/API function call.\n\nFigure 3 shows an example of a backward library/API\nfunction call strcpy (line 9). It is a backward library/API\nfunction call because it does not receive any external input\ndirectly.\n\nNote that a program slice consists of multiple statements\nthat may belong to multiple user-defined functions. That is, a\nslice can go beyond the boundary of user-defined functions in\nquestion.\n\nWe highlight a distinction between forward and backward\nlibrary/API function calls. For forward library/API function\ncalls, the statements influenced by the input arguments are critical because they may be vulnerable to improper (e.g., sophisticatedly crafted) argument values; for backward library/API\nfunction calls, the statements influencing the values of the\narguments are critical because they could make the library/API\nfunction calls vulnerable. This insight will be leveraged to\nguide the heuristic padding of the vector representations of\ncode gadgets.\n\nFigure 3 shows an example program that contains the\nlibrary function call strcpy, which has two arguments buf and\nstr. Since strcpy is a backward function call, for each of its\narguments we will generate a backward slice. For argument\nbuf , the slice consists of three statements, namely lines 4,\n5, and 9 of the program, which belong to the user-defined\nfunction test. For argument str, the slice consists of six\nstatements, namely lines 13, 15, 18, 19, 2, and 9 of the\nprogram, where the first 4 belong to the user-defined function\nmain and the last 2 belong to the user-defined function test.\n6\n\n\fSecond, map user-defined variables to symbolic names (e.g.,\n“VAR1”, “VAR2”) in the one-to-one fashion, while noting that\nmultiple variables may be mapped to the same symbolic name\nwhen they appear in different code gadgets. Third, map userdefined functions to symbolic names (e.g., “FUN1”, “FUN2”)\nin the one-to-one fashion, while noting that multiple functions\nmay be mapped to the same symbolic name when they appear\nin different code gadgets.\n\nThe two slices are chains (i.e., a linear structure) because\nCheckmarx uses chains to represent slices, while noting that\nslices can also be represented by trees [23], [50]. Since the\nlinear structure can only represent one individual slice, a\nlibrary/API function call often corresponds to multiple slices.\nD. Step II: Extracting code gadgets and labeling their ground\ntruth\n1) Step II.1: Assembling program slices into code gadgets:\nThe program slices generated in the previous step can be\nassembled into code gadgets as follows.\n\n13 main(int argc, char **argv)\n15 ch ar *userstr;\n18 userstr = argv[1];\n19 test(userstr);\n2 test(char *str)\n4 int MAXSIZE=40;\n5 ch ar buf[MAX SIZE];\n9 strcpy(buf, str); /*string copy*/\n\nFirst, given a library/API function call and the corresponding program slices, we combine the statements (i.e., pieces of\ncode) belonging to the same, user-defined function into a single\npiece according to the order of the statements’ appearance\nin the user-defined function. If there is a duplication of any\nstatement, the duplication is eliminated.\n\nInp ut: code gadget (from Step II.1)\n\nIn the example shown in Figure 3, three statements (i.e.,\nlines 4, 5, and 9) belonging to the user-defined function test\nconsists the program slice corresponding to the argument buf ,\nand two statements (i.e., lines 2 and 9) belonging to the\nuser-defined function test are a piece of the program slice\ncorresponding to the argument str. Therefore, we need to\nassemble them into a single piece because they are related to\nthe same function test. According to the line numbers of these\nstatements’ appearance in the function test, this would lead to\n2 → 4 → 5 → 9 → 9. Since the statement corresponding\nto line 9 is duplicated, we eliminate the duplication to derive\na piece of assembled statements 2 → 4 → 5 → 9, which\ncorrespond to the function test.\n\n13 main(int argc, char **argv)\n15 ch ar *userstr;\n18 userstr = argv[1];\n19 test(userstr);\n2 test(char *str)\n4 int MAXSIZE=40;\n5 char buf[MAXSIZE];\n9 strcpy(buf, str);\n\n(1) Remove non-ASCII\ncharacters and comments\n\n13 main(int argc, char **argv)\n15 char *VAR1;\n18 VAR1 = argv[1];\n19 test(VAR1);\n2 test(ch ar *VAR2)\n4 int VAR3=40;\n5 ch ar VAR4[VAR3];\n9 strcpy(VAR5, VAR2);\n\n13 main(int argc, ch ar **argv)\n15 char *VAR1;\n18 VAR1 = argv[1];\n19 FUN1(VAR1);\n2 FUN1(char *VAR2)\n4 int VAR3=40;\n5 ch ar VAR4[VAR3];\n9 strcpy(VAR5, VAR2);\n\n(2) Map user-defined variables\n\n(3) Map user-defined functions\n\nFigure 4. Illustration of Step III.1: transforming code gadgets into their\nsymbolic representations\n\nFigure 4 highlights the above process by using the code\nfragment generated by Step II.1 as shown in Figure 3.\n2) Step III.2: Encoding the symbolic representations into\nvectors: Each code gadget needs to be encoded into a vector\nvia its symbolic representation. For this purpose, we divide\na code gadget in the symbolic representation into a sequence\nof tokens via lexical analysis, including identifiers, keywords,\noperators, and symbols. For example, a code gadget in the\nsymbolic representation,\n\nSecond, assembling the statements belonging to different,\nuser-defined functions into a single code gadget. If there is\nalready an order between two pieces of statements belonging to\nthese user-defined functions, this order is preserved; otherwise,\na random order is used.\n\n“strcpy(VAR5, VAR2); ”\n\nIn the example shown in Figure 3, when assembling the\npiece of statements belonging to the user-defined function\nmain (i.e., lines 13, 15, 18, and 19) and the assembled piece of\nstatements belonging to user-defined function test (i.e., lines\n2, 4, 5, and 9), we obtain 13 → 15 → 18 → 19 → 2 → 4 →\n5 → 9, which is a code gadget corresponding to the library\nfunction call strcpy. This code gadget preserves the order of\nuser-defined functions that are contained in the program slice\ncorresponding to the argument str.\n\nis represented by a sequence of 7 tokens:\n“strcpy”, “(”, “VAR5”, “,”, “VAR2”, “)”, and “;”.\nThis leads to a large corpus of tokens. In order to transform\nthese tokens into vectors, we use the word2vec tool [14], which\nis selected because it is widely used in text mining [58]. This\ntool is based on the idea of distributed representation, which\nmaps a token to an integer that is then converted to a fixedlength vector [43].\n\n2) Step II.2: Labeling the ground truth: Each code gadget\nneeds to be labeled as “1” (i.e., vulnerable) and “0” (i.e., not\nvulnerable). If a code gadget corresponds to a vulnerability that\nis known in the training dataset, it is labeled as “1”; otherwise,\nit is labeled as “0”. In Section IV-C, we will discuss the\nlabeling of ground truth in details, when dealing with programs\nrelated to specific vulnerability data sources.\n\nSince code gadgets may have different numbers of tokens,\nthe corresponding vectors may have different lengths. Since\nBLSTM takes equal-length vectors as input, we need to make\nan adjustment. For this purpose, we introduce a parameter τ\nas the fixed length of vectors corresponding to code gadgets.\n•\n\nWhen a vector is shorter than τ , there are two cases: if\nthe code gadget is generated from a backward slice or\ngenerated by combining multiple backward slices, we\npad zeros in the beginning of the vector; otherwise,\nwe pad zeros to the end of the vector.\n\n•\n\nWhen a vector is longer than τ , there are also two\ncases: if the code gadget is generated from one\n\nE. Step III: Transforming code gadgets into vectors\n1) Step III.1: Transforming code gadgets into their symbolic representations: This step aims to heuristically capture\nsome semantic information in the programs for training a\nneural network. First, remove the non-ASCII characters and\ncomments because they have nothing to do with vulnerability.\n7\n\n\f·T P R\nF 1-measure metric F 1 = 2·P\nP +T P R takes consideration of\nboth precision and true positive rate.\n\nbackward slice, or generated by combining multiple\nbackward slices, we delete the beginning part of the\nvector; otherwise, we delete the ending part of the\nvector.\n\nIt would be ideal that a vulnerability detection system\nneither misses vulnerabilities (i.e., F N R ≈ 0 and T P R ≈ 1)\nnor triggers false alarms (i.e., F P R ≈ 0 and P ≈ 1), which\nmeans F 1 ≈ 1. However, this is difficult to achieve in practice,\nand often forces one to trade the effectiveness in terms of one\nmetric for the effectiveness in terms of another metric. In this\nstudy, we prefer to achieving low FNR and low FPR.\n\nThis ensures that the last statement of every code gadget\ngenerated from a backward slice is a library/API function call,\nand that the first statement of every code gadget generated\nfrom a forward slice is a library/API function call. As a result,\nevery code gadget is represented as a τ -bit vector. The length\nof vectors is related to the number of hidden nodes at each\nlayer of the BLSTM, which is a parameter that can be tuned\nto improve the accuracy of vulnerability detection (see Section\nIV-C).\nIV.\n\nB. Preparing input to VulDeePecker\nCollecting programs. There are two widely used sources of\nvulnerability data maintained by the NIST: the NVD [10]\nwhich contains vulnerabilities in production software, and\nthe SARD project [12] which contains production, synthetic,\nand academic security flaws or vulnerabilities. In the NVD,\neach vulnerability has a unique Common Vulnerabilities and\nExposures IDentifier (CVE ID) and a Common Weakness\nEnumeration IDentifier (CWE ID) that indicates the type of\nthe vulnerability in question. We collect the programs that\ncontain one or multiple vulnerabilities. In the SARD, each\nprogram (i.e., test case) corresponds to one or multiple CWE\nIDs because a program can have multiple types of vulnerabilities. Therefore, programs with one or multiple CWE IDs are\ncollected.\n\nE XPERIMENTS AND R ESULTS\n\nOur experiments are centered at answering the following\nthree research questions (RQs):\n•\n\nRQ1: Can VulDeePecker deal with multiple types of\nvulnerabilities at the same time?\nA vulnerability detection system should be able to\ndetect multiple types of vulnerabilities at the same\ntime, because multiple detection systems need to be\nmaintained otherwise. For answering this question, we\nwill conduct experiments involving one or multiple\ntypes of vulnerabilities.\n\n•\n\nRQ2: Can human expertise (other than defining features) improve the effectiveness of VulDeePecker?\nFor answering this question, we will investigate the\neffectiveness of using some manually-selected library/API function calls vs. the effectiveness of using\nall of the library/API function calls.\n\n•\n\nRQ3: How effective is VulDeePecker when compared\nwith other vulnerability detection approaches?\nFor answering this question, we will compare\nVulDeePecker with other approaches, including some\nstatic analysis tools and code similarity-based vulnerability detection systems.\n\nIn the present paper, we focus on two types of vulnerabilities: buffer error (i.e., CWE-119) and resource management\nerror (i.e., CWE-399), each of which has multiple subtypes.\nThese vulnerabilities are very common, meaning that we can\ncollect enough data for using deep learning. We select 19\npopular C/C++ open source products, including the Linux\nkernel, Firefox, Thunderbird, Seamonkey, Firefox esr, Thunderbird esr, Wireshark, FFmpeg, Apache Http Server, Xen,\nOpenSSL, Qemu, Libav, Asterisk, Cups, Freetype, Gnutls,\nLibvirt, and VLC media player, which contain, according to\nthe NVD, these two types of vulnerabilities. We also collect\nthe C/C++ programs in the SARD that contain these two\ntypes of vulnerabilities. In total, we collect from the NVD\n520 open source software programs related to buffer error\nvulnerabilities and 320 open source software programs related\nto resource management error vulnerabilities; we also collect\nfrom the SARD 8,122 programs (i.e., test cases) related to\nbuffer error vulnerabilities and 1,729 programs related to\nresource management error vulnerabilities. Note that program\ncontaining a vulnerability may actually consist of multiple\nprogram files.\n\nA. Metrics for evaluating vulnerability detection systems\nWe use the widely used metrics false positive rate (F P R),\nfalse negative rate (F N R), true positive rate or recall (T P R),\nprecision (P ), and F 1-measure (F 1) to evaluate vulnerability detection systems [39]. Let TP be the number of samples\nwith vulnerabilities detected correctly, FP be the number of\nsamples with false vulnerabilities detected, FN be the number\nof samples with true vulnerabilities undetected, and TN be\nthe number of samples with no vulnerabilities undetected.\nFP\nThe false positive rate metric F P R = FP+TN\nmeasures the\nratio of false positive vulnerabilities to the entire population\nof samples that are not vulnerable. The false negative rate\nFN\nmetric F N R = TP+FN\nmeasures the ratio of false negative\nvulnerabilities to the entire population of samples that are\nvulnerable. The true positive rate or recall metric T P R =\nTP\nTP+FN measures the ratio of true positive vulnerabilities to the\nentire population of samples that are vulnerable, while noting\nTP\nthat T P R = 1 − F N R. The precision metric P = TP+FP\nmeasures the correctness of the detected vulnerabilities. The\n\nTraining programs vs. target programs. We randomly\nchoose 80% of the programs we collect as training programs\nand the remaining 20% as target programs. This ratio is applied\nequally when dealing with one or both types of vulnerabilities.\nC. Learning BLSTM neural networks\nThis corresponds to the learning phase of VulDeePecker.\nWe implement the BLSTM neural network in Python using\nTheano [24] together with Keras [8]. We run experiments on\na machine with NVIDIA GeForce GTX 1080 GPU and Intel\nXeon E5-1620 CPU operating at 3.50GHz.\nStep I: Extracting library/API function calls and corresponding program slices. We extract C/C++ library/API\n8\n\n\fTable I.\n\nfunction calls from the programs. There are 6,045 C/C++\nlibrary/API function calls that involve standard library function\ncalls [1], basic Windows API and Linux kernel API function\ncalls [9], [13]. In total, we extract 56,902 library/API function\ncalls from the programs, including 7,255 forward function calls\nand 49,647 backward function calls.\n\nDataset\nBE-ALL\nRM-ALL\nHY-ALL\nBE-SEL\nRM-SEL\nHY-SEL\n\nIn order to answer the RQs, we also manually select 124\nC/C++ library/API function calls (including function calls with\nwildcard) related to buffer error vulnerabilities (CWE-119)\nand 16 C/C++ library/API function calls related to resource\nmanagement error vulnerabilities (CWE-399). These function\ncalls are selected because the aforementioned commercial\ntool Checkmarx [2] claims, using their own rules written by\nhuman experts, that they are related to these two types of\nvulnerabilities. The list of these function calls are deferred\nto Table VII in the Appendix B. Correspondingly, we extract\n40,351 library/API function calls from the training programs,\nincluding 4,012 forward function calls and 36,339 backward\nfunction calls. For each argument of the library/API function\ncalls, one or multiple program slices are extracted.\n\nBE-ALL: The subset of CGD corresponding to Buffer\nError vulnerabilities (CWE-119) and ALL library/API\nfunction calls (i.e., extracted without human expert).\n\n•\n\nRM-ALL: The subset of CGD corresponding to Resource Management error vulnerabilities (CWE-399)\nand ALL library/API function calls.\n\n•\n\nHY-ALL: The subset of CGD corresponding to the\nHYbrid of (i.e., both) buffer error vulnerabilities\n(CWE-119) and resource management error vulnerabilities (CWE-399) and ALL library/API function\ncalls. That is, it is the same as the CGD.\n\n•\n\nBE-SEL: The subset of CGD corresponding to Buffer\nError vulnerabilities (CWE-119) and manually SELected function calls (rather than all function calls).\n\n•\n\nRM-SEL: The subset of CGD corresponding to Resource Management error vulnerabilities (CWE-399)\nand manually SELected function calls.\n\n•\n\nHY-SEL: The subset of CGD corresponding to the\nHYbrid of buffer error vulnerabilities (CWE-119) and\nresource management error vulnerabilities (CWE-399)\nand manually SELected function calls.\n\n#Code\ngadgets\n39,753\n21,885\n61,638\n26,720\n16,198\n42,918\n\n#Vulnerable\ncode gadgets\n10,440\n7,285\n17,725\n8,119\n6,573\n14,692\n\n#Not vulnerable\ncode gadgets\n29,313\n14,600\n43,913\n18,601\n9,625\n28,226\n\nof the NVD, we focus on the vulnerabilities whose patches\ninvolve line deletions or modifications. This process has two\nsteps. In the first step, a code gadget is automatically labeled\nas “1” (i.e., vulnerable) if it contains at least one statement that\nis deleted or modified according to the patch, and labeled as\n“0” otherwise (i.e., not vulnerable). However, this automatic\nprocess may mislabel some code gadgets, which are not\nvulnerable, as “1”. In order to remove these mislabels, the\nsecond step is to manually check the code gadgets that are\nlabeled as “1” so as to correct the mislabels (if any).\nRecall that each program in the SARD is already labeled\nas good (i.e., no security defect), bad (i.e., containing security\ndefects), or mixed (i.e., containing functions with security\ndefects and their patched versions) with corresponding CWE\nIDs. For the code gadgets extracted from the programs with\nrespect to the SARD, a code gadget extracted from a good\nprogram is labeled as “0” (i.e., not vulnerable), and a code\ngadget extracted from a bad or mixed program is labeled as “1”\n(i.e., vulnerable) if it contains at least one vulnerable statement\nand “0” otherwise. Since we used heuristics in the labeling\nprocess for the SARD program, we looked at the labels of\n1,000 random code gadgets and found that only 6 of them (i.e.\n0.6%) were mislabeled. These mislabeled samples are caused\nby the fact that a statement in a piece of code that is not\nvulnerable is the same as a statement in a piece of code that\nis vulnerable. As the mislabeled code gadgets are very few\nand the neural networks are robust against a small portion of\nmislabeled samples, it is unnecessary to check manually all\nlabels of the code gadgets that are extracted for the SARD\nprograms.\n\nStep II.1: Generating code gadgets. Code gadgets are generated from program slices. We obtain a Code Gadget Database\n(CGD) of 61,638 code gadgets, among which 48,744 code\ngadgets are generated from program slices of training programs, and 12,894 code gadgets are generated from program\nslices of target programs. The time complexity for generating\ngadgets mainly depends on the data flow analysis tool. For\nexample, it takes 883 seconds to generate 2,494 code gadgets\nfrom 100 programs (99,232 lines) that are randomly selected\nthe SARD, meaning an average of 354 milliseconds per code\ngadget. For answering the RQs mentioned above, we use the\nCGD to derive the following 6 datasets.\n•\n\nDATASETS FOR ANSWERING THE RQ S\n\nIt is possible to encounter the situation that the same code\ngadget is labeled with both “1” and “0” (i.e., conflicting labels).\nOne cause of this phenomenon is the imperfection of the data\nflow analysis tool. In this case, we simply delete these code\ngadgets. As a result, 17,725 code gadgets are labeled as “1”\nand 43,913 code gadgets are labeled as “0”. Among the 17,725\ncode gadgets labeled as “1”, 10,440 code gadgets correspond\nto the buffer error vulnerabilities and 7,285 code gadgets\ncorrespond to the resource management error vulnerabilities.\nTable I shows the number of code gadgets that are vulnerable\n(Column 3) and the number of code gadgets that are not\nvulnerable in each dataset (Column 4).\nStep III: Transforming code gadgets into vectors. The CGD\ncontains a total number of 6,166,401 tokens, of which 23,464\nare different. After mapping user-defined variable names and\nfunction names to some symbolic names, the number of\ndifferent tokens is further reduced to 10,480. These symbolic\nrepresentations are encoded into vectors, which are used as the\ninput for training a BLSTM neural network.\n\nTable I summarizes the number of code gadgets in these\ndatasets.\nStep II.2: Labeling code gadgets. Code gadgets are labeled\nas follows. For the code gadgets extracted from the programs\n\nStep IV: Training BLSTM neural network. For each dataset\n9\n\n\fcalls that are related to resource management error vulnerabilities (i.e., 16) is far smaller than the number of library/API\nfunction calls that are related to buffer error vulnerabilities\n(i.e., 124). We also observe that, in terms of the FPR and P\nmetrics, the neural network trained from the HY-ALL dataset\nis not as good as the neural network trained from the BE-ALL\nor RM-ALL dataset. We further observe that the TPR and\nFNR of the neural network trained from the HY-ALL dataset\nreside in between that of the neural network trained from the\nRM-ALL dataset and that of the neural network trained from\nthe BE-ALL dataset. The F1-measure of the neural network\ntrained from the HY-ALL dataset is 1.2% lower than that\nof the neural network trained from the BE-ALL dataset, and\n9.6% lower than that of the neural network trained from the\nRM-ALL dataset. This can be explained by the fact that the\nnumber of library/API function calls that are related to the\nvulnerabilities of the hybrid dataset (i.e., 140) is larger than\nthe number of library/API function calls that are related to a\nsingle type of vulnerabilities. We speculate this is caused by the\nfollowing: it is more difficult to extract vulnerability patterns\nfor a large number of library/API function calls that are related\nto vulnerabilities than to extract vulnerability patterns for a\nsmall number of library/API function calls that are related to\nvulnerabilities.\n\ndescribed in Table I, we adopt a 10-fold cross validation to\ntrain a BLSTM neural network, and select the best parameter\nvalues corresponding to the effectiveness for vulnerability\ndetection. For example, we vary the number of hidden layers\nfor each BLSTM neural network and observe the influence\non the resulting F1-measure. When we adjust the number of\nhidden layers, we set the parameters to their default values\nwhen such default values are available, and set the parameters\nto the values that are widely used by the deep learning\ncommunity otherwise. The number of tokens in the vector\nrepresentation of code gadgets is set to 50, the dropout is set\nto 0.5, the batch size is set to 64, the number of epochs is set\nto 4, the minibatch stochastic gradient descent together with\nADAMAX [29] is used for training with the default learning\nrate of 1.0, and 300 hidden nodes are chosen.\n1 0 0\n8 0\n\nF 1 (% )\n\n6 0\n4 0\n\nF 1 (\nF 1 (\nF 1 (\nF 1 (\nF 1 (\nF 1 (\n\n2 0\n0\n0\n\n5\n\nB E -S\nB E -A\nR M -S\nR M -A\nH Y -S\nH Y -A\n\nE L )\nL L )\nE L )\nL L )\nE L )\nL L )\n\n1 0\n\n1 5\n\nTable III summarizes the training time and detection time\ncorresponding to the HY-ALL dataset, where the second column represents the number of code gadgets for training (i.e.,\nextracted from the training programs) and the third column\nrepresents the number of code gadgets for detection (i.e.,\nextracted from the target programs). We observe that the\ntraining time of VulDeePecker, as implied by the deep learning\ntechnology in general, is large, but the detecting time is small.\n\n2 0\n\nN u m b e r o f h id d e n la y e r s\n\nFigure 5. F1-measure of VulDeePecker for the 6 datasets with different\nnumber of hidden layers\n\nTable III.\n\nFigure 5 plots the F1-measure of VulDeePecker with respect to the 6 datasets with different number of hidden layers,\neach of which leads to a different neural network. We observe\nthat the F1-measure of the 6 BLSTM neural networks reaches\nthe maximum at 2 or 3 layers, and the F1-measure of most of\nthese BLSTM neural networks declines when the number of\nlayers is greater than 6. Note that the other parameters of the\nBLSTM neural network can be tuned in a similar fashion.\n\nDataset\nHY-ALL\nHY-SEL\n\nTPR(%)\n82.0\n95.3\n83.9\n\nP(%)\n91.7\n94.6\n86.9\n\nTraining\ntime (s)\n36,372.2\n25,242.3\n\nDetection\ntime (s)\n156.2\n76.6\n\n2) Experiments for answering RQ2: In order to answer\nwhether VulDeePecker can be improved by incorporating human expertise, we conduct the experiment using all library/API\nfunction calls that are automatically extracted vs. using some\nlibrary/API function calls that are manually selected under the\nguidance of vulnerability rules written by Checkmarx’s human\nexperts.\n\nTable II.\nR ESULTS FOR ANSWERING RQ1, INDICATING THAT\nV UL D EE P ECKER CAN DETECT MULTIPLE TYPES OF VULNERABILITIES .\nFNR(%)\n18.0\n4.7\n16.1\n\n#Detection\ncode gadgets\n12,894\n9,105\n\nInsight 1: VulDeePecker can simultaneously detect multiple types of vulnerabilities, but the effectiveness is sensitive to\nthe number of library/API function calls related to vulnerabilities (i.e., the fewer the better).\n\n1) Experiments for answering RQ1: In order to test\nwhether VulDeePecker can be applied to multiple types of\nvulnerabilities, we conduct experiments on three datasets: BEALL, RM-ALL, and HY-ALL. This respectively leads to three\nneural networks, whose effectiveness is reported in Table II.\n\nFPR(%)\n2.9\n2.8\n5.1\n\n#Training\ncode gadgets\n48,744\n33,813\n\nIn summary, we answer RQ1 affirmatively with the following:\n\nD. Experimental results & implications\n\nDataset\nBE-ALL\nRM-ALL\nHY-ALL\n\nT IME COMPLEXITY OF TRAINING AND DETECTION\n\nTable IV.\n\nR ESULTS FOR ANSWERING RQ2, INDICATING THAT USING\nMANUALLY- SELECTED LIBRARY /API FUNCTION CALLS CAN INDEED\nIMPROVE THE EFFECTIVENESS OF V UL D EE P ECKER .\n\nF1(%)\n86.6\n95.0\n85.4\n\nDataset\nHY-ALL\nHY-SEL\n\nWe observe that the neural network trained from the RMALL dataset outperforms the neural network trained from the\nBE-ALL dataset in terms of all five metrics. This can be\nexplained by the fact that the number of library/API function\n\nFPR(%)\n5.1\n4.9\n\nFNR(%)\n16.1\n6.1\n\nTPR(%)\n83.9\n93.9\n\nP(%)\n86.9\n91.9\n\nF1(%)\n85.4\n92.9\n\nAs shown in Table IV, the BLSTM network trained from\nthe HY-SEL dataset is more effective than the BLSTM network\n10\n\n\fTable V.\n\nR ESULTS FOR ANSWERING RQ3: V UL D EE P ECKER ACHIEVES\nA MUCH SMALLER OVERALL FNR OF 7.0% CORRESPONDING TO THE\nENTIRE BE-SEL DATASET ( THE LARGER FNR OF 16.9% CORRESPONDING\nTO THE SMALL SUB - DATASET DERIVED FROM THE NVD AND THE\nSMALLER FNR OF 5.1% CORRESPONDING TO THE SUB - DATASET DERIVED\nFROM THE SARD), WHILE NOTING THAT THE OVERALL FPR OF 5.7% IS\nREASONABLY SMALL . “N/C” MEANS THAT THE SYSTEM IS N OT C APABLE\nOF DETECTING VULNERABILITIES IN THE CORRESPONDING DATASET.\n\ntrained from the HY-ALL dataset. Although the improvement\nin FPR is small (0.2%), the improvement in each of the other\nmetrics is substantial: 10% in FNR and TPR, 5% in precision,\nand 7.5% in F1-measure. Moreover, Table III shows that the\ntraining time of using manually selected library/API function\ncalls can be smaller than that of using all library/API function\ncalls, because a smaller number of code gadgets need to be\nprocessed. This leads to the following preliminary understanding regards the usefulness of human expertise in improving the\neffectiveness of deep learning-based vulnerability detection:\n\nFPR\nFNR\nTPR\nP\nF1\n(%)\n(%)\n(%)\n(%)\n(%)\nVulDeePecker vs. Other pattern-based vulnerability detection systems\nFlawfinder\nBE-SEL\n44.7\n69.0\n31.0\n25.0\n27.7\nRATS\nBE-SEL\n42.2\n78.9\n21.1\n19.4\n20.2\nCheckmarx\nBE-SEL\n43.1\n41.1\n58.9\n39.6\n47.3\nVulDeePecker\nBE-SEL\n5.7\n7.0\n93.0\n88.1\n90.5\nSystem\n\nInsight 2: Human expertise can be used to select library/API function calls to improve the effectiveness of\nVulDeePecker, especially the overall effectiveness in F1measure.\n3) Experiments for answering RQ3: In order to answer\nRQ3, we compare the effectiveness of VulDeePecker with\nother pattern-based and code similarity-based vulnerability\ndetection systems. We here report the comparison between\ntheir effectiveness in detecting buffer error vulnerabilities (i.e.,\nBE-SEL dataset), while noting that a similar phenomenon\nis observed when comparing their effectiveness in detecting resource management error vulnerabilities (i.e., RM-SEL\ndataset) — the details are omitted due to the lack of space.\n\nDataset\n\nVulDeePecker\nVUDDY\nVulPecker\nVulDeePecker\n\nvs. Code similarity-based vulnerability detection systems\nBE-SEL-NVD\n0\n95.1\n4.9\n100\n9.3\nBE-SEL-NVD\n1.9\n89.8\n10.2\n84.3\n18.2\nBE-SEL-NVD\n22.9\n16.9\n83.1\n78.6\n80.8\n\nVUDDY\nVulPecker\nVulDeePecker\n\nBE-SEL-SARD\nBE-SEL-SARD\nBE-SEL-SARD\n\nN/C\nN/C\n3.4\n\nN/C\nN/C\n5.1\n\nN/C\nN/C\n94.9\n\nN/C\nN/C\n92.0\n\nN/C\nN/C\n93.4\n\nsystem can be more effective by taking advantage of the data\nflow analysis. (This hints us to speculate that a system can be\neven more effective by taking advantage of the control flow\nanalysis. It is an interesting future work to validate or invalidate\nthis speculation.)\n\nFor comparison with other pattern-based vulnerability detection systems, which use rules defined by human experts,\nwe consider a commercial product called Checkmarx [2] and\ntwo open source tools called Flawfinder [6] and RATS [11].\nThese systems are chosen because we have access to them\nand to the best of our knowledge, they have been widely\nused. For comparison with code similarity-based vulnerability\ndetection systems, which are mainly geared towards clonecaused vulnerabilities, we consider the two state-of-the-art\nsystems called VUDDY [28] and VulPecker [32]. We use\nVUDDY’s open service, and use the original implementation\nof VulPecker provided to us by its authors. For fair comparison,\nwe need to address some subtle issues. We observe that\nVulPecker uses diffs as an input, where a diff describes the\ndifference between a vulnerable piece of code and its patched\nversion, we divide the BE-SEL dataset of target programs\ninto two subsets, namely BE-SEL-NVD (266 samples derived\nfrom the NVD) and BE-SEL-SARD (the rest samples derived\nfrom the SARD). We use BE-SEL-NVD for the comparison\nstudy because VUDDY and VulPecker were designed to detect\nvulnerabilities with CVE IDs or vulnerabilities with diffs, but\nare unable to detect vulnerabilities in BE-SEL-SARD.\n\nSecond, for the BE-SEL-NVD sub-dataset, VUDDY and\nVulPecker trade high FNRs (95.1% and 89.8%, respectively)\nfor low FPRs (0% and 1.9%, respectively), which lead to very\nlow F1-measures (9.3% and 18.2%, respectively). The large\nFNRs can explained by the following facts: VUDDY can only\ndetect the vulnerabilities related to functions, which are nearly\nidentical to the vulnerable functions in the training programs\n(i.e., vulnerabilities caused by Types I and II code clones [42]);\nVulPecker can only detect vulnerabilities caused by Type I,\nType II, and some Type III code clones [42] (e.g., deletion,\ninsertion, and rearrangement of statements), which explains\nwhy VulPecker incurs a lower FNR than VUDDY. However,\nthese systems cannot detect vulnerabilities that are not caused\nby code clones, which explains why they incur high FNRs.\nIn contrast, VulDeePecker has a much higher F1-measure\n(i.e., 80.8% vs. 9.3% for VUDDY and 18.2% for VulPecker)\nbecause it has a much higher TPR (i.e., much lower FNR),\nwhile noting that its FPR is 22.9% (vs. 0% for VUDDY and\n1.9% for VulPecker). We suspect that this high FPR of 22.9%\ncorresponding to the BE-SEL-NVD dataset is caused by a\nsmall number of training code gadgets from NVD. This can\nbe justified by the small FPR of 3.4% corresponding to a large\nnumber of training code gadgets from SARD, which is about\n18 times larger than the number of training code gadgets from\nNVD. Moreover, the FPR of 5.7% corresponding to the entire\nBE-SEL dataset resides some where in between them. The\nhigh FNR of 16.9% can be explained similarly.\n\nTable V summarizes the comparison. We make the following observations. First, VulDeePecker substantially outperforms the other pattern-based vulnerability detection systems,\nbecause VulDeePecker incurs a FPR of 5.7% and a FNR\nof 7.0%, which are respectively much smaller than their\ncounterparts in the other detection systems. By looking into\nthe other systems, we find that Flawfinder and RATS do not\nuse data flow analysis and therefore miss many vulnerabilities.\nAlthough Checkmarx does use data flow analysis, its rules for\nrecognizing vulnerabilities are defined by human experts and\nare far from perfect. This further highlights the importance of\nrelieving human experts from tedious tasks (similar to task of\nmanually defining features). This observation leads to:\n\nThe high FPR and FNR of VulDeePecker with respect to\nthe BE-SEL-NVD sub-dataset should not be used as evidence\nagainst VulDeePecker, simply because for the BE-SEL-SARD\nsub-dataset, VulDeePecker incurs an even smaller FPR of 3.4%\nand a FNR of 5.1%, while noting that VUDDY and VulPecker\nare not applicable (i.e., not capable of detecting vulnerabilities\nin this sub-dataset). Moreover, VulDeePecker incurs a FPR of\n5.7% and a FNR of 7.0% over the entire BE-SEL dataset,\n\nInsight 3: A deep learning-based vulnerability detection\n11\n\n\fTable VI.\n\nV UL D EE P ECKER DETECTED 4 VULNERABILITIES IN 3 PRODUCTS , WHICH ARE NOT PUBLISHED IN THE NVD BUT HAVE BEEN “ SILENTLY ”\nPATCHED BY THE VENDORS IN THE LATER RELEASES OF THESE PRODUCTS .T HESE VULNERABILITIES ARE ENTIRELY MISSED BY THE OTHER\nVULNERABILITY DETECTION SYSTEMS , EXCEPT THAT F LAW F INDER DETECTED ONLY ONE VULNERABILITY WHILE MISSING THE OTHER THREE .\nTarget product\n\nCVE ID\n\nXen 4.6.0\nSeamonkey\n2.31\nLibav 10.2\n\nCVE-2016-9104\nCVE-2015-4517\nCVE-2015-4513\nCVE-2014-2263\n\nVulnerable product\npublished in the NVD\nQemu\nFirefox\nFirefox\nFFmpeg\n\nVulnerability\npublish time\n12/09/2016\n09/24/2015\n11/05/2015\n02/28/2014\n\nVulnerable file in target product\n.../qemu-xen/hw/9pfs/virtio-9p.c\n.../system/gonk/NetworkUtils.cpp\n.../protocol/http/Http2Stream.cpp\nlibavformat/mpegtsenc.c\n\n1st patched version\nof target product\nXen 4.9.0\nSeamonkey 2.38\nSeamonkey 2.39\nLibav 10.4\n\nFourth, the present design of VulDeePecker only accommodates data flow analysis (i.e., data dependency), but not control\nflow analysis (i.e., control dependency), despite the fact that the\nnotion of code gadgets can accommodate data dependency and\ncontrol dependency. It is an important future work to improve\nthe leverage of data flow analysis and accommodate control\nflow analysis to enhance vulnerability detection capabilities.\n\nwhich is the more practical case because one would use all\ndata available in practice.\nTherefore, it is fair to say that VulDeePecker substantially\noutperforms two state-of-the-art code similarity-based vulnerability detection systems, simply because VulDeePecker incurs\na FPR of 5.7% and a FNR of 7.0% over the entire dataset.\nNevertheless, it is important to note that deep learning-based\nvulnerability detection largely rely on the amount of data. This\nleads to:\n\nFifth, the present design of VulDeePecker uses some\nheuristics in labeling the ground truth of code gadgets, transforming code gadgets into their symbolic representations,\ntransforming variable-length vector representations of code\ngadgets into fixed-length vectors. While intuitive, further research needs to be conducted to characterize the impact of\nthese heuristics on the effectiveness of VulDeePecker.\n\nInsight 4: VulDeePecker is more effective than code\nsimilarity-based vulnerability detection systems, which cannot\ndetect vulnerabilities that are not caused by code clones and\nthus often incur high false negative rate. Nevertheless, the\neffectiveness of VulDeePecker is sensitive to the amount of\ndata, which appears to be inherent to the nature of deep\nlearning.\n\nSixth, the present implementation of VulDeePecker is\nlimited to the BLSTM neural network. We plan to conduct\nsystematic experiments with other kinds of neural networks\nthat could be used for vulnerability detection.\n\nUsing VulDeePecker in practice. In order to further show\nthe usefulness of VulDeePecker, we collected 20 versions\nof 3 software products: Xen, Seamonkey, and Libav. These\nproducts are different from the target programs mentioned\nabove. We use VulDeePecker and the other vulnerability\ndetection systems to detect the vulnerabilities in those software\nproducts. As highlighted in Table VI, VulDeePecker detected\n4 vulnerabilities that have not been published in the NVD.\nWe manually checked and confirmed these vulnerabilities,\nand found that they have been published for other products\nand have been “silently” patched by the product vendors\nin the subsequent versions. In contrast, these vulnerabilities\nare missed by almost all of the other vulnerability detection\nsystems mentioned above, except that Flawfinder detects the\nvulnerability corresponding to CVE-2015-4517 while missing\nthe other three.\n\nSeventh, the present evaluation of VulDeePecker is limited\nbecause the dataset only contains buffer error vulnerabilities and resource management error vulnerabilities. We will\nconduct experiments on all available types of vulnerabilities.\nAlthough we further tested VulDeePecker against 3 software\nproducts (i.e., Xen, Seamonkey, and Libav) and found 4 vulnerabilities that were not reported in the NVD and were “silently”\npatched by the vendors when releasing later versions of these\nproducts, these vulnerabilities were known rather than 0-day\nones. Extensive experiments need to be conducted against more\nsoftware products to check whether VulDeePecker has the\ncapability in detecting 0-day vulnerabilities. In principle, this is\npossible because VulDeePecker uses pattern-based approach.\nVI.\n\nV.\n\nLibrary/API\nfunction call\nmemcpy\nsnprintf\nmemset\nstrchr, strlen\n\nL IMITATIONS\n\nR ELATED W ORK\n\nWe classify the related prior work into two categories:\nvulnerability detection (in relation to the purpose of the present\npaper), and program analysis (in the relation to the means for\nvulnerability detection).\n\nThe present design, implementation, and evaluation of\nVulDeePecker have several limitations, which suggest interesting open problems for future research. First, the present\ndesign of VulDeePecker is limited to dealing with vulnerability\ndetection by assuming source code of programs is available.\nThe detection of vulnerabilities in executables is a different\nand more challenging problem.\n\nA. Prior work in vulnerability detection\nPattern-based approach. This approach can be further divided to three categories. In the first category, patterns are\ngenerated manually by human experts (e.g., open source tools\nFlawfinder [6], RATS [11], and ITS4 [52], commercial tools\nCheckmarx [2], Fortify [7], and Coverity [3]). These tools\noften have high false positive rate or false negative rate. In\nthe second category, patterns are generated semi-automatically\nfrom pre-classified vulnerabilities ( e.g., missing check vulnerabilities [62], taint-style vulnerabilities [61], and information\nleakage vulnerabilities [15]) and a pattern is specific to a type\n\nSecond, the present design of VulDeePecker only deals\nwith C/C++ programs. Future research needs to be conducted\nto adapt it to deal with other kinds of programming languages.\nThird, the present design of VulDeePecker only deals with\nvulnerabilities related to library/API function calls. We will\ninvestigate how to detect the other kinds of vulnerabilities by\nleveraging the other kinds of key points mentioned above.\n12\n\n\fSomewhat related work is the use of deep learning for software defect prediction [54], [63]. However, software defects\nare different from software vulnerabilities (i.e., methods for\ndetecting defects cannot be used for detecting vulnerabilities\nin general) [34], and the file-level representation of programs\nin [54] is too coarse-grained to pin down the locations of\nvulnerabilities. Moreover, the defect prediction method presented in [63] is geared towards code changes rather than target\nprograms as a whole. Remotely related work is the use of\ndeep learning for purposes, like software language modeling\n[57], code cloning detection [56], API learning [20], binary\nfunction boundary recognition [48], and malicious URLs, file\npaths detection and registry keys detection [45].\n\nof vulnerabilities. In the third category, patterns are generated\nsemi-automatically from type-agnostic vulnerabilities (i.e., no\nneed to pre-classify them into different types). These methods\nuse machine learning techniques, which rely on human experts\nfor defining features to characterize vulnerabilities [19], [37],\n[38], [49], [59], [60]. Moreover, these methods cannot pin\ndown the precise locations of vulnerabilities because programs\nare represented in coarse-grained granularity (e.g., program\n[19], package [37], component [38], [46], file [35], [49], and\nfunction [59], [60]).\nVulDeePecker falls into the pattern-based approach to vulnerability detection. In contrast to the studies reviewed above,\nVulDeePecker has two advantages. First, it does not need\nhuman experts to define features for distinguishing vulnerable\ncode and non-vulnerable code. Second, it uses a fine-grained\ngranularity to represent programs, and therefore can pin down\nthe precise locations of vulnerabilities.\n\nVII.\n\nC ONCLUSION\n\nWe have presented VulDeePecker, the first deep learningbased vulnerability detection system, which aims to relieve\nhuman experts from the tedious and subjective work of manually defining features and reduce the false negatives that are\nincurred by other vulnerability detection systems. Since deep\nlearning is invented for applications that are very different from\nvulnerability detection, we have presented some preliminary\nprinciples for guiding the practice of applying deep learning\nto vulnerability detection. These principles should be further\nrefined because deep learning has great potential in solving\nthe problem of vulnerability detection. We have collected, and\nmade publicly available, a useful dataset for evaluating the\neffectiveness of VulDeePecker and other deep learning-based\nvulnerability detection systems that will be developed in the\nfuture. Systematic experiments show that VulDeePecker can\nachieve much lower false negative rate than other vulnerability\ndetection systems, while relieving human experts from the\ntedious work of manually defining features. For the 3 software\nproducts we experimented with (i.e., Xen, Seamonkey, and\nLibav), VulDeePecker detected 4 vulnerabilities, which were\nnot reported in the NVD and were “silently” patched by the\nvendors when they released later versions of these products.\nIn contrast, the other detection systems missed almost all of\nthese vulnerabilities, except that one system detected 1 of these\nvulnerabilities and missed the other three vulnerabilities.\n\nCode similarity-based approach. This approach has three\nsteps. The first step is to divide a program into some code\nfragments [25], [28], [31], [41], [44]. The second step is to\nrepresent each code fragment in the abstract fashion, including\ntokens [25], [28], [44], trees [26], [41], and graphs [31], [41].\nThe third step is to compute the similarity between code\nfragments via their abstract representations obtained in the\nsecond step.\nCompared with any pattern-based approach to vulnerability\ndetection (including VulDeePacker), the code similarity-based\napproach has the advantage that a single instance of vulnerable\ncode is sufficient for detecting the same vulnerability in target\nprograms. But it can only detect vulnerabilities in the Type\nI and Type II code clones [42] (i.e., identical or almostidentical code clones), and some Type III code clones [42]\n(e.g., deletion, insertion, and rearrangement of statements).\nIn order to achieve a higher effectiveness of vulnerability\ndetection, human experts need to define features in order\nto automatically select the right code similarity algorithms\nfor different kinds of vulnerabilities [32]. However, even the\nenhanced approach with expert-defined features [32] cannot\ndetect vulnerabilities that are not caused by code clones. In\ncontrast, VulDeePecker can detect vulnerabilities that may or\nmay not caused by code clones, in an automatic fashion (i.e.,\nno need of human expert to define features).\n\nOpen problems for future research are abundant, including\nthe limitations of the present study discussed in Section\nV. In particular, precisely characterizing the capabilities and\nlimitations of deep learning-based vulnerability detection is an\nexciting research problem.\n\nB. Prior work related to using deep learning for program\nanalysis\nTo the best of our knowledge, we are the first to use deep\nlearning to detect software vulnerabilities, as inspired by the\nsuccess of deep learning in image processing, speech recognition, and natural language processing [21], [30], [40]. In order\nto use deep learning for detecting software vulnerabilities,\nprograms need to be represented in vectors. There are two\napproaches for this purpose. One is to map the tokens extracted\nfrom programs, such as data types, variable names, function\nnames, and keywords, to vectors [57]; the other is to map\nthe nodes of abstract syntax trees extracted from programs,\nsuch as function definitions, function invocations, identifier\ndeclarations, and control flow nodes, to vectors [36], [54].\nVulDeePecker maps the tokens extracted from code gadgets\nto vectors, while taking it into consideration that the lines of\ncode in the code gadget is not necessarily consecutive.\n\nACKNOWLEDGMENT\nWe thank the anonymous reviewers for their comments\nthat helped us improve the paper, and Marcus Pendleton for\nproofreading the paper. This paper is supported by the National Basic Research Program of China (973 Program) under\ngrant No.2014CB340600, the National Science Foundation of\nChina under grant No. 61672249, the Shenzhen Fundamental\nResearch Program under grant No. JCYJ20170413114215614,\nand the Natural Science Foundation of Hebei Province under\ngrant No. F2015201089. Shouhuai Xu is supported in part\nby NSF Grant #1111925 and ARO Grant #W911NF-17-10566. Any opinions, findings, conclusions or recommendations\nexpressed in this material are those of the authors and do not\nreflect the views of the funding agencies.\n13\n\n\fR EFERENCES\n\n[30]\n\nA. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification\nwith deep convolutional neural networks,” in Advances in Neural\nInformation Processing Systems, 2012, pp. 1097–1105.\n\n[31]\n\nJ. Li and M. D. Ernst, “CBCD: Cloned buggy code detector,” in Proceedings of the 34th International Conference on Software Engineering.\nIEEE, 2012, pp. 310–320.\n\n[32]\n\nZ. Li, D. Zou, S. Xu, H. Jin, H. Qi, and J. Hu, “VulPecker: An\nautomated vulnerability detection system based on code similarity\nanalysis,” in Proceedings of the 32nd Annual Conference on Computer\nSecurity Applications. ACM, 2016, pp. 201–213.\n\n[33]\n\nS. Montemagni and V. Pirelli, “Augmenting WordNet-like lexical resources with distributional evidence. an application-oriented perspective,” in Proceedings of the COLING/ACL Workshop on Use of WordNet\nin Natural Language Processing Systems, 1998, pp. 87–93.\n\n[34]\n\nP. Morrison, K. Herzig, B. Murphy, and L. Williams, “Challenges with\napplying vulnerability prediction models,” in Proceedings of the 2015\nSymposium and Bootcamp on the Science of Security. ACM, 2015,\npp. 1–9.\n\n[35]\n\nS. Moshtari and A. Sami, “Evaluating and comparing complexity,\ncoupling and a new proposed set of coupling metrics in cross-project\nvulnerability prediction,” in Proceedings of the 31st Annual ACM\nSymposium on Applied Computing. ACM, 2016, pp. 1415–1421.\n\n[1] C/C++ standard library functions, http://en.cppreference.com/w.\n[2] Checkmarx, https://www.checkmarx.com/.\n[3] Coverity, https://scan.coverity.com/.\n[4] CVE, http://cve.mitre.org/.\n[5] Cyber Grand Challenge, https://www.cybergrandchallenge.com/.\n[6] FlawFinder, http://www.dwheeler.com/flawfinder.\n[7] HP Fortify, https://www.hpfod.com/.\n[8] Keras, https://github.com/fchollet/keras.\n[9] Linux kernel API functions, https://www.kernel.org/doc/htmldocs/\nkernel-api/.\n[10] NVD, https://nvd.nist.gov/.\n[11] Rough Audit Tool for Security, https://code.google.com/archive/p/\nrough-auditing-tool-for-security/.\n[12] Software Assurance Reference Dataset, https://samate.nist.gov/SRD/\nindex.php.\n[13] Windows API functions, https://msdn.microsoft.com/en-us/library/\nwindows/desktop/ff818516(v=vs.85).aspx#user interface.\n[14]\n\nword2vec, http://radimrehurek.com/gensim/models/word2vec.html.\n\n[36]\n\n[15]\n\nM. Backes, B. Köpf, and A. Rybalchenko, “Automatic discovery and\nquantification of information leaks,” in Proceedings of the 30th IEEE\nSymposium on Security and Privacy. IEEE, 2009, pp. 141–153.\n\nL. Mou, G. Li, Y. Liu, H. Peng, Z. Jin, Y. Xu, and L. Zhang,\n“Building program vector representations for deep learning,” arXiv\npreprint arXiv:1409.3358, 2014.\n\n[37]\n\n[16]\n\nY. Bengio, “Learning deep architectures for AI,” Foundations and\nTrends in Machine Learning, vol. 2, no. 1, pp. 1–127, 2009.\n\nS. Neuhaus and T. Zimmermann, “The beauty and the beast: Vulnerabilities in Red Hat’s packages.” in Proceedings of the 2009 USENIX\nAnnual Technical Conference. USENIX, 2009, pp. 527–538.\n\n[17]\n\nK. Cho, B. Van Merriënboer, D. Bahdanau, and Y. Bengio, “On the\nproperties of neural machine translation: Encoder-decoder approaches,”\narXiv preprint arXiv:1409.1259, 2014.\n\n[38]\n\n[18]\n\nL. V. Davi, “Code-reuse attacks and defenses,” Ph.D. dissertation,\nDarmstadt University of Technology, Germany, 2015.\n\nS. Neuhaus, T. Zimmermann, C. Holler, and A. Zeller, “Predicting\nvulnerable software components,” in Proceedings of the 14th ACM\nconference on Computer and communications security. ACM, 2007,\npp. 529–540.\n\n[39]\n\n[19]\n\nG. Grieco, G. L. Grinblat, L. Uzal, S. Rawat, J. Feist, and L. Mounier,\n“Toward large-scale vulnerability discovery using machine learning,”\nin Proceedings of the 6th ACM Conference on Data and Application\nSecurity and Privacy. ACM, 2016, pp. 85–96.\n\nM. Pendleton, R. Garcia-Lebron, J. Cho, and S. Xu, “A survey on\nsystems security metrics,” ACM Comput. Surv., vol. 49, no. 4, pp. 62:1–\n62:35, 2017.\n\n[40]\n\nJ. Pennington, R. Socher, and C. D. Manning, “Glove: Global vectors\nfor word representation.” in Proceedings of the 2014 Conference on\nEmpirical Methods in Natural Language Processing, vol. 14, 2014, pp.\n1532–1543.\n\n[41]\n\nN. H. Pham, T. T. Nguyen, H. A. Nguyen, and T. N. Nguyen, “Detection\nof recurring software vulnerabilities,” in Proceedings of the IEEE/ACM\nInternational Conference on Automated Software Engineering. ACM,\n2010, pp. 447–456.\n\n[42]\n\nD. Rattan, R. Bhatia, and M. Singh, “Software clone detection: A\nsystematic review,” Information and Software Technology, vol. 55, no. 7,\npp. 1165–1199, 2013.\n\n[43]\n\nD. Rumelhart, J. McClelland, and G. Hinton, “Distributed representations,” Parallel Distributed Processing: Explorations in the Microstructure of Cognition, vol. 1, pp. 77–109, 1986.\n\n[44]\n\nH. Sajnani, V. Saini, J. Svajlenko, C. K. Roy, and C. V. Lopes, “SourcererCC: Scaling code clone detection to big-code,” in Proceedings of the\n38th International Conference on Software Engineering. ACM, 2016,\npp. 1157–1168.\n\n[45]\n\nJ. Saxe and K. Berlin, “eXpose: A character-level convolutional neural\nnetwork with embeddings for detecting malicious URLs, file paths and\nregistry keys,” arXiv preprint arXiv:1702.08568, 2017.\n\n[46]\n\nR. Scandariato, J. Walden, A. Hovsepyan, and W. Joosen, “Predicting\nvulnerable software components via text mining,” IEEE Transactions\non Software Engineering, vol. 40, no. 10, pp. 993–1006, 2014.\n\n[47]\n\nR. Jozefowicz, W. Zaremba, and I. Sutskever, “An empirical exploration\nof recurrent network architectures,” in Proceedings of the 32nd International Conference on Machine Learning, 2015, pp. 2342–2350.\n\nM. Schuster and K. K. Paliwal, “Bidirectional recurrent neural networks,” IEEE Transactions on Signal Processing, vol. 45, no. 11, pp.\n2673–2681, 1997.\n\n[48]\n\nS. Kim, S. Woo, H. Lee, and H. Oh, “VUDDY: A scalable approach\nfor vulnerable code clone discovery,” in Proceedings of the 38th IEEE\nSymposium on Security and Privacy, 2017.\n\nE. C. R. Shin, D. Song, and R. Moazzezi, “Recognizing functions in\nbinaries with neural networks.” in Proceedings of the 24th USENIX\nSecurity Symposium. USENIX Associatioin, 2015, pp. 611–626.\n\n[49]\n\nY. Shin, A. Meneely, L. Williams, and J. A. Osborne, “Evaluating\ncomplexity, code churn, and developer activity metrics as indicators of\nsoftware vulnerabilities,” IEEE Transactions on Software Engineering,\nvol. 37, no. 6, pp. 772–787, 2011.\n\n[20]\n\n[21]\n\nX. Gu, H. Zhang, D. Zhang, and S. Kim, “Deep API learning,” in\nProceedings of the 24th ACM SIGSOFT International Symposium on\nFoundations of Software Engineering. ACM, 2016, pp. 631–642.\nG. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-r. Mohamed, N. Jaitly,\nA. Senior, V. Vanhoucke, P. Nguyen, T. N. Sainath, and B. Kingsbury,\n“Deep neural networks for acoustic modeling in speech recognition:\nThe shared views of four research groups,” IEEE Signal Processing\nMagazine, vol. 29, no. 6, pp. 82–97, 2012.\n\n[22]\n\nS. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural\nComputation, vol. 9, no. 8, pp. 1735–1780, 1997.\n\n[23]\n\nS. Horwitz, T. Reps, and D. Binkley, “Interprocedural slicing using\ndependence graphs,” ACM Transactions on Programming Languages\nand Systems (TOPLAS), vol. 12, no. 1, pp. 26–60, 1990.\n\n[24]\n\nB. James, B. Olivier, B. Frédéric, L. Pascal, and P. Razvan, “Theano: A\nCPU and GPU math expression compiler,” in Proceedings of the Python\nfor Scientific Computing Conference (SciPy), 2010.\n\n[25]\n\nJ. Jang, A. Agrawal, and D. Brumley, “ReDeBug: Finding unpatched\ncode clones in entire OS distributions,” in Proceedings of the 33th IEEE\nSymposium on Security and Privacy. IEEE, 2012, pp. 48–62.\n\n[26]\n\nL. Jiang, G. Misherghi, Z. Su, and S. Glondu, “Deckard: Scalable and\naccurate tree-based detection of code clones,” in Proceedings of the 29th\nInternational Conference on Software Engineering. IEEE Computer\nSociety, 2007, pp. 96–105.\n\n[27]\n\n[28]\n\n[29]\n\nD. Kingma and J. Ba, “Adam: A method for stochastic optimization,”\narXiv preprint arXiv:1412.6980, 2014.\n\n14\n\n\f[50]\n\n[51]\n\n[52]\n\n[53]\n\n[54]\n\n[55]\n[56]\n\n[57]\n\n[58]\n\n[59]\n\n[60]\n\n[61]\n\n[62]\n\n[63]\n\nlayer l at the time t is:\n\nS. Sinha, M. J. Harrold, and G. Rothermel, “System-dependencegraph-based slicing of programs with arbitrary interprocedural control\nflow,” in Proceedings of the 1999 International Conference on Software\nEngineering. IEEE, 1999, pp. 432–441.\nJ. Su, Z. Tan, D. Xiong, and Y. Liu, “Lattice-based recurrent neural\nnetwork encoders for neural machine translation,” in Proceedings of the\n31st AAAI Conference on Artificial Intelligence, 2017, pp. 3302–3308.\nJ. Viega, J. T. Bloch, Y. Kohno, and G. McGraw, “ITS4: A static\nvulnerability scanner for C and C++ code,” in Proceedings of the 16th\nAnnual Computer Security Applications Conference. IEEE, 2000, pp.\n257–267.\nO. Vinyals, A. Toshev, S. Bengio, and D. Erhan, “Show and tell: A\nneural image caption generator,” in Proceedings of the IEEE Conference\non Computer Vision and Pattern Recognition, 2015, pp. 3156–3164.\nS. Wang, T. Liu, and L. Tan, “Automatically learning semantic features for defect prediction,” in Proceedings of the 38th International\nConference on Software Engineering. ACM, 2016, pp. 297–308.\nM. Weiser, “Program slicing,” IEEE Transactioins on Software Engineering, vol. 10, no. 4, 1984.\nM. White, M. Tufano, C. Vendome, and D. Poshyvanyk, “Deep learning\ncode fragments for code clone detection,” in Proceedings of the 31st\nIEEE/ACM International Conference on Automated Software Engineering. ACM, 2016, pp. 87–98.\nM. White, C. Vendome, M. Linares-Vásquez, and D. Poshyvanyk,\n“Toward deep learning software repositories,” in Proceedings of the\n12th Working Conference on Mining Software Repositories. IEEE,\n2015, pp. 334–345.\nL. Wolf, Y. Hanani, K. Bar, and N. Dershowitz, “Joint word2vec\nnetworks for bilingual semantic representations,” International Journal\nof Computational Linguistics and Applications, vol. 5, no. 1, pp. 27–44,\n2014.\nF. Yamaguchi, F. Lindner, and K. Rieck, “Vulnerability extrapolation:\nAssisted discovery of vulnerabilities using machine learning,” in Proceedings of the 5th USENIX Conference on Offensive Technologies.\nUSENIX Association, 2011, pp. 13–13.\nF. Yamaguchi, M. Lottmann, and K. Rieck, “Generalized vulnerability\nextrapolation using abstract syntax trees,” in Proceedings of the 28th\nAnnual Computer Security Applications Conference. ACM, 2012, pp.\n359–368.\nF. Yamaguchi, A. Maier, H. Gascon, and K. Rieck, “Automatic inference\nof search patterns for taint-style vulnerabilities,” in Proceedings of the\n2015 IEEE Symposium on Security and Privacy. IEEE, 2015, pp.\n797–812.\nF. Yamaguchi, C. Wressnegger, H. Gascon, and K. Rieck, “Chucky:\nExposing missing checks in source code for vulnerability discovery,”\nin Proceedings of the 2013 ACM SIGSAC Conference on Computer &\nCommunications Security. ACM, 2013, pp. 499–510.\nX. Yang, D. Lo, X. Xia, Y. Zhang, and J. Sun, “Deep learning for just-intime defect prediction,” in Proceedings of the 2015 IEEE International\nConference on Software Quality, Reliability and Security. IEEE, 2015,\npp. 17–26.\n\nhlt = olt\n\ntanh(clt ),\n\nwhere the output gate olt of the layer l at the time t is:\nl\nl\nl l\nolt = σ(Wxo\nxlt + Who\nhlt−1 + Wco\nct + blo )\n\nand the state of LSTM cell clt of the layer l at the time t is:\nclt = ftl\n\nclt−1 + ilt\n\nl\nl\ntanh(Wxc\nxlt + Whc\nhlt−1 + blc ).\n\nThe forget gate ftl and the input gate ilt of the layer l at\nthe time t are calculated as follows:\nftl\n\nl\nl\nl\n= σ(Wxf\nxlt + Whf\nhlt−1 + Wcf\nclt−1 + blf ),\n\nilt\n\nl\nl\nl l\n= σ(Wxi\nxlt + Whi\nhlt−1 + Wci\nct−1 + bli ),\n\nwhere xlt is the input to layer l − 1 (l > 1) or the input of\nl\nl\nl\nl\nthe network (l = 1), Wxi\n, Wxf\n, Wxo\n, Wxc\nare the weight\nl\nmatrices connecting xt with the input gate, the forget gate, the\nl\nl\nl\nl\noutput gate, and the LSTM cell input, Whi\n, Whf\n, Who\n, Whc\nl\nare the weight matrices connecting ht−1 with the input gate,\nthe forget gate, the output gate, and the LSTM cell input, and\nbli , blf , blo , blc are the bias items of the input gate, the forget\ngate, the output gate, and the LSTM cell input.\nB. Library/API function calls selected by Checkmarx\nTable VII summarizes the C/C++ library/API function calls\nrelated to the two types of vulnerabilities, buffer error (CWE119) and resource management error (CWE-399), where “*”\nrepresents the wildcard. These library/API function calls are\ngenerated by the commercial product Checkmarx [2].\nTable VII.\n\nL IBRARY /API FUNCTION CALLS RELATED TO TWO TYPES\nOF VULNERABILITIES\n\nCWE ID\nCWE-119\n\nA PPENDIX\nA. LSTM cells\nThe BLSTM layers in the BLSTM neural network contain\na complex structure called LSTM cells, which are briefly\nreviewed below and referred to [22] for greater details.\n\nCWE-399\n\nLet denote the element-wise multiplication, tanh denote\nthe hyperbolic tangent function exp(x)−exp(−x)\nexp(x)+exp(−x) , and σ denote\n1\nthe sigmoid function 1+exp(−x) .\nEach LSTM cell, denoted by c, uses an input gate i (i.e.,\nthe input data), a forget gate f (i.e., the state flow of the cell),\nand an output gate o (i.e., the output of module) to control\nthe data flow through the neural network. The output hlt of the\n15\n\nC/C++ library/API function calls related to vulnerabilities\ncin, getenv, getenv s, wgetenv, wgetenv s, catgets, gets, getchar,\ngetc, getch, getche, kbhit, stdin, getdlgtext, getpass, scanf,\nfscanf, vscanf, vfscanf, istream.get, istream.getline, istream.peek,\nistream.read*, istream.putback, streambuf.sbumpc, streambuf.sgetc,\nstreambuf.sgetn,\nstreambuf.snextc,\nstreambuf.sputbackc,\nSendMessage,\nSendMessageCallback,\nSendNotifyMessage,\nPostMessage, PostThreadMessage, recv, recvfrom, Receive,\nReceiveFrom, ReceiveFromEx, Socket.Receive*, memcpy, wmemcpy,\nmemccpy, memmove, wmemmove, memset, wmemset, memcmp,\nwmemcmp, memchr, wmemchr, strncpy,\nstrncpy*, lstrcpyn,\ntcsncpy*, mbsnbcpy*, wcsncpy*, wcsncpy, strncat, strncat*,\nmbsncat*, wcsncat*, bcopy, strcpy, lstrcpy, wcscpy, tcscpy,\nmbscpy, CopyMemory, strcat, lstrcat, lstrlen, strchr, strcmp,\nstrcoll, strcspn, strerror, strlen, strpbrk, strrchr, strspn, strstr, strtok,\nstrxfrm, readlink, fgets, sscanf, swscanf, sscanf s, swscanf s, printf,\nvprintf, swprintf, vsprintf, asprintf, vasprintf, fprintf, sprint, snprintf,\nsnprintf*, snwprintf*, vsnprintf, CString.Format, CString.FormatV,\nCString.FormatMessage,\nCStringT.Format,\nCStringT.FormatV,\nCStringT.FormatMessage, CStringT.FormatMessageV, syslog, malloc,\nWinmain, GetRawInput*, GetComboBoxInfo, GetWindowText,\nGetKeyNameText, Dde*, GetFileMUI*, GetLocaleInfo*, GetString*,\nGetCursor*, GetScroll*, GetDlgItem*, GetMenuItem*\nfree, delete, new, malloc, realloc, calloc, alloca, strdup, asprintf,\nvsprintf, vasprintf, sprintf, snprintf, snprintf, snwprintf, vsnprintf\n\n\f",
         "train",
         "93454",
         "14329"
        ],
        [
         "38",
         "18768",
         "cs.AI",
         "Artificial Intelligence",
         "1802.03501v1.pdf",
         "Path Consistency Learning in Tsallis Entropy Regularized MDPs\n\nOfir Nachum * 1 Yinlam Chow * 2 Mohamamd Ghavamzadeh * 2\n\narXiv:1802.03501v1 [cs.AI] 10 Feb 2018\n\nAbstract\nWe study the sparse entropy-regularized reinforcement learning (ERL) problem in which the\nentropy term is a special form of the Tsallis entropy. The optimal policy of this formulation is\nsparse, i.e., at each state, it has non-zero probability for only a small number of actions. This\naddresses the main drawback of the standard\nShannon entropy-regularized RL (soft ERL) formulation, in which the optimal policy is softmax,\nand thus, may assign a non-negligible probability\nmass to non-optimal actions. This problem is aggravated as the number of actions is increased. In\nthis paper, we follow the work of Nachum et al.\n(2017) in the soft ERL setting, and propose a\nclass of novel path consistency learning (PCL)\nalgorithms, called sparse PCL, for the sparse\nERL problem that can work with both on-policy\nand off-policy data. We first derive a sparse consistency equation that specifies a relationship between the optimal value function and policy of\nthe sparse ERL along any system trajectory. Crucially, a weak form of the converse is also true,\nand we quantify the sub-optimality of a policy\nwhich satisfies sparse consistency, and show that\nas we increase the number of actions, this suboptimality is better than that of the soft ERL optimal policy. We then use this result to derive the\nsparse PCL algorithms. We empirically compare\nsparse PCL with its soft counterpart, and show\nits advantage, especially in problems with a large\nnumber of actions.\n\n1. Introduction\nIn reinforcement learning (RL), the goal is to find a policy with maximum long-term performance, defined as the\nsum of discounted rewards generated by following the policy (Bertsekas & Tsitsiklis, 1996; Sutton & Barto, 1998).\nIn case the number of states and actions are small, and the\n*\nEqual contribution 1 Google Brain 2 Google DeepMind. Correspondence to: Yinlam Chow <yinlamchow@google.com>.\n\nProceedings of the 35 th International Conference on Machine\nLearning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018\nby the author(s).\n\nmodel is known, the optimal policy is the solution of the\nnon-linear Bellman optimality equations (Bellman, 1957).\nWhen the system is large or the model is unknown, greedily solving the Bellman equations often results in policies\nthat are far from optimal. A principled way of dealing\nwith this issue is regularization. Among different forms\nof regularization, such as `2 (e.g., Farahmand et al. 2008;\n2009) and `1 (e.g., Kolter & Ng 2009; Johns et al. 2010;\nGhavamzadeh et al. 2011), entropy regularization is among\nthe most studied in both value-based (e.g., Kappen 2005;\nTodorov 2006; Ziebart 2010; Azar et al. 2012; Fox et al.\n2016; O’Donoghue et al. 2017; Asadi & Littman 2017)\nand policy-based (e.g., Peters et al. 2010; Todorov 2010)\nRL formulations. In particular, two of the most popular\ndeep RL algorithms, TRPO (Schulman et al., 2015) and\nA3C (Mnih et al., 2016), are based on entropy-regularized\npolicy search. We refer the interested readers to Neu et al.\n(2017), for an insightful discussion on entropy-regularized\nRL algorithms and their connection to online learning.\nIn entropy-regularized RL (ERL), an entropy term is added\nto the Bellman equation. This formulation has four main\nadvantages: 1) it softens the non-linearity of the Bellman\nequations and makes it possible to solve them more easily, 2) the solution of the softened problem is quantifiably\nnot much worse than the optimal solution in terms of accumulated return, 3) the addition of the entropy term brings\nnice properties, such as encouraging exploration (Shannon\nentropy) (e.g., Fox et al. 2016; Nachum et al. 2017) and\nmaintaining a close distance to a baseline policy (relative\nentropy) (e.g., Schulman et al. 2015; Nachum et al. 2018),\nand 4) unlike the original problem that has a deterministic\nsolution, the solution to the softened problem is stochastic, which is preferable in problems in which exploration or\ndealing with unexpected situations is important. However,\nin the most common form of ERL, in which a Shannon\n(or relative) entropy term is added to the Bellman equations, the optimal policy is of the form of softmax. Despite the advantages of a softmax policy in terms of exploration, its main drawback is that at each step, it assigns a\nnon-negligible probability mass to non-optimal actions, a\nproblem that is aggravated as the number of actions is increased. This may result in policies that may not be safe\nto execute. To address this issue, Lee et al. (2018) proposed to add a special form of a general notion of entropy,\n\n\fPath Consistency Learning in Tsallis Entropy Regularized MDPs\n\ncalled Tsallis entropy (Tsallis, 1988), to the Bellman equations. This formulation has the property that its solution has\nsparse distributions, i.e., at each state, only a small number of actions have non-zero probability. Lee et al. (2018)\nstudied the properties of this ERL formulation, proposed\nvalue-based algorithms (fitted Q-iteration and Q-learning)\nto solve it, and showed that although it is harder to solve\nthan its soft counterpart, it potentially has a solution closer\nto that of the original problem.\nIn this paper, we propose novel path consistency learning (PCL) algorithms for the Tsallis ERL problem, called\nsparse PCL. PCL is a class of actor-critic type algorithms\ndeveloped by Nachum et al. (2017) for the soft (Shannon\nentropy) ERL problem. It uses a nice property of soft ERL,\nnamely the equivalence of consistency and optimality, and\nlearns parameterized policy and value functions by minimizing a loss that is based on the consistency equation of\nsoft ERL. The most notable feature of soft PCL is that it\ncan work with both on-policy (sub-trajectories generated\nby the current policy) and off-policy (sub-trajectories generated by a policy different than the current one, including\nany sub-trajectory from the replay buffer) data. We first derive a multi-step consistency equation for the Tsallis ERL\nproblem, called sparse consistency. We then prove that in\nthis setting, while optimality implies consistency (similar\nto the soft case), unlike the soft case, consistency only implies sub-optimality. We then use the sparse consistency\nequation and derive PCL algorithms that use both on-policy\nand off-policy data to solve the Tsallis ERL problem. We\nempirically compare sparse PCL with its soft counterpart.\nAs expected, we gain from using the sparse formulation\nwhen the number of actions is large, both in algorithmic\ntasks and in discretized continuous control problems.\n\n2. Markov Decision Processes (MDPs)\nWe consider the reinforcement learning (RL) problem in\nwhich the agent’s interaction with the system is modeled as\na MDP. A MDP is a tuple M = (X , A, r, P, P0 , γ), where\nX and A are state and action spaces; r : X × A → R\nand P : X × A → ∆X are the reward function and transition probability distribution, with r(x, a) ∈ [0, Rmax ] and\nP (·|x, a) being the reward and the next state probability of\ntaking action a in state x; P0 : X → ∆X is the initial state\ndistribution; and γ ∈ [0, 1) is a discounting factor. In this\npaper, we assume that the action space is finite, but can be\nlarge. The goal in RL is to find a stationary Markovian policy, i.e., a mapping from state and action spaces to a simplex over the actions µ : X × A → ∆A , that maximizes\nthe expected discounted sum of rewards, i.e.,\nmax E\n\n∞\n\u0002X\n\nµ\n\ns.t.\n\nt\n\n\u0003\nγ r(xt , at )\n\n(1)\n\nt=0\n\n∀x\n\nX\na∈A\n\nµ(a|x) = 1,\n\n∀x, a µ(a|x) ≥ 0,\n\nwhere x0 ∼ P0 , at ∼ µ(·|xt ), and xt+1 ∼ P (·|xt , at ).\nFor a given policy µ, we define its value and action-value\nfunctions as\n∞\n\u0002X\n\u0003\nV µ (x) = E\nγ t r(xt , at )|x0 = x, µ, P ,\nt=0\n∞\n\u0002X\n\u0003\nQµ (x, a) = E\nγ t r(xt , at )|x0 = x, a0 = a, µ, P .\nt=0\n\nAny solution of the optimization problem (1) is called an\noptimal policy and is denoted by µ∗ . Note that while a\nMDP may have several optimal policies, it only has a sin∗\ngle optimal value function V ∗ = V µ . It has been proven\nthat (1) has a solution in the space of deterministic policies,\ni.e., Πd = {µ : µ : X → A}, which can be obtained as\nthe greedy action w.r.t. the optimal action-value function,\ni.e., µ∗ (x) ∈ arg maxa Q∗ (x, a) (Puterman, 1994; Bertsekas & Tsitsiklis, 1996). The optimal action-value function Q∗ is the unique solution of the non-linear Bellman\noptimality equations, i.e., for all x ∈ X and a ∈ A,\nX\nQ(x, a) = r(x, a)+γ\nP (x0 |x, a) max\nQ(x0 , a0 ). (2)\n0\na ∈A\n\nx0 ∈X\n\nAny optimal policy µ∗ and the optimal state and stateaction value functions, V ∗ and Q∗ , satisfy the following\nequations for all states and action,\nX\n\nQ∗ (x, a) = r(x, a) + γ\n\nP (x0 |x, a)V ∗ (x0 ),\n\nx0 ∈X\n\nV ∗ (x) = max Q∗ (x, a),\na∈A\n\nµ∗ (x) ∈ arg max Q∗ (x, a).\na∈A\n\n3. Entropy Regularized MDPs\nAs discussed in Section 2, finding an optimal policy for\na MDP involves solving a non-linear system of equations\n(see Eq. 2), which is often complicated. Moreover, the optimal policy may be deterministic, always selecting the same\noptimal action at a state even when there are several optimal actions in that state. This is undesirable when it is important to explore and to deal with unexpected situations.\nIn such cases, one might be interested in multimodal policies that still have good performance. This is why many\nresearchers have proposed to add a regularizer in the form\nof an entropy term to the objective function (1) and solve\nthe following entropy-regularized optimization problem\n∞\nhX\n\u0001i\nmax E\nγ t r(xt , at ) + αH µ (xt , at )\nµ\n\ns.t.\n\n(3)\n\nt=0\n\n∀x\n\nX\n\nµ(a|x) = 1,\n\n∀x, a µ(a|x) ≥ 0,\n\na∈A\n\nwhere H µ (x, a) is an entropy-related term and α is the regularization parameter. The entropy term smoothens the objective function (1) such that the resulting problem (3) is often easier to solve than the original one (1). This is another\nreason for the popularity of entropy-regularized MDPs.\n\n\fPath Consistency Learning in Tsallis Entropy Regularized MDPs\n\n3.1. Entropy Regularized MDP with Shannon Entropy\n4\n\nIt is common to use Hsfµ (xt , at ) = − log µ(at |xt ) in\nentropy-regularized MDPs (e.g., Fox\n\u0002 et al. 2016;\n\u0003 Nachum\net al. 2017). Note that Hsf (µ) = Eµ Hsfµ (x, a) is the Shannon entropy. Problem (3) with Hsfµ (x, a) can be seen as a\nRL problem in which the reward function is the sum of the\noriginal reward function r(x, a) and a term that encourages\nexploration.1 Unlike (1), the optimization problem (3) with\nHsfµ has a unique optimal policy µ∗sf and a unique optimal\nvalue Vsf∗ (action-value Q∗sf ) function that satisfy the following equations:\nQ∗sf (x, a) = r(x, a) + γ\n\nX\n\nP (x0 |x, a)Vsf∗ (x0 ),\n\n3.2. Entropy Regularized MDP with Tsallis Entropy\nTo address the issues with the softmax policy, Lee et al.\n\u0001\n4\nµ\n(2018) proposed to use Hsp\n(xt , at ) = 21 1 − µ(at |xt )\nin \u0002entropy-regularized\nMDPs. Note that Hsp (µ) =\n\u0003\nµ\nEµ Hsp\n(x, a) is a special case of a general notion of entropy, called\nentropy (Tsallis, 1988), i.e., Sq,k (p) =\nP Tsallis\nq\nk\n(1\n−\np\n),\nfor\nthe parameters q = 2 and k = 12 .2\ni i\nq−1\nSimilar to the soft MDP problem, the optimization probµ\nlem (3) with Hsp\nhas a unique optimal policy µ∗sp and a\nunique optimal value Vsp∗ (action-value Q∗sp ) function that\nsatisfy the following equations (Lee et al., 2018):\nQ∗sp (x, a) = r(x, a) + γ\n\nx0 ∈X\n\nX\n\nP (x0 |x, a)Vsp∗ (x0 ),\n\nx0 ∈X\n\n\u0001\nVsf∗ (x) = α · sfmax Q∗sf (x, ·)/α ,\n\u0001\nexp Q∗sf (x, a)/α\n\u0001,\nµ∗sf (a|x) = P\n∗\n0\na0 ∈A exp Qsf (x, a )/α\n\n(4)\n\nwhere for any function f : X\u0001 × A → R,P\nthe sfmax operator\n\u0001\u0001\nis defined as sfmax f (x, ·) = log\na exp f (x, a) .\nNote that the equations in (4) are derived from the KKT\nconditions of (3) with Hsfµ . In this case, the optimal policy\nis soft-max, with the regularization parameter α playing the\nrole of its temperature (see Eq. 4). This is why (3) with Hsfµ\nis called the soft MDP problem. In soft MDPs, the optimal\nvalue function Vsf∗ is the unique solution of the soft Bellman\noptimality equations, i.e., ∀x ∈ X , ∀a ∈ A,\n\n\u0001\nVsp∗ (x) = α · spmax Q∗sp (x, ·)/α ,\n\u0010\n\u0001\u0011+\n,\nµ∗sp (a|x) = Q∗sf (x, a)/α − G Q∗sf (x, ·)/α\n\nwhere (·)+ = max(·, 0), and for any function f : X ×A →\nR, the spmax operator is defined as\n\u0010 f (x, ·) \u00112 \u0011i\nX \u0010\u0010 f (x, a) \u00112\n\u0001\n1h\n1+\n−G\n,\nspmax f (x, ·) =\n2\nα\nα\na∈S(x)\n\nin which\nP\n\u0001\nG f (x, ·) =\n\na∈S(x)\n\nf (x, a) − 1\n\n|S(x)|\nf (x,a\n\nV (x) = α · sfmax\n\n\u0010\u0002\n\nr(x, ·) + γ\n\nX\n\n\u0003 \u0011\nP (x |x, ·)V (x ) /α . (5)\n0\n\n0\n\nx0\n\nNote that the sfmax operator is a smoother function of its\ninputs than the max operator associated with the Bellman\noptimality equation (2). This means that solving the soft\nMDP problem is easier than the original one, with the cost\nthat its optimal policy µ∗sf performs worse than the optimal policy of the original MDP µ∗ . This difference can be\nquantified as\n∀x ∈ X\n\nV ∗ (x) −\n\n∗\nα\nlog(|A|) ≤ V µsf (x) ≤ V ∗ (x), (6)\n1−γ\n\nwhere we discriminate between the value function of a policy µ in the soft Vsfµ and original V µ MDPs. Note that the\nsub-optimality of µ∗sf is unbounded as |A| → ∞. This is\nthe main drawback of using softmax policies; in large action space problems, at each step, the policy assigns a nonnegligible probability mass to non-optimal actions, which\nin aggregate can be detrimental to its reward performance.\n1\n\nAnother entropy term that has been studied in the literature\n\n(7)\n\n)\n\nand S(x) is the set of actions satisfying 1 + i α (i) >\nPi f (x,a(j) )\n, where a(i) indicates the action with the ith\nj=0\nα\nlargest value of f (x, a). Note that the equations in (7) are\nµ\nderived from the KKT conditions of (3) with Hsp\n. In this\ncase, the optimal policy may have zero probability for sevµ\neral actions (see Eq. 7). This is why (3) with Hsp\nis called\nthe sparse MDP problem. The regularization parameter\nα controls the sparsity of the resulted policy. The policy\nwould be more sparse for smaller values of α. In sparse\nMDPs, the optimal value function Vsp∗ is the unique fixedpoint of the sparse Bellman optimality operator Tsp (Lee\net al., 2018) that for any function f : X → R is defined as\n\u0010\u0002\nX\n\u0003 \u0011\nP (x0 |x, ·)f (x0 ) /α .\n(Tsp f )(x) = α · spmax r(x, ·) + γ\nx0\n\n(8)\n\nSimilar to (5), the spmax operator is a smoother function of\nits inputs than the max, and thus, solving the sparse MDP\nproblem is easier than the original one, with the cost that its\noptimal policy µ∗sp performs worse than the optimal policy\nof the original MDP µ∗ . This difference can be quantified\nas (Lee et al., 2018),\n\n4\n\nµ\nt |xt )\nis Hrel\n(xt , at ) = − log µµ(a\n, where πb is a baseline policy.\nt |xt ) \u0003\n\u0002 b (a\nµ\nNote that Hrel (µ) = Eµ Hrel (x, a) is the relative entropy. Probµ\nlem (3) with Hrel\n(x, a) can be seen as a RL problem in which the\nreward function is the sum of the original reward function r(x, a)\nand a term that penalizes deviation from the baseline policy πb .\n\n∀x ∈ X\n\nV ∗ (x) −\n\n∗\n|A| − 1\nα\n·\n≤ V µsp (x) ≤ V ∗ (x). (9)\n1−γ\n2|A|\n\n2\nNote that the Shannon entropy is a special case of the Tsallis\nentropy for the parameters q = k = 1 (Tsallis, 1988).\n\n\fPath Consistency Learning in Tsallis Entropy Regularized MDPs\n\nOn the other hand, the spmax operator is more complex\nthan sfmax, and thus, it is slightly more complicated to\nsolve the sparse MDP problem than its soft counterpart.\nHowever, as can be seen from Eqs. 6 and 9, the optimal policy of the sparse MDP, µ∗sp , can have a better performance\nthan its soft counterpart, µ∗sf , and this difference becomes\nmore apparent as the number of actions |A| grows. For\nlarge action size, the term (|A| − 1)/(2|A|) in (9) turns to\na constant, while log |A| in (6) grows unbounded.\n\n4. Path Consistency Learning in Soft MDPs\nA nice property of soft MDPs that was elegantly used\nby Nachum et al. (2017) is that any policy µ and function\nV : X → R that satisfy the (one-step) consistency equation, i.e., for all x ∈ X and for all a ∈ A,\nV (x) = r(x, a)−α log µ(a|x)+γ\n\nX\n\nP (x0 |x, a)V (x0 ), (10)\n\nx0 ∈X\n\nµ∗sf\n\nare optimal, i.e., µ =\nand V = Vsf∗ (consistency implies\noptimality). Due to the uniqueness of the optimal policy\nin soft MDPs, the reverse is also true, i.e., the optimal policy µ∗sp and the value function Vsp∗ satisfy the consistency\nequation (optimality implies consistency).\nAs shown in Nachum et al. (2017), the (one-step) consistency equation (10) can be easily extended to multi-step,\ni.e., any policy µ and function V : X → R that for any\nstate x0 and sequence of actions a0 , . . . , ad−1 , satisfy the\nmulti-step consistency equation\nh\nV (x0 ) = Ex1:d |x0 ,a0:d−1 γ d V (xd )\n+\n\nd−1\nX\n\nγ t r(xt , at ) − α log µ(at |xt )\n\n(11)\n\u0001i\n\nt=0\n\nare optimal, i.e., µ = µ∗sf and V = Vsf∗ .\nThe property that both single and multiple step consistency\nequations imply optimality (Eqs. 10 and 11) was the motivation of a RL algorithm by Nachum et al. (2017), path\nconsistency learning (PCL). The main idea of (soft) PCL is\nto learn a parameterized policy and value function by minimizing the following objective function:\nJ (θ, φ) =\n\n1X\nJ(ξi , θ, φ)2 ,\n2\nξi\n\nwhere ξ = (x0 , a0 , r0 , . . . , xd−1 , ad−1 , rd−1 , xd ) is any dlength sub-trajectory, θ and φ are the policy and value function parameters, respectively, and\nJ(ξ, θ, φ) = −Vφ (x0 ) + γ d Vφ (xd )\n+\n\nd−1\nX\n\n(12)\n\n\u0001\nγ t r(xt , at ) − α log µθ (at |xt ) .\n\nt=0\n\nAn important property of the soft PCL algorithm is that\nsince the multi-step consistency (11) holds for any d-length\n\nsub-trajectory, it can use both on-policy (ξ’s generated by\nthe current policy µθ ) and off-policy data, i.e., ξ’s generated\nby a policy different than the current one, including any dlength sub-trajectory from the replay buffer.\nNote that since both optimal policy µ∗sf and value function Vsf∗ can be written based on the optimal action-value\nfunction Q∗sf (see Eq. 4), we may write the objective function (12) based on Qψ , and optimize only one set of parameters ψ, instead of separate θ and φ.\n\n5. Consistency between Optimal Value &\nPolicy in Sparse MDPs\nThis section begins the main contributions of our work.\nWe first identify a (one-step) consistency equation for the\nsparse MDPs defined by (3). We then prove the relationship\nbetween the sparse consistency equation and the optimal\npolicy and value function of the sparse MDP, and highlight\nits similarities and differences with that in soft MDPs, discussed in Section 4. We then extend the sparse consistency\nequation to multiple steps and prove results that allow us\nto use the multi-step sparse consistency equation to derive\non-policy and off-policy algorithms to solve sparse MDPs,\nwhich we fully describe in Section 6. The significance\nof the sparse consistency equation is in providing an efficient tool for computing a near-optimal policy for sparse\nMDPs, which only involves solving a set of linear equations and linear complementary constraints, as opposed to\n(iteratively) solving the fixed-point of the non-linear sparse\nBellman operator (8). We report the proofs of all the theorems of this section in Appendix A.\nFor any policy µ and value function V : X → R, we define\nthe (one-step) consistency equation of the sparse MDPs as,\nfor all state x ∈ X and for all actions a ∈ A,\nα\nV (x) = r(x, a) + − αµ(a|x) + λ(a|x) − Λ(x)\n2\nX\n+γ\nP (x0 |x, a)V (x0 ),\n(13)\nx0\n\nwhere λ : X × A → R+ and Λ : X → R− are Lagrange multipliers, such that λ(a|x) · µ(a|x) = 0 and\n− α2 ≤ Λ(x) ≤ 0. We call this the one-step sparse consistency equation and it is the equivalent of Eq. 10 in soft\nMDPs.\nWe now present a theorem which states that, similar to soft\nMDPs, optimality in sparse MDPs is a necessary condition\nfor consistency, i.e., optimality implies consistency.\nTheorem 1. The optimal policy µ∗sp and value function Vsp∗\nof the sparse MDP (3) satisfy the consistency equation (13).\nTheorem 2 shows that in the sparse MDPs, consistency\nonly implies near-optimality, as opposed to optimality in\nthe case of soft MDPs.\n\n\fPath Consistency Learning in Tsallis Entropy Regularized MDPs\n\nTheorem 2. Any policy µ that satisfies the consistency\nequation (13) is α/(1 − γ)-optimal in the sparse MDP (3),\ni.e., for each state x ∈ X , we have\nα\nVspµ (x) ≥ Vsp∗ (x) −\n.\n(14)\n1−γ\nThis result indicates that for a fixed γ, as α decreases, a\npolicy µ satisfying the one-step consistency equations approaches the true optimal µ∗sp . To connect the performance\nof µ to the original goal of maximizing expected return,\nwe present the following corollary, which is a direct consequence of Theorem 2 and the results reported in Section 3.2\non the performance of µ∗sp in the original MDP.\nCorollary 1. Any policy µ that satisfies the consistency\n1\nα\n) · 1−γ\n-optimal in the original\nequation (13) is ( 32 − |A|\nMDP (1), i.e., for each state x ∈ X , we have\n\u0012\n\u0013\n3\n1\nα\n∗\nV (x) −\n−\n·\n≤ V µ (x) ≤ V ∗ (x).\n2 |A|\n1−γ\nWe now extend the (one-step) sparse consistency equation (13) to multiple steps. For any state x0 ∈ X and sequence of actions a0 , . . . , ad−1 , define the multi-step consistency equation for sparse MDPs as\nh\nV (x0 ) = Ex1:d |x0 ,a0:d−1 γ d V (xd )\n+\n\nd−1\nX\nt=0\n\nγ t r(xt , at ) +\n\n(15)\n\n\u0001i\nα\n− αµ(at |xt ) + λ(at |xt ) − Λ(xt ) ,\n2\n\nwhere λ : X × A → R+ and Λ : X → R− are Lagrange multipliers, such that λ(a|x) · µ(a|x) = 0 and\n− α2 ≤ Λ(x) ≤ 0. We call this multi-step sparse consistency equation, the equivalent of Eq. 11 in soft MDPs.\nFrom Theorem 1, we can immediately show that multi-step\nsparse consistency is a necessary condition of optimality.\nCorollary 2. The optimal policy µ∗sp and value function\nVsp∗ of the sparse MDP (3) satisfy the multi-step consistency\nequation (15).\nProof. The proof follows directly from Theorem 1, by repeatedly applying the expression in (13) over the trajectory\nξ, taking the expectation over the trajectory, and using telescopic cancellation of the value function of intermediate\nstates.\nConversely, followed from Theorem 2, we prove the following result on the performance of any policy satisfying\nthe mutli-step consistency equation. This is a novel result\nshowing that solving the multi-step consistency equation is\nindeed sufficient to guarantee near-optimality.\nCorollary 3. Any policy µ that satisfies the multi-step consistency equation (15) is α/(1 − γ)-optimal in the sparse\nMDP (3).\n\nProof. Consider the multi-step consistency equation (15).\nSince it is true for any initial state x0 and sequence of actions a0:d−1 , unrolling it for another d steps starting at state\nxd and using the action sequence ad:2d−1 yields\nh\nV (x0 ) = Ex1:2d |x0 ,a0:2d−1 γ 2d V (x2d )\n+\n\n2d−1\nX\n\nγ t r(xt , at ) +\n\nt=0\n\n\u0001i\nα\n− αµ(at |xt ) + λ(at |xt ) − Λ(xt ) .\n2\n\nNote that this process can be repeated for an arbitrary\nnumber of times (say k times), and also note that as V\nis a bounded function, one has limk→∞ γ kd V (xkd ) = 0.\nTherefore, by further unrolling, we obtain\nV (x0 ) = Ex1:∞ |x0 ,a0:∞\n\n∞\nhX\n\nγ t r(xt , at ) +\n\nt=0\n\nα\n− αµ(at |xt )\n2\n\n\u0001i\n+ λ(at |xt ) − Λ(xt ) .\n\nFollowed from the Banach fixed-point theorem (Bertsekas\n& Tsitsiklis, 1996), one can show that the solution pair\n(V, µ) is also a solution to the one-step consistency condition in (13), i.e.,PV (x) = r(x, a) + α2 − αµ(a|x) +\nλ(a|x)−Λ(x)+γ x0 ∈X P (x0 |x, a)V (x0 ), for any x ∈ X\nand a ∈ A. Thus the α/(1 − γ)-optimality performance\nguarantee of µ is implied by Theorem 2.\nEquipped with the above results on the relationship between (near)-optimality and multi-step consistency in\nsparse MDPs, we are now ready to present our off-policy\nRL algorithms to solve the sparse MDP (3).\n\n6. Path Consistency Learning in Sparse MDPs\nSimilar to the PCL algorithm for soft MDPs, in sparse\nMDPs the multi-step consistency equation (15) naturally\nleads to a path-wise algorithm for training a policy µθ and\nvalue function Vφ parameterized by θ and φ, as well as Lagrange multipliers Λρ and λθ,ρ parameterized by the auxiliary parameter ρ. To characterize the objective function of\nthis algorithm, we first define the soft consistency error for\nthe d-step sub-trajectory ξ as a function of θ, ρ, and φ,\nJ(ξ; θ,ρ, φ) = −Vφ (x) + γ d Vφ (xd )\n+\n\nd−1\nX\nt=0\n\nγ j r(xt , at ) +\n\n\u0001\nα\n− αµθ (at |xt ) + λθ,ρ (at |xt ) − Λρ (xt ) .\n2\n\nThe goal of our algorithm is to learn Vφ , µθ , λθ,ρ ,\nand Λρ , such that the expectation of J(ξ; θ, ρ, φ) for\nany initial state x0 and action sequence a0:d−1 is as\nclose to 0 as possibles. Our sparse PCL algorithm minimizes\nobjective function Jn (θ, ρ, φ) =\nP the empirical\n1\n2\nJ(ξ\n;\nθ,\nρ,\nφ)\n,\nwhich\nconverges to J (θ, ρ, φ) =\ni\nξi\n2\n\n\fPath Consistency Learning in Tsallis Entropy Regularized MDPs\n\n\u0002\n\u0003\nEx0 ,a0:d−1 E[J(ξ; θ, ρ, φ)2 | x0 , a0:d−1 ] as i → ∞. By\nthe Cauchy-Schwarz inequality, J (θ, ρ, φ) is a conserva\u0002\n\u00032\ntive surrogate of E J(ξ; θ, ρ, φ) , which represents the\nerror of the multi-step consistency equation. This relationship justifies that the solution policy of the sparse PCL algorithm is near-optimal (see Corollary 3). Moreover, the\ngradient of J(ξ) w.r.t. the parameters is as follows:\nd−1\nX\n\u0001\n∂J(ξ)\n= J(ξ; θ, ρ, φ)\nγ t ∇θ λθ,ρ (at |xt ) − αµθ (at |xt ) ,\n∂θ\nt=0\nd−1\nX\n\n\u0001\n∂J(ξ)\n= J(ξ; θ, ρ, φ)\nγ t ∇ρ λθ,ρ (at |xt ) − Λρ (xt ) ,\n∂ρ\nt=0\n\u0001\n∂J(ξ)\n= J(ξ; θ, ρ, φ)∇φ Vφ (x0 ) − γ d Vφ (xd ) .\n∂φ\n\nWe may relate the sparse PCL algorithm to the standard\nactor-critic (AC) algorithm (Konda & Tsitsiklis, 2000; Sutton et al., 2000), where ∂J(ξ)/∂θ and ∂J(ξ)/∂φ correspond to the actor and critic updates, respectively. An advantage of sparse PCL over the standard AC is that it does\nnot need the multi-time-scale update required by AC for\nconvergence.\nWhile optimizing J(θ, ρ, φ) minimizes the mean square\nof the soft consistency error, in order to satisfy the multistep consistency in (15), one still needs to impose the following constraints on Lagrange multipliers into the optimization problem: (i) − α2 ≤ Λρ (x) ≤ 0, and (ii)\nλθ,ρ (a|x) · µθ (a|x) = 0, ∀x ∈ X , ∀a ∈ A. One standard\napproach is to replace the above constraints with adding\npenalty functions (Bertsekas, 1999) to the original objective function Jn . Note that each penalty function is associated with a penalty parameter and there are |X | · |A| + 2|X |\nconstraints. When |X | and |A| are large, tuning all the\nparameters becomes computationally expensive. Another\napproach is to update the penalty parameters using gradient ascent methods (Bertsekas, 2014). This is equivalent to\nfinding the saddle point of the Lagrangian function in the\nconstrained optimization problem. However, the challenge\nis to balance the primal and dual updates in practice.\nWe hereby describe an alternative and a much simpler\nmethodology to parameterize the Lagrange multipliers\nλθ,ρ (a|x) and Λρ (x), such that the aforementioned constraints are immediately satisfied. Although this method\nmay impose extra restrictions to the representations of their\nfunction approximations, it avoids the difficulties of directly solving a constrained optimization problem. Specifically, to satisfy the constraint (i), one can parameterize Λρ\nwith a multilayer perceptron network that has either an activation function of −α/2 · σ(·) or −α/2 · (1 + tanh(·))/2\nat its last layer. To satisfy constraint (ii), we consider the\ncase when µθ is written in form of (fθ (x, a))+ for some\nfunction approximator fθ . This parameterization of µθ is\njustified by the closed-form solution policy of the Tsallis\n\nentropy-regularized MDP problem in (7). Specifically, (7)\n∗\nuses fsp\n(x, a) = Q∗sp (x, a)/α − G(Q∗sp (x, ·)/α). Now suppose that λθ,ρ is parameterized as follows: λθ,ρ (a|x) =\n\u0001+\n−fθ (x, a) · Fρ (x, a), where Fρ : X × A → R+ is\nan auxiliary function approximator. Then by the property\n(x)+ · (−x)+ = 0, constraint (ii) is immediately satisfied.\nA pseudo-code of our sparse PCL algorithm can be found\nin Algorithm 1 in the Appendix A.\nUnified Sparse PCL Note that the closed-form optimal\npolicy µ∗sp and value function Vsp∗ are both functions of the\noptimal state-action value function Q∗sp . As in soft PCL,\nbased on this observation one can also parameterize both\npolicy and value function in sparse PCL (see Eq. 7) with\na single function approximator Qψ (x, a). Although consistency does not imply optimality in sparse MDPs (as opposed to the case of soft MDPs), the justification of this parameterization comes from Corollary 2, where the unique\noptimal value function and optimal policy satisfy the consistency equation (15). From an actor-critic perspective,\nthe significance of this is that both policy (actor) and value\nfunction (critic) can be updated simultaneously without affecting the convergence. Accordingly, the update rule for\nthe model parameter ψ takes the form\nd−1\n\u0010X\n\u0001\n∂J(ξ)\n= J(ξ; ψ, ρ)\nγ t ∇ψ λψ,ρ (at |xt ) −αµψ (at |xt )\n∂ψ\nt=0\n\u0011\n+ ∇ψ Vψ (x0 ) − γ d ∇ψ Vψ (xd ) .\n\n7. Experimental Results\nWe demonstrate the effectiveness of the sparse PCL algorithm by comparing its performance with that of the soft\nPCL algorithm on a number of RL environments available\nin the OpenAI Gym (Brockman et al., 2016) environment.\n7.1. Discrete Control\nHere we compare the performance of these two algorithms\non the following standard algorithmic tasks: 1) Copy, 2)\nDuplicatedInput, 3) RepeatCopy, 4) Reverse, and 5) ReversedAddition (see appendix for more details). Each task\ncan be viewed as a grid environment, where each cell stores\na single character from a finite vocabulary V. An agent\nmoves on the grid of the environment and writes to output.\nAt each time step the agent observes the character of the\nsingle cell in which it is located. After observing the character, the agent must take an action of the form (m, w, c),\nwhere m determines the agent’s move to an adjacent cell,\n(in 1D environments, m ∈ {left, right}; in 2D environments, m ∈ {left, right, up, down}), w ∈ {0, 1} determines\nwhether the agent writes to output or not, and c ∈ V determines the character that the agent writes if w = 1 (otherwise c = ∅). Based on this problem setting, the action\n\n\fPath Consistency Learning in Tsallis Entropy Regularized MDPs\n\nCopy\n\n|A| = 20\n\n|A| = 40\n30\n\n30\n\n25\n\n25\n\n25\n\n25\n\n20\n\n20\n\n20\n\n20\n\n15\n\n15\n\n15\n\n15\n\n10\n\n10\n\n10\n\n10\n\n5\n\n5\n\n5\n\n0\n0\n\n500\n\n1000\n\n1500\n\n2000\n\nDuplicatedInput\n\n5\n\n0\n0\n\n1000\n\n|A| = 20\n\n2000\n\n3000\n\n4000\n\n0\n0\n\n|A| = 80\n\n2000\n\n4000\n\n6000\n\n8000\n\n10000\n\n0\n\n|A| = 160\n\n15\n\n15\n\n15\n\n10\n\n10\n\n10\n\n10\n\n5\n\n5\n\n5\n\n5\n\n0\n\n0\n500\n\n1000\n\n1500\n\n2000\n\n2500\n\n0\n0\n\n1000\n\n|A| = 20\n\n2000\n\n3000\n\n4000\n\n5000\n\n5000\n\n10000\n\n15000\n\n0\n\n|A| = 80\n\n80\n\n80\n\n80\n\n60\n\n60\n\n60\n\n40\n\n40\n\n40\n\n40\n\n20\n\n20\n\n20\n\n20\n\n0\n\n0\n\n0\n\n10000\n\n15000\n\n0\n\n|A| = 16\n\n2000\n\n4000\n\n6000\n\n8000\n\n10000\n\n5000\n\n10000\n\n15000\n\n20000\n\n0\n\n|A| = 64\n\n30\n\n30\n\n30\n\n25\n\n25\n\n25\n\n25\n\n20\n\n20\n\n20\n\n20\n\n15\n\n15\n\n15\n\n15\n\n10\n\n10\n\n10\n\n10\n\n5\n\n5\n\n5\n\n0\n5000\n\n10000\n\n15000\n\n20000\n\n5000\n\n10000\n\n15000\n\n20000\n\nSoft PCL\n\n5000\n\n10000\n\n15000\n\n20000\n\n5\n\n0\n0\n\n10000 20000 30000 40000 50000\n\n|A| = 128\n\n30\n\n0\n\n20000\n\n0\n0\n\n|A| = 32\n\n0\n\n15000\n\n|A| = 160\n\n60\n\n5000\n\n10000\n\n0\n0\n\n|A| = 40\n\n80\n\n0\n\n5000\n\n|A| = 320\n\n15\n\n0\n\nRepeatCopy\n\n|A| = 160\n\n30\n\n0\n\nReverse\n\n|A| = 80\n\n30\n\n0\n0\n\n10000 20000 30000 40000 50000\n\n0\n\n10000 20000 30000 40000 50000\n\nSparse PCL\n\nFigure 1. Results of the average reward from sparse PCL and standard soft PCL during training. Here each row corresponds to a specific\nalgorithmic task. For each particular task, the action space is increased from left to right across the rows, corresponding to an increase in\ndifficulty. We observe that soft PCL returns a better solution when the action space is small, but its performance degrades quickly as the\nsize of action space grows. On the other hand, sparse PCL is not only able to learn good policies in tasks with small action spaces, but,\nunlike soft PCL, also successfully learns high-reward policies in the higher-dimension variants. See the appendix for additional results.\n\nspace A has size |A| = Θ(|V|). Accordingly, the difficulty of these tasks grows with the size of the vocabulary.\nTo illustrate the effectiveness of Tsallis entropy-regularized\nMDPs in problems with large action space, we evaluate\nthese two PCL algorithms on 4 different choices of |V|.\nIn each task, the agent has a different goal. In Copy, the\nenvironment is a 1D sequence of characters and the agent\naims to copy the sequence to output. In DuplicatedInput,\nthe environment is a 1D sequence of duplicated characters\nand the agent needs to write the de-duplicated sequence to\noutput. In RepeatCopy, the environment is a 1D sequence\nof characters in which the agent must copy in forward order, reverse order, and finally forward order again. In Reverse, the environment is a 1D sequence of characters in\nwhich the agent must copy to output in reverse order. Finally, in ReversedAddition, the environment is a 2 × n\ngrid of digits representing two numbers in base-|V| that the\nagent needs to sum. In each task the agent receives a reward of 1 for each correctly output character. The episode\nis terminated either when the task is completed, or when\nthe agent outputs an incorrect character.\n\nWe follow a similar experimental procedure as in Nachum\net al. (2017), where the functions V , µ, λ, Λ in the consistency equations are parameterized with a recurrent neural\nnetwork with multiple heads. For each task and each PCL\nalgorithm, we perform a hyper-parameter search to find\nthe optimal regularization weight α, and the corresponding training curves for average reward are shown in Figure\n1. To increase the statistical significance of these experiments, we also train these policies on 5 different Monte\nCarlo trials (Notice that these environments are inherently\ndeterministic, therefore no additional Monte Carlo evaluation is needed.). Details of the experimental setup and extra\nnumerical results are included in the Appendix.\nFor each task we evaluated sparse PCL compared to the\noriginal soft PCL on a suite of variants which successively\nincrease the vocabulary size. For low vocabulary sizes soft\nPCL achieves better results. This suggests that Shannon entropy encourages better exploration in small action spaces.\nIndeed, in such regimes, a greater proportion of the total actions are useful to explore, and exploration is not as costly.\nTherefore, the decreased exploration of the Tsallis entropy\n\n\fPath Consistency Learning in Tsallis Entropy Regularized MDPs\n\n7.2. Continuous Control\nWe further evaluate the two PCL algorithms on HalfCheetah, a continuous control problem in the OpenAI gym.\nThe environment consists of a 6−dimensional action\nspace, where each dimension corresponds to a torque\nof [−1, 1]. Here we discretize each continuous action\nwith either one of the following grids: {−1, 0, 1} and\n{−1, −0.5, 0, 0.5, 1}. Even though the resolution of these\ndiscretization grids is coarse, the corresponding action\nspaces are quite large, with sizes of 36 = 729 and 56 =\n15625, respectively.\nWe present the results of sparse PCL and soft PCL on these\ndiscretized problems in Figure 2. Similar to the observations in the algorithmic tasks, here the policy learned by\nsparse PCL performs much better than that of soft PCL.\nSpecifically sparse PCL achieves higher average reward\nand is able to learn much faster. To better visualize the\nlearning progress of these two PCL algorithms in these\nproblems, at each training step we also compare the average\nprobability of the most-likely actions across all time-steps\nfrom the on-policy trajectory.3 Clearly, sparse PCL quickly\nconverges to a near-deterministic policy, while the policy\ngenerated by soft PCL still allocates significant probability\nmasses to non-optimal actions (as the average probability\nof most-likely actions barely ever exceeds 0.75). In environments like HalfCheetah, where the trajectory has a long\nhorizon (1000 steps), the soft-max policy will in general\nsuffer because it chooses a large number of sub-optimal actions in each episode for exploration.\nComparing with the performance of other continuous RL\nalgorithms such as deterministic policy gradient (DPG)\n(Silver et al., 2014), we found that the policy generated by\n3\n\nSpecifically in each iteration we collect a single on-policy\ntrajectory of 1000 steps. Therefore this metric is an average over\n1000 samples of (greedy) action probabilities.\n\n|A| = 56\n\n2500\n\n2500\n\n2000\n\n2000\n\n1500\n\n1500\n\n1000\n\n1000\n\n500\n\n500\n0\n\n0\n0\n\nMost Likely\nProbability\n\nAs we increase the vocabulary size (and thus the action\nspace), the picture changes. We see that the advantage of\nsoft PCL over sparse PCL decreases until eventually the\norder is reversed and sparse PCL begins to show a significant improvement over the standard soft PCL. This supports our original hypothesis. In large action spaces, the\ntendency of soft PCL to assign a non-zero probability to\nmany sub-optimal actions over-emphasizes exploration and\nis detrimental to the final reward performance. On the other\nhand, sparse PCL is able to handle exploration in large action spaces properly. These empirical results provide evidence for this unique advantage of sparse PCL.\n\nReward\n\n|A| = 36\nmay outweigh its asymptotic benefits. The sub-optimality\nbounds presented in this paper support this behavior: when\n|A| is small, αsoft PCL log(|A|) ≤ 3αsparse PCL /2.\n\n20000\n\n40000\n\n60000\n\n1.0\n\n1.0\n\n0.8\n\n0.8\n\n0.6\n\n0.6\n\n0.4\n\n0.4\n0\n\n20000\n\n40000\n\n60000\n\nSoft PCL\n\n0\n\n20000\n\n40000\n\n60000\n\n0\n\n20000\n\n40000\n\n60000\n\nSparse PCL\n\nFigure 2. Results of sparse PCL and soft PCL in HalfCheetah\nwith discretized actions. The top figure shows the average reward\nover 5 random runs during training, with best hyper-parameters.\nOn the bottom we plot the average probability of the most-likely\nactions during training. The bottom figure illustrates the fast convergence of sparse PCL to a near-deterministic policy.\n\nsparse PCL is sub-optimal. This is mainly due to the coarse\ndiscretization of the action space. Our main purpose here\nis to demonstrate the fast and improved convergence to deterministic policies in sparse PCL, compared to soft PCL.\nFurther evaluation of sparse PCL will be left to future work.\n\n8. Conclusions\nIn this work we studied the sparse entropy-regularized\nproblem in RL, whose optimal policy has non-zero probability for only a small number of actions. Similar to the\nwork by Nachum et al. (2017), we derived a relationship\nbetween (near-)optimality and consistency for this problem. Furthermore, by leveraging the properties of the consistency equation, we proposed a class of sparse path consistency learning (sparse PCL) algorithms that are applicable to both on-policy and off-policy data and can learn\nfrom multi-step trajectories. We found that the theoretical\nadvantages of sparse PCL correspond to empirical advantages as well. For tasks with a large number of actions,\nwe find significant improvement in final performance and\namount of time needed to reach that performance by using\nsparse PCL compared to the original soft PCL.\nFuture work includes 1) extending the sparse PCL algorithm to the more general class of Tsallis entropy, 2) investigating the possibility of combining sparse PCL and\npath following algorithms such as TRPO (Schulman et al.,\n2015), and 3) comparing the performance of sparse PCL\nwith other deterministic policy gradient algorithms, such\nas DPG (Silver et al., 2014) in the continuous domain.\n\n\fPath Consistency Learning in Tsallis Entropy Regularized MDPs\n\nReferences\nAsadi, K. and Littman, M. An alternative softmax operator for reinforcement learning. In Proceedings of the\n34th International Conference on Machine Learning, pp.\n243–252, 2017.\nAzar, M., Gómez, V., and Kappen, H. Dynamic policy\nprogramming. Journal of Machine Learning Research,\n13:3207–3245, 2012.\nBellman, R. Dynamic Programming. Princeton University\nPress, 1957.\nBertsekas, D. Nonlinear programming. Athena scientific\nBelmont, 1999.\nBertsekas, D. Constrained optimization and Lagrange multiplier methods. Academic press, 2014.\nBertsekas, D. and Tsitsiklis, J. Neuro-Dynamic Programming. Athena Scientific, 1996.\nBrockman, G., Cheung, V., Pettersson, L., Schneider, J.,\nSchulman, J., Tang, J., and Zaremba, W. OpenAI Gym.\narXiv:1606.01540, 2016.\nFarahmand, A. M., Ghavamzadeh, M., Szepesvári, Cs., and\nMannor, S. Regularized policy iteration. In Proceedings\nof Advances in Neural Information Processing Systems\n21, pp. 441–448. MIT Press, 2008.\nFarahmand, A. M., Ghavamzadeh, M., Szepesvári, Cs., and\nMannor, S. Regularized fitted Q-iteration for planning in\ncontinuous-space Markovian decision problems. In Proceedings of the American Control Conference, pp. 725–\n730, 2009.\nFox, R., Pakman, A., and Tishby, N. G-learning: Taming the noise in reinforcement learning via soft update.\nIn Proceedings of the 32nd International Conference on\nUncertainty in Artificial Intelligence, pp. 202–211, 2016.\nGhavamzadeh, M., Lazaric, A., Munos, R., and Hoffman,\nM. Finite-sample analysis of lasso-td. In Proceedings of\nthe Twenty-Eighth International Conference on Machine\nLearning, pp. 1177–1184, 2011.\nJohns, J., Painter-Wakefield, C., and Parr, R. Linear complementarity for regularized policy evaluation and improvement. In Proceedings of Advances in Neural Information Processing Systems 23, pp. 1009–1017. MIT\nPress, 2010.\nKappen, H. Path integrals and symmetry breaking for optimal control theory. Journal of Statistical Mechanics, 11,\n2005.\n\nKolter, Z. and Ng, A. Regularization and feature selection\nin least-squares temporal difference learning. In Proceedings of the Twenty-Sixth International Conference\non Machine Learning, pp. 521–528, 2009.\nKonda, V. and Tsitsiklis, J. Actor-critic algorithms. In\nAdvances in neural information processing systems, pp.\n1008–1014, 2000.\nLee, K., Choi, S., and Oh, S. Sparse Markov decision processes with causal sparse Tsallis entropy regularization\nfor reinforcement learning. IEEE Robotics and Automation Letters, 2018.\nMnih, V., Badia, A., Mirza, M., Graves, A., Lillicrap,\nT., Harley, T., Silver, D., and Kavukcuoglu, K. Asynchronous methods for deep reinforcement learning. In\nProceedings of the 33rd International Conference on\nMachine Learning, pp. 1928–1937, 2016.\nNachum, O., Norouzi, M., Xu, K., and Schuurmans, D.\nBridging the gap between value and policy based reinforcement learning. In NIPS, pp. 2772–2782, 2017.\nNachum, Ofir, Norouzi, Mohammad, Xu, Kelvin, and\nSchuurmans, Dale. Trust-pcl: An off-policy trust region\nmethod for continuous control. In Proceedings of the 5th\nInternational Conference on Learning Representations,\n2018.\nNeu, G., Jonsson, A., and Gómez, V.\nA unified\nview of entropy-regularized Markov decision processes.\narXiv:1705.07798, 2017.\nO’Donoghue, B., Munos, R., Kavukcuoglu, K., and Mnih,\nV. PGQ: Combining policy gradient and Q-learning.\nIn Proceedings of the 5th International Conference on\nLearning Representations, 2017.\nPeters, J., Müling, K., and Altun, Y. Relative entropy policy search. In Proceedings of the 24th Conference on\nArtificial Intelligence, pp. 1607–1612, 2010.\nPuterman, M. Markov Decision Processes. Wiley Interscience, 1994.\nSchulman, J., Levine, S., Moritz, P., Jordan, M., and\nAbbeel, P. Trust region policy optimization. In Proceedings of the 32nd International Conference on Machine\nLearning, pp. 1889–1897, 2015.\nSilver, David, Lever, Guy, Heess, Nicolas, Degris, Thomas,\nWierstra, Daan, and Riedmiller, Martin. Deterministic\npolicy gradient algorithms. In ICML, 2014.\nSutton, R. and Barto, A. An Introduction to Reinforcement\nLearning. MIT Press, 1998.\n\n\fPath Consistency Learning in Tsallis Entropy Regularized MDPs\n\nSutton, R., McAllester, D., Singh, S., and Mansour, Y.\nPolicy gradient methods for reinforcement learning with\nfunction approximation. In Proceedings of Advances in\nNeural Information Processing Systems 12, pp. 1057–\n1063, 2000.\nTodorov, E. Linearly-solvable Markov decision problems.\nIn Proceedings of the 19th Advances in Neural Information Processing, pp. 1369–1376, 2006.\nTodorov, E. Policy gradients in linearly-solvable MDPs. In\nProceedings of the 23rd Advances in Neural Information\nProcessing, pp. 2298–2306, 2010.\nTsallis, C. Possible generalization of Boltzmann-Gibbs\nstatistics. Journal of Statistical Physics, 52(1):479–487,\n1988.\nZiebart, B. Modeling Purposeful Adaptive Behavior with\nthe Principle of Maximum Causal Entropy. PhD thesis,\nCarnegie Mellon University, 2010.\n\n\fPath Consistency Learning in Tsallis Entropy Regularized MDPs\n\nA. Proofs of Section 5\nConsider the Bellman operator for the entropy-regularized MDP with Tsallis entropy:\n\u0010\u0002\nX\n\u0003 \u0011\n(Tsp f )(x) = α · spmax r(x, ·) + γ\nP (x0 |x, ·)f (x0 ) /α .\nx0\n\nWe first have the following technical result about its properties.\nProposition 1. The sparse-max Bellman operator Tsp has the following properties: (i) Translation: (Tsp (V + β))(x) =\n(Tsp V )(x) + γβ; (ii) γ-contraction: k(Tsp V1 ) − (Tsp V2 )k∞ ≤ γkV1 − V2 k∞ ; (iii) Monotonicity: (Tsp V1 )(x) ≤ (Tsp V2 )(x)\nfor any value functions V1 , V2 : X → R such that V1 (x) ≤ V2 (x), ∀x ∈ X .\nThe detailed proof of this proposition can be found in Lee et al. (2018). Using these results, the Banach fixed point theorem\nshows that there exists a unique solution for the following fixed point equation: V (x) = (Tsp V )(x), ∀x ∈ X , and this\nsolution is equal to the optimal value function Vsp∗ (x). Analogous to the arguments in standard MDPs, in this case the\noptimal value function can also be computed using dynamic programming methods such as value iteration.\nBefore proving the main results, notice that by using analogous arguments of the complementary-slackness property in\nKKT conditions, the second and the third consistency equation in (13) is equivalent to the following condition:\nX\nα\nr(x, a) + γ\nP (x0 |x, a)V (x0 ) + − αµ(a|x) − V (x) = Λ(x), ∀x ∈ X , ∀a ∈ Aµ (x),\n2\nx0 ∈X\n(16)\nX\nα\nr(x, a) + γ\nP (x0 |x, a)V (x0 ) + − αµ(a|x) − V (x) ≤ Λ(x), ∀x ∈ X , ∀a 6∈ Aµ (x),\n2\n0\nx ∈X\n\nwhere Aµ (x) = {a ∈ A : µ(a|x) > 0} represents the set of actions that have non-zero probabilities w.r.t policy µ.\nTheorem 3. The pair of optimal value function and optimal policy (Vsp∗ , µ∗sp ) of the MDP problem in (3) satisfies the\nconsistency equation in (13).\nProof. Recall that the optimal state-action value function is given by\nX\nQ∗sp (x, a) = r(x, a) + γ\nP (x0 |x, a)Vsp∗ (x0 ).\nx0 ∈X\n\nAccording to Bellman’s optimality, the optimal value function satisfies the following equality:\n\u0014\n\u0015\nX\nα\nVsp∗ (x) = max\nµ(a|x) Q∗sp (x, a) + (1 − µ(a|x)) ,\nµ∈∆x\n2\n\n(17)\n\na∈A\n\nat any state x ∈ X , where µ∗sp is the corresponding maximizer. By the KKT condition, we have that\nQ∗sp (x, a) +\n\nα\nα\n(1 − µ∗sp (a|x)) + λ∗sp (a|x) = Λ∗sp (x) + µ∗sp (a|x),\n2\n2\n\nfor any x ∈ X and any a ∈ A, where Λ∗sp is the Lagrange multiplier that corresponds to equality constraint\n1, and λ∗sp ≥ 0 is the Lagrange multiplier that corresponds to inequality constraint µ(a|x) ≥ 0 such that\n\nP\n\na∈A\n\nµ(a|x) =\n\nλ∗sp (a|x) · µ∗sp (a|x) = 0, ∀x ∈ X , ∀a ∈ A.\nRecall from the definition of optimal state-action value function Q∗sp and the definition of the optimal policy µ∗sp , one has\nthat Aµ∗sp (x) = S(Q∗sp (x, ·)). This condition further implies\nα\n(1 − 2µ∗sp (a|x)), ∀x ∈ X , a ∈ S(Q∗sp (x, ·)).\n2\nP\nSubstituting the equality in (17) to this KKT condition, and noticing that 0 ≤ a∈A µ∗sp (a|x))2 ≤ 1, the KKT condition\nimplies that\nα\nαX ∗\nΛ∗sp (x) + ≥ Vsp∗ (x) = Λ∗sp (x) +\nµsp (a|x)µ∗sp (a|x) ≥ Λ∗sp (x),\n2\n2\nΛ∗sp (x) = Q∗sp (x, a) +\n\na∈A\n\n\fPath Consistency Learning in Tsallis Entropy Regularized MDPs\n\nwhich further implies that\n\nα\n≤ Λ∗sp (x) − Vsp∗ (x) ≤ 0, ∀x ∈ X .\n2\nTherefore, by defining Λ(x) = Λ∗sp (x) − Vsp∗ (x), and λ(a|x) = λ∗sp (a|x), one immediately has that − α2 ≤ Λ(x) ≤ 0,\n∀x ∈ X . Using this construction, one further has the following expression for any x ∈ X and any a ∈ S(Q∗sp (x, ·)):\n−\n\nΛ(x) = Q∗sp (x, a) +\n\nα\n− αµ∗sp (a|x) − Vsp∗ (x),\n2\n\nwhich proves consistency, based on the equivalence condition in (16).\nTheorem 4. The solution policy µ of the consistency equation in (13) is α/(1 − γ)-optimal w.r.t. the sparse MDP problem\nin (3). That is,\n\n\nE\n\n∞\nX\n\n\u0014\n\u0015\n\u0001\nα\nα\nγ t Rt +\n.\n1 − µ(at |xt ) | x0 = x, µ, P  ≥ Vsp∗ (x) −\n2\n(1\n−\nγ)\nt=0\n\n(18)\n\nProof. To proof the sub-optimality performance bound given in this theorem, we first study the expression of (Tsp V ),\nwhere Tsp is the Bellman operator of the Tsallis entropy-regularized MDP problem in (3). Let\nX\nQ̄(x, a) = r(x, a) + γ\nP (x0 |x, a)V (x0 )\nx0 ∈X\n\nbe the corresponding state-action value function. Using the definition from (3), one has the following expression:\n\n\n\n\n\n\nX\n1\n\n(Tsp V )(x) = α · spmax  · r(x, a) + γ\nP (x0 |x, a)V (x0 )\n\n\nα \n0\nx ∈X\n\n= α · spmax\n\nQ̄(x, ·)\nα\n\na∈A\n\n!\n.\n\nFurthermore, by exploiting the structure of the sparse-max formulation of an arbitrary value function, one also has the\nfollowing chain of equalities/inequalities:\n!\n\u0012\n\u0013\nX\nα\nQ̄(x, ·)\nα · spmax\n= max\nµ(a|x) · Q̄(x, a) + (1 − µ(a|x))\nµ∈∆x\nα\n2\na∈A\n\u0012\n\u0013\nX\nα\n=\nµ(a|x) · Q̄(x, a) + (1 − µ(a|x))\n2\na∈A\n\u0012\n\u0013\nX\nα\nαX\n=\nµ(a|x) Q̄(x) + − αµ(a|x) +\nµ(a|x)2\n2\n2\na∈A\na∈A\nα\n≤V (x) + .\n2\nThe first equality follows from the fact that α · spmax(Q̄(x, ·)/α) is a closed form solution of the optimization problem\nX\n\u0001\nmax\nµ(a|x) Q̄(x, a) − αHµ (x, a) ,\nµ∈∆x\n\na∈A\n\nwhen Hµ is the Tsallis entropy. The second equality follows from the fact that if (V, µ) satisfies the consistency equation,\nthen there exists a Lagrange multiplier Λ∗ (x) = Λ(x) + V (x), ∀x ∈ X such that the following KKT conditions hold:\nα\n− αµ(a|x) = Λ∗ (x), ∀x ∈ X , ∀a ∈ Aµ (x),\n2\nα\nQ̄(x, a) + − αµ(a|x) ≤ Λ∗ (x), ∀x ∈ X , ∀a 6∈ Aµ (x),\n2\nX\nµ(a|x) = 1, µ(a|x) ≥ 0, ∀x ∈ X , ∀a ∈ A,\n\nQ̄(x, a) +\n\na\n\n\fPath Consistency Learning in Tsallis Entropy Regularized MDPs\n\nwhich further implies that µ is the maximizer of the inner optimization problem. The third equality follows from arithmetic\nmanipulations, and the first inequality follows from the consistency equation in (16), i.e., for any x ∈ X and any a ∈\nAµ (x), there exists Λ(x) ∈ [− α2 , 0] such that:\nα\nα\n0 ≥ Λ(x) = Q̄(x, a) + − αµ(a|x) − V (x) ⇐⇒ Q̄(x, a) + − αµ(a|x) ≤ V (x).\n2\n2\nTherefore combining all these arguments, one concludes that the following Bellman inequality holds:\nα\n(Tsp V )(x) ≤ V (x) + , ∀x ∈ X .\n(19)\n2\nNow recall that the γ−contraction property (w.r.t. the ∞−norm) of the Bellman operator Tsp . By the Banach fixedpoint theorem, this property implies that there exists a unique fixed point solution Vsp∗ to equation V (x) = (Tsp V )(x),\nfor all x ∈ X , and it is the limit point (over all x ∈ X ) of the converging iterative sequence limn→∞ (Tspn V0 )(x) for\nany initial value function V0 . Also recall that the translation property of this Bellman operator, i.e., for any constant K,\n(Tsp (V + K)) = (Tsp V ) + γK. Therefore, by repeatedly applying the Bellman operator to both sides of the inequality in\n(19), and by using the above properties of a Bellman operator, one can show that\nVsp∗ (x) = lim (Tspn V )(x) ≤\nn→∞\n\n∞\nX\n\n−γ t ·\n\nn=0\n\nα\n1\nα\n+ V (x) = − ·\n+ V (x), ∀x ∈ X .\n2\n2 1−γ\n\n(20)\n\nFurthermore, consider the consistency equation in (13), i.e., there exists a function Λ(x) ∈ [0, α2 ] such that for any x ∈ X\nand any a ∈ Aµ (x),\nα\nα\n− ≤ Λ(x) = Q̄(x, a) + − αµ(a|x) − V (x) ⇐⇒ V (x) ≤ Q̄(x, a) + α − αµ(a|x).\n2\n2\nBy multiplying µ(a|x) on both sides of this inequality and summing over a ∈ A, the above expression implies\nX\n\u0001\nV (x) ≤\nµ(a|x) Q̄(x, a) + α − αµ(a|x)\na∈A\n\n\u0013\n\u0001\n\u0001\nαX\nα\n1 − µ(a|x) +\n≤\nµ(a|x) Q̄(x, a) +\nµ(a|x) 1 − µ(a|x)\n2\n2\na∈A\na∈A\n\n\nX\nX\n\u0001\nα\nα\n1 − µ(a|x)  + .\n=\nµ(a|x) r(x, a) + γ\nP (x0 |x, a)V (x0 ) +\n2\n2\n0\n\u0012\n\nX\n\n(21)\n\nx ∈X\n\na∈A\n\nTherefore, equipped with the γ−contraction property of the following Bellmen operator:\n\n\nX\nX\n\u0001\nα\n(Tµ V )(x) =\nµ(a|x) r(x, a) +\n1 − µ(a|x) + γ\nP (x0 |x, a)V (x0 )\n2\n0\nx ∈X\n\na∈A\n\nand the Banach fixed-point theorem, for any initial value function V0 , one can deduce the following expression:\n\n\n\u0015\n\u0014\n∞\nX\n\u0001\nα\n1 − µ(at |xt ) | µ, x0 = x .\nlim Tµ [V0 ]n (x) = E \nγ t r(xt , at ) +\nn→∞\n2\nt=0\nUsing the translation property of the Bellman operator (Tµ V ) and repeatedly applying this Bellman operator to both sides\nof (21), one obtains the following inequality for any x ∈ X :\nV (x) ≤ lim (Tµ V )n (x) +\nn→∞\n\n∞\nX\nα t\nγ\n2\nn=0\n\n\n\n\u0014\n\u0015\n∞\nX\n\u0001\nα\nα\n1\n=E \nγ t r(xt , at ) +\n1 − µ(at |xt ) | µ, x0 = x + ·\n.\n2\n2\n1\n−\nγ\nt=0\nTherefore, by combining the results in (20) and in (22), one completes the proof of this theorem.\n\n(22)\n\n\fPath Consistency Learning in Tsallis Entropy Regularized MDPs\n\nAlgorithm 1 Sparse Path Consistency Learning\nInput: Environment EN V , learning rate η, discount factor γ, regularization α, rollout d, number of steps N , replay\nbuffer capacity B, prioritized replay hyper-parameter α. Parameterizations of Λ and λ follow from the descriptions in\nSection 6.\nfunction Gradients(x0:T , R0:T −1 , a0:T −1 )\nPd−1\nCompute C(t) = −V̄φ (xt ) + γ d V̄φ (xt+d ) + j=0 γ j (Rj + α/2 − αµ̄θ (aj |xj ) + λθ (aj |xj ) − Λρ (xj )) for t < T ,\npadding with zeros\nPTas−1necessary.\nCompute ∆θ = t=0 C(t)∇θ C(t).\nPT −1\nCompute ∆φ = t=0 C(t)∇φ C(t).\nPT −1\nCompute ∆ρ = t=0 C(t)∇ρ C(t).\nReturn ∆θ, ∆φ, ∆ρ\nend function\nInitialize θ, φ, ρ.\nInitialize empty replay buffer RB(α).\nfor i = 0 to N − 1 do\nSample x0:T , a0:T −1 ∼ µ̄θ on EN V , yielding reward R0:T −1 .\n∆θ, ∆φ, ∆ρ = Gradients(x0:T , a0:T −1 , R0:T −1 ).\nUpdate θ ← θ − η∆θ.\nUpdate φ ← φ − η∆φ.\nUpdate ρ ← ρ − η∆ρ.\nPT −d\nInput x0:T , a0:T −1 into RB with priority j=0 Rj .\nIf |RB| > B, remove episodes uniformly at random.\nSample s0:T from RB.\n∆θ, ∆φ, ∆ρ = Gradients(x0:T , a0:T −1 , R0:T −1 ).\nUpdate θ ← θ − η∆θ.\nUpdate φ ← φ − η∆φ.\nUpdate ρ ← ρ − η∆ρ.\nend for\n\nB. Experimental Details\nFor the algorithmic tasks, we follow a similar experimental setup as described in Nachum et al. (2017). We parameterize\nall values by a single LSTM recurrent neural network with internal dimension 128 and multiple heads (one for each desired\nquantity). At each training step, we sample a batch of 400 episodes using the current policy acting on the environment.\nWe perform a gradient step based on this batch. We then add the experience to the replay buffer and perform a gradient\nstep based on an off-policy batch sampled from the replay buffer. We fix the rollout to d = 10. As in Nachum et al.\n(2017), our replay buffer is prioritized by episode rewards: the probability of sampling an episode from the replay buffer\nis 0.1 + 0.9 · exp{αR}/Z where R is the total reward of the episode, Z is a normalizing factor, and we use α = 0.5. We\nuse a replay buffer of capacity B = 10, 000 episodes. In our experiments we use a learning rate of η = 0.005 and discount\nγ = 0.9.\nFor HalfCheetah we parameterized the policy and value networks as feed forward networks with two hidden layers of\ndimension 64 and tanh non-linearities. At each training step we sampled 100 steps from the environment and input\nthese into a replay buffer. We then sample a batch of 25 sub-episodes of 100 steps from the replay buffer, prioritized by\nexponentiated recency (with weight 0.01) and perform a single training step. We use rollout d = 10, discount γ = 0.99,\nand performed a hyperparameter search over learning rate η ∈ {0.0005, 0.0001}.\nIn standard Soft PCL, the policy µ̄θ is determined by logits output by the neural network. That is,\n\u0010\n\u0011\nµ̄θ (−|x) = softmax NN(x, θ)0:|A|−1 ,\n\n(23)\n\nwhere NN(x, θ)0:|A|−1 are |A| output values of the neural network. For Sparse PCL, to induce sparsity, we parameterize\nthe policy using the G function:\n\u0010\n\u0011\nµ̄θ (−|x) = relu NN(x, θ)0:|A|−1 − G(NN(x, θ)0:|A|−1 ) .\n(24)\n\n\fPath Consistency Learning in Tsallis Entropy Regularized MDPs\n\nAccordingly, λθ is parameterized as\n\u0010\n\u0011\nλθ (−|x) = relu G(NN(x, θ)0:|A|−1 − NN(x, θ)0:|A|−1 ) exp{NN(x, θ)|A| }.\n\n(25)\n\nB.1. Experimental Results for ReversedAddition\n\nReversedAddition\n\n|A| = 40\n\n|A| = 64\n\n30\n\n30\n\n25\n\n25\n\n20\n\n20\n\n15\n\n15\n\n10\n\n10\n\n5\n\n5\n\n0\n\n0\n0\n\n20000 40000 60000 80000 100000\n\n|A| = 96\n15\n\n10\n\n5\n\n0\n0\n\n20000 40000 60000 80000 100000\n\nSoft PCL\n\n0\n\n20000 40000 60000 80000 100000\n\nSparse PCL\n\nFigure 3. The average reward over training for sparse PCL compared to the standard soft PCL on ReversedAddition. In this task, the\nenvironment is a 2 × n grid of digits representing two numbers in base-|V| that the agent needs to sum. As in the other tasks in the main\npaper, we see that sparse PCL becomes more advantageous compared to soft PCL as the action space increases in size.\n\n\f",
         "train",
         "55892",
         "10226"
        ],
        [
         "39",
         "20033",
         "cs.AI",
         "Artificial Intelligence",
         "1802.07782v1.pdf",
         "Artificial Intelligence and Legal Liability\nJ.K.C. Kingston 1\n\nAbstract A recent issue of a popular computing journal asked which laws\nwould apply if a self-driving car killed a pedestrian. This paper considers the\nquestion of legal liability for artificially intelligent computer systems. It discusses\nwhether criminal liability could ever apply; to whom it might apply; and, under\ncivil law, whether an AI program is a product that is subject to product design\nlegislation or a service to which the tort of negligence applies. The issue of sales\nwarranties is also considered.\nA discussion of some of the practical limitations that AI systems are subject to\nis also included.\n\n1 Introduction\nA recent issue of a popular computing journal [1] posed the following question:\n“It is the year 2023, and for the first time, a self-driving car navigating city\nstreets strikes and kills a pedestrian. A lawsuit is sure to follow. But exactly which\nlaws will apply? No-one knows.”\nThe article goes on to suggest that the laws that are likely to apply are those\nthat deal with products with a faulty design. However, it argues that following this\nlegal route holds back the development of self-driving cars, as settlements for\nproduct design cases (in the USA) are typically almost ten times higher than for\ncases involving human negligence, and that does not include the extra costs\nassociated with product recalls to fix the issue. It goes on to argue that such cases\nshould instead be dealt with as cases of negligence, just as they would for a human\ndriver; the author points out that a standard handbook of US tort law [2] states that\n“A bad state of mind is neither necessary nor sufficient to show negligence;\nconduct is everything.”\nIt may be that the issue will arise even sooner than the year 2023. The author of\nthis paper recently hired a car that included several new safety features. One of\nthese features was that, if the car’s radars detected an imminent collision while the\ncar was travelling at between 4 and 19 mph, the car’s engine would cut out to help\nprevent the collision.\n\n1 University of Brighton, BN2 4JG, UK\nj.k.kingston@brighton.ac.uk\n\n\fJ.K.C. Kingston\n\nWhile reversing the car out of a driveway, the author drove too close to a\nhedge. The car sounded its proximity alarm, and cut the engine. However, even\nwhen the steering wheel was turned so that the car would miss the hedge, the\nengine would not restart while the car was in reverse gear. The author had to put\nthe car into a forward gear and travel forward slightly before he was able to\ncontinue reversing out.\nAll of this took place wholly within the driveway. However, if it had taken\nplace while the rear end of the car was projecting into the road, with a heavy lorry\ntravelling at some speed towards the car, most drivers would prefer to risk getting\ntheir paintwork scratched by a hedge than sitting in a car that refused to restart and\ncomplete the desired manoeuvre. It seems inevitable that soon, some driver will\nblame these ‘safety features’ for their involvement in a serious accident.\nThe purpose of this paper is to consider the current capabilities, or lack of\nthem, of artificial intelligence, and then to re-visit the question of where legal\nliability might lie in the above cases.\nFirst, it is important to establish what this paper means by the term “artificial\nintelligence”. There are researchers in the AI field who consider anything that\nmimics human intelligence, by whatever method, to be “artificial intelligence”;\nthere are others who think that the only “artificially intelligent” programs are those\nthat mimic the way in which humans think. There are also those in the field of\ninformation systems who would classify many “artificially intelligent” programs\nas being complex information systems, with ‘true’ artificial intelligence being\nreserved for the meta-level decision making that is sometimes characterised as\n‘wisdom’.\nIn this paper, any computer system that is able to recognise a situation or event,\nand to take a decision of the form “IF this situation exists THEN recommend or\ntake this action” is taken to be an artificially intelligent system.\n\n2 Legal Liability\n\n2.1 Criminal Liability\nThe references cited below refer primarily to US law; however, many other\njurisdictions have similar legislation in the relevant areas.\nIn [3], Gabriel Hallevy discusses how, and whether, artificial intelligent entities\nmight be held criminally liable. Criminal laws normally require both an actus reus\n(an action) and a mens rea (a mental intent), and Hallevy helpfully classifies laws\nas follows:\n\n\f1. Those where the actus reus consists of an action, and those where the\nactus reus consists of a failure to act;\n2. Those where the mens rea requires knowledge or being informed; those\nwhere the mens rea requires only negligence (“a reasonable person would\nhave known”); and strict liability offences, for which no mens rea needs\nto be demonstrated.\nHallevy goes on to propose three legal models by which offences committed by\nAI systems might be considered:\n1. Perpetrator-via-another. If an offence is committed by a mentally\ndeficient person, a child or an animal, then the perpetrator is held to be an\ninnocent agent because they lack the mental capacity to form a mens rea\n(this is true even for strict liability offences). However, if the innocent\nagent was instructed by another person (for example, if the owner of a\ndog instructed his dog to attack somebody), then the instructor is held\ncriminally liable (see [4] for US case law).\nAccording to this model, AI programs could be held to be an innocent\nagent, with either the software programmer or the user being held to be\nthe perpetrator-via-another.\n2. Natural-probable-consequence. In this model, part of the AI program\nwhich was intended for good purposes is activated inappropriately and\nperforms a criminal action. Hallevy gives an example (quoted from [5])\nin which a Japanese employee of a motorcycle factory was killed by an\nartificially intelligent robot working near him. The robot erroneously\nidentified the employee as a threat to its mission, and calculated that the\nmost efficient way to eliminate this threat was by pushing him into an\nadjacent operating machine. Using its very powerful hydraulic arm, the\nrobot smashed the surprised worker into the machine, killing him\ninstantly, and then resumed its duties.\nThe normal legal use of “natural or probable consequence” liability is to\nprosecute accomplices to a crime. If no conspiracy can be demonstrated,\nit is still possible (in US law) to find an accomplice legally liable if the\ncriminal acts of the perpetrator were a natural or probable consequence\n(the phrase originated in [6]) of a scheme that the accomplice encouraged\nor aided [7], as long as the accomplice was aware that some criminal\nscheme was under way.\n\n\fJ.K.C. Kingston\n\nSo users or (more probably) programmers might be held legally liable if\nthey knew that a criminal offence was a natural, probable consequence of\ntheir programs/use of an application. The application of this principle\nmust, however, distinguish between AI programs that ‘know’ that a\ncriminal scheme is under way (i.e. they have been programmed to\nperform a criminal scheme) and those that do not (they were programmed\nfor another purpose). It may well be that crimes where the mens rea\nrequires knowledge cannot be prosecuted for the latter group of programs\n(but those with a ‘reasonable person’ mens rea, or strict liability offences,\ncan).\n3. Direct liability. This model attributes both actus reus and mens rea to an\nAI system.\nIt is relatively simple to attribute an actus reus to an AI system. If a\nsystem takes an action that results in a criminal act, or fails to take an\naction when there is a duty to act, then the actus reus of an offence has\noccurred.\nAssigning a mens rea is much harder, and so it is here that the three\nlevels of mens rea become important. For strict liability offences, where\nno intent to commit an offence is required, it may indeed be possible to\nhold AI programs criminally liable. Considering the example of selfdriving cars, speeding is a strict liability offence; so according to\nHallevy, if a self-driving car was found to be breaking the speed limit for\nthe road it is on, the law may well assign criminal liability to the AI\nprogram that was driving the car at that time.\nThis possibility raises a number of other issues that Hallevy touches on,\nincluding defences (could a program that is malfunctioning claim a\ndefence similar to the human defence of insanity? Or if it is affected by\nan electronic virus, could it claim defences similar to coercion or\nintoxication?); and punishment (who or what would be punished for an\noffence for which an AI system was directly liable?).\n\n\f2.2 The Trojan defence\nIn the context of defences against liability for AI systems, it is\nimportant to mention a number of cases where a defendant accused of\ncybercrime offences has successfully offered the defence that his\ncomputer had been taken over by a Trojan or similar malware program,\nwhich was committing offences using the defendant’s computer but\nwithout the defendant’s knowledge. A review of such cases can be found\nin [8]; they include a case in the United Kingdom when a computer\ncontaining indecent pictures of children was also found to have eleven\nTrojan programs on it, and another UK case where a teenage computer\nhacker’s defence to a charge of executing a denial of service attack was\nthat the attack had been performed from the defendant’s computer by a\nTrojan program, which had subsequently wiped itself from the computer\nbefore it was forensically analysed. The defendant’s lawyer successfully\nconvinced the jury that such a scenario was not beyond reasonable doubt.\n\n2.3 Civil Law: Torts and Breach of Warranty\n\n2.3.1 Negligence\nWhen software is defective, or when a party is injured as a result of using\nsoftware, the resulting legal proceedings normally allege the tort of negligence\nrather than criminal liability [9]. Gerstner [10] discusses the three elements that\nmust normally be demonstrated for a negligence claim to prevail:\n1. The defendant had a duty of care;\n2. The defendant breached that duty;\n3. That breach caused an injury to the plaintiff.\nRegarding point 1, Gerstner suggests there is little question that a software\nvendor owes a duty of care to the customer, but it is difficult to decide what\nstandard of care is owed. If the system involved is an “expert system”, then\nGerstner suggests that the appropriate standard of care is that of an expert, or at\nleast of a professional.\nOn point 2, Gerstner suggests numerous ways in which an AI system could\nbreach the duty of care: errors in the program’s function that could have been\ndetected by the developer; an incorrect or inadequate knowledge base; incorrect or\ninadequate documentation or warnings; not keeping the knowledge up to date; the\n\n\fJ.K.C. Kingston\n\nuser supplying faulty input; the user relying unduly on the output; or using the\nprogram for an incorrect purpose.\nAs for point 3, the question of whether an AI system can be deemed to have\ncaused an injury is also open to debate. The key question is perhaps whether the\nAI system recommends an action in a given situation (as many expert systems do),\nor takes an action (as self-driving and safety-equipped cars do). In the former case,\nthere must be at least one other agent involved, and so causation is hard to prove;\nin the latter case, it is much easier.\nGerstner also discussed an exception under US law for “strict liability\nnegligence.” This applies to products that are defective or unreasonably dangerous\nwhen used in a normal, intended or reasonably foreseeable manner, and which\ncause injury (as opposed to economic loss). She discusses whether software is\nindeed a ‘product’ or merely a ‘service’; she quotes a case in which electricity was\nheld to be a product [11], and therefore leans towards defining software as a\nproduct rather than a service. Assuming that software is indeed a product, it\nbecomes incumbent on the developers of AI systems to ensure that their systems\nare free from design defects; manufacturing defects; or inadequate warning or\ninstructions.\nCole [12] provides a longer discussion of the question of whether software is a\nproduct or a service. His conclusion is that treating AI systems as products is\n“partially applicable at best”, and prefers to view AI as a service rather than a\nproduct; but he acknowledges that law in the area is ill-defined.\nCole cites some case law regarding the “duty of care” that AI systems must\nabide by:\n1. In [14], a school district brought a negligence claim against a statistical\nbureau that (allegedly) provided inaccurate calculations of the value of a\nschool that had burned down, causing the school district to suffer an\nunderinsured loss. The duty being considered was the duty to provide\ninformation with reasonable care. The court considered factors\nincluding: the existence, if any, of a guarantee of correctness; the\ndefendant's knowledge that the plaintiff would rely on the information;\nthe restriction of potential liability to a small group; the absence of proof\nof any correction once discovered; the undesirability of requiring an\ninnocent party to carry the burden of another's professional mistakes;\nand, the promotion of cautionary techniques among the informational\n(tool) providers.\n2. Based on [15], Cole discusses the duty to provide reasonable conclusions\nfrom unreasonable inputs. He follows [16] to suggest that AI developers\nprobably have an affirmative duty to provide relatively inexpensive,\nharmless, and simple, input error-checking techniques, but notes that\nthese rules may not apply where the AI program is performing a function\n\n\fin which mistakes in input may be directly life-threatening (e.g.\nadministering medicine to a patient); in such cases, he suggests applying\nthe rules relating to “ultra-hazardous activities and instrumentalities”\ninstead [17].\n3. Cole suggests that AI systems must be aware of their limitations, and this\ninformation must be communicated to the purchaser. It is well\nestablished that vendors have a duty to tell purchasers of any known\nflaws; but how can unknown weaknesses or flaws be established, and\nthen communicated?\n\n2.3.2 Breach of Warranty\nIf an AI system is indeed a product, then it must be sold with a warranty; even\nif there is no express warranty given by the vendor (or purchased by the user),\nthere is an implied warranty that it is (to use the phrase from the UK Sale of\nGoods Act 1979), “satisfactory as described & fit for a reasonable time.” Some\njurisdictions permit implied warranties to be voided by clauses in the contract;\nhowever, when an AI system is purchased built into other goods (such as a car), it\nseems unlikely that any such contractual exclusions (e.g. between the\nmanufacturer of the car and the supplier of the AI software) could successfully be\npassed on to the purchaser of the car.\n\n2.3 Legal liability: Summary\nSo it seems that the question of whether AI systems can be held legally liable\ndepends on at least three factors:\n• The limitations of AI systems, and whether these are known and\ncommunicated to the purchaser;\n• Whether an AI system is a product or a service;\n• Whether the offence requires a mens rea or is a strict liability offence.\nIf an AI system is held liable, the question arises of whether it should be held\nliable as an innocent agent, an accomplice, or a perpetrator.\nThe final section of this paper consider the first of these three factors.\n\n\fJ.K.C. Kingston\n\n3 Limitations of AI systems\nThe various limitations that AI systems are subject to can be divided into two\ncategories:\n• Limitations that human experts with the same knowledge are also subject\nto;\n• Limitations of artificial intelligence technology compared with humans.\n\n3.1 Limitations that affect both AI systems and human experts\nThe limitations that affect both AI systems and human experts are connected\nwith the knowledge that is specific to the problem.\nFirstly, the knowledge may change very rapidly. This requires humans and AI\nsystems both to know what the latest knowledge is, and also to identify which\nparts of their previous knowledge is out of date. Whether this is an issue depends\nalmost entirely on the domain: in our example of automated car driving, the\nknowledge that is required to drive a car changes very slowly indeed. However, in\nthe world of cyber security, knowledge of exploits and patches changes on a daily\nbasis.\nSecondly, the knowledge may be too vast for all possibilities to be considered.\nAI systems can actually perform better than human experts at such tasks – it is\nfeasible to search thousands, or even hundreds of thousands of solutions – but\nthere are still some tasks where the scope is even wider than that. This is typically\nthe case in planning and design tasks, where the number of possible plans or\ndesigns may be close to infinite. (In contrast, scheduling and configuration, which\nrequire planning and design within a fixed framework, are less complex, though\nthe possible options may still run into thousands). In such cases, AI systems can\npromise to give a good answer in most cases, but cannot guarantee that they will\ngive the best answer in all cases.\nFrom a legal standpoint, it could be argued that the solution to such issues is for\nthe vendor to warn the purchaser of an AI system of these limitations. In fastchanging domains, it may also be considered legally unreasonable if the vendor\ndoes not provide a method for frequently updating the system’s knowledge. This\nraises the question of where the boundaries of ‘fast-changing’ lie. As ever, the\nlegal test is reasonableness, which is usually compared against the expected life of\nan AI system; so if knowledge was expected to change annually (e.g. in an AI\nsystem for calculating personal tax liability), then it would probably be judged\nreasonable for a vendor to warn that the knowledge was subject to change.\nHowever, it would probably not be judged ‘reasonable’ for the vendor to provide\nautomatic updates to the knowledge, because the complexity of tax law is such\n\n\fthat any updates would not merely require downloading files of data and\ninformation; they would require a newly developed and newly tested system.\nIn contrast, AI systems that help local councils calculate household benefits\nmay have been built on the (apparently unshakeable) assumption that marriage\nwas between a man and a woman. That knowledge has now changed, however, to\npermit marriage between any two human adults. Is it reasonable to require a\nvendor to warn a purchaser that those laws could change too? Such changes seem\nhighly unlikely at present; but in the USA, there have already been attempts by a\nwoman to marry her dog and by a man to marry his laptop, and there has been\nlong-running lobbying from certain religious groups to legalise polygamy.\nThe US case of Kociemba v Searle [18] found a pharmaceutical manufacturer\nliable for failing to warn purchasers that use of a particular drug was associated\nwith a pelvic inflammatory disease, even though the product had been passed as\n“safe and effective” by the Food and Drug Administration. It seems, therefore,\nthat the boundary of where a warning might reasonably be required is indeed\ndependent on knowledge rather than on regulatory approval.\nMykytyn et al [19] discuss issues of legal liability for AI systems that are\nlinked to identification and selection of human experts. They quote two cases\n([20] and [21]) where hospitals were found liable for failing to select physicians\nwith sufficient competence to provide the medical care that they were asked to\nprovide; by analogy, AI developers could also be held liable unless they select\nexperts with sufficient competence in the chosen domain, or warn users that the\nexpert’s competence does not extend to other domains where the system might\nconceivably be used.\nThe solution proposed by Mykytyn et al. is to use licensed and certified\nexperts. They point out that the standards required by licensing bodies are\nsometimes used to determine if a professional’s performance is up to the level\nexpected [22]. They even suggest that it may be desirable to get the AI system\nitself licensed. The US Securities and Exchange Commission has been particularly\nkeen on this; it required a stock market recommender system to be registered as a\nfinancial adviser [23] and also classified developers of investment advice\nprograms as investment advisors [24].\n\n3.2 Limitations of AI systems that do not affect human experts\nThe key limitation is that AI systems lack general knowledge. Humans carry a\ngreat deal of knowledge that is not immediately relevant to a specific task, but that\ncould become relevant. For example, when driving a car, it is advisable to drive\nslowly when passing a school, especially if there is a line of parked cars outside it,\nor you know that the school day finishes at about the time when you are driving\npast. The reason is to avoid the risk of children dashing out from behind parked\n\n\fJ.K.C. Kingston\n\ncars, because a human driver’s general knowledge includes the fact that some\nchildren have poor road safety skills. An automated car would not know to do this\nunless it was programmed with a specific rule, or a set of general rules about\nunusually hazardous locations.\nAdmittedly, there are occasions when humans fail to apply their general\nknowledge to recognise a hazardous situation: as one commentator once said,\n“What is the difference between a belt-driven vacuum cleaner and a Van de Graaff\ngenerator? Very little. Never clean your laptop with that type of vacuum cleaner.”\nHowever, without general knowledge, AI systems have no chance of recognising\nsuch situations.\nA related issue is that AI systems are notoriously poor at degrading gracefully.\nThis can be seen when considering edge cases (cases where one variable in the\ncase takes an extreme value) or corner cases (multiple variables take extreme\nvalues). When human beings are faced with a situation that they previously\nbelieved to be very unlikely or impossible, they can usually choose a course of\naction that has some positive effect on the situation. When AI systems face a\nsituation that they are not programmed for, they generally cannot perform at all.\nFor example, in the car driving example given at the start of this paper, the\n(hypothetical) situation where the car refuses to start while a lorry is bearing down\non it is an edge case. Furthermore, the car’s safety system does not seem to have\nbeen designed with city drivers in mind; the car warns drivers to see that their\nroute is safe before making a manoeuvre, but it does not take account of the fact\nthat in a city, a route may only be safe for a short period of time, thus making this\ntype of ‘edge’ case more common than expected.\nAs for a corner case, September 26 1983 was the day when a Soviet earlywarning satellite indicated first one, then two, then eventually that five US nuclear\nmissiles had been launched. The USSR’s standard policy at the time was to\nretaliate with its own missiles, and it was a time of high political tension between\nthe USA and USSR. The officer in charge had a matter of minutes to decide what\nto do, and no further information; he chose to consider the message as a false\nalarm, reasoning that “when people start a war, they don’t start it with only five\nmissiles.”\nIt was later discovered that the satellite had mistaken the reflection of sun from\nclouds as the heat signature of missile launches. The orbit of the satellite was\ndesigned to avoid such errors, but on that day (near the Equinox) the location of\nthe satellite, the position of the sun and the location of US missile fields all\ncombined to give five false readings.\nIf an AI system had been in charge of the Soviet missile launch controls that\nday, it may well have failed to identify any problem with the satellite, and\nlaunched the missiles. It would then have been legally liable for the destruction\nthat followed, although it is unclear whether there would have been any lawyers\nleft to prosecute the case.\nA third issue is that AI systems may lack the information that humans use\nbecause of poorer quality inputs. This is certainly the case with the car safety\n\n\fsystem; its only input devices are relatively short range radar detectors, which\ncannot distinguish between a hedge and a lorry, nor can detect an object that is\nsome distance away but is rapidly approaching. It may be that, should a case come\nto court regarding an accident ‘caused’ by these safety systems, the focus will be\non how well the AI was programmed to deal with these imprecise inputs.\nThere is also the issue of non-symbolic information. In the world of knowledge\nmanagement, it is common to read assertions that human knowledge can never be\nfully encapsulated in computer systems because it is too intuitive [25]. Kingston\n[26] argues that this view is largely incorrect because it is based on a poor\nunderstanding of the various types of tacit knowledge; but he does allow that nonsymbolic information (information based on numbers; shapes; perceptions such as\ntextures; or physiological information e.g. the muscle movements of a ballet\ndancer), and the skills or knowledge generated from such information, are beyond\nthe scope of nearly all AI systems.\nIn some domains, this non-symbolic information is crucial: physicians\ninterviewing patients, for example, draw a lot of information from a patient’s body\nlanguage as well as from the patient’s words. Some of the criticisms aimed at the\nUK’s current telephone-based diagnostic service, NHS Direct, can be traced back\nto the medical professional lacking this type of information. In the car-driving\nexample, non-symbolic information might include headlights being flashed by\nother drivers to communicate messages from one car to another; such information\nis not crucial but it is important to being a driver who respects others.\n\n4 Conclusion\nIt has been established that the legal liability of AI systems depends on at least\nthree factors:\n1. Whether AI is a product or a service. This is ill-defined in law; different\ncommentators offer different views.\n2. If a criminal offence is being considered, what mens rea is required. It\nseems unlikely that AI programs will contravene laws that require\nknowledge that a criminal act was being committed; but it is very\npossible they might contravene laws for which ‘a reasonable man would\nhave known’ that a course of action could lead to an offence, and it is\nalmost certain that they could contravene strict liability offences.\n3. Whether the limitations of AI systems are communicated to a purchaser.\nSince AI systems have both general and specific limitations, legal cases\non such issues may well be based on the specific wording of any\nwarnings about such limitations.\n\n\fJ.K.C. Kingston\n\nThere is also the question of who should be held liable. It will depend on which of\nHallevy’s three models apply (perpetrator-by-another; natural-probableconsequence; or direct liability):\n•\n\nIn a perpetrator-by-another offence, the person who instructs the AI\nsystem – either the user or the programmer – is likely to be found liable.\n• In a natural-or-probable-consequence offence, liability could fall on\nanyone who might have foreseen the product being used in the way it\nwas; the programmer, the vendor (of a product), or the service provider.\nThe user is less likely to be blamed unless the instructions that came with\nthe product/service spell out the limitations of the system and the\npossible consequences of misuse in unusual detail.\n• AI programs may also be held liable for strict liability offences, in which\ncase the programmer is likely to be found at fault.\nHowever, in all cases where the programmer is deemed liable, there may be\nfurther debates whether the fault lies with the programmer; the program designer;\nthe expert who provided the knowledge; or the manager who appointed the\ninadequate expert, program designer or programmer.\n\nReferences\n1. Greenblatt N.A.: Self-Driving Cars and the Law. IEEE Spectrum, p.42 (16 February 2016).\n2. Dobbs D.B.: Law of Torts. West Academic Publishing (2008).\n3. Hallevy G.: The Criminal Liability of Artificial Intelligence entities. http://ssrn.com/\nabstract=1564096 (15 February 2010).\n4. Morrisey v. State, 620 A.2d 207 (Del.1993); Conyers v. State, 367 Md. 571, 790 A.2d 15\n(2002); State v. Fuller, 346 S.C. 477, 552 S.E.2d 282 (2001); Gallimore v. Commonwealth,\n246 Va. 441, 436 S.E.2d 421 (1993).\n5. Weng Y-H, Chen C-H and Sun C-T: Towards the Human-Robot Co-Existence Society: On\nSafety Intelligence for Next Generation Robots, 1 Int.J.Soc.Robot. 267, 273 (2009).\n6. United States v. Powell, 929 F.2d 724 (D.C.Cir.1991).\n7. Francis Bowes Sayre: Criminal Responsibility for the Acts of Another, 43 Harv. L. Rev. 689\n(1930).\n8. Brenner S.W., Carrier B., Henninger J.: The Trojan Horse Defense in Cybercrime Cases, 21\nSanta Clara High Tech. L.J. 1 http://digitalcommons.law.scu.edu/chtlj/vol21/iss1/1 (2004).\n9. Tuthill G.S.: Legal Liabilities and Expert Systems, AI Expert (Mar. 1991).\n10. Gerstner M.E.: Comment, Liability Issues with Artificial Intelligence Software, 33 Santa\nClara L. Rev. 239. http://digitalcommons.law.scu.edu/lawreview/vol33/iss1/7 (1993).\n11. Ransome v. Wisconsin Elec. Power Co., 275 N.W.2d 641, 647-48. Wis. (1979).\n12. Cole G.S.: Tort Liability for Artificial Intelligence and Expert Systems, 10 Computer L.J.\n127 (1990).\n13. Restatement (Second) of Torts: Section 552: Information Negligently Supplied for the\nGuidance of Others. (1977).\n14. Independent School District No. 454 v. Statistical Tabulating Corp 359 F. Supp. 1095. N.D.\nIll. (1973).\n15. Stanley v. Schiavi Mobile Homes Inc., 462 A.2d 1144. Me. (1983).\n\n\f16. Helling v. Carey 83 Wash. 2d 514, 519 P.2d 981 (1974).\n17. Restatement (Second) of Torts: Sections 520-524. op.cit.\n18. Kociemba v. GD Searle & Co., 683 F. Supp. 1579. D. Minn. (1988).\n19. Mykytyn K., Mykytyn P.P., Lunce S.: Expert identification and selection: Legal liability\nconcerns and directions. AI & Society, 7, 3, pp. 225-237 (1993)\n20. Joiner v Mitchell County Hospital Authority, 186 S.E.2d 307. Ga.Ct.App. (1971).\n21. Glavin v Rhode Island Hospital, 12 R. I. 411, 435, 34 Amer. Rep. 675, 681 (1879).\n22. Bloombecker R.: Malpractice in IS? Datamation, 35, pp. 85-86 (1989).\n23. Warner E.: Expert Systems and the Law. In Boynton and Zmud (eds) Management\nInformation Systems, Scott Foresman/Little Brown Higher Education, Glenview Il, pp. 144-149\n(1990).\n24. Hagendorf W.: Bulls and Bears and Bugs: Computer Investment Advisory programs That Go\nAwry. Computer Law Journal, X, pp. 47-69 (1990).\n25. Jarche, H.: Sharing Tacit Knowledge. http://www.jarche.com/2o1o/o1/sharing-tacitknowledge/ (2010). Accessed April 2012.\n26. Kingston J.: Tacit Knowledge: Capture, Sharing, And Unwritten Assumptions. Journal of\nKnowledge Management Practice, Vol. 13, No. 3. (September 2012).\n\n\f",
         "train",
         "31064",
         "5115"
        ],
        [
         "40",
         "19627",
         "cs.AI",
         "Artificial Intelligence",
         "1711.07477v1.pdf",
         "M A M A D ROID: Detecting Android Malware by Building Markov\nChains of Behavioral Models (Extended Version)∗\nLucky Onwuzurike1 , Enrico Mariconti1 , Panagiotis Andriotis2 ,\nEmiliano De Cristofaro1 , Gordon Ross1 , and Gianluca Stringhini1\n\narXiv:1711.07477v1 [cs.CR] 20 Nov 2017\n\n1\n\nUniversity College London\n\n2\n\nUniversity of the West of England\n\nAbstract\n\nlenges compared to desktop/laptop computers: smartphones\nhave limited battery life, making it impossible to use traditional approaches requiring constant scanning and complex\ncomputation [43]. Thus, Android malware detection is typically performed in a centralized fashion, i.e., by analyzing\napps submitted to the Play Store using Bouncer [40]. However, many malicious apps manage to avoid detection [56, 38],\nand manufacturers as well as users can install apps that come\nfrom third parties, which might not perform any malware\nchecks at all [67].\nAs a result, the research community has proposed a number\nof techniques to detect malware on Android. Previous work\nhas often relied on the permissions requested by apps [18, 47],\nusing models built from malware samples. This, however, is\nprone to false positives, since there are often legitimate reasons\nfor benign apps to request permissions classified as dangerous [18]. Another approach, used by D ROIDAPIM INER [1],\nis to perform classification based on API calls frequently used\nby malware. However, relying on the most common calls observed during training prompts the need for constant retraining, due to the evolution of malware and the Android API\nalike. For instance, “old” calls are often deprecated with new\nAPI releases, so malware developers may switch to different\ncalls to perform similar actions.\nIn this paper, we present a novel malware detection system for Android that relies on the sequence of abstracted API\ncalls performed by an app rather than their use or frequency,\naiming to capture the behavioral model of the app. We design M A M A D ROID to abstract API calls to either the class\nname (e.g., java.lang.Throwable) of the call or its package\nname (e.g., java.lang) or its source (e.g., java, android,\ngoogle), which we refer to as family.\nAbstraction provides resilience to API changes in the Android framework as families and packages are added and removed less frequently than single API calls. At the same time,\nthis does not abstract away the behavior of an app: for instance, packages include classes and interfaces used to perform similar operations on similar objects, so we can model\nthe types of operations from the package name alone. For example, the java.io package is used for system I/O and access\nto the file system, even though there are different classes and\ninterfaces provided by the package for such operations.\nAfter abstracting the calls, M A M A D ROID analyzes the sequence of API calls performed by the app aiming to model\n\nAs Android becomes increasingly popular, so does malware\ntargeting it, this motivating the research community to propose\nmany different detection techniques. However, the constant\nevolution of the Android ecosystem, and of malware itself,\nmakes it hard to design robust tools that can operate for long\nperiods of time without the need for modifications or costly\nre-training. Aiming to address this issue, we set to detect malware from a behavioral point of view, modeled as the sequence\nof abstracted API calls. We introduce M A M A D ROID, a staticanalysis based system that abstracts app’s API calls to their\nclass, package, or family, and builds a model from their sequences obtained from the call graph of an app as Markov\nchains. This ensures that the model is more resilient to API\nchanges and the features set is of manageable size. We evaluate M A M A D ROID using a dataset of 8.5K benign and 35.5K\nmalicious apps collected over a period of six years, showing\nthat it effectively detects malware (with up to 0.99 F-measure)\nand keeps its detection capabilities for long periods of time (up\nto 0.87 F-measure two years after training). We also show that\nM A M A D ROID remarkably improves over D ROIDAPIM INER,\na state-of-the-art detection system that relies on the frequency\nof (raw) API calls. Aiming to assess whether M A M A D ROID’s\neffectiveness mainly stems from the API abstraction or from\nthe sequencing modeling, we also evaluate a variant of it that\nuses frequency (instead of sequences), of abstracted API calls.\nWe find that it is not as accurate, failing to capture maliciousness when trained on malware samples including API calls\nthat are equally or more frequently used by benign apps.\n\n1\n\nIntroduction\n\nMalware running on mobile devices can be particularly lucrative, as it may enable attackers to defeat two-factor authentication for financial and banking systems [52] and/or trigger the leakage of sensitive information [25]. As a consequence, the number of malware samples has skyrocketed in\nrecent years, and, due to its increased popularity, cybercriminals have increasingly targeted the Android ecosystem [15].\nDetecting malware on mobile devices presents additional chal∗ A preliminary version of this paper appears in the 24th Network and Distributed System Security Symposium (NDSS 2017) [36].\n\n1\n\n\fthe app’s behavior using Markov chains. Our intuition is\nthat malware may use calls for different operations, and\nin a different order, than benign apps. For example, android.media.MediaRecorder can be used by any app that\nhas permission to record audio, but the call sequence may\nreveal that malware only uses calls from this class after\ncalls to getRunningTasks(), which allows recording conversations [65], as opposed to benign apps where calls from the\nclass may appear in any order. Relying on the sequence of abstracted calls allows us to model behavior in a more complex\nway than previous work, which only looked at the presence or\nabsence of certain API calls or permissions [1, 4], while still\nkeeping the problem tractable [30]. M A M A D ROID then builds\na statistical model to represent the transitions between the API\ncalls performed by an app as Markov chains, and use them to\nextract features. Finally, it classifies an app as either malicious\nor benign using the features it extracts from the app.\nWe present a detailed evaluation of the classification accuracy (using F-measure, precision, and recall) and runtime\nperformance of M A M A D ROID, using a dataset of almost 44K\napps (8.5K benign and 35.5K malware samples). We include\na mix of older and newer apps, from October 2010 to May\n2016, verifying that our model is robust to changes in Android malware samples and APIs. To the best of our knowledge, this is the largest malware dataset used to evaluate an\nAndroid malware detection system in a research paper. Our\nexperimental analysis shows that M A M A D ROID can effectively model both benign and malicious Android apps, and\nefficiently classify them. Compared to other systems such as\nD ROIDAPIM INER [1], our approach allows us to account for\nchanges in the Android API, without the need to frequently\nretrain the classifier. Moreover, to assess the impact of abstraction and Markov chain modeling on M A M A D ROID, we\nnot only compare to D ROIDAPIM INER, but also build a variant (called FAM) that still abstracts API calls but instead of\nbuilding a model from the sequence of calls it does so on the\nfrequency, similar to D ROIDAPIM INER.\nOverall, we find that M A M A D ROID can effectively detect\nunknown malware samples not only in the “present,” (with Fmeasure up to 0.99) but also consistently over the years (i.e.,\nwhen the system is trained on older samples and evaluated\nover newer ones), as it keeps an average detection accuracy,\nevaluated in terms of F-measure, of 0.87 after one year and\n0.75 after two years (as opposed to 0.46 and 0.42 achieved\nby D ROIDAPIM INER [1] and 0.81 and 0.76 by FAM). We\nalso highlight that when the system is not efficient anymore\n(when the test set is newer than the training set by more than\ntwo years), it is as a result of M A M A D ROID having low recall, but maintaining high precision. We also do the opposite,\ni.e., training on newer samples and verifying that the system\ncan still detect old malware. This is particularly important as\nit shows that M A M A D ROID can detect newer threats, while\nstill identifying malware samples that have been in the wild\nfor some time.\n\nin a tool called M A M A D ROID, to detect Android malware\nby abstracting API calls to their class, package, and family,\nand model the behavior of the apps through the sequences of\nAPI calls as Markov chains. Second, we can detect unknown\nsamples on the same year of training with an F-measure of\n0.99, but also years after training the system, meaning that\nM A M A D ROID does not need continuous re-training. Compared to previous work [1], M A M A D ROID achieves higher\naccuracy with reasonably fast running times, while also being more robust to evolution in malware development and\nchanges in the Android API. Third, by abstracting API calls\nand using frequency analysis we still perform better than a\nsystem that also uses frequency analysis but without abstraction (D ROIDAPIM INER). Finally, we explore the detection\nperformance of a finer-grained abstraction and show that abstracting to classes does not perform better than abstracting to\npackages.\nPaper Organization. The rest of the paper is organized as fol-\n\nlows. The next section presents M A M A D ROID, then, Section 3 introduces the datasets used throughout the paper. In\nSection 4, we evaluate M A M A D ROID in family and package modes, while, in Section 5, we explore the effectiveness\nof finer-grained abstraction (i.e., class mode). In Section 6,\nwe present and evaluate the variant using a frequency analysis model (FAM), while we analyze runtime performances in\nSection 7. Section 8 further discusses our results as well as\nits limitations. After reviewing related work in Section 9, the\npaper concludes in Section 10.\n\n2\n\nThe MaMaDroid System\n\nIn this section, we introduce M A M A D ROID, an Android malware detection system that relies on the transitions between\ndifferent API calls performed by Android apps.\n\n2.1\n\nOverview\n\nM A M A D ROID builds a model of the sequence of API calls\nas Markov chains, which are in turn used to extract features\nfor machine learning algorithms to classify apps as benign or\nmalicious.\nAbstraction. M A M A D ROID does not use the raw API calls,\n\nbut abstracts each call to its family, package, or class. For instance, the API call getMessage() in Figure 1 is parsed to, respectively, java, java.lang, and java.lang.Throwable.\npackage\n\nz }| {\njava.lang.Throwable: String getMessage()\n|{z}\n\nfamily\n\n|\n\n{z\n\nClass\n\n}\n\nFigure 1: Example of an API call and its family, package, and class.\n\nGiven the three different types of abstractions, M A M A D ROID operates in one of three modes, each using one of\nthe types of abstraction. Naturally, we expect that the higher\n\nSummary of Contributions. This paper makes several contri-\n\nbutions. First, we introduce a novel approach, implemented\n2\n\n\f?\n\nCall Graph\nExtraction (1)\n\nSequence\nExtraction (2)\n\nMarkov Chain\nModeling (3)\n\nClassification\n(4)\n\nFigure 2: Overview of M A M A D ROID operation. In (1), it extracts the call graph from an Android app, next, it builds the sequences of\n(abstracted) API calls from the call graph (2). In (3), the sequences of calls are used to build a Markov chain and a feature vector for that app.\nFinally, classification is performed in (4), labeling the app as benign or malicious.\npackage com.fa.c;\nimport\nimport\nimport\nimport\nimport\nimport\nimport\n\nandroid.content.Context;\nandroid.os.Environment;\nandroid.util.Log;\ncom.stericson.RootShell.execution.Command;\ncom.stericson.RootShell.execution.Shell;\ncom.stericson.RootTools.RootTools;\njava.io.File;\n\npublic class RootCommandExecutor {\npublic static boolean Execute(Context paramContext) {\nparamContext = new Command(0, new String[] { \"cat \" + Environment.getExternalStorageDirectory().getAbsolutePath() + File.separator + Utilities.GetWatchDogName(\nparamContext) + \" > /data/\" + Utilities.GetWatchDogName(paramContext), \"cat \" + Environment.getExternalStorageDirectory().getAbsolutePath() + File.separator +\nUtilities.GetExecName(paramContext) + \" > /data/\" + Utilities.GetExecName(paramContext), \"rm \" + Environment.getExternalStorageDirectory().getAbsolutePath() +\nFile.separator + Utilities.GetWatchDogName(paramContext), \"rm \" + Environment.getExternalStorageDirectory().getAbsolutePath() + File.separator + Utilities.\nGetExecName(paramContext), \"chmod 777 /data/\" + Utilities.GetWatchDogName(paramContext), \"chmod 777 /data/\" + Utilities.GetExecName(paramContext), \"/data/\" +\nUtilities.GetWatchDogName(paramContext) + \" \" + Utilities.GetDeviceInfoCommandLineArgs(paramContext) + \" /data/\" + Utilities.GetExecName(paramContext) + \" \" +\nEnvironment.getExternalStorageDirectory().getAbsolutePath() + File.separator + Utilities.GetExchangeFileName(paramContext) + \" \" + Environment.\ngetExternalStorageDirectory().getAbsolutePath() + File.separator + \" \" + Utilities.GetPhoneNumber(paramContext) });\ntry {\nRootTools.getShell(true).add(paramContext);\nreturn true;\n}\ncatch (Exception paramContext) {\nLog.d(\"CPS\", paramContext.getMessage());\n}\nreturn false;\n}\n}\n\nFigure 3: Code from a malicious app (com.g.o.speed.memboost) executing commands as root.\n\nthe abstraction, the lighter the system is, although possibly less\naccurate.\nBuilding Blocks. M A M A D ROID’s operation goes through four\nphases, as depicted in Figure 2. First, we extract the call graph\nfrom each app by using static analysis (1), then, we obtain\nthe sequences of API calls using all unique nodes after which\nwe abstract each call to class, package, or family (2). Next,\nwe model the behavior of each app by constructing Markov\nchains from the sequences of API calls for the app (3), with\nthe transition probabilities used as the feature vector to classify\nthe app as either benign or malware using a machine learning\nclassifier (4). In the rest of this section, we discuss each of\nthese steps in detail.\n\nlists a class extracted from the decompiled apk of malware\ndisguised as a memory booster app (with package name\ncom.g.o.speed.memboost), which executes commands (rm,\nchmod, etc.) as root.1 To ease presentation, we focus on the\nportion of the code executed in the try/catch block. The resulting call graph of the try/catch block is shown in Figure 4. For\nsimplicity, we omit calls for object initialization, return types\nand parameters, as well as implicit calls in a method. Additional calls that are invoked when getShell(true) is called are\nnot shown, except for the add() method that is directly called\nby the program code, as shown in Figure 3.\n\n2.2\n\nIn its second phase, M A M A D ROID extracts the sequences of\nAPI calls from the call graph and abstract the calls to one of\nthree mode.\n\n2.3\n\nCall Graph Extraction\n\nThe first step in M A M A D ROID is to extract the app’s call\ngraph. We do so by performing static analysis on the app’s\napk, i.e., the standard Android archive file format containing\nall files, including the Java bytecode, making up the app. We\nuse a Java optimization and analysis framework, Soot [51], to\nextract call graphs and FlowDroid [5] to ensure contexts and\nflows are preserved.\nTo better clarify the different steps involved in our system, we employ, throughout this section, a “running example,” using a real-world malware sample. Figure 3\n\nSequence Extraction and Abstraction\n\nSequence Extraction. Since M A M A D ROID uses static analy-\n\nsis, the graph obtained from Soot represents the sequence of\nfunctions that are potentially called by the app. However, each\nexecution of the app could take a specific branch of the graph\nand only execute a subset of the calls. For instance, when running the code in Figure 3 multiple times, the Execute method\ncould be followed by different calls, e.g., getShell() in the try\n1 https://www.hackread.com/ghost-push-android-malware/\n\n3\n\n\fcom.fa.c.RootCommandExecutor:\nExecute()\n\nandroid.util.Log:\nd()\n\ncom.stericson.RootTools.RootTools:\ngetShell()\n\njava.lang.Throwable:\ngetMessage()\ncom.stericson.RootShell.execution.Shell:\nadd()\n\ncom.fa.c.RootCommandExecutor:\nExecute()\n[self-defined,\nself-defined, self-defined]\n\ncom.stericson.RootTools.RootTools:\ngetShell()\n[self-defined,\nself-defined, self-defined]\n\ncom.fa.c.RootCommandExecutor:\nExecute()\n[self-defined,\nself-defined, self-defined]\n\nandroid.util.Log:\nd()\n[android.util.Log,\nandroid.util, android]\n\ncom.fa.c.RootCommandExecutor:\nExecute()\n[self-defined,\nself-defined, self-defined]\n\njava.lang.Throwable:\ngetMessage()\n[java.lang.Throwable,\njava.lang, java]\n\ncom.stericson.RootShell.\nexecution.Shell: add()\n[self-defined,\nself-defined, self-defined]\n\nFigure 5: Sequence of API calls extracted from the call graphs in\nFigure 4, with the corresponding class/package/family abstraction in\nsquare brackets.\n\nFigure 4: Call graph of the API calls in the try/catch block of Figure 3. (Return types and parameters omitted to ease presentation).\n\nidentifier mangling. Overall, there are 11 (9+2) families, 340\n(243+95+2) possible packages, and 5,973 (4,855+1,116+2)\npossible classes.\n\nblock only or getShell() and then getMessage() in the catch\nblock.\nThus, in this phase, M A M A D ROID operates as follows.\nFirst, it identifies a set of entry nodes in the call graph, i.e.,\nnodes with no incoming edges (for example, the Execute\nmethod in the snippet from Figure 3 is the entry node if there is\nno incoming edge from any other call in the app). Then, it enumerates the paths reachable from each entry node. The sets of\nall paths identified during this phase constitutes the sequences\nof API calls which will be used to build a Markov chain behavioral model and to extract features. In Figure 5, we show\nthe sequence of API calls obtained from the call graph in Figure 4. We also report in square brackets, the family, package,\nand class to which the call is abstracted.\n\n2.4\n\nMarkov-chain Based Modeling\n\nNext, M A M A D ROID builds feature vectors, used for classification, based on the Markov chains representing the sequences\nof abstracted API calls for an app. Before discussing this in\ndetail, first review the basic concepts of Markov chains.\nMarkov Chains. Markov Chains are memoryless models where\n\nthe probability of transitioning from a state to another only\ndepends on the current state [39]. They are often represented\nas a set of nodes, each corresponding to a different state, and\na set of edges connecting one node to another labeled with\nthe probability of that transition. The sum of all probabilities\nassociated to all edges from any node (including, if present,\nan edge going back to the node itself) is exactly 1. The set\nof possible states of the Markov chain is denoted as S. If Sj\nand Sk are two connected states, Pjk denotes the probability\nof transition from Sj to Sk . Pjk is given by the number of\noccurrences (Ojk ) of state Sk after state Sj , divided by Oji\nO\nfor all states i in the chain, i.e., Pjk = P jkOji .\n\nAPI Call Abstraction. Rather than analyzing raw API calls\n\nfrom the sequence of calls, we build M A M A D ROID to work at\na higher level, and operate in one of three modes by abstracting each call to its family, package, or class. The intuition is\nto make M A M A D ROID resilient to API changes and achieve\nscalability. In fact, our experiments, presented in Section 3,\nshow that, from a dataset of 44K apps, we extract more than\n10 million unique API calls, which, depending on the modeling approach used to model each app, may result in the feature\nvectors being very sparse. When operating in family mode,\nwe abstract an API call to one of the nine Android families,\ni.e., android, google, java, javax, xml, apache, junit,\njson, dom, which correspond to the android.*, com.google.*,\njava.*, javax.*, org.xml.*, org.apache.*, junit.*, org.json, and\norg.w3c.dom.* packages. Whereas, in package mode, we abstract the call to its package name using the list of Android\npackages from the documentation2 consisting of 243 packages\nas of API level 24 (the version as of September 2016), as well\nas 95 from the Google API.3 In class mode, we abstract each\ncall to its class name using a whitelist of all class names in the\nAndroid and Google APIs, which consists respectively, 4,855\nand 1116 classes.4\nIn all modes, we abstract developer-defined (e.g.,\ncom.stericson.roottools) and obfuscated (e.g. com.fa.a.b.d)\nAPI calls respectively, as self-defined and obfuscated.\nNote that we label an API call as obfuscated if we cannot\ntell what its class implements, extends, or inherits, due to\n\ni∈S\n\nBuilding the model. For each app, M A M A D ROID takes as in-\n\nput the sequence of abstracted API calls of that app (classes,\npackages or families, depending on the selected mode of operation), and builds a Markov chain where each class/package/family is a state and the transitions represent the probability\nof moving from one state to another. For each Markov chain,\nstate S0 is the entry point from which other calls are made\nin a sequence. As an example, Figure 6 illustrates the Markov\nchains built using classes, packages, and families, respectively,\nfrom the sequences reported in Figure 5.\nWe argue that considering single transitions is more robust\nagainst attempts to evade detection by inserting useless API\ncalls in order to deceive signature-based systems [33]. In\nfact, M A M A D ROID considers all possible calls – i.e., all the\nbranches originating from a node – in the Markov chain, so\nadding calls would not significantly change the probabilities\nof transitions between nodes (specifically, families, packages,\nor classes depending on the operational mode) for each app.\nFeature Extraction. Next, we use the probabilities of tran-\n\n2 https://developer.android.com/reference/packages.html\n\nsitioning from one state (abstracted call) to another in the\nMarkov chain as the feature vector of each app. States that are\n\n3 https://developers.google.com/android/reference/packages\n4 https://developer.android.com/reference/classes.html\n\n4\n\n\fself-defined\n0.5\n\n0.25\n\nself-defined\n\n0.25\n\n0.25\n\njava.lang.Throwable android.util.Log\n\nself-defined\n0.5\n\n0.5\n\njava.lang\n\n(a)\n\n0.25\n\nandroid.util\n\n(b)\n\n0.25\n\n0.25\n\njava\n\nandroid\n\n(c)\n\nFigure 6: Markov chains originating from the call sequence in Figure 5 when using classes (a), packages (b) or families (c).\n\n3\n\nnot present in a chain are represented as 0 in the feature vector. The vector derived from the Markov chain depends on the\noperational mode of M A M A D ROID. With families, there are\n11 possible states, thus 121 possible transitions in each chain,\nwhile, when abstracting to packages, there are 340 states and\n115,600 possible transitions and with classes, there are 5,973\nstates therefore, 35,676,729 possible transitions.\n\nIn this section, we introduce the datasets used in the evaluation of M A M A D ROID (presented later in Section 4), which\ninclude 43,940 apk files, specifically, 8,447 benign and 35,493\nmalware samples. We include a mix of older and newer apps,\nranging from October 2010 to May 2016, as we aim to verify\nthat M A M A D ROID is robust to changes in Android malware\nsamples as well as APIs. To the best of our knowledge, we are\nleveraging the largest dataset of malware samples ever used in\na research paper on Android malware detection.\n\nWe also apply Principal Component Analysis (PCA) [29],\nwhich performs feature selection by transforming the feature\nspace into a new space made of components that are a linear combination of the original features. The first components\ncontain as much variance (i.e., amount of information) as possible. The variance is given as percentage of the total amount\nof information of the original feature space. We apply PCA to\nthe feature set in order to select the principal components, as\nPCA transforms the feature space into a smaller one where the\nvariance is represented with as few components as possible,\nthus considerably reducing computation/memory complexity.\nAlso, PCA could improve the accuracy of the classification by\nremoving, from the feature space, features that make the classifier perform worse.\n\n2.5\n\nDataset\n\nBenign Samples. Our benign datasets consist of two sets of\n\nsamples: (1) one, which we denote as oldbenign, includes\n5,879 apps collected by PlayDrone [54] between April and\nNovember 2013, and published on the Internet Archive5 on\nAugust 7, 2014; and (2) another, newbenign, obtained by\ndownloading the top 100 apps in each of the 29 categories\non the Google Play store as of March 7, 2016, using the\ngoogleplay-api tool.6 Due to errors encountered while downloading some apps, we have actually obtained 2,843 out of\n2,900 apps. Note that 275 of these belong to more than\none category, therefore, the newbenign dataset ultimately includes 2,568 unique apps.\nAndroid Malware Samples. The set of malware samples in-\n\nClassification\n\ncludes apps that were used to test D REBIN [4], dating back\nto October 2010 – August 2012 (5,560), which we denote as\ndrebin, as well as more recent ones that have been uploaded\non the VirusShare7 site over the years. Specifically, we gather\nfrom VirusShare, respectively, 6,228, 15,417, 5,314, and 2,974\nsamples from 2013, 2014, 2015, and 2016. We consider each\nof these datasets separately for our analysis.\n\nThe last step is to perform classification, i.e., labeling apps as\neither benign or malware. To this end, we test M A M A D ROID\nusing different classification algorithms: Random Forests, 1Nearest Neighbor (1-NN), 3-Nearest Neighbor (3-NN), and\nSupport Vector Machines (SVM). Note that since both accuracy and speed are worse with SVM, we omit results obtained\nwith it.\n\nAPI Calls. For each app, we extract all API calls, using An-\n\ndroguard8 , since, as explained in Section 4.5, these constitute\nthe features used by D ROIDAPIM INER [1] (against which we\ncompare our system) as well as a variant of M A M A D ROID that\nis based on frequency analysis (see Section 6). Due to Androguard failing to decompress some of the apks, bad CRC-32\nredundancy checks, and errors during unpacking, we are not\nable to extract the API calls for all the samples, but only for\n\nEach model is trained using the feature vector obtained from\nthe apps in a training sample. Results are presented and discussed in Section 4, and have been validated by using 10-fold\ncross validation. Also note that, due to the different number\nof features used in different modes, we use two distinct configurations for the Random Forests algorithm. Specifically,\nwhen abstracting to families, we use 51 trees with maximum\ndepth 8, while, with classes and packages, we use 101 trees of\nmaximum depth 64. To tune Random Forests we follow the\nmethodology applied in [6].\n\n5 https://archive.org/details/playdrone-apk-e8\n6 https://github.com/egirault/googleplay-api\n7 https://virusshare.com/\n8 https://github.com/androguard/androguard\n\n5\n\n\fCategory\n\nName\n\nDate Range\n\n#Samples\n\nBenign\n\noldbenign\nnewbenign\n\nApr 2013 – Nov 2013\nMar 2016 – Mar 2016\nTotal Benign:\n\nMalware\n\ndrebin\n2013\n2014\n2015\n2016\n\nOct 2010 – Aug 2012\nJan 2013 – Jun 2013\nJun 2013 – Mar 2014\nJan 2015 – Jun 2015\nJan 2016 – May 2016\nTotal Malware:\n\n5,879\n2,568\n8,447\n\n#Samples\n(API Calls)\n5,837\n2,565\n8,402\n\n#Samples\n(Call Graph)\n5,572\n2,465\n8,037\n\n5,560\n6,228\n15,417\n5,314\n2,974\n35,493\n\n5,546\n6,146\n14,866\n5,161\n2,802\n34,521\n\n5,512\n6,091\n13,804\n4,451\n2,555\n32,413\n\n1.0\n\n0.8\n\n0.8\n\n0.6\n\n0.6\n\n0.4\n0.2\n0.00\n\n10000\n\n20000\n\n#API Calls\n(a) API calls\n\n2015\nnewbenign\noldbenign\ndrebin\n2013\n2014\n2016\n\n30000\n\n40000\n\n1.0\n\n2016\n2015\n2014\n2013\ndrebin\nnewbenign\noldbenign\n\n0.8\n0.6\nCDF\n\n1.0\n\nCDF\n\nCDF\n\nTable 1: Overview of the datasets used in our experiments.\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\n0.0\n0.0\n\n0.2\n\n0.4\n0.6\nFraction of Calls\n\n(b) android\n\n0.8\n\n1.0\n\n0.0\n0.0\n\n0.2\n\n0.4\n0.6\nFraction of Calls\n\n2016\n2015\n2014\n2013\ndrebin\nnewbenign\noldbenign\n0.8\n1.0\n\n(c) google\n\nFigure 7: CDFs of the number of API calls per app in each dataset (a), and of the percentage of android (b) and google (c) family calls.\n\nure 7(b)), both in benign and malicious datasets, while google\ncalls become more common in newer apps (Figure 7(c)). In\ngeneral, we conclude that benign and malicious apps show the\nsame evolutionary trends over the years. Malware, however,\nappears to reach the same characteristics (in terms of level of\ncomplexity and fraction of API calls from certain families) as\nlegitimate apps with a few years of delay.\n\n40,923 (8,402 benign, 34,521 malware) out of the 43,940 apps\nin our datasets.\nCall Graphs. To extract the call graph of each apk, we use\nSoot. Note that for some of the larger apks, Soot requires a\nnon-negligible amount of memory to extract the call graph, so\nwe allocate 16GB of RAM to the Java VM heap space. We find\nthat for 2,472 (364 benign + 2,108 malware) samples, Soot is\nnot able to complete the extraction due to it failing to apply the\njb phase as well as reporting an error in opening some zip files\n(i.e., the apk). The jb phase is used by Soot to transform Java\nbytecode into jimple intermediate representation (the primary\nIR of Soot) for optimization purposes. Therefore, we exclude\nthese apps in our evaluation and discuss this limitation further\nin Section 8.3. In Table 1, we provide a summary of our seven\ndatasets, reporting the total number of samples per dataset, as\nwell as those for which we are able to extract the API calls\n(second-to-last column) and the call graphs (last column).\nDataset Characterization. Aiming to shed light on the evolution of API calls in Android apps, we also performed some\nmeasurements over our datasets. In Figure 7(a), we plot the\nCumulative Distribution Function (CDF) of the number of\nunique API calls in the apps in different datasets, highlighting that newer apps, both benign and malicious, use more API\ncalls overall than older apps. This indicates that as time goes\nby, Android apps become more complex. When looking at the\nfraction of API calls belonging to specific families, we discover some interesting aspects of Android apps developed in\ndifferent years. In particular, we notice that API calls to the\nandroid family become less prominent as time passes (Fig-\n\nPrincipal Component Analysis. Finally, we apply PCA to se-\n\nlect the two most important PCA components. We plot and\ncompare the positions of the two components for benign (Figure 8(a)) and malicious samples (Fig. 8(b)). As PCA combines\nthe features into components, it maximizes the variance of the\ndistribution of samples in these components, thus, plotting the\npositions of the samples in the components shows that benign\napps tend to be located in different areas of the components\nspace, depending on the dataset, while malware samples occupy similar areas but with different densities. These differences highlight a different behavior between benign and malicious samples, and these differences should also be found by\nthe machine learning algorithms used for classification.\n\n4\n\nM A M A D ROID Evaluation\n\nWe now present an experimental evaluation of M A M A D ROID\nrun in family and package mode. Later in Section 5, we evaluate it in class mode. We use the datasets summarized in\nTable 1, and evaluate M A M A D ROID, as per (1) its accuracy\non benign and malicious samples developed around the same\n6\n\n\f1.0\n\n0.8\n\n0.8\n\n0.6\n\n0.6\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\nPCA2\n\nPCA2\n\n1.0\n\n0.0\n\n0.0\n\n0.2\n\n0.2\n\n0.4\n\n0.4\n\n0.6\n0.8\n1.0\n\n0.5\n\n0.0\n\nPCA1\n\n0.5\n\n1.0\n\n0.6\n\noldbenign\nnewbenign\n\n0.8\n1.0\n\n1.5\n\n(a) benign\n\n0.5\n\n0.0\n\nPCA1\n\n0.5\n\n1.0\n\ndrebin\n2013\n2014\n2015\n2016\n\n1.5\n\n(b) malware\n\nFigure 8: Positions of benign vs malware samples in the feature space of the first two components of the PCA (family mode).\n\ntime; and (2) its robustness to the evolution of malware as well\nas of the Android framework by using older datasets for training and newer ones for testing and vice-versa.\n\n4.1\n\nsmaller one. When operating in package mode, PCA could\nbe particularly beneficial to reduce computation and memory complexity, since M A M A D ROID originally has to operate\nover 116,281 features. Hence, in Table 2 we report the precision, recall, and F-measure achieved by M A M A D ROID in both\nmodes with and without the application of PCA using Random\nForest classifier. We report the results for Random Forest only\nbecause it outperforms both 1-NN and 3-NN (Figure 9) while\nalso being very fast. In package mode, we find that only 67%\nof the variance is taken into account by the 10 most important\nPCA components, and, in family mode, at least 91% of the\nvariance is included by the 10 PCA Components. As shown\nin Table 2, the F-measure using PCA is only slightly lower\n(up to 3%) than using the full feature set. In general, M A M A D ROID performs better in package mode in all datasets\nwith F-measure ranging from 0.92 – 0.99 compared to 0.88 –\n0.98 in family mode. This is as a result of the increased granularity which enables M A M A D ROID identify more differences\nbetween benign and malicious apps. On the other hand, however, this likely reduces the efficiency of the system, as many\nof the states derived from the abstraction are used only a few\ntimes. The differences in time performance between the two\nmodes are analyzed in details in Section 7.\n\nExperimental Settings\n\nTo assess the accuracy of the classification, we use the standard F-measure metric, calculated as F = 2 · (precision ·\nrecall)/(precision + recall), where precision = TP/(TP+FP)\nand recall = TP/(TP+FN). TP denotes the number of samples correctly classified as malicious, while FP an FN indicate,\nrespectively, the number of samples mistakenly identified as\nmalicious and benign.\nNote that all our experiments perform 10-fold cross validation using at least one malicious and one benign dataset from\nTable 1. In other words, after merging the datasets, the resulting set is shuffled and divided into ten equal-size random\nsubsets. Classification is then performed ten times using nine\nsubsets for training and one for testing, and results are averaged out over the ten experiments.\nWhen implementing M A M A D ROID in family mode, we exclude json and dom families because they are almost never\nused across all our datasets, and junit, which is primarily\nused for testing. In package mode, in order to avoid mislabeling when self-defined APIs have “android” in the\nname, we split the android package into its two classes, i.e.,\nandroid.R and android.Manifest. Therefore, in family\nmode, there are 8 possible states, thus 64 features, whereas,\nin package mode, we have 341 states and 116,281 features\n(cf. Section 2.4).\n\n4.2\n\n4.3\n\nDetection Over Time\n\nAs Android evolves over the years, so do the characteristics of\nboth benign and malicious apps. Such evolution must be taken\ninto account when evaluating Android malware detection systems, since their accuracy might significantly be affected as\nnewer APIs are released and/or as malicious developers modify their strategies in order to avoid detection. Evaluating this\naspect constitutes one of our research questions, and one of the\nreasons why our datasets span across multiple years (2010–\n2016).\nRecall that M A M A D ROID relies on the sequence of API\ncalls extracted from the call graphs and abstracted to either the\npackage or the family level. Therefore, it is less susceptible\nto changes in the Android API than other classification systems such as D ROIDAPIM INER [1] and D REBIN [4]. Since\nthese rely on the use, or the frequency, of certain API calls to\n\nM A M A D ROID’s Performance (Family and\nPackage Mode)\n\nWe start by evaluating the performance of M A M A D ROID\nwhen it is trained on dataset from the same year.\nIn Figure 9, we plot the F-measure achieved by M A M A D ROID in family and package modes using datasets from\nthe same year for training and testing and the three different classifiers. As already discussed in Section 2.4, we apply PCA as it allows us transform a large feature space into a\n7\n\n\f1.0\n\nRF\n1-NN\n3-NN\n\n0.8\n\n0.8\n\n0.6\n\n0.6\n\nF-measure\n\nF-measure\n\n1.0\n\n0.4\n0.2\n0.0\n\nRF\n1-NN\n3-NN\n\n0.4\n0.2\n\nDrebin &\nOldBenign\n\n2013 &\nOldBenign\n\n2014 &\nOldBenign\n\n2014 &\nNewbenign\n\n2015 &\nNewbenign\n\n0.0\n\n2016 &\nNewbenign\n\nDrebin &\nOldBenign\n\n(a) family mode\n\n2013 &\nOldBenign\n\n2014 &\nOldBenign\n\n2014 &\nNewbenign\n\n2015 &\nNewbenign\n\n2016 &\nNewbenign\n\n(b) package mode\n\nFigure 9: F-measure of M A M A D ROID classification with datasets from the same year using three different classifiers.\n\nXXX\nX Mode\nDataset XXX\nX\ndrebin, oldbenign\n2013, oldbenign\n2014, oldbenign\n2014, newbenign\n2015, newbenign\n2016, newbenign\n\n0.82\n0.91\n0.88\n0.97\n0.89\n0.87\n\nFamily\n0.95\n0.93\n0.96\n0.99\n0.93\n0.91\n\n0.88\n0.92\n0.92\n0.98\n0.91\n0.89\n\n0.95\n0.98\n0.93\n0.98\n0.93\n0.92\n\n[Precision, Recall, F-measure]\nPackage\nFamily (PCA)\n0.97\n0.96 0.84\n0.92\n0.88\n0.95\n0.97 0.93\n0.90\n0.92\n0.97\n0.95 0.87\n0.94\n0.90\n1.00\n0.99 0.96\n0.99\n0.97\n0.98\n0.95 0.87\n0.93\n0.90\n0.92\n0.92 0.86\n0.88\n0.87\n\nPackage (PCA)\n0.94\n0.95\n0.94\n0.97\n0.95\n0.96\n0.92\n0.96\n0.94\n0.97\n1.00\n0.99\n0.91\n0.97\n0.94\n0.88\n0.89\n0.89\n\nTable 2: Precision, Recall, and F-measure obtained by M A M A D ROID when trained and tested with dataset from the same year in package and\nfamily mode, using Random Forests, and with and without PCA.\n\nclassify malware vs benign samples, they need to be retrained\nfollowing new API releases. On the contrary, retraining is not\nneeded as often with M A M A D ROID, since families and packages represent more abstract functionalities that change less\nover time. Consider, for instance, the android.os.health\npackage: released with API level 24, it contains a set of classes\nhelping developers track and monitor system resources.9 Classification systems built before this release – as in the case\nof D ROIDAPIM INER [1] (released in 2013, when Android\nAPI was up to level 20) – need to be retrained if this package is more frequently used by malicious apps than benign\napps, while M A M A D ROID only needs to add a new state to\nits Markov chain when operating in package mode, while no\nadditional state is required when operating in family mode.\n\nwhen classifying future samples and using drebin (with samples from 2010 to 2012) or 2013 as the malicious training set\nand oldbenign (late 2013/early 2014) as the benign training\nset. More specifically, we observe that M A M A D ROID correctly detects benign apps, while it starts missing true positives\nand increasing false negatives – i.e., achieving lower recall.\nNewer training, older testing. We also set to verify whether\n\nolder malware samples can still be detected by the system—\nif not, this would obviously become vulnerable to older (and\npossibly popular) attacks. Therefore, we also perform the “opposite” experiment, i.e., training M A M A D ROID with newer\nbenign (March 2016) and malware (early 2014 to mid 2016)\ndatasets, and checking whether it is able to detect malware developed years before. Specifically, Figure 11(a) and 11(b) report results when training M A M A D ROID with samples from\na given year, and testing it with others that are up to 4 years\nolder: M A M A D ROID retains similar F-measure scores over\nthe years. Specifically, in family mode, it varies from 0.93 to\n0.96, whereas, in package mode, from 0.95 to 0.97 with the\noldest samples.\n\nOlder training, newer testing. To verify this hypothesis, we test\n\nM A M A D ROID using older samples as training sets and newer\nones as test sets. Figure 10(a) reports the average F-measure\nof the classification in this setting, with M A M A D ROID operating in family mode. The x-axis reports the difference in\nyears between training and test malware data. We obtain 0.86\nF-measure when we classify apps one year older than the samples on which we train. Classification is still relatively accurate, at 0.75, even after two years. Then, from Figure 10(b),\nwe observe that the average F-measure does not significantly\nchange when operating in package mode. Both modes of operations are affected by one particular condition, already discussed in Section 3: in our models, benign datasets seem to\n“anticipate” malicious ones by 1–2 years in the way they use\ncertain API calls. As a result, we notice a drop in accuracy\n\n4.4\n\nCase Studies of False Positives and Negatives\n\nThe experiment analysis presented above show that M A M A D ROID detects Android malware with high accuracy. As\nin any detection system, however, the system makes a small\nnumber of incorrect classifications, incurring some false positives and false negatives. Next, we discuss a few case studies aiming to better understand these misclassifications. We\nfocus on the experiments with newer datasets, i.e., 2016 and\n\n9 https://developer.android.com/reference/android/os/health/\n\npackage-summary.html\n\n8\n\n\f1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n\nRF\n1-NN\n3-NN\n\n0.8\n\nF-measure\n\nF-measure\n\n1.0\n\nRF\n1-NN\n3-NN\n\n0.6\n0.4\n0.2\n\n0\n\n1\n\n2\nYears\n\n3\n\n0.0\n\n4\n\n0\n\n1\n\n(a) family mode\n\n2\nYears\n\n3\n\n4\n\n(b) package mode\n\n1.0\n\n1.0\n\n0.8\n\n0.8\n\n0.6\n\n0.6\n\nF-measure\n\nF-measure\n\nFigure 10: F-measure achieved by M A M A D ROID using older samples for training and newer samples for testing. The x-axis shows the\ndifference in years between the training and test data.\n\n0.4\n0.2\n0.0\n\n0.2\n\nRF\n1-NN\n3-NN\n0\n\n1\n\n2\nYears\n\n3\n\n0.4\n\n0.0\n\n4\n\nRF\n1-NN\n3-NN\n0\n\n(a) family mode\n\n1\n\n2\nYears\n\n3\n\n4\n\n(b) package mode\n\nFigure 11: F-measure achieved by M A M A D ROID using newer samples for training and older samples for testing. The x-axis shows the\ndifference in years between the training and test data.\n\n45% of M A M A D ROID’s false negatives are adware, typically,\nrepackaged apps in which the advertisement library has been\nsubstituted with a third-party one, which creates a monetary\nprofit for the developers. Since they are not performing any\nclearly malicious activity, M A M A D ROID is unable to identify\nthem as malware. Finally, we find that 16% of the false negatives reported by M A M A D ROID are samples sending text messages or starting calls to premium services. We also do a similar analysis of false negatives when abstracting to packages\n(74 samples), with similar results: there a few more adware\nsamples (53%), but similar percentages for potentially benign\napps (15%) and samples sending SMSs or placing calls (11%).\n\nnewbenign.\nFalse Positives. We analyze the manifest of 164 apps mistak-\n\nenly detected as malware by M A M A D ROID, finding that most\nof them use “dangerous” permissions [3]. In particular, 67%\nwrite to external storage, 32% read the phone state, and 21%\naccess the device’s fine location. We further analyzed apps\n(5%) that use the READ SMS and SEND SMS permissions,\ni.e., even though they are not SMS-related apps, they can read\nand send SMSs as part of the services they provide to users. In\nparticular, a “in case of emergency” app is able to send messages to several contacts from its database (possibly added by\nthe user), which is a typical behavior of Android malware in\nour dataset, ultimately leading M A M A D ROID to flag it as malicious.\n\n4.5\n\nFalse Negatives. We also check 114 malware samples missed\n\nM A M A D ROID vs D ROIDAPIM INER\n\nWe also compare the performance of M A M A D ROID to previous work using API features for Android malware classification, specifically, to D ROIDAPIM INER [1], because: (i) it\nuses API calls and its parameters to perform classification; (ii)\nit reports high true positive rate (up to 97.8%) on almost 4K\nmalware samples obtained from McAfee and G ENOME [66],\nand 16K benign samples; and (iii) its source code has been\n\nby M A M A D ROID when operating in family mode, using\nVirusTotal.10 We find that 18% of the false negatives are actually not classified as malware by any of the antivirus engines used by VirusTotal, suggesting that these are actually\nlegitimate apps mistakenly included in the VirusShare dataset.\n10 https://www.virustotal.com\n\n9\n\n\fmade available to us by the authors.\n\nthe future and past respectively. Likewise, we use the same\ndatasets for M A M A D ROID, with the best results achieved on\nthe same dataset as D ROIDAPIM INER. In package mode,\nM A M A D ROID achieves an F-measure of 0.99 which is maintained more than two years into the past, but drops to respectively, 0.85 and 0.81 one and two years into the future\nAs summarized in Table 3, M A M A D ROID achieves significantly higher performance than D ROIDAPIM INER in all but\none experiment. This case occurs when the malicious training\nset is much older than the malicious test set.\n\nIn D ROIDAPIM INER, permissions that are requested more\nfrequently by malware samples than by benign apps are used\nto perform a baseline classification. Then, the system also applies frequency analysis on the list of API calls after removing\nAPI calls from ad libraries, using the 169 most frequent API\ncalls in the malware samples (occurring at least 6% more in\nmalware than benign samples). Finally, data flow analysis is\napplied on the API calls that are frequent in both benign and\nmalicious samples, but do not occur by at least 6% more in the\nmalware set. Using the top 60 parameters, the 169 most frequent calls change, and authors report a precision of 97.8%.\n\n5\n\nAfter obtaining D ROIDAPIM INER’s source code, as well\nas a list of packages (i.e., ad libraries) used for feature refinement, we re-implement the system by modifying the code\nin order to reflect recent changes in Androguard (used by\nD ROIDAPIM INER for API call extraction), extract the API\ncalls for all apps in the datasets listed in Table 1, and perform a frequency analysis on the calls. Recall that Androguard fails to extract calls for about 2% (1,017) of apps,\nthus D ROIDAPIM INER is evaluated over the samples in the\nsecond-to-last column of Table 1. We also implement classification, which is missing from the code provided by the authors, using k-NN (with k=3) since it achieves the best results\naccording to the paper. We use 2/3 of the dataset for training\nand 1/3 for testing as implemented by the authors.\n\nFiner-grained Abstraction\n\nIn Section 4, we have showed that building models from abstracted API calls allows M A M A D ROID to obtain high accuracy, as well as to retain it over the years, which is crucial due\nto the continuous evolution of the Android ecosystem. Our experiments have focused on operating M A M A D ROID in family\nand package mode (i.e., abstracting calls to family or package).\nIn this section, we investigate whether a finer-grained abstraction – namely, to classes – performs better in terms of\ndetection accuracy. Recall that our system performs better in\npackage mode than in family mode due to the system using\nin the former, finer and more features to distinguish between\nmalware and benign samples, so we set to verify whether one\ncan trade-off higher computational and memory complexities\nfor better accuracy. To this end, as discussed in Section 2.3, we\nabstract each API call to its corresponding class name using a\nwhitelist of all classes in the Android API, which consists of\n4,855 classes (as of API level 24), and in the Google API, with\n1,116 classes, plus self-defined and obfuscated.\n\nIn Table 3, we report the results of D ROIDAPIM INER compared to M A M A D ROID on different combination of datasets.\nSpecifically, we report results for experiments similar to those\ncarried out in Section 4.3 as we evaluate its performance on\ndataset from the same year and over time. First, we train it\nusing older dataset composed of oldbenign combined with\none of the three oldest malware datasets each (drebin, 2013,\nand 2014), and test on all malware datasets. Testing on all\ndatasets ensures the model is evaluated on dataset from the\nsame year and newer. With this configuration, the best result\n(with 2014 and oldbenign as training sets) is 0.62 F-measure\nwhen tested on the same dataset. The F-measure drops to\n0.33 and 0.39, respectively, when tested on samples one year\ninto the future and past. If we use the same configurations\nin M A M A D ROID, in package mode, we obtain up to 0.97 Fmeasure (using 2013 and oldbenign as training sets), dropping to 0.73 and 0.94 respectively, one year into the future\nand into the past. For the datasets where D ROIDAPIM INER\nachieves its best result (i.e., 2014 and oldbenign), M A M A D ROID achieves an F-measure of 0.95, which drops to\nrespectively, 0.78 and 0.93 one year into the future and the\npast. The F-measure is stable even two years into the future\nand the past at 0.75 and 0.92 respectively. As a second set\nof experiments, we train D ROIDAPIM INER using a dataset\ncomposed of newbenign (March 2016) combined with one\nof the three most recent malware datasets each (2014, 2015,\nand 2016). Again, we test D ROIDAPIM INER on all malware\ndatasets. The best result is obtained with the dataset (2014\nand newbenign) used for both testing and training, yielding a\nF-measure of 0.92, which drops to 0.67 and 0.75 one year into\n\n5.1\n\nReducing the size of the problem\n\nSince there are 5,973 classes, processing the Markov chain\ntransitions that results in this mode increases the memory requirements. Therefore, to reduce the complexity, we cluster\nclasses based on their similarity. To this end, we build a cooccurrence matrix that counts the number of times a class is\nused with other classes in the same sequence in all datasets.\nMore specifically, we build a co-occurrence matrix C, of size\n(5,973·5,973)/2, where Ci,j denotes the number of times the ith and the j-th class appear in the same sequence, for all apps in\nall datasets. From the co-occurrence matrix, we compute the\ny\n·y\nx, y ) = ||xxx||·||y\ncosine similarity (i.e., cos(x\ny || ), and use k-means\nto cluster the classes based on their similarity into 400 clusters\nand use each cluster as the label for all the classes it contains.\nSince we do not cluster classes abstracted to self-defined and\nobfuscated, we have a total of 402 labels.\n\n5.2\n\nClass Mode Accuracy\n\nIn Table 4, we report the resulting F-measure in class mode using the above clustering approach. Once again, we also report\nthe corresponding results from package mode for comparison\n10\n\n\fdrebin, oldbenign\nTraining Sets\nDroid\nMaMa\ndrebin & oldbenign 0.32\n0.96\n2013 & oldbenign\n0.33\n0.94\n2014 & oldbenign\n0.36\n0.92\ndrebin, newbenign\nTraining Sets\nDroid\nMaMa\n2014 & newbenign\n0.76\n0.98\n2015 & newbenign\n0.68\n0.97\n2016 & newbenign\n0.33\n0.96\n\n2013, oldbenign\nDroid\nMaMa\n0.35\n0.95\n0.36\n0.97\n0.39\n0.93\n2013, newbenign\nDroid\nMaMa\n0.75\n0.98\n0.68\n0.97\n0.35\n0.98\n\nTesting Sets\n2014, oldbenign\nDroid\nMaMa\n0.34\n0.72\n0.35\n0.73\n0.62\n0.95\n2014, newbenign\nDroid\nMaMa\n0.92\n0.99\n0.69\n0.99\n0.36\n0.98\n\n2015, oldbenign\nDroid\nMaMa\n0.30\n0.39\n0.31\n0.37\n0.33\n0.78\n2015, newbenign\nDroid\nMaMa\n0.67\n0.85\n0.77\n0.95\n0.34\n0.92\n\n2016, oldbenign\nDroid\nMaMa\n0.33\n0.42\n0.33\n0.28\n0.37\n0.75\n2016, newbenign\nDroid\nMaMa\n0.65\n0.81\n0.65\n0.88\n0.36\n0.92\n\nTable 3: Classification performance of D ROIDAPIM INER (Droid) [1] vs M A M A D ROID (MaMa) in package mode using Random Forest.\n\nPP Mode\nP\nDataset PP\nP\n\ndrebin, oldbenign\n2013, oldbenign\n2014, oldbenign\n2014, newbenign\n2015, newbenign\n2016, newbenign\n\n0.95\n0.98\n0.93\n0.98\n0.93\n0.91\n\n[Precision, Recall, F-measure]\nClass\nPackage\n0.97\n0.96 0.95\n0.97\n0.95\n0.97 0.98\n0.95\n0.97\n0.95 0.93\n0.97\n1.00\n0.99 0.98\n1.00\n0.98\n0.95 0.93\n0.98\n0.92\n0.92 0.92\n0.92\n\nwhen the training samples are two years newer, M A M A D ROID\nachieves an F-measure of 0.99, 0.97, and 0.95 respectively, in\nclass, package, and family modes. Whereas, when they are\nthree years newer, the F-measure is respectively, 0.97, 0.97,\nand 0.96 in class, package, and family modes.\n\n0.96\n0.97\n0.95\n0.99\n0.95\n0.92\n\nTable 4: M A M A D ROID’s Precision, Recall, and F-measure when\ntrained and tested on dataset from the same year using Random\nForests and API calls abstracted to classes and packages.\n\n6\n\nM A M A D ROID mainly relies on (1) API call abstraction, and\n(2) behavioral modeling via sequence of calls. As shown,\nit outperforms state-of-the-art Android detection techniques,\nsuch as D ROIDAPIM INER [1], that are based on the frequency\nof non-abstracted API calls. In this section, we aim to assess\nwhether M A M A D ROID’s effectiveness mainly stems from the\nAPI abstraction, or from the sequence modeling. To this\nend, we implement and evaluate a variant that uses frequency,\nrather than sequences, of abstracted API calls. More precisely,\nwe perform frequency analysis on the API calls extracted using Androguard after removing ad libraries, as also done in\nD ROIDAPIM INER. In the rest of the section, we denote this\nvariant as FAM (Frequency Analysis Model).\nWe again use the datasets in Table 1 to evaluate FAM’s accuracy when training and testing on datasets from the same\nyear and from different years. We also evaluate how it compares to standard M A M A D ROID. Although we have also implemented FAM in class mode, we do not discuss/report results here due to space limitation.\n\n(cf Section 4.2). Overall, we find that class abstraction does\nnot provide significantly higher accuracy. In fact, compared\nto package mode, abstraction to classes only yields an average\nincrease in F-measure of 0.0012.\n\n5.3\n\nFrequency Analysis Model (FAM)\n\nDetection over time\n\nWe also compare accuracy when M A M A D ROID is trained and\ntested on dataset from different years (Figure 12). We find\nthat, when M A M A D ROID operates in class mode, it achieves\nan F-measure of 0.95 and 0.99, respectively, when trained with\ndatasets one and two years newer than the test sets, as reported\nin Figure 12(a)). Likewise, when trained on datasets one and\ntwo years older than the test set, F-measure reaches 0.84 and\n0.59, respectively (see Figure 12(b)).\nOverall, comparing results from Figure 10 to Figure 12(b),\nwe find that finer-grained abstraction actually performs worse\nwith time when older samples are used for training and newer\nfor testing. We note that this is due to a possible number of reasons: 1) newer classes or packages in recent API releases cannot be captured in the behavioral model of older tools whereas,\nfamilies are; and 2) evolution of malware either as a result of\nchanges in the API or patching of vulnerabilities or presence\nof newer vulnerabilities that allows for stealthier malicious activities.\nOn the contrary, Figure 11 and 12(a) show that finer-grained\nabstraction performs better when the training samples are\nmore recent than the test samples. This is because from recent samples, we are able to capture the full behavioral model\nof older samples. However, our results indicate there is a\nthreshold for the level of abstraction which when exceeded,\nfiner-grained abstraction will not yield any significant improvement in detection accuracy. This is because API calls in\nolder releases are subsets of subsequent releases. For instance,\n\n6.1\n\nFAM Accuracy\n\nWe start our evaluation by measuring how well FAM detects\nmalware by training and testing using samples that are developed around the same time. Figure 13 reports the F-measure\nachieved in family and package modes using three different\nclassifiers. Also, Table 5 reports precision, recall, and Fmeasure achieved by FAM on each dataset combination, when\noperating in family and package mode, using Random Forests.\nWe only report the results from the Random Forest classifier\nbecause it outperforms both the 1-NN and 3-NN classifiers.\nFamily mode. Due to the number of possible families (i.e.,\n\n11), FAM builds a model from all families that occur more\nin our malware dataset than the benign dataset. Note that in\nthis modeling approach, we also remove the junit family as\nit is mainly used for testing. When the drebin and 2013 mal11\n\n\f1.0\n\n0.8\n\n0.8\n\n0.6\n\n0.6\n\nF-measure\n\nF-measure\n\n1.0\n\n0.4\n0.2\n0.0\n\n0\n\nClass\nPackage\n\n0.4\n0.2\n\nClass\nPackage\n\n1\n\n2\n\n3\n\nYears\n\n0.0\n\n4\n\n0\n\n1\n\n(a) Newer/Older\n\n2\n\nYears\n\n3\n\n4\n\n(b) Older/Newer\n\nFigure 12: F-measure achieved by M A M A D ROID in class mode when using newer (older) samples for training and older (newer) samples for\ntesting. The x-axis shows the difference in years between the training and test data.\n\n0.6\n0.4\n0.2\n\n0.6\n0.4\n0.2\n\nDrebin & 2013 & 2014 & 2014 & 2015 & 2016 &\nOldBenign OldBenign OldBenign Newbenign Newbenign Newbenign\n\n(a) family mode\n\n0.0\n\n1.0\n\nRF\n1-NN\n3-NN\n\n0.8\n\nF-measure\n\nF-measure\n\n0.8\n\n0.0\n\n1.0\n\nRF\n1-NN\n3-NN\n\nRF\n1-NN\n3-NN\n\n0.8\n\nF-measure\n\n1.0\n\n0.6\n0.4\n0.2\n\nDrebin & 2013 & 2014 & 2014 & 2015 & 2016 &\nOldBenign OldBenign OldBenign Newbenign Newbenign Newbenign\n\n(b) package mode\n\n0.0\n\nDrebin & 2013 & 2014 & 2014 & 2015 & 2016 &\nOldBenign OldBenign OldBenign Newbenign Newbenign Newbenign\n\n(c) class mode\n\nFigure 13: F-measure for the FAM variant, over same-year datasets, with different classifiers.\n\nware datasets are used in combination with the oldbenign\ndataset, there are no families that are more frequently used in\nthese datasets than the benign dataset. As a result, FAM does\nnot yield any result with these datasets as it builds a model\nonly from API calls that are more frequently used in malware\nthan benign samples. With the other datasets, there are two\n(2016), four (2014), and five families (2015) that occur more\nfrequently in the malware dataset than the benign one.\n\nClassification performance improves in package mode, with\nF-measure ranging from 0.53 with 2016 and newbenign to\n0.89 with 2014 and newbenign, using Random Forests. Figure 13(b) shows that Random Forests generally provides better\nresults also in this case. Similar to family mode, the drebin\nand 2013 datasets respectively, have only five and two packages that occur more than in the oldbenign dataset. Hence,\nthe results when these datasets are evaluated is poor due to the\nlimited amount of features.\n\nFrom Figure 13(a), we observe that F-measure is always\nat least 0.5 with Random Forests, and, when tested on the\n2014 (malware) dataset, it reaches 0.87. In general, lower Fmeasures are due to increased false positives. This follows a\nsimilar trend observed in Section 4.3.\n\nClass mode. When FAM operates in class mode, we build a\n\nmodel using the minimum of, all API calls that occur more\nfrequently in malware than benign samples or the top 336 API\ncalls that occur more in malware than benign apps. We use\nthe top 336 classes so as to build a model with classes from at\nleast two different packages as the highest number of classes\nin a single package (java.util) is 335. In our datasets, there\nis at least three classes that occur more in malware (2013)\nthan benign samples and at most, 862 classes that occur more\nfrequently in malware (2015) than the benign dataset.\n\nWhen FAM operates in package mode, it\nbuilds a model using the minimum of, all API calls that occur more frequently in malware or the top 172 API calls used\nmore frequently in malware than benign apps. We use the top\n172 API calls as we attempt to build the model where possible,\nwith packages from at least two families (the android family\nhas 171 packages). In our dataset, there are at least two (2013)\nand at most 39 (2016) packages that are used more frequently\nin malware than in benign samples. Hence, all packages that\noccur more in malware than benign apps are always used to\nbuild the model.\nPackage mode.\n\nIn Figure 13(c), we report precision, recall, and F-measure\nachieved by FAM. It achieves its best result (0.89 F-measure)\nwhen trained and tested with the 2014 and newbenign datatsets. Also, we show in Table 5 how the three modes compare\nwhen trained and tested on dataset from the same year. Over12\n\n\fPP Mode\nP\nDataset PP\nP\n\ndrebin, oldbenign\n2013, oldbenign\n2014, oldbenign\n2014, newbenign\n2015, newbenign\n2016, newbenign\n\n0.71\n0.85\n0.64\n0.51\n\nFamily\n0.76\n0.90\n0.70\n0.49\n\n[Precision, Recall, F-measure]\nPackage\n- 0.51\n0.57\n0.54 0.50\n- 0.53\n0.57\n0.55 0.58\n0.73 0.73\n0.73\n0.73 0.73\n0.87 0.88\n0.89\n0.89 0.88\n0.67 0.68\n0.66\n0.67 0.68\n0.50 0.53\n0.52\n0.53 0.54\n\nClass\n0.47\n0.57\n0.76\n0.89\n0.67\n0.54\n\n0.49\n0.58\n0.75\n0.89\n0.68\n0.54\n\nTable 5: Precision, Recall, and F-measure (with Random Forests) of FAM when trained and tested on dataset from the same year in family,\npackage, and class modes.\n\nall, we find that abstraction to classes only slightly improves\nover package mode.\nTake-Away. Although we discuss in more detail the performance of the FAM variant vs the standard M A M A D ROID in\nSection 6.3, we can already observe that the former does not\nyield as robust of a model, mostly due to the fact that in some\ncases no abstracted API calls occur more in malware than benign samples.\n\n6.2\n\nNewer training, older testing. We also evaluate the opposite\n\nsetting, i.e., training FAM with newer datasets, and checking\nwhether it is able to detect malware developed years before.\nSpecifically, Figure 15 report results when training FAM with\nsamples from a given year, and testing it with others that are\nup to 4 years older showing that F-measure range from 0.69\nto 0.92 in family mode, 0.65 to 0.94 in package mode, and\n0.66 to 0.97 in class mode. Recall that in family mode, FAM\nis unable to build a model when drebin and 2013 are used\nfor training, thus, effecting the overall result. This effect is\nminimal in this setting since the training sets are newer than\nthe test sets, thus, the drebin dataset is not used to evaluate\nany dataset while the 2013 dataset is used in only one setting\ni.e., when the training set is one year newer than the test set.\n\nDetection Over Time\n\nOnce again, we evaluate the detection accuracy over time, i.e.,\nwe train FAM using older samples and test it with newer samples and vice versa. We report the F-measure as the average of the F-measure over multiple dataset combinations; e.g.,\nwhen training with newer samples and testing on older samples, the F-measure after three years is the average of the Fmeasure when training with (2015, newbenign) and (2016,\nnewbenign) respectively, and testing on drebin and 2013.\nOlder training, newer testing. In Figure 14(a), we show the Fmeasure when FAM operates in family mode and is trained\nwith datasets that are older than the classified datasets. The\nx-axis reports the difference in years between training and test\ndata. We obtain an F-measure of 0.97 when training with samples that are one year older than the samples in the testing\nset. As mentioned in Section 6.1, there is no result when the\ndrebin and 2013 datasets are used for training, hence, after 3\nyears the F-measure is 0. In package mode, the F-measure is\n0.81 after one year, and 0.76 after two (Figure 14(b)). Whereas\nin class mode, the F-measure after one and two years are 0.85\nand 0.70 respectively (Figure 14(c)).\nWhile FAM appears to perform better in family mode than\nin package and class modes, note that the detection accuracy\nafter one and two years in family mode does not include results\nwhen the training set is (drebin, oldbenign) or (2013,\noldbenign) (cf Section 6.1). We believe this is as a result of\nFAM performing best when trained on the 2014 dataset in all\nmodes and performing poorly in package mode when trained\nwith (drebin, oldbenign) and (2013, oldbenign) due\nto limited features. For example, accuracy after two years\nis the average of the F-measure when training with (2014,\noldbenign/newbenign) datasets and testing on the 2016\ndataset. Whereas, in package mode, accuracy is the average Fmeasure obtained from training with (drebin, oldbenign),\n(2013, oldbenign), and (2014, oldbenign/newbenign)\ndatasets and testing with respectively, 2014, 2015, and 2016.\n\n6.3\n\nComparing Frequency\nMarkov Chain Model\n\nAnalysis\n\nvs.\n\nWe now compare the detection accuracy of FAM– a variant\nof M A M A D ROID that is based on a frequency analysis model\n– to the standard M A M A D ROID, which is based on a Markov\nchain model using the sequence of abstracted API calls.\nDetection Accuracy of malware from same year. In Table 6, we\n\nreport accuracy of FAM and M A M A D ROID when they are\ntrained and tested on samples from the same year using Random Forests in all modes. For completeness, we also report\nresults from D ROIDAPIM INER, showing that M A M A D ROID\noutperforms FAM and D ROIDAPIM INER in all tests. Both\nFAM and D ROIDAPIM INER performs best when trained\nand tested with (2014 and newbenign) with F-measures of\n0.89 (package mode) and 0.92, respectively. Overall, M A M A D ROID achieves higher F-measure compared to FAM\nand D ROIDAPIM INER due to both API call abstraction and\nMarkov chain modeling of the sequence of calls, which successfully captures the behavior of the app. In addition, M A M A D ROID is more robust as with some datasets, frequency\nanalysis fails to build a model with abstracted calls when the\nabstracted calls occur equally or more frequently in benign\nsamples.\nDetection Accuracy of malware from different years. We also\n\ncompare FAM with M A M A D ROID when they are trained and\ntested with datasets across several years. In Table 7, we report the F-measures, achieved by M A M A D ROID and FAM\nin package mode using Random Forests, and show how they\ncompare with D ROIDAPIM INER using two different sets of\n13\n\n\f1.0\n\n0.8\n\n0.8\n\n0.8\n\n0.6\n\n0.6\n\n0.6\n\n0.4\n0.2\n0.0\n\n0\n\n2\n\nYears\n\n3\n\n0.4\n0.2\n\nRF\n1-NN\n3-NN\n\n1\n\nF-measure\n\n1.0\n\nF-measure\n\nF-measure\n\n1.0\n\n0.0\n\n4\n\n0\n\n(a) family mode\n\n0.2\n\nRF\n1-NN\n3-NN\n\n1\n\n2\n\nYears\n\n3\n\n0.4\n\n0.0\n\n4\n\n0\n\nRF\n1-NN\n3-NN\n\n1\n\n(b) package mode\n\n2\n\nYears\n\n3\n\n4\n\n(c) class mode\n\n1.0\n\n1.0\n\n0.8\n\n0.8\n\n0.8\n\n0.6\n\n0.6\n\n0.6\n\n0.4\n0.2\n0.0\n\n0\n\n2\n\nYears\n(a) family mode\n\n3\n\n0.4\n0.2\n\nRF\n1-NN\n3-NN\n\n1\n\nF-measure\n\n1.0\n\nF-measure\n\nF-measure\n\nFigure 14: F-measure achieved by FAM using older samples for training and newer samples for testing. The x-axis shows the difference in\nyears between the training and test data.\n\n4\n\n0.0\n\n0\n\n0.2\n\nRF\n1-NN\n3-NN\n\n1\n\n2\n\nYears\n\n(b) package mode\n\n3\n\n0.4\n\n4\n\n0.0\n\n0\n\nRF\n1-NN\n3-NN\n\n1\n\n2\n\nYears\n\n3\n\n4\n\n(c) class mode\n\nFigure 15: F-measure achieved by FAM using newer samples for training and older samples for testing. The x-axis shows the difference in\nyears between the training and test data.\n\nexperiments. We report the results for package mode only because with both systems, when the training sets are older than\nthe test sets, package mode performs better than class mode\n(although, less than family mode, there are no results for FAM\nwith two of our training datasets in family mode) and only\nslightly lower when the training sets are newer than the test\nsets.\n\nusing samples comprising the newbenign and one of the three\nrecent malware datasets (2014, 2015, 2016) each, and testing on all malware datasets. In this setting, M A M A D ROID\noutperforms both FAM and D ROIDAPIM INER in all but one\nexperiment where FAM is only slightly better. Comparing\nD ROIDAPIM INER and FAM shows that D ROIDAPIM INER\nonly performs better than FAM in two out of 15 experiments.\nIn these two experiments, FAM was trained and tested on samples from the same year and resulted in a slightly lower precision, thus, increasing false positives.\nOverall, we find that the Markov chain based model\nachieves higher detection accuracy in both family and package\nmodes when M A M A D ROID is trained and tested on dataset\nfrom the same year (Table 6) and across several years (Table 7).\n\nIn the first set of experiments, we train M A M A D ROID,\nFAM, and D ROIDAPIM INER using samples comprising the\noldbenign and one of the three oldest malware datasets\n(drebin, 2013, 2014) each, and testing on all malware datasets. M A M A D ROID and FAM both outperform\nD ROIDAPIM INER in all experiments in this set, showing that\nabstracting the API calls improves the detection accuracy of\nour systems. FAM outperforms M A M A D ROID in nine out of\nthe 15 experiments, largely, when the training set comprises\nthe drebin/2013 and oldbenign datasets. Recall that when\ndrebin and 2013 malware datasets are used for training FAM\nin package mode, only five and two packages respectively, are\nused to build the model. It is possible that these packages\nare the principal components (as in PCA) that distinguishes\nmalware from benign samples. In the second set of experiments, we train M A M A D ROID, FAM, and D ROIDAPIM INER\n\n7\n\nRuntime Performance\n\nWe now analyze the runtime performance of M A M A D ROID\nand and the FAM variant, when operating in family, package,\nor class mode, as well as D ROIDAPIM INER. We run our experiments on a desktop with an 40-core 2.30GHz CPU and\n14\n\n\fF-measure\n\nXX Mode\nFamily\nPackage\nClass\nDataset XXX\nX FAM M A M A D ROID FAM M A M A D ROID FAM M A M A D ROID D ROIDAPIM INER\n\nXX\n\ndrebin, oldbenign\n2013, oldbenign\n2014, oldbenign\n2014, newbenign\n2015, newbenign\n2016, newbenign\n\n0.73\n0.87\n0.67\n0.50\n\n0.88\n0.92\n0.92\n0.98\n0.91\n0.89\n\n0.96\n0.97\n0.95\n0.99\n0.95\n0.92\n\n0.54\n0.55\n0.73\n0.89\n0.67\n0.53\n\n0.49\n0.58\n0.75\n0.89\n0.68\n0.54\n\n0.96\n0.97\n0.95\n0.99\n0.95\n0.92\n\n0.32\n0.36\n0.62\n0.92\n0.77\n0.36\n\nTable 6: F-measure of FAM and M A M A D ROID in all modes using Random Forests as well as, D ROIDAPIM INER [1] when trained and tested\non dataset from the same year.\nTesting Sets\ndrebin, oldbenign 2013, oldbenign\n2014, oldbenign\n2015, oldbenign\n2016, oldbenign\nTraining Sets\nDroid FAM MaMa Droid FAM MaMa Droid FAM MaMa Droid FAM MaMa Droid FAM MaMa\ndrebin,oldbenign 0.32 0.54 0.96\n0.35 0.50 0.96\n0.34 0.50 0.79\n0.30 0.50 0.42\n0.33 0.51 0.43\n2013,oldbenign\n0.33 0.90 0.93\n0.36 0.55 0.97\n0.35 0.95 0.74\n0.31 0.87 0.36\n0.33 0.82 0.29\n2014,oldbenign\n0.36 0.95 0.92\n0.39 0.99 0.93\n0.62 0.73 0.95\n0.33 0.81 0.79\n0.37 0.82 0.78\ndrebin, newbenign 2013, newbenign\n2014, newbenign\n2015, newbenign\n2016, newbenign\nTraining Sets\nDroid FAM MaMa Droid FAM MaMa Droid FAM MaMa Droid FAM MaMa Droid FAM MaMa\n2014,newbenign\n0.76 0.99 0.99\n0.75 0.99 0.99\n0.92 0.89 0.99\n0.67 0.86 0.89\n0.65 0.82 0.83\n2015,newbenign\n0.68 0.92 0.98\n0.68 0.84 0.98\n0.69 0.95 0.99\n0.77 0.67 0.95\n0.65 0.91 0.90\n2016,newbenign\n0.33 0.83 0.97\n0.35 0.69 0.97\n0.36 0.91 0.99\n0.34 0.86 0.93\n0.36 0.53 0.92\n\nTable 7: F-Measure of M A M A D ROID (MaMa) vs our variant using frequency analysis (FAM) vs D ROIDAPIM INER (Droid) [1].\n\nM A M A D ROID’s third step includes Markov chain modeling and feature vector extraction. With malicious samples, it\ntakes on average 0.2s±0.3, 2.5s±3.2, and 1.49s±2.39 (and\nat most 2.4s, 22.1s, and 46.10s), respectively, with families,\npackages, and classes, whereas, with benign samples, it takes\n0.6s±0.3, 6.7s±3.8, and 2.23s±2.74 (at most 1.7s, 18.4s, and\n43.98s). Finally, the last step is classification, and performance depends on both the machine learning algorithm employed and the mode of operation. More specifically, running\ntimes are affected by the number of features for the app to be\nclassified, and not by the initial dimension of the call graph, or\nby whether the app is benign or malicious. Regardless, in family mode, Random Forests, 1-NN, and 3-NN all take less than\n0.01s. With packages, it takes, respectively, 0.65s, 1.05s, and\n0.007s per app with 1-NN, 3-NN, Random Forests. Whereas,\nit takes, respectively, 1.02s, 1.65s, and 0.05s per app with 1NN, 3-NN, and Random Forests in class mode.\nOverall, when operating in family mode, malware and benign samples take on average, 10.7s and 27.3s respectively to\ncomplete the entire process, from call graph extraction to classification. In package mode, the average completion times\nfor malware and benign samples are 13.37s and 33.83s respectively. Whereas, in class mode, the average completion\ntimes are respectively, 21.7s and 41.12s for malware and benign apps. In both modes of operation, time is mostly (>80%)\nspent on call graph extraction.\n\n128GB of RAM, but only use 1 core and allocate 16GB of\nRAM for evaluation.\n\n7.1\n\nM A M A D ROID\n\nWe envision M A M A D ROID to be integrated in offline detection systems, e.g., run by the app store. Recall that M A M A D ROID consists of different phases, so in the following, we\nreview the computational overhead incurred by each of them,\naiming to assess the feasibility of real-world deployment.\nM A M A D ROID’s first step involves extracting the call graph\nfrom an apk and the complexity of this task varies significantly\nacross apps. On average, it takes 9.2s±14 (min 0.02s, max\n13m) to complete for samples in our malware sets. Benign\napps usually yield larger call graphs, and the average time\nto extract them is 25.4s±63 (min 0.06s, max 18m) per app.\nNext, we measure the time needed to extract call sequences\nwhile abstracting to families, packages or classes depending\non M A M A D ROID’s mode of operation. In family mode, this\nphase completes in about 1.3s on average (and at most 11.0s)\nwith both benign and malicious samples. Abstracting to packages takes slightly longer, due to the use of 341 packages in\nM A M A D ROID. On average, this extraction takes 1.67s±3.1\nfor malicious apps and 1.73s±3.2 for benign samples. Recall\nthat in class mode, after abstracting to classes, we cluster the\nclasses to a smaller set of labels due to its size. Therefore, in\nthis mode it takes on average, 5.84s±2.1 and 7.3s±4.2 respectively, to first abstract the calls from malware and benign apps\nto classes and 2.74s per app to build the co-occurrence matrix\nfrom which we compute the similarity between classes. Finally, clustering and abstracting each call to its corresponding\nclass label takes 2.38s and 3.4s respectively, for malware and\nbenign apps. In total, it takes 10.96s to abstract calls from\nmalware apps to their corresponding class labels and 13.44s\nfor benign apps.\n\n7.2\n\nFAM\n\nRecall that FAM is a variant of M A M A D ROID including three\nphases. The first one, API calls extraction, takes 0.7s±1.5\n(min 0.01s, max 28.4s) per app in our malware datasets and\n13.2s±22.2 (min 0.01s, max 222s) per benign app. The second phase includes API call abstraction, frequency analysis,\nand feature extraction. While API call abstraction is depen15\n\n\fdent on the dataset and the mode of operation, frequency analysis and feature extraction are only dependent on the mode\nof operation and are very fast in all modes. In particular, it\ntakes on average, 1.32s, 1.69s±3.2, and 5.86s±2.1 respectively, to complete a malware app in family, package, and class\nmodes. Whereas, it takes on average, 1.32s±3.1, 1.75s±3.2,\nand 7.32s±2.1 respectively, for a benign app in family, package, and class modes. The last phase which is classification is\nvery fast regardless of dataset, mode of operation, and classifier used. Specifically, it takes less than 0.01s to classify each\napp in all modes using the three different classifiers. Overall,\nit takes in total 2.02s, 2.39s, and 6.56s respectively, to classify\na malware app in family, package, and class modes. While\nwith benign apps, the total is 14.52s, 14.95s, and 20.52s respectively, in family, package, and class modes.\n\n7.3\n\nand Markov chains, discuss possible evasion techniques, and\nhighlight some limitations of our approach.\n\n8.1\n\nOur work yields important insights around the use of API calls\nin malicious apps, showing that, by abstracting the API calls\nto higher levels and modeling these abstracted calls, we can\nobtain high detection accuracy and retain it over several years\nwhich is crucial due to the continuous evolution of the Android\necosystem.\nAs discussed in Section 3, the use of API calls changes over\ntime, and in different ways across malicious and benign samples. From our newer datasets, which include samples up to\nSpring 2016 (API level 23), we observe that newer APIs introduce more packages, classes, and methods, while also deprecating some. Figure 7(a) shows that benign apps use more\ncalls than malicious ones developed around the same time. We\nalso notice an interesting trend in the use of Android (Figure 7(b)) and Google (Figure 7(c)) APIs: malicious apps follow the same trend as benign apps in the way they adopt certain APIs, but with a delay of some years. This might be a side\neffect of Android malware authors repackaging benign apps,\nadding their malicious functionalities onto them.\nGiven the frequent changes in the Android framework\nand the continuous evolution of malware, systems like\nD ROIDAPIM INER [1] – being dependent on the presence or\nthe use of certain API calls – become increasingly less effective with time. As shown in Table 3, malware that uses\nAPI calls released after those used by samples in the training\nset cannot be identified by these systems. On the contrary,\nas shown in Figure 10, M A M A D ROID detects malware samples that are 1 year newer than the training set obtaining an Fmeasure of 0.86 (as opposed to 0.46 with D ROIDAPIM INER)\nwhen the apps are modeled as Markov chains. After 2 years,\nthe value is still at 0.75 (0.42 with D ROIDAPIM INER), dropping to 0.51 after 4 years.\nWe argue that the effectiveness of M A M A D ROID’s classification remains relatively high “over the years” owing to the\nMarkov models capturing app’s behavior. These models tend\nto be more robust to malware evolution because abstracting to\ne.g., packages makes the system less susceptible to the introduction of new API calls. To verify this, we developed a variant of M A M A D ROID named FAM that abstracts API calls and\nis based on frequency analysis similar to D ROIDAPIM INER.\nAlthough, the addition of API call abstraction results in an\nimprovement of the detection accuracy of the system (an Fmeasure of 0.81 and 0.76 after one and two years respectively),\nit also resulted in scenarios where there are no API calls that\nare more frequently used in malware than benign apps.\nIn general, abstraction allows M A M A D ROID to capture\nnewer classes/methods added to the API, since these are abstracted to already-known families or packages. In case newer\npackages are added to the API, and these packages start being used by malware, M A M A D ROID only requires adding a\nnew state to the Markov chains, and probabilities of a transition from a state to this new state in old apps would be 0. In\n\nD ROIDAPIM INER\n\nFinally, we evaluate the runtime performance of\nD ROIDAPIM INER [1]. Its first step, i.e., extracting API\ncalls, takes 0.7s±1.5 (min 0.01s, max 28.4s) per app in our\nmalware datasets. Whereas, it takes on average 13.2s±22.2\n(min 0.01s, max 222s) per benign app. In the second phase,\ni.e., frequency and data flow analysis, it takes, on average, 4.2s\nper app. Finally, classification using 3-NN is very fast: 0.002s\non average. Therefore, in total, D ROIDAPIM INER takes\nrespectively, 17.4s and 4.9s for a complete execution on one\napp from our benign and malware datasets, which while faster\nthan M A M A D ROID, achieves significantly lower accuracy. In\ncomparison to M A M A D ROID, D ROIDAPIM INER takes 5.8s\nand 9.9s less on average to analyze and classify a malicious\nand benign app when M A M A D ROID operates in family mode\nand 8.47s and 16.43s less on average in package mode.\n\n7.4\n\nTake Away\n\nIn conclusion, our experiments show that our prototype implementation of M A M A D ROID is scalable enough to be deployed. Assuming that, everyday, a number of apps in the\norder of 10,000 are submitted to Google Play, and using the\naverage execution time of benign samples in family (27.3s),\npackage (33.83s), and class (41.12s) modes, we estimate that\nit would take less than an hour and a half to complete execution of all apps submitted daily in both modes, with just 64\ncores. Note that we could not find accurate statistics reporting the number of apps submitted everyday, but only the total\nnumber of apps on Google Play.11 On average, this number\nincreases of a couple of thousands per day, and although we\ndo not know how many apps are removed, we believe 10,000\napps submitted every day is likely an upper bound.\n\n8\n\nLessons Learned\n\nDiscussion\n\nWe now discuss the implications of our results with respect to\nthe feasibility of modeling app behavior using static analysis\n11 http://www.appbrain.com/stats/number-of-android-apps\n\n16\n\n\freality though, methods and classes are more frequently added\nthan packages with new API releases. Hence, we also evaluate whether M A M A D ROID still performs as well as in package\nmode when we abstract an API call to class and measure the\noverall overhead increase. Results from Figure 14, 15, and 12\nindicate that finer-grained abstraction is less effective as time\npasses when older samples are used for training and newer\nsamples for testing, while they are more effective when samples from the same year or newer than the test sets are used\nfor training. However, while all three modes of abstraction\nperforms relatively well, we believe abstraction to packages\nis the most effective as it generally performs better than family – though less lightweight – and as well as class but more\nefficient.\n\n8.2\n\nmodeled, as it is not Java and is not processed by Soot. These\nlimitations are not specific of M A M A D ROID, but are a problem of static analysis in general, which can be mitigated by\nusing M A M A D ROID alongside dynamic analysis techniques.\nAnother approach could be using dynamic dispatch so that\na class X in package A is created to extend class Y in package\nB with static analysis reporting a call to root() defined in Y as\nX.root(), whereas, at runtime Y.root() is executed. This can be\naddressed, however, with a small increase in M A M A D ROID’s\ncomputational cost, by keeping track of self-defined classes\nthat extend or implement classes in the recognized APIs, and\nabstract polymorphic functions of this self-defined class to the\ncorresponding recognized package, while, at the same time,\nabstracting as self-defined overridden functions in the class.\nFinally, identifier mangling and other forms of obfuscation\ncould be used aiming to obfuscate code and hide malicious actions. However, since classes in the Android framework cannot be obfuscated by obfuscation tools, malware developers\ncan only do so for self-defined classes. M A M A D ROID labels\nobfuscated calls as obfuscated so, ultimately, these would\nbe captured in the behavioral model (and the Markov chain)\nfor the app. In our sample, we observe that benign apps use\nsignificantly less obfuscation than malicious apps, indicating\nthat obfuscating a significant number of classes is not a good\nevasion strategy since this would likely make the sample more\neasily identifiable as malicious. Malware developers might\nalso attempt to evade M A M A D ROID by naming their selfdefined packages in such a way that they look similar to that of\nthe android or google APIs, e.g., java.lang.reflect.malware\nis easily prevented by first abstracting to classes before abstracting to any further modes as we already do in Section 5.\n\nEvasion\n\nNext, we discuss possible evasion techniques and how they\ncan be addressed. One straightforward evasion approach could\nbe to repackage a benign app with small snippets of malicious\ncode added to a few classes. However, it is difficult to embed malicious code in such a way that, at the same time, the\nresulting Markov chain looks similar to a benign one. For\ninstance, our running example from Section 2 (malware posing as a memory booster app and executing unwanted commands as root) is correctly classified by M A M A D ROID; although most functionalities in this malware are the same as\nthe original app, injected API calls generate some transitions\nin the Markov chain that are not typical of benign samples.\nThe opposite procedure, i.e., embedding portions of benign\ncode into a malicious app, is also likely ineffective against\nM A M A D ROID, since, for each app, we derive the feature vector from the transition probability between calls over the entire\napp. A malware developer would have to embed benign code\ninside the malware in such a way that the overall sequence of\ncalls yields similar transition probabilities as those in a benign\napp, but this is difficult to achieve because if the sequences of\ncalls have to be different (otherwise there would be no attack),\nthen the models will also be different.\nAn attacker could also try to create an app with a similar\nMarkov chain to that of a benign app. Because this is derived\nfrom the sequence of abstracted API calls in the app, it is actually very difficult to create sequences resulting in Markov\nchains similar to benign apps while, at the same time, actually\nengaging in malicious behavior.\nMoreover, attackers could try using reflection, dynamic\ncode loading, or native code [42]. Because M A M A D ROID\nuses static analysis, it fails to detect malicious code when it\nis loaded or determined at runtime. However, M A M A D ROID\ncan detect reflection when a method from the reflection package (java.lang.reflect) is executed. Therefore, we obtain\nthe correct sequence of calls up to the invocation of the reflection call, which may be sufficient to distinguish between\nmalware and benign apps. Similarly, M A M A D ROID can detect the usage of class loaders and package contexts that can be\nused to load arbitrary code, but it is not able to model the code\nloaded; likewise, native code that is part of the app cannot be\n\n8.3\n\nLimitations\n\nM A M A D ROID requires a sizable amount of memory in order\nto perform classification, when operating in package mode,\nworking on more than 100,000 features per sample. The quantity of features, however, can be further reduced using feature\nselection algorithms such as PCA. As explained in Section 6\nwhen we use 10 components from the PCA the system performs almost as well as the one using all the features; however, using PCA comes with a much lower memory complexity in order to run the machine learning algorithms, because\nthe number of dimensions of the features space where the classifier operates is remarkably reduced.\nSoot [51], which we use to extract call graphs, fails to analyze some apks. In fact, we were not able to extract call graphs\nfor a fraction (4.6%) of the apps in the original datasets due to\nscripts either failing to apply the jb phase, which is used to\ntransform Java bytecode to the primary intermediate representation (i.e., jimple) of Soot or not able to open the apk. Even\nthough this does not really affect the results of our evaluation,\none could avoid it by using a different/custom intermediate\nrepresentation for the analysis or use different tools to extract\nthe call graphs.\nIn general, static analysis methodologies for malware detection on Android could fail to capture the runtime environment\n17\n\n\fcontext, code that is executed more frequently, or other effects\nstemming from user input [4]. These limitations can be addressed using dynamic analysis, or by recording function calls\non a device. Dynamic analysis observes the live performance\nof the samples, recording what activity is actually performed\nat runtime. Through dynamic analysis, it is also possible to\nprovide inputs to the app and then analyze the reaction of the\napp to these inputs, going beyond static analysis limits. To this\nend, we plan to integrate dynamic analysis to build the models\nused by M A M A D ROID as part of future work.\n\n9\n\nthis still takes a non-negligible toll on battery life. Recently,\nhybrid systems like IntelliDroid [55] have also been proposed\nthat use input generators, producing inputs specific to dynamic\nanalysis tools. Other work combining static and dynamic analysis include [23, 28, 58, 7].\n\n9.2\n\nA number of techniques have used signatures for Android\nmalware detection. NetworkProfiler [16] generates network\nprofiles for Android apps and extracts fingerprints based on\nsuch traces, ASTROID [20] used common subgraphs among\nsamples as signatures for identifying unknown malware samples, while work in [10] obtains resource-based metrics (CPU,\nmemory, storage, network) to distinguish malware activity\nfrom benign one. [13] extract statistical features, such as permissions and API calls, and extend their vectors to add dynamic behavior-based features. While their experiments show\nthat their solution outperforms, in terms of accuracy, other antivirus systems, [13] indicate that the quality of their detection\nmodel critically depends on the availability of representative\nbenign and malicious apps for training. MADAM [46] also\nextract features at four layers which are used to build a behavioral model for apps and uses two parallel classifier to detect malware. Similarly, ScanMe Mobile [64] uses the Google\nCloud Messaging Service (GCM) to perform static and dynamic analysis on apks found on the device’s SD card. While,\nTriFlow [37] rank apps based on potential risks by using the\nobserved and possible information flows in the apps.\nThe sequences of system calls have also been used to detect\nmalware in both desktop and Android environments. Hofmeyr\net al. [27] demonstrate that short sequences of system calls\ncan be used as a signature to discriminate between normal and\nabnormal behavior of common UNIX programs. Signaturebased methods, however, can be evaded using polymorphism\nand obfuscation, as well as by call re-ordering attacks [33],\neven though quantitative measures, such as similarity analysis, can be used to address some of these attacks [48]. M A M A D ROID inherits the spirit of these approaches, proposing\na statistical method to model app behavior that is more robust\nagainst evasion attempts.\nIn the Android context, [9] use the sequences of three system calls (extracted from the execution traces of apps under\nanalysis) to detect malware. This approach models specific\nmalware families, aiming to identify additional samples belonging to such families. In contrast, M A M A D ROID’s goal is\nto detect previously-unseen malware, and we also show that\nour system can detect new malware families that even appear\nyears after the system has been trained. In addition, using strict\nsequences of system or API calls can be easily evaded by malware authors who could add unnecessary calls to effectively\nevade detection. Conversely, M A M A D ROID builds a behavioral model of an Android app, which makes it robust to this\ntype of evasion.\nDynamic analysis has also been applied to detect Android\nmalware by using predefined scripts of common inputs that\nwill be performed when the device is running. However, this\n\nRelated Work\n\nOver the past few years, Android security has attracted a\nwealth of work by the research community. In this section,\nwe review (i) program analysis techniques focusing on general security properties of Android apps, and then (ii) systems\nthat specifically target malware on Android.\n\n9.1\n\nAndroid Malware Detection\n\nProgram Analysis\n\nPrevious work on program analysis applied to Android security has used both static and dynamic analysis. With the former, the program’s code is decompiled in order to extract features without actually running the program, usually employing tools such as Dare [41] to obtain Java bytecode. The latter\ninvolves real-time execution of the program, typically in an\nemulated or protected environment.\nStatic analysis techniques include work by Felt et al. [19],\nwho analyze API calls to identify over-privileged apps, while\nKirin [18] is a system that examines permissions requested by\napps to perform a lightweight certification, using a set of security rules that indicate whether or not the security configuration bundled with the app is safe. RiskRanker [26] aims to\nidentify zero-day Android malware by assessing potential security risks caused by untrusted apps. It sifts through a large\nnumber of apps from Android markets and examines them to\ndetect certain behaviors, such as encryption and dynamic code\nloading, which form malicious patterns and can be used to detect stealthy malware. Other methods, such as CHEX [34],\nuse data flow analysis to automatically vet Android apps for\nvulnerabilities. Static analysis has also been applied to the detection of data leaks and malicious data flows from Android\napps [5, 32, 62, 31].\nDroidScope [59] and TaintDroid [17] monitor run-time app\nbehavior in a protected environment to perform dynamic taint\nanalysis. DroidScope performs dynamic taint analysis at the\nmachine code level, while TaintDroid monitors how thirdparty apps access or manipulate users’ personal data, aiming\nto detect sensitive data leaving the system. However, as it is\nunrealistic to deploy dynamic analysis techniques directly on\nusers’ devices, due to the overhead they introduce, these are\ntypically used offline [45, 67, 49]. ParanoidAndroid [44] employs a virtual clone of the smartphone, running in parallel\nin the cloud and replaying activities of the device – however,\neven if minimal execution traces are actually sent to the cloud,\n18\n\n\fmight be inadequate due to the low probability of triggering\nmalicious behavior, and can be side-stepped by knowledgeable adversaries, as suggested by Wong and Lie [55]. Other\napproaches include random fuzzing [35, 63] and concolic testing [2, 24]. Dynamic analysis can only detect malicious activities if the code exhibiting malicious behavior is actually running during the analysis. Moreover, according to [53], mobile\nmalware authors often employ emulation or virtualization detection strategies to change malware behavior and eventually\nevade detection.\nMachine learning techniques have also been applied to assist Android malware detection. Droidmat [57] uses API call\ntracing and manifest files to learn features for malware detection, Teufl et al. [50] apply knowledge discovery processes and\nlean statistical methods on app metadata extracted from the\napp market, while [22] rely on embedded call graphs. DroidMiner [60] studies the program logic of sensitive Android/Java\nframework API functions and resources, and detects malicious\nbehavior patterns. MAST [12] statically analyzes apps using\nfeatures such as permissions, presence of native code, and intent filters and measures the correlation between multiple qualitative data. Crowdroid [8] relies on crowdsourcing to distinguish between malicious and benign apps by monitoring system calls. AppContext [61] models security-sensitive behavior, such as activation events or environmental attributes, and\nuses SVM to classify these behaviors, while RevealDroid [21]\nemploys supervised learning and obfuscation-resilient methods targeting API usage and intent actions to identify their\nfamilies.\nD REBIN [4] deduces detection patterns and identifies malicious software directly on the device, performing a broad static\nanalysis. This is achieved by gathering numerous features\nfrom the manifest file as well as the app’s source code (API\ncalls, network addresses, permissions). Malevolent behavior\nis reflected in patterns and combinations of extracted features\nfrom the static analysis: for instance, the existence of both\nSEND SMS permission and the android.hardware.telephony\ncomponent in an app might indicate an attempt to send premium SMS messages, and this combination can eventually\nconstitute a detection pattern.\nIn Section 4.5,\nwe have compared against\nD ROIDAPIM INER [1]. This system relies on the top169 API calls that are used more frequently in the malware\nthan in the benign set, along with data flow analysis on calls\nthat are frequent in both benign and malicious apps, but occur\nup to 6% more in the latter. As shown in our evaluation, using\nthe most common calls observed during training requires\nconstant retraining, due to the evolution of both malware\nand the Android API. On the contrary, M A M A D ROID can\neffectively model both benign and malicious Android apps,\nand perform an efficient classification on them. Compared to\nD ROIDAPIM INER, our approach is more resilient to changes\nin the Android framework than D ROIDAPIM INER, resulting\nin a less frequent need to re-train the classifier.\nOverall, compared to state-of-the-art systems like\nD REBIN [4] and D ROIDAPIM INER [1], M A M A D ROID\n\nis more generic and robust as its statistical modeling does not\ndepend on specific app characteristics, but can actually be run\non any app created for any Android API level.\nFinally, also related to M A M A D ROID are Markov-chain\nbased models for Android malware detection. [14] dynamically analyze system- and developer-defined actions from intent messages (used by app components to communicate with\neach other at runtime), and probabilistically estimate whether\nan app is performing benign or malicious actions at run time,\nbut obtain low accuracy overall. Canfora et al. [11] use a\nHidden Markov model (HMM) to identify malware samples\nbelonging to previously observed malware families, whereas,\nM A M A D ROID can detect previously unseen malware, not relying on specific malware families.\n\n10\n\nConclusion\n\nThis paper presented M A M A D ROID, an Android malware detection system that is based on modeling the sequences of API\ncalls as Markov chains. Our system is designed to operate in\none of three modes, with different granularities, by abstracting API calls to either families, packages or classes. We ran\nan extensive experimental evaluation using, to the best of our\nknowledge, the largest malware dataset in an Android malware detection research paper, and aiming at assessing both\nthe accuracy of the classification (using F-measure, precision,\nand recall) and runtime performances. We showed that M A M A D ROID effectively detects unknown malware samples developed around the same time as the samples on which it is\ntrained (F-measure up to 0.99). It also maintains good detection performance: one year after the model has been trained\nwith a F-measure of 0.86, and 0.75 after two years.\nWe compared M A M A D ROID to D ROIDAPIM INER [1], a\nstate-of-the-art system based on API calls frequently used by\nmalware, showing that, not only does M A M A D ROID outperforms D ROIDAPIM INER when trained and tested on datasets\nfrom the same year, but that it is also much more resilient over\nthe years to changes in the Android API. We also developed\na variant of M A M A D ROID, called FAM, that performs API\ncall abstraction but is based on frequency analysis to evaluate whether M A M A D ROID’s high detection accuracy is based\nsolely on the abstraction. We found that FAM improves on\nD ROIDAPIM INER but, while abstraction is important for high\ndetection rate and resilience to API changes, abstraction and a\nmodeling approach based on frequency analysis is not as robust as M A M A D ROID, especially in scenarios where API calls\nare not more frequent in malware than in benign apps.\nOverall, our results demonstrate that statistical behavioral\nmodels introduced by M A M A D ROID—in particular, abstraction and Markov chain modeling of API call sequence—are\nmore robust than traditional techniques, highlighting how our\nwork can form the basis of more advanced detection systems\nin the future. As part of future work, we plan to further investigate the resilience to possible evasion techniques, focusing\non repackaged malicious apps as well as injection of API calls\nto maliciously alter Markov models. We also plan to explore\n19\n\n\fthe possibility of seeding the behavioral modeling performed\nby M A M A D ROID with dynamic instead of static analysis.\nAcknowledgments. We wish to thank Yousra Aafer for sharing\nthe D ROIDAPIM INER source code and Yanick Fratantonio for\nhis comments on an early draft of the paper. This research was\nsupported by the EPSRC under grant EP/N008448/1, by an\nEPSRC-funded “Future Leaders in Engineering and Physical\nSciences” award, a Xerox University Affairs Committee grant,\nand by a small grant from GCHQ. Enrico Mariconti was supported by the EPSRC under grant 1490017, while Lucky Onwuzurike was funded by the Petroleum Technology Development Fund (PTDF).\n\n[12] S. Chakradeo, B. Reaves, P. Traynor, and W. Enck. MAST:\nTriage for Market-scale Mobile Malware Analysis. In ACM\nConference on Security and Privacy in Wireless and Mobile\nNetworks (WiSec), 2013.\n[13] S. Chen, M. Xue, Z. Tang, L. Xu, and H. Zhu. StormDroid: A\nStreaminglized Machine Learning-Based System for Detecting\nAndroid Malware. In ACM Asia Conference on Computer and\nCommunications Security (AsiaCCS), 2016.\n[14] Y. Chen, M. Ghorbanzadeh, K. Ma, C. Clancy, and R. McGwier. A hidden Markov model detection of malicious Android\napplications at runtime. In Wireless and Optical Communication Conference (WOCC), 2014.\n[15] J. Clay. Continued Rise in Mobile Threats for 2016. http://blog.\ntrendmicro.com/continued-rise-in-mobile-threats-for-2016/,\n2016.\n\nReferences\n\n[16] S. Dai, A. Tongaonkar, X. Wang, A. Nucci, and D. Song.\nNetworkProfiler: Towards automatic fingerprinting of Android\napps. In IEEE International Conference on Computer Communications (INFOCOM), 2013.\n\n[1] Y. Aafer, W. Du, and H. Yin. DroidAPIMiner: Mining APILevel Features for Robust Malware Detection in Android. In\nInternational Conference on Security and Privacy in Communication Networks (SecureComm), 2013.\n\n[17] W. Enck, P. Gilbert, S. Han, V. Tendulkar, B.-G. Chun, L. P.\nCox, J. Jung, P. McDaniel, and A. N. Sheth. TaintDroid: An\nInformation-Flow Tracking System for Realtime Privacy Monitoring on Smartphones. ACM Transactions on Computer Systems, 32(2), 2014.\n\n[2] S. Anand, M. Naik, M. J. Harrold, and H. Yang. Automated\nConcolic Testing of Smartphone Apps. In ACM Symposium on\nthe Foundations of Software Engineering (FSE), 2012.\n[3] P. Andriotis, M. A. Sasse, and G. Stringhini. Permissions snapshots: Assessing users’ adaptation to the android runtime permission model. In IEEE Workshop on Information Forensics\nand Security (WIFS), 2016.\n\n[18] W. Enck, M. Ongtang, and P. McDaniel. On Lightweight Mobile Phone Application Certification. In ACM Conference on\nComputer and Communications Security (CCS), 2009.\n\n[4] D. Arp, M. Spreitzenbarth, M. Hubner, H. Gascon, and\nK. Rieck. DREBIN: Effective and Explainable Detection of\nAndroid Malware in Your Pocket. In Annual Symposium on\nNetwork and Distributed System Security (NDSS), 2014.\n\n[19] A. P. Felt, E. Chin, S. Hanna, D. Song, and D. Wagner. Android\nPermissions Demystified. In ACM Conference on Computer\nand Communications Security (CCS), 2011.\n[20] Y. Feng, O. Bastani, R. Martins, I. Dillig, and S. Anand. Automated synthesis of semantic malware signatures using maximum satisfiability. In Annual Symposium on Network and Distributed System Security (NDSS), 2017.\n\n[5] S. Arzt, S. Rasthofer, C. Fritz, E. Bodden, A. Bartel, J. Klein,\nY. Le Traon, D. Octeau, and P. McDaniel. FlowDroid: Precise Context, Flow, Field, Object-sensitive and Lifecycle-aware\nTaint Analysis for Android Apps. In ACM SIGPLAN Conference on Programming Language Design and Implementation\n(PLDI), 2014.\n[6] S. Bernard, S. Adam, and L. Heutte. Using random forests for\nhandwritten digit recognition. In Ninth International Conference on Document Analysis and Recognition, 2007.\n\n[21] J. Garcia, M. Hammad, B. Pedrood, A. Bagheri-Khaligh, and\nS. Malek. Obfuscation-resilient, efficient, and accurate detection and family identification of android malware. Department\nof Computer Science, George Mason University, Tech. Rep,\n2015.\n\n[7] R. Bhoraskar, S. Han, J. Jeon, T. Azim, S. Chen, J. Jung,\nS. Nath, R. Wang, and D. Wetherall. Brahmastra: Driving Apps\nto Test the Security of Third-Party Components. In USENIX\nSecurity Symposium, 2014.\n\n[22] H. Gascon, F. Yamaguchi, D. Arp, and K. Rieck. Structural Detection of Android Malware Using Embedded Call Graphs. In\nACM Workshop on Artificial Intelligence and Security (AISec),\n2013.\n\n[8] I. Burguera, U. Zurutuza, and S. Nadjm-Tehrani. Crowdroid:\nBehavior-based Malware Detection System for Android. In\nACM Workshop on Security and Privacy in Smartphones and\nMobile Devices (SPSM), 2011.\n\n[23] X. Ge, K. Taneja, T. Xie, and N. Tillmann. DyTa: Dynamic\nSymbolic Execution Guided with Static Verification Results.\nIn International Conference on Software Engineering (ICSE),\n2011.\n\n[9] G. Canfora, E. Medvet, F. Mercaldo, and C. A. Visaggio. Detecting Android Malware Using Sequences of System Calls. In\nWorkshop on Software Development Lifecycle for Mobile, 2015.\n\n[24] P. Godefroid, N. Klarlund, and K. Sen. DART: Directed Automated Random Testing. ACM SIGPLAN Notices, 40(6), 2005.\n[25] M. I. Gordon, D. Kim, J. H. Perkins, L. Gilham, N. Nguyen,\nand M. C. Rinard. Information Flow Analysis of Android Applications in DroidSafe. In Annual Symposium on Network and\nDistributed System Security (NDSS), 2015.\n\n[10] G. Canfora, E. Medvet, F. Mercaldo, and C. A. Visaggio. Acquiring and Analyzing App Metrics for Effective Mobile Malware Detection. In International Workshop on Security and Privacy Analytics (IWSPA), 2016.\n\n[26] M. Grace, Y. Zhou, Q. Zhang, S. Zou, and X. Jiang.\nRiskRanker: Scalable and Accurate Zero-day Android Malware\nDetection. In International Conference on Mobile Systems, Applications, and Services (MobiSys), 2012.\n\n[11] G. Canfora, F. Mercaldo, and C. A. Visaggio. An HMM and\nStructural Entropy based Detector for Android malware: An\nEmpirical Study. Computers & Security, 61, 2016.\n\n20\n\n\f[45] V. Rastogi, Y. Chen, and X. Jiang. DroidChameleon: Evaluating Android Anti-malware Against Transformation Attacks. In\nACM Asia Conference on Computer and Communications Security (AsiaCCS), 2013.\n\n[27] S. A. Hofmeyr, S. Forrest, and A. Somayaji. Intrusion detection\nusing sequences of system calls. Journal of Computer Security,\n6(3), 1998.\n[28] Y. Z. X. Jiang. Detecting passive content leaks and pollution\nin android applications. In Annual Symposium on Network and\nDistributed System Security (NDSS), 2013.\n\n[46] A. Saracino, D. Sgandurra, G. Dini, and F. Martinelli. Madam:\nEffective and efficient behavior-based android malware detection and prevention. IEEE Transactions on Dependable and\nSecure Computing, 2016.\n\n[29] I. Jolliffe. Principal Component Analysis. John Wiley & Sons,\n2002.\n\n[47] B. P. Sarma, N. Li, C. Gates, R. Potharaju, C. Nita-Rotaru,\nand I. Molloy. Android Permissions: A Perspective Combining Risks and Benefits. In ACM Symposium on Access Control\nModels and Technologies (SACMAT), 2012.\n\n[30] M. J. Kearns. The Computational Complexity of Machine\nLearning. MIT press, 1990.\n[31] J. Kim, Y. Yoon, K. Yi, J. Shin, and S. Center. ScanDal: Static\nanalyzer for detecting privacy leaks in android applications. In\nMoST, 2012.\n\n[48] M. K. Shankarapani, S. Ramamoorthy, R. S. Movva, and\nS. Mukkamala. Malware detection using assembly and API call\nsequences. Journal in Computer Virology, 7(2), 2011.\n\n[32] W. Klieber, L. Flynn, A. Bhosale, L. Jia, and L. Bauer. Android\nTaint Flow Analysis for App Sets. In SOAP, 2014.\n\n[49] K. Tam, S. J. Khan, A. Fattori, and L. Cavallaro. CopperDroid:\nAutomatic Reconstruction of Android Malware Behaviors. In\nAnnual Symposium on Network and Distributed System Security\n(NDSS), 2015.\n\n[33] C. Kolbitsch, P. M. Comparetti, C. Kruegel, E. Kirda, X.-y.\nZhou, and X. Wang. Effective and Efficient Malware Detection at the End Host. In USENIX security symposium, 2009.\n\n[50] P. Teufl, M. Ferk, A. Fitzek, D. Hein, S. Kraxberger, and C. Orthacker. Malware detection by applying knowledge discovery processes to application metadata on the Android Market\n(Google Play). Security and Communication Networks, 9(5),\n2016.\n\n[34] L. Lu, Z. Li, Z. Wu, W. Lee, and G. Jiang. CHEX: Statically\nVetting Android Apps for Component Hijacking Vulnerabilities. In ACM Conference on Computer and Communications\nSecurity (CCS), 2012.\n[35] A. Machiry, R. Tahiliani, and M. Naik. Dynodroid: An Input Generation System for Android Apps. In Joint Meeting on\nFoundations of Software Engineering (ESEC/FSE), 2013.\n\n[51] R. Vallée-Rai, P. Co, E. Gagnon, L. Hendren, P. Lam, and\nV. Sundaresan. Soot - a Java Bytecode Optimization Framework. In Conference of the Centre for Advanced Studies on\nCollaborative Research, 1999.\n\n[36] E. Mariconti, L. Onwuzurike, P. Andriotis, E. De Cristofaro,\nG. Ross, and G. Stringhini. MaMaDroid: Detecting Android\nMalware by Building Markov Chains of Behavioral Models. In\nAnnual Symposium on Network and Distributed System Security\n(NDSS), 2017.\n\n[52] D. Venkatesan.\nAndroid.Bankosy: All ears on voice\ncall-based 2FA.\nhttp://www.symantec.com/connect/blogs/\nandroidbankosy-all-ears-voice-call-based-2fa, 2016.\n[53] T. Vidas and N. Christin. Evading android runtime analysis via\nsandbox detection. In ACM Asia Conference on Computer and\nCommunications Security (AsiaCCS), 2014.\n\n[37] O. Mirzaei, G. Suarez-Tangil, J. Tapiador, and J. M. de Fuentes.\nTriflow: Triaging android applications using speculative information flows. In ACM Asia Conference on Computer and Communications Security (AsiaCCS), 2017.\n\n[54] N. Viennot, E. Garcia, and J. Nieh. A measurement study of\ngoogle play. ACM SIGMETRICS Performance Evaluation Review, 42(1), 2014.\n\n[38] D. Morris. An Extremely Convincing WhatsApp Fake Was\nDownloaded More Than 1 Million Times From Google Play.\nhttp://fortune.com/2017/11/04/whatsapp-fake-google-play/,\n2017.\n\n[55] M. Y. Wong and D. Lie. IntelliDroid: A Targeted Input Generator for the Dynamic Analysis of Android Malware. In Annual Symposium on Network and Distributed System Security\n(NDSS), 2016.\n\n[39] J. R. Norris. Markov chains. Cambridge University Press, 1998.\n[40] J. Oberheide and C. Miller. Dissecting the Android Bouncer. In\nSummerCon, 2012.\n\n[56] B. Woods. Google Play has hundreds of Android apps\nthat contain malware. http://www.trustedreviews.com/news/\nmalware-apps-downloaded-google-play, 2016.\n\n[41] D. Octeau, S. Jha, and P. McDaniel. Retargeting Android Applications to Java Bytecode. In ACM Symposium on the Foundations of Software Engineering (FSE), 2012.\n\n[57] D.-J. Wu, C.-H. Mao, T.-E. Wei, H.-M. Lee, and K.-P. Wu.\nDroidMat: Android Malware Detection through Manifest and\nAPI Calls Tracing. In Asia JCIS, 2012.\n\n[42] S. Poeplau, Y. Fratantonio, A. Bianchi, C. Kruegel, and G. Vigna. Execute This! Analyzing Unsafe and Malicious Dynamic\nCode Loading in Android Applications. In Annual Symposium\non Network and Distributed System Security (NDSS), 2014.\n\n[58] M. Xia, L. Gong, Y. Lyu, Z. Qi, and X. Liu. Effective RealTime Android Application Auditing. In IEEE Symposium on\nSecurity and Privacy (S&P), 2015.\n\n[43] I. Polakis, M. Diamantaris, T. Petsas, F. Maggi, and S. Ioannidis. Powerslave: Analyzing the Energy Consumption of Mobile\nAntivirus Software. In DIMVA, 2015.\n\n[59] L. K. Yan and H. Yin. DroidScope: Seamlessly Reconstructing the OS and Dalvik Semantic Views for Dynamic Android\nMalware Analysis. In USENIX Security Symposium, 2012.\n\n[44] G. Portokalidis, P. Homburg, K. Anagnostakis, and H. Bos.\nParanoid Android: Versatile Protection for Smartphones. In\nAnnual Computer Security Applications Conference (ACSAC),\n2010.\n\n[60] C. Yang, Z. Xu, G. Gu, V. Yegneswaran, and P. Porras. Droidminer: Automated mining and characterization of fine-grained\nmalicious behaviors in Android applications. In European Symposium on Research in Computer Security (ESORICS), 2014.\n\n21\n\n\fCloud-based Android Malware Analysis Service. SIGAPP Applied Computing Review, 16(1), 2016.\n\n[61] W. Yang, X. Xiao, B. Andow, S. Li, T. Xie, and W. Enck. AppContext: Differentiating Malicious and Benign Mobile App\nBehaviors Using Context. In International Conference on Software Engineering (ICSE), 2015.\n\n[65] N. Zhang, K. Yuan, M. Naveed, X. Zhou, and X. Wang. Leave\nme alone: App-level protection against runtime information\ngathering on Android. In IEEE Symposium on Security and\nPrivacy (S&P), 2015.\n\n[62] Z. Yang, M. Yang, Y. Zhang, G. Gu, P. Ning, and X. S. Wang.\nAppIntent: Analyzing Sensitive Data Transmission in Android\nfor Privacy Leakage Detection. In ACM Conference on Computer and Communications Security (CCS), 2013.\n\n[66] Y. Zhou and X. Jiang. Dissecting Android Malware: Characterization and Evolution. In IEEE Symposium on Security and\nPrivacy (S&P), 2012.\n\n[63] H. Ye, S. Cheng, L. Zhang, and F. Jiang. DroidFuzzer: Fuzzing\nthe Android Apps with Intent-Filter Tag. In International Conference on Advances in Mobile Computing and Multimedia\n(MoMM), 2013.\n\n[67] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang. Hey, You, Get Off of\nMy Market: Detecting Malicious Apps in Official and Alternative Android Markets. In Annual Symposium on Network and\nDistributed System Security (NDSS), 2012.\n\n[64] H. Zhang, Y. Cole, L. Ge, S. Wei, W. Yu, C. Lu, G. Chen,\nD. Shen, E. Blasch, and K. D. Pham. ScanMe Mobile: A\n\n22\n\n\f",
         "train",
         "111655",
         "18376"
        ],
        [
         "41",
         "19606",
         "cs.AI",
         "Artificial Intelligence",
         "1712.04443v1.pdf",
         "arXiv:1712.04443v1 [cs.SI] 12 Dec 2017\n\nSequential Prediction of Social Media Popularity with\nDeep Temporal Context Networks\nBo Wu1,2 , Wen-Huang Cheng3 , Yongdong Zhang1,2 , Qiushi Huang4 , Jintao Li1 , Tao Mei5\n1\nInstitute of Computing Technology, Chinese Academy of Sciences, China\n2\nUniversity of Chinese Academy of Sciences, China\n3\nAcademia Sinica, Taiwan\n4\nUniversity of Surrey, UK\n5\nMicrosoft Research, China\n{wubo, zhyd, jtli}@ict.ac.cn; whcheng@citi.sinica.edu.tw; hqsiswiliam@gmail.com; tmei@microsoft.com\nAbstract\nPrediction of popularity has profound impact for\nsocial media, since it offers opportunities to reveal\nindividual preference and public attention from\nevolutionary social systems. Previous research,\nalthough achieves promising results, neglects one\ndistinctive characteristic of social data, i.e., sequentiality. For example, the popularity of online content is generated over time with sequential post\nstreams of social media. To investigate the sequential prediction of popularity, we propose a novel\nprediction framework called Deep Temporal Context Networks (DTCN) by incorporating both temporal context and temporal attention into account.\nOur DTCN contains three main components, from\nembedding, learning to predicting. With a joint embedding network, we obtain a unified deep representation of multi-modal user-post data in a common embedding space. Then, based on the embedded data sequence over time, temporal context\nlearning attempts to recurrently learn two adaptive\ntemporal contexts for sequential popularity. Finally, a novel temporal attention is designed to predict new popularity (the popularity of a new userpost pair) with temporal coherence across multiple time-scales. Experiments on our released image dataset with about 600K Flickr photos demonstrate that DTCN outperforms state-of-the-art deep\nprediction algorithms, with an average of 21.51%\nrelative performance improvement in the popularity prediction (Spearman Ranking Correlation).\n\n1\n\nIntroduction\n\nSocial media is now globally ubiquitous and prevalent. Consequently, understanding and predicting popularity in social\nmedia (e.g., Twitter, Facebook, Youtube and Flickr) has attracted great attention [Wu et al., 2016b; Wu et al., 2016a;\nLi et al., 2015; He et al., 2014; Khosla et al., 2014; Pinto\net al., 2013], since it offers opportunities to reveal individual\npreference and public attention from evolutionary social systems. Accurate popularity prediction can help improve user\n\nexperience, service effectiveness, and benefit a broad range\nof applications, such as content recommendation [Khosla et\nal., 2014], online advertising [Li et al., 2015] and information\nretrieval [Roy et al., 2013; Gan et al., 2016].\nPrevious research, although achieves promising results, neglects one distinctive characteristic of social data, i.e., temporal sequentiality. For example, the popularity generated by\nphoto sharing in Instagram on a weekday is observed to be at\nthe peak during hours at 2 a.m., 8-9 a.m. and 5 p.m. [Beese,\n2016]. Existing predictive algorithms on social media popularity are not considering the temporal order of data, making them have limited success to sequential data scenarios\n(e.g. news feed, tweet timeline, photo stream, etc.). Particularly, most of the existing works on popularity prediction are based on the content of a post or the person who\npublished the post [Shamma et al., 2011; Gelli et al., 2015;\nCappallo et al., 2015]. Recently, although some researchers\nhave analyzed temporal characteristics of social popularity\n(e.g., temporal fluctuations), the temporal interrelationship of\npopularity data is not explicitly exploited [Shen et al., 2014;\nZhao et al., 2015; Wu et al., 2016a; Wu et al., 2016b;\nMartin et al., 2016].\nIn this research, we take one step further to investigate\nthe problem as a temporal prediction task with sequentiality. Unlike previous work on using time information as latent factors or variables [Shen et al., 2014; He et al., 2014;\nZhao et al., 2015], our purpose is to predict popularity from\nboth sequential and temporal views based on time series\ndata. Specifically, we incorporate a time-centered perspective\ncalled ‘temporal context’ into popularity prediction, which\nwas inspired by social psychology for human behavioral processes [McGrath and Kelly, 1992]. Utilizing temporal context\nof popularity as a novel prior knowledge, we attempt to predict new popularity by exploiting consecutive temporal coherence of popularity at multiple time-scales.\nBased on the above idea, we propose two types of sequential temporal contexts for learning two different types of temporal coherence of popularity: Neighboring Temporal Context (NTC) and Periodic Temporal Context (PTC). On one\nhand, we model NTC to learn the continuous trend or patterns in short-term time series. For instance, before and after\nThanksgiving Day, the popularity of pumpkin picture rises\n\n\fFigure 1: Overview of Deep Temporal Context Network (DTCN). (A) Multi-modal Joint Embedding converts user feature and visual feature\ninto an embedding space, i.e., mapping the two kinds of multi-modal information into a same latent space; (B) Temporal Context Learning\nconstructs two temporal contexts, and learns contextual information based on LSTM; (C) Multiple Time-scale Temporal Attention assists the\nfinal prediction process based on temporal attention mechanism. (Best view in color)\n\nand decays in only a few days. The NTC helps us reveal\nthe trend and variances. Such temporal coherence has also\nbeen successfully applied to the citation estimation of scientific articles [Shen et al., 2014]. On the other hand, we model\nPTC to learn discontinuous temporal coherence in long-term\ntime series. Temporal coherence is often influenced by periodic events or human activities. For example, according to\nthe survey in 2016 [Ellering, 2016], the best time periods to\nmake a post on Facebook are Saturday and Sunday around 12\na.m. to 1 p.m., with periodic peaking time from 9 a.m. to 3\np.m. And weekly peak time for Pinterest is on Saturday from\n8 p.m. to 11 p.m. These findings motivate us to consider both\nof the temporal and sequential characteristics for predicting\npopularity more precisely.\nIn this paper, therefore, we propose a novel deep prediction\nframework called Deep Temporal Context Networks (DTCN)\nby exploring both temporal contexts and temporal attention\nat different time-scales jointly (such as days of a week, hours\nof a day). Figure 1 shows the overview of our DTCN framework, which is a sequential prediction architecture containing\nthree main components: from embedding, learning to predicting, along with the model trained as an entire network\nby optimization learning. With a joint embedding network,\nwe map multi-modal data onto the same embedding space\nto obtain a unified deep representation for user-post sharing activities. Then, based on the embedded data sequence,\nwe design temporal context learning to recurrently learn the\ndynamic popularity from adaptive temporal contexts (NTC\nand PTC) for popularity over time. Finally, we provide a\nmultiple time-scale attention for computing multi-scale temporal coherence in predicting the popularity of a new userpost pair. Unlike previous work on temporal modeling for\npopularity prediction [Wu et al., 2016b; Wu et al., 2016a;\nLi et al., 2015], our study attempts to provide a novel view\n\non temporal context modeling, which considers both of the\ntemporal and sequential coherence during prediction.\nThe main contributions of this study are: (i) To our best\nknowledge, we are the first to consider both temporal and\nsequential characteristics into sequential prediction of social\nmedia popularity over time; (ii) we address the problem by\nincorporating a temporal context perspective, and proposing two types of novel temporal contexts including NTC and\nPTC; (iii) we propose a novel deep prediction model DTCN\narchitecture jointly integrating embedding, temporal context\nlearning and predicting with temporal attention to optimize\nthe entire network, which outperforms state-of-the-art predictive algorithms in sequential popularity prediction.\n\n2\n\nRelated Work\n\nRecently, time-aware popularity prediction receives much attention. Both academia and industry have paid more effort on this research topic. Existing works about prediction\nwith temporal information can be concluded into two main\nparadigms. The first paradigm focuses on predicting the popularity growth of a published post by analyzing its temporal\ntrend and pattern at early stage. Szabo and Huberman proposed to predict popularity based on growth pattern characteristics of online popularity at early stage [Szabo and Huberman, 2010]. Yang and Leskovec found the temporal patterns\nreveal how the contents popularity grows and fades during the\npost propagation [Yang and Leskovec, 2011]. Roy et al. proposed to grasp sudden bursts of a post popularity with crossdomain knowledge [Roy et al., 2013]. Kong et al. explored\nthe problem of detecting which hashtag would be bursting.\nMost of these works provided dynamic comprehension on\npopularity accumulation of online content, but their prediction needs to rely on early stage popularity patterns of a pub-\n\n\flished post. Our method takes one step further on popularity\nprediction before that the corresponding post was published.\nThe other paradigm is predicting popularity based on temporal features or dynamic signals. Zhao et al. applied human\nreaction time as temporal variables in self-exciting point processes [Zhao et al., 2015]. Shen et al. proposed a reinforced\nPoisson process to model the dynamic popularity based on\nthe arrival time of attention [Shen et al., 2014]. He et al.\ndesigned a time-aware bipartite graph for popularity estimation [He et al., 2014]. Wu et al. proposed to predict popularity by context factorization and tensor decomposition algorithms to unfold popularity dynamics [Wu et al., 2016b;\nWu et al., 2016a]. These models all neglect the sequentiality\nof popularity during prediction.\nSummary. We focus on the investigation of sequential\ntemporal coherence of popularity over time before the corresponding sharing behavior happened. Being differed from\nprevious works on the predicting popularity with temporal information e.g., [Shen et al., 2014; He et al., 2014;\nZhao et al., 2015; Wu et al., 2016a; Wu et al., 2016b], we\nexplore the temporal context of popularity from sequential\ndata and consider both of sequential and temporal characteristics of popularity during prediction. It is worth mentioning\nthat our algorithm is generic and applicable to the prediction\nof other sequential data scenarios in social media, e.g. news\nfeed, tweet timeline, photo stream, and so forth.\n\n3\n\nSocial Media Popularity Prediction\n\nTaking photo popularity prediction on Flickr as an exemplary\ncase, we define our problem and introduce the definitions of\nseveral core concepts, including user-post sequence, temporal\ncontext, and multiple time-scales.\nProblem Definition: Given a new photo v of a user u, the\nproblem of predicting its popularity s is to estimate how many\nattentions would be obtained after the post was published on\nsocial media (e.g. views, likes or clicks etc.).\nOn Flickr, when browsing a personal photo stream or image search results, users can view details of a photo content\nwith its metadata through clicking photo thumbnails. In our\nprediction, since “viewing count” is a significant indicator of\nhow popular a photo is, we use it to describe the photo popularity as follows:\nPopularity Normalization. To suppress the large variations among different photos (e.g. view count of different\nphotos vary from zero to millions), we implement a log function to normalize the value of popularity, based on the previous work [Wu et al., 2016a; Khosla et al., 2014]. In brief, the\nlog-normalization function for popularity can be defined as:\nr\ns = log2 + 1,\n(1)\nd\nwhere s is the normalized value, r is the view count of a\nphoto, and d is the number of days since the photo was posted.\nSeveral core concepts in the paper are also defined as follows:\nDefinition 1: User-Post Sequence. A user-photo pair p ⇔\nhu, vi is derived from the photo sharing behavior (e.g., post\npublishing, photo sharing and video uploading), which made\nby user u on photo v. Suppose we have n user-photo pairs and\n\nthe sharing time of each pair. Then the user-post sequence can\nbe denoted by S = {hu1 , v1 i , hu2 , v2 i , ..., hun , vn i} with its\nsharing time order t1 ≤ t2 ≤ ... ≤ tn .\nDefinition 2: Temporal Context. Given the prediction\ntarget p and its previous user-post sequence Pu before time\nt, temporal context (as a prior knowledge) is a time series,\nwhich was built on Pu and expressed by a triple sequence:\nCp = {hu1 , v1 , tp1 i , hu2 , v2 , tp2 i , ..., huk , vk , tpk i}, tp1 ≤\ntp2 ≤ ... ≤ tpk ≤ t where k is the item count in the temporal context.\nDefinition 3: Multiple Time-scales. For time order sequence, time-scale determines a time unit of the sequential\ndata. In our paper, without loss of generality, there are four\nlevels of time-scales, Tunit = {t1M , t1P , t1D , t1W }, which\nmeans that minute of a hour, period of a day, day of a week\nand week of a month. With regard to the period of a day,\nwe segment one day into six periods [Wu et al., 2016a],\ni.e. “morning (8:00am-12:00am)”, “lunch time (12:00am14:00pm)”, “afternoon (14:00am-17:00pm)”, “dinner time\n(17:00am-20:00pm)”, “evening (20:00am-24:00pm)” and\n“night (0:00am-8:00am)”.\n\n4\n\nDeep Temporal Context Network\n\nHow can the temporal context at multiple time-scales be utilized for popularity prediction? We address the problem as\na sequential prediction task, where the input is a user-photo\nsequence (with time order) while the output is the popularity of a “future” photo (a photo before its publication on social media). We propose a deep prediction framework called\nDTCN containing three components: (1) Multi-modal Joint\nEmbedding (2) Temporal Context Learning and (3) Multiple\nTime-scale Temporal Attention. With all the components, the\nmodel is trained as an entire network by optimization algorithm RMSprop [Tieleman and Hinton, 2012].\n\n4.1\n\nMulti-modal Joint Embedding\n\nIn the first stage of DTCN, Multi-modal Joint Embedding\n(MJE) is to generate a unified deep representation of multimodal sequence data. While an individual popularity is\nhighly correlated with user-photo interactions [Cappallo et\nal., 2015; Khosla et al., 2014; Qian et al., 2014], our embedding model is not only designed to correctly understand\nwhat appears in photos but also incorporate the knowledge of\nwho posts it.\nSuppose that a variety of photo sharing behaviors over time\ncan be naturally viewed as a user-photo sequence. The bimodal sequence data are the input data of our embedding network. In order to parametrize the visual content and user influence from the data sequence, we design a two-stream Feedforward Neural Network (FNN), which has both of the user\nanalysis pipeline and the photo analysis pipeline respectively.\nOn one hand, the photo analysis pipeline starts with a pretrained ResNet [He et al., 2015] in 152 layers for generating\nhigh-level visual representations of 2048 dimensions. On the\nother hand, we adopted a group of features to measure user influence in the user analysis pipeline, such as the average value\nof views, photo count, the number of contacts, mean number\nof members in a user’s groups, and having a Pro Flickr account or not. In our embedding network, each of the pipelines\n\n\fcontains four layers with two hidden layers and shares the\nsame dimension number of hidden neural nodes of 256 and\n32. In order to perform non-linear mapping of features from\nthe original space to a new latent space, the tanh activation\nfunction is applied in each layer of the embedding networks.\nMeanwhile, we apply a random dropout mechanism with parameter 0.5 in each hidden layer of the two pipelines, since\ndropout strategies have been adopted to prevent over fitting\nin neural network training phrase [Srivastava et al., 2014]. In\nthe end of the architecture, user and photo information xu and\nxv generated from the last layers of the two-stream FNN are\nembedded together by minimizing on embedding loss:\nX\nL(xu , xv ) =\n||sof tmax(xu xv − xu xv )||22 ,\nxu ∈U,xv ∈V\n\n(2)\nwhere U and V are the collections of all users and photos respectively, and || · ||2 means L2 norm regularization for loss\nfunction. The final output of the embedding network is a 64dimensional vector. By joint training with all the other components of the DTCN framework, we obtain an embedding\nrepresentation of the user-photo sequence.\n\n4.2\n\nTemporal Context Learning\n\nIn the learning stage of DTCN, Temporal Context Learning\n(TCL) is to learn sequential and temporal coherence from the\ntemporal context for prediction. Different from traditional\ncontext learning, our temporal context is adaptive time series\nand correlated with the time information of a prediction target\nand its previous user-photo sequence.\nThe first step of TCL is constructing temporal contexts\nas prior knowledge for each “future” popularity. To model\nshort or long-term fluctuations of popularity over time, we\npropose two variable-length temporal contexts: Neighboring Temporal Context (NTC) and Periodic Temporal Context\n(PTC). Suppose we already have the embedding data of previous user-photo sequence Pu for a prediction target p, the\ndata items are corresponding with the user-photo pairs in Pu .\nSpecifically, the temporal context Cp is a time series generated from the time information of Pu . Therefore, NTC consist\nof neighboring items of the prediction target from its previous\ndata sequence, which is applied to describe rapidly-varying\npopularity fluctuations in a short-term time range; PTC is\nbuilt with discontinuous s from the previous data sequence,\nwhich is applied to represent periodic popularity patterns in\na long-term time range. Here we design two discrimination\nfunctions of NTC and PTC to determine whether a certain\nitem s ∈ Pu would be a possible element of the corresponding temporal context. The NTC discrimination function is\ndefined as follows:\ntp − ts\nfN T C (tp , ts ) = δ(\n< l), ∀s ∈ Pu ,\n(3)\n∆tunit\nwhere tp and ts is the sharing time of p and s, and ∆tunit\nis the duration of a time unit. Dirac delta function δ(·) is to\ncompute a discrimination signal, and we use l in discrimination function to control the signal condition lengths of time\nspan for temporal context computation. In addition to shortterm fluctuations, popularity also has periodic variances in\n\nlong-term. Therefore the discrimination function for PTC is:\ntp − ts\nfP T C (tp , ts ) = δ(mod(\n= 0)), ∀s ∈ Pu (4)\n∆tunit\nwhere the modulo function mod(·) is to detect whether p\nand s are in the same time blocks in different time-scales (e.g.\nthe same period in different days or the same day in different\nweeks). In order to learn consecutive variance from both of\nNTC and PTC, we maintain the time-scale tunit ∈ Tunit of\nthem to be same in context learning.\nTo learn consecutive coherence from temporal contexts,\nwe provide a two-stream recurrent neural network based\non LSTM [Hochreiter and Schmidhuber, 1997] with Mean\nSquared Error (MSE) loss function as the optimization objective. Our network not only considers contextual information\nbut also utilizes temporal information to learn the temporal\ncontext for both short-term and long-term temporal coherence. Taking the embedding data sequence as the input of\nLSTM, TCL is able to learn and read the surrounding temporal context for each prediction target by controlling recurrent\nstate updates of the network.\n\n4.3\n\nMultiple Time-scale Temporal Attention\n\nMultiple Time-scale Temporal Attention (MTTA) is proposed\nto consider the dynamic impact of each contextual item into\nprediction. Intuitively, we incorporate the attention mechanism to be infer the temporal attention across multiple\ntimescales between previous instances and new instances for\nnew popularity prediction. Different from traditional attention, multiple timescale coherent among data need to be learnt\nfrom both of weights of relative hidden states and multiple\nscales of time-series.\nConsidering all data items of temporal context, the temporal context vector ci is the input of LSTM at the step i. It can\nbe computed by a weighted sum of hidden state hi :\n|Cp |\n\nci =\n\nX\n\nαij hj ,\n\n(5)\n\nj=1\n\nwhere the αij is attention weight. It is calculated by comparing current prediction target p and the data item of previous\ntemporal context at position j:\nexp(e−1\nt̄i · t̄j\nij )\nαij = P|C |\n, eij = 1 −\n,\np\n−1\n||\nt̄\n||2 ||t̄j ||2\ni\nk=1 exp(eik )\n\n(6)\n\nwhere t̄ denotes multi-scale time vector. Note that unlike in\nthe traditional attention mechanism, we use attention score\neij to leverage the temporal consistency between t̄p and t̄s .\nIts calculation relies on time vector t̄ = (t1M , t1P , t1D , t1W )\nwith multiple time-scale information instead of hidden state\nvector h for temporal attention. To compute the temporal\nconsistency, we apply cosine distance function as a simple\nmetric, while it can be alternated by other distance functions.\n\n5\n\nExperiments\n\nIn this section, we demonstrate the effectiveness of the proposed framework on Flickr dataset as follows: (1) we compare performances between our proposed method and current\n\n\fstate-of-the-art algorithms for popularity prediction on different data scales respectively. (2) we provide the experiment results of using single temporal context on DTCN and demonstrate the performance results with different context types,\nconsidering temporal unit and time-scales.\n\n5.1\n\nDataset\nMetric\nCNN-AlexNet\nCNN-VGG\nSVR\nSVR(T)\nMLP\nMLP(T)\nLSTM\nCLSTM\nDTCN\n\nExperimental Setup\n\nTemporal Popularity Image Collection (TPIC17)1 .\nTPIC17 is an image popularity dataset with multi-faceted\ninformation, such as user profile, photo metadata, and visual\ncontent. To construct the sequential prediction dataset and\nprotect the privacy of photo sharing behaviors, we extracted\ntime information of the adopted time-scales from the original\ntimestamps of photo sharing. It contains 680K photos in\ntotal, and the sharing time of photos are over three years\nfrom Flickr. In order to use the temporal information from\nthe dataset, we extracted time information from the metadata.\nTo obtain multiple data settings with different dataset size,\nwe individually sampled three sub datasets (100K, 200K and\n400K) from the 680K dataset to evaluate algorithms.\nMoving Partition Validation. In order to evaluate sequential prediction task, we have a 5-round moving partition strategy on the segment of training and testing data for validation.\nWe organized the entire data in time order and divided it into\n14 parts in total. The moving partition strategy is using data\nfrom a moving time window recurrently. In our experiments,\nwe use the data in time window as input for each round. In\nour experiments, the length of time window are 10, which\nmeans the partition ratio of training versus testing data is 9:1.\nEvaluation Metrics. We evaluated the prediction performance of our approach and the baselines on a correlation\nmetric Spearman Ranking Correlation (SRC) and a precision\nmetric Mean Absolute Error (MAE). SRC is to measure the\nranking correlation between ground-truth popularity set P\nand predicted popularity set P̂ , varying from 0 to 1. If there\nare k samples, the SRC can be expressed as:\n!\n\u0013\nk \u0012\n¯\n1 X Pi − P̄\nP̂i − P̂\nrs =\n,\n(7)\nk − 1 i=1\nσP\nσP̂\nwhere P̄ and σP are mean and variance of the corresponding popularity set. Furthermore, we also use Mean Absolute\nError (MAE) to calculate the averaged prediction error:\nM AE =\n\n5.2\n\nTable 1: Prediction performances on TPIC17-100K, 200K, and\n400K datasets (metric: Spearman Ranking Correlation).\n\nn\n1X\n| P̂i − Pi | .\nk i=1\n\n(8)\n\nCompared Methods\n\nIn order to compare with state-of-the-art models, we implemented the following approaches which can be applied into\npopularity prediction task as baselines.\nBaseline 1 & 2: Convolutional Neural Networks (CNNAlexNet [Krizhevsky et al., 2012] and CNN-VGG [Russakovsky et al., 2015]). CNNs have been proved a powerful\ntool in the field of image understanding for photo popularity\n1\nWe released the data set in https://github.com/social-mediaprediction/flickr-data-prediction-2017\n\n100K\n0.2450\n0.2281\n0.2647\n0.2741\n0.4135\n0.4436\n0.4629\n0.4966\n0.5990\n\n200K\nSRC\n0.2435\n0.2445\n0.2367\n0.2984\n0.5282\n0.5068\n0.5837\n0.5730\n0.6175\n\n400K\n0.1423\n0.1064\n0.2289\n0.2643\n0.5559\n0.5084\n0.5885\n0.6072\n0.6692\n\nprediction [Cappallo et al., 2015]. Consequently, we apply\nCNN-AlexNet and CNN-VGG as the baselines for CNNs,\nand fine tuned the 8-layer AlexNet and 19-layer VGG as a\nregression task that is optimized with our image dataset to\npredict photo popularity. Different from other methods, the\ninput of CNNs baseline is original image file only.\nBaseline 3: Support Vector Regression (SVR) [Khosla\net al., 2014]. Khosla et.al. implement SVR algorithm in popularity prediction task, which utilized user information and\nvisual content together as feature vectors by using linear kernel. Simultaneously, we add temporal information into SVR\nas another baseline method that denotes as SVR(T).\nBaseline 4: Multiple Layer Perceptron (MLP) [Zhang\net al., 1998]. MLP is a typical feedforward neural network\ntrained with back propagation, which has the general ability\nand does not require any assumption about the distribution of\ntraining data to solve real-world problems. Meanwhile, we\nalso implement a variant MLP(T) by adding temporal information to the input vector of MLP.\nBaseline 5: Long Short-Term Memory (LSTM)\n[Hochreiter and Schmidhuber, 1997]. LSTM is a recurrent neural network (RNN) architecture, which is capable of\ndealing with sequential information for popularity prediction.\nBaseline 6: Contextual LSTM (CLSTM) [Ghosh et al.,\n2016]. Since the contextual deep learning is a relatively new\nresearch direction, there are only few existing research works\nto compare with. To the best of our knowledge, the most\nclosely related work is CLSTM, which also considered contextual information in training and predicting phrase. Therefore, we used Contextual LSTM as a representative of Contextual Recurrent Neural Network (CRNN). Different from\ntraditional LSTM, CLSTM takes the contextual information\ninto account during the training and predicting process, and\nit has been proved feasible in NLP tasks. The parameters\nof Recurrent Layers (e.g. LSTM) and hidden neural nodes\nshared the same settings over proposed prediction framework\n(DTCN), LSTM and CLSTM. The numbers of output dimensions are 64 with the “hard sigmoid” activation function.\n\n5.3\n\nPrediction Performance\n\nThe prediction performances of our proposed method and the\ncompared models are shown in Table 1 and Figure 2. Overall, our approach DTCN achieves the best prediction performance on three data size settings with highest SRC of 0.6692\n\n\fTable 2: Prediction performances of context type NTC and PTC\n(metric: Spearman Ranking Correlation).\n\nNTC\nContext Type\nT C1P -0.5D\nT C1P -1D\nT C1D -3D\nT C1D -7D\n\nFigure 2: MAE (Mean Absolute Error) comparison of different algorithms on 100K, 200K and 400K datasets.\n\nand minimum MAE 1.2341. DTCN outperforms state-of-theart deep prediction algorithms (MLP, MLP(T), LSTM and\nCLSTM), with an average of 21.51% relative performance\nimprovement on SRC. Using raw data from images directly\nwithout user metadata and temporal information, both CNNAlexNet and CNN-VGG receive the worse results compared\nto other deep learning baseline algorithms. As multiple layer\nnetworks, MLPs obtains higher effectiveness than SVRs on\nprediction, while both of them are using user and visual features. From SVR and MLP to SVR(T) and MLP(T), there\nare neck-to-neck results across different sizes of datasets.\nThus involving temporal information as non-sequential feature only has limited power for prediction, the behind reason might be ignorance of the sequential coherence of temporal information. With consideration of sequential coherence\nin the modeling of prediction, LSTM and CLSTM achieve\ngood performances on SRC, i.e., 0.4629 and 0.6072, which\nare better than MLP and lower than DTCN. Overall, the results of sequential prediction (i.e. RNNs) are much superior\nthan the results of non-sequential prediction (e.g. SVR, MLP\nor CNNs) on predicting social media popularity. The prediction accuracies of different methods are shown in Figure\n2. From the histogram of MAE, our model also achieves the\nminimal prediction error 1.2341. From CNNs to DCTN, it\ncan be seen that the error drops from about 2.1 to 1.2, and\nDTCN has stable improvements on TPIC17-100K, TPIC17200K, and TPIC17-400K dataset. That means our approach\nprovides a more accurate model for popularity prediction.\n\n5.4\n\nTemporal Context Analysis\n\nHere we analyze different types of temporal context in terms\nof using only one of them in our prediction model on TPIC17100K. There can be different variants of distinct temporal\ncontext type settings T Ctunit -tr , based on the type of time\nunit tunit and the temporal range of context tr chosen. Generally, short-term settings are applied for NTC types, which\nranges from 0.5 day to 1 week in our experiment. Simultaneously, PTC types are applied to explore long-term patterns for popularity evolving, which ranges from 3 days to\n1 month. The time unit tunit control the time-scale of NTC\nand PTC. For instance, T C1P -1D of NTC means to construct\n\nSRC\n0.5607\n0.5875\n0.5549\n0.5784\n\nPTC\nContext Type\nT C1P -3D\nT C1P -5D\nT C1D -3W\nT C1D -4W\n\nSRC\n0.4975\n0.5745\n0.5365\n0.5485\n\nNTC from the data in previous 1 day range using the timescale on period of day. Another case is T C1D -3W of PTC,\nwhich means the range of PTC for prediction target is in the\nsame weekday of previous 3 weeks.\nThe results of using different types of NTC and PTC in our\nmodel are shown in Table 2, where the highest SRC is 0.5875\nwhen using T C1P -1D of NTC. Overall, the results using\nNTC settings are better than PTC settings, which reveals that\nthere are obvious short-term patterns in the 100K dataset of\nFlickr. Next, we analyze the improvements of performance in\nterms of NTC and PTC, respectively. Compared with the performance of DTCN on same data in Table 1, the performances\nof using a single temporal context (NTC or PTC) in Table 2\ndrop down from 0.5990 to 0.5875 and 0.5745. This finding illustrates that prediction using both of NTC and PTC on same\ndata performs more accurately than using one of them only,\nand our method can incorporate them together effectively.\n\n6\n\nConclusions and Future Work\n\nThis paper proposes to learn consecutive temporal coherence\nof temporal context for predicting social media popularity\nover time, which comprises of three components. Firstly,\nwe design a joint embedding network for multi-modal feature representation. Then, we propose and utilize two types\nof temporal context alignment to learn sequential popularity\nin short-term and long-term popularity fluctuations. Furthermore, we provide a temporal attention mechanism for predicting popularity at multiple time-scales. To evaluate our\napproach, we constructed a publicly available dataset with\nuser-photo sequence data. Experimental results show that\nour prediction network achieves promising performances and\noutperforms the state-of-the-art deep prediction algorithms\nby 5.79%–44.86% relative improvements on TPIC17. The\ntechnique serves a deep prediction framework for sequential\npopularity prediction, and our paper along with the released\ndataset further helps promote the research.\nThere are several possible directions for future investigations on social popularity prediction. One is considering the\nsocial network structure (and inherent social network analysis techniques) to improve the popularity prediction. Another\nopen question is to exploit impact of most influential users in\nthe social network.\n\nAcknowledgements\nThis work was supported in part by the National Key Research and Development Program of China under Grant\n2016YFB0800403 and the National Nature Science Foundation of China (61525206, 61571424).\n\n\fReferences\n[Beese, 2016] Jennifer Beese. 5 insightful instagram stats\nthat you should know. http://sproutsocial.com/insights/5instagram-stats/, 2016. [Online].\n[Cappallo et al., 2015] Spencer Cappallo, Thomas Mensink,\nand Cees GM Snoek. Latent factors of visual popularity\nprediction. In Proc. of ICMR, 2015.\n[Ellering, 2016] Nathan Ellering.\nWhat 16 studies\nsay about the best times to post on social media.\nhttp://coschedule.com/blog/best-times-to-post-on-socialmedia/, 2016. [Online].\n[Gan et al., 2016] Chuang Gan, Chen Sun, Lixin Duan, and\nBoqing Gong. Webly-supervised video recognition by\nmutually voting for relevant web images and web video\nframes. In ECCV, 2016.\n[Gelli et al., 2015] Francesco Gelli, Tiberio Uricchio, Marco\nBertini, Alberto Del Bimbo, and Shih-Fu Chang. Image\npopularity prediction in social media using sentiment and\ncontext features. In Proc. of ACM MM, 2015.\n[Ghosh et al., 2016] Shalini Ghosh, Oriol Vinyals, Brian\nStrope, Scott Roy, Tom Dean, and Larry Heck. Contextual lstm (clstm) models for large scale nlp tasks. arXiv\npreprint arXiv:1602.06291, 2016.\n[He et al., 2014] Xiangnan He, Ming Gao, Min-Yen Kan,\nYiqun Liu, and Kazunari Sugiyama. Predicting the popularity of web 2.0 items based on user comments. In Proc.\nof SIGIR, pages 233–242, 2014.\n[He et al., 2015] Kaiming He, Xiangyu Zhang, Shaoqing\nRen, and Jian Sun. Deep residual learning for image recognition. arXiv preprint arXiv:1512.03385, 2015.\n[Hochreiter and Schmidhuber, 1997] Sepp Hochreiter and\nJürgen Schmidhuber. Long short-term memory. Neural\ncomputation, 9(8):1735–1780, 1997.\n[Khosla et al., 2014] Aditya Khosla, Atish Das Sarma, and\nRaffay Hamid. What makes an imag e popular? In Proc.\nof WWW, 2014.\n[Krizhevsky et al., 2012] Alex Krizhevsky, Ilya Sutskever,\nand Geoffrey E Hinton. Imagenet classification with deep\nconvolutional neural networks. In Advances in neural information processing systems, pages 1097–1105, 2012.\n[Li et al., 2015] Cheng Li, Yue Lu, Qiaozhu Mei, Dong\nWang, and Sandeep Pandey. Click-through prediction for\nadvertising in twitter timeline. In Proc. of KDD, 2015.\n[Martin et al., 2016] Travis Martin, Jake M Hofman, Amit\nSharma, Ashton Anderson, and Duncan J Watts. Exploring\nlimits to prediction in complex social systems. In Proc. of\nWWW, 2016.\n[McGrath and Kelly, 1992] Joseph E. McGrath and Janice R.\nKelly. Temporal context and temporal patterning. Time &\nSociety, 1(3):399–420, 1992.\n[Pinto et al., 2013] Henrique Pinto, Jussara M Almeida, and\nMarcos A Gonçalves. Using early view patterns to predict\nthe popularity of youtube videos. In Proc. of WSDM, pages\n365–374, 2013.\n\n[Qian et al., 2014] Xueming Qian, He Feng, Guoshuai Zhao,\nand Tao Mei. Personalized recommendation combining user interest and social circle. IEEE Transactions\non Knowledge and Data Engineering, 26(7):1763–1777,\n2014.\n[Roy et al., 2013] Suman Deb Roy, Tao Mei, Wenjun Zeng,\nand Shipeng Li. Towards cross-domain learning for social\nvideo popularity prediction. IEEE Transactions on Multimedia, 15(6):1255–1267, 2013.\n[Russakovsky et al., 2015] Olga Russakovsky, Jia Deng,\nHao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,\nZhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael\nBernstein, Alexander C. Berg, and Li Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. IJCV,\n115(3):211–252, 2015.\n[Shamma et al., 2011] David A Shamma, Jude Yew, Lyndon\nKennedy, and Elizabeth F Churchill. Viral actions: Predicting video view counts using synchronous sharing behaviors. In Proc. of ICWSM, 2011.\n[Shen et al., 2014] Hua-Wei Shen, Dashun Wang, Chaoming\nSong, and Albert-László Barabási. Modeling and predicting popularity dynamics via reinforced poisson processes.\nIn Proc. of AAAI, 2014.\n[Srivastava et al., 2014] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan\nSalakhutdinov. Dropout: a simple way to prevent neural\nnetworks from overfitting. Journal of Machine Learning\nResearch, 15, 2014.\n[Szabo and Huberman, 2010] Gabor Szabo and Bernardo A\nHuberman. Predicting the popularity of online content.\nCommunications of the ACM, 53(8):80–88, 2010.\n[Tieleman and Hinton, 2012] T. Tieleman and G. Hinton.\nLecture 6.5—RmsProp: Divide the gradient by a running\naverage of its recent magnitude. COURSERA: Neural\nNetworks for Machine Learning, 2012.\n[Wu et al., 2016a] Bo Wu, Wen-Huang Cheng, Yongdong\nZhang, and Tao Mei. Time matters: Multi-scale temporalization of social media popularity. In Proc. ACM MM,\n2016.\n[Wu et al., 2016b] Bo Wu, Tao Mei, Wen-Huang Cheng, and\nYongdong Zhang. Unfolding temporal dynamics: Predicting social media popularity using multi-scale temporal decomposition. In Proc. AAAI, 2016.\n[Yang and Leskovec, 2011] Jaewon\nYang\nand\nJure\nLeskovec.\nPatterns of temporal variation in online\nmedia. In Proc. of WSDM, 2011.\n[Zhang et al., 1998] Zhengyou Zhang, Michael Lyons,\nMichael Schuster, and Shigeru Akamatsu. Comparison\nbetween geometry-based and gabor-wavelets-based facial\nexpression recognition using multi-layer perceptron. In\nProc. of ICCV, pages 454–459. IEEE, 1998.\n[Zhao et al., 2015] Qingyuan Zhao, Murat A Erdogdu,\nHera Y He, Anand Rajaraman, and Jure Leskovec. Seismic, a self-exciting point process model for predicting\ntweet popularity. In Proc. of KDD, 2015.\n\n\f",
         "train",
         "37373",
         "5800"
        ],
        [
         "42",
         "17933",
         "cs.AI",
         "Artificial Intelligence",
         "1612.06505v4.pdf",
         "1\n\nParallelized Tensor Train Learning of Polynomial\nClassifiers\n\narXiv:1612.06505v4 [cs.LG] 6 Nov 2017\n\nZhongming Chen∗ , Kim Batselier† , Johan A.K. Suykens‡ and Ngai Wong†\n\nAbstract—In pattern classification, polynomial classifiers are\nwell-studied methods as they are capable of generating complex\ndecision surfaces. Unfortunately, the use of multivariate polynomials is limited to kernels as in support vector machines, because\npolynomials quickly become impractical for high-dimensional\nproblems. In this paper, we effectively overcome the curse of\ndimensionality by employing the tensor train format to represent\na polynomial classifier. Based on the structure of tensor trains,\ntwo learning algorithms are proposed which involve solving\ndifferent optimization problems of low computational complexity. Furthermore, we show how both regularization to prevent\noverfitting and parallelization, which enables the use of large\ntraining sets, are incorporated into these methods. The efficiency\nand efficacy of our tensor-based polynomial classifier are then\ndemonstrated on the two popular datasets USPS and MNIST.\nIndex Terms—Supervised learning, tensor train, pattern classification, polynomial classifier.\n\nI. I NTRODUCTION\nPattern classification is the machine learning task of identifying to which category a new observation belongs, on the\nbasis of a training set of observations whose category membership is known. This type of machine learning algorithm\nthat uses a known training dataset to make predictions is\ncalled supervised learning, which has been extensively studied\nand has wide applications in the fields of bioinformatics\n[1], computer-aided diagnosis (CAD) [2], machine vision [3],\nspeech recognition [4], handwriting recognition [5], spam\ndetection and many others [6], [7], [8]. Usually, different kinds\nof learning methods use different models to generalize from\ntraining examples to novel test examples.\nAs pointed out in [9], [10], one of the important invariants\nin these applications is the local structure: variables that are\nspatially or temporally nearby are highly correlated. Local\ncorrelations benefit extracting local features because configurations of neighboring variables can be classified into a small\nnumber of categories (e.g. edges, corners...). For instance, in\nhandwritten character recognition, correlations between image\npixels that are nearby tend to be more reliable than the\nones of distant pixels. Learning methods incorporating this\nkind of prior knowledge often demonstrate state-of-the-art\nperformance in practical applications. One popular method\nfor handwritten character recognition is using convolutional\nneural networks (CNNs) [11], [12] which are variations of\n∗ Department of Mathematics, School of Science, Hangzhou Dianzi University, Hangzhou 310018, China. Email: czm183015@126.com.\n† Department of Electrical and Electronic Engineering, The University of\nHong Kong. Email: {kimb, nwong}@eee.hku.hk.\n‡ KU Leuven, ESAT, STADIUS. B-3001 Leuven, Belgium. Email: johan.suykens@esat.kuleuven.be.\n\nmultilayer perceptrons designed to use minimal amounts of\npreprocessing. In this model, each unit in a layer receives\ninputs from a set of units located in a small neighborhood\nin the previous layer, and these mappings share the same\nweight vector and bias in a given convolutional layer. An\nimportant component of a CNN are the pooling layers, which\nimplement a nonlinear form of down-sampling. In this way,\nthe amount of parameters and computational load are reduced\nin the network. Another popular method uses support vector\nmachines (SVMs) [13], [14]. The original finite-dimensional\nfeature space is mapped into a much higher-dimensional\nspace, where the inner product is easily computed through the\n‘kernel trick’. By considering the Wolfe dual representation,\none can find the maximum-margin hyperplane to separate the\nexamples of different categories in that space. However, it is\nworth mentioning that these models require a large amount of\nmemory and a long processing time to train the parameters.\nFor instance, if there are thousands of nodes in the CNN,\nthe weight matrices of fully-connected layers are of the order\nof millions. The major limitation of basic SVMs is the high\ncomputational complexity which is at least quadratic with the\ndataset size. One way to deal with large datasets in the SVMframework is by using a fixed-size least squares SVM (fixedsize LS-SVM) [15], which approximates the kernel mapping\nin such a way that the problem can be solved in the primal\nspace.\nII. T ENSORS IN MACHINE LEARNING\nTensors are a multidimensional generalization of matrices\nto higher orders and have recently gained attention in the\nfield of machine learning. The classification via tensors, as\nopposed to matrices or vectors, was first considered in [16], by\nextending the concept of spectral regularization for matrices to\ntensors. The tensor data is assumed to satisfy a particular lowrank Tucker decomposition, which unfortunately still suffers\nfrom an exponential storage complexity. Other work has\nfocused speeding-up the convolution operation in CNNs [17]\nby approximating this operation with a low-rank polyadic\ndecomposition of a tensor. In [18], the weight matrices of\nfully-connected layers of neural networks are represented\nby tensor trains (TTs), effectively reducing the number of\nparameters. TTs have also been used to represent nonlinear\npredictors [19] and classifiers [20]. The key idea here is always\nto approximate a mapping that is determined by an exponential\nnumber of parameters nd by a TT with a storage complexity\nof dnr2 parameters. To our knowledge, this idea has not yet\nbeen applied to polynomial classifiers that also suffer from the\n\n\f2\n\ncurse of dimensionality. The usual approach to circumvent the\nexponential number of polynomial coefficients would be to\nuse SVMs with a polynomial kernel and solve the problem\nin the dual space. In this article, we exploit the efficient\nrepresentation of a multivariate polynomial as a TT in order to\navoid the curse of dimensionality, allowing us to work directly\nin the feature space. The main contributions are:\n•\n\n•\n•\n\nWe derive a compact description of a polynomial classifier using the TT format, avoiding the curse of dimensionality.\nTwo efficient learning algorithms are proposed by exploiting the TT structure.\nBoth regularization and a parallel implementation are\nincorporated into our methods, thus avoiding overfitting\nand allowing the use of large training datasets.\n\nThis paper is organized as follows. In Section III, we give\na brief introduction to tensor basics, including the TT decomposition, important tensor operations and properties. The\nframework of TT learning for pattern classification is presented\nin Section IV. Based on different loss functions, two efficient\nlearning algorithms are proposed in Section V, together with a\ndiscussion on regularization and parallelization. In Section VI,\nwe test our algorithms on two popular datasets: USPS and\nMNIST and compare their performance with polynomial classifiers trained with LS-SVMs [15]. Finally, some conclusions\nand further work are summarized in Section VII.\nThroughout this paper, we use small letters x, y, . . . , for\nscalars, small bold letters x, y, . . . , for vectors, capital letters\nA, B, . . . , for matrices, and calligraphic letters A, B, . . . , for\ntensors. The transpose of a matrix A or vector x is denoted by\nA> and x> , respectively. The identity matrix of dimension n is\ndenoted by In . A list of abbreviations used here is summarized\nin Table I.\nTABLE I\nL IST OF A BBREVIATIONS\nTT\nCNN\nSVM\nTTLS\nTTLR\nUSPS\nMNIST\n\nTensor Train\nConvolutional Neural Network\nSupport Vector Machine\nTensor Train learning by Least Squares\nTensor Train learning by Logistic Regression\nUS Postal Service database\nModified NIST database\n\ni3\ni2\ni1\n\n1\n2\n3\n4\n\n5 9\n6 10\n7 11\n8 12\n\n13\n14\n15\n16\n\n17\n18\n19\n20\n\n21\n22\n23\n24\n\nFig. 1. An example tensor A = (Ai1 i2 i3 ) ∈ R4×3×2 , where i1 , i2 , i3\ndenote the indices for each mode respectively.\n\nThe k-mode product B = A ×k U of a tensor A ∈\n0\nRn1 ×n2 ×···×nd and a matrix U ∈ Rnk ×nk is defined by\nBi1 ···ik−1 jik+1 ···id =\n\nnk\nX\n\nAi1 ···ik−1 ik ik+1 ···id Ujik ,\n\n(1)\n\nik =1\n0\n\nand B ∈ Rn1 ×···×nk−1 ×nk ×nk+1 ×···×nd . In particular, given\na d-way tensor A ∈ Rn×n×···×n and a vector x ∈ Rn , the\nmultidimensional contraction, denoted by Axd , is the scalar\nAxd = A ×1 x> ×2 x> ×3 · · · ×d x> ,\n\n(2)\n\nwhich is obtained as a homogeneous polynomial of x ∈ Rn\nwith degree d. The inner product of two same-sized tensors\nA, B ∈ Rn1 ×n2 ×···×nd is the sum of the products of their\nentries, i.e.,\nhA, Bi =\n\nn1 X\nn2\nX\ni1 =1 i2 =1\n\n···\n\nnd\nX\n\nAi1 i2 ···id Bi1 i2 ···id .\n\n(3)\n\nid =1\n\nThe Frobenius norm of a tensor A ∈ Rn1 ×n2 ×···×nd is given\nby\np\n(4)\nkAkF = hA, Ai.\nThe vectorization of a tensor A ∈ Rn1 ×n2 ×···×nd is denoted by vec(A) and maps the tensor element with indices\n(i1 , i2 , . . . , id ) to the vector element with index i where\ni = i1 + (i2 − 1)n1 + · · · + (id − 1)\n\nd−1\nY\n\nnk .\n\nk=1\n\nIII. P RELIMINARIES\nA. Tensors and pure-power-n polynomials\nA real dth-order or d-way tensor is a multidimensional array\nA ∈ Rn1 ×n2 ×···×nd that generalizes the notions of vectors\nand matrices to higher orders. Each of the entries Ai1 i2 ···id\nis determined by d indices. The numbers n1 , n2 , . . . , nd are\ncalled the dimensions of the tensor. An example tensor with\ndimensions 4, 3, 2 is shown in Fig. 1. We now give a brief\nintroduction to some required tensor operations and properties,\nmore information can be found in [21].\n\nGiven d vectors x(i) ∈ Rni , i = 1, 2, . . . , d, their outer product\nis denoted by x(1) ◦ x(2) ◦ · · · ◦ x(d) , which is a tensor in\nRn1 ×n2 ×···×nd such that its entry with indices (i1 , i2 , . . . , id )\nis equal to the product of the corresponding vector elements,\n(1) (2)\n(d)\nnamely, xi1 xi2 · · · xid . It follows immediately that\nvec(x(1) ◦ x(2) ◦ · · · ◦ x(d) ) = x(d) ⊗ x(d−1) ⊗ · · · ⊗ x(1) , (5)\nwhere the symbol “⊗” denotes the Kronecker product.\nWe now illustrate how to represent a polynomial by using\ntensors. Denote by R[x] the polynomial ring in d variables\nx = (x1 , x2 , . . . , xd )> with coefficients in the field R.\nDefinition 1. Given a vector ñ = (ñ1 , ñ2 , . . . , ñd ) ∈ Nd , a\npolynomial f ∈ R[x] with d variables is called pure-power-ñ\n\n\f3\n\nif the degree of f is at most ñi with respect to each variable\nxi , i = 1, 2, . . . , d.\n4x1 +x31 −2x1 x2 x3 −7x2 x23\n\nExample 1. The polynomial f =\nis a pure-power-ñ polynomial with ñ = (3, 1, 2).\n\nThe set of all pure-power-ñ polynomials with the degree\nvector ñ = (ñ1 , ñ2 , . . . , ñd ) ∈ Nd is denoted\nby R[x]ñ . For\nQd\nany f (x) ∈ R[x]ñ , there are a total of k=1 (ñk + 1) distinct\nmonomials\nd\nY\n\nxikk −1 ,\n\n1 ≤ ik ≤ ñk + 1,\n\nk = 1, 2, . . . , d.\n\nk=1\n>\n\nFor x = (x1 , x2 , . . . , xd )\nVandermonde vectors\n\nd\n\n∈ R , denote by\n\n{v(xk )}dk=1\n\nv(xk ) := (1, xk , . . . , xñk k )> ∈ Rñk +1 .\n\nthe\n(6)\n\nIt follows that there is a one-to-one mapping between\npure-power-ñ polynomials and tensors. To be specific, for\nany f (x) ∈ R[x]ñ , there exists a unique tensor A ∈\nR(ñ1 +1)×(ñ2 +1)×···×(ñd +1) such that\nf (x) = A ×1 v(x1 )> ×2 v(x2 )> ×3 · · · ×d v(xd )> .\n\n(7)\n\nn3\n\nr1\n\nn2\n\nr1\n\nB. Tensor trains\nIt is well known that the number of tensor elements grows\nexponentially with the order d. Even when the dimensions\nare small, the storage cost for all elements is prohibitive for\nlarge d. The TT decomposition [22] gives an efficient way (in\nstorage and computation) to overcome this so-called curse of\ndimensionality.\nThe main idea of the TT decomposition is to re-express\nthe entries of a tensor A ∈ Rn1 ×n2 ×···×nd as a product of\nmatrices\nAi1 i2 ···id = G1 (i1 )G2 (i2 ) · · · Gd (id ),\n\n(8)\n\nwhere Gk (ik ) is an rk−1 × rk matrix for each index ik , also\ncalled the TT-core. To turn the matrix-by-matrix product (8)\ninto a scalar, boundary conditions r0 = rd = 1 have to be\nintroduced. The quantities {rk }dk=0 are called the TT-ranks.\nNote that each core Gk is a third-order tensor with dimensions\nrk−1 , nk and rk . The TT-decomposition for a tensor A ∈\nRn1 ×n2 ×n3 is illustrated in Fig. 2. The most common way\nto convert a given tensor A into a TT would be the TT-SVD\nalgorithm [22, p. 2301].\nExample 3. TT-SVD algorithm [22, p. 2301]. Using the TTSVD algorithm, we can convert the tensor A from Example\n\nr2\n\nn2\n\nG3\n\nG2\n\nFig. 2. The TT decomposition for a tensor in Rn1 ×n2 ×n3 .\n\n2 into a TT that consists of TT-cores G1 ∈ R1×4×3 , G2 ∈\nR3×2×3 , G3 ∈ R3×3×1 .\nNote that throughout this article, we will not need to use\nthe TT-SVD algorithm. Instead, we will initialize the TT-cores\nrandomly and iteratively update the cores one-by-one in an\nalternating fashion. It turns out that if all TT-ranks are bounded\nby r, the storage of the TT grows linearly with the order d as\nO(dnr2 ), where n = max{n1 , n2 , . . . , nd }.\nProposition 1 (Theorem 2.1 of [23]). For any tensor A ∈\nRn1 ×n2 ×···×nd , there exists a TT-decomposition with TT-ranks\nrk ≤ min(\n\nk\nY\n\nni ,\n\ni=1\n\nExample 2. We revisit the polynomial f from Example 1\nand illustrate its corresponding tensor representation. Since\nñ = (3, 1, 2), we construct the Vandermonde vectors v(x1 ) =\n(1, x1 , x21 , x31 ), v(x2 ) = (1, x2 ), v(x3 ) = (1, x3 , x23 ). The\nnonzero entries of the corresponding 4×2×3 tensor A are then\nA211 = 4, A411 = 1, A222 = −2, A123 = −7. The indices of\nthe tensor A are easily found from grouping together corresponding indices of the Vandermonde vectors. For example,\nthe tensor index 123 corresponding with the monomial x2 x23\nis found from v(x1 )1 = 1, v(x2 )2 = x2 , v(x3 )3 = x23 .\n\nr2\n\nn1\n\n=\n\nA\n\nn1\n\nn3\n\nG1\n\nd\nY\n\nni ),\n\nk = 1, 2, . . . , d − 1.\n\ni=k+1\n\nWe also mention that the TT representation of a tensor is\nnot unique. For instance, let Q be an orthogonal matrix in\nRr1 ×r1 , namely, QQ> = Q> Q = Ir1 . Then the tensor A in\n(8) also has the TT-decomposition\nAi1 i2 ···id = G10 (i1 )G20 (i2 ) · · · Gd (id ),\n\n(9)\n\nwhere\nG10 (i1 ) = G1 (i1 )Q,\n\nG20 (i2 ) = Q> G2 (i2 ).\n\nNumerical stability of our learning algorithms is guaranteed\nby keeping all the TT-cores left-orthogonal or right-orthogonal\n[24], which is achieved through a sequence of QR decompositions as explained in Section V.\nDefinition 2. The rk−1 × nk × rk core Gk is called leftorthogonal if\nnk\nX\n\nGk (ik )> Gk (ik ) = Irk ,\n\nik =1\n\nand the rk−1 × nk × rk core Gk is called right-orthogonal if\nnk\nX\n\nGk (ik )Gk (ik )> = Irk−1 .\n\nik =1\n\nAs stated before, the structure of a TT also benefits the\ncomputation of the general multidimensional contraction:\nf = A ×1 (v(1) )> ×2 (v(2) )> ×3 · · · ×d (v(d) )> ,\n(i)\n\n(i)\n\n(10)\n(i)\n\nwhere A ∈ Rn1 ×n2 ×···×nd and v(i) = (v1 , v2 , . . . , vni )> ∈\nRni , i = 1, 2, . . . , d. If a tensor A is given in the TTformat (8), then we have\nf=\n\nnk\nd X\nY\nk=1 ik =1\n\n(k)\n\nvik Gk (ik ).\n\n(11)\n\n\f4\n\nThe described procedure for fast TT contraction is summarized\nin Algorithm 1. In order to simplify the analysis on the\ncomputational complexity of Algorithm 1, we assume that\nr1 = r2 = · · · = rd−1 = r and n1 = n2 = · · · = nd = n.\nThere are two required steps to compute the contraction of\na TT with vector. First, we need to construct d matrices\nV (k) by contracting the TT-cores Gk with the vectors v(k) .\nThis operation is equivalent with d matrix-vector products\nwith a total computational cost of approximately O(dr2 n)\nflops. Fortunately, the contraction of one TT-core is completely\nindependent from the other contractions and hence can be\ndone in parallel over d processors, reducing the computational\ncomplexity to O(r2 n) per processor. Maximal values for r and\nn in our experiments are 10 and 4, respectively, so that the\ncontraction of one TT-core is approximately equivalent with\nthe product of a 100 × 4 matrix with a 4 × 1 vector. The final\nstep in Algorithm 1 is the product of all matrices V (k) with\na total computational complexity of O(dr2 ). If we again set\nr = 10, n = 4, then this final step in Algorithm 1 is equivalent\nwith the product of a 100×40 matrix with a 40×1 vector. For\nmore basic operations implemented in the TT-format, such as\ntensor addition and computing the Frobenius norm, the reader\nis referred to [22].\nAlgorithm 1 Fast TT contraction [22]\nInput: Vectors v(k) ∈ Rnk , k = 1, 2, . . . , d and a tensor A\nin the TT-format with cores Gk\nOutput: The multidimensional contraction f in (10)\n1: for k = 1 : d do\nPn\n(k)\n2:\nV (k) = ikk=1 vik Gk (ik )\n%Computed in parallel\n3: end for\n4: f := V (1)\n5: for k = 2 : d do\n6:\nf := f V (k)\n7: end for\n8: return f\n\nIV. TT L EARNING\nIt is easy for us to recognize a face, understand spoken\nwords, read handwritten characters and identify the gender\nof a person. Machines, however, make decisions based on\ndata measured by a large number of sensors. In this section,\nwe present the framework of TT learning. Like most pattern\nrecognition systems [25], our TT learning method consists in\ndividing the system into three main modules, shown in Fig. 3.\nThe first module is called feature extraction, which is of\nparamount importance in any pattern classification problem.\nThe goal of this module is to build features via transformations\nof the raw input, namely, the original data measured by a large\nnumber of sensors. The basic reasoning behind transformbased features is that an appropriately chosen transformation can exploit and remove information redundancies, which\nusually exist in the set of samples obtained by measuring\ndevices. The set of features exhibit high information packaging\nproperties compared with the original input samples. This\nmeans that most of the classification-related information is\n\ncompressed into a relatively small number of features, leading\nto a reduction of the necessary feature space dimension.\nFeature extraction benefits training the classifier in terms of\nmemory and computation, and also alleviates the problem of\noverfitting since we get rid of redundant information. To deal\nwith the task of feature extraction, some linear or nonlinear\ntransformation techniques are widely used. For example, the\nKarhunen-Loève transform, related to principal component\nanalysis (PCA), is one popular method for feature generation\nand dimensionality reduction. A nonlinear kernel version of\nthe classical PCA is called kernel PCA, which is an extension\nof PCA using kernel methods. The discrete Fourier transform\n(DFT) can be another good choice due to the fact that for\nmany practical applications, most of the energy lies in the\nlow-frequency components. Compared with PCA, the basis\nvectors in the DFT are fixed and problem-dependent, which\nleads to a low computational complexity.\nThe second module, the TT classifier, is the core of TT\nlearning. The purpose of this module is to mark a new\nobservation based on its features generated by the previous\nmodule. As will be discussed, the task of pattern classification\ncan be divided into a sequence of binary classifications. For\neach particular binary classification, the TT classifier assigns\nto each new observation a score that indicates which class it\nbelongs to. In order to construct a good classifier, we exploit\nthe fact that we know the labels for each sample of a given\ndataset. The TT classifier is trained optimally with respect\nto an optimality criterion. In some ways, the TT classifier\ncan be regarded as a kind of generalized linear classifier,\nit does a linear classification in a higher dimensional space\ngenerated by the items of a given pure-power polynomial. The\nlocal information is encoded by the products of features. In\ncontrast to kernel-based SVM classifiers that work in the dual\nspace, the TT classifier is able to work directly in the high\ndimensional space by exploiting the TT-format. Similar with\nthe backpropagation algorithm for multilayer perceptrons, the\nstructure of a TT allows for updating the cores in an alternating\nway. In the next section, we will describe the training of two\nTT classifiers through the optimization of two different loss\nfunctions.\nThe last module in Fig. 3 is the decision module that\ndecides which category a new observation belongs to. For\nbinary classification, decisions are made according to the\nsign of the score assigned by the TT classifier, namely, the\ndecision depends on the value of corresponding discriminant\nfunction. In an m-class problem, there are several strategies to\ndecompose it into a sequence of binary classification problems.\nA straightforward extension is the one-against-all, where m\nbinary classification problems are involved. We seek to design\ndiscriminant functions {gi (x)}m\ni=1 so that gi (x) > gj (x),\n∀j 6= i if x belongs to the ith class. Classification is then\nachieved according to the rule:\nassign x to the ith class if i = argmaxk gk (x).\nAn alternative technique is the one-against-one, where we\nneed to consider m(m − 1)/2 pairs of classes. The decision\nis made on the basis of a majority vote. It means that each\nclassifier casts one vote and the final class is the one with\n\n\f5\n\nRaw\nInput\n\nFeature\nExtraction\nModule\n\nTT Classifier\nModule\n\nDecision\nModule\n\nCategory\n\nFig. 3. Framework of TT learning.\n\nthe most votes. When the number m is too large, one can\nalso apply the technique of binary coding. It turns out that\nonly dlog2 me classifiers are needed, where d·e is the ceiling\noperation. In this case, each class is represented by a unique\nbinary code word of length dlog2 me. The decision is then\nmade on the basis of minimal Hamming distance.\nV. L EARNING A LGORITHMS\nFor notational convenience, we define nk := ñk + 1\nand continue to use this notation for the remainder of the\narticle. As stated before, TT classifiers are designed for binary\nclassification. Given a set of N training examples of the form\n(j)\n{(x(j) , y (j) )}N\n∈ Rd is the feature vector of\nj=1 such that x\n(j)\nthe jth example and y ∈ {−1, 1} is the corresponding class\nlabel of x(j) . Let ñ = (ñ1 , ñ2 , . . . , ñd )> ∈ Nd be the degree\nvector. Each feature is then mapped to a higher dimensional\nspace generated by all corresponding pure-power-ñ monomials\nthrough the mapping T : Rd → Rn1 ×n2 ×···×nd\nT (x)i1 i2 ···id =\n\nd\nY\n\nxikk −1 .\n\n(12)\n\nd\n\n{v(xk )}dk=1\n\nFor x = (x1 , x2 , . . . , xd ) ∈ R , let\nbe the\nVandermonde vectors defined in (6). Clearly, we have\nT (x) = v(x1 ) ◦ v(x2 ) ◦ · · · ◦ v(xd ).\n\n(13)\n\nThis high-dimensional pure-power polynomial space benefits\nthe learning task from the following aspects:\n• all interactions between features are described by the\nmonomials of pure-power polynomials;\n• the dimension of the tensor space grows exponentially\nQd\nwith d, namely, k=1 nk , which increases the probability\nof separating all training examples linearly into twoclasses;\n• the one-to-one mapping between pure-power polynomials\nand tensors enables the use of tensor trains to lift the curse\nof dimensionality.\nWith these preparations, our goal is to find a decision\nhyperplane to separate these two-class examples in the tensor\nspace, also called the generic feature space. In other words,\nlike the inductive learning described in [16], we try to find a\ntensor A ∈ Rn1 ×n2 ×···×nd such that\ny (j) hT (x(j) ), Ai > 0,\n\nLemma 1. Given a vector ñ = (ñ1 , ñ2 , . . . , ñd )> ∈ Nd , let\nT be the mapping defined by (12), and let A be a TT with\ncores Gk ∈ Rrk−1 ×nk ×rk , k = 1, 2, . . . , d. For any x ∈ Rd\nand k = 1, . . . , d, we have that\n\u0001\nhT (x), Ai = qk (x)> ⊗ v(xk )> ⊗ pk (x) vec(Gk ), (14)\n\np1 (x) = 1,\n\npk (x) =\nk≥2\n\nk−1\nY\n\n\u0001\nGi ×2 v(xi )> ∈ R1×rk−1 ,\n\ni=1\n\nand\nqk (x) =\nk<d\n\nd\nY\n\n\u0001\nGi ×2 v(xi )> ∈ Rrk ×1 ,\n\nqd (x) = 1.\n\ni=k+1\n\nProof. By definition, we have\nhT (x), Ai = A ×1 v(x1 )> ×2 · · · ×d v(xd )>\n\u0001\n\u0001\n= G1 ×2 v(x1 )> · · · Gd ×2 v(xd )>\n= Gk ×1 pk (x) ×2 v(xk )> ×3 qk (x)>\n\u0001\n= qk (x)> ⊗ v(xk )> ⊗ pk (x) vec(Gk )\nfor any k = 1, 2, . . . , d. This completes the proof.\n\n∀y (j) = 1,\n∀y (j) = −1.\n\nExample 5. Next, we illustrate the expressions for\nT (x), A, v(xk ), qk (x), pk (x) for the following quadratic\n\nj = 1, 2, . . . , N.\n\nand\ng(x(j) ) < 0,\n\nuntil convergence, which is guaranteed under certain conditions as described in [27], [28]. It turns out that updating\none TT-core is equivalent with minimizing a loss function in\na small number of variables, which can be done in a very\nefficient manner. The following lemma shows how the inner\nproduct hT (x), Ai in the generic feature space is a linear\nfunction in any of the TT-cores Gk .\n\nExample 4. In this example we illustrate the advantageous\nrepresentation of a pure-power polynomial f as a TT. Suppose\nwe have a polynomial f with d = 10 and all degrees ñi =\n9 (i = 1, . . . , 10). All coefficients of f (x) can then be stored\ninto a 10-way tensor 10 × 10 × · · · × 10 tensor A such that\nthe evaluation of f in a particular x is given by (7). The TTrepresentation of f consists of 10 TT-cores G1 , . . . , G10 , with\na storage complexity of O(100r2 ), where r is the maximal TTrank. This demonstrates the potential of the TT-representation\nin avoiding the curse of dimensionality when the TT-ranks are\nsmall.\n\nNote that the bias is absorbed into the first element of A. Note\nthat the learning problem can also be interpreted as finding a\npure-power-ñ polynomial g(x) such that\ng(x(j) ) > 0,\n\nG1 → G2 → · · · → Gd → Gd−1 → · · · → G1 → · · ·\n\nwhere\n\nk=1\n>\n\nHere we consider that the tensor A is expressed as a tensor\ntrain with cores {Gk }dk=1 . The main idea of the TT learning\nalgorithms is to update the cores in an alternating way by\noptimizing an appropriate loss function. Prior to updating the\nTT-cores, the TT-ranks are fixed and a particular initial guess\nof {Gk }dk=1 is made. The TT-ranks can be interpreted as tuning\nparameters, higher values will result in a better fit at the risk\nof overfitting. It is straightforward to extend our algorithms by\nmeans of the Density Matrix Renormalization Group (DMRG)\nmethod [26] such that the TT-ranks are updated adaptively.\nEach core is updated in the order\n\n\f6\n\npolynomial in two variables f (x) = 1 + 3x1 − x2 − x21 +\n7x1 x2 + 9x22 . Since d = 2 and ñ1 = ñ2 = 2, both T and A\nare the following 3 × 3 matrices\n\n\n\n\n1 −1 9\n1\nx2\nx22\n7 0 .\nT (x) = x1 x1 x2 x1 x22  , A =  3\nx21 x21 x2 x21 x22\n−1 0 0\n\nWe have thus shown that updating the core Gk is equivalent\nwith solving a least squares optimization problem in rk−1 nk rk\nvariables. Minimizing (17) with respect to Gk for any k =\n1, . . . , d results in solving the linear system\n\nThe TT-representation of A consists of a 1 × 3 × 3 tensor G1\nand a 3×3×1 tensor G2 . Suppose now that k = 2 and we want\nto compute the evaluation of the polynomial f in a particular\nx, which is hT (x), Ai. From Lemma 1 we then have that\n\u0001\nhT (x), Ai = q2 (x)> ⊗ v(x2 )> ⊗ p2 (x) vec(G2 ),\n\nSupposing r1 = r2 = · · · = rd−1 = r and n1 = n2 = · · · =\nnd = n, then the computational complexity of solving (19) is\nO((r2 n)3 ). For the maximal values of r = 10 and n = 4 in\nour experiments, this implies that we need to solve a linear\nsystem of order 400, which takes about 0.01 seconds using\nMATLAB on our desktop computer.\n\n(Ck> Ck ) vec(Gk ) = Ck> y.\n\n(19)\n\nwith\nB. TT Learning by Logistic Regression\n\nq2 (x) = 1 ∈ R,\nv(x2 ) = 1\n\nx2\n\n\u0001\n2 >\n\nx2\n\n∈ R3 ,\n\n>\n\np2 (x) = G1 ×2 v(x1 ) ∈ R1×3 ,\n\u0001>\nv(x1 ) = 1 x1 x21 ∈ R3 .\nIn what follows, we first present two learning algorithms\nbased on different loss functions. These algorithms will learn\nthe tensor A directly in the TT-representation from a given\ndataset. Two enhancements, namely, regularization for better\naccuracy and parallelization for higher speed will be described\nin the last two subsections.\n\nSince our goal is to find a hyperplane to separate two-class\ntraining examples in the generic feature space, we may not\ncare about the particular value of the output. Indeed, only\nthe sign of the output makes sense. This gives us the idea to\ndecrease the number of sign differences as much as possible\nwhen updating the TT-cores, i.e., to minimize the number of\nmisclassified examples. However, this model is discrete so\nthat a difficult combinatorial optimization problem is involved.\nInstead, we try to find a suboptimal solution in the sense of\nminimizing a continuous cost function that penalizes misclassified examples. Here, we consider the logistic regression cost\nfunction. First, consider the standard sigmoid function\n\nA. TT Learning by Least Squares\nLeast squares estimation is the simplest and thus most\ncommon estimation method. In the generic feature space, we\nattempt to design a linear classifier so that its desired output\nis exactly 1 or −1. However, we have to live with errors, that\nis, the true output will not always be equal to the desired one.\nThe least squares estimator is then found from minimizing the\nfollowing mean square error function\nJ(A) =\n\nN\n\u00112\n1 X\u0010\nhT (x(j) ), Ai − y (j) .\nN j=1\n\n(15)\n\nWe now show how updating a TT-core Gk is equivalent with\nsolving a relatively small linear system. First, we define the\nN × rk−1 nk rk matrix\n\n\n(1)\nqk (x(1) )> ⊗ v(xk )> ⊗ pk (x(1) )\n\n\n(2)\n qk (x(2) )> ⊗ v(xk )> ⊗ pk (x(2) ) \n\n\nCk = \n(16)\n..\n\n\n\n.\n(N )\n\nqk (x(N ) )> ⊗ v(xk )> ⊗ pk (x(N ) )\n\nfor any k = 1, 2, . . . , d. The matrix Ck is hence obtained\nfrom the concatenation of the row vectors qk (x)> ⊗v(xk )> ⊗\npk (x) from (14) for N samples x(1) , . . . , x(N ) . It follows from\nLemma 1 that\n1\n(17)\nJ(A) = kCk vec(Gk ) − yk2\nN\nwhere\ny = (y (1) , y (2) , . . . , y (N ) )> ∈ RN .\n(18)\n\nσ(z) =\n\n1\n,\n1 + e−z\n\nz ∈ R,\n\nwhere the output always takes values between 0 and 1. An\nimportant property is that its derivative can be expressed by\nthe function itself, i.e.,\nσ 0 (z) = σ(z)(1 − σ(z)).\n\n(20)\n\nThe logistic function for the jth example x(j) is given by\n\u0010\n\u0011\nhA (x(j) ) := σ hT (x(j) ), Ai .\n(21)\nWe can also interpret the logistic function as the probability\nthat the example x(j) belongs to the class denoted by the\nlabel 1. The predicted label ỹ (j) for x(j) is then obtained\naccording to the rule\n(\nhA (x(j) ) ≥ 0.5 ⇔ hT (x(j) ), Ai ≥ 0 → ỹ (j) = 1,\nhA (x(j) ) < 0.5 ⇔ hT (x(j) ), Ai < 0 → ỹ (j) = −1.\nFor a particular example x(j) , we define the cost function as\n\u0010\n\u0011\n\n − ln hA (x(j) )\nif y (j) = 1,\n(j)\n\u0010\n\u0011\nCost(x , A) =\n − ln 1 − h (x(j) )\nif y (j) = −1.\nA\nThe goal now is to find a tensor A such that hA (x(j) ) is near\n1 if y (j) = 1 or near 0 if y (j) = −1. As a result, the logistic\n\n\f7\n\nregression cost function for the whole training dataset is given\nby\nN\n1 X\nCost(x(j) , A)\nN j=1\nN \u0014\n\u0011\n−1 X 1 + y (j) \u0010\nln hA (x(j) ) +\n=\nN j=1\n2\n\u0011\u0015\n1 − y (j) \u0010\n(j)\nln 1 − hA (x ) .\n2\n\nJ(A) =\n\nwhere J(A) is given by (15) or (22), γ is a parameter that\nbalances the loss function and the regularization term. Here\nwe use the Tikhonov regularization, namely,\n1\nhA, Ai.\n(27)\n2\nThanks to the TT structure, the gradient of R(A) with respect\nto the TT-core Gk can be equivalently rewritten as a linear\ntransformation of vec(Gk ). In other words, there is a matrix\nDk ∈ Rrk−1 nk rk ×rk−1 nk rk determined by the cores {Gj }j6=k\nsuch that ∇Gk R(A) = Dk vec(Gk ). See Appendix A for more\ndetails. It follows that\nR(A) =\n\n(22)\n\nIt is important to note that (22) is convex though the sigmoid\nfunction is not. This guarantees that we can find the globally\noptimal solution instead of a local optimum.\nFrom equation (21) and Lemma 1, one can see that the\nfunction J(A) can also be regarded as a function of the core\nGk since\nhT (x(j) ), Ai = Ck (j, :) vec(Gk )\nwhere Ck (j, :) denote the jth row vector of Ck defined in\n(16). It follows that updating the core Gk is equivalent with\nsolving a convex optimization problem in rk−1 nk rk variables.\nLet\n\u0010\n\u0011>\nhA = hA (x(1) ), hA (x(2) ), . . . , hA (x(N ) )\n∈ RN (23)\nand DA be the diagonal matrix in RN ×N with\n\u0001 the jth\ndiagonal element given by hA (x(j) ) 1 − hA (x(j) ) . By using\nthe property (20) one can derive the gradient and Hessian with\nrespect to Gk as\n\u0012\n\u0013\ny+1\n1\n(24)\n∇Gk J(A) = Ck> hA −\nN\n2\n\n˜\n∇Gk J(A)\n= ∇Gk J(A) + γDk vec(Gk )\nand\n˜\n∇2Gk J(A)\n= ∇2Gk J(A) + γDk .\nThese small modifications lead to small changes when updating the core Gk . For instance, the first-order condition of (26)\nfor the least squares model results in solving the modified\nlinear system\n\u0013\n\u0012\nN\n>\n(28)\nCk Ck + γDk vec(Gk ) = Ck> y,\n2\nwhen compared with the original linear system (19).\nD. Orthogonalization and Parallelization\nThe matrix Ck from (16) needs to be reconstructed for each\nTT-core Gk during the execution of the two TT learning algorithms. Fortunately, this can be done efficiently by exploiting\nthe TT structure. In particular, after updating the core Gk in the\nleft-to-right sweep, the new row vectors {pk+1 (x(j) )}N\nj=1 to\nconstruct the next matrix Ck+1 can be easily computed from\n(j)\n\nand\n∇2Gk J(A)\n\n1\n= Ck> DA Ck ,\nN\n\npk+1 (x(j) ) = Gk ×1 pk (x(j) ) ×2 v(xk )> .\n(25)\n\nrespectively, where y is defined in (18) and 1 denotes the\nall-ones vector in RN . Although we do not have a closedform solution to update the core Gk , the gradient and Hessian\nallows us to find the solution by efficient iterative methods, e.g.\nNewton’s method whose convergence is at least quadratic in a\nneighbourhood of the solution. A quasi-Newton method, like\nthe Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm, is\nanother good choice if the inverse of the Hessian is difficult\nto compute.\nC. Regularization\nThe cost functions (15) and (22) of the two TT learning\nalgorithms do not have any regularization term, which may\nresult in overfitting and hence bad generalization properties of\nthe obtained TT classifier. Next, we discuss how the addition\nof a regularization term to (15) and (22) results in a small\nmodification of the small optimization problem that needs to\nbe solved when updating the TT-cores Gk .\nConsider the regularized optimization problem\n˜\nJ(A)\n= J(A) + γR(A),\n\n(26)\n\nSimilarly, in the right-to-left sweep, the new column vectors\n{qk−1 (x(j) )}N\nj=1 to construct the next matrix Ck−1 can be\neasily computed from\n(j)\n\nqk−1 (x(j) ) = Gk ×2 v(xk )> ×3 qk (x(j) )> .\nTo make the learning algorithms numerically stable, the\ntechniques of orthogonalization are also applied. The main\nidea is to make sure that before updating the core Gk , the cores\nG1 , . . . , Gk−1 are left-orthogonal and the cores Gk+1 , . . . , Gd\nare right-orthogonal by a sequence of QR decompositions. In\nthis way, the condition number of the constructed matrix Ck\nis upper bounded so that the subproblem is well-posed. After\nupdating the core Gk , we orthogonalize it with an extra QR\ndecomposition, and absorb the upper triangular matrix into\nthe next core (depending on the direction of updating). More\ndetails on the orthogonalization step can be found in [27].\nAnother computational challenge is the potentially large\nsize N of the training dataset. Luckily, the dimension of the\noptimization problem when updating Gk in the TT learning\nalgorithms is rk−1 (nk + 1)rk , which is much smaller and\nindependent from N . We only need to compute the products\nCk> Ck , Ck> y, Ck> hA and Ck> DA Ck in (19), (24) and (25).\nThese computations are easily done in parallel. Specifically,\n\n\f8\n\nPL\ngiven a proper partition {Nl }L\nl=1 satisfying\nl=1 Nl = N ,\nwe divide the large matrix Ck into several blocks, namely,\n (1) \nC\n k(2) \n Ck \nN ×rk−1 (nk +1)rk\n\n,\nCk = \n ..  ∈ R\n . \n(L)\nCk\n\nTABLE II\nDATASET D ESCRIPTION\n\nUSPS\nMNIST\n\n•\n\n(l)\n\nwhere Ck ∈ RNl ×rk−1 nk rk , l = 1, 2, . . . , L. Then, for\nexample, the product Ck> DA Ck can be computed by\nCk> DA Ck\n\n=\n\nL\nX\n\n(l)\n\n(l)\n\n(l)\n\n(Ck )> DA Ck ,\n\nl=1\n(l)\nDA\n\nwhere\ndenotes the corresponding diagonal block. Each\nterm in the summation on the right-hand side of the above\nequation can be computed over L distributed cores, with\na computational complexity of O(r4 n2k Nl ) for each core,\nsupposing rk−1 = rk = r. The other matrix products can\nalso be computed in a similar way.\nWe summarize our learning algorithms in Algorithm 2.\nThe two most computationally expensive steps are lines 5\nand 7. As we mentioned before, solving (26) takes approximately O((r2 n)3 ) flops. If the QR decomposition of line 7\nis computed through Householder transformations, then the\ncomputational complexity is approximately O(r3 n2 ) flops. For\nthe maximal values of n = 4 and r = 10 in our experiments,\nthis amounts to solving computing the inverse and the QR\nfactorization of a 400 × 400 matrix. Note that based on the\ndecision strategy, an m-class problem is decomposed into a\nsequence of two-class problems whose TT classifiers can be\ntrained in parallel.\nAlgorithm 2 Tensor Train Learning Algorithm\nInput: Training dataset of pairs {(x(j) , y (j) )}N\nj=1 , TT-ranks\n{rk }d−1\n,\ndegree\nvector\nñ\n=\n(ñ\n,\nñ\n,\n.\n.\n.\n,\nñ\n)> ∈ Nd and\n1\n2\nd\nk=1\nregularization parameter γ\nOutput: Tensor A in TT format with cores {Gk }dk=1\n1: Initialize right orthogonal cores {Gk }d\nk=1 of prescribed\nranks\n2: while termination condition is not satisfied do\n3:\n%Left-to-right sweep\n4:\nfor k = 1, 2, . . . , d − 1 do\n5:\nGk∗ ← find the minimal solution of the regularized\noptimization problem (26) with respect to Gk\n6:\nUk ← reshape(Gk∗ , rk−1 nk , rk )\n7:\n[Q, R] ← compute QR decomposition of Uk\n8:\nGk ← reshape(Q, rk−1 , nk , rk )\n9:\nVk+1 ← R ∗ reshape(Gk+1 , rk , nk+1 , rk+1 )\n10:\nGk+1 ← reshape(Vk+1 , rk , nk+1 , rk+1 )\n11:\nend for\n12:\nPerform the right-to-left sweep\n13: end while\nWe end this section with the following remarks:\n• Other loss functions can also be used in the framework\nof TT learning provided that there exists an efficient way\nto solve the corresponding subproblems.\n\n•\n\nImage size\n\nTraining size\n\nTest size\n\n16 × 16\n28 × 28\n\n7291\n60000\n\n2007\n10000\n\nThe DMRG method [26] can also be used to update\nthe cores. This involves updating two cores at a time\nso that the TT-ranks are adaptively determined by means\nof a singular value decomposition (SVD). This may give\nbetter performance at the cost of a higher computational\ncomplexity. It also removes the need to fix the TT-ranks\na priori.\nThe local linear convergence of Algorithm 2 has been\nestablished in [27], [28] under certain conditions. In\nparticular, if the TT-ranks are correctly estimated for\nconvex optimization problems, then the obtained solution\nis guaranteed to be the global optimum. When choosing\nthe TT-ranks, one should keep the upper bounds of the\nTT-ranks from Proposition 1 in mind.\nVI. E XPERIMENTS\n\nIn this section, we test our TT learning algorithms and\ncompare their performance with LS-SVMs with polynomial\nkernels on two popular digit recognition datasets: USPS\nand MNIST. All our algorithms were implemented in MATLAB Version R2016a, which can be freely downloaded from\nhttps://github.com/kbatseli/TTClassifier. We compare our TTpolynomial classifiers with a polynomial classifier based on\nLS-SVMs with a polynomial kernel. The LS-SVM-polynomial\nclassifier was trained with the MATLAB LS-SVMlab toolbox, which can be freely downloaded from http://www.esat.\nkuleuven.be/sista/lssvmlab/. The numerical experiments were\ndone on a desktop PC with an Intel i5 quad-core processor\nrunning at 3.3GHz and 16GB of RAM.\nThe US Postal Service (USPS) database1 contains 9298\nhandwritten digits, including 7291 for training and 2007 for\ntesting. Each digit is a 16×16 grayscale image. It is known that\nthe USPS test set is rather difficult and the human error rate is\n2.5%. The Modified NIST (MNIST) database2 of handwritten\ndigits has a training set of 60,000 examples, and a test set of\n10,000 examples. It is a subset of a larger set available from\nNIST. The digits have been size-normalized and centered in\na 28×28 image. The description of these two databases is\nsummarized in Table II.\nBefore extracting features of the handwritten digits, we first\nexecute the pre-process of deskewing which is the process\nof straightening an image that has been scanned or written\ncrookedly. By choosing a varying number d, the corresponding\nfeature vectors are then extracted from a pre-trained CNN\nmodel 1-20-P-100-P-d-10, which represents a net with an input\nimages of size 28×28, a convolutional layer with 20 maps and\n1 The USPS database is downloaded from\nhttp://statweb.stanford.edu/∼tibs/ElemStatLearn/data.html\n2 The MNIST database is downloaded from\nhttp://yann.lecun.com/exdb/mnist/\n\n\f9\n\nwhere A+ is the updated tensor from tensor A after one sweep.\nAnd the maximum number of sweeps is 4, namely, 4(d−1) iterations through the entire training data are performed for each\nsession. To simplify notations, we use “TTLS” and “TTLR” to\ndenote the TT learning algorithms based on minimizing loss\nfunctions (15) and (22), respectively. For these two models, the\nregularization parameter γ is determined by the technique of\n10-fold cross-validation. In other words, we randomly assign\nthe training data to ten sets of equal size. The parameter γ is\nchosen so that the mean over all test errors is minimal.\nThe numerical results for USPS database and MNIST\ndatabase are reported in Tables III and IV, respectively. The\nmonotonic decrease is always seen when training the ten TT\nclassifiers. Fig. 4 shows the convergence of both TT learning\nalgorithms on the USPS data for the case d = 20, ñ =\n1, rmax = 8 when training the classifier for the character “6”.\nIn addition, we also trained a polynomial classifier using LSSVMs with polynomial kernels on these two databases. Using\nthe basic LS-SVM scheme, a training error rate of 0 and a test\nerror rate of 8.37% were obtained for the USPS dataset after\nmore than three and a half hours of computation. This runtime\nincludes the time required to tune the tuning parameters via\n10-fold cross-validation. When using an RBF kernel with the\nLS-SVM, it is possible to attain a test error of 2.14% [30],\nbut then the classifier is not polynomial anymore. The MNIST\ndataset resulted in consistent out-of-memory errors, which is\nto be expected as the basic SVM scheme is not intended\nfor large data sets. We would also like to point out that a\n\n0.5\nTTLS\nTTLR\n\n0.3\n0.2\n\nTTLS\nTTLR\n\n0.08\nTrain error rate\n\n0.4\nLoss function\n\n5×5 filters, a max-pooling layer over non-overlapping regions\nof size 2×2, a convolutional layer with 100 maps and 5×5\nfilters, a max-pooling layer over non-overlapping regions of\nsize 2×2, a convolutional layer with d maps and 4×4 filters,\nand a fully connected output layer with 10 neurons. As the\nvariants of the well-known CNN model LeNet-5 [9], these\nCNN models have been trained well on the MNIST database.\nFor an input 28×28 image, we get a feature vector of length\nd from the third hidden layer. Note that for USPS database,\nwe must resize image data to the size of image input layer.\nWe mention that these techniques of deskewing and feature\nextraction using pre-trained CNN model are widely used in\nthe literature [9], [10], [29].\nFor the decision module, we adopt the one-against-all decision strategy where ten TT classifiers are trained to separate\neach digit from all the others. In the implementation of\nAlgorithm 2, we normalize each initial core such that its\nFrobenius norm is equal to one. The degree vector is given\nby ñ1 = · · · = ñd = ñ. The TT-ranks are upper bounded\nby rmax . The values of d, ñ, rmax were chosen to minimize\nthe test error rate and to ensure that each of the subproblems\nto update the TT-cores Gk could be solved in a reasonable\n2\n.\ntime. The dimension of each subproblem is at most n rmax\nFor example, in the USPS case, we first fixed the values of\nn and rmax . We then fixed the value of d and incremented\nn and rmax to see whether this resulted in a better test error\nrate. We use the optimality criterion\n˜ + ) − J(A)|\n˜\n|J(A\n≤ 10−2 ,\n˜\n|J(A)|\n\n0.06\n0.04\n0.02\n\n0.1\n0\n\n0\n0\n\n20\n\n40\nIterations\n\n60\n\n0\n\n20\n\n40\nIterations\n\n60\n\nFig. 4. The convergence of TT learning algorithms.\n\ntest error of 1.1% is reported on the MNIST website for a\npolynomial classifier of degree 4 that uses conventional SVMs\nand deskewing.\nVII. C ONCLUSION\nThis paper presents the framework of TT learning for pattern\nclassification. For the first time, TTs are used to represent\npolynomial classifiers, enabling the learning algorithms to\nwork directly in the high-dimensional feature space. Two\nefficient learning algorithms are proposed based on different\nloss functions. The numerical experiments show that each TT\nclassifier is trained in up to several minutes with competitive\ntest errors. When compared with other polynomial classifiers,\nthe proposed learning algorithms can be easily parallelized\nand have considerable advantage on storage and computation\ntime. We also mention that these results can be improved by\nadding virtual examples [10]. Future improvements are the\nimplementation of on-line learning algorithms, together with\nthe extension of the binary TT classifier to the multi-class case.\nA PPENDIX A\nGiven the degree vector ñ = (ñ1 , ñ2 , . . . , ñd ) ∈ Nd , let A ∈\nR\nbe the tensor in TT format with cores Gk ∈\nRrk−1 ×nk ×rk , k = 1, 2, . . . , d. To investigate the gradient of\nR(A) in (27) with respect to the TT-core Gk , we give a small\nvariation \u000f to the ith element of vec(Gk ), resulting in a new\ntensor A\u000f given by\nn1 ×n2 ×···×nd\n\n(k)\n\nA\u000f = A + \u000fIi ,\n(k)\n\nwhere 1 ≤ i ≤ rk−1 nk rk and Ii is the tensor which has\nthe same TT-cores with A except that the vectorization of the\ncore Gk is replaced by the unit vector in Rrk−1 nk rk with the\nith element equal to 1 and 0 otherwise. Then we have\nR(A\u000f ) − R(A)\n(k)\n= hA, Ii i.\n(29)\n\u000f→0\n\u000f\nOn the other hand, by the definition of vectorization, the ith\nelement of vec(Gk ) ∈ Rrk−1 nk rk is mapped from the tensor\nelement of Gk ∈ Rrk−1 ×nk ×rk with indices (αk−1 , jk , αk )\nsatisfying\n[∇Gk R(A)]i = lim\n\ni = αk−1 + (jk − 1)rk−1 + (αk − 1)rk−1 nk ,\nwhere 1 ≤ αk−1 ≤ rk−1 , 1 ≤ jk ≤ nk and 1 ≤ αk ≤ rk .\nDenote by E (αk−1 ,αk ) the matrix in Rrk−1 ×rk such that the\n\n\f10\n\nTABLE III\nN UMERICAL RESULTS FOR DATASET USPS\n\nd\n\nñ\n\nrmax\n\n20\n25\n30\n35\n40\n20\n25\n30\n35\n40\n20\n25\n30\n20\n25\n30\n35\n40\n\n1\n1\n1\n1\n1\n2\n2\n2\n2\n2\n3\n3\n3\n1\n1\n1\n1\n1\n\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n10\n10\n10\n10\n10\n\nTrain error\n\nTTLS\nTest error\n\nTime(s)\n\nTrain error\n\nTTLR\nTest error\n\nTime(s)\n\n0.58%\n0.47%\n0.49%\n0.38%\n0.34%\n0.49%\n0.38%\n0.51%\n0.45%\n0.34%\n0.59%\n0.49%\n0.63%\n0.56%\n0.41%\n0.51%\n0.34%\n0.44%\n\n4.33%\n4.04%\n3.84%\n4.04%\n3.89%\n4.29%\n4.29%\n4.14%\n4.38%\n4.09%\n4.58%\n4.53%\n4.43%\n4.33%\n3.94%\n3.84%\n3.94%\n3.84%\n\n1.10×10\n1.57×10\n1.83×10\n2.21×10\n2.59×10\n2.04×10\n2.68×10\n3.28×10\n3.87×10\n4.48×10\n3.26×10\n4.07×10\n4.93×10\n1.91×10\n2.48×10\n3.09×10\n3.71×10\n4.36×10\n\n0.45%\n0.27%\n0.30%\n0.26%\n0.14%\n0.55%\n0.29%\n0.47%\n0.32%\n0.21%\n0.64%\n0.56%\n0.51%\n0.44%\n0.27%\n0.25%\n0.22%\n0.33%\n\n4.33%\n3.99%\n3.99%\n4.24%\n3.74%\n4.24%\n4.14%\n3.99%\n4.38%\n3.74%\n4.33%\n4.14%\n4.09%\n4.33%\n3.94%\n4.04%\n4.29%\n3.84%\n\n4.87×10\n6.49×10\n8.18×10\n9.77×10\n11.39×10\n8.29×10\n10.82×10\n13.34×10\n15.88×10\n18.39×10\n11.47×10\n14.98×10\n18.35×10\n17.69×10\n24.72×10\n31.14×10\n38.17×10\n45.24×10\n\nTABLE IV\nN UMERICAL RESULTS FOR DATASET MNIST\n\nd\n\nñ\n\nrmax\n\n20\n25\n30\n35\n40\n20\n25\n30\n35\n40\n20\n30\n40\n20\n30\n40\n40\n40\n40\n\n1\n1\n1\n1\n1\n2\n2\n2\n2\n2\n3\n3\n3\n1\n1\n1\n2\n3\n4\n\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n10\n10\n10\n10\n10\n10\n\nTrain error\n\nTTLS\nTest error\n\nTime(s)\n\nTrain error\n\nTTLR\nTest error\n\nTime(s)\n\n0.16%\n0.15%\n0.13%\n0.19%\n0.21%\n0.19%\n0.13%\n0.19%\n0.17%\n0.17%\n0.20%\n0.22%\n0.21%\n0.20%\n0.16%\n0.17%\n0.13%\n0.18%\n0.24%\n\n0.96%\n0.97%\n0.86%\n0.81%\n0.94%\n1.03%\n1.00%\n0.88%\n0.86%\n0.90%\n1.10%\n1.02%\n0.97%\n0.99%\n0.88%\n0.88%\n0.93%\n0.94%\n1.02%\n\n7.14×10\n9.38×10\n11.73×10\n13.95×10\n16.22×10\n12.08×10\n15.72×10\n18.94×10\n23.11×10\n25.67×10\n17.45×10\n27.21×10\n36.48×10\n10.14×10\n17.15×10\n24.05×10\n39.61×10\n59.66×10\n78.83×10\n\n0.12%\n0.09%\n0.10%\n0.03%\n0.07%\n0.14%\n0.13%\n0.10%\n0.13%\n0.17%\n0.19%\n0.21%\n0.07%\n0.19%\n0.17%\n0.13%\n0.14%\n0.10%\n0.14%\n\n0.99%\n0.98%\n0.86%\n0.82%\n0.83%\n1.01%\n0.98%\n0.91%\n0.83%\n0.88%\n1.00%\n0.90%\n0.89%\n0.98%\n0.90%\n0.89%\n0.92%\n0.90%\n0.91%\n\n17.52×10\n22.96×10\n28.96×10\n34.55×10\n40.31×10\n29.45×10\n38.32×10\n46.77×10\n56.54×10\n64.68×10\n42.24×10\n65.89×10\n90.37×10\n36.66×10\n62.24×10\n83.62×10\n144.1×10\n207.7×10\n264.2×10\n\nelement with index (αk−1 , αk ) equal to 1 and 0 otherwise. By\nsimple computation, one can obtain that\nX\n(k)\nhA, Ii i =\nAi1 i2 ···id (Iik )i1 i2 ···id\n\nand\nbk =\n\nnl\nd\nY\nX\n\u0002\n\u0003\n2\nGl (il ) ⊗ Gl (il ) ∈ Rrk ×1 .\n\n(32)\n\nl=k+1 il =1\n\ni1 ,i2 ,...id\n\n\u0010\n\u0011\n= ak E (αk−1 ,αk ) ⊗ Gk (jk ) bk ,\n\n(30)\n\nwhere\n\n(1)\n\n(r\n\n(2)\n\n(1)\n\nak =\n\nnl\nk−1\nYX\nl=1 il =1\n\n)\n\nLet ak , ak , . . . , ak k−1 ∈ R1×rk−1 be the row vectors such\nthat\n(2)\n\n(r\n\n)\n\n2\n\nak = (ak , ak , . . . , ak k−1 ) ∈ R1×rk−1 ,\n\u0002\n\u0003\n2\nGl (il ) ⊗ Gl (il ) ∈ R1×rk−1\n\n(31)\n\n(1)\n\n(2)\n\n(r )\n\nand let bk , bk , . . . , bk k ∈ Rrk ×1 be the column vectors\n\n\f11\n\nsuch that\n\n\n\n\nbk = \n\n\n\n(1)\n\nbk\n(2)\nbk\n..\n.\n(r )\n\n\n\n\n ∈ Rrk2 ×1 ,\n\n\n\nbk k\n\nCombining (29) and (30) together, we have\n(α\n\n)\n\n(α )\n\n[∇Gk R(A)]i = ak k−1 Gk (jk )bk k\n\u0010\n\u0011\n(α\n)\n(α )\n= (bk k )> ⊗ (e(jk ) )> ⊗ ak k−1 vec(Gk ),\nwhere e(j) ∈ Rnk denotes the unit vector with the jth element\nequal to 1 and 0 otherwise. If we define the rk−1 nk rk ×\nrk−1 nk rk matrix\n\n\n(1)\n(1)\n(bk )> ⊗ (e(1) )> ⊗ ak\n\n\n(1)\n(2)\n\n (bk )> ⊗ (e(1) )> ⊗ ak\n,\n(33)\nDk = \n..\n\n\n\n\n.\n(r )\n\n(r\n\n(bk k )> ⊗ (enk )> ⊗ ak k−1\n\n)\n\nit follows immediately that ∇Gk R(A) = Dk vec(Gk ).\nACKNOWLEDGMENT\nZhongming Chen acknowledges the support of the National Natural Science Foundation of China (Grant No.\n11701132). Johan Suykens acknowledges support of ERC\nAdG A-DATADRIVE-B (290923), KUL: CoE PFV/10/002\n(OPTEC); FWO: G.0377.12, G.088114N, G0A4917N; IUAP\nP7/19 DYSCO. Ngai Wong acknowledges the support of\nthe Hong Kong Research Grants Council under the General\nResearch Fund (GRF) project 17246416.\nR EFERENCES\n[1] H.-B. Shen and K.-C. Chou, “Ensemble classifier for protein fold pattern\nrecognition,” Bioinformatics, vol. 22, no. 14, pp. 1717–1722, 2006.\n[2] H.-D. Cheng, X. Cai, X. Chen, L. Hu, and X. Lou, “Computer-aided\ndetection and classification of microcalcifications in mammograms: a\nsurvey,” Pattern recognition, vol. 36, no. 12, pp. 2967–2991, 2003.\n[3] B. Roberto, Template matching techniques in computer vision: theory\nand practice. Wiley, Hoboken, 2009.\n[4] B.-H. Juang, W. Hou, and C.-H. Lee, “Minimum classification error\nrate methods for speech recognition,” IEEE Transactions on Speech and\nAudio processing, vol. 5, no. 3, pp. 257–265, 1997.\n[5] L. Xu, A. Krzyzak, and C. Y. Suen, “Methods of combining multiple\nclassifiers and their applications to handwriting recognition,” IEEE\ntransactions on systems, man, and cybernetics, vol. 22, no. 3, pp. 418–\n435, 1992.\n[6] R. O. Duda, P. E. Hart, and D. G. Stork, Pattern classification. John\nWiley & Sons, 2012.\n[7] Y. Zhang, S. Wang, G. Ji, and P. Phillips, “Fruit classification using\ncomputer vision and feedforward neural network,” Journal of Food\nEngineering, vol. 143, pp. 167–177, 2014.\n[8] S. Wang, X. Yang, Y. Zhang, P. Phillips, J. Yang, and T.-F. Yuan,\n“Identification of Green, Oolong and Black Teas in China via Wavelet\nPacket Entropy and Fuzzy Support Vector Machine,” Entropy, vol. 17,\nno. 10, pp. 6663–6682, 2015.\n\n[9] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning\napplied to document recognition,” Proceedings of the IEEE, vol. 86,\nno. 11, pp. 2278–2324, 1998.\n[10] D. Decoste and B. Schölkopf, “Training invariant support vector machines,” Machine learning, vol. 46, no. 1-3, pp. 161–190, 2002.\n[11] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard,\nW. Hubbard, and L. D. Jackel, “Backpropagation applied to handwritten\nzip code recognition,” Neural computation, vol. 1, no. 4, pp. 541–551,\n1989.\n[12] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification\nwith deep convolutional neural networks,” in Advances in neural information processing systems, 2012, pp. 1097–1105.\n[13] C. Cortes and V. Vapnik, “Support-vector networks,” Machine learning,\nvol. 20, no. 3, pp. 273–297, 1995.\n[14] Y.-W. Chang, C.-J. Hsieh, K.-W. Chang, M. Ringgaard, and C.-J. Lin,\n“Training and testing low-degree polynomial data mappings via linear\nSVM,” Journal of Machine Learning Research, vol. 11, no. Apr, pp.\n1471–1490, 2010.\n[15] J. A. K. Suykens, T. Van Gestel, J. De Brabanter, B. De Moor,\nand J. Vandewalle, Least Squares Support Vector Machines. World\nScientific, Singapore, 2002.\n[16] M. Signoretto, Q. T. Dinh, L. De Lathauwer, and J. A. K. Suykens,\n“Learning with tensors: a framework based on convex optimization and\nspectral regularization,” Machine Learning, vol. 94, no. 3, pp. 303–351,\n2014.\n[17] V. Lebedev, Y. Ganin, M. Rakhuba, I. Oseledets, and V. Lempitsky, “Speeding-up convolutional neural networks using fine-tuned cpdecomposition,” arXiv preprint arXiv:1412.6553, 2014.\n[18] A. Novikov, D. Podoprikhin, A. Osokin, and D. P. Vetrov, “Tensorizing neural networks,” in Advances in Neural Information Processing\nSystems, 2015, pp. 442–450.\n[19] A. Novikov, M. Trofimov, and I. Oseledets, “Exponential machines,”\narXiv preprint arXiv:1605.03795, 2016.\n[20] E. M. Stoudenmire and D. J. Schwab, “Supervised learning with\nquantum-inspired tensor networks,” arXiv preprint arXiv:1605.05775,\n2016.\n[21] T. G. Kolda and B. W. Bader, “Tensor decompositions and applications,”\nSIAM review, vol. 51, no. 3, pp. 455–500, 2009.\n[22] I. Oseledets, “Tensor-train decomposition,” SIAM Journal on Scientific\nComputing, vol. 33, no. 5, pp. 2295–2317, 2011.\n[23] I. Oseledets and E. Tyrtyshnikov, “TT-cross approximation for multidimensional arrays,” Linear Algebra and its Applications, vol. 432, no. 1,\npp. 70–88, 2010.\n[24] D. Savostyanov and I. Oseledets, “Fast adaptive interpolation of multidimensional arrays in tensor train format,” in 2011 7th International\nWorkshop on Multidimensional (nD) Systems (nDs). IEEE, 2011, pp.\n1–8.\n[25] S. Theodoridis and K. Koutroumbas, Pattern Recognition, Fourth Edition, 4th ed. Academic Press, 2008.\n[26] S. R. White, “Density matrix formulation for quantum renormalization\ngroups,” Physical Review Letters, vol. 69, no. 19, p. 2863, 1992.\n[27] S. Holtz, T. Rohwedder, and R. Schneider, “The alternating linear\nscheme for tensor optimization in the tensor train format,” SIAM Journal\non Scientific Computing, vol. 34, no. 2, pp. A683–A713, 2012.\n[28] T. Rohwedder and A. Uschmajew, “On local convergence of alternating\nschemes for optimization of convex problems in the tensor train format,”\nSIAM Journal on Numerical Analysis, vol. 51, no. 2, pp. 1134–1162,\n2013.\n[29] F. Lauer, C. Y. Suen, and G. Bloch, “A trainable feature extractor for\nhandwritten digit recognition,” Pattern Recognition, vol. 40, no. 6, pp.\n1816–1824, 2007.\n[30] J. A. K. Suykens, “Deep restricted kernel machines using conjugate\nfeature duality,” Neural Computation, vol. 29, no. 8, pp. 2123–2163,\n2017.\n\n\f",
         "train",
         "54334",
         "10065"
        ],
        [
         "43",
         "17473",
         "cs.AI",
         "Artificial Intelligence",
         "1712.03249v1.pdf",
         "Social Emotion Mining Techniques\nfor Facebook Posts Reaction Prediction\nFlorian Krebs∗ , Bruno Lubascher*, Tobias Moers*, Pieter Schaap*, Gerasimos Spanakis†\n\narXiv:1712.03249v1 [cs.AI] 8 Dec 2017\n\nDepartment of Data Science and Knowledge Engineering, Maastricht University, Maastricht, Netherlands\nEmail: {florian.krebs, bruno.lubascher, tobias.moers, pieter.schaap}@student.maastrichtuniversity.nl,\njerry.spanakis@maastrichtuniversity.nl\n\nKeywords:\n\nEmotion mining, Social media, Deep Learning, Natural Language Processing\n\nAbstract:\n\nAs of February 2016 Facebook allows users to express their experienced emotions about a post by using\nfive so-called ‘reactions’. This research paper proposes and evaluates alternative methods for predicting these\nreactions to user posts on public pages of firms/companies (like supermarket chains). For this purpose, we collected posts (and their reactions) from Facebook pages of large supermarket chains and constructed a dataset\nwhich is available for other researches. In order to predict the distribution of reactions of a new post, neural\nnetwork architectures (convolutional and recurrent neural networks) were tested using pretrained word embeddings. Results of the neural networks were improved by introducing a bootstrapping approach for sentiment\nand emotion mining on the comments for each post. The final model (a combination of neural network and\na baseline emotion miner) is able to predict the reaction distribution on Facebook posts with a mean squared\nerror (or misclassification rate) of 0.135.\n\n1\n\nINTRODUCTION\n\nThe ability to accurately classify the sentiment of\nshort sentences such as Facebook posts or tweets is\nessential to natural language understanding. In recent\nyears, more and more users share information about\ntheir customer experience on social media pages related to (and managed by) the equivalent firms/companies. Generated data attracts a lot of research towards sentiment analysis with many applications in\npolitical science, social sciences, business, education,\netc. (Ortigosa et al., 2014), (Feldman, 2013), (Troussas et al., 2013).\nCustomer experience (CX) represents a holistic\nperspective on customer encounters with a firm’s\nproducts or services. Thus, the more managers\ncan understand about the experiences customers have\nwith their product and service offerings, the more they\ncan measure them again in the future to influence purchase decisions. The rise of social media analytics\n(Fan and Gordon, 2014) offers managers a tool to\nmanage this process with customer opinion data being\nwidely available on social media. Analysing Facebook posts can help firm managers to better manage\nposts by allowing customer care teams to reply faster\n∗ Denotes\n\nequal contribution\nauthor\n\n† Corresponding\n\nto unsatisfied customers or maybe even delegate posts\nto employees based on their expertise. Also, it would\nbe possible to estimate how the reply on a post affects\nthe reaction from other customers. To our knowledge,\nno previous research work on predicting Facebook reaction posts exists.\nThe main goals and contributions of this paper are\nthe following: (a) contribute a dataset which can be\nused for predicting reactions on Facebook posts, useful for both machine learners and marketing experts\nand (b) perform sentiment analysis and emotion mining to Facebook posts and comments of several supermarket chains by predicting the distribution of the\nuser reactions. Firstly, sentiment analysis and emotion mining baseline techniques are utilized in order\nto analyse the sentiment/emotion of a post and its\ncomments. Afterwards, neural networks with pretrained word embeddings are used in order to accurately predict the distribution of reactions to a post.\nCombination of the two approaches gives a working\nfinal ensemble which leaves promising directions for\nfuture research.\nThe remainder of the paper is organized as follows. Section 2 presents related work about sentiment and emotion analysis on short informal text like\nfrom Facebook and Twitter. The used dataset is described in Section 3, followed by the model (pipeline)\n\n\fdescription in Section 4. Section 5 presents the experimental results and finally, Section 6 concludes the\npaper and presents future research directions.\n\n2\n\nRELATED WORK\n\nDeep learning based approaches have recently become more popular for sentiment classification since\nthey automatically extract features based on word embeddings. Convolutional Neural Networks (CNN),\noriginally proposed in (LeCun et al., 1998) for document recognition, have been extensively used for\nshort sentence sentiment classification. (Kim, 2014)\nuses a CNN and achieves state-of-the art results in\nsentiment classification. They also highlight that\none CNN layer in the model’s architecture is sufficient to perform well on sentiment classification\ntasks. Recurrent Neural Networks (RNN) and more\nspecifically their variants Long Short Term Memory (LSTM) networks (Hochreiter and Schmidhuber,\n1997) and Gated Recurrent Units (GRU) networks\n(Chung et al., 2014) have also been extensively used\nfor sentiment classification since they are able to capture long term relationships between words in a sentence while avoiding vanishing and exploding gradient problems of normal recurrent network architectures (Hochreiter, 1998). (Wang et al., 2014) proves\nthat combining different architectures, such as CNN\nand GRU, in an ensemble learner improves the performance of individual base learners for sentiment classification, which makes it relevant for this research\nwork as well.\nMost of the work on short text sentiment classification concentrates around Twitter and different\nmachine learning techniques (Wang et al., 2011),\n(Kouloumpis et al., 2011), (Saif et al., 2012), (Sarlan\net al., 2014). These are some examples of the extensive research already done on Twitter sentiment analysis. Not many approaches for Facebook posts exist,\npartly because it is difficult to get a labeled dataset for\nsuch a purpose.\nEmotion lexicons like EmoLex (Mohammad and\nTurney, 2013) can be used in order to annotate\na corpus, however, results are not satisfactory and\nthis is the reason that bootstrapping techniques have\nbeen attempted in the past. For example, (Canales\net al., 2016) propose such a technique which enhances\nEmoLex with synonyms and then combines word vectors (Mikolov et al., 2013) in order to annotate more\nexamples based on sentence similarity measures.\nRecently, (Tian et al., 2017) presented some first\nresults which associate Facebook reactions with emojis but their analysis stopped there. (Pool and Nissim,\n\n2016) utilized the actual reactions on posts in a distant supervised fashion to train a support vector machine classifier for emotion detection but they are not\nattempting at actually predicting the distribution of reactions.\nMoreover, analysis of customer feedback is an\narea which gains interest for many companies over\nthe years. Given the amount of text feedback available, there are many approaches around this topic,\nhowever none of them are handling the increasing\namounts of information available through Facebook\nposts. For the sake of completeness, we highlight\nhere some these approaches. Sentiment classification\n((Pang et al., 2002), (Glorot et al., 2011b), (Socher\net al., 2013)) deals only with the sentiment analysis (usually mapping sentiments to positive, negative\nand neutral (or other 5-scale classification) and similarly emotion classification ((Yang et al., 2007), (Wen\nand Wan, 2014) only considers emotions. Some work\nexists on Twitter data (Pak and Paroubek, 2010) but\ndoes not take into account the reactions of Facebook.\nMoreover, work has been conducted towards customer review analysis ((Yang and Fang, 2004), (Hu\nand Liu, 2004), (Cambria et al., 2013)) but none of\nthem are dealing with the specific nature of Facebook\n(or social media in general).\nIn this work, we combine sentiment analysis and\nemotion mining techniques with neural network architectures in order to predict the distribution of reactions on Facebook posts and actually demonstrate that\nsuch an approach is feasible.\n\n3\n\nDATASET CONSTRUCTION\n\nOur dataset consists out of Facebook posts on the\ncustomer service page of 12 US/UK big supermarket/retail chains, namely Tesco, Sainsbury, Walmart,\nAldiUK, The Home Depot, Target, Walgreens, Amazon, Best Buy, Safeway, Macys and publix. The vast\nmajority of these posts are initiated by customers of\nthese supermarkets. In addition to the written text of\nthe posts, we also fetch the Facebook’s reaction matrix 1 as well as the comments attached to this post\nmade by other users. Such reactions only belong to\nthe initial post, and not to replies to the post since the\nfeature to post a reaction on a reply has only been introduced very recently (May 2017) and would result\nin either a very small dataset or an incomplete dataset.\nThese reactions include like, love, wow, haha, sad,\nangry as shown in Figure 1. This form of communication was introduced by Facebook on February 24th,\n1 http://newsroom.fb.com/news/2016/02/\n\nreactions-now-available-globally/\n\n\f2016 and allows users to express an ‘emotion’ towards the posted content.\n\nall previous insights and the fact that there are 25,969\nposts with at least one reaction and since the like reaction dominates the posts, we chose to include posts\nwith at least one reaction which is not a like, leading\nto finally 8,103 posts. Full dataset is available 2 and\nwill be updated as it is curated and validated at the\nmoment of the paper submission.\n\nFigure 1: The Facebook reaction icons that users are able to\nselect for an original post.\n\nIn total, there were more than 70,000 posts without any reaction, thus they were excluded from the\ndataset. Apart from this problem, people are using\nthe ‘like’ reaction not only to show that they like what\nthey see/read but also to simply tell others that they\nhave seen this post or to show sympathy. This results\nin a way too often used ‘like’-reaction which is why\nlikes could be ignored in the constructed dataset. So,\ninstead of using all crawled data, the developed models will be trained on posts that have at least one other\nreaction than likes. After applying this threshold the\nsize of the training set reduced from 70,649 to 25,969.\nThe threshold of 1 is still not optimal since it leaves\nmuch space for noise in the data (e.g. miss-clicked\nreactions) but using a higher threshold will lead to extreme loss of data. Statistics on the dataset and on\nhow many posts ‘survive’ by using different thresholds can be seen in Figure 2.\n\nFigure 3: Reaction match when there is more than one type\n\nFigure 4: Distribution of reactions with different minimum\nthresholds\n\n3.1\n\nPre-processing\n\nPre-processing on the dataset is carried out using the\nStanford CoreNLP parser (Manning et al., 2014) and\nincludes the following steps:\n• Convert everything to lower case\nFigure 2: Amount of survived posts for different thresholds\nincluding/excluding likes\n\nExploratory analysis on the dataset shows that\npeople tend to agree in the reactions they have to\nFacebook posts (which is consistent for building a\nprediction system), i.e. whenever there are more than\none types of reactions they seem to be the same in a\ngreat degree (over 80 %) as can be seen in Figure 3.\nIn addition, Figure 4 shows that even by excluding the\nlike reaction, which seems to dominate all posts, the\ndistribution of the reactions remains the same, even if\nthe threshold of minimum reactions increases. Using\n\n• Replace URLs with “ URL ” as a generic token\n• Replace user/profile links with “ AT USER ” as\na generic token\n• Remove the hash from a hashtag reference (e.g.\n#hashtag becomes “hashtag”)\n• Replace three or more occurrences of one character in a row with the character itself (e.g.\n“looooove” becomes ”love”)\n• Remove sequences containing numbers (e.g.\n“gr34t”)\n2 https://github.com/jerryspan/FacebookR\n\n\fAfterwards, each post is split using a tokenizer\nbased on spaces and after some stop-word filtering\nthe final list of different tokens is derived. Since preprocessing on short text has attracted much attention\nrecently (Singh and Kumari, 2016), we also demonstrate the effect of it on the developed models in the\nExperiments section.\n\nemotion vector. By merging and normalizing all emotion vectors, the final emotion distribution for a particular Facebook post, based on the equivalent comments, can be computed. However, this naive approach yielded poor results, thus several enhancements were considered, implemented and described\nin subsections 4.1.1-4.1.3.\n4.1.1\n\n4\n\nREACTION DISTRIBUTION\nPREDICTION SYSTEM\nPIPELINE\n\nIn this Section, the complete prediction system is\ndescribed. There are three core components: emotion mining applied to Facebook comments, artificial\nneural networks that predict the distribution of the reactions for a Facebook post and a combination of the\ntwo in the final prediction of the distribution of reactions.\n\n4.1\n\nEmotion mining\n\nThe overall pipeline of the emotion miner can be\nfound in Figure 5.\nThe emotion lexicon that we utilize is created by\n(Mohammad and Turney, 2013) and is called NRC\nEmotion Lexicon (EmoLex). This lexicon consists of\n14,181 words with eight basic emotions (anger, fear,\nanticipation, trust, surprise, sadness, joy, and disgust)\nassociated with each word in the lexicon. It is possible that a single word is associated with more than one\nemotion. An example can be seen in Table 1. Annotations were manually performed by crowd-sourcing.\nTable 1: Examples from EmoLex showing the emotion association to the words abuse and shopping.\nabuse\nshopping\n\nAnger\n1\n0\n\nAnticipation\n0\n1\n\nDisgust\n1\n0\n\nFear\n1\n0\n\nJoy\n0\n1\n\nSadness\n1\n0\n\nSurprise\n0\n1\n\nTrust\n0\n1\n\nInspired by the approach of (Canales et al., 2016),\nEmoLex is extended by using WordNet (Fellbaum,\n1998): for every synonym found, new entries are introduced in EmoLex having the same emotion vector\nas the original words. By applying this technique the\noriginal database has increased in size from 14,181\nto 31,485 words that are related to an emotion vector.\nThe lexicon can then be used to determine the emotion of the comments to a Facebook post. For each\nsentence in a comment, the emotion is determined\nby looking up all words in the emotion database and\nthe found emotion vectors are added to the sentence\n\nNegation Handling\n\nThe first technique that was used to improve the quality of the mined emotions is negation handling. By\ndetecting negations in a sentence, the ability to ‘turn’\nthis sentiment or emotion is provided. In this paper\nonly basic negation handling is applied since the majority of the dataset contains only small sentences and\nthis was proved to be sufficient for our goal. The following list of negations and pre- and suffixes are used\nfor detection (based on work of (Farooq et al., 2016)):\nTable 2: Negation patterns\n\nNegations\n\nPrefixes\nSuffixes\n\nno, not, rather, wont, never, none,\nnobody, nothing, neither, nor,\nnowhere, cannot, without, n’t\na, de, dis, il, im, in, ir, mis, non, un\nless\n\nThe following two rules are applied:\n1. The first rule is used when a negation word is instantly followed by an emotion-word (which is\npresent in our emotion database).\n2. The second rule tries to handle adverbs and past\nparticle verbs (Part-of-Speech (POS) tags: RB,\nVBN). If a negation word is followed by one or\nmore of these POS-tags and a following emotionword, the emotion-word’s value will be negated.\nFor example this rule would apply to ‘not very\nhappy’.\nThere are two ways to obtain the emotions of a\nnegated word:\n1. Look up all combinations of negation pre- and\nsuffixes together with the word in our emotion\nlexicon.\n2. If there is no match in the lexicon a manually created mapping is used between the emotions and\ntheir negations. This mapping is shown in Table\n3.\nTable 3: Mapping between emotion and negated emotions.\nAnger\nAnticipation\nDisgust\nFear\nJoy\nSadness\nSurprise\nTrust\n\nAnger\n0\n0\n0\n0\n1\n0\n0\n0\n\nAnticipation\n0\n0\n0\n0\n0\n0\n1\n0\n\nDisgust\n0\n0\n0\n0\n1\n0\n0\n1\n\nFear\n0\n0\n0\n0\n1\n1\n0\n0\n\nJoy\n1\n1\n1\n1\n0\n0\n0\n0\n\nSadness\n0\n0\n0\n0\n1\n0\n0\n0\n\nSurprise\n0\n1\n0\n0\n0\n0\n0\n1\n\nTrust\n0\n0\n1\n1\n0\n0\n1\n0\n\n\fFigure 5: Emotion miner pipeline\n\n4.1.2\n\nSentence similarity measures\n\n(Canales et al., 2016)’s approach is using word vectors (Mikolov et al., 2013) in order to calculate similarities between sentences and further annotate sentences. In the context of this paper, a more recent approach was attempted (Sanjeev Arora, 2017), together\nwith an averaging word vector approach for comparison. (Sanjeev Arora, 2017) creates a representation\nfor a whole sentence instead of only for one word as\nword2vec. The average word vector approach is summing up the word vector of each word and then taking\nthe mean of this sum. To find a similarity between two\nsentences, one then uses the cosine similarity. Surprisingly, both approaches return comparable similarity scores. One main problem which occurred here is\nthat two sentences with different emotions but with\nthe same structure are measured as ‘similar’. This\nproblem is exemplified with an example:\n\nannotations. The SVM is trained as a one-versus-all\nclassifier with a linear kernel (8 models are trained,\none for each emotion of EmoLex) and the TF-IDF\nmodel (Salton and Buckley, 1988) is used for providing the input features. Input consists of a single sentence as data (transformed using the TF-IDF model)\nand an array of 8 values representing the emotions as a\nlabel. With a training/test-split of 80%/20%, the average precision-recall is about 0.93. Full results of the\nSVM training can be seen in Figure 6 together with\nthe precision-recall curve for all emotions. The result\nin this case was judged to be satisfactory in order to\nutilize it for the next step, which is the reaction prediction and is used as presented here.\n\nSentence 1: \"I really love your car.\"\nSentence 2: \"I really hate your car.\"\nSentence2Vec similarity: 0.9278\nAvg vector similarity: 0.9269\nThis high similarity is problematic since the emotions of the two sentences are completely different.\nAlso, one can see that the two models output almost\nthe same result and that there is no advantage by using the approach of (Sanjeev Arora, 2017) over the\nsimple average word vector approach. Hence, the\nsentence similarity measure method to annotate more\nsentences is not suited for this emotion mining task\nbecause one would annotate positive emotions to a\nnegative sentence and was not adapted for further use.\n4.1.3\n\nClassification of not annotated sentences\n\nIf after performing these enhancement steps there remain any non-emotion-annotated sentences, then a\nSupport Vector Machine (SVM) is used to estimate\nthe emotions of these sentences based on the existing\n\nFigure 6: Precision-Recall (ROC) curve using a linear SVM\nin an one-versus-all classifier\n\n4.2\n\nReaction distribution predictor\n\nIn order to predict the distribution of the post reactions, neural networks are built and trained using Tensorflow (Abadi et al., 2016). Two networks were\ntested, based on literature research: a Convolutional\nNeural Network (CNN) and a Recurrent Neural Network (RNN) that uses LSTMs.\n\n\fBoth networks start with a word embedding layer.\nSince the analysed posts were written in English, the\nGloVe (Pennington et al., 2014) pretrained embeddings (with 50 as a vector dimension) were used.\nMoreover, posts are short texts and informal language is expected, thus we opted for using embeddings previously trained on Twitter data instead of the\nWikipedia versions.\n4.2.1\n\nCNN\n\nThe CNN model is based on existing successful architectures (see (Kim, 2014)) but is adapted to give a\ndistribution of reactions as an output. An overview of\nthe used architecture is provided in Figure 7.\nFirst issue to be handled with CNNs is that\nsince they deal with variable length input sentences,\npadding is needed so as to ensure that all posts have\nthe same length. In our case, we padded all posts to\nthe maximum post length which also allows efficient\nbatching of the data. In the example of Figure 7 the\nlength of the sentence is 7 and each word xi is represented by the equivalent word vector (of dimension\n50).\nThe convolutional layer is the core building block\nof a CNN. Common patterns in the training data\nare extracted by applying the convolution operation\nwhich in our case is limited into 1 dimension: we adjust the height of the filter, i.e. the number of adjacent rows (words) that are considered together (see\nalso red arrows in Figure 7). These patterns are then\nfed to a pooling layer. The primary role of the pooling\nlayer is to reduce the spatial dimensions of the learned\nrepresentations (that’s why this layer is also known\nto perform downsampling). This is beneficial, since\nit controls for over-fitting but also allows for faster\ncomputations. Finally, the output of the pooling layer\nis fed to a fully-connected layer (with dropout) which\nhas a softmax as output and each node corresponds to\neach predicted reaction (thus we have six nodes initially). However, due to discarding like reaction later\non in the research stage, the effective number of output nodes was decreased to 5 (see Experiments). The\nsoftmax classifier computes a probability distribution\nover all possible reactions, thus provides a probabilistic and intuitive interpretation.\n4.2.2\n\nFigure 7: Convolutional network architecture example\n\ncapture content as needed. The implementation used\nhere is inspired by (Graves, 2013) and an overivew is\nprovided in Figure 8.\nAn LSTM unit (at each time step t) is defined as\na collection of vectors: the input gate (it ), the forget\ngate ( ft ), the output gate (ot ), a memory cell (ct ) and\na hidden state (ht ). Input is provided sequentially in\nterms of word vectors (xt ) and for each time step t the\nprevious time step information is used as input. Intuitively, the forget gate controls the amount of which\neach unit of the memory cell is replaced by new info,\nthe input gate controls how much each unit is updated,\nand the output gate controls the exposure of the internal memory state.\nIn our case, the RNN model utilizes one recurrent layer (which has 50 LSTM cells) and the rest\nof the parameters are chosen based on current default\nworking architectures. The output then comes from\na weighted fully connected 6-(or 5, depending on the\nnumber of reactions)-class softmax layer. Figure 8\nexplains the idea of recurrent architecture based on\nan input sequence of words.\n\nFigure 8: Recurrent network architecture example\n\n4.3\n\nPrediction ensemble\n\nRNN\n\nLong short-term memory networks (LSTM) were\nproposed by (Hochreiter and Schmidhuber, 1997) in\norder to adress the issue of learning long-term dependencies. The LSTM maintains a separate memory\ncell inside it that updates and exposes its content only\nwhen deemed necessary, thus making it possible to\n\nThe final reaction ratio prediction is carried out by\na combination of the neural networks and the mined\nemotions on the post/comments. For a given post,\nboth networks provide an estimation of the distributions, which are then averaged and normalised. Next,\nemotions from the post and the comments are extracted following the process described in Section 4.1.\n\n\fThe ratio of estimations and emotions are combined\ninto a single vector which is then computed through\na simple linear regression model, which re-estimates\nthe predicted reaction ratios. The whole pipeline\ncombining the emotion miner and the neural networks\ncan be seen in Figure 9 and experimental results are\npresented in the next Section.\n\n5\n\nEXPERIMENTS\n\nSeveral experiments were conducted in order to\nassess different effects on the reaction distribution\nprediction. Firstly, the effect of pre-processing on\nposts is examined in subsection 5.1. Since Facebook\nreactions were not introduced too long ago, a lot of\nposts in the dataset still contain primarily like reactions. This might lead to uninteresting results as described in the Dataset Section and in Subsection 5.2.\nFinally, Subsection 5.3 discusses the training with respect to the mean squared error (MSE) for CNN and\nRNN models, as well as the effect of the ensembled\napproach.\nAs mentioned before, both networks utilized the\nGloVe pre-trained embeddings (with size 50). Batch\nsize was set to 16 for the CNN and 100 for the RNN/LSTM.\nCNN used 40 filters for the convolution (with\nvarying height sizes from 3 to 5), stride was set to\n1 and padding to the maximum post length was used.\nRectified Linear Unit (ReLU) (Glorot et al., 2011a)\nactivation function was used.\nLearning rate was set to 0.001 and dropout was\napplied to both networks and performance was measured by the cross entropy loss with scores and labels\nwith L2-regularization (Masnadi-Shirazi and Vasconcelos, 2009). Mean Squared Error (MSE) is used in\norder to assess successful classifications (which effectively means that every squared error will be a 1) and\nin the end MSE is just the misclassification rate of\npredictions.\n\n5.1\n\nRaw vs Pre-processed Input\n\nIn order to assess the effect of pre-processing on\nthe quality of the trained models, two versions for\neach neural network were trained. One instance\nwas trained without pre-processing the dataset and\nthe other instance was trained with the pre-processed\ndataset. Results are cross-validated and here the average values are reported. Figure 10 indicates that overall the error was decreasing or being close to equal\n(which is applicable for both CNN and RNN). The xaxis represents the minimum number of ‘non-like’ re-\n\nactions in order to be included in the dataset. It should\nbe noted that these models were trained on the basis of having 6 outputs (one for each reaction), thus\nthe result might be affected by the skewed distribution over many ‘like’ reactions. This is the reason\nthat the pre-processed version of CNN performs very\nwell for posts with 5 minimum reactions and very bad\nfor posts with 10 minimum reactions In addition, the\nvariance for the different cross-validation results was\nhigh. In the next subsection we explore what happens\nafter the removal of ‘like’ reactions.\n\n5.2\n\nExclusion of like reactions\n\nEarly results showed that including the original like\nreaction in the models would lead to meaningless results. The huge imbalanced dataset led to predicting\na 100% ratio for the like reaction. In order to tackle\nthis issue, the like reactions are not fed into the models during the training phase (moreover the love reaction can be used for equivalent purposes, since they\nexpress similar emotions). Figure 11 shows an increase of the error when the likes are ignored. The\nexplanation for this increase is related to heavily unbalanced distribution of like reactions: Although there\nis an increase in the error, predictions now are more\nmeaningful than always predicting a like ratio close to\n100%. After all, it is the relative reaction distribution\nthat we are interested in predicting.\n\n5.3\n\nEnsemble performance\n\nTable 4 summarizes the testing error for the CNN and\nRNN with respect to the same split dataset and by\nalso taking the validation error into account. One can\nsee that RNN performs better than CNN, although it\nrequires additional training time. Results are crossvalidated on 10 different runs and variances are presented in the Table as well.\nTable 4: RNN and CNN comparison after cross-validation\n\nCNN\nRNN\n\nMSE\n0.186 (±0.023)\n0.159 (±0.017)\n\n# Epochs\n81\n111\n\nCombined results for either of the networks and\nthe emotion miner can be seen in Figure 12. The networks themselves have the worst results but an average combination of both is able to achieve a better\nresult. Optimal result is achieved by the emotions +\ncnn combination, although this difference is not significant than other combinations. These results can be\nboosted by optimizing the hyperparameters of the networks and also by varying different amount of posts.\n\n\fFigure 9: Pipeline for final prediction of reaction distributions\n\nFigure 10: Effect of pre-processing on different models\n\nFigure 12: Performance results for different combinations\nof the neural networks and emotions.\n\nthis figure, one can see at the input field of the Facebook post on the top and then four different result panels: the first one shows the reaction distribution, the\nsecond panel shows the proportions of the eight emotions, the third panel highlights the emotions (and by\nhovering one can see the total shows the overall distribution (vector of eight) and the fourth panel shows\nthe highlighting of the sentiments.\n\nFigure 11: Effect of inclusion/exclusion of likes on different\nmodels\n\nAs a conclusion one can say that using emotions to\ncombine them with neural network output improves\nthe results of prediction.\nFinally, we present a simple, yet effective visualization environment which highlights the results of\nthe current paper, that can be found in Figure 13. In\n\n6\n\nConclusion\n\nIn this paper, a framework for predicting the Facebook post reaction distribution was presented, trained\non a customer service dataset from several supermarket Facebook posts. This study revealed that a baseline sentiment miner can be used in order to detect\na post sentiment/emotion. Afterwards, these results\ncan be combined with the output of neural network\nmodels to predict the Facebook reactions. While there\n\n\fFigure 13: Example visualisation\n\nhas been a lot of research around sentiment analysis,\nemotion mining is still mostly uncharted territory and\nthis work also contributes to this direction. The used\ndataset is available for other researchers and can be\nalso used as a baseline for performing further experiments. In addition, a more accurate evaluation of the\nemotion miner can be conducted by using the MPQA\ncorpus (Deng and Wiebe, 2015).\nFacebook reaction predictions can clearly enhance\ncustomer experience analytics. Most companies are\ndrowned in social media posts, thus a system that\nidentifies the emotion/reaction prediction of a post in\nalmost real-time can be used to provide effective and\nuseful feedback to customers and improve their experience. So far in the dataset, the reaction of the page\nowner has not been included but this could be useful\ninformation on how the post was addressed (or could\nbe addressed).\nFuture work includes working towards refining the\narchitectures of the neural networks used. Moreover,\none of the next steps is to implement a network that\npredicts the (absolute) amount of reactions (and not\njust the ratio). This number is of course susceptible\nto external parameters (e.g. popularity of the post/poster, inclusion of other media like images or external links, etc.), so another direction would be to include this information as well. More specifically, the\ncombination of images and text can reveal possible\nsynergies in the vision and language domains for sentiment/emotion related tasks.\n\nREFERENCES\nAbadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z.,\nCitro, C., Corrado, G. S., Davis, A., Dean, J., Devin,\nM., et al. (2016). Tensorflow: Large-scale machine\nlearning on heterogeneous distributed systems. arXiv\npreprint arXiv:1603.04467.\nCambria, E., Schuller, B., Xia, Y., and Havasi, C. (2013).\nNew avenues in opinion mining and sentiment analysis. IEEE Intelligent Systems, 28(2):15–21.\nCanales, L., Strapparava, C., Boldrini, E., and Martı́nezBarco, P. (2016). Exploiting a bootstrapping approach\nfor automatic annotation of emotions in texts. 2016\nIEEE International Conference on Data Science and\nAdvanced Analytics (DSAA), pages 726–734.\nChung, J., Gulcehre, C., Cho, K., and Bengio, Y.\n(2014). Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint\narXiv:1412.3555.\nDeng, L. and Wiebe, J. (2015). Mpqa 3.0: An entity/eventlevel sentiment corpus. In Mihalcea, R., Chai, J. Y.,\nand Sarkar, A., editors, HLT-NAACL, pages 1323–\n1328. The Association for Computational Linguistics.\nFan, W. and Gordon, M. D. (2014). The power of social media analytics. Communications of the ACM, 57(6):74–\n81.\nFarooq, U., Nongaillard, A., Ouzrout, Y., and Qadir, M. A.\n(2016). Negation Handling in Sentiment Analysis at\nSentence Level. In Internation Conference on Information Management, Londres, United Kingdom.\nFeldman, R. (2013). Techniques and applications for\nsentiment analysis. Communications of the ACM,\n56(4):82–89.\nFellbaum, C. (1998). WordNet: An Electronic Lexical\nDatabase. Bradford Books.\n\n\fGlorot, X., Bordes, A., and Bengio, Y. (2011a). Deep sparse\nrectifier neural networks. In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, pages 315–323.\nGlorot, X., Bordes, A., and Bengio, Y. (2011b). Domain\nadaptation for large-scale sentiment classification: A\ndeep learning approach. In Proceedings of the 28th\ninternational conference on machine learning (ICML11), pages 513–520.\nGraves, A. (2013). Generating sequences with recurrent\nneural networks. arXiv preprint arXiv:1308.0850.\nHochreiter, S. (1998). The vanishing gradient problem during learning recurrent neural nets and problem solutions. International Journal of Uncertainty, Fuzziness\nand Knowledge-Based Systems, 6(02):107–116.\nHochreiter, S. and Schmidhuber, J. (1997). Long short-term\nmemory. Neural computation, 9(8):1735–1780.\nHu, M. and Liu, B. (2004). Mining and summarizing\ncustomer reviews. In Proceedings of the tenth ACM\nSIGKDD international conference on Knowledge discovery and data mining, pages 168–177. ACM.\nKim, Y. (2014). Convolutional neural networks for sentence\nclassification. CoRR, abs/1408.5882.\nKouloumpis, E., Wilson, T., and Moore, J. D. (2011). Twitter sentiment analysis: The good the bad and the omg!\nIcwsm, 11(538-541):164.\nLeCun, Y., Bottou, L., Bengio, Y., and Haffner, P. (1998).\nGradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324.\nManning, C. D., Surdeanu, M., Bauer, J., Finkel, J.,\nBethard, S. J., and McClosky, D. (2014). The Stanford CoreNLP natural language processing toolkit. In\nAssociation for Computational Linguistics (ACL) System Demonstrations, pages 55–60.\nMasnadi-Shirazi, H. and Vasconcelos, N. (2009). On the\ndesign of loss functions for classification: theory, robustness to outliers, and savageboost. In Advances in\nneural information processing systems, pages 1049–\n1056.\nMikolov, T., Chen, K., Corrado, G., and Dean, J. (2013).\nEfficient estimation of word representations in vector\nspace. arXiv preprint arXiv:1301.3781.\nMohammad, S. M. and Turney, P. D. (2013). Crowdsourcing a word-emotion association lexicon. 29(3):436–\n465.\nOrtigosa, A., Martı́n, J. M., and Carro, R. M. (2014). Sentiment analysis in facebook and its application to elearning. Computers in Human Behavior, 31:527–\n541.\nPak, A. and Paroubek, P. (2010). Twitter as a corpus for\nsentiment analysis and opinion mining. In LREc, volume 10.\nPang, B., Lee, L., and Vaithyanathan, S. (2002). Thumbs\nup?: sentiment classification using machine learning techniques. In Proceedings of the ACL-02 conference on Empirical methods in natural language\nprocessing-Volume 10, pages 79–86. Association for\nComputational Linguistics.\nPennington, J., Socher, R., and Manning, C. D. (2014).\nGlove: Global vectors for word representation. In\n\nEmpirical Methods in Natural Language Processing\n(EMNLP), pages 1532–1543.\nPool, C. and Nissim, M. (2016). Distant supervision for\nemotion detection using facebook reactions. arXiv\npreprint arXiv:1611.02988.\nSaif, H., He, Y., and Alani, H. (2012). Semantic sentiment\nanalysis of twitter. The Semantic Web–ISWC 2012,\npages 508–524.\nSalton, G. and Buckley, C. (1988). Term-weighting approaches in automatic text retrieval. Information processing & management, 24(5):513–523.\nSanjeev Arora, Yingyu Liang, T. M. (2017). A simple but\ntough-to-beat baseline for sentence embeddings.\nSarlan, A., Nadam, C., and Basri, S. (2014). Twitter sentiment analysis. In Information Technology and Multimedia (ICIMU), 2014 International Conference on,\npages 212–216. IEEE.\nSingh, T. and Kumari, M. (2016). Role of text preprocessing in twitter sentiment analysis. Procedia\nComputer Science, 89:549–554.\nSocher, R., Perelygin, A., Wu, J., Chuang, J., Manning,\nC. D., Ng, A., and Potts, C. (2013). Recursive deep\nmodels for semantic compositionality over a sentiment treebank. In Proceedings of the 2013 conference\non empirical methods in natural language processing,\npages 1631–1642.\nTian, Y., Galery, T., Dulcinati, G., Molimpakis, E., and Sun,\nC. (2017). Facebook sentiment: Reactions and emojis.\nSocialNLP 2017, page 11.\nTroussas, C., Virvou, M., Espinosa, K. J., Llaguno, K., and\nCaro, J. (2013). Sentiment analysis of facebook statuses using naive bayes classifier for language learning. In Information, Intelligence, Systems and Applications (IISA), 2013 Fourth International Conference\non, pages 1–6. IEEE.\nWang, G., Sun, J., Ma, J., Xu, K., and Gu, J. (2014). Sentiment classification: The contribution of ensemble\nlearning. Decision support systems, 57:77–93.\nWang, X., Wei, F., Liu, X., Zhou, M., and Zhang, M. (2011).\nTopic sentiment analysis in twitter: a graph-based\nhashtag sentiment classification approach. In Proceedings of the 20th ACM international conference\non Information and knowledge management, pages\n1031–1040. ACM.\nWen, S. and Wan, X. (2014). Emotion classification in microblog texts using class sequential rules. In AAAI,\npages 187–193.\nYang, C., Lin, K. H.-Y., and Chen, H.-H. (2007). Emotion\nclassification using web blog corpora. In Web Intelligence, IEEE/WIC/ACM International Conference on,\npages 275–278. IEEE.\nYang, Z. and Fang, X. (2004). Online service quality dimensions and their relationships with satisfaction: A\ncontent analysis of customer reviews of securities brokerage services. International Journal of Service Industry Management, 15(3):302–326.\n\n\f",
         "train",
         "37749",
         "5872"
        ],
        [
         "44",
         "17289",
         "cs.AI",
         "Artificial Intelligence",
         "1802.06485v1.pdf",
         "Robust Estimation via Robust Gradient Estimation\n\narXiv:1802.06485v1 [stat.ML] 19 Feb 2018\n\nAdarsh Prasad‡\n\nArun Sai Suggala‡\n\nSivaraman Balakrishnan†\n\nPradeep Ravikumar‡\n\nMachine Learning Department‡\nDepartment of Statistics†\nCarnegie Mellon University,\nPittsburgh, PA 15213.\nAbstract\nWe provide a new computationally-efficient class of estimators for risk minimization.\nWe show that these estimators are robust for general statistical models: in the classical Huber ǫ-contamination model and in heavy-tailed settings. Our workhorse is a novel\nrobust variant of gradient descent, and we provide conditions under which our gradient descent variant provides accurate estimators in a general convex risk minimization problem.\nWe provide specific consequences of our theory for linear regression, logistic regression\nand for estimation of the canonical parameters in an exponential family. These results\nprovide some of the first computationally tractable and provably robust estimators for\nthese canonical statistical models. Finally, we study the empirical performance of our\nproposed methods on synthetic and real datasets, and find that our methods convincingly\noutperform a variety of baselines.\n\n1\n\nIntroduction\n\nRobust estimation has a rich history in statistics with seminal contributions due to Box [4],\nTukey [42], Huber [24], Hampel [21] and several others. In the classical analysis of statistical\nestimators, statistical guarantees are derived under strong model assumptions and in most\ncases these guarantees hold only in the absence of arbitrary outliers, and other deviations from\nthe model assumptions. Strong model assumptions are rarely met in practice, and this has led\nto the development of robust inferential procedures and various associated statistical concepts\nsuch as the influence function, the breakdown point and the Huber ǫ-contamination model to\nassess the robustness of estimators. Despite this progress however, the statistical methods with\nthe strongest robustness guarantees, for instance those based on non-convex M -estimators [24],\nℓ1 tournaments [13, 15, 45] and notions of depth [10, 20, 38], are computationally intractable.\nIn this paper, we present a class of estimators that are computationally tractable and have\nstrong robustness guarantees.\nThe estimators we propose are obtained by robustifying classical algorithms for risk minimization and are applicable to a wide-range of parametric statistical models for which parameter estimation can be cast within this framework. In contrast to classical work, for instance\non M-estimation, we do not attempt to replace the risk minimization objective with a robust\ncounterpart but instead focus on making canonical gradient-based optimization for the usual\nrisk minimization objective robust. We find that this shift in perspective enables a unified\ntreatment of different statistical models, leads to computationally tractable estimators and\nleads to estimators with strong robustness guarantees.\nIn the risk minimization framework, the target parameter θ ∗ is defined as the solution to\nan optimization problem:\n\u0003\n\u0002\n(1)\nθ ∗ = argmin R(θ) ≡ argmin Ez∼P L(θ; z) ,\nθ∈Θ\n\nθ∈Θ\n\n1\n\n\fwhere L is an appropriate loss-function, R is the population risk and Θ is the set of feasible\nparameters. The goal of empirical risk minimization procedures is then to compute an approximate minimizer to the above program when given access to samples Dn = {z1 , . . . , zn }.\nIn this classical setting, a standard assumption that is imposed on Dn is that the data has no\noutliers, and has no arbitrary deviations from model assumptions; i.e., it is typically assumed\nthat each of the zi ’s are independent and identically distributed according to the distribution\nP . Many analyses of risk minimization further assume that P follows a sub-gaussian distribution, or has otherwise well-controlled tails in order to appropriately control the deviation\nbetween the population risk and its empirical counterpart.\nWhile our general results can be specialized to obtain results for a variety of models and\nnotions of robustness, we focus on developing estimators which are robust to two canonical\nclasses of deviations from the model assumptions:\n1. Robustness to arbitrary outliers: In this setting, we focus on Huber’s ǫ-contamination\nmodel, where rather than observe samples directly from P in (1) we instead observe samples drawn from Pǫ which for an arbitrary distribution Q is defined as:\nPǫ = (1 − ǫ)P + ǫQ.\nThe distribution Q allows for arbitrary outliers, which may correspond to gross corruptions or more subtle deviations from the assumed model. This model can be equivalently\nviewed as model mis-specfication in the Total Variation (TV) metric.\n2. Robustness to heavy-tails: In this setting, we are interested in developing estimators\nunder weak moment assumptions. We assume that the distribution P from which we\nobtain samples only has finite low-order moments (see Section 5.4 for a precise characterization). Such heavy tailed distributions arise frequently in the analysis of financial data\nand large-scale biological datasets (see for instance examples in [18, 47]). In contrast to\nclassical analyses of empirical risk minimization [43], in this setting the empirical risk\nis not uniformly close to the population risk, and methods that directly minimize the\nempirical risk perform poorly (see Section 4).\nThe goal of our work is to develop estimators which are computationally tractable and robust\nin these models. Below, we provide an outline of our results and contributions.\n1. Our first contribution is to introduce a new class of robust estimators for risk minimization (1). These estimators are based on robustly estimating gradients of the population\nrisk, and are computationally tractable by design. Building on prior work for robust\nmean estimation in the Huber model [29], and in the heavy-tailed model [37], we design\nrobust gradient estimators for the population risk in (1). Our main insight is that in\nthis general risk minimization setting, the gradient of the population risk is simply a\nmultivariate mean vector, and we can leverage prior work on mean estimation to design robust gradient estimators. Through this we are able to significantly generalize the\napplicability of mean estimation methods to general parametric models.\n2. Our estimators are practical and our second contribution is to conduct extensive numerical experiments on real and simulated data with our proposed estimators. We provide\nguidelines for tuning parameter selection and we compare the proposed estimators with\nseveral competitive baselines [3, 19, 24]. Across different settings and according to various metrics we find that our estimators consistently perform well.\n2\n\n\f3. Finally, we provide rigorous robustness guarantees for the estimators we propose for\na variety of canonical statistical models including for linear regression, for logistic regression and for estimation of the canonical parameters in an exponential family. Our\ncontributions in this direction are two-fold: building on prior work [2] we provide a general result on the stability of gradient descent for risk minimization, showing that in\nfavorable cases gradient descent can be quite tolerant to inaccurate gradient estimates.\nSubsequently, in concrete settings we provide a careful analysis of the quality of gradient\nestimation afforded by our proposed gradient estimators and combine these results to\nobtain guarantees on our final estimates.\nBroadly, as we discuss in the sequel, our work suggests that estimators which are based on\nrobust gradient estimation offer a variety of practical, conceptual, statistical and computational\nadvantages for robust estimation.\n\n1.1\n\nRelated Work\n\nThere is extensive work broadly in the area of robust statistics (see for instance [21] and\nreferences therein), and we focus this section on some lines of work that are most related\nto this paper. Classical work has already developed several estimators which are known to\nbe optimally robust for a variety of inferential tasks, including hypothesis testing [26], mean\nestimation [38], general parametric estimation [11, 15, 45], and non-parametric estimation [13].\nHowever, a major drawback of this classical line of work has been that most of the estimators\nwith strong robustness guarantees are computationally intractable [42], while the remaining\nones are heuristics which are not optimal [22].\nRecently, there has been a flurry of research in theoretical computer science [9, 14, 16, 29,\n32] designing provably robust estimators which are computationally tractable while achieving\nnear-optimal contamination dependence for special classes of problems. Some of the proposed\nalgorithms, are not practical as they rely on the ellipsoid algorithm or require solving semidefinite programs [9, 14, 16, 32] which can be slow for modern problem sizes. We build on\nthe work of Lai et al. [29], who study practical robust mean and covariance estimators for\ndistributions with appropriately controlled moments. A complementary line of recent research\n[10, 20] has focused on providing minimax upper and lower bounds on the performance of\nestimators under ǫ-contamination model, without the constraint of computational tractability.\nIn the ǫ-contaminated model, Q can be arbitrary, but there has been a lot of work in settings\nwhere the contamination distribution is restricted in various ways. For example, recent work in\nhigh-dimensional statistics (for instance [7, 12, 33, 34, 46]) have studied problems like principal\ncomponent analysis and linear regression under the assumption that the corruptions are evenly\nspread throughout the dataset.\nAnother line of research has focused on designing robust estimators under the heavy tailed\ndistribution setting. These approaches relax the sub-gaussian or sub-exponential distributional\nassumptions that are typically imposed on the target distribution P and allow it to be a heavy\ntailed distribution. Most of the approaches in this category use robust mean estimators [8, 31]\nthat exhibit sub-gaussian type concentration around the true mean for distributions satisfying\nmild moment assumptions. The median-of-means estimator [31] and Catoni’s mean estimator\n[8] are two popular examples of such robust mean estimators.\nHsu and Sabato [23] use the median-of-means estimator to develop an alternative to ERM\nunder heavy tails. Although this estimator has strong theoretical guarantees and is computationally tractable, as noted by the authors in [23] it performs poorly in practice. In recent\n3\n\n\fwork Brownlees et al. [5] replace empirical mean in the empirical risk minimization framework\n(ERM) with Catoni’s mean estimator and perform risk minimization. The authors provide risk\nbounds similar to the bounds one can achieve under sub-gaussian distributional assumptions.\nHowever, their estimator is not easily computable and the authors do not provide a practical\nalgorithm to compute the estimator. Other recent works by Lerasle and Oliveira [31], Lugosi\nand Mendelson [35] use similar ideas to derive estimators that perform well theoretically, in\nheavy-tailed situations. However, these approaches involve optimization of complex objectives\nfor which no computationally tractable algorithms exist. We emphasize that in contrast to\nour work, these works focus on robustly estimating the population risk which does not directly\nlead to a computable estimator. We instead consider robustly estimating the gradient of the\npopulation risk. When complemented with the gradient descent algorithm this leads naturally\nto a computable estimator.\n\n1.2\n\nOutline\n\nWe conclude this section with a brief outline of the remainder of the paper. In Section 2, we\nprovide some background on risk minimization and the Huber and heavy-tailed noise models.\nIn Section 3, we introduce our class of estimators and provide concrete algorithms for the\nǫ-contaminated and heavy-tailed setting. In Section 4 we study the empirical performance of\nour estimator on a variety of tasks and datasets. We complement our empirical results with\ntheoretical guarantees in Sections 5, 6 and 7. We defer technical details to the Appendix.\nFinally, we conclude in Section 8 with a discussion of some open problems.\n\n2\n\nBackground and Problem Setup\n\nIn this section we provide the necessary background on risk minimization, gradient descent\nand introduce two notions of robustness that we consider in this work.\n\n2.1\n\nRisk Minimization and Parametric Estimation\n\nIn the setting of risk minimization, we assume that we have access to a differentiable\n\u0003 loss\n\u0002\nfunction L : Θ × Z 7→ R, where Θ is a convex subset of Rp . Let R(θ) = Ez∼P L(θ; z) be the\npopulation loss (risk), and let θ ∗ be the minimizer of the population risk R(θ), over the set Θ\nθ ∗ = argmin R(θ).\n\n(2)\n\nθ∈Θ\n\nThe goal of risk minimization is to minimize the population risk R(θ), given only n samples\nDn = {zi }ni=1 . Whereas in parameter estimation we are interested in estimating the unknown\nparameter θ ∗ from samples Dn .\nIn this work we assume that the population risk is convex to ensure tractable minimization.\nMoreover, in order to ensure identifiability of the parameter θ ∗ , we impose two standard\nregularity conditions [6] on the population risk. These properties are defined in terms of the\nerror of the first-order Taylor approximation of the population risk, i.e. defining, τ (θ1 , θ2 ) :=\nR(θ1 ) − R(θ2 ) − h∇R(θ2 ), θ1 − θ2 i, we assume that\nτℓ\nτu\nkθ1 − θ2 k22 ≤ τ (θ1 , θ2 ) ≤ kθ1 − θ2 k22 ,\n2\n2\n\n(3)\n\nwhere the parameters τℓ , τu > 0 denote the strong-convexity and smoothness parameters\nrespectively.\n4\n\n\f2.2\n\nGradient Descent and Empirical Risk Minimization\n\nA starting point for the techniques we develop in this paper is the classical projected gradient\ndescent method for empirical risk minimization. Given data Dn = {zi }ni=1 , empirical risk\nminimization (ERM) estimates the unknown parameter θ ∗ as the minimizer of the empirical\nrisk, i.e.\nn\n\n1X\nL(θ; zi ).\nθbn = argmin Rn (θ) :=\nn\nθ∈Θ\ni=1\n\nA popular method for solving this optimization problem is projected gradient descent. Projected gradient descent generates a sequence of iterates {θ t }∞\nt=0 , by refining an initial parameter\nθ0 ∈ Θ via the update:\n\u0001\nθ t+1 = PΘ θ t − η∇Rn (θ t ) ,\n\nwhere η > 0 is the step size and Pθ is the projection operator onto Θ. Despite its simplicity, the\ngradient descent method is not robust for general convex losses. Furthermore, the empirical\nrisk minimizer is a poor estimator of θ ∗ in the presence of outliers in the data: since ERM\ndepends on the sample mean, outliers in the data can effect the sample mean and lead ERM\nto sub-optimal estimates. This observation has led to a large body of research that focuses\non developing robust M-estimators which have favorable statistical properties, but are often\ncomputationally intractable.\nIn this work we take a different approach. \u0002Our work\u0003 relies on an important observation\nthat the gradient of the population risk (Ez∼P ∇L(θ; z) ) is simply a mean vector: one that\ncan be estimated robustly by leveraging recent advances in robust mean estimation [29, 37].\nThis leads to a general method for risk minimization based on robust gradient estimation (see\nAlgorithm 1).\n\n2.3\n\nRobust Estimation\n\nOne of the goals of this work is to develop general statistical estimation methods that are\nrobust in one of the following two models: Huber’s ǫ-contamination model or the heavy-tailed\nmodel. We now briefly review these two notions of robustness.\n1. Huber’s ǫ-contamination model:\nHuber [25, 26] proposed the ǫ-contamination\nmodel where we observe samples that are obtained from a mixture of the form\nPǫ = (1 − ǫ)P + ǫQ,\n\n(4)\n\nwhere P is the true distribution, ǫ is the expected fraction of outliers and Q is an\narbitrary outlier distribution. Given i.i.d. observations drawn from \u0002Pǫ , our \u0003objective is\nto estimate θ ∗ , the minimizer of the population risk R(θ) = Ez∼P L(θ; z) , robust to\nthe contamination from Q.\n2. Heavy-tailed model: In the heavy-tailed model it is assumed that the data follows\na heavy-tailed distribution (i.e, P is heavy-tailed). While heavy-tailed distributions\nhave various possible characterizations: in this paper we consider a characterization via\ngradients.\nFor a fixed θ ∈ Θ we let Pgθ denote the multivariate distribution of the gradient of\npopulation loss, i.e. ∇L(θ; z). We refer to a heavy-tailed distribution as one for which\n5\n\n\fPgθ has finite second moments for any θ ∈ Θ. As we illustrate in Section 7, in various\nconcrete examples this translates to relatively weak low-order moment assumptions on\nthe data distribution P .\nGiven n i.i.d observations from P , our objective is to estimate the minimizer of the\npopulation risk. From a conceptual standpoint, the classical analysis of risk-minimization\nwhich relies on uniform concentration of the empirical risk around the true risk, fails in\nthe heavy-tailed setting necessitating new estimators and analyses [5, 23, 35, 36].\n\n3\n\nGradient Estimation\n\nGradient descent and its variants are at the heart of modern optimization and are well-studied\nin the literature. Suppose we have access to the true distribution Pθ∗ . Then to minimize the\npopulation risk R(θ), we can use projected gradient descent, where starting at some initial θ 0\nand for an appropriately chosen step-size η, we update our estimate according to:\nθ t+1 ← PΘ (θ t − η∇R(θ t )).\n\n(5)\n\nHowever, we only have access to n samples Dn = {zi }ni=1 . The key technical challenges are\nthen to estimate the gradient of R(θ) from samples Dn , and to ensure that an appropriate\nmodification of gradient descent is stable to the resulting estimation error.\nTo address the first challenge we observe that the gradient of the\u0002 population\n\u0003 risk at any\npoint θ is the mean of a multivariate distribution, i.e. ∇R(θ) = Ez∼P ∇L(θ; z) . Accordingly,\nthe problem of gradient estimation can be reduced to a multivariate mean estimation problem,\nwhere our goal is to robustly estimate the true mean ∇R(θ) from n samples {∇L(θ; zi )}ni=1 .\nFor a given sample-size n and confidence parameter δ ∈ (0, 1) we define a gradient estimator:\nDefinition 1. A function g(θ; Dn , δ) is a gradient estimator, if for functions α and β, with\nprobability at least 1 − δ, at any fixed θ ∈ Θ, the estimator satisfies the following inequality:\nkg(θ; Dn , δ) − ∇R(θ)k2 ≤ α(n, δ)kθ − θ ∗ k2 + β(n, δ).\n\n(6)\n\nIn subsequent sections, we will develop conditions under which we can obtain gradient estimators with strong control on the functions α(n, δ) and β(n, δ) in the Huber and heavy-tailed\nmodels. Furthermore, by investigating the stability of gradient descent we will develop sufficient conditions on these functions such that gradient descent with an inaccurate gradient\nestimator still returns an accurate estimate.\nTo minimize R(θ), we replace ∇R(θ) in equation (5) with the gradient estimator g(θ; Dn , δ)\nand perform projected gradient descent. In order to avoid complex statistical dependency\nissues that can arise in the analysis of gradient descent, for our theoretical results we consider\na sample-splitting variant of the algorithm where each iteration is performed on a fresh batch\nof samples (see Algorithm 1). We further assume that the number of gradient iterations T is\nspecified a-priori, and accordingly we define:\njnk\nδ\nand δe = ,\n(7)\nn\ne=\nT\nT\n\nWe discuss methods for selecting T , and the impact of sample-splitting in later sections. As\nconfirmed in our experiments (see Section 4), sample-splitting should be viewed as a device\nintroduced for theoretical convenience which can likely be eliminated via more complex uniform\narguments (see for instance the work [2]).\n6\n\n\fAlgorithm 1 Projected Gradient Descent\nfunction PGD({z1 , . . . , zn }, Step Size η, Number of Iterations T , δ)\ne.\nSplit samples into T subsets {Zt }Tt=1 of size n\nfor t = 0 to T − 1 do\n\u0010\n\u0011\ne k2 .\nθ t+1 = argminθ∈Θ kθ − θ t − ηg(θ t ; Zt , δ)\n2\nend for\nend function\n\nNext, we consider the two notions of robustness described in Section 2, and derive specific\ngradient estimators for each of the models using the framework described above. Although\nthe major focus of this work is on Huber contamination and heavy-tailed models, our class of\nestimators are more general and are not restricted to these two notions of robustness.\n\n3.1\n\nGradient Estimation in Huber’s ǫ-contamination model\n\nThere has been a flurry of recent interest [9, 14, 16, 29, 32] in designing mean estimators\nwhich, under the Huber contamination model, can robustly estimate the mean of a random\nvector. While some of these results are focused on the case where the uncorrupted distribution\nis Gaussian, or isotropic, we are more interested in robust mean oracles for more general\ndistributions. Lai et al. [29] proposed a robust mean estimator for general distributions,\nsatisfying weak moment assumptions, and we leverage the existence of such an estimator to\ndesign a Huber gradient estimator g(θ; Dn , δ) which works in the Huber contamination model\n(see Algorithm 2).\nNow, we briefly describe the main idea behind Algorithm 2 and the mean estimator of Lai\net al. [29]. The algorithm builds upon the fact that in one-dimension, it is relatively easy to\nestimate the gradient robustly. In higher-dimension, the crucial insight of Lai et al. [29] is that\nthe effect of the contamination Q on the mean of uncontaminated distribution P is effectively\none-dimensional provided we can accurately estimate the direction along which the mean is\nshifted. In our context, if we can compute the gradient shift direction, i.e. the direction\nof the difference between the sample (corrupted) mean gradient and the true (population)\ngradient, then the true gradient can be estimated by using a robust 1D-mean algorithm along\nthe gradient-shift direction and a non-robust sample-gradient in the orthogonal direction since\nthe contamination has no effect on the gradient in this orthogonal direction. In order to\nidentify the gradient shift direction, we use a recursive Singular Value Decomposition (SVD)\nbased algorithm. In each stage of the recursion, we first remove gross-outliers via a truncation\nalgorithm (described in more detail in the Appendix) and subsequently identify two subspaces\nusing an SVD – a clean subspace where the contamination has a small effect on the mean\nand another subspace where the contamination has a potentially larger effect. We use a\nsimple sample-mean estimator in the clean subspace and recurse our computation on the\nother subspace. Building on the work of Lai et al. [29], in Lemma 1 and Appendix J we\nprovide a careful analysis of this gradient estimator.\n7\n\n\fAlgorithm 2 Huber Gradient Estimator\nfunction HuberGradientEstimator(Sample Gradients S = {∇L(θ; zi )}ni=1 , Corruption Level ǫ, Dimension p, δ)\nSe = HuberOutlierGradientTruncation(S, ǫ, p, δ).\nif p=1 then\ne\nreturn mean(S)\nelse\ne\nLet ΣSe be the covariance matrix of S.\nLet V be the span of the top p/2 principal components of ΣSe and W be its complement.\ne where PV is the projection operation on to V .\nSet S1 := PV (S)\nLet µ\nbV := HuberGradientEstimator(S1 , ǫ, p/2, δ).\ne\nLet µ\nbW := mean(PW S).\np\nLet µ\nb ∈ R be such that PV (b\nµ) = µ\nbV , and PW (b\nµ) = µ\nbW .\nreturn µ\nb.\nend if\nend function\n\n3.2\n\nGradient Estimation in the Heavy-Tailed model\n\nTo design gradient estimators for the heavy-tailed model, we leverage recent work on designing\nrobust mean estimators in this setting. These robust mean estimators build on the classical\nwork of Alon et al. [1], Nemirovski and Yudin [39] and Jerrum et al. [27] on the so-called\nmedian-of-means estimator. For the problem of one-dimensional mean estimation, Catoni\n[8], Lerasle and Oliveira [31] propose robust mean estimators that achieve exponential concentration around the true mean for any distribution with bounded second moment. In this work\nwe require mean estimators for multivariate distributions. Several recent works ([23, 36, 37])\nextend the median-of-means estimator of to general metric spaces. In this paper we use the\ngeometric median-of-means estimator (Gmom), which was originally proposed and analyzed\nby Minsker [37], to design the gradient estimator g(θ; Dn , δ).\nThe basic idea behind the Gmom estimator is to first split the samples into non-overlapping\nsubsamples and estimate the sample mean of each of the subsamples. Then the Gmom estimator is given by the median-of-means of the subsamples. Formally, let {xi . . . xn } ∈ R be n i.i.d\nrandom variables sampled from a distribution P . Then the Gmom estimator for estimating\nthe mean of P can be described as follows. Partition the n samples into b blocks B1 , P\n. . . Bb each\n1\nof size ⌊n/b⌋. Let {b\nµ1 , . . . , µ\nbb } be the sample means in each block, where µ\nbi = |Bi | xj ∈Bi xj .\nThen the Gmom estimator is given by median{b\nµ1 , . . . µ\nbb }. In high dimensions where different\nnotions of the median have been considered Minsker [37] uses geometric median:\nµ\nb = argmin\nµ\n\nb\nX\ni=1\n\nkµ − µ\nbi k2 .\n\nAlgorithm 3 presents the gradient estimator g(θ; Dn , δ) obtained using Gmom as the mean\nestimator.\n8\n\n\fAlgorithm 3 Heavy Tailed Gradient Estimator\nfunction HeavyTailedGradientEstimator(Sample Gradients S = {∇L(θ; zi )}ni=1 ,\nδ)\nDefine number of buckets b = 1 + ⌊3.5 log 1/δ⌋.\nPartition S into b blocks B1 , . . . Bb each of size ⌊n/b⌋.\nfor i = 1 . . . nX\ndo\ns.\nµ\nbi = |B1i |\ns∈Bi\n\nend for\n\nLet µ\nb = argmin\nµ\n\nreturn µ\nb.\nend function\n\n4\n\nb\nX\ni=1\n\nkµ − µ\nbi k2 .\n\nExperiments\n\nIn this section we demonstrate our proposed methods for Huber contamination and heavytailed models, on a variety of simulated and real data examples.\n\n4.1\n\nHuber Contamination\n\nWe first consider the Huber contamination model and demonstrate the practical utility of\ngradient-descent based robust estimator described in Algorithms 1 and 2.\n4.1.1\n\nSynthetic Experiments: Linear Regression\n\nIn linear regression we observe paired samples {(x1 , y1 ), . . . (xn , yn )}, where each (xi , yi ) ∈\nRp × R. We assume that the (x, y) pairs sampled from the true distribution P are linked via\na linear model:\ny = hx, θ ∗ i + w,\n\n(8)\n\nwhere w is drawn from a zero-mean normal distribution with variance σ 2 (w ∼ N (0, σ 2 )). We\nuse the squared loss as our loss function\n1\nL(θ; (x, y)) = (y − hx, θi)2 .\n2\nNote that the true parameter θ ∗ is the minimizer of the resulting population risk R(θ). We\nnow describe the experiment setup, the data model and present the results.\nSetup We fix the contamination level ǫ = 0.1 and σ 2 = 0.1. Next, we generate (1 − ǫ)n\nclean covariates from x ∼ N (0, Ip ), the corresponding clean responses using y = hx, θ ∗ i + w\nwhere θ ∗ = [1, . . . , 1]T and w ∼ N (0, σ 2 ). We simulate an outlier distribution by drawing\nthe covariates from N (0, p2 Ip ), and setting the responses to 0. The total number of samples\nare set to be(10 ǫp2 ) i.e. the sample size increases with the dimension. This scaling is used to\nensure that the statistical (minimax) error, in the absence of any contamination, is roughly\n0.001. An optimally robust method should have error close to 0.1 (roughly equal to corruption\nlevel), which ours does (see Figure 1).\n9\n\n\f25\n\n1.7\nOLS\nRobustGD\nTORRENT\nHuber\nPlugin\nRANSAC\n\n1.6\n1.5\n\nParameter Error\n\n||θb − θ∗ ||2\n\n20\n\n×10-3\n\n15\n\n10\n\n1.4\n1.3\n1.2\n1.1\n\n5\n\n1\n0\n100\n\n150\n\n200\n\n250\n\n300\n\n350\n\n400\n\n450\n\n0.9\n0.1\n\n500\n\n0.15\n\n0.2\n\np\n\n0.25\n\n0.3\n\nǫ\n\n(a) Parameter error vs p for ǫ = 0.1\n\n(b) Parameter error vs ǫ\n\n3\nepsilon=0.1\nepsilon=0.2\nepsilon=0.3\nepsilon=0.4\n\nlog(Parameter Error)\n\n2\n\n1\n\n0\n\n-1\n\n-2\n\n-3\n0\n\n10\n\n20\n\n30\n\n40\n\n50\n\n60\n\nIterations\n\n(c) log(kθt − θ∗ k2 ) vs t for different ǫ.\n\nFigure 1: Robust Linear Regression.\nMetric We measure the parameter error in ℓ2 -norm. We also study the convergence properties of our proposed method, for different contamination levels ǫ. We use code provided by\nLai et al. [29] to implement our gradient estimator.\nBaselines We use OLS, TORRENT [3], Huber-loss, RANSAC and plugin estimator as our\nbaselines. TORRENT is an iterative hard-thresholding based alternating minimization algorithm, where in one step, it calculates an active set of examples by keeping only (1−ǫ)n samples\nwhich have the smallest absolute values of residual r = y − x, θ t , and in the other step it\nupdates the current estimates by solving OLS on the active set. Bhatia et al. [3] had shown the\nsuperiority of TORRENT over other convex-penalty based outlier techniques, hence, we do\nnot compare against those methods.P\nThe plugin estimator is implemented using\nP Algorithm 2\nto estimate both the mean vector n1 ni=1 yi xi and the covariance matrix n1 ni=1 xi xTi .\nResults We summarize our main findings here.\n1. All estimators except our proposed algorithm perform poorly (Figure 1(a)). Note that the\nTORRENT algorithm has strong guarantees when only the response y is corrupted but\n10\n\n\fperforms poorly in the Huber contamination model where both x and y may be contaminated. The error for the robust plugin estimator increases with dimension. We investigate\nthis theoretically in Section 6.1, where we find that the error of the plugin estimator grows\n√\nwith the norm of θ ∗ . In our experiment, we choose kθ ∗ k2 = p, and thus Figure 1(a)\ncorroborates Corollary 3 in Section 6.1.\n2. In Figure 1(b) we find that the parameter error kθb − θ ∗ k2 increases linearly with the contamination rate ǫ and we study this further in Section 6.1.\n\n3. Finally, Figure 1(c) shows that the convergence rate decreases with increasing contamination ǫ and after ǫ is high enough, the algorithm remains stuck at θ0 , corroborating Lemma 8\n(in the Appendix).\nNext, we study the performance of our proposed method in the context of classification.\n4.1.2\n\nSynthetic Experiments: Logistic Regression\n\nIn logistic regression we observe paired samples, {(x1 , y1 ), . . . , (xn , yn )} where each (xi , yi ) ∈\nRp × R. We assume that the (x, y) pairs sampled from the true distribution P are linked via\na linear model:\n(\n1\n1 with probability 1+exp(−hx,\nθ ∗ i) ,\n(9)\ny=\n0 otherwise.\nIn this case, we use the negative conditional log-likelihood as our loss function, i.e.\nL(θ; (x, y)) = −yhx, θi + log(1 + exp(hx, θi)).\n\nSetup We simulate a linearly separable classification problem, where the clean covariates are\nsampled from N (0, Ip ), the corresponding clean responses are computed as y = sign(hx, θ ∗ i)\n√\n√\nwhere θ ∗ = [1/ p, . . . , 1/ p]T . We simulate the outlier distribution by adding asymmetric\nnoise, i.e. we flip the labels of one class, and increase the variance of the corresponding\ncovariates by multiplying them by p2 . The total number of samples are set to be (10 pǫ ).\nMetric We measure the 0-1 classification error on a separate (clean) test set. We study how\nthe 0-1 error changes with p and ǫ and the convergence properties(parameter error) of our\nproposed method for different contamination levels ǫ.\nBaselines We use the logistic regression MLE and the linear Support Vector Machine (SVM)\nas our baselines.\nResults Figures 2(b) and 2(c) show qualitatively similar results to the linear regression\nsetting, i.e. that the error of our proposed estimator degrades gracefully (and grows linearly)\nwith the contamination level ǫ and that the gradient descent iterates converge linearly. In\nFigure 2(a) we observe that both the SVM and logistic regression MLE perform poorly. The\nlogistic regression MLE completely flips the labels and has a 0-1 error close to 1, whereas the\nlinear SVM outputs a random hyperplane classifier that flips the label for roughly half of the\ndataset.\n11\n\n\f1\n\n1\n\nRobustGD\nlogisticRegression\nSVM\n\n0.9\n\n0.8\n\n0.7\n\n0.7\n\n0.6\n\n0.6\n\n0-1 error\n\n0-1 error\n\n0.8\n\n0.5\n0.4\n\n0.5\n0.4\n\n0.3\n\n0.3\n\n0.2\n\n0.2\n\n0.1\n\n0.1\n\n0\n100\n\n150\n\n200\n\n250\n\n300\n\n350\n\n400\n\n450\n\nRobustGD\n\n0.9\n\n0\n0.1\n\n500\n\n0.15\n\n0.2\n\n0.25\n\np\n\n0.3\n\n0.35\n\n0.4\n\n0.45\n\nepsilon\n\n(a) 0-1 Error vs p at ǫ = 0.1\n\n(b) 0-1 error vs ǫ\n\n0.5\neta=0.1\neta=0.2\neta=0.3\neta=0.4\n\nlog(Parameter Error)\n\n0\n\n-0.5\n\n-1\n\n-1.5\n\n-2\n\n-2.5\n0\n\n100\n\n200\n\n300\n\n400\n\n500\n\n600\n\nIterations\n\n(c) log(kθt − θ∗ k2 ) vs t for different ǫ\n\nFigure 2: Robust Logistic Regression.\n4.1.3\n\nRobust Face Reconstruction\n\nSetup In this experiment, we show the efficacy of our algorithm by attempting to reconstruct\nface images that have been corrupted with heavy occlusion, where the occluding pixels play\nthe role the outliers. We use the data from the Cropped Yale Dataset [30] . The dataset\ncontains 38 subjects, and each image has 192×168 pixels. Following the methodology of Wang\net al. [44], we choose 8 face images per subject, taken under mild illumination conditions and\ncomputed an eigenface set with 20 eigenfaces. Then given a new corrupted face image of a\nsubject, the goal is to get the best reconstruction/approximation of the true face. To remove\nthe scaling effects, we normalized all images to [0, 1] range. One image per person was used to\ntest reconstruction. Occlusions were simulated by randomly placing 10 blocks of size 30 × 30.\nWe repeated this 10 times for each test image. Note that in this example, we use a linear\nregression model as the uncontaminated statistical model, which is almost certainly not an\n\nTable 1: Fitting to original image error.\nMean RMSE\n\nBest Possible\n\nProposed\n\nTORRENT\n\nOLS\n\nSCRRR\n\n0.05\n\n0.09\n\n0.175\n\n0.21\n\n0.13\n\n12\n\n\fexact match for the unknown ground truth distribution. Despite this model misspecification,\nas our results show, that robust mean based gradient algorithms do well.\nMetric We use Root Mean Square Error (RMSE) between the original and reconstructed\nimage to evaluate the performance of the algorithms. We also compute the best possible\nreconstruction of the original face image by using the 20 eigenfaces.\nMethods We use TORRENT, OLS as baselines. Wang et al. [44] implemented popular robust estimators such as RANSAC, Huber Loss etc. and showed their poor performance. Wang\net al. [44] then proposed an alternate robust regression algorithm called Self Scaled Regularized\nRobust Regression(SCRRR), and showed its equivalence to and ℓ1 -penalized method. We also\ncompare against the best possible RMSE obtained by reconstructing the un-occluded image\nusing the eigenfaces.\nResults Table 1 shows that the mean RMSE is best for our proposed gradient descent\nbased method and that the recovered images are in most cases closer to the un-occluded\noriginal image. (Figure 4.1.3). Figure 3(c) shows a case when none of the methods succeed in\nreconstruction.\n\n(a) Successful Reconstruction\n\n(b) Successful Reconstruction\n\n(c) Failed Reconstruction\n\nFigure 3: Robust Face recovery results: Top; in order from L to R: original image, occluded\nimage, best possible recovery with given basis. Bottom; in order from L to R: Reconstructions\nusing our proposed algorithm, TORRENT and ordinary least squares (OLS).\n\n4.2\n\nHeavy-tailed Estimation\n\nWe now consider the heavy-tailed model and present experimental results on synthetic and\nreal world datasets comparing the gradient descent based robust estimator described in Algo13\n\n\frithms 1 and 3 (which we call GMOM) with ERM and several other recent proposals. In these\nexperiments we focus on the problem of linear regression which is described in Section 4.1 and\nwork with heavy-tailed noise distributions.\n4.2.1\n\nSynthetic Experiments: Simple Linear Regression\n\nSetup. The covariate x ∈ Rp is sampled from a zero-mean isotropic gaussian distribution.\n√\nWe set each entry of θ ∗ to 1/ p. The noise w is sampled from a Pareto distribution, with mean\nzero, variance σ 2 and tail parameter β. The tail parameter β determines the moments of the\nPareto random variable. More specifically, the moment of order k exists only if k < β, hence,\nsmaller the β the more heavy-tailed the distribution. In this setup, we keep the dimension p\nfixed to 128 and vary n, σ and β. We always maintain the sample-size n to be at least 2p.\nMethods. We use ERM as our baseline and compare it with GMOM. Since we are always\nin the low-dimensional (n ≥ p) setting, the solution to ERM has a closed form expression and\nis simply the OLS solution. We also study ERM-GD, which performs a gradient descent on\nERM and is equivalent to using empirical mean as the gradient oracle in our framework. We\nalso compare against the robust estimation techniques of Hsu and Sabato [23] and Duchi and\nNamkoong [17]. In our experiments, all the iterative techniques are run until convergence.\nHyper Parameter Selection. The GMOM estimator depends on the confidence parameter\nδ ∈ (0, 1), which needs to be tuned. In our experiments, we noticed that the performance of\nGMOM varies very little when δ is selected from a reasonable range that is not too close to 0\n(see Figure 5 and the discussion below). So we set δ = 0.1 in all our simulations.\nMetrics. In our experiments, we vary σ and β, the parameters of Pareto distribution, which\ncan change the minimal risk R(θ ∗ ). So to compare various approaches across parameter values,\n∗ ) − 1.0, where θ\nb\nb is\nwe use a scaled version of the Excess Risk, which we define as R(θ)/R(θ\nthe estimator.\nTo compare the performance of two estimators θb1 , θb2 , we define the notion of relative\nefficiency:\n(R(θb2 ) − R(θ ∗ )) − (R(θb1 ) − R(θ ∗ ))\n.\nRelEff(θb1 , θb2 ) =\nR(θb1 ) − R(θ ∗ )\n\nRoughly, this corresponds to the percentage improvement in the excess risk obtained using θb1\nover θb2 . Whenever RelEff(θb1 , θb2 ) > 0, θb1 has a lower risk, and higher the value, the more\nthe fractional improvement.\n\nResults. To reduce the variance in the plots presented here and in the next section, we\naveraged results over 25 repetitions. Figure 4 shows the benefits of using GMOM over ERM.\nIn Figure 4(a) we plot the excess risk of ERM, ERM-GD and GMOM against the number\nof Iterations. We see that upon convergence GMOM has a much lower population risk than\nERM. As expected, ERM-GD converges to ERM. However, the population risk of ERM-GD\nin the first few iterations is much lower than the risk of ERM, suggesting early stopping.\nNext, in Figure 4(b) we plot the scaled excess risk for ERM and GMOM as n/p increases. We\nsee that GMOM is always better than ERM, even when the number of samples is 12 times\nthe dimension p. In Figure 4(c), we plot the relative efficiency of GMOM and ERM against\nσ. This shows that the percentage improvement in the excess risk by GMOM decreases as\n14\n\n\fthe noise level σ decreases. This behavior is expected because in the noiseless setting both\nmethods would have a similar behavior. We do a similar study to see the relative efficiency\nagainst the heavy-tailedness of the noise distribution. As noted before, as β is increased more\nmoments exist for the underlying distribution. Figure 4(d) shows that as the noise distribution\nbecomes more heavy-tailed, there is more benefit in using GMOM over ERM.\n2\n\n1\n\nERM\nERM (GD)\nGMOM (GD)\n\n1.9\n\nExcess Risk / True Risk\n\n1.8\n1.7\n\nPopulation Risk\n\nERM\nGMOM (GD)\n\n0.9\n\n1.6\n1.5\n1.4\n1.3\n\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n\n1.2\n\n0.2\n\n1.1\n\n0.1\n0\n\n1\n50\n\n100\n\n150\n\n2\n\n200\n\n4\n\n6\n\n(a) Population Risk vs Iterations\n\n10\n\n12\n\n(b) ExcessRisk/TrueRisk vs n/p\n0.6\n\nRelEff(GMOM,ERM)\n\n1.2\n\n8\n\nn/p\n\nIterations\n\nRelEff(GMOM,ERM)\n\n0.5\n\nRelative Efficiency\n\nRelative Efficiency\n\n1\n0.8\n0.6\n0.4\n\n0.4\n\n0.3\n\n0.2\n\n0.1\n\n0.2\n\n0\n\n0\n1\n\n0.9\n\n0.8\n\n0.7\n\n0.6\n\n0.5\n\n0.4\n\n0.3\n\n0.2\n\n2\n\n4\n\n6\n\n8\n\n10\n\n12\n\nβ+1\n\nσ\n\n(c) Relative Efficiency vs σ\n\n(d) Relative Efficiency vs β + 1\n\nFigure 4: Linear Regression: Performance comparison of GMOM and ERM.\n\nDependence on Confidence Level. Figure 5(a) shows the performance of GMOM estimator for various values of δ. It can be seen that the choice of δ have very little effect on the\nperformance of the estimator. However, we notice that for small values of δ the performance\nof the GMOM degrades. In practice, one can use either cross validation or a validation set for\nchoosing δ.\n\n5\n\nTheoretical Preliminaries\n\nIn this section we develop some theoretical preliminaries. We begin with a description of\nsome canonical examples of risk minimization in Section 5.1. Next we develop a general\n15\n\n\f2\nERM\nδ=0.01\nδ=0.05\nδ=0.1\nδ=0.2\n\n1.9\n1.8\n\nPopulation Risk\n\n1.7\n1.6\n1.5\n1.4\n1.3\n1.2\n1.1\n1\n50\n\n100\n\n150\n\n200\n\nIterations\n\n(a) Population Risk vs δ\n\nFigure 5: Linear Regression: Dependence on Confidence Level δ.\ntheory on convergence of projected gradient descent in Section 5.2. We analyze the gradient\nestimators defined in Algorithms 2 and 3 in Sections 5.3 and 5.4 respectively. Finally in\nSections 6,7 we present consequences of our general theory for the canonical examples, under\nHuber contamination and heavy-tailed models.\nFor some of our examples, we will assume certain mild moment conditions. Concretely, for\na random vector x ∈ Rp , let µ = E[x] and Σ be the covariance matrix. Then x has bounded\n2kth moments if there exists a constant C2k such that for every unit vector v we have that\ni\nh\n\u0002\n\u0003\u0001k\n.\n(10)\nE hx − µ, vi2k ≤ C2k E hx − µ, vi2\n\n5.1\n\nIllustrative Examples\n\nThe framework of risk minimization is a central paradigm of statistical estimation and is widely\napplicable. In this section, we provide illustrative examples that fall under this framework.\n5.1.1\n\nLinear Regression\n\nHere we observe paired samples {(x1 , y1 ), . . . (xn , yn )}, where each (xi , yi ) ∈ Rp ×R. We assume\nthat the (x, y) pairs sampled from the true distribution P are linked via a linear model:\ny = hx, θ ∗ i + w,\n\n(11)\n\nwhere w is drawn from a zero-mean distribution such as normal distribution with variance σ 2\n(N (0, σ 2 )) or a more heavy-tailed distribution such as student-t or Pareto distribution. We\nsuppose that under P the covariates x ∈ Rp , have mean 0, and covariance Σ.\nFor this setting we use the squared loss as our loss function, which induces the following\npopulation risk:\n1\n1\n(y − hx, θi)2 , and R(θ) = (θ − θ ∗ )T Σ(θ − θ ∗ ).\n2\n2\n∗\nNote that the true parameter θ is the minimizer of the population risk R(θ). The strongconvexity and smoothness assumptions from (3) in this setting require that τℓ ≤ λmin (Σ) ≤\nλmax (Σ) ≤ τu .\nL(θ; (x, y)) =\n\n16\n\n\f5.1.2\n\nGeneralized Linear Models\n\nHere we observe paired samples {(x1 , y1 ), . . . (xn , yn )}, where each (xi , yi ) ∈ Rp × Y. We\nsuppose that the (x, y) pairs sampled from the true distribution P are linked via a linear model\nsuch that when conditioned on the covariates x, the response variable has the distribution:\n\u0013\n\u0012\nyhx, θ ∗ i − Φ(hx, θ ∗ i)\n(12)\nP (y|x) ∝ exp\nc(σ)\nHere c(σ) is a fixed and known scale parameter and Φ : R 7→ R is the link function. We focus\non the random design setting where the covariates x ∈ Rp , have mean 0, and covariance Σ.\nWe use the negative conditional log-likelihood as our loss function, i.e.\nL(θ; (x, y)) = −yhx, θi + Φ(hx, θi).\n\n(13)\n\nOnce again, the true parameter θ ∗ is the minimizer of the resulting population risk R(θ). It is\neasy to see that Linear Regression with Gaussian Noise lies in the family of generalized linear\nmodels. We now instantiate GLMs for logistic regression.\nLogistic Regression In this case the (x, y) pairs are linked as:\n(\n1\n1 with probability 1+exp(−hx,\nθ ∗ i) ,\ny=\n0 otherwise.\n\n(14)\n\nThis corresponds to setting Φ(t) = log(1 + exp(t)) and c(γ) = 1 in (12). The hessian of the\npopulation risk is given by\n\u0014\n\u0015\nexp hx, θi\nT\n2\nxx .\n∇ R(θ) = E\n(1 + exp hx, θi)2\nNote that as θ diverges, the minimum eigenvalue of the hessian approaches 0 and the loss is\nno longer strongly convex. To prevent this, in this case we take the parameter space Θ to be\nbounded.\n5.1.3\n\nExponential Families and Canonical Parameters\n\nFinally we consider the case where the true distribution P is in exponential family with\ncanonical parameters θ ∗ ∈ Rp , and a vector of sufficient statistics obtained from the map\nφ : Z 7→ Rp . Note that while the linear and logistic regression models are indeed in an\nexponential family, our interest in those cases was not in the canonical parameters.\nIn more details, we can write the true distribution P in this case as\nP (z) = h(z) exp (hφ(z), θ ∗ i − A(θ ∗ )) ,\nwhere h(z) is an arbitrary nuisance function. The negative log-likelihood gives us the following\nloss function:\nL(θ; z) = −hφ(z), θi + A(θ).\n\n(15)\n\nThe strong-convexity and smoothness assumptions require that there are constants τℓ , τu such\nthat τℓ ≤ ∇2 A(θ) ≤ τu , for θ ∈ Θ.\n17\n\n\f5.2\n\nStability of Gradient Descent\n\nIn this section we develop a general theory for the convergence of the projected gradient\ndescent described in Algorithm 1. Note that our gradient estimators could be biased and are\nnot guaranteed to be consistent estimators of the true gradient ∇R(θ). This is especially true\nin the Huber contamination model where it is impossible to obtain consistent estimators of the\ngradient of the risk because of the non-vanishing bias caused by the contaminated samples.\nHence, we turn our attention to understanding the behavior of projected gradient descent with\na biased, inexact, gradient estimator of the form in (6). Before we present our main result, we\ndefine the notion of stability of a gradient estimator, which plays a key role in the convergence\nof gradient descent.\nDefinition 2 (Stability). A gradient estimator is stable for a given risk function R : Θ 7→ R\nif for some φ ∈ [0, τℓ ),\nα(e\nn, δ̃) < τℓ − φ.\nWe denote by κ the following contraction parameter:\nr\n2ητℓ τu\ne\nκ := 1 −\n+ ηα(e\nn, δ),\nτℓ + τu\n\nand note that κ < 1. With these definitions in place we state our main result on the stability\nof gradient descent:\n\nTheorem 1. Suppose that the gradient estimator satisfies the condition in (6) and is stable for\nthe risk function R : Θ 7→ R. Then Algorithm 1 initialized at θ 0 with step-size η ≤ 2/(τℓ + τu ),\nreturns iterates {θbt }Tt=1 such that with probability at least 1 − δ for the contraction parameter\nκ above we have that,\nkθbt − θ ∗ k2 ≤ κt kθ 0 − θ ∗ k2 +\n\n1\ne\nβ(e\nn, δ).\n1−κ\n\n(16)\n\nWe defer a proof of this result to the Appendix. Theorem 1 provides a general result for risk\nminimization and parameter estimation. In any concrete instantiation for a given gradient\nestimator, risk pair, we first study the distribution of the gradient of the risk to estimate the\ne β(e\ne and then apply Theorem 1.\nerror suffered by the gradient estimator (α(e\nn, δ),\nn, δ))\nFor the bound (16), the first term is decreasing in T , while the second term is increasing\nin T . This suggests that for a given n and δ, we need to run just enough iterations for the\nfirst term to be bounded by the second. Hence, we can fix the number of iterations T ∗ as the\nsmallest positive integer such that:\nT ≥ log1/κ\n\n(1 − κ)kθ 0 − θ ∗ k2\n.\ne\nβ(e\nn, δ)\n\nSince we obtain linear convergence, i.e. κ < 1, typically a logarithmic number of iterations\nsuffice to obtain an accurate estimate.\n\n5.3\n\nGeneral Analysis of Algorithm 2\n\nWe now analyze the gradient estimator described in Algorithm 2 for Huber contamination\nmodel and study the error suffered by it. As stated before, Algorithm 2 uses the robust mean\n18\n\n\festimator of Lai et al. [29]. Hence, while our proof strategy mimics that of Lai et al. [29], we\npresent a different result which is obtained by a more careful non-asymptotic analysis of the\nalgorithm.\nWe define:\n\u0010 p log p log n/(pδ)\u0001 \u00113/8 \u0010 ǫp2 log p log\n+\nγ(n, p, δ, ǫ) :=\nn\nn\n\np log(p) \u0001 \u0011\n1/4\nδ\n\n,\n\n(17)\n\nand with this definition in place we have the following result:\nLemma 1. Let P be the true probability distribution of z and let Pθ be the true distribution\nof the gradients ∇L(θ; z) on Rp with mean µθ = ∇R(θ), covariance Σθ , and bounded fourth\nmoments. There exists a positive constant C1 > 0, such that given n samples from the distribution in (4), the Huber Gradient Estimator described in Algorithm 2 when instantiated with\nthe contamination level ǫ, with probability at least 1 − δ, returns an estimate µ\nb of µθ such that,\nkb\nµ − µθ k2 ≤ C1\n\n\u0010√\n\n\u0011\n1p\nǫ + γ(n, p, δ, ǫ) kΣθ k22 log p.\n\nWe note in particular, if n → ∞ (with other parameters held fixed) then γ(n, p, δ, ǫ) → 0 and\nthe error of our gradient estimator satisfies\nkb\nµ − µθ k2 ≤ C\n\np\nkΣθ k2 ǫ log p,\n\nand has only a weak dependence on the dimension p.\n\n5.4\n\nGeneral Analysis of Algorithm 3\n\nIn this section we analyze the gradient estimator for heavy-tailed setting, described in Algorithm 3. The following result shows that the gradient estimate has exponential concentration around the true gradient, under the mild assumption that the gradient distribution has\nbounded second moment. Its proof follows from the analysis of geometric median-of-means\nestimator of Minsker [37]. We use tr (Σθ ) to denote the trace of the matrix Σθ .\nLemma 2. Let P be the probability distribution of z and Pθ be the distribution of the gradients\n∇L(θ; z) on Rp with mean µθ = ∇R(θ), covariance Σθ . Then the heavy tailed gradient estib that satisfies the following exponential\nmator described in Algorithm 3 returns an estimate µ\nconcentration inequality, with probability at least 1 − δ:\nr\n\nkb\nµ − µθ k2 ≤ 11\n\n6\n\ntr (Σθ ) log 1.4/δ\n.\nn\n\nConsequences for Estimation under ǫ-Contaminated Model\n\nWe now turn our attention to the examples introduced earlier, and present specific applications of Theorem 1, for parametric estimation under Huber contamination model. As shown\nin Lemma 1, we need the added assumption that the true gradient distribution has bounded\nfourth moments, which suggests the need for additional assumptions. We make our assumptions explicit and defer the technical details to the Appendix.\n19\n\n\f6.1\n\nLinear Regression\n\nWe assume that the covariates x ∈ Rp have bounded 8th -moments and the noise w has bounded\n4th moments.\nTheorem 2 (Robust Linear Regression). Consider the statistical model in equation (11), and\nC1√τℓ\ne <\nsuppose that the number of samples n is large enough such that γ(e\nn, p, δ)\nand the\nkΣk2 log p\n\u00112\n\u0010\nℓ\ne\ncontamination level is such that ǫ < kΣkC2√τlog\n− γ(e\nn, p, δ)\nfor some constants C1 and C2 .\np\n2\n\nThen, there are universal constants C3 , C4 , such that if Algorithm 1 is initialized at θ 0 with\nstepsize η ≤ 2/(τu + τℓ ) and Algorithm 2 as gradient estimator, then it returns iterates {θbt }Tt=1\nsuch that with probability at least 1 − δ\np\n\u0011\nC\nσ\nkΣk2 log p \u0010 1\n3\nt\n∗\nt\n0\n∗\ne ,\nkθb − θ k2 ≤ κ kθ − θ k2 +\nn, p, δ)\n(18)\nǫ 2 + γ(e\n1−κ\nfor some contraction parameter κ < 1.\n\nIn the asymptotic setting when the number of samples n → ∞ (and other parameters are held\nfixed), we see that for the Huber Gradient Estimator, the corresponding maximum allowed\nC τ2\n\ncontamination level is ǫ < τ 2 1logℓ p . This says that the more well-conditioned the covariance\nu\nmatrix Σ, the higher the contamination level we can tolerate.\nPlugin Estimation For linear regression, the true parameter can be written in closed form\nas θ ∗ = E[xxT ]−1 E[xy]. A non-iterative way to estimate θ ∗ is to separately estimate E[xxT ]\nand E[xy] using robust covariance and mean oracles respectively. Under the assumption that\nx ∼ N (0, Ip ), one can reduce the problem to robustly estimating E[xy]. Under this setting,\nwe now present a result using Lai et al. [29] as the mean estimator for estimation of E[xy].\nRecall, the definition of γ in (17). We have the following result:\nCorollary 3. Consider the model in equation(11) with the covariates drawn from N (0, Ip )\nand w ∈ N (0, 1), then there are universal constants C1 , C2 such that if ǫ < C1 , then [29]\nreturns an estimate θb of E[xy], such that with probability at least 1 − δ\nq\n\u0011\n\u0010 1\n(19)\nkθb − θ ∗ k2 ≤ C2 (1 + 2kθ ∗ k22 ) log p ǫ 2 + γ(n, p, δ, ǫ) .\n\nComparing bounds (18) and (19), we see that the error of the plugin estimator depends on\nkθ ∗ k2 , which would make the estimator vacuous if kθ ∗ k2 scales with the dimension p. On\nthe other hand, the asymptotic rate of our robust gradient estimator is independent of the\nkθ ∗ k2 . This disadvantage of plugin estimation is inescapable, due to known minimax results\nfor robust mean estimation [10] that show that the dependence on kθ ∗ k2 is unavoidable for\nany oracle which estimates the mean of xy in the ǫ-contaminated setting. Next, we apply our\nestimator to generalized linear models.\n\n6.2\n\nGeneralized Linear Models\n\nHere we assume that the covariates have bounded 8th moments. Additionally, we assume\nsmoothness of Φ′ (·) around θ ∗ . To be more precise, we assume that there exist universal\nconstants LΦ,2k , B2k such that\nh\ni\n2k\n≤ LΦ,2k kθ ∗ − θk2k\nEx Φ′ (hx, θi) − Φ′ (hx, θ ∗ i)\n2 + BΦ,2k , for k = 1, 2, 4\n20\n\n\fk\n\nWe also assume that Ex [ Φ(t) (hx, θ ∗ i) ] ≤ MΦ,t,k where Φ(t) (·) is the tth -derivative of Φ(·).\nTheorem 4 (Robust Generalized Linear Models). Consider the statistical model in equation (12), and suppose that the number of samples n is large enough such that\ne <\nγ(e\nn, p, δ)\n√\n\nC1 τ ℓ\n1\n\n1\n\n1\n\n,\n\n4\n2\n+ LΦ,2\n]\nlog pkΣk22 [LΦ,4\n\nand the contamination level is such that,\n\n2\nC\nτ\n2 ℓ\ne ,\nǫ < √\n− γ(e\nn, p, δ)\n1\n1\n1\n2\n4\n2\nlog pkΣk2 [LΦ,4 + LΦ,2 ]\n\nfor some constants C1 and C2 . Then, there are universal constants C3 , C4 , such that if Algorithm 1 is initialized at θ 0 with stepsize η ≤ 2/(τu + τℓ ) and Algorithm 2 as gradient estimator,\nthen it returns iterates {θbt }Tt=1 such that with probability at least 1 − δ\nkθbt − θ ∗ k2 ≤κt kθ 0 − θ ∗ k2\n1\n1\n1\n1\n1\n√\n1\n3\n4\n2\n4\n4\n\u0011\n+ BΦ,2\n+ c(σ) 2 MΦ,2,2\n+ c(σ) 4 MΦ,4,1\n]\u0010 1\nC3 log pkΣk22 [BΦ,4\ne\n2\n+\nγ(e\nn\n,\np,\nδ)\n,\nǫ\n+\n1−κ\n(20)\n\nfor some contraction parameter κ < 1.\nNote that for the case of linear regression with gaussian noise, it is relatively straightforward\nto see that LΦ,2k = C2k kΣkk2 , BΦ,2k = 0, MΦ,t,k = 1 ∀(t ≥ 2, k ∈ N ) and MΦ,t,k = 0 ∀(t ≥\n3, k ∈ N ) under the assumption of bounded 8th moments of the covariates; which essentially\nleads to an equivalence between Theorem 2 and Theorem 4 for this setting. In the following\nsection, we instantiate the above Theorem for logistic regression and compare and contrast\nour results to other existing methods.\n6.2.1\n\nLogistic Regression\n\nBy observing that Φ(t) (·) is bounded for logistic regression for all t ≥ 1, we can see that\nLΦ,2k = 0, and that there exists a universal constant C > 0 such that BΦ,2k < C and\nMΦ,t,k < C ∀(t ≥ 1, k ∈ N ).\nCorollary 5 (Robust Logistic Regression). Consider the model in equation(14), then there\nare universal constants C1 , C2 , such that if ǫ < C1 , then Algorithm 1 initialized at θ 0 with\nstepsize η ≤ 2/(τu + τℓ ) and Algorithm 2 as gradient estimator, returns iterates {θbt }Tt=1 , such\nthat with probability at least 1 − δ\np\n\u0011\nC2 kΣk2 log p \u0010 1\nt\n∗\nt 0\n∗\ne ,\nb\nn, p, δ)\n(21)\nǫ 2 + γ(e\nkθ − θ k2 ≤ κ kθ − θ k2 +\n1−κ\nfor some contraction parameter κ < 1.\n\nUnder the restrictive assumption that x ∼ N (0, Ip ), Du et al. [16] exploited Stein’s trick to\nderive a plugin estimator for logistic regression. However, similar to the linear regression, the\nerror of the plugin estimator scales with kθ ∗ k2 , which is avoided in our robust gradient descent\nalgorithm. We also note that our algorithm extends to general covariate distributions.\n21\n\n\f6.3\n\nExponential Family\n\nHere we assume that the random vector φ(z), z ∼ P has bounded 4th moments.\nTheorem 6 (Robust Exponential Family). Consider the model in equation(15), then there\nare universal constants C1 , C2 , such that if ǫ < C1 , then Algorithm 1 initialized at θ 0 with\nstepsize η ≤ 2/(τu + τℓ ) and Algorithm 2 as gradient oracle, returns iterates {θbt }Tt=1 , such that\nwith probability at least 1 − δ\n√\n\u0011\nC2 τu log p \u0010 1\nt\n∗\nt 0\n∗\ne ,\nb\nǫ 2 + γ(e\nn, p, δ)\n(22)\nkθ − θ k2 ≤ κ kθ − θ k2 +\n1−κ\nfor some contraction parameter κ < 1.\n\nPlugin Estimation Since the true parameter θ ∗ is the minimizer of the negative loglikelihood, we know that E[∇L(θ ∗ )] = 0, which implies that ∇A(θ ∗ ) = Eθ∗ [φ(Z)]. This\nshows that the true parameter θ ∗ can be obtained by inverting the ∇A operator, whenever\npossible. In the robust estimation framework, we can use a robust mean of the sufficient\nstatistics to estimate Eθ∗ [φ(Z)]. We instantiate this estimator using the mean estimator of\n[29] to estimate Eθ∗ [φ(Z)]:\nCorollary 7. Consider the model in equation(15), then there are universal constants C1 , C2\nb of E[φ(z)], such that with probability at\nsuch that if ǫ < C1 , then [29] returns an estimate µ\nleast 1 − δ\n√\n\u0011\n\u0002\n\u0003\nτu log p \u0010 1\n−1\n∗\nǫ 2 + γ(n, p, δ, ǫ) ,\n(23)\nb − θ k2 ≤ C2\nkPΘ (∇A) µ\nτℓ\nwhere PΘ [θ] = argminy∈Θ ky − θk22 is the projection operator onto the feasible set Θ.\n\n6.4\n\nDiscussion and Limitations\n\nIn the asymptotic setting of n → ∞, Algorithm 1 √\nwith Algorithm 2 as gradient estimator\nconverges to a point θb such that kθb − θ ∗ k2 = O( ǫ log p). Hence, our error scales only\nlogarithmically with the dimension p. This dependency on the dimension p is a facet of\nusing the estimator from Lai et al. [29] for gradient estimation. Using better oracles will only\nimprove our performance. Next, we would like to point to the difference in the maximum\nallowed contamination ǫ∗ between the three models. For logistic regression and exponential\nC τ2\nfamily, ǫ∗ < C1 , while for linear regression, ǫ∗ < τ 2 1logℓ p . These differences are in large part\nu\ndue to differing variances of the gradients, which naturally depend on the underlying risk\nfunction. This scaling of the variance of gradients for linear regression also provides insights\ninto the limitations of Algorithm 1 for gradient estimators. In the Appendix, we provide an\nupper bound for the contamination level ǫ based on the initialization point θ 0 , above which,\nAlgorithm 1 would not work for any gradient estimator.\n\n7\n\nConsequences for Heavy-Tailed Estimation\n\nIn this section we present specific applications of Theorem 1 for parametric estimation, under\nheavy tailed setting. The proofs of the results can be found in the Appendix.\n22\n\n\f7.1\n\nLinear Regression\n\nWe first consider the linear regression model described in Equation (11). We assume that the\ncovariates x ∈ Rp have bounded 4th -moments and the noise w has bounded 2th moments. This\nassumption is needed to bound the error in the gradient estimator (see Lemma 2).\nTheorem 8 (Heavy Tailed Linear Regression). Consider the statistical model in equation (11).\nThere are universal constants C1 , C2 > 0 such that if\nn\ne>\n\nC1 τu2\ne\np log(1/δ)\nτl2\n\nand if Algorithm 1 is initialized at θ 0 with stepsize η ≤ 2/(τu + τℓ ) and Algorithm 3 as gradient\nestimator, then it returns iterates {θbt }Tt=1 such that with probability at least 1 − δ\ns\n\np\ne\nC2 σ kΣk2  p log(1/δ) \n,\n(24)\nkθbt − θ ∗ k2 ≤ κt kθ 0 − θ ∗ k2 +\n1−κ\nn\ne\n\nfor some contraction parameter κ < 1.\n\n7.2\n\nGeneralized Linear Models\n\nIn this section we consider generalized linear models described in Equation (12), where the\ncovariate x is allowed to have a heavy tailed distribution. Here we assume that the covariates\nhave bounded 4th moment. Additionally, we assume smoothness of Φ′ (·) around θ ∗ . Specifically, we assume that there exist universal constants LΦ,2k , B2k such that\nh\ni\n2k\n≤ LΦ,2k kθ ∗ − θk2k\nEx Φ′ (hx, θi) − Φ′ (hx, θ ∗ i)\n2 + BΦ,2k , for k = 1, 2\nk\n\nWe also assume that Ex [ Φ(t) (hx, θ ∗ i) ] ≤ MΦ,t,k for t ∈ {1, 2, 4}, where Φ(t) (·) is the tth derivative of Φ(·).\nTheorem 9 (Heavy Tailed Generalized Linear Models). Consider the statistical model in\nequation (12). There are universal constants C1 , C2 > 0 such that if\n\u0001\np\nLΦ,4 + LΦ,2\nC1 kΣk2\ne\nn\ne>\np log 1/δ,\nτl2\nand if Algorithm 1 is initialized at θ 0 with stepsize η ≤ 2/(τu + τℓ ) and Algorithm 3 as gradient\nestimator, it returns iterates {θbt }Tt=1 such that with probability at least 1 − δ\n\nkθbt − θ ∗ k2 ≤κt kθ 0 − θ ∗ k2\n\u0014 1\n\u0015\n1\n1\n1\n1\n1\n3\ns\n\n2\n4\n2\n4\n4\nC2 kΣk2 BΦ,4 + BΦ,2 + c(σ) 2 MΦ,2,2 + c(σ) 4 MΦ,4,1\ne\n p log(1/δ)  , (25)\n+\n1−κ\nn\ne\n\nfor some contraction parameter κ < 1.\n\nWe now instantiate the above Theorem for logistic regression model.\n23\n\n\fCorollary 10 (Heavy Tailed Logistic Regression). Consider the model in equation(14). There\nare universal constants C1 , C2 > 0 such that if\nn\ne>\n\nC12 kΣk2\ne\np log 1/δ.\nτl2\n\nand if Algorithm 1 initialized at θ 0 with stepsize η ≤ 2/(τu + τℓ ) and Algorithm 3 as gradient\nestimator, it returns iterates {θbt }Tt=1 such that with probability at least 1 − δ\ns\n\np\ne\nC\nkΣk\np\nlog(1/\nδ)\n2\n2 \n,\nkθbt − θ ∗ k2 ≤ κt kθ 0 − θ ∗ k2 +\n1−κ\nn\ne\n\n(26)\n\nfor some contraction parameter κ < 1.\n\n7.3\n\nExponential Family\n\nWe now instantiate Theorem 1 for parameter estimation in heavy-tailed exponential family\ndistributions. Here we assume that the random vector φ(z), z ∼ P has bounded 2nd moments,\nand we obtain the following result:\nTheorem 11 (Heavy Tailed Exponential Family). Consider the model in equation(15). If\nAlgorithm 1 is initialized at θ 0 with stepsize η ≤ 2/(τu + τℓ ) and Algorithm 3 as gradient\nestimator, it returns iterates {θbt }Tt=1 , such that with probability at least 1 − δ\nkθbt − θ ∗ k2 ≤ κt kθ 0 − θ ∗ k2 +\n\n1\nC\n1−κ\n\ns\n\nk∇2 A(θ ∗ )k2 p log 1/δe\n,\nn\ne\n\n(27)\n\nfor some contraction parameter κ < 1 and universal constant C.\n\n8\n\nDiscussion\n\nIn this paper we introduced a broad class of estimators and showed that these estimators\ncan have strong robustness guarantees in Huber’s ǫ-contamination model and for heavy-tailed\ndistributions. These estimators leverage the robustness of gradient descent, together with the\nobservation that for risk minimization in most statistical models the gradient of the risk takes\nthe form of a simple multivariate mean which can be robustly estimated by using recent work\nof robust mean estimation. These estimators based on robust gradient descent work well in\npractice and in many cases outperform other robust (and non-robust) estimators.\nThere are several avenues for future work, including developing a better understanding of\nrobust mean estimation. Any improvement for robust mean estimation would immediately\ntranslate to improved guarantees for the estimators we propose for general parametric models.\nFinally, it would also be of interest to understand the extent to which we could replace gradient\ndescent with other optimization methods such as accelerated gradient descent or Newton’s\nmethod. We note however, that although these methods may have faster rates of convergence in\nthe classical risk minimization setting: in our setup their stability (to using inexact gradients)\nis far more crucial and warrants further investigation.\n24\n\n\f9\n\nAcknowledgements\n\nThe research of SB was supported in part by the grant NSF-DMS-1713003. We thank Larry\nWasserman for helpful comments on the paper.\n\nReferences\n[1] Noga Alon, Yossi Matias, and Mario Szegedy. The space complexity of approximating the frequency moments. In Proceedings of the Twenty-eighth Annual ACM Symposium on Theory of\nComputing, STOC ’96, pages 20–29, New York, NY, USA, 1996. ACM.\n[2] Sivaraman Balakrishnan, Martin J Wainwright, and Bin Yu. Statistical guarantees for the em\nalgorithm: From population to sample-based analysis. The Annals of Statistics, 45(1):77–120,\n2017.\n[3] Kush Bhatia, Prateek Jain, and Purushottam Kar. Robust regression via hard thresholding. In\nAdvances in Neural Information Processing Systems, pages 721–729, 2015.\n[4] G. E. P. Box. Non-normality and tests on variances. Biometrika, 40(3-4):318–335, 1953.\n[5] Christian Brownlees, Emilien Joly, and Gábor Lugosi. Empirical risk minimization for heavytailed losses. The Annals of Statistics, 43(6):2507–2536, 2015.\n[6] Sébastien Bubeck. Convex optimization: Algorithms and complexity. Foundations and Trends R\nin Machine Learning, 8(3-4):231–357, 2015.\n[7] Emmanuel J Candès, Xiaodong Li, Yi Ma, and John Wright. Robust principal component analysis.\nJournal of the ACM (JACM), 58(3):11, 2011.\n[8] Olivier Catoni. Challenging the empirical mean and empirical variance: a deviation study. In\nAnnales de l’Institut Henri Poincaré, Probabilités et Statistiques, volume 48, pages 1148–1185.\nInstitut Henri Poincaré, 2012.\n[9] Moses Charikar, Jacob Steinhardt, and Gregory Valiant. Learning from untrusted data. In STOC,\n2017.\n[10] Mengjie Chen, Chao Gao, and Zhao Ren. Robust covariance matrix estimation via matrix depth.\narXiv preprint arXiv:1506.00691, 2015.\n[11] Mengjie Chen, Chao Gao, Zhao Ren, et al. A general decision theory for huber’s epsiloncontamination model. Electronic Journal of Statistics, 10(2):3752–3774, 2016.\n[12] Yudong Chen, Constantine Caramanis, and Shie Mannor. Robust sparse regression under adversarial corruption. In Proceedings of the 30th International Conference on Machine Learning,\nICML 2013, Atlanta, GA, USA, 16-21 June 2013, pages 774–782, 2013.\n[13] L. Devroye and L. Györfi. Nonparametric density estimation: the L1 view. Wiley series in\nprobability and mathematical statistics. Wiley, 1985.\n[14] Ilias Diakonikolas, Gautam Kamath, Daniel M Kane, Jerry Li, Ankur Moitra, and Alistair Stewart. Robust estimators in high dimensions without the computational intractability. In Foundations of Computer Science (FOCS), 2016 IEEE 57th Annual Symposium on, pages 655–664.\nIEEE, 2016.\n[15] David L Donoho and Richard C Liu. The\" automatic\" robustness of minimum distance functionals.\nThe Annals of Statistics, pages 552–586, 1988.\n\n25\n\n\f[16] Simon S Du, Sivaraman Balakrishnan, and Aarti Singh. Computationally efficient robust estimation of sparse functionals. Conference on Learning Theory, 2017.\n[17] John Duchi and Hongseok Namkoong. Variance-based regularization with convex objectives.\narXiv preprint arXiv:1610.02581, 2016.\n[18] Jianqing Fan, Weichen Wang, and Ziwei Zhu. A shrinkage principle for heavy-tailed data: Highdimensional robust low-rank matrix recovery, 2016.\n[19] Martin A. Fischler and Robert C. Bolles. Random sample consensus: A paradigm for model\nfitting with applications to image analysis and automated cartography. Commun. ACM, 24(6):\n381–395, 1981.\n[20] Chao Gao. Robust regression via mutivariate regression depth. 2017.\n[21] Frank R Hampel, Elvezio M Ronchetti, Peter J Rousseeuw, and Werner A Stahel. Robust statistics:\nthe approach based on influence functions, volume 114. John Wiley & Sons, 2011.\n[22] Cecil Hastings Jr, Frederick Mosteller, John W Tukey, and Charles P Winsor. Low moments for\nsmall samples: a comparative study of order statistics. The Annals of Mathematical Statistics,\npages 413–426, 1947.\n[23] Daniel Hsu and Sivan Sabato. Loss minimization and parameter estimation with heavy tails.\nJournal of Machine Learning Research, 17(18):1–40, 2016.\n[24] P. J. Huber. Robust Statistics. John Wiley & Sons, 1981.\n[25] Peter J Huber. Robust estimation of a location parameter. The Annals of Mathematical Statistics,\n35(1):73–101, 1964.\n[26] Peter J Huber. A robust version of the probability ratio test. The Annals of Mathematical\nStatistics, 36(6):1753–1758, 1965.\n[27] Mark R. Jerrum, Leslie G. Valiant, and Vijay V. Vazirani. Random generation of combinatorial\nstructures from a uniform distribution. Theoretical Computer Science, 43:169 – 188, 1986.\n[28] S Kakade, Shai Shalev-Shwartz, and Ambuj Tewari. Applications of strong convexity–strong\nsmoothness duality to learning with matrices. CoRR, abs/0910.0610, 2009.\n[29] Kevin A Lai, Anup B Rao, and Santosh Vempala. Agnostic estimation of mean and covariance.\nIn Foundations of Computer Science (FOCS), 2016 IEEE 57th Annual Symposium on, pages\n665–674. IEEE, 2016.\n[30] Kuang-Chih Lee, Jeffrey Ho, and David J Kriegman. Acquiring linear subspaces for face recognition under variable lighting. IEEE Transactions on pattern analysis and machine intelligence, 27\n(5):684–698, 2005.\n[31] Matthieu Lerasle and Roberto I Oliveira. Robust empirical mean estimators. arXiv preprint\narXiv:1112.3914, 2011.\n[32] Jerry Li. Robust sparse estimation tasks in high dimensions. Conference on Learning Theory,\n2017.\n[33] Po-Ling Loh. Statistical consistency and asymptotic normality for high-dimensional robust mestimators. Ann. Statist., 45(2):866–896, 04 2017.\n[34] Po-Ling Loh and Martin J Wainwright. High-dimensional regression with noisy and missing data:\nProvable guarantees with non-convexity. In Advances in Neural Information Processing Systems,\npages 2726–2734, 2011.\n\n26\n\n\f[35] Gabor Lugosi and Shahar Mendelson. Risk minimization by median-of-means tournaments. arXiv\npreprint arXiv:1608.00757, 2016.\n[36] Gábor Lugosi and Shahar Mendelson. Sub-gaussian estimators of the mean of a random vector.\nThe Annals of Statistics, 2017.\n[37] Stanislav Minsker. Geometric median and robust estimation in banach spaces. Bernoulli, 21(4):\n2308–2335, 2015.\n[38] Ivan Mizera. On depth and deep points: a calculus. Annals of Statistics, pages 1681–1736, 2002.\n[39] A.S. Nemirovski and D.B. Yudin. Problem Complexity and Method Efficiency in Optimization. A\nWiley-Interscience publication. Wiley, 1983.\n[40] Yurii Nesterov. Introductory lectures on convex optimization: A basic course, volume 87. Springer\nScience & Business Media, 2013.\n[41] Joel A Tropp. User-friendly tail bounds for sums of random matrices. Foundations of computational mathematics, 12(4):389–434, 2012.\n[42] John W Tukey. Mathematics and the picturing of data. In Proceedings of the international\ncongress of mathematicians, volume 2, pages 523–531, 1975.\n[43] S. van de Geer. Empirical Processes in M-Estimation. Cambridge University Press, 2000.\n[44] Yin Wang, Caglayan Dicle, Mario Sznaier, and Octavia Camps. Self scaled regularized robust\nregression. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,\npages 3261–3269, 2015.\n[45] Yannis G. Yatracos. Rates of convergence of minimum distance estimators and kolmogorov’s\nentropy. Ann. Statist., 13(2):768–774, 06 1985.\n[46] Xinyang Yi, Dohyung Park, Yudong Chen, and Constantine Caramanis. Fast algorithms for robust\nPCA via gradient descent. In Advances in Neural Information Processing Systems 29: Annual\nConference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona,\nSpain, pages 4152–4160, 2016.\n[47] Wen-Xin Zhou, Koushiki Bose, Jianqing Fan, and Han Liu. A new perspective on robust mestimation: Finite sample theory and applications to dependence-adjusted multiple testing. 2017.\n\nA\n\nProof of Theorem 1\n\nIn this section, we present the proof of our main result on projected gradient descent with an\ninexact gradient estimator. To ease the notation we will often omit {Dn , δ} from g(θ; Dn , δ).\nProof. At any iteration step t ∈ {1, 2, . . . , T }, by assumption we have that with probability at\nleast 1 − Tδ ,\nkg(θ t ; Dn , δ/T ) − ∇R(θ t )k2 ≤ α(n/T, δ/T )kθ − θ ∗ k2 + β(n/T, δ/T ).\n\n(28)\n\nTaking union bound, (28) holds over all iteration steps t ∈ {1 . . . T }, with probability at least\n1 − δ. For the remainder of the analysis, we assume this event to be true.\n27\n\n\fNotation. Let g(θ k ) = ∇R(θ k ) + ek be the noisy gradient. Let α = α(n/T, δ/T ) and\nβ = β(n/T, δ/T ) for brevity.\nWe have the following Lemma from Bubeck [6].\nLemma 3. [Lemma 3.11 [6]] Let f be M -smooth and m-strongly convex, then for all x, y ∈ Rp ,\nwe have:\nh∇f (x) − ∇f (y), x − yi ≥\n\nmM\n1\nkx − yk22 +\nk∇f (y) − ∇f (x)k22 .\nm+M\nm+M\n\nBy assumptions\nwe have that:\nk∇R(θ k ) − g(θ k )k2 = kek k2 ≤ αkθ k − θ ∗ k2 + β. Our update\n\u0002\n\u0003\nrule is θ k+1 = PΘ θ k − ηg(θ k ) . Then we have that:\nkθ k+1 − θ ∗ k22 = kPΘ [θ k − ηg(θ k )] − θ ∗ k22 = kPΘ [θ k − ηg(θ k )] − PΘ [θ ∗ − η∇R(θ ∗ )]k22\n≤ kθ k − ηg(θ k ) − (θ ∗ − η∇R(θ ∗ ))k22\n\n=\n≤\n\nk\n\n∗\n\nk\n\nkθ − θ − η(∇R(θ ) − ∇R(θ )) − ηek k22\nkθ k − θ ∗ − η(∇R(θ k ) − ∇R(θ ∗ ))k22 + η 2 kek k22\n+ 2kek k2 kθ k − θ ∗ − η(∇R(θ k ) − ∇R(θ ∗ ))k2 ,\n\n(29)\n\n∗\n\n(30)\n\nwhere Equation (29) follows from contraction property of projections. Now, we can write\nkθ k − θ ∗ − η(∇R(θ k ) − ∇R(θ ∗ ))k2 as\n\nkθk − θ∗ − η(∇R(θk ) − ∇R(θ∗ ))k22 = kθk − θ∗ k22 + η 2 k∇R(θk ) − ∇R(θ∗ )k22 − 2η ∇R(θk ) − ∇R(θ∗ ), θk − θ∗\n\u0012\n\u0013\n1\nτℓ τu\nk\n∗ 2\n2\nk\n∗ 2\nk\n∗ 2\nk\n∗ 2\n≤ kθ − θ k2 + η k∇R(θ ) − ∇R(θ )k2 − 2η\nkθ − θ k2 +\nk∇R(θ ) − ∇R(θ )k2\nτℓ + τu\nτℓ + τu\n(31)\n= kθk − θ∗ k22 (1 − 2ητℓ τu /(τℓ + τu )) + ηk∇R(θk ) − ∇R(θ∗ )k22 (η − 2/(τu + τℓ ))\n≤ kθk − θ∗ k22 (1 − 2ητℓ τu /(τℓ + τu )),\n\n(32)\n(33)\n\nwhere the second step follows from Lemma 3 and the last step follows from the step size\nη ≤ 2/(τℓ + τu ).\nNow, combining Equations (30) and (33), and using our assumption that kek k2 ≤ αkθ k −\nθ ∗ k2 + β, we get:\n\u0010\n\u00112\np\nkθ k+1 − θ ∗ k22 ≤ kθ k − θ ∗ k2 (1 − 2ητℓ τu /(τℓ + τu )) + ηkek k2\np\n\nkθ k+1 − θ ∗ k2 ≤\n\nhp\n\ni\n1 − 2ητℓ τu /(τℓ + τu ) + ηα kθ k − θ ∗ k2 + ηβ.\n\n1 − 2ητℓ τu /(τℓ + τu ) + ηα. By assumption, we choose ǫ < ǫ∗ such that α < τℓ .\np\nκ = 1 − 2ητℓ τu /(τℓ + τu ) + ηα\n(34)\np\n< 1 − 2ητℓ τu /(τℓ + τu ) + ητℓ .\n(35)\np\np\nSince 0 ≤ η ≤ 2/(τℓ + τu ), we get that 1 − 2ητℓ τu /(τℓ + τu ) ≤ 1 − η 2 τℓ τu . We have:\np\n(36)\nκ < 1 − η 2 τℓ τu + ητℓ\nq\n(∵ τℓ ≤ τu )\n(37)\n< 1 − η 2 τℓ2 + ητℓ\n\nLet κ =\n\n(38)\n\n< 1.\n\n28\n\n\fTherefore, we have that,\nkθ k+1 − θ ∗ k2 ≤ κkθ k − θ ∗ k2 + ηβ.\n\nfor some κ < 1. Solving the induction,we get:\n\nkθ k − θ ∗ k2 ≤ κk kθ 0 − θ ∗ k2 +\n\nB\n\n1\nηβ.\n1−κ\n\nProof of Theorem 4\n\nTo prove our result on Robust Generalized Linear Models, we first study the distribution of\ngradients of the corresponding risk function.\nLemma 4. Consider the model in Equation (12), then there exist universal constants C1 , C2 >\n0 such that\n\u0010p p\n\u0011\nC4 LΦ,4 + LΦ,2\nkCov(∇L(θ)k2 ≤C1 k∆k22 kΣk2\n\u0013\n\u0012\nq\np\np\n3\n+ C2 kΣk2 BΦ,2 + BΦ,4 + c(σ) 3MΦ,2,2 + c(σ) MΦ,4,1\nBounded fourth moments E\n\nh\u0002\n\n(∇L(θ) − E[∇L(θ)])T v\n\n\u00034 i\n\n≤ C2 (Var[∇L(θ)T v])2 .\n\nProof. The gradient ∇L(θ) and it’s expectation can be written as:\n∇L(θ) = −y.x + u(hx, θi).x\n\n\u0001\nE[∇L(θ)] = E[x u(xT θ) − u(xT θ ∗ ) ],\n\nwhere u(t) = Φ′ (t).\n\nkE[∇L(θ)]k2 = sup y T E[∇L(θ)]\ny∈Sp−1\n\n\u0001\n≤ sup E[(y T x) u(xT θ) − u(xT θ ∗ ) ]\ny∈Sp−1\n\n≤ sup\n\ny∈Sp−1\n\nq\n1\n2\n\n≤ C1 kΣk2\n\nE[(y T x)2 ]\n\nq\n\nq\n\n2\n\nE[(u(xT θ) − u(xT θ ∗ )) ]\n\nLΦ,2 k∆k22 + BΦ,2\n\nwhere the last line follows from our assumption of smoothness.\nNow, to bound the maximum eigenvalue of the Cov(∇L(θ)),\n\u0002\n\u0003\n\u0001\nkCov(∇L(θ))k2 = sup z T E ∇L(θ)∇L(θ)T − E[∇L(θ)]E[∇L(θ)]T z\nz∈Sp−1\n\n\u0003\u0001\n\u0001\n\u0002\n≤ sup z T E ∇L(θ)∇L(θ)T z + sup z T E[∇L(θ)]E[∇L(θ)]T z\nz∈Sp−1\nz∈Sp−1\ni\u0011\n\u0010 h\n\u0001\n2\nz + kE[∇L(θ)]k22\n≤ sup z T E xxT u(xT θ) − y)\np−1\nz∈S\nh \u0010\n\u00012 \u0011 i\nz + kE[∇L(θ)]k22\n≤ sup E z T xxT u(xT θ) − y\nz∈Sp−1\n\n≤ sup\n\nz∈Sp−1\n\nq\n\nr h\ni\nE (u(xT θ) − y)4 ] + kE[∇L(θ)]k22\n\nE [(z T x)4 ]\n\n29\n\n\fTo bound E\n\nh\n\nu(xT θ) − y\n\n\u00014 i\n\n, we make use of the Cr inequality.\n\nCr inequality. If X and Y are random variables such that E|X|r < ∞ and E|Y |4 < ∞\nwhere r ≥ 1 then:\nE|X + Y |r ≤ 2r−1 (E|X|r + E|Y |r )\nUsing the Cr inequality, we have that\nh\n\u0010 h\nh\n\u00014 i\u0011\n\u00014 i\n\u00014 i\n+ E u(xT θ ∗ ) − y\n≤ 8 E u(xT θ) − u(xT θ ∗ )\nE u(xT θ) − y\n\u0001\n≤ C LΦ,4 k∆k42 + BΦ,4 + c(σ)3 MΦ,4,1 + 3c(σ)2 MΦ,2,2\n\nwhere the last line follows from our assumption that Pθ∗ (y|x) is in the exponential family,\nhence, the cumulants are higher order derivatives of the log-normalization function.\n\u0012\n\u0013\nq\n√ p\np\np\np\n2\n3\nLΦ,4 k∆k2 + BΦ,4 + c(σ) 3MΦ,2,2 + c(σ) MΦ,4,1 + kE[∇L(θ)]k22\nkCov(∇L(θ))k2 ≤ C C4 kΣk2\n\u0012\n\u0013\nq\n√ p\np\np\np\n\u0001\n2\n3\n≤ C C4 kΣk2\nLΦ,4 k∆k2 + BΦ,4 + c(σ) 3MΦ,2,2 + c(σ) MΦ,4,1 + C12 kΣk2 LΦ,2 k∆k22 + BΦ,2\n\u0012\n\u0013\nq\n\u0010p p\n\u0011\np\np\n≤ Ck∆k22 kΣk2\nC4 LΦ,4 + LΦ,2 + C6 kΣk2 BΦ,2 + BΦ,4 + c(σ) 3MΦ,2,2 + c(σ)3 MΦ,4,1\nBounded Fourth Moment. To show that the fourth moment of the gradient distribution\nis bounded, we have\nh\u0002\nh\u0002\n\u00034 i\n\u00034 i\n≤ E (∇L(θ) − E[∇L(θ)])T v\nE (∇L(θ) − E[∇L(θ])T v\n\n\n≤ 8 E[|∇L(θ])T v|4 ] + E[|E[∇L(θ)]T v|4 ] .\n{z\n} |\n{z\n}\n|\nA\n\nControl of A.\n\nB\n\nE[|∇L(θ])T v|4 ] = E[(xT v)4 (u(xT θ) − y)4 ]\nq\nq\nT\n8\n≤ E[(x v) ] E[(u(xT θ) − y)8 ]\nq\np\n2\n≤ C8 kΣk2 E[(u(xT θ) − u(xT θ ∗ ))8 ] + E[(u(xT θ ∗ ) − y)8 ]\nv\nu\n8\nX\np\nu\n2t\n8\ngt,k MΦ,t,k\n≤ C8 kΣk2 LΦ,8 k∆k2 + BΦ,8 +\nt,k=2\n\n≤\n\n√\n\nv\nu 8\nuX\np\np\n2\n4\nCkΣk2 LΦ,8 k∆k2 + BΦ,8 + t\ngt,k MΦ,t,k\nt,k=2\n\nwhere the last step follows from the fact that the 8th central moment can be written as\na polynomial involving the lower cumulants, which in turn are the derivatives of the lognormalization function.\nControl of B.\n\u0001\n2\nE[|E[∇L(θ)]T v|4 ] ≤ kE[∇L(θ)k42 ≤ C1 kΣk22 L2Φ,2 k∆k22 + BΦ,2\n30\n\n\fBy assumption LΦ,k , BΦ,k , MΦ,t,k are all bounded for k, t ≤ 8, which implies that there exist\nconstants c1 , c2 > 0 such that\nh\u0002\n\u00034 i\n≤ c1 kΣk22 k∆k42 + c2\n(39)\nE (∇L(θ) − E[∇L(θ])T v\n\nPreviously, we say that kCov∇L(θ)k2 ≤ c3 kΣk2 k∆k22 +c4 , for some universal constants c3 , c4 >\n0, hence the gradient ∇L(θ) has bounded fourth moments.\nHaving studied the distribution of the gradients, we use Lemma 1 to characterize the\nstability of Huber Gradient estimator. Using Lemma 1, we know that at any point θ, the\nHuber Gradient Estimator g(θ, δ/T ) satisfies that with probability 1 − δ/T ,\n\u0011\n\u0010 1\n1p\ne kCov(∇L(θ))k 2 log p.\nn, p, δ)\nkg(θ, δ/T ) − ∇R(θ)k2 ≤ C2 ǫ 2 + γ(e\n2\n\nSubstituting the upper bound on kCov(∇L(θ))k2 from Lemma 4, we get that there are universal constants C1 , C2 such that with probability at least 1 - δ/T\n\u0010 1\n\u0011p\n1\n1\n1\n4\n2\ne\nlog pkΣk22 [LΦ,4\n(40)\nkg(θ) − ∇R(θ)k2 ≤ C1 ǫ 2 + γ(e\n+ LΦ,2\n] k∆k2\nn, p, δ)\n{z\n}\n|\ne\nα(e\nn,δ)\n\n\u0010\n\n\u0011p\n1\n1\n1\n1\n1\n1\n1\n3\n4\n2\n4\n4\ne\n+ C2 ǫ 2 + γ(e\nn, p, δ)\n+ BΦ,2\n+ c(σ) 2 MΦ,2,2\n+ c(σ) 4 MΦ,4,1\n]\nlog pkΣk22 [BΦ,4\n|\n{z\n}\ne\nβ(e\nn,δ)\n\n(41)\n\ne < τℓ . Using Equation (40), we\nTo ensure stability of gradient descent, we need that α(e\nn, δ)\nget that gradient descent is stable as long as the number of samples n is large enough such\nC1 τℓ\ne <\nthat γ(e\nn, p, δ)\n, and the contamination level is such that\n1\n1\n1\n√\n4 +L 2 ]\nlog pkΣk22 [LΦ,4\nΦ,2\n\nǫ<\n\nC2 τℓ\n1\n1\n1\n√\n4 +L 2 ]\nlog pkΣk22 [LΦ,4\nΦ,2\n\n!2\n\ne\n− γ(e\nn, p, δ)\n\nfor some constants C1 and C2 . Plugging the corre-\n\ne into Theorem 1, we get back the result of Theorem 4.\nsponding ǫ and β(e\nn, δ)\n\nC\n\nProof of Corollary 3\n\nWe begin by studying the distribution of the random variable xy = xxT θ ∗ + x.w.\nLemma 5. Consider the model in Equation (11), with x ∼ N (0, Ip ) and w ∼ N (0, 1) then\nthere exist universal constants C1 , C2 such that\nE[xy] = θ ∗\nkCov(xy)k2 = 1 + 2kθ ∗ k22\nh\u0002\n\u00034 i\n≤ C2 (Var[(xy)T v])2 .\nBounded fourth moments E (xy − E[xy])T v\n\nProof. Mean.\n\nxy = xxT θ ∗ + x.w\nT ∗\n\nE[xy] = E[xx θ + x.w]\n∗\n\n(42)\n(43)\n(44)\n\nE[xy] = θ .\n31\n\n\fCovariance.\nCov(xy) = E[(xxT − I)θ ∗ + x.w)((xxT − I)θ ∗ + x.w)T )]\n∗ ∗T\n\nCov(xy) = E[(xxT − I)θ θ\n\n(45)\n\n(xxT − I)] + Ip .\n\n(46)\n\nNow, Z = (xxT − I)θ ∗ can be written as:\n\n  ∗  ∗ 2\n 2\nθ1 (x1 − 1) + x1 x2 θ2∗ + . . . + x1 xp θp∗\nθ1\n(x1 − 1)\nx1 x2\n...\nx1 xp\n∗\n∗\n2\n∗\n ∗ \n x1 x2\nx2 xp \n(x22 − 1) . . .\n θ2  x1 x2 θ1 + (x2 − 1)θ2 + . . . + x2 xp θp \n\nT\n∗\n(xx −I)θ = \n.\n  ..  = \n..\n..\n..\n..\n..\n\n .  \n\n.\n.\n.\n.\n.\n∗\n2\n2\n∗\n∗\n∗\nθp\nx1 xp\nx2 xp\n. . . (xp − 1)\nx1 xp θ1 + x2 xp θ2 + . . . + (xp − 1)θp\n\nThen,\n\n\n...\nθ1∗ θp∗\n2θ1∗ 2 + θ2∗ 2 + . . . + θp∗ 2\nθ1∗ θ2∗\n\nθ1∗ 2 + 2θ2∗ 2 + . . . + θp∗ 2 . . .\nθ2∗ θp∗\nθ1∗ θ2∗\n\u0002\n\u0003 \n\n\nT\nE ZZ = \n.\n..\n..\n..\n..\n\n\n.\n.\n.\n.\n2\n2\n2\n∗\n∗\n∗\n∗\n∗\n∗\n∗\n. . . θ1 + θ2 + . . . + 2θp\nθ2 θp\nθp θ1\n\n\nHence the covariance matrix can be written as:\n\nCov(xy) = Ip (1 + kθ ∗ k22 ) + θ ∗ θ ∗ T .\nTherefore kCov(xy)k2 = 1 + 2kθ ∗ k22 .\nBounded Fourth Moment.\nE\n\nh\u0002\n\n(xy − E[xy])T v\n\n\u00034 i\n\n≤E\n\nWe start from the LHS\nh\u0002\n\n\u0002\n\n(xy − E[xy])T v\n\n\u00034 i\n\n(47)\n\u00034\n\n= E ((xxT − I)θ ∗ + wx)T v\ni4\nh\n= E (θ ∗T x)(xT v) − θ ∗T v + wv T x\n \n\n\n4\n \nT\n∗T\n∗T\n\n≤ 8\n8 E (θ x)(x v) + E θ v\n|\n{z\n} | {z\nA\n\nB\n\n(48)\n(49)\n\n\n\n + E w(xT v) 4 .\n\n| {z } \n}\n4\n\n(50)\n\nC\n\nThe last line follows from two applications of the following inequality:\n\nCr inequality. If X and Y are random variables such that E|X|r < ∞ and E|Y |4 < ∞\nwhere r ≥ 1 then:\nE|X + Y |r ≤ 2r−1 (E|X|r + E|Y |r ) .\nNow to control each term on:\n• Control of A. Using Cauchy Schwartz, and normality of 1D projections of normal\ndistribution\nq\nq\nT 8\n∗\nA ≤ E[|θ x| ] E[|xT v|8 ]\n(51)\n- kθ ∗ k42 .\n\n32\n\n(52)\n\n\f• Control of B, B ≤ kθ ∗ k42 .\n• Control of C, C = O(1), using independence of w and normality of 1D projections of\nnormal distribution.\nh\u0002\n\u00034 i\nTherefore the E (xy − E[xy])T v\n- c + kθ ∗ k42 .\nFor the RHS:\n\nVar((xy)T v)2 = (v T Cov(xy)v)2 ≤ kCov(xy)k22 .\n\nWe saw that the kCov(xy)k2 - c + kθ ∗ k22 , so both the LHS and RHS scale with kθ ∗ k42 . Hence,\nxy has bounded fourth moments.\nNow that we’ve established that xy has bounded fourth moments implies that we can use\n[29] as a mean estimation oracle. Using Theorem 1.3 [29], we know that the oracle of [29]\noutputs an estimate θb of E[xy] such that with probability at least 1 − 1/pC1 , we have:\n\u0011\n\u0010 1\np\nkθb − θ ∗ k2 ≤ C2 kCov(xy)k2 log p ǫ 2 + γ(n, p, δ, ǫ)\nUsing Lemma 5 to subsitute kCov(xy)k2 ≤ 1+2kθ ∗ k22 ), we recover the statement of Corollary 3.\n\nD\n\nProof of Theorem 6\n\nTo prove our result on Robust Exponential Family, we first study the distribution of gradients\nof the corresponding risk function.\nLemma 6. Consider the model in Equation (15), then there exists a universal constant C1\nsuch that\nE[∇L(θ)] = ∇A(θ) − ∇A(θ ∗ )\n2\n\n∗\n\nkCov[∇L(θ)]k2 = k∇ A(θ )k2\nh\u0002\n\u00034 i\n≤ C1 (Var[∇L(θ)T v])2 .\nBounded fourth moments E (∇L(θ) − E[∇L(θ)])T v\n\n(53)\n(54)\n(55)\n\nProof. By Fisher Consistency of the negative log-likelihood, we know that\nEθ∗ [∇L(θ ∗ )] = 0\n\n(56)\n\n=⇒ ∇A(θ ) − Eθ∗ [φ(z)] = 0\n\n(57)\n\n∗\n\n∗\n\n=⇒ ∇A(θ ) = Eθ∗ [φ(z)].\n\n(58)\n\nFor the mean,\n∇L(θ) = ∇A(θ) − φ(z)\n\n(59)\n\nE[∇L(θ)] = ∇A(θ) − Eθ∗ [φ(z)]\n∗\n\nE[∇L(θ)] = ∇A(θ) − ∇A(θ ).\n\nNow, for the covariance:\n\u0001\n\u0001T i\n∇L(θ) − Eθ∗ [∇L(θ)] ∇L(θ) − Eθ∗ [∇(L(θ)]\ni\nh\nT\n∗\n∗\n∗\n= Eθ (∇A(θ ) − φ(z)) (∇A(θ ) − φ(z))\n\u0003\n\u0002\n= Covθ∗ ∇L(θ ∗ ) = ∇2 A(θ ∗ ).\n\nCovθ∗ [∇L(θ)] = Eθ∗\n\nh\n\n33\n\n(60)\n(61)\n\n\fBounded moments follows from our assumption that the sufficient statistics have bounded 4th\nmoments.\nHaving studied the distribution of the gradients, we use Lemma 1 to characterize the\nstability of Huber Gradient estimator. Using Lemma 1, we know that at any point θ, the\nHuber Gradient Estimator g(θ, δ/T ) satisfies that with probability 1 − δ/T ,\n\u0011\n\u0010 1\n1p\ne kCov(∇L(θ))k 2 log p.\nn, p, δ)\nkg(θ, δ/T ) − ∇R(θ)k2 ≤ C2 ǫ 2 + γ(e\n2\n\nSubstituting the upper bound on kCov(∇L(θ))k2 from Lemma 6, we get that there are universal constants C1 , C2 such that\n\u0010 1\n\u0011p\n√\ne\nkg(θ) − ∇R(θ)k2 ≤ C1 ǫ 2 + γ(e\nn, p, δ)\nlog p τu .\n|\n{z\n}\ne\nβ(e\nn,δ)\n\ne = 0 < τℓ by assumption. Therefore we just have that ǫ <\nIn this case we have that α(e\nn, δ)\ne into Theorem 1,\nC1 for some universal constant C1 . Plugging the corresponding ǫ and β(e\nn, δ)\nwe get back the result of Corollary 6.\n\nE\n\nProof of Corollary 7\n\nUsing the contraction property of projections, we know that\n\u0002\n\u0003\n\u0002\n\u0003\nkPΘ (∇A)−1 µ\nb − θ ∗ k2 = kPΘ (∇A)−1 µ\nb − PΘ [θ ∗ ] k2 ≤ k(∇A)−1 µ\nb − θ ∗ k2 .\nBy Fisher Consistency of the negative log-likelihood, we know that\n∇A(θ ∗ ) = Eθ∗ [φ(z)].\nThe true parameter θ ∗ can be obtained by inverting the ∇A operator whenever possible.\nk(∇A)−1 µ\nb − θ ∗ k2 = k(∇A)−1 µ\nb − (∇A)−1 Eθ∗ [φ(z)]k2\n∗\n\n∗\n\n= k∇A µ\nb − ∇A Eθ∗ [φ(z)]k2 .\n\n(62)\n(63)\n\nwhere A∗ is the convex conjugate of A. We can use the following result to control the Lipschitz\nsmoothness A∗ .\nTheorem 12. (Strong/Smooth Duality) Assume f (·) is closed and convex. Then f (·) is smooth\nwith parameter M if and only if its convex conjugate f (·) is strongly convex with parameter\n1\n.\nm= M\nA proof of the above theorem can be found in [28]. Hence, we have that:\n\u0002\n\u0003\n1\nµ − Eθ∗ [φ(z)]k2\nb − θ ∗ k2 ≤ kb\nkPΘ (∇A)−1 µ\nτℓ\n\n(64)\n\nBy assumption, we have that the fourth moments of the sufficient statistics are bounded. We\nalso know that Cov(φ(z) = ∇2 A(θ ∗ ) which implies that we can use [29] as our oracle. Using\nLemma 1, we get that, there exists universal constants C1 , C2 such that with probability at\nleast 1 − 1/pC1 ,\n\u0010 1\n\u0011\np\nkb\nµ − Eθ∗ [φ(z)]k2 ≤ C2 τu log p ǫ 2 + γ(n, p, δ, ǫ) .\n\nCombining the above with Equation (64) recovers the result of Corollary 7.\n34\n\n\fF\n\nProof of Theorem 8\n\nBefore we present the proof of Theorem 8, we first study the distribution of gradients of the\nloss function. This will help us bound the error in the gradient estimator.\nLemma 7. Consider the model in Equation (11). Suppose the covariates x ∈ Rp have bounded\n4th -moments and the noise w has bounded 2th moments.. Then there exist universal constants\nC1 , C2 such that\nE[∇L(θ)] = Σ∆\nkCov(∇L(θ)k2 ≤ σ 2 kΣk2 + C1 k∆k22 kΣk22 ,\nwhere ∆ = θ − θ ∗ and E[xxT ] = Σ.\nProof. We start by deriving the results for E[∇L(θ)].\n1\n1\nL(θ) = (y − xT θ)2 = (xT (∆) − w)2\n2\n2\n∇L(θ) = xxT ∆ − x.w\n\n(65)\n(66)\n(67)\n\nE[∇L(θ)] = Σ∆.\n\nNext, we bound the operator norm of the covariance of the gradients ∇L(θ) at any point θ.\nCovariance.\nCov(∇L(θ)) = E[(xxT − Σ)∆ − x.w)((xxT − Σ)∆ − x.w)T )]\nT\n\nT\n\nT\n\n(68)\n\n2\n\nCov(∇L(θ)) = E[(xx − Σ)∆∆ (xx − Σ)] + σ Σ.\n\n(69)\n\nNow, we want to bound kCov(∇L(θ))k2 = λmax (Cov(∇L(θ))).\n\n\u0001\nλmax (Cov(∇L(θ))) ≤ σ 2 λmax (Σ) + λmax E[(xxT − Σ)∆∆T (xxT − Σ)]\n2\n\n≤ σ λmax (Σ) + sup y\ny∈Sp−1\n\nT\n\n(70)\n\n\u0001\nE[(xx − Σ)∆∆ (xx − Σ)] y\nT\n\nT\n\nT\n\n(71)\n\n\u0001\n≤ σ 2 λmax (Σ) + sup y T E[(xxT − Σ)∆∆T (xxT − Σ)] y\ny∈Sp−1\n\n≤ σ 2 λmax (Σ) + k∆k22\n\n≤ σ 2 λmax (Σ) + k∆k22\n\nsup\n\ny,z∈Sp−1\n\nsup\n\n≤ σ 2 λmax (Σ) + 2k∆k22\n2\n\n≤ σ λmax (Σ) +\n≤ σ 2 kΣk2 +\n\n\u0002\n\u0003\nE (y T (xxT − Σ)z)2\n\ny,z∈Sp−1\n\n≤ σ 2 λmax (Σ) + 2k∆k22\n\n2k∆k22\n\nsup\ny,z∈Sp−1\n\nsup\ny,z∈Sp−1\n\nsup\n\n(72)\n(73)\n\n\u0002\n\u0003\u0001\nE 2(y T x)2 (xT z)2 + 2(y T Σz)2\n\n(74)\n\n\u0002\n\u0003\n\u0001\nE (y T x)2 (xT z)2 + kΣk22\n\n\u0002\n\u0003\n\u0001\nE (y T x)2 (xT z)2 + kΣk22\n\n\u0012q\n\nE [(y T x)4 ]\n\ny,z∈Sp−1\n2\n2k∆k2 (kΣk22 + C4 kΣk22 ),\n\nq\n\nE [(z T x)4 ]\n\n+ kΣk22\n\n(75)\n(76)\n\u0013\n\n(77)\n(78)\n\nwhere the second last step follows from Cauchy-Schwartz and the last step follows from our\nassumption of bounded 4th moments (see Equation (10)).\n35\n\n\fWe now proceed to the proof of Theorem 8. From Lemma 2, we know that at any point\ne satisfies the following with\nθ, the gradient estimator described in Algorithm 3, g(θ; Dne , δ),\nprobability at least 1 − δ,\ne − ∇R(θ)k2 ≤ C\nkg(θ; Dne , δ)\n\nq\n\ntr(Cov(∇L(θ))) log 1/δe\n.\nn\ne\n\nWe substitute the upper bound for kCov(∇L(θ))k2 from Lemma 7 in the above equation\ne − ∇R(θ)k2 ≤ C\nkg(θ; Dne , δ)\n\n≤ C\n\nq\n\nq\n\n≤ C1\n|\n\ntr(Cov(∇L(θ))) log 1/δe\nn\ne\np(σ2 kΣk2 +2k∆k22 (kΣk22 +C4 kΣk22 )) log 1/δe\nn\ne\n\ns\n\nkΣk22 p log 1/δe\nkθ − θ ∗ k2\nn\ne\n{z\n}\ne\n\nα(e\nn,δ)\ns\nkΣk2 p log 1/δe\n.\n+ C2 σ\nn\ne\n{z\n}\n|\ne\nβ(e\nn,δ)\n\nTo complete the proof of this theorem, we use the results from Theorem 1. Note that the\ne < τl . This holds when\ngradient estimator satisfies the stability condition if α(e\nn, δ)\nn\ne>\n\nC12 τu2\ne\np log 1/δ.\nτl2\n\ne into Theorem 1 gives us\nNow suppose n\ne satisfies the above condition, then plugging β(e\nn, δ)\nthe required result.\n\nG\n\nProof of Theorem 9\n\nTo prove the Theorem we use the result from Lemma 4, where we derived the following\nexpression for covariance of ∇L(θ)\n\u0010p p\n\u0011\nkCov(∇L(θ)k2 ≤C1 k∆k22 kΣk2\nC4 LΦ,4 + LΦ,2\n\u0013\n\u0012\nq\np\np\n3\n+ C2 kΣk2 BΦ,2 + BΦ,4 + c(σ) 3MΦ,2,2 + c(σ) MΦ,4,1\nFrom Lemma 2, we know that at any point θ, the gradient estimator described in Algorithm 3,\ne satisfies the following with probability at least 1 − δ,\ng(θ; Dne , δ),\ne − ∇R(θ)k2 ≤ C\nkg(θ; Dne , δ)\n36\n\nq\n\ntr(Cov(∇L(θ))) log 1/δe\n.\nn\ne\n\n\fSubstitute the upper bound for kCov(∇L(θ))k2 in the above equation, we get\nq\nlog 1/δe\ne\nkg(θ; Dne , δ) − ∇R(θ)k2 ≤ C tr(Cov(∇L(θ)))\nn\ne\ns\n\u0001\n√ p\nkΣk2\nC4 LΦ,4 + LΦ,2 p log 1/δe\nkθ − θ ∗ k2\n≤ C1\nn\ne\n{z\n}\n|\ne\n\n+ C2\n|\n\nα(e\nn,δ)\nv\n\u0010\n\u0011\nu\np\nu kΣk B + pB + c(σ)p3M\n3\nc(σ) MΦ,4,1 p log 1/δe\nΦ,2\n2\nΦ,4\nΦ,2,2 +\nt\n\n{z\n\nn\ne\n\ne\nβ(e\nn,δ)\n\nWe now use the results from Theorem 1. The gradient estimator satisfies the stability condition\ne < τl . This holds when\nif α(e\nn, δ)\n\u0001\n√ p\nC12 kΣk2\nC4 LΦ,4 + LΦ,2\ne\nn\ne>\np log 1/δ.\nτl2\n\ne into Theorem 1 gives us\nNow suppose n\ne satisfies the above condition, then plugging β(e\nn, δ)\nthe required result.\n\nH\n\nProof of Theorem 11\n\nThe proof proceeds along similar lines as the proof of Theorem 9. To prove the Theorem we utilize the result of Lemma 6, where we showed that kCov[∇L(θ)]k2 = k∇2 A(θ ∗ )k2 . Combining\nthis result with Lemma 2 we get that with probability at least 1 − δ\nq\nlog 1/δe\ne\nkg(θ; Dne , δ) − ∇R(θ)k2 ≤ C tr(Cov(∇L(θ)))\nn\ne\ns\nk∇2 A(θ ∗ )k2 p log 1/δe\n≤ C\n.\nn\ne\n|\n{z\n}\ne\nβ(e\nn,δ)\n\ne = 0, the stability condition is always satisfied, as long as τl > 0. Substituting\nSince α(e\nn, δ)\ne into Theorem 1 gives us the required result.\nβ(e\nn, δ)\n\nI\n\nUpper bound on Contamination Level\n\nWe provide a complementary result, which gives an upper bound for the contamination level ǫ\nbased on the initialization point θ 0 , above which, Algorithm 1 would not work. The key idea\nis that the error incurred by any mean estimation oracle is lower bounded by the variance of\nthe distribution, and that if the zero vector lies within that error ball, then any mean oracle\ncan be forced to output 0 as the mean. For Algorithm 1, this implies that, in estimating the\nmean of the gradient, if the error is high, then one can force the mean to be 0 which forces\nthe algorithm to converge. For the remainder of the section we consider the case of linear\nregression with x ∼ N (0, Ip ) in the asymptotic regime of n → ∞.\n37\n\n}\n\n.\n\n\fLemma 8. Consider the model in equation(11) with x ∼ N (0, Ip ) and w ∼ N (0, 1), then\n0\n∗\nthere exists a universal constant C1 such that if ǫ > C1 √ kθ −θ0 k2∗ 2 , then for every gradient\n1+2kθ −θ k2\n\noracle, there exists a contamination distribution Q such that, Algorithm 1 will converge to θ 0\neven when the number of samples n → ∞.\nProof. Using Lemma 5, we know that for any point θ,\n∇L(θ) = xxT ∆ − x.w\n\nEθ∗ [∇L(θ)] = (θ − θ ∗ ) = ∆\n\nkCov(∇L(θ)k2 = 1 + 2k∆k22 ,\n\nwhere ∆ = θ − θ ∗ .\nLet P∇L(θ) represent the distribution ∇Lθ. Similarly, let Pǫ,∇L(θ),Q represent the corresponding\nǫ-contaminated distribution. Then, using Theorem 2.1 [10], we know that the minimax rate\nfor estimating the mean of the distribution of gradients is given by:\n\b\nµ − Eθ∗ [∇L(θ)]k22 ≥ Cǫ2 (1 + 2k∆k22 ) ≥ c.\ninf sup Pǫ,∇L(θ),Q kb\nµ\nb θ∈Rp ,Q\n\nThe above\np statement says that at any point θ, any mean oracle Ψ will always incur an\nerror of Ω( Cǫ2 (1 + 2k∆k22 )) in estimating the gradient Eθ∗ [∇L(θ)].\nkΨ(θ) − Eθ∗ [∇L(θ)]k2 ≥ Cǫ\n\nq\n\n(1 + 2k∆k22 ) ∀ Ψ\n\nForp\nany oracle Ψ, there exists some adversarial contamination Q, such that whenever kEθ∗ [∇L(θ)]k2 <\nCǫ (1 + 2k∆k22 ), then kΨ(θ)k2 = 0.\nSuppose that the contamination level ǫ is such that,\nǫ>\n\n1 kEθ∗ [∇L(θ 0 )]k2\np\n,\nC (1 + 2kθ 0 − θ ∗ k22 )\n\nthen for every oracle there exists a corresponding Q such that Algorithm 1 will remain stuck\nat θ 0 .\nPlugging Eθ∗ [∇L(θ 0 )] = θ 0 − θ ∗ , we recover the statement of the lemma.\nChen et al. [10] provide a general minimax lower bound of Ω(ǫ) for ǫ-contamination√models\nin this setting. In contrast, using Algorithm 1 with [29] as oracle, we can only O( ǫ log p)\nclose to the true parameter even when the contamination is small, which implies that our\nprocedure is not minimax optimal. Our approach is nonetheless the only practical algorithm\nfor robust estimation of general statistical models.\n\nJ\n\nDetails and Analysis of Algorithm 2\n\nIn this section we present a refined, non-asymptotic analysis of the algorithm from [29]. We begin by introducing some preliminaries. We subsequently analyze the algorithm in 1-dimension\nand finally turn our attention to the general algorithm.\n38\n\n\fJ.1\n\nPreliminaries\n\nUnless otherwise stated, we assume throughout that the random variable X has bounded\nfourth moments, i.e. for every unit vector v,\n\u0002\n\u0003\n\u0002 \u0002\n\u0003\u00032\nE hX − µ, vi4 ≤ C4 E hX − µ, vi2 .\n\nWe summarize some useful results from [29], which bound the deviation of the conditional\nmean/covariance from the true mean/covariance.\n\nLemma 9. [Lemma 3.11 [29]] Let X be a univariate random variable with bounded fourth\nmoments, and let A be any with event with probability P(A) = 1 − γ ≥ 21 . Then,\np\n|E(X|A) − E(X)| ≤ σ 4 8C4 γ 3 .\n\nLemma 10.\u0001 [Lemma 3.12 [29]] Let X be a univariate random variable with E[X] = µ,\nE (X − µ)2 = σ 2 and let E((X − µ)4 ) ≤ C4 σ 4 . Let A be any with event with probability\nP(A) = 1 − γ ≥ 12 . Then,\np\n(1 − C4 γ)σ 2 ≤ E((X − µ)2 |A) ≤ (1 + 2γ)σ 2 .\n\nCorollary 13. [Corollary 3.13 [29]] Let A be any event with probability P(A) = 1 − γ ≥ 21 ,\nand let X be a random variable with bounded fourth moments. We denote Σ|A = E(XX T |A) −\n(E(X|A))(E(X|A))T to be the conditional covariance matrix. We have that,\np\np\n(1 − C4 γ − 8C4 γ 3 )Σ \u0016 Σ|A \u0016 (1 + 2γ)Σ.\n\nFor random variables with bounded fourth moments we can use Chebyshev’s inequality to\nobtain tail bounds.\n\nLemma 11. [Lemma 3.14 [29]] Let X have bounded fourth moments, then for every unit\nvector v we have that,\nP(|hX, vi − E[hX, vi]| ≥ t\n\np\n\n[E [hX − µ, vi2 ]]) ≤\n\nC4\n.\nt4\n\nOur proofs also use the matrix Bernstein inequality for rectangular matrices. As a preliminary,\nwe consider a finite sequence {Zk } of independent, random matrices of size d1 ×d2 . We assume\nthat each random matrix satisfies E(Zk ) = 0, and kZk kop ≤ R almost surely. We define:\n(\n)\nX\nX\nσ 2 := max k\nE(Zk ZkT )kop , k\nE(Zk ZkT )kop .\nk\n\nk\n\nWith these preliminaries in place we use the following result from [41].\nLemma 12. For all t ≥ 0,\nP\n\n\u0010 X\nk\n\nZk\nop\n\n\u0011\n\n≥ t ≤ (d1 + d2 ) exp\n\n\u0012\n\n−t2 /2\nσ 2 + Rt/3\n\n\u0013\n\n.\n\nEquivalently, with probability at least 1 − δ,\ns\n\u0012\n\u0012\n\u0013\n\u0013\nX\nd1 + d2\nd1 + d2\n2R\nlog\n+\n.\n≤ 2σ 2 log\nZk\nδ\n3\nδ\nop\nk\n\n39\n\n\fWe let I denote the set of all intervals in R. The following is a standard uniform convergence\nresult.\nLemma 13. Suppose X1 , . . . , Xn ∼ P, then with probability at least 1 − δ,\nr\nn\n4 log(en) + 2 log(2/δ)\n1X\nI(Xi ∈ I) ≤ 2\n.\nsup P(I) −\nn\nn\nI∈I\ni=1\n\nAlgorithm 4 Huber Outlier Gradients Truncation\nfunction HuberOutlierGradientTruncation(Sample Gradients S, Corruption\nLevel ǫ, Dimension p,δ)\nif p=1 then\n\u0012\n\u0012r\n\u0010 \u0011\u0013\u0013\n|S|\n1\nLet [a, b] be smallest interval containing 1 − ǫ − C5\n(1 − ǫ) fracδ\n|S| log\n\ntion of points.\nSe ← S ∩ [a, b].\nreturn Se\nelse\nLet [S]i be the samples with the ith co-ordinates only, [S]i = {hx, ei i |x ∈ S}\nfor i = 1 to p do\na[i] = HuberGradientEstimator([S]i , ǫ, 1, δ/p).\nend for\n\u0012r Let B(r, a)\u0013 be the ball of smallest radius centered at a containing (1 − ǫ −\n\nCp\n\np\n|S|\n\nlog\n\n\u0010\n\n|S|\npδ\n\n\u0011\n\n(1 − ǫ) fraction of points in S.\n\nSe ← S ∩ B(r, a).\nreturn Se\nend if\nend function\n\nWe now turn our attention to an analysis of Algorithm 2 for the 1-dimensional case.\n\nJ.2\n\nThe case when p = 1\n\nFirstly, we analyze Algorithm 2 when p = 1.\nLemma 14. Suppose that, Pθ∗ is a distribution on R1 with mean µ, variance σ 2 , and bounded\nfourth moments. There exist positive universal constants C1 , C2 , C8 > 0, such that given n\nsamples from the distribution in (4), the algorithm with probability at least 1 − δ, returns an\nestimate µ\nb such that,\n!3\n!1 r\nr\nr\n4\n2\n1\nlog\n3/δ\nlog\n3/δ\nlog(3/δ)\n+t\n+t\n+ C2 σ ǫ +\nkb\nµ − µk2 ≤ C1 C44 σ ǫ +\n2n\n2n\nn\nwhere t = C8\n\nq\n\n1\nn\n\nn\nδ\n\nlog\n1\n4\n\n\u0001\n\n. which can be further simplified to,\n\nkb\nµ − µk2 ≤ C1 C4 σ ǫ + C8\n\nr\n\n!3\n!1 r\nr\n\u0010n\u0011 4\n\u0010 n \u0011 2 log(1/δ)\n1\n1\n+ C2 σ ǫ + C8\nlog\nlog\nn\nδ\nn\nδ\nn\n40\n\n\fProof. By an application of Hoeffding’s inequality we obtain that with probability at least\n1 − δ/3,\nq the fraction of corrupted samples (i.e. samples from the distribution Q) is less than\n\nǫ + log(3/δ)\n2n . We condition on this event through the remainder of this proof. We let η\ndenote the fraction of corrupted samples. Further, we let SP be the samples from the true\ndistribution. Let nP be the cardinality of this set, i.e. nP := |SP |.\nLet I1−η be the interval around µ containing 1 − η mass of Pθ∗ . Then, using Lemma 11,\nwe have that:\n1\n\nlength (I1−η ) ≤\n\nC44 σ\n1\n\nη4\n\n.\n\nUsing Lemma 13 we obtain that with probability at least 1 − δ/3 the number of samples from\nthe distribution P that fall in the interval I1−η is at least 1 − η − t where t is upper bounded\nas:\nr\n4 log(en) + 2 log(6/δ)\n.\nt≤2\nn\nNow we let Se be the set of points in the smallest interval containing (1 − η − t)(1 − η) fraction\nof all the points.\n• Using VC theory, we know that for every interval I ⊂ R, there exists some universal\nconstant C3 such that\nP (|(P (x ∈ I|x ∼ D) − P (x ∈ I|x ∈u SD ))| > t/2) ≤ n2D exp(−nD t2 /8)\n\n(79)\n\nThis can be re-written as, that with probability at least (1−δ/3), there exists a universal\nconstant C0 such that,\nr\nr\n\u0010n \u0011\n\u0010n\u0011\n1\n1\nD\n≤ C5\nlog\nlog\nsup |(P (x ∈ I|x ∼ D) − P (x ∈ I|x ∈u SD ))| ≤ C0\nnD\nδ\nn\nδ\nI\n|\n{z\n}\nt\n\n• Using Equation (79), we know that (1 − η − t) fraction of SD lie in I1−η .\nLet Se be the set of points in the smallest interval containing (1 − η − t)(1 − η) fraction\nof the points.\n\n• We know that the length of minimum interval containing (1 − η − t)(1 − η) fraction of\nthe points of S is less than length of smallest interval containing (1 − η − t) fraction of\npoints of SD , which in turn is less than length of I1−η .\n\n• Now, I1−η and minimum interval containing (1 − η − t) fraction of points of SD need\nto overlap. This is because, n is large enough such that t < 12 − η hence, the extreme\npoints for such an interval can be atmost 2length (I1−η ) away.\n• Hence, the distance of all chosen noise-points from µ will be within the length (I1−η ).\n• Moreover, the interval of minimum length with (1−η −t)(1−η) fraction of S will contain\nat least 1 − 3η − t fraction of SD .\ne by controlling the sources of error.\n• Hence, we can bound the error of mean(S)\n41\n\n\f– All chosen noise points are within length (I1−η ), and there are atmost η of them,\nhence the maximum error can be ηlength (I1−η ).\n– Next, the mean of chosen good points will converge to the mean of the conditional\ndistribution. i.e. points sampled from D but conditioned to lie in the minimum\nlength interval. The variance of these random variables is upper bounded using\nLemma 10.\n– To control the distance between the mean(E(X) and the conditional mean(E(X|A)),\nwhere A is the event that a sample x is in the chosen interval. We know that\nP (A) ≥ 1 − 3η − t, hence, using Lemma 3.11[29], we get that there exists a constant\nC13 such that,\n1\n\n3\n\n|E[X] − E[X|A]| ≤ C13 C44 σ(η + t) 4\n• Hence, with probability at least 1 − δ/3, the mean of Se will be within\nr\n1\n3\n1\nlog(3/δ)\n4\nη × length (I1−η ) + C13 C4 σ(η + t) 4 + C6 σ(1 + 2η) 2\nn\n• q\nTaking union-bound over all conditioning statements, and upper bounding, η with ǫ +\nlog(3/δ)\n2n , we recover the statement of the lemma.\n\nJ.3\n\nThe case when p > 1\n\nTo prove the case for p > 1, we use a series of lemmas. Lemma 15 proves that the outlier\nfiltering constrains the points in a ball around the true mean. Lemma 17 controls the error in\ne Lemma 18 controls\nthe mean and covariance the true distribution after outlier filtering (D).\ne\nthe error for the mean of S when projected onto the bottom span of the covariance matrix\nΣSe.\n\nLemma 15. Suppose that, Pθ∗ is a distribution on Rp with mean µ, covariance Σ, and bounded\nfourth moments. There exist positive universal constants C1 , C2 , C8 > 0, such that given n\nsamples from the distribution in Equation (4), we can find a vector a ∈ Rp such that with\nprobability at least 1 − δ,\n1\n4\n\nka − µk2 ≤C1 C4\n\n+ C2\n\n!3\n\u0010 np \u0011 4\n1\ntr (Σ) ǫ + C8\nlog\nn\nδ\n!1\nr\nr\n\u0010 np \u0011 2 p\n1\nlog(p/δ)\ntr (Σ)\nlog\nǫ + C8\nn\nδ\nn\nr\n\np\n\nProof. Pick n orthogonal directions v1 , v2 , . . . , vn , and use method for one-dimensions, and\nusing union bound, we can recover the result.\nNext, we prove the case when p > 1. Firstly, we prove that after the outlier step,\nLemma 16. After the outlier removal step, there exists universal constants C11 > 0 such that\nwith probability at least 1 − δ, every remaining point x satisfies,\nkx − µk2 ≤ r1∗ + 2r2∗\n42\n\n\f√\n\nq\n1p\np\n3\n1\nand r2∗ = C1 C44 pkΣk2 (η + t) 4 + C2 pkΣk2 (η + t) 2 log(1/δ)\nand\nn\nq\nq\n\u0001\nlog(1/δ)\nis the fraction of samples corrupted.\nt = C8 n1 log np\nδ . Here η ≤ ǫ +\n2n\n1\n\nwhere\n\nr1∗\n\n= C10\n\nC44\n\npkΣk2\n\n1\nη4\n\nProof.\n• Let Se be the set of points chosen after the outlier filtering. Let SeD be set of good\npoints chosen after the outlier filtering. Let SeN be the set of bad points chosen after the\noutlier filtering.\n• Using VC theory we know that for every closed ball B(µ, r) = {x|kx − µk2 ≤ r}, there\nexists a constant C9 such that with probability at least 1 − δ\ns\n\u0012 \u0013\nn\np\nlog\nsup |P (x ∈ B|x ∼ D) − P (x ∈ B|x ∈u SD )| ≤ C9\nn\npδ\nB\n|\n{z\n}\nt2\n\n1\n\n• Let B ∗ = B(µ, r ∗ ) for r1∗ = C10\n\nC44\n\n1\n(η) 4\n\np\n\npkΣk2 . Then, we claim that\n\nP (x ∈ B ∗ |x ∼ D) ≥ 1 − η\n– To see this, suppose we have some x ∈ D. LetPz = x − µ. Let zi = z T vi for some\northogonal directions v1 , v2 , . . . , vp . Let Z 2 = zi2 = kzk22 .\n–\n\n\n\n1\n2\n\n\n\nC pkΣk2\nP Z 2 ≥ 4 1  = P\n(η) 2\n\n\u0012\n\nZ4 ≥\n\nC4 p2 kΣk22\n(η)\n\n\u0013\n\n≤\n\n(η)E(Z 4 )\nC4 p2 kΣk22\n\n– Now, E(Z 4 ) ≤ p2 maxi E(zi4 ) ≤ C4 p2 kΣk22 . Plugging this in the above, we have\nthat P (x ∈ B ∗ |x ∼ D) ≥ 1 − η.\n• Hence, we have that P (x ∈ B ∗ |x ∈u SD ) ≥ 1 − η − t2 .\n• Using Lemma 15, we have that at least (1 − η − t2 ) fraction of good points are r1∗ + r2∗\naway from a. Hence, we have that the minimum radius of the ball containing all the\n(1 − η − t2 )(1 − η) has a radius of atmost r1∗ + r2∗ , which when combined with the triangle\ninequality recovers the statement of lemma.\ne µe =\nAs before, let Se be the set of points after outlier filtering. Let µSe = mean(S),\nSD\nmean(SeD ), µ e = mean(SeN ).\nSN\n\nLemma 17. Let SeD be the set of clean points remaining after the outlier filtering. Then, with\nprobability at least 1 − δ, we have that\nr\n\u0012\n\u0013\n1\np\np\n3p\nlog(p/δ)\n1\n4\nkµSeD − µk2 ≤ C1 C4 (η + t2 ) 4 kΣk2 1 +\nlog(p/δ)\n+ kΣk2 (1 + 2(η + t2 )\nn\nn\n(r ∗ + 2r2∗ )\nlog(p/δ)\n+ C15 1\nn\n43\n\n\fand\nkΣSeD k2 ≤ β(n, δ)kΣk2 ,\nwhere\nβ(n, δ) =\n\n!!\n√\n\u0013 r\n3\n3\np C4 p\nlog(p/δ log(p/δ)\n+\n1 + 2C(η + t2 ) + 1 + √ + C4 p(η + t) 2 + (η + t2 ) 2\nη\nn\nn\n\u0012\n\nProof. We first prove the bounds on the mean shift.\nkµSeD − µk2 ≤ kµSeD − µDe k2 + kµDe − µk2\n{z\n} | {z }\n|\nB\n\nA\n\nµ −µ\n\n• Control of B. We use Lemma 9 on X = xT kµ De−µk2 for x ∼ D, and A be the event\ne\nD\nthat x is not removed by the outlier filtering.\n1\n\n3\n\nkµDe − µk2 ≤ C1 C44 (η + t2 ) 4\n\np\n\nkΣk2\n\n(80)\n\n• Control of A. Using Lemma 10,we have that kΣDe k2 ≤ (1 + 2(η + t2 ))kΣk2 . Now, we\nuse Bernstein’s inequality . Lemma 12 with R = C(r1∗ + 2r2∗ + B), we get that, with\nprobability at least 1 − δ,\nr\np\np\n(r ∗ + 2r2∗ + B)\n1\nlog(p/δ) + C15 1\nlog(p/δ)\nkµSeD − µDe k2 ≤ C14 kΣk2 (1 + 2(η + t2 )\nn\nn\n(81)\nNext, we prove the bound for covariance matrix.\nkΣDe − Σk2\n|\n{z\n}\n\nkΣSeD k2 ≤ kΣSeD − ΣDe k2 +\n\n+kΣk2\n\n(82)\n\n≤2C(η+t2 )kΣk2 (By Corollary 13))\n(x −µ )(x −µ )T −Σ\n\ne\nD\n. From,\nTo control kΣSeD −ΣDe k2 , we use Bernstein’s inequality, with Zk = k De kn De\nLemma 16, we know that the points are constrained in a ball. Plugging this into Lemma 12,\n!\nr\nlog(p/δ log(p/δ)\n2\nkΣSeD − ΣDe k2 ≤ C(kΣk2 + R )\n+\nn\nn\n\n\u0011\n\u0010 2\n2\nwhere R2 = C r1∗ + r2∗ + B 2 .\n\nPlugging in the values, we get that,\n\nkΣSeD − ΣDe k2 ≤ CkΣk2\n\n\u0012\n\n!\n√\n\u0013 r\n3\n3\np C4 p\nlog(p/δ log(p/δ)\n1 + √ + C4 p(η + t) 2 + (η + t2 ) 2\n+\nη\nn\nn\n\nFinally, we have that,\n!!\n√\n\u0013 r\n3\n3\nlog(p/δ log(p/δ)\np C4 p\n+\nkΣSeD k2 ≤ kΣk2 1 + 2C(η + t2 ) + 1 + √ + C4 p(η + t) 2 + (η + t2 ) 2\nη\nn\nn\n|\n{z\n}\n\u0012\n\nβ(n,δ)\n\n44\n\n\fLemma 18. Let W be the bottom p/2 principal components of the covariance matrix after\nfiltering ΣSe. Then there exists a universal constant C > 0 such that with probability at least\n1 − δ, we have that\n\u0012\n\u0013\n1\n2\n2\nkηPW δµ k2 ≤ Cη β(n, δ) + γ(n, δ)C4 )kΣk2 ,\nwhere δµ = µSeN − µSeD , PW is the projection matrix on the bottom p/2-span of ΣSe, β(n, δ)\n\u0010 1\n\u0011\nis as defined in Lemma 17 and γ(n, δ) = η 2 + (η + t)5/2 + η(η + t) log(1/δ)\nn\n\nProof. We have\n\nΣSe = (1 − η)ΣSeD + ηΣSeN + (η − η 2 )δµ δµT\n{z\n} |\n{z\n}\n|\nE\n\n(83)\n\nF\n\n(84)\n\nBy Weyl’s inequality we have that,\nλp/2 (ΣSe) ≤ λ1 (E) + λp/2 (F )\n• Control of λp/2 (F ).\ntr (F )\np/2\n((r ∗ )2 + (r2∗ )2 ) + B 2\n≤ C15 η 1\np/2\n\u0013\n\u0012\n1\n1\nlog(1/δ)\n5/2\n2\n≤ C16 C4 kΣk2 η 2 + (η + t) + η(η + t)\nn\n|\n{z\n}\n\nλp/2 (F ) ≤\n\nγ(n,δ)\n\nwhere t = C8\n\nq\n\n1\nn\n\nlog\n\n• Control of λ1 (E).\n\nnp \u0001\nδ .\n\nλ1 (E) ≤ (1 − η)βkΣk2\nHence, we have that:\nλp/2 (ΣSe) ≤ (1 − η)βkΣk2 + C16 γ\n\np\n\nC4 kΣk2\n\nUsing that W is the space spanned by the bottom p/2 eigenvectors of ΣSe and PW is corresponding projection operator, we have that:\nh\np i\nT\nPW\nΣSePW \u0016 (1 − η)β + C16 γ C4 kΣk2 Ip\nFollowing some algebraic manipulation in [29], we get that,\n\u0012\n\u0013\n1\n2\n2\nkηPW δµ k2 ≤ η (β(n, δ) + γC4 )kΣk2\n\n45\n\n\fHaving established all required results, we are now ready to prove Lemma 1. We restate\nthe result for the sake of completeness.\nTheorem 14. Suppose that, Pθ∗ is a distribution on Rp with mean µ, covariance Σ and\nbounded fourth moments. There exist positive universal constant C > 0, such that given n\nsamples from the distribution in Equation (4), the algorithm with probability at least 1 − δ,\nreturns an estimate µ\nb such that,\n\n!1 \nr\n1\n1\n1\np\n3\nlog p log(p log(p/δ)) 2 \n√\n√\n2\n4\n2\n\n4\nkb\nµ − µk2 ≤ CkΣk2 (1 + log p)\nη + C4 (η + t2 ) +\nηpC4\nn\nwhere η = ǫ +\n\nq\n\nlog(p) log(log p/δ)\n2n\n\nand t2 =\n\nq\n\np log(p) log(n/(pδ))\n.\nn\n\nProof. We divide n samples into ⌊log(p)⌋ different sets. We choose the first set and keep that as\nour active set of samples. We run our outlier filtering on this set, and let the remaining samples\nafter the outlier filtering be SeD . By orthogonality of subspaces spanned by eigenvectors,\ncoupled with triangle inequality and contraction of projection operators, we have that\nµV − PV µk22\nkb\nµ − µk22 ≤ 2kPW (b\nµ − µSeD )k22 + 2kPW (µSeD − µ)k22 + kb\nµV − PV µk22\nkb\nµ − µk22 ≤ 2kPW (b\nµ − µSeD )k22 + 2k(µSeD − µ)k22 + kb\nbV is the mean vector\nwhere V is the span of the top p/2 principal components of ΣSe and where µ\nof returned by the running the algorithm on the reduced dimensions dim(V ) = p/2. From\nLemma 18, both β(n, δ) and γ(n, δ) are monotonically increasing in the dimension; moreover\nthe upper bound in Lemma 17 is also monotonically increasing in the dimension p, hence, the\nerror at each step of the algorithm can be upper bounded by error incurred when running on\ndimension p, with n/ log(p) samples, and probability of δ/ log p. Hence, the overall error for\nthe recursive algorithm can be upper bounded as,\n\u0011\n\u0010\nkb\nµ − µk22 ≤ 2kPW (b\nµ − µSeD )k22 + 2kµSeD − µk22 (1 + log p)\nCombining Lemma 17 and Lemma 18 which are instantiated for n/ log p samples and\nprobability δ/ log p, we get,\n\n!1 \nr\n2\n1p\n1\n1\n3\nlog\np\nlog(p\nlog(p/δ))\n√\n√\n\nkb\nµ − µk2 ≤ CkΣk22 log p  η + C44 (η + t2 ) 4 +\nηpC42\nn\n\n46\n\n\f",
         "train",
         "104947",
         "20227"
        ],
        [
         "45",
         "17923",
         "cs.AI",
         "Artificial Intelligence",
         "1711.04564v1.pdf",
         "Phonemic and Graphemic Multilingual CTC Based Speech Recognition\nMarkus Müller1 , Sebastian Stüker1 , Alex Waibel1,2\n1\n\nInteractive Systems Lab, Institute for Anthropomatics and Robotics\nKarlsruhe Institute of Technology, Karlsruhe, Germany\n2\nCarnegie Mellon University, Pittsburgh PA, USA\n\narXiv:1711.04564v1 [eess.AS] 13 Nov 2017\n\nm.mueller@kit.edu\n\nAbstract\nTraining automatic speech recognition (ASR) systems requires large amounts of data in the target language in order\nto achieve good performance. Whereas large training corpora\nare readily available for languages like English, there exists\na long tail of languages which do suffer from a lack of resources. One method to handle data sparsity is to use data\nfrom additional source languages and build a multilingual\nsystem. Recently, ASR systems based on recurrent neural\nnetworks (RNNs) trained with connectionist temporal classification (CTC) have gained substantial research interest. In\nthis work, we extended our previous approach towards training CTC-based systems multilingually. Our systems feature\na global phone set, based on the joint phone sets of each\nsource language. We evaluated the use of different language\ncombinations as well as the addition of Language Feature\nVectors (LFVs). As contrastive experiment, we built systems based on graphemes as well. Systems having a multilingual phone set are known to suffer in performance compared to their monolingual counterparts. With our proposed\napproach, we could reduce the gap between these mono- and\nmultilingual setups, using either graphemes or phonemes.\n\n1. Introduction\nAutomatic speech recognition systems have matured dramatically in recent years, lately with reported recognition accuracies similar to those of humans on certain tasks [1, 2]. A\nlarge amount of carefully prepared training data is required to\nachieve this level of performance. While such data is available for well-researched and -resourced languages like English, there exists a long tail of languages for which such\ntraining material does not exist. Various methods have been\nproposed to handle data sparsity. In this work, we focus on\nmultilingual systems: A common approach is to incorporate\ndata from supplementary source languages in addition to data\nfrom the target language.\nLately, systems based on RNNs trained with connectionist temporal classification (CTC) [3] have become popular.\nIn this work we focus on building multilingual RNN/CTC\nsystems, instead of systems based on either GMM/HMM\nor DNN/HMM, with the goal of applying them in a multilingual manner and are planning crosslingual experiments in\n\nthe future. For this future crosslingual case, the multilingual\nRNN acts as a network that can be adapted to multiple languages for which only very little adaptation data is available.\nIn the multilingual scenario of this paper, we have one multilingual model that is able to recognize speech from multiple\nlanguages simultaneously, while for all languages a comparatively large amount of training data is available. This is particular useful in environments with fast language changes.\nRecently, we demonstrated the use of a second language\nin addition to the target language when building a phoneme\nbased CTC system [4]. We now extend this approach by using data from up to 4 languages (English, French, German\nand Turkish). Building systems using phones as acoustic\nmodeling unit requires a pronunciation dictionary. But, creating these dictionaries is a time-consuming, resource intense\nprocess and often a bottle-neck when building speech recognition systems for new languages. While automatic methods to create pronunciations for new words given an existing\ndictionary exist [5, 6], such approaches are based on an existing seed dictionary. Using graphemes as acoustic modeling units, instead has the advantage of loosing the need\nfor a pronunciation dictionary at the cost that graphemes\nmight not always be a good modeling unit, depending on\nthe grapheme-to-phoneme relation of the target language.\n[7, 8, 9] This is particularly challenging in a multilingual setting, because different languages, although they might share\nthe same writing system, do feature different pronunciation\nrules [10, 11, 12].\nThis paper is organized as follows: Next, in Section (2),\nwe provide an overview of related work in the field. In Section 3, we describe our proposed approach, followed by the\nexperimental setup in Section 4. The results are presented in\nSection 5. This paper concludes with Section 6, where we\nalso provide an outlook to future work.\n\n2. Related Work\n2.1. Multi- and Crosslingual Speech Recognition Systems\nUsing GMM/HMM based systems was considered state of\nthe art prior to the emergence of systems with neural networks. Data sparsity has been addressed in the past, by\n\n\ftraining systems multi- and crosslingually [13, 14]. Methods for crosslingual adaptation exist [15], but also methods\nfor adapting the cluster tree were proposed [16]. Traditional\nsystems typically use context-dependent phones. When\ntrained multi- or crosslingually, the clustering of phones into\ncontext-dependent phones needs to be adapted [17].\nBut when using an RNN, the system is trained on\ncontext-independent targets, so that in the multilingual case\nthis kind of adaptation is unnecessary, as the network learns\nthe context-dependency during training.\n2.2. Multilingual Bottleneck Features\nDeep Neural Networks (DNNs) are a data-driven method\nwith many parameters to be trained, failing to generalize\nif trained on only a limited data set. Different methods\nhave been proposed to train networks on data from multiple source languages. Training DNNs typically involves a\npre-training and a fine-tuning step. It has been shown, that\nthe pre-training is language independent [18]. Several approaches exist to fine-tune a network using data from multiple languages. One method is to share hidden layers between languages, but to use language specific output layers\n[19, 20, 21, 22]. Combining language specific output layers into one layer is also possible [23]. By dividing the output layer into language specific blocks, the setup uses language dependent phone sets. Training DNNs simultaneously\non data from multiple languages on the other hand can then\nbe considered a form of multi-task learning [24, 25].\n\nGiven enough training data, even training on whole words is\npossible [34]. Multi-task learning has also been proposed\n[35, 36, 37]. CTC based systems are able to outperform\nHMM based setups on certain tasks [38].\n\n3. Language Adaptive Multilingual CTC\nBased Systems\nTraditional speech recognition systems typically rely on a\npronunciation dictionary which maps words to phone sequences. It is also possible to train systems on graphemes\nas acoustic units, but this affects the performance depending on the language. While there are languages with a close\nmapping between letters and sounds, e.g., Spanish, this does\nnot hold for every language. Pronunciation rules are quite\ncomplex, with groups of characters being mapped to different sounds based on their context. An example of such complex mappings would be English. The string “ough” has 8\ndifferent acoustic realizations, depending on the context, as\nin, e.g., “rough”, “ought” or “through”.\n3.1. Multilingual Systems\n\nBy supplying additional input features, neural networks can\nbe adapted to various conditions. One of the most common\nmethods is to adapt neural nets to different speakers by providing a low dimensional code representing speaker characteristics. These so called i-Vectors [26] allow to train speaker\nadaptive neural networks [27]. An alternative method for\nadaptation are Bottleneck Speaker Vectors (BSVs) [28].\nSimilar to BSVs, we proposed an adaptation method for\nadapting neural networks to different languages when trained\non multiple languages. We first proposed using the language\nidentity information via one-hot encoding [29]. One of the\nshortcomings of this approach is that it does not supply language characteristics to the network. To address this issue, we proposed Language Feature Vectors (LFVs) [30, 31]\nwhich have shown to encode language properties, even if the\nLFV net was not trained on the target language.\n\nSpeech recognition systems are typically built to recognize\nspeech of a single language. Training traditional systems\nmultilingually involves a hybrid DNN/HMM setup where the\nhidden layers of the DNN are shared between languages and\nthe output layers are kept language dependent. Such systems can be seen as individual, language dependent systems,\ntrained jointly. Training language universal systems using\na global phones set is possible, however HMM based systems do not generalize well when being trained on multiple languages. In this work, we propose an approach using\nRNN based systems trained using CTC on data from multiple languages, with a global set of units modeling the acoustics (graphemes or phones). The main advantage of such a\nsystem is the ability to recognize speech from multiple languages simultaneously, without knowledge of the input language’s identity.\nIn the past, we proposed a setup for training CTC-based\nsystems multilingually using a universal phone set [4]. In\nthis work, we extended our previous work in three ways: 1)\nwe increased the number of languages used 2) we used multilingually trained bottleneck features (BNFs) 3) in addition\nto phones, we evaluated the use of graphemes. In the past,\nwe demonstrated the use of LFVs using DNN/HMM-based\nsystems for multilingual speech recognition. We now apply\nthis technique to CTC-based speech recognition.\n\n2.4. CTC Based ASR Systems\n\n3.2. Language Feature Vectors\n\nRecently, RNN-based systems trained using the CTC loss\nfunction [3] have become popular. Similar to traditional ASR\nsystems, CTC based ones are trained using either phones,\ngraphemes, or both [32]. Training on units larger than characters is also possible [33]. This method, called Byte Pair\nEncoding (BPE), derives larger units based on the transcripts.\n\nLFVs are a low dimensional representation of language properties, extracted using a neural network. The setup consisted\nof two networks, Figure 1 shows the network architecture.\nThe first network was used to extract BNFs from acoustic\ninput features. It was trained using a combination of lMel\nand tonal features as input and phone states as targets. The\n\n2.3. Neural Network Adaptation\n\n\fsecond network was trained for language identification using\nBNFs as input features. In contrast to networks trained for\nspeech recognition, we used a much larger input context because of the language information being long-term in nature.\nThis network was trained to detect languages and featured a\nbottleneck layer, which was used to extract the LFVs after\ntraining.\n3.3. Input Features\nUsing BNFs as input features is common for traditional\nspeech recognition systems. By forcing the information\nto pass through a bottleneck, the network creates a lowdimensional representation of features relevant to discriminate between phones. DNN/HMM or GMM/HMM based\nsystems benefit from using such features over plain features\nlike, e.g., MFCCs. We evaluated training our CTC systems\non multilingual BNFs.\n\nplying all filtering steps, approximately 50h of data per language was available. We split the available data on a speaker\nbasis into a 45h training and 5h test set.\n4.2. Acoustic Units\nWe conducted experiments using both phones and graphemes\nas acoustic units. As graphemes we used the provided transcripts, while we used MaryTTS [45] to generate a pronunciation dictionary automatically to map words to phones. In\naddition, we included a marker to indicate word boundaries.\n4.3. Input Features\n\nWe built our systems using a framework based on PyTorch\n[40], as well as warp-ctc [41] for computing the CTC loss\nduring network training. To extract acoustic features from\nthe data, we used the Janus Recognition Toolkit (JRTk) [42],\nwhich features the IBIS single-pass decoder [43].\n\nAs input features, we used log Mel and tonal features (FFV\n[46] and pitch [47]), extracted using a 32ms window with\na 10ms frame-shift. We included tonal features as part of\nour standard pre-processing pipeline because previous experiments showed a reduction in the word error rate (WER) of\nspeech recognition systems, even if the language is not tonal\n[48].\nBased on these features, we trained a network for extracting multilingual bottleneck features (BNFs). The network featured 5 feed-forward layers, with 1,000 neurons per\nlayer, with the second last layer being the bottleneck with\nonly 42 neurons. The acoustic features were fed with a context of +/− 6 frames into the network. While the hidden\nlayers were shared between languages, we used language dependent output layers. 6,000 context-dependent phone states\nwere used as targets, with data from 5 languages (French,\nGerman, Italian, Russian, Turkish). To obtain phone state\nlabels, DNN/HMM systems for each language were trained.\nAfter training, all layers after the bottleneck were discarded\nand the output activations of this layer were taken as BNFs.\n\n4.1. Dataset\n\n4.4. LFV Network Training\n\nWe conducted our experiments using data from the Euronews\nCorpus [44], a dataset containing recordings of TV broadcast\nnews from 10 different languages (Arabic, English, French,\nGerman, Italian, Polish, Portuguese, Russian, Spanish, Turkish), with orthographic transcripts at utterance level. The advantage of this dataset is that the channel conditions do not\ndiffer between languages, ensuring that we are adapting our\nsystems to different languages instead of different channel\nconditions, like, e.g., different environmental noises present\nin different languages. We filtered the available data, retaining only utterances with a length of at least 1s and a transcript\nlength of at most 639 symbols, because of an internal limitation within CUDA1 .\nNoises were annotated in a very basic way, consisting\nof only one generic noise marker covering both human and\nnon-human noises. With noises accounting for a quite large\namount of utterances, we only selected a small subset of them\nto account for a more balanced set of training data. After ap-\n\nTraining the network for the extraction of LFVs is a two step\nprocess. First, BNFs are being trained (see Section 4.3), and\nthen based on these BNFs, a second network is trained to\nrecognize the language. This network features 6 layers with\n1,600 neurons per layer, except for the bottleneck layer with\nonly 42 neurons. In contrast to networks trained for speech\nrecognition, this network featured a large context spanning\n+/− 33 frames. To reduce the dimensionality of the input,\nonly every third frame was taken. For training this network,\nwe used data from 9 languages( all available languages in the\ncorpus except English).\n\n3.4. Network Architecture\nThe network architecture chosen was based on Baidu’s Deepspeech2 [39]. As shown in Figure 2, the network consists of\ntwo TDNN / CNN layers. We add LFVs to the output of\nthe second TDNN / CNN layer as input to the bi-directional\nLSTM layers. We use a feed-forward output layer to map the\noutput of the last LSTM layer to the targets.\n\n4. Experimental Setup\n\n1 see:\n\nhttps://github.com/baidu-research/warp-ctc, accessed 2017-10-09\n\n4.5. CTC RNN Network Training\nThe RNN network was trained using either log Mel / tonal\nfeatures or BNFs. As targets, we used both graphemes\nand phonemes as acoustic units, with an additional symbol\nadded for separating words. The networks were trained using\nstochastic gradient descent (SGD) with Nesterov momentum\n[49] of 0.9 and a learning rate of 0.0003. Mini-batch updates\n\n\fAF stack\n\nLFV\n\nBNF stack\n\nBNF\n\nLanguage Feature Network\nFigure 1: Overview of the network architecture used to extract language feature vectors (LFV). The acoustic features (AF) are\nbeing pre-processed in a DBNF in order to extract BNFs. These BNFs are being stacked and fed into the second network to\nextract LFVs.\nobtained with it should indicate whether the improvements in\nTER of the pure CTC model measured on English also lead\nto a better word level speech recognition system.\n\nLFV\n\n5. Results\nWe first evaluated using multilingual BNFs over plain log\nMel / tone features. Next, we used multilingual BNFs to\ntrain systems using a combination of 4 languages (English,\nFrench, German, Turkish).\n2D Convolution\nLayers\n\nBi-directional LSTM Layers\n\nOutput\nLayer\n\nFigure 2: Network layout, based on Baidu’s Deepspeech2\n[39]. LFVs are being added after the final convolution layer.\nwith a batch size of 20 and batch normalization were used.\nDuring the first epoch, the network was trained with utterances sorted ascending by length to stabilize the training, as\nshorter utterances are easier to align.\n\n5.1. Multilingual BNFs\nFirst, we evaluated the use of multilingually trained BNFs as\ninput features. To assess the performance, we trained systems for English and German monolingually on all available\ndata. The results are shown in Table 1. The gain by the addition of BNFs is larger for German which can be explained by\nGerman being among the languages the BNF net was trained\non (see Section 4.3). But the BNFs also show an improvement for English, although they did not see this language\nduring training.\n\n4.6. Evaluation\n\nCondition\n\nTo evaluate our setup, we used the same decoding procedure\nas in [3] and greedily search the best path without an external\nlanguage model and evaluated our systems by computing the\ntoken error rate (TER) as primary measure. In addition, we\ntrained a character based neural network language model for\nEnglish on the training utterances, as described in [50], so\nthat for the recognition of English we could also measure\na word error rate (WER) by decoding the network outputs\nwith this language model. As the language model is only\ntrained on only a small amount of data, the word error rate\n\nlog Mel + Tone\nML BNF\n\nEnglish TER\n\nGerman TER\n\n13.0%\n10.2%\n\n10.8%\n7.8%\n\nTable 1: Comparison of using ML-BNFs over log Mel + tone\nfeatures\n\n5.2. Multilingual Phoneme Based Systems\nNext, we evaluated the performance using 4 languages (English, French, German, Turkish). We evaluated adding the\n\n\fLFVs after the TDNN / CNN layers. As baseline, we did\nnot apply our language adaptation technique and used only\nmultilingual BNFs. As shown in Table 2, adding LFVs after\nthe TDNN / CNN layer shows improvements over the baseline. The relative improvements vary and while the language\nadapted systems are not en par with the monolingual ones,\nthe adaptation does decrease the gap between the multi- and\nmonolingual setup.\nCondition\n\nDE\n\nEN\n\nFR\n\nTR\n\nMonolingual\n\n7.8%\n\n10.2%\n\n8.3%\n\n7.1%\n\nML\nML + LFV\n\n9.9%\n8.9%\n\n14.1%\n12.9%\n\n12.8%\n10.7%\n\n8.4%\n7.6%\n\nTable 2: Term Error Rate (TER) of multilingual (ML)\nphoneme CTC based systems, trained on 4 languages.\n\n5.3. Multilingual Grapheme Based Systems\nIn addition to using phones, we also evaluated the performance using only the transcripts, without a pronunciation\ndictionary. As shown in Table 3, using LFVs improves\nthe performance in this condition as well. For English and\nFrench, the TER is higher compared to their phoneme counterpart, whereas lower TERs could be observed for both German and Turkish. One explanation could be that English\nand French feature more complex pronunciation rules that\nare better reflected by MaryTTS’ language definitions. The\ngenerated pronunciations for German and Turkish appear to\nworsen the performance. The RNN seems to capture the letter to sound rules for these languages better.\nCondition\n\nDE\n\nEN\n\nFR\n\nTR\n\nMonolingual\n\n7.5%\n\n12.9%\n\n11.5%\n\n6.6%\n\nML\nML + LFV\n\n9.1%\n7.9%\n\n15.6%\n14.3%\n\n13.4%\n12.5%\n\n7.9%\n7.3%\n\nTable 3: Term Error Rate (TER) of multilingual (ML)\ngrapheme CTC based systems, trained on 4 languages.\nFor English, we also trained a basic character based language model to decode the network output and compute the\nWER. As shown in Table 4, similar improvements can be\nobserved by adding LFVs.\nCondition\n\nMono\n\nML\n\nML + LFV\n\nEnglish\n\n25.2%\n\n30.8%\n\n28.1%\n\nTable 4: Word Error Rate (WER) of English phoneme CTC\nbased systems. Adding LFVs improves the multilingual performance.\n\n6. Conclusion\nWe have presented an approach to adapt recurrent neural networks to multiple languages. Using multilingual BNFs improved the performance, as well as providing LFVs for language adaptation. These language adaptive networks are able\nto capture language specific peculiarities in a multilingual\nsetup which results in an increased performance. Such multilingual systems are able to recognize speech from multiple\nlanguages simultaneously.\nFuture work includes the use of different language\ncombinations and working towards cross-lingual knowledge\ntransfer. We aim at further closing the gap between monoand multilingual systems using additional adaptation techniques.\n\n7. References\n[1] W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer,\nA. Stolcke, D. Yu, and G. Zweig, “Achieving Human\nParity in Conversational Speech Recognition,” arXiv\npreprint arXiv:1610.05256, 2016.\n[2] ——, “The microsoft 2016 conversational speech\nrecognition system,” in Acoustics, Speech and Signal\nProcessing (ICASSP), 2017 IEEE International Conference on. IEEE, 2017, pp. 5255–5259.\n[3] A. Graves, S. Fernández, F. Gomez, and J. Schmidhuber, “Connectionist temporal classification: labelling\nunsegmented sequence data with recurrent neural networks,” in Proceedings of the 23rd international conference on Machine learning. ACM, 2006, pp. 369–\n376.\n[4] M. Müller, S. Stüker, and A. Waibel, “Multilingual ctc\nspeech recognition,” in SPECOM, 2017.\n[5] M. Bisani and H. Ney, “Joint-sequence models for\ngrapheme-to-phoneme conversion,” Speech communication, vol. 50, no. 5, pp. 434–451, 2008.\n[6] J. R. Novak, D. Yang, N. Minematsu, and K. Hirose,\n“Phonetisaurus: A wfst-driven phoneticizer,” The University of Tokyo, Tokyo Institute of Technology, pp. 221–\n222, 2011.\n[7] C. Schillo, G. A. Fink, and F. Kummert, “Grapheme\nbased speech recognition for large vocabularies,” in\nProceedings of the Sixth International Conference on\nSpoken Language Processing (ICSLP 2000). Beijing,\nChina: ISCA, October 2000, pp. 584–587.\n[8] S. Kanthak and H. Ney, “Context-dependent acoustic\nmodeling using graphemes for large vocabulary speech\nrecognition,” in Proceedings the 2002 IEEE International Conference on Acoustics, Speech, and Signal\nProcessing (ICASSP’02), vol. 1.\nOrlando, Florida,\nUSA: IEEE, 2002, pp. 845–848.\n\n\f[9] M. Killer, S. Stüker, and T. Schultz, “Grapheme based\nspeech recognition,” in Proceedings of the 8th European Conference on Speech Communication and Technology EUROSPEECH’03.\nGeneva, Switzerland:\nISCA, September 2003, pp. 3141–3144.\n[10] S. Kanthak and H. Ney, “Multilingual acoustic modeling using graphems,” in Proceedings of the 8th European Conference on Speech Communication and Technology EUROSPEECH’03.\nGeneva, Switzerland:\nISCA, September 2003, pp. 1145–1148.\n[11] S. Stüker, “Modified polyphone decision tree specialization for porting multilingual grapheme based asr systems to new languages,” in Proceedings of the 2008\nIEEE International Conference on Acoustics, Speech,\nand Signal Processing. Las Vegas, NV, USA: IEEE,\nApril 2008, pp. 4249–4252.\n[12] ——, “Integrating thai grapheme based acoustic models into the ml-mix framework - for language independent and cross-language asr,” in Proceedings of\nthe First International Workshop on Spoken Languages\nTechnologies for Under-resourced languages (SLTU),\nHanoi, Vietnam, May 2008.\n[13] B. Wheatley, K. Kondo, W. Anderson, and\nY. Muthusamy, “An evaluation of cross-language\nadaptation for rapid hmm development in a new\nlanguage,” in Acoustics, Speech, and Signal Processing, 1994. ICASSP-94., 1994 IEEE International\nConference on, vol. 1. IEEE, 1994, pp. I–237.\n[14] T. Schultz and A. Waibel, “Fast bootstrapping of\nlvcsr systems with multilingual phoneme sets.” in Eurospeech, 1997.\n[15] S. Stüker, “Acoustic modelling for under-resourced languages,” Ph.D. dissertation, Karlsruhe, Univ., Diss.,\n2009, 2009.\n[16] T. Schultz and A. Waibel, “Language-independent and\nlanguage-adaptive acoustic modeling for speech recognition,” Speech Communication, vol. 35, no. 1, pp. 31–\n51, 2001.\n[17] ——, “Polyphone decision tree specialization for language adaptation,” in Acoustics, Speech, and Signal Processing, 2000. ICASSP’00. Proceedings. 2000\nIEEE International Conference on, vol. 3. IEEE, 2000,\npp. 1707–1710.\n\n[20] S. Scanzio, P. Laface, L. Fissore, R. Gemello, and\nF. Mana, “On the use of a multilingual neural network\nfront-end,” in Proceedings of the Interspeech, 2008, pp.\n2711–2714.\n[21] G. Heigold, V. Vanhoucke, A. Senior, P. Nguyen,\nM. Ranzato, M. Devin, and J. Dean, “Multilingual\nAcoustic Models Using Distributed Deep Neural Networks,” in Proceedings of the ICASSP, Vancouver,\nCanada, May 2013.\n[22] K. Vesely, M. Karafiat, F. Grezl, M. Janda, and\nE. Egorova, “The language-independent bottleneck features,” in Proceedings of the Spoken Language Technology Workshop (SLT), 2012 IEEE. IEEE, 2012, pp.\n336–341.\n[23] F. Grézl, M. Karafiát, and K. Vesely, “Adaptation of\nmultilingual stacked bottle-neck neural network structure for new language,” in Acoustics, Speech and Signal\nProcessing (ICASSP), 2014 IEEE International Conference on. IEEE, 2014, pp. 7654–7658.\n[24] R. Caruana, “Multitask learning,” Machine learning,\nvol. 28, no. 1, pp. 41–75, 1997.\n[25] A. Mohan and R. Rose, “Multi-lingual speech recognition with low-rank multi-task deep neural networks,”\nin Acoustics, Speech and Signal Processing (ICASSP),\n2015 IEEE International Conference on. IEEE, 2015,\npp. 4994–4998.\n[26] G. Saon, H. Soltau, D. Nahamoo, and M. Picheny,\n“Speaker Adaptation of Neural Network Acoustic\nModels Using i-Vectors,” in ASRU. IEEE, 2013, pp.\n55–59.\n[27] Y. Miao, H. Zhang, and F. Metze, “Towards Speaker\nAdaptive Training of Deep Neural Network Acoustic\nModels,” 2014.\n[28] H. Huang and K. C. Sim, “An Investigation of Augmenting Speaker Representations to Improve Speaker\nNormalisation for DNN-based Speech Recognition,” in\nICASSP. IEEE, 2015, pp. 4610–4613.\n[29] M. Müller and A. Waibel, “Using Language Adaptive Deep Neural Networks for Improved Multilingual\nSpeech Recognition,” IWSLT, 2015.\n\n[18] P. Swietojanski, A. Ghoshal, and S. Renals, “Unsupervised cross-lingual knowledge transfer in DNN-based\nLVCSR,” in SLT, IEEE. IEEE, 2012, pp. 246–251.\n\n[30] M. Müller, S. Stüker, and A. Waibel, “Language Adaptive DNNs for Improved Low Resource Speech Recognition,” in Interspeech, 2016.\n\n[19] A. Ghoshal, P. Swietojanski, and S. Renals, “Multilingual training of Deep-Neural networks,” in Proceedings\nof the ICASSP, Vancouver, Canada, 2013.\n\n[31] ——, “Language Feature Vectors for Resource Constraint Speech Recognition,” in Speech Communication; 12. ITG Symposium; Proceedings of. VDE, 2016.\n\n\f[32] D. Chen, B. Mak, C.-C. Leung, and S. Sivadas,\n“Joint acoustic modeling of triphones and trigraphemes\nby multi-task learning deep neural networks for lowresource speech recognition,” in Acoustics, Speech and\nSignal Processing (ICASSP), 2014 IEEE International\nConference on. IEEE, 2014, pp. 5592–5596.\n[33] R. Sennrich, B. Haddow, and A. Birch, “Neural machine translation of rare words with subword units,”\narXiv preprint arXiv:1508.07909, 2015.\n[34] H. Soltau, H. Liao, and H. Sak, “Neural speech\nrecognizer: Acoustic-to-word lstm model for large\nvocabulary speech recognition,” arXiv preprint\narXiv:1610.09975, 2016.\n[35] S. Kim, T. Hori, and S. Watanabe, “Joint ctc-attention\nbased end-to-end speech recognition using multi-task\nlearning,” arXiv preprint arXiv:1609.06773, 2016.\n[36] L. Lu, L. Kong, C. Dyer, and N. A. Smith, “Multi-task\nlearning with ctc and segmental crf for speech recognition,” arXiv preprint arXiv:1702.06378, 2017.\n[37] H. Sak and K. Rao, “Multi-accent speech recognition\nwith hierarchical grapheme based models,” 2017.\n[38] Y. Miao, M. Gowayyed, X. Na, T. Ko, F. Metze, and\nA. Waibel, “An empirical exploration of ctc acoustic models,” in Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE International Conference on.\nIEEE, 2016, pp. 2623–2627.\n[39] D. Amodei, S. Ananthanarayanan, R. Anubhai, J. Bai,\nE. Battenberg, C. Case, J. Casper, B. Catanzaro,\nQ. Cheng, G. Chen, et al., “Deep speech 2: End-to-end\nspeech recognition in english and mandarin,” in International Conference on Machine Learning, 2016, pp.\n173–182.\n[40] “PyTorch,” http://pytorch.org, accessed: 2017-04-13.\n[41] “warp-ctc,” https://github.com/baidu-research/warpctc, accessed: 2017-04-13.\n[42] M. W. et al., “JANUS 93: Towards Spontaneous Speech\nTranslation,” in International Conference on Acoustics,\nSpeech, and Signal Processing 1994, Adelaide, Australia, 1994.\n[43] H. Soltau, F. Metze, C. Fugen, and A. Waibel, “A\nOne-Pass Decoder Based on Polymorphic Linguistic\nContext Assignment,” in Automatic Speech Recognition and Understanding, 2001. ASRU’01. IEEE Workshop on. IEEE, 2001, pp. 214–217.\n[44] R. Gretter, “Euronews: A Multilingual Benchmark\nfor ASR and LID,” in Fifteenth Annual Conference of\nthe International Speech Communication Association,\n2014.\n\n[45] M. Schröder and J. Trouvain, “The German text-tospeech synthesis system MARY: A tool for research,\ndevelopment and teaching,” International Journal of\nSpeech Technology, vol. 6, no. 4, pp. 365–377, 2003.\n[46] K. Laskowski, M. Heldner, and J. Edlund, “The Fundamental Frequency Variation Spectrum,” in Proceedings of the 21st Swedish Phonetics Conference (Fonetik\n2008), Gothenburg, Sweden, June 2008, pp. 29–32.\n[47] K. Schubert, “Grundfrequenzverfolgung und deren Anwendung in der Spracherkennung,” Master’s thesis,\nUniversität Karlsruhe (TH), Germany, 1999, in German.\n[48] F. Metze, Z. Sheikh, A. Waibel, J. Gehring, K. Kilgour, Q. B. Nguyen, V. H. Nguyen, et al., “Models\nof Tone for Tonal and Non-tonal Languages,” in Automatic Speech Recognition and Understanding (ASRU),\n2013 IEEE Workshop on. IEEE, 2013, pp. 261–266.\n[49] I. Sutskever, J. Martens, G. Dahl, and G. Hinton, “On\nthe importance of initialization and momentum in deep\nlearning,” in Proceedings of the 30th International\nConference on Machine Learning (ICML-13), 2013,\npp. 1139–1147.\n[50] T. Zenkel, R. Sanabria, F. Metze, J. Niehues, M. Sperber, S. Stüker, and A. Waibel, “Comparison of decoding strategies for ctc acoustic models,” arXiv preprint\narXiv:1708.04469, 2017.\n\n\f",
         "train",
         "30358",
         "4571"
        ],
        [
         "46",
         "18924",
         "cs.AI",
         "Artificial Intelligence",
         "1803.05049v1.pdf",
         "Fractal AI\nA Fragile Theory of Intelligence\nSergio Hernández Cerezo\nGuillem Duran Ballester\n\nFr{​AGI​}le\nBOOK #1\n“Forward Thinking”\nVersion: V1.0\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nMain researchers\nSergio Hernández Cerezo (​@EntropyFarmer​)\nGuillem Duran Ballester (​@Miau_DB​)\nReviewers\nEiso Kant (​@EisoKant​), CEO at ​source{d}\nJosé María Amigó García (​Elche University​)\nRoshawn Terrell (​@RoshawnTerrell​)\nJuan G. Cruz Ayoroa\nJesús P. Nieto (​@HedgeFair​)\nAidan Rocke (​@AidanRocke​)\nSpecial thanks\nResearchers’ families for suffering us in all the ‘eureka’ moments.\nHCSoft​ and ​Source{d}​ for their unconditional support.\n\n13 March 2018\n\n1\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nContents\n\n1 - Introduction\n\n5\n\n1.1 - The playground of intelligence\n\n5\n\n1.1.1 - Cart-pole example\n\n6\n\n1.1.2 - General strategy\n\n6\n\n1.1.2.1 - Forward vs Backward intelligence\n\n7\n\n1.1.2.2 - Scoring actions\n\n7\n\n2 - Fundamental concepts\n\n9\n\n2.1 - Causal Cones\n\n9\n\n2.1.1 - Causal Slices\n\n10\n\n2.1.2 - Conditional Causal Cones\n\n10\n\n2.2 - Reward function\n\n11\n\n2.2.1 - Dead vs Alive states\n\n11\n\n2.2.2 - Reward function properties\n\n12\n\n2.2.3 - Reward density over Causal Slices\n\n12\n\n2.3 - Policies: defining strategies\n\n12\n\n2.3.1 - Scanning policy\n\n13\n\n2.3.2 - Deciding policy\n\n13\n\n2.3.3 - Probability density due to policy over Causal Slices\n\n14\n\n2.4 - Divergence between distributions\n\n14\n\n3 - Defining Intelligence\n\n16\n\n3.1 - Scanning process\n\n16\n\n3.1.1 - Causal Slice divergence\n\n16\n\n3.1.2 - Intelligent Scanning\n\n16\n\n3.1.3 - Scanning sub-optimality coefficient\n\n17\n\n3.2 - Decision process\n\n18\n\n3.2.1 - Intelligent decision\n\n18\n\n3.2.2 - Decision sub-optimality coefficient\n\n19\n\n3.3 - Global sub-optimality\n\n19\n\n3.4 - Policy IQ\n\n19\n\n4 - Fractal AI algorithm\n\n20\n\n4.1 - Algorithm blueprints\n\n21\n\n4.1.1 - Starting at Monte Carlo\n\n21\n\n4.1.2 - Choosing the intelligence parameters\n\n22\n\n4.1.2.1 - Decisions per second\n\n22\n\n4.1.2.2 - Time horizon\n\n23\n\n4.1.1.3 - Number of walkers\n\n23\n\n4.1.3 - Simultaneous walks\n13 March 2018\n\n23\n2\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n4.1.4 - Probability densities\n\n25\n\n4.1.4.1 - Density of walkers\n\n25\n\n4.1.4.2 - Reward density\n\n26\n\n4.1.5 - Migratory flows\n\n27\n\n4.1.6 - Taking the decision\n\n29\n\n4.2 - The migratory process\n\n30\n\n4.2.1 - Virtual reward\n\n31\n\n4.2.2 - Simplifying the Virtual Reward\n\n32\n\n4.2.3 - Balancing exploitation and exploration\n\n34\n\n4.2.3.1 - The “Common Sense”\n\n35\n\n4.2.4 - Probability of cloning\n\n35\n\n4.3 - Pseudo-code\n\n36\n\n4.4 - Classifying the algorithm\n\n37\n\n4.4.1 - Monte Carlo Tree Search\n\n37\n\n4.4.2 - Swarm algorithm\n\n38\n\n4.4.3 - Evolutive algorithm\n\n38\n\n4.4.4 - Entropic algorithm\n\n39\n\n4.4.5 - Fractal algorithm\n\n39\n\n5 - Experiments\n\n40\n\n5.1 - Discrete case: Atari 2600 games\n\n40\n\n5.1.1 - RAM vs Images\n\n40\n\n5.1.2 - Results\n\n40\n\n5.1.2.1 - MCTS vs Fractal AI\n\n42\n\n5.1.2.2 - Human record vs Fractal AI\n\n42\n\n5.1.3 - Implementation details\n\n43\n\n5.1.3.1 - Auto-adjusting ‘Samples per step’\n\n43\n\n5.1.3.2 - Additional death condition\n\n43\n\n5.1.4 - Github repository\n\n44\n\n5.2 - Continuous case: Flying rocket\n\n44\n\n5.2.1 - Flying a chaotic attractor\n\n44\n\n5.2.2 - Results\n\n45\n\n5.2.3 - Implementation details\n\n46\n\n5.2.3.1 - Reward\n\n46\n\n5.2.3.2 - Distance\n\n47\n\n6 - Research topics\n\n48\n\n6.1 - Distributed computing\n\n48\n\n6.2 - Adding learning capabilities\n\n48\n\n6.2.1 - Using a DQN for learning\n\n50\n\n6.3 - Common Sense Assisted Control\n\n50\n\n6.4 - Consciousness\n\n50\n\n6.5 - Real-time decision-making\n\n51\n\n13 March 2018\n\n3\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n6.6 - Universality pattern\n\n51\n\n7 - Conclusions\n\n53\n\nBibliography\n\n54\n\nATARI experiment references\n\n13 March 2018\n\n55\n\n4\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n1 - Introduction\n“For instance, on the planet Earth, man had always assumed\nthat he was more intelligent than dolphins because he had\nachieved so much—the wheel, New York, wars and so\non—whilst all the dolphins had ever done was muck about in\nthe water having a good time. But conversely, the dolphins had\nalways believed that they were far more intelligent than\nman—for precisely the same reasons.”\nDouglas Adams​, ​The Hitchhiker's Guide to the Galaxy\nOne of the big obstacles in the field of artificial intelligence is not having a definition of\nintelligence based on solid mathematical and physical principles that could inspire the design\nand implementations of efficient intelligent algorithms.\nFor instance, consider the most widely accepted definition of intelligence, signed by 52\nspecialist on the field [2]:\n“​A very general mental capability that, among other things, involves the ability to reason, plan,\nsolve problems, think abstractly, comprehend complex ideas, learn quickly and learn from\nexperience. It is not merely book learning, a narrow academic skill, or test-taking smarts. Rather,\nit reflects a broader and deeper capability for comprehending our surroundings...​”\nA more recent definition [3] provided by Shane Legg, chief scientist of Deep Mind, and Marcus\nHutter, founder of AIXI, is the following:\n“Intelligence measures an agent’s ability to achieve goals in a wide range of environments.”\nAlthough there are many other definitions of intelligence, they are too fuzzy to help us develop\na theory of intelligent behaviour or give us an insight on how a general, computable and\nefficient algorithm for generating intelligent behaviour should look like.\nThis document is an effort to present such a definition based on entropic principles deeply\ninspired by the concept of “Causal Entropic Forces” introduced by Alexander Wissner-Gross in\n2013 [1] and to propose a generic implementation of those principles.\n\n1.1 - The playground of intelligence\n“The most difficult thing is the decision to act, the rest is merely\ntenacity. The fears are paper tigers. You can do anything you\n13 March 2018\n\n5\n\n\fFractal AI: A Fragile Theory of Intelligence\n\ndecide to do. You can act to change and control your life; and\nthe procedure, the process is its own reward”\nAmelia Earhat\nAs a first attempt in defining intelligence, we could say that intelligence works by taking\ndecisions that directly affect the degrees of freedom of a system in such a way that its future\nevolution is biased toward rewarding futures.\n\n1.1.1 - Cart-pole example\nLet's suppose we are controlling a cart-pole that can move left or right by pushing one of the\ntwo available buttons. Our goal is to keep the pole standing up, so the ball at the tip of the\ncart-pole must be as high as possible.\n\nIn that case, the intelligence can affect the system evolution by pressing one of the two buttons\nat any time. The ultimate goal of the intelligence is then to continuously choose the actions that\nkeeps the ball as high as possible.\nIn this example, the action-space is discrete, but it could also be continuous: instead of having\ntwo buttons to choose from, we may have a “joystick” we can push, so our available actions are\nreal numbers in the range [-1, 1]. The simulation of the system can also be more or less\ndeterministic, and the goals could be a combination of several sub-goals. None of this would\nchange the problem except that they would require more computation.\n\n1.1.2 - General strategy\nWhen the intelligence is asked to choose between a discrete set of actions {a​i​} it will internally\nscore them accordingly to some metrics and then output an “intelligent decision” as being the\naction with the highest score or, in the continuous case, the average of a number of actions\nweighted by their normalised scores.\nDecision = ∑(a​i​ * Score(a​i​)) / ∑(Score(a​i​))\n13 March 2018\n\n6\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n1.1.2.1 - Forward vs Backward intelligence\n“You can know the past, but not control it. You can control the\nfuture, but have not knowledge of it.”\nClaude Shannon\nThere are two main strategies used in an intelligent decision making process:\nOn one hand, we can use information from past events, along with the decisions that were\ntaken and their corresponding outcomes, and eventually learn from that information, to\ninfluence future decisions. We will refer to this as ‘backward-thinking’, as we will only base our\ndecisions on events from the past.\nSuch a backward-thinking process could in fact learn to predict the best action given an initial\nstate, but it could also learn to predict the next state of the system, as it has access to pairs of\ninitial states, actions, and final states. Predicting the final state from the initial one is equivalent\nto being able to internally simulate the system for relatively long periods by simulating one\nstate after the other in small jumps.\nAt some point, evolution began to develop agents that were able to project their actual state\ninto the future with relative accuracy. Enabling it to ponder about its available actions in terms\nnot only of its past experiences, but by predicting the foreseeable future each action leads to\nand its consequences.\nThis ‘forward-thinking’ process will make better decisions as the simulation gets better, as\nopposed to learning-based strategies of back-thinking that depend on the accumulation of past\nexperiences.\nBoth strategies are complementary. You need to learn how to simulate the system before you\ncan start thinking forward, while forward-thinking can be used to detect and develop better\ndecisions for situations where only repeating past strategies, is no longer viable.\nThis document will focus on forward-thinking, or the ability to make near-perfect intelligent\ndecisions based on a near-perfect simulation of the system without the need of any previous\nlearning. This is present in the human cognitive processes. But in contrast, is absent in current\nAI methods.\n\n1.1.2.2 - Scoring actions\n\n13 March 2018\n\n7\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n“No sensible decision can be made any longer without taking\ninto account not only the world as it is, but the world as it will\nbe.”\nIsaac Asimov\nSo what is the basic idea behind “scoring” an action? Imagine the cart holding the pole is in the\nsituation shown in the image:\n\nIf we push the cart to the right, the pole will fall and the red ball will be at the lowest possible\nposition, a single possible future state having a reward of zero. However, if we instead push it\nto the left, the pole will recover its up position, not only maximising the reward but also\nproviding access to a greater number of future states.\nThe right decision here is then pushing to the left for two separated reasons:\n1. It leads to a greater diversity of available future states.\n2. It leads to future states with higher reward.\nThe process of scoring options needs then to be guided by a search for more possible future\nstates, usually called ‘exploration’, while also taking into account how rewarding such future\nstates are, i.e. ‘exploitation’. Reaching and maintaining this fragile balance is the key idea\nbehind any intelligent process.\nWe have nailed down the actual problem of intelligence to finding a way to scan the space of\nfuture states in such a way that exploration and exploitation are balanced during the process,\nand then make a decision about our next action based on the findings.\n\n13 March 2018\n\n8\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n2 - Fundamental concepts\n“By far, the greatest danger of Artificial Intelligence is that\npeople conclude too early that they understand it.”\nEliezer Yudkowsky\nBuilding a detailed theory of intelligence based on these ideas requires fleshing out some\nfundamental concepts: the shape of this ‘space of future states’, what ‘scanning’ will mean to\nus, what ‘balancing exploration and exploitation’ means, and finally, how can we use\ninformation derived from the scanning process to make intelligent decisions over the available\nactions.\n\n2.1 - Causal Cones\n“What is required is that the mind be prepared in advance, and\nbe already stepping from thought to thought, so that it will not\nbe too much held up when the path becomes slippery and\ntreacherous.”\nLeibniz, on Rational Decision-Making\n\nIn order to understand the ‘space of future states’ an intelligence will need to scan, we define a\nCausal Cone X(x​0​, 𝛕) as the set of all the paths the system can take starting from an initial state\nx​0​ if allowed to evolve over a time interval of length 𝛕, the ‘time horizon’ of the cone.\n\n13 March 2018\n\n9\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nCausal cones are usually divided into two parts: the cone’s ‘horizon’, formed by the final states\n(t = 𝛕) for all the possible paths, and the rest of the cone (t < 𝛕) usually referred to as the cone’s\n‘bulk’.\n\n2.1.1 - Causal Slices\nA Causal Slice of the cone X(x​0​, 𝛕) at time t∈[0, 𝛕] is the horizon of the cone X(x​0​, t) which may\nbe denoted by X​H​(x​0​, t). Meanwhile, it is important to note that causal slices consist of a set of\nstates, unlike causal cones that are formed by full paths.\nWe can imagine this causal slices as being the set of all future states the system can evolve to in\na given time t, starting from x​0​.\n\n2.1.2 - Conditional Causal Cones\nGiven that the initial state x​0​ contains specific information concerning the system’s degrees of\nfreedom, and given that the intelligence can alter those values by taking an initial action, all the\npaths forming the Causal Cone can then be partitioned based on this initial action taken.\n\n13 March 2018\n\n10\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nWe define the Conditional Causal Cone associated with an action a ∈ A, X(x​0​, 𝛕|a), as the cone\nformed by all the paths that start by taking the option a. The conditional cones are then a\npartition of the original cone:\n\nX (x0 , τ ) =\n\nX (x0 , τ |a)\n∪\na∈A\n\n2.2 - Reward function\n“To employ the art of consequences, we need an art of bringing\nthings to mind, another of estimating probabilities and, in\naddition, knowledge of how to evaluate goods and ills.”\nLeibniz, on Rational Decision-Making\nIn our setup, we will assume a reward function R(x) is defined over the state space. This reward\nfunction must follow some basic rules in order to be useful to the intelligence.\n\n2.2.1 - Dead vs Alive states\n“The reports of my death have been greatly exaggerated”\nMark Twain\nWe will say an state of the system is ‘alive’ from the intelligence standpoint when:\n●\n●\n\nIt is a feasible state, meaning the system dynamics allow it.\nModifying the degrees of freedom causes the system evolution to be affected.\n\nWe will then say the intelligence is ‘alive’ when it is in a alive state, and ‘dead’ in the other cases.\n\n13 March 2018\n\n11\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n2.2.2 - Reward function properties\n“I came to see that there is a species of mathematics in\nestimating reasons, where they sometimes have to be added,\nsometimes multiplied together in order to get the sum. This has\nnot yet been noted by the logicians.”\nLeibniz, on Rational Decision-Making\n\nA function R(x) defined over the state space of the system can be considered a reward function\nfor an intelligent agent when it meets the following criteria:\n1. The reward is positive for all alive states of the system.\n2. The reward is zero for all dead states of the system.\n3. States with higher rewards are considered better for the agent.\nAs an example, consider R(x) as being the battery level of an electric powered remote\ncontrolled agent, then:\n1. When R(x) is positive, the batteries are working and the intelligence can take decisions\nthat will affect the evolution of the system.\n2. if R(x) is zero, the agent is out of batteries and any decision the intelligence could take\nwill not affect the evolution of the system.\n3. The higher the energy, the better for the agent.\n\n2.2.3 - Reward density over Causal Slices\nFor every slice X​H​(x​0​, t) of the causal cone, we can calculate the total reward R​TOT​(x​0​, t) of the\nslice as the integral of the reward over the slice. We may then convert the reward into a\nprobability density P​R​ over the slice as follows:\nP​R​(x|x​0​, t) = R(x) / R​TOT​(x​0​, t)\n\n2.3 - Policies: defining strategies\n“You have brains in your head. You have feet in your shoes. You\ncan steer yourself any direction you choose. You're on your\nown. And you know what you know. And YOU are the one\nwho'll decide where to go...”\nDr. Seuss​, ​Oh, The Places You'll Go!\n13 March 2018\n\n12\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nA policy 𝜋 is a set of two functions that completely define the strategy an intelligent system\nwould follow when scanning the future consequences of its actions and deciding on the next\naction to take.\n𝜋 = {𝜋​S​, 𝜋​D​}\n\n2.3.1 - Scanning policy\nThe scanning policy 𝜋​S is\n​ a function that, given a state x ∈ E of the system, outputs a probability\ndistribution P over the available actions:\n𝜋​S​ : E → P\nWhen considering the probability of choosing a particular action a, we will use the conditional\nnotation 𝜋​S​(a|x).\nA special case of scanning policy is the random policy 𝜋​S​RND​ that would assign a uniform\ndistribution over the actions regardless of the state x, so all actions are equally probable and\n𝜋​S​RND​(a​i​|x) = 𝜋​S​RND​(a​j​|x), ∀a​i​, a​j​ ∈ A:\n𝜋​S​RND​ : E → P with P a uniform distribution.\n\n2.3.2 - Deciding policy\n“It is the mark of a truly intelligent person to be moved by\nstatistics.”\nGeorge Bernard Shaw\nA policy must also include a mechanism to score the available actions and assign them a\nprobability of being chosen after the scanning phase is finished. This deciding probability\ndistribution shall be denoted by:\n𝜋​D​ : A → [0, 1]\nThere is also a special case where the decision is taken in a random manner so each action is\nequiprobable and 𝜋​D​RND​(a​i​) = 𝜋​D​RND​(a​j​), ∀a​i​, a​j​ ∈ A:\n𝜋​D​RND​ : A → [0, 1] is a uniform distribution.\n\n13 March 2018\n\n13\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n2.3.3 - Probability density due to policy over Causal Slices\nOnce a scanning policy 𝜋​S​ is defined, we may use it to calculate the probability of the system\nevolving to a given state, as the policy serves as a transition probability which, as in a Markov\nchain, allows us to project the evolution of the probability density over time.\nFor instance, in the initial causal slice for t = 0, the density is concentrated on the initial state x​0​,\nas the slice X​H​(x​0​, t = 0), only contain this state. However, as time increases, the causal slice\nvolume will grow and the distribution will evolve.\nWe can then define this ‘scanning probability density’ P​s​ as being a function defined over the\nslice X​H​(x​0​, t), with parameters x​0​, t and 𝜋​S​:\nP​s​(x|x​0​, t, 𝜋​S​)\n\nIt is important to note that, given a scanning policy 𝜋​S​, some of the states in a slice could be\nunreachable. For instance, if a policy chooses the same action all the time with probability 1,\nthen P​s​(x|x​0​, t, 𝜋​S​) is not guaranteed to be non zero for all x in the slice, as it occurs with the\nrandom policy 𝜋​S​RND​.\n\n2.4 - Divergence between distributions\nWe will need to define a reliable measure of how similar two probability distributions are. This\nis usually done using the Kullback-Leibler divergence as follows:\nD​KL​(p || q) = -𝚺(p​i​ Log(p​i​/q​i​)) ≥ 0\nThis formulation requires q​i​ > 0 whenever p​i​ > 0. In our case, where p = P​R​(x|x​0​, t) and q​i​ =\nP​s​(x|x​0​, t, 𝜋​S​), this is not guaranteed to be true as we noted before, but we could use Gibbs’\ntheorem to find a divergence formulation which doesn’t suffer from this weakness.\n13 March 2018\n\n14\n\n\fFractal AI: A Fragile Theory of Intelligence\n\npi​\npi​\nGibbs’ Theorem 1.​ Let P, Q ∈ ​P​n​ ​= {p ∈ ℝ​n​ : p​i​ ≥ 0, ​𝚺 ​p​i =\n​ 1}, t​hen 𝚷​(q​i​ ) is maximized by 𝚷​(p​i​ ).\n\nUsing this theorem we may define a different divergence of two distributions as follows:\nD​H​(P || Q) = Log(​𝚷​(p​i​pi​) / ​𝚷​(q​i​pi​))\nThis divergence is well defined for any possible distributions p and q, including the problematic\ncase when (p​i​ > 0, q​i​ = 0) and it satisfies the main properties of the KL-divergence we need:\n1. D​H​(P || Q) is well defined for any pair of distributions.\n2. D​H​(P || Q) ≥ 0 for any pair of distributions.\n3. D​H​(P || Q) = 0 if and only if p = q.\n\n13 March 2018\n\n15\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n3 - Defining Intelligence\n“There is always another way to say the same thing that doesn't\nlook at all like the way you said it before. I don't know what the\nreason for this is. I think it is somehow a representation of the\nsimplicity of nature.”\nRichard P. Feynman\nWe will define the intelligence as the ability to minimize a ‘sub-optimality’ coefficient based on\nthe similitude of two pairs of probability distributions obtained during the processes involved:\nscanning and the decision-making.\n\n3.1 - Scanning process\n“Intelligence is not to make no mistakes, but quickly to see how\nto make them good.”\nBertolt Brecht\nIn the scanning phase, the possible future outcomes of the initial actions are sampled using the\nscanning policy 𝜋​S​.\n\n3.1.1 - Causal Slice divergence\nGiven a slice of the causal cone X​H​(x​0​, t) and a scanning policy 𝜋​S​ we previously defined two\nprobability distributions over it: the scanning density distribution P​s​(x|x​0​, t, 𝜋​S​), and the reward\ndistribution P​R​(x|x​0​, t).\nThe reward distribution is provided by the environment in an objective manner so the policy\ncan not change it, while the scanning density distribution is directly dependent on 𝜋​S​, so it\nmakes sense to use the divergence D​H​(P​R​, P​s​) as a measure of how well the scanning policy\nleads the agent to rewarding states.\n\n3.1.2 - Intelligent Scanning\n“...in order to decide what we ought to do to obtain some good\nor avoid some harm, it is necessary to consider not only the\ngood or harm in itself, but also the probability that it will or will\n13 March 2018\n\n16\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nnot occur, and to view geometrically the proportion all these\nthings have when taken together.”\nLeibniz, on Rational Decision-Making\n\nWe will define the ‘Intelligent Scanning’ as the optimal policy 𝜋​S​OPT​ that produces a scanning\ndensity distribution that is proportional to the reward for every slice of the causal cone:\nP​s​(x|x​0​, t, 𝜋​S​) ∝ R(x), ∀x 𝛜 X​H​(x​0​, t)\nThis implies that both probability densities are coincident:\nP​s​(x|x​0​, t, 𝜋​S​) = P​R​(x|x​0​, t), ∀t 𝛜 [0, 𝛕], ∀x 𝛜 X​H​(x​0​, t)\nEquivalently, we may define 𝜋​S​OPT​ as the policy that makes the causal slide divergence to equal\nzero for any t 𝛜 [0, 𝛕]:\nD​H​(P​R​(x | x​0​, t), P​s​(x | x​0​, t, 𝜋​S​)) = 0, ∀t 𝛜 [0, 𝛕], ∀x 𝛜 X​H​(x​0​, t)\nThe idea behind this definition is that the optimal way of scanning a space is to make the\nprobability of searching on a particular zone to be proportional to the expected reward: should\nyou be searching for gold over a wide landscape, it would make sense to adjust the density of\ngold-miners in different zones to be proportional to the density -probability of finding- gold.\n\n3.1.3 - Scanning sub-optimality coefficient\nThe more similar the two distributions are, the more intelligent and efficient the scanning will\nbe, and, in the limit when the policy is optimal, we would reach an equilibrium where the\ndivergence between both distributions is exactly zero.\nGiven that real-world scanning policies will not produce scanning probability densities exactly\nproportional to the rewards, this divergence will generally not be exactly zero over the\ndifferent slices X​H​(x​0​, t), so integrating the divergences over time can provide us with a\nmeasure of the sub-optimality of the scanning policy:\nτ\n\nS can(π s |x0 , τ ) =\n\n∫\n\nt=0\n\nDH (P R (x|x0 , t), P s (x|x0 , t, π s )) dt\n\nIn order to scale this coefficient into a more sensible figure, we may define the ‘unit of\nsub-optimality’ to be the sub-optimality associated with the random scanning policy 𝜋​S​RND​.\nRandom Scan Sub-optimality= Scan(𝜋​S​RND​|x​0​, 𝛕)\n13 March 2018\n\n17\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nWe may now divide the previous coefficient into this sub-optimality unit, so only policies that\nare ‘better than random’ will score below 1, while ‘worse than random’ ones will score above 1.\nScan Sub-Optimality(𝜋​S​|x​0​, 𝛕) = Scan(𝜋​S​|x​0​, 𝛕) / Scan(𝜋​S​RND​|x​0​, 𝛕)\n\n3.2 - Decision process\n“There is hardly anyone who could work out the entire table of\npros and cons in any deliberation, that is, who could not only\nenumerate the expedient and inexpedient aspects but also\nweigh them rightly. Now, however, our characteristic will\nreduce the whole to numbers, so that reasons can also be\nweighed, as if by a kind of statics.”\nLeibniz, on Rational Decision-Making\nAs the second part of the process, the information obtained by the scanning phase is used to\ndecide which action to take or, more generally, the probability 𝜋​D​(a) of each action to be taken.\n\n3.2.1 - Intelligent decision\nWe will say a decision, defined as a probability distribution 𝜋​D​(a) over all possible actions a ∊ A,\nis the ‘intelligent decision’ ID(a|𝜋​S​ , 𝛕) for policy 𝜋​S​ and time horizon 𝛕, when the probabilities\nare proportional to the entropy of the conditional scanning probability densities for the actions\nover the last slice of the cone, X​H​(x​0​, 𝛕).\nID(a|𝜋​S​ , 𝛕) ∝ 𝓗(P​s​(x|x​0​, 𝛕, 𝜋​S​, a))\nUsing that the conditional probabilities P​S​ for different actions a ∈ A are independent and that\nthe corresponding conditional causal cones form a partition of the causal cone, we have that:\n𝓗(P​s​(x|x​0​, 𝛕, 𝜋​S​)) =\n\n∑\na∈A\n\n𝓗(P​s​(x|x​0​, 𝛕, 𝜋​S​, a))\n\nSo we may obtain the intelligent decision as a probability density over the actions as follows:\nID(a|𝜋​S​, 𝛕) = 𝓗(P​s​(x|x​0​, 𝛕, 𝜋​S​, a)) / 𝓗(P​s​(x|x​0​, 𝛕, 𝜋​S​))\nThis formulation implies that the intelligent decision in the discrete and the continuous cases\nare:\nDiscrete case\n13 March 2018\n\nIntelligent decision= arg max ID(a|𝜋​S​, 𝛕)\n18\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nContinuous case\n\nIntelligent decision=\n\n∫\n\na · I D(a|π s , τ ) da\n\na∈A\n\n3.2.2 - Decision sub-optimality coefficient\nGiven a policy 𝜋 = {𝜋​S​, 𝜋​D​} that generates a probability distribution 𝜋​D​(a) over the actions, we\ncan define its sub-optimality as the divergence with the ideal distribution ID(a):\nDecision sub-optimality(𝜋|x​0​, 𝛕) ∝ D​H​(ID(a|𝜋​S​, 𝛕), 𝜋​D​(a))\nAs we want this coefficient to be 1 for the random policy, we can define our unit of\nsub-optimality as the sub-optimality of the random decision policy 𝜋​D​RND​ ,​ the uniform\ndistribution:\nDecision sub-optimality(𝜋|x​0​, 𝛕) = D​H​(ID(a|𝜋​S​, 𝛕), 𝜋​D​) / D​H​(ID(a|𝜋​S​, 𝛕), 𝜋​D​RND​)\n\n3.3 - Global sub-optimality\nGiven a policy 𝜋 responsible for both scanning and deciding, we can define its global\nsub-optimality as the average of both sub-optimality coefficients:\nSub-optimality(𝜋|x​0​, 𝛕) = (Scan sub-optimality(𝜋​S​|x​0​, 𝛕) + Decision sub-optimality(𝜋|x​0​, 𝛕)) / 2\nThis global sub-optimality coefficient allows us to determine which policies are approximately\nrandom (≈1) and which are nearly optimal (≈0).\n\n3.4 - Policy IQ\nGiven the definition of sub-optimality of a policy, we can define the IQ of a given policy as\nfollows:\nIQ(𝜋|x​0​, 𝛕) = 1 / sub-optimality(𝜋|x​0​, 𝛕)\nBy using a moving average of this IQ over time as the system evolves, we can build a reliable\nreal-time measurement of the intelligence of a particular system evolution.\n\n13 March 2018\n\n19\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n4 - Fractal AI algorithm\n“Intelligence is the ability to avoid doing work, yet getting the\nwork done.”\nLinus Torvalds\nOnce we have a sensible definition of intelligence, the next step is use it to define a practical\nand efficient intelligent decision-taking algorithm, or more precisely:\n“Given a system with some degrees of freedom that can be controlled, an informative\nsimulation of the system’s dynamics (not necessarily a perfect simulation nor a deterministic\none), and a reward function defined over the state space, find an algorithm that use this\ninformation to push the degrees of freedom in such a way that the system behaves -or evolvesintelligently”.\nWe will guide our search in two ambitious “design principles”:\n1. An algorithm with a sub-optimality coefficient tending to zero.\n2. An algorithm with the lowest time-complexity possible.\nThe algorithm presented here is not the only possible one, nor it is a complete implementation\nof all the potential uses of the previous theory. It must instead be considered as one direct and\nintuitive use of the concepts presented in order to generate intelligent behaviour from the raw\nsimulation of a system.\n\n13 March 2018\n\n20\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n4.1 - Algorithm blueprints\n“You can recognize truth by its beauty and simplicity. When you\nget it right, it is obvious that it is right—at least if you have any\nexperience—because usually what happens is that more comes\nout than goes in. (...) the truth always turns out to be simpler\nthan you thought.“\nRichard P. Feynman\nBefore presenting the pseudo-code of the algorithm, we will introduce the ideas behind it and\nhow its design aims to meet the previously defined theory in the lowest computational time\ncomplexity.\n\n4.1.1 - Starting at Monte Carlo\n“Any one who considers arithmetical methods of producing\nrandom digits is, of course, in a state of sin.”\nJohn von Neumann\n\nWe will start our implementation by considering the random policy or, equivalently, using the\nstandard Monte Carlo- approach, where a set of independent random walks are simulated over\na number of discrete time steps to actually build a collection of paths in the causal cone\nconsidered in the theory.\nIn practical terms, we will need a informative simulation function -not necessary perfect nor\ndeterministic- that, given a system state -that includes the positions of the different degrees of\nfreedom the AI can modify- and a small delta of time dt, outputs the expected next state of the\nsystem:\nx(t+dt) = Simulation(x(t), dt)\nStarting at the actual system’s state x​0​ and iterating the process of taking a random decision\nover the degrees of freedom and then simulating the next state for a fixed number T of ticks ,\nwe can build a random walk of length 𝝉 = T*dt.\nIn the image below, two different actions -pushing buttons “A” or “B”- are available. In the\ncontinuous case, actions would be real vectors representing the velocities of the degrees of\nfreedom, or how strong it pushes each free param, and in which direction.\n\n13 March 2018\n\n21\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nAs we are looking for a decision-taking algorithm, the first decision -or action- taken during the\nwalk, “B” in this example, will be an important piece of information, so we will keep it in the\nwalker’s internal state for later use.\nBy building one path after another we can actually build a set of N ‘feasible random walks’\nstarting at x​0​ and ending at one of the possible system future states.\n\n4.1.2 - Choosing the intelligence parameters\nAt this point, some practical question like how many random walks we will be using, the time\nhorizon those walks will explore, and the number of ticks we will divide this time into will\nprobably arise.\nBefore going any deeper in the algorithm it is worth spending some lines addressing those\nquestion as they are the main parameters related to the CPU you will need and the quality of\nthe results.\n\n4.1.2.1 - Decisions per second\nThe first parameter to be chosen is about the number of decisions per second the agent will be\ntaking, or the FPS (frames per second) of the algorithm. We are basically deciding here on the\nlength of the dt used in the simulations, our tick length.\n\n13 March 2018\n\n22\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nBasically, this length depends on the system reaction times. If our agent is modeling a fly we\nwill need a faster decision taking, so a lower tick length. If it were modeling a spaceship\ntraveling to andromeda, we could safely take one decision each month or even year.\nAs a guiding number, human brains are considered to run at about 12 decisions per second, so\nif we were to mimic some human behaviour, a dt of about 0.1 seconds (or 10 FPS) is a nice\nstarting point.\nSetting a FPS higher that the reaction time will not really improve the results, while CPU time\nwill grow proportionally to FPS, so just keep this figure around the sweet point.\n\n4.1.2.2 - Time horizon\nThe time horizon dictates how far into the future will the walkers explore the consequences of\ntheir initial actions.\nThe idea here is to try to scan long enough to detect the problems before you can not avoid\nthem and, again, it depends naturally on the task:\n●\n●\n\nA F1 driver, deciding on the driving wheel and pedals, needs to foresee where the car\nwill be in about 5-10 seconds in order to properly drive a race.\nA spaceship traveling to andromeda needs to foresee some years to know is pushing\nthe thruster now will lead you to andromeda or not.\n\n4.1.1.3 - Number of walkers\nThis one is easy: the more the better. Of course it will use CPU linearly, but the most efficient\nway to improve the agent behaviour is using more walkers.\n\n4.1.3 - Simultaneous walks\nAs the theory mandates that the ‘density of scanning’ -or ‘density of walkers’- must be kept\nproportional to some reward density, we will need to build all the random walks\nsimultaneously, so a density of walkers can be defined.\n\n13 March 2018\n\n23\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nBefore going any further, we will show a simple pseudo-code that would generate this set of\nwalks and finally decide based on the highest reward found at the final states of each path: if\nthe path leading to the most rewarding state found started with the action “A”, then it will\nactually take action “A”.\n\n// INITIALIZATION:\n// Create N walkers with copies of the system’s state:\nFOR i:= 1 TO N DO BEGIN\n// Walkers start at the system’s initial state:\nWalker(i).State:= System.State\n// Take walker’s initial decision:\nWalker(i).Initial_decision:= random values\nEND\n// SCANNING PHASE:\n// Evolve walkers from time=t to t+Tau in M ticks:\nFOR t:= 1 TO M DO BEGIN\n// PERTURBATION:\nFOR i:= 1 TO N DO BEGIN\n// First tick use the stored initial decision\nIF (t=1) THEN\nWalker(i).Degrees_of_freedom:= Walker(i).Initial_decision\nELSE\nWalker(i).Degrees_of_freedom:= random values\n// Use the simulation to fill the other state’s component:\nWalker(i).State:= Simulation(Walker(i).State, dt:= Tau/M)\n\n13 March 2018\n\n24\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nEND\nEND\n// DECIDING PHASE:\nBest:= ArgMax(Reward(Walker(i).State))\nDecision:= Walker(Best).Initial_decision\n\nBeing this code just a simple starting point, it already meets some of our design goals:\n1. The more accurate the simulation is, and the smaller that dt is made, the more\ncompatible with the system’s dynamic the generated paths are.\n2. The bigger the number of walkers used, the bigger portion of the causal cone will be\nscanned.\n\n4.1.4 - Probability densities\n“In applying dynamical principles to the motion of immense\nnumbers of atoms, the limitation of our faculties forces us to\nabandon the attempt to express the exact history of each atom,\nand to be content with estimating the average condition of a\ngroup of atoms large enough to be visible. This method... which\nI may call the statistical method, and which in the present state\nof our knowledge is the only available method of studying the\nproperties of real bodies, involves an abandonment of strict\ndynamical principles, and an adoption of the mathematical\nmethods belonging to the theory of probability.”\nJames Clerk Maxwell\nAccordingly to theory, no matter which partition {A​1​, ... , A​N​} of the causal slice you consider, the\nwalker density D​i on\neach part A​i​ should be made proportional to the density of reward R​i\n​\nOur next step will be properly defining both densities.\n\n4.1.4.1 - Density of walkers\nIn the next image we have partitioned the space with boxes of the same size. Each one of the\nfour populated boxes A​1​ to A​4​ have a number of walkers W​i​ inside it from a total of six walkers\nconsidered, so the walker’s density at A​i​ will be D​i​ = W​i​/6 .\nPlease note that we didn’t need it to be a partition, the different zones may overlap, so we are\nactually using a covering of the set of all the walker’s positions.\n\n13 March 2018\n\n25\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n4.1.4.2 - Reward density\nAt the same time, a reward value is defined over the state space, so we can assign a reward\nvalue to each box A​i​ by averaging the rewards at the positions of the walkers in A​i​.\n\n13 March 2018\n\n26\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n4.1.5 - Migratory flows\n“Failure is simply the opportunity to begin again,\nthis time more intelligently.\nHenry Ford\nOur final goal is to make both densities proportionals, or, equivalently, we need R​i​/D​i​ to be as\nconstant as possible.\nBasically, R​i​/D​i​ is a measure of the “reward per capita” that a walkers in the box Ai will receive,\nand the idea of making this a constant could be interpreted as the need of a fair wealth\ndistribution over the walkers: if zone A​i​ has a much higher reward per capita than zona A​j​ then\nwalkers in A​j​ will likely prefer to move to A​i​. As we aim to make both densities to be\nproportional, we need to define a ‘migratory flow’ in order to balance the reward per capita.\n\n13 March 2018\n\n27\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nThis migratory flow will need to detect zones where walker density is higher-than-proportional\nto the reward (zones with a low ‘reward per capita’) and move some walkers from there to\nother zones with higher ‘reward per capita’.\nIn order to move a walker W​1​ from zone A​i​ to A​j​ we could just select a random walker W​2​ at A​j\nand copy its state, W​1​.state ← W​2​.state. We say that W​1​ ‘cloned’ into W​2​ position.\n\n13 March 2018\n\n28\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nHere we just sketched a nïve way to choose which walkers needs to be cloned into which\nothers by using boxes. In the final algorithm this idea will be replaced with a more general\nsolution.\n\n4.1.6 - Taking the decision\n“Deliberation is nothing else but a weighing, as it were on scales,\nthe conveniences and inconveniences of the fact we are\nattempting.”\nLeibniz, on Rational Decision-Making\nIn the previous example, when a walker labeled with the first option “A” is cloned to the\nposition of a walker labeled “B”, it not only clone its position but also its label, so after the\nclone, the initial action “A” will have one ‘follower’ less, while action “B” will gain one. After\nsome ticks are performed, the distribution of the initial actions in the population of walkers will\nvary.\n\n13 March 2018\n\n29\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nIn the example above, both actions start having a proportion of 3/6 = 0.5 of the walkers, but\nafter the migratory flow takes place, “B” population grows to 5/6 while “A” drops to 1/6.\nIf the process was to be stop here -time horizon 𝛕 was 6 ticks of length dt- then we would use\nthese proportions to build our decision.\nIn the discrete case, the AI would take its decision by sampling an action from the probability\ndistribution (1/6, 5/6) of the actions, so the most probable action would be “B”.\nIn the continuous case, where actions are real vectors and there is no finite list of available\nactions, the decision is formed by averaging the initial decisions of all the walkers.\n\n4.2 - The migratory process\nWe commented on the need of forcing migratory flows from areas were reward was low or\npopulation density high, but defining a density is a tricky thing that can also be computationally\ndemanding.\nThe idea of using boxes -as in the previous introduction- was just a sketch of the idea, we didn’t\ndefine a method to effectively choose which walkers will clone and, more importantly, which\nwalkers will they copy from.\n\n13 March 2018\n\n30\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n4.2.1 - Virtual reward\n“Presuming that a man has wisdom of the third degree and\npower in the fourth, his total estimation would be twelve and\nnot seven, since wisdom be of assistance to power.”\nLeibniz, on Rational Decision-Making\nThe ‘Virtual reward’ is a generalization of the ‘reward per capita’ concept introduced before,\nbut instead of using an externally defined partition, we will build one with a different zone per\nwalker, so we can obtain a ‘personalized’ reward value that will tell a walker how ‘lucky’ he is\nas compared to other walkers: the higher the reward is, and the fewer the walkers around you,\nthe better.\nChoosing one partition per walker to account for the number of walkers inside each part is\nactually just a way to approximate the concept of ‘density of walkers’ around a position. At his\ntime we will just assume we have defined some general measure of such density around the\nposition of each walker:\nD​i​ =Density of Walkers around W​i​ position/state.\nWe will then define the ‘virtual reward’ VR​i​ at a walker’s W​i​ position, where the reward value is\nR​i​, as being:\nVR​i =\n​ R​i​ / D​i\nOne simple way to define a density of walkers around a given position is to consider our\ncovering as being formed by a set of spheres of a fixed radius in the state space, each centered\nat one walker position, and counting for the number of walkers inside each one to get a density.\n\n13 March 2018\n\n31\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nPlease note that, as we will only focus on the proportionality of those densities -and not in their\nactual values- we can safely use the number N​i​ of walkers inside the ball as a density, without\ndividing it by N, as it will not alter the proportions.\nThen, by looking at the image, we can say that at walker W​1​ position, there is a reward of R​1​ = 6\nand a walker density of N​1​ = 3, so we will calculate its virtual reward as:\nVR​1​ = R​1​ / N​1​ = 6 / 3 = 2\nIf we compare it with the virtual reward for walker W​2​, VR​2​ = R​2​ / N​2​ = 2 / 1 = 2, we find that\nboth positions are equally ‘appealing’ as the number of walkers is kept proportional to the\nreward.\n\n4.2.2 - Simplifying the Virtual Reward\n“Everything should be made as simple as possible,\nbut not simpler.”\nAlbert Einstein\nUsing densities around the walker positions may not be an ideal approach for some reasons:\n\n13 March 2018\n\n32\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n1. The algorithm would need to check the distances between all possible pairs of walkers,\nmaking the computational time-complexity to be, at least, of order O(n²), where n\naccounts for the number of walkers times the number of ticks you divide your time\nhorizon in.\n2. We would need to externally set a radius that makes sense and, probably, adjust it\ndynamically so it doesn’t get too big or small during the process. You could, for instance,\nforce the average number of walkers per ball to be between some reasonable values,\nlet’s say in (1.5, 3), so if radius is so small that there is only one walker at each ball then,\nas 1 < 1.5, you would need to increase the radius.\nOur first simplification will eliminate the need of a externally defined radius, by far the smaller\nof our two concerns.\nThe key idea we will use here is that walker density D​i​ defined over a sphere centered at the\nwalker W​i​ position, is roughly -the relation may not be strictly linear- inversely proportional to\nthe average distance from W​i​ to the other walkers W​j​.\nD​i​ ∝ 1 / (∑ Dist(W​i​, W​j​)/N)\nAgain, N can be eliminated from the equation as we only need to compare proportions, so:\nD​i​ ∝ 1 / ∑ Dist(W​i​, W​j​)\nBy replacing Di ∝ 1/N​i​ in the previous formula with this new version of D​i​ we obtain:\nVR​i​ ∝ R​i​ * ∑ Dist(W​i​, W​j​)\n\n13 March 2018\n\n33\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nThe second simplification we will introduce is quite a dramatic one and it may initially sound\nlike a really bad idea: we will replace the average distance from walker W​i​ to all the other\nwalkers W​j​ with just one of those distances, randomly chosen:\nD​i​ ∝ 1 / Dist(W​i​, W​j​) with j randomly chosen, j<>i\nThe resulting virtual reward formulation have a time-complexity of only O(n) while making it to\nbe a highly stochastic function:\nVR​i​ ∝ R​i​ / D​i​ ∝ R​i​ * Dist(W​i​, W​j​) with j≠i, randomly chosen.\nAs our only purpose is to compare virtual rewards, being proportional allows us to safely\ndefine:\nVR​i​ = R​i​ * Dist(W​i​, W​j​) with j≠i, randomly chosen.\nUsing this stochastic version of the density actually do a better job than using the standard\naverage distance, and at a much lower computational cost.\n\n13 March 2018\n\n34\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n4.2.3 - Balancing exploitation and exploration\n“Nobody ever figures out what life is all about, and it doesn't\nmatter. Explore the world. Nearly everything is really\ninteresting if you go into it deeply enough.”\nRichard Feynman\nA more general formula for the virtual reward can be considered:\nVR​i​ = R​i​⍺​ * Dist​β​(W​i​, W​j​) with j≠i, randomly chosen.\nBy default, both ⍺ and β are set to 1, meaning that, as far as the the reward is properly scaled\nso its rate of change is roughly linear (and thus in the same order of magnitudes as for the\ndistance changes), exploitation and exploration are balanced.\nThe value of β is considered fixed at 1 and highly dependent on the metric used, while ⍺ is a\nparameter we can freely change in a standard range from 0 up to 2 or more, actually pushing\nthis balance from equilibrium (⍺ = β) toward an exploration-only mode (⍺ = 0) or toward an\naggressive search for reward (⍺ > β).\n\n13 March 2018\n\n35\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n4.2.3.1 - The “Common Sense”\nBy manually setting ⍺ = 0, the behaviour changes to a goal-less intelligence, where the\ndecisions are taken in order to increase the number of different reachable futures, regardless\nof how rewarding they are. The effect is a very clever autopilot that can keep a plane flying\naround avoiding dangerous paths almost indefinitely.\nPlease note this “Common sense” mode is nearly equivalent to the idea of maximizing the\nempowerment [​6​] of the agent as an intrinsic goal. In fact, in this case the agent is maximizing a\nintrinsic reward represented by the entropy of the available futures after your decision.\nInversely, if ⍺>β the agent will be somehow blinded by the reward and will not care much\nabout safety, driving the agent to dangerous situations where the reward is particularly high. In\nour system can be in death states, if our agent can die, then keeping ⍺ low is mandatory.\nWe can then conclude that the value of ⍺ roughly represents how safe is it to focus on\nexploitation in detriment of exploration, or how ‘safe’ the environment is for the agent.\n\n4.2.4 - Probability of cloning\n“Often one postulates that a priori, all states are equally\nprobable. This is not true in the world as we see it. This world is\nnot correctly described by the physics which assumes this\npostulate.”\nRichard P. Feynman\nOnce we defined a simple yet informative value for the virtual reward of a walker, it is time to\nget back to the migratory process we outlined before and try to draw a simple method to\nchoose which walkers will be cloning which.\nIn the process of calculating the virtual reward, a walker must obtain the state of another\nrandomly chosen walker in order to compare positions and obtain a distance. We will also start\nthe cloning process by choosing another random walker in order to compare virtual rewards\nand obtain a probability of cloning.\nOnce walker W​i​ choose a second random walker W​k​ it will compare virtual rewards and, should\nhe find his to be lower, he could decide to jump to W​k​ position by cloning its state.\nWe will define the probability of walker W​i​ with virtual reward VR​i​ cloning to W​k​ state, with\nvirtual reward VR​k​, as:\n●\n●\n\nProb = 1\nProb = 0\n\n13 March 2018\n\nIf VR​i​ = 0\nIf VR​i​ < VR​k\n36\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n●\n\nProb = (VR​K​ - VR​i​) / VR​i\n\nIf VR​i​ ≥ VR​K\n\n4.3 - Pseudo-code\nWe present a pseudo-code implementation to serve as a base code. The implementation\npresented here is aimed at simplicity and readability, not efficiency or scalability.\n\n// [0] INITIALIZATION PHASE:\n// Define dt for a time horizon Tau, divided on M ticks:\ndt:= Tau/M\n// Create N walkers with copies of the system’s state:\nFOR i:= 1 TO N DO BEGIN\n// Walkers start at the system’s initial state:\nWalker(i).State:= System.State\n// Walkers take an initial decision:\nWalker(i).Ini_Dec:= random values\n// Walkers simulate their next states:\nWalker(i).State:= Simulation(Walker(i).State, dt)\nEND\n// [1] SCANNING PHASE:\nFOR t:= 1 TO M DO BEGIN\n// [1.1] CALCULATE VIRTUAL REWARD:\nFOR i:= 1 TO N DO BEGIN\n// Choose a random walker:\nj:= random index from 1 to n, j<>i\n// Use reward and distance to define virtual reward:\nd:= Distance(Walker(i), Walker(j))\nWalker(i).VR:= d * Reward(Walker(i).State)\nEND\n// [1.2] PERTURB STATE:\nFOR i:= 1 TO N DO BEGIN\n// [1.2.1] Probability of cloning to random walker’s position:\nj:= random index from 1 to n, j<>i\nIF (Walker(i).VR=0) THEN\nProb:= 1\nELSE IF (Walker(i).VR < Walker(j).VR) THEN\nProb:= 0\nELSE\nProb:= (Walker(j).VR - Walker(i).VR) / Walker(i).VR\n// [1.2.2] Perturb state by Cloning or Simulation:\nIF (random < Prob) THEN BEGIN\n// [1.2.2a] Cloning:\nWalker(i).State:= Walker(j).State\nWalker(i).Ini_Dec:= Walker(j).Ini_Dec\nEND ELSE BEGIN\n// [1.2.2b] Simulating:\n// Start by perturbing degrees of freedom:\nWalker(i).Degrees_of_freedom:= random values\n\n13 March 2018\n\n37\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n// Simulate the other state’s component:\nWalker(i).State:= Simulation(Walker(i).State, dt)\nEND\nEND\nEND\n// [2] DECIDING PHASE:\nDecision:= Sum(Walker(i).Ini_Dec) / N\n\n4.4 - Classifying the algorithm\nThe algorithm presented has an algorithmic time-complexity of O(n), where n is the number of\nwalkers used times the number of ticks we divide the time horizon interval.\nThe algorithm may actually fit in many of the categories used in the field of algorithmics,\nmaking it difficult to properly classify it. Instead, we will name and comment on the categories\nwhere it could eventually fit.\n\n4.4.1 - Monte Carlo Tree Search\n“We shall not cease from exploration\nAnd the end of all our exploring\nWill be to arrive where we started\nAnd know the place for the first time.”\nT.S. Eliot​, ​Four Quartets\nOne of the most evident classification of the algorithm is as a version of the Monte Carlo Tree\nSearch (​MCTS​), where the different futures a system can visit are scanned up to some depth\nlevel (a time horizon) while forcing the less appealing branches to be rejected in the process in\norder to focus on the most promising ones.\nThe main differences between Fractal AI and the many MCTS variants [4] are:\n1. MCTS only deal with discrete decision spaces, while Fractal AI deals with both cases.\n2. MCTS build the decision tree one branch -or random walk- at a time, while Fractal AI\nbuilds a big number of branches simultaneously, interacting one with each other.\n\n4.4.2 - Swarm algorithm\n\n13 March 2018\n\n38\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n“There is nothing that living things do that cannot be\nunderstood from the point of view that they are made of atoms\nacting according to the laws of physics.”\nRichard P. Feynman\n\nFractal AI is also a​ swarm intelligence​ algorithm where the collective behaviour of a pool of\ndecentralized, self-organized agents, is solely based on the are used to take decisions.\nPlease note that, although in the pseudo-code the walkers are moved and cloned in a\nsynchronized way for the sake of clarity, it is not mandatory at all, walkers could communicate\nvia asynchronous messages and evolve in a asynchronous and isolated way, making it\nextremely easy to parallelize or distribute the algorithm in order to scale it. Adding a linear\ntime-complexity makes the algorithm highly scalable.\n\n4.4.3 - Evolutive algorithm\n“There's a theory that says that life is based on a competition\nand the struggle and the fight for survival, and it's interesting\nbecause when you look at the fractal character of evolution, it's\ntotally different. It's based on cooperation among the elements\nin the geometry and not competition.”\nBruce Lipton\nFractal AI is a population-based ​evolutive algorithm​ where walkers are divided into population\ngroups (based on their initial actions) that compete for success by cloning the best fits (highest\nvirtual reward) overwriting the worst fits, and then mutating them by randomly changing their\nstates on the simulating phase.\n\n4.4.4 - Entropic algorithm\n“Only entropy comes easy. “\nAnton Chekhov\n\nThere is not a real category of “entropic” algorithms, but it should. An algorithm is entropic\nwhen it is driven by the maximization/minimization of some kind of entropy, cross-entropy, or\ndivergence.\nGradient optimization of a loss function like cross-entropy or divergence of two distributions,\nas used in deep learning, is a clear example of an entropic algorithm.\n13 March 2018\n\n39\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nFractal AI is clearly an entropic algorithm, as it is based on minimizing the divergence -or\nequivalently a cross-entropy- of two distributions: reward and walker probability distributions.\n\n4.4.5 - Fractal algorithm\n“All created forms are fractal, as is their purpose, use, and\nallotted time for existence.”\nGuy Finley\nIn a Monte Carlo Tree Search, where actions are discrete, the graph of the states we visited in\nthe search process is a tree. Fractal AI generate the same kind of trees in the same conditions.\nWhen the decision and the state spaces are both continuous, then the distances between\nwalkers and the time step dt we use for the simulation can we made as small as we want\nmaking the resulting tree to be formed by smaller and smaller pieces.\nIn the limit when both the number of ticks used to divide the time horizon and the number of\nwalkers tend to infinity, the graph morph from a finite tree to a fractal tree.\nThere is a recursive version of the same algorithm -not covered in this document- that could be\nlabeled as a using “fractal recursivity”.\n\n13 March 2018\n\n40\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n5 - Experiments\nWe have run several experiments in order to show the algorithm strong points and to compare\nFractal AI with other similar algorithms.\n\n5.1 - Discrete case: Atari 2600 games\nOne of the most widely used benchmarks for AI methods are the ​Atari 2600 games​ from\nOpenAI gym. They all have a discrete decision space of six on/off buttons and well defined\nscorings allowing fair comparison between algorithms.\n\n5.1.1 - RAM vs Images\nPlaying any of those games involves a continuous two steps loop:\n1. The game sends us its actual state.\n2. AI answer with a decision vector of six booleans.\nA game can send us its actual state in two flavours:\n1. The screen image as a RGB array.\n2. The internal RAM state as a byte array.\nFractal AI base its decisions on the entropic properties of the pool of walker states. Being this\nan intrinsic goal, fractal AI can be equally applied to RAM or image based games with very\nsimilar results.\nAs most of the methods we will be comparing with can only be played on image-based games,\nwe can only compare Image vs RAM-based games solved with fractal AI using the same\nparameters, but in this case, there is no significant change in the scorings but takes less\ncomputation, as RAM size is smaller than image size on Atari-2600.\n\n5.1.2 - Results\nFractal AI is a forward-thinking algorithm -without any kind of learning- like a Monte Carlo\nTree Search family algorithms, so it makes perfect sense to compare it with MCTS algorithms\nlike UCT [​7​], as both measure efficiency in “samples per step”, where “samples” stand for the\nnumber of simulations being used in the internal process of making one decision.\nMost of the games have never been played with a MCTS approach, mainly because they are too\ncomplex to be played with just a planning algorithm. Most of the methods make a heavy use of\nlearning (DQN, A3C, etc.) plus, in some cases, a MCTS to help in the decisions.\n\n13 March 2018\n\n41\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nComparing Fractal AI with neural network based algorithms [​8​] [​9​] it is not that easy. Learning\nbased strategies measured its efficiency in “number of samples used for learning”, a figure\nseveral orders of magnitude bigger that “samples per step”.\nIn general, learning based methods are very slow at learning (in the order of a billion samples)\nbut, once they have learn, they can be very fast at making a decision. In contrast, Monte Carlo\nmethods, like Fractal AI, doesn’t need a previous learning process but use a lot more time to\nmake a decision.\nThat said, we have compared Fractal AI with a number of methods in the literature (including\nthe average human level after 2 hours of playing) focusing in the scores each method get on a\nrepresentative number of atari games.\nGame\n\nHuman\nLevel\n\nBest AI\n\nFractal AI\n(*)\n\nFAI vs AI\n\nSamples per\nstep\n\nBest AI method\n\nAllien\n\n7,128\n\n5,899\n\n19,380\n\n329%\n\n2,700\n\nNoiseNet-A3C\n\nAmidar\n\n2,354\n\n2,215\n\n4,306\n\n182%\n\n1,222\n\nNoiseNet-A3C\n\n47,389\n\n26,380\n\n76,274\n\n289%\n\n2,733\n\nNoiseNet-A3C\n\n12\n\n99.4\n\n100\n\n100.6%\n\n77.8\n\nDueling\n\nCentipede\n\n12,017\n\n25,275\n\n1,222,000\n\n4,835%\n\n1960\n\nHiperNEAT\n\nCrazy climber\n\n35,829\n\n179,877\n\n238,300\n\n132%\n\n1,243\n\nC51 DQN\n\nDouble dunk\n\n-15.5\n\n5\n\n20\n\n400%\n\n5,327\n\nDueling\n\n860\n\n3,454\n\n800\n\n23%\n\n826\n\nC51 DQN\n\n1\n\n10.6\n\n52\n\n603%\n\n12,158\n\nDueling\n\nMontezuma\n\n4,753\n\n53\n\n2,500\n\n4,717%\n\n5,175\n\nA3C\n\nMs Pacman\n\n15,693\n\n6,283\n\n58,521\n\n931%\n\n5,129\n\nDueling\n\nPhoenix\n\n7,243\n\n70,324\n\n11,930\n\n17%\n\n1,289\n\nNoiseNet-A3C\n\nQ-Bert\n\n13,455\n\n23,784\n\n35,750\n\n150%\n\n2,728\n\nMCTS (UCT)\n\nSeaquest\n\n42,055\n\n266,434\n\n5,220\n\n42%\n\n6,149\n\nC51 DQN\n\n1,669\n\n15,312\n\n3,605\n\n24%\n\n4,261\n\nDueling\n\n-8\n\n23.1\n\n24\n\n104%\n\n6,454\n\nDQN\n\n168\n\n321\n\n223\n\n69%\n\n3,023\n\nA3C\n\nVideo pinball\n\n17,668\n\n949,604\n\n604,043\n\n64%\n\n?\n\nC51 DQN\n\nWizard of wor\n\n4,756\n\n12,352\n\n93,090\n\n753%\n\n2,229\n\nDueling\n\nAsteroids\nBoxing\n\nEnduro\nIce hockey\n\nSpace invaders\nTennis\nTutankham\n\n13 March 2018\n\n42\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nPlease note that:\nMost of the games have been played only 2 or 3 times with somehow standard\nparameters, and the best result used.\nMany games supported by the gym environment have not being tested at all.\nSome games were tested but didn’t score so well. The most simple games (the easiest\nfor neural networks) like Pong and Breakout, were the most difficult for FAI, surely\nbecause the game screen is so simple that the entropy gradient is not very significant,\nso learning is more efficient than planning here.\n\n●\n●\n●\n\n5.1.2.1 - MCTS vs Fractal AI\nFractal AI can be considered in the family of MCTS algorithms and fairly compared with other\nstate-of-the-art Monte Carlo methods like the UCT algorithm used in AlphaZero.\nIn the literature [​7​] we only found seven Atari games solved with the UCT algorithm. They are\nall simple games where DQN are good at (the main experiment were DQN + MCTS) but Fractal\nAI is not, at least using 1000 times fewer samples per step.\nScores\nGame\n\nSamples per step\n\nUCT\n\nFractal AI\n\n%\n\nUCT\n\nFractal AI\n\n%\n\n7,233\n\n2,160\n\n30%\n\n3,000,000\n\n4,052\n\n0,14%\n\nBreakout\n\n406\n\n36\n\n9%\n\n3,000,000\n\n5,309\n\n0,18%\n\nEnduro\n\n788\n\n800\n\n102%\n\n4,000,000\n\n826\n\n0,03%\n\nPong\n\n21\n\n---\n\n---\n\n150,000\n\n---\n\n---\n\nQ-bert\n\n18,850\n\n35,750\n\n189%\n\n3,000,000\n\n2,728\n\n0.09%\n\nSeaquest\n\n3,257\n\n5,220\n\n160%\n\n3,000,000\n\n2,933\n\n0.21%\n\nSpace invaders\n\n2,354\n\n3,605\n\n153%\n\n3,000,000\n\n4,261\n\n0.14%\n\nBeam rider\n\n5.1.2.2 - Human record vs Fractal AI\n“To boldly play where no man has played before!”\nWilliam Shatner (almost)\nHuman level stated in the previous table refers to the highest score obtained by an average\nhuman after 2 hours of playing. Being this a fair baseline to compare with, the figures are far\nfrom what a well trained human can get [​10​].\n13 March 2018\n\n43\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nBeating humans records is much harder than beating the best actual AI methods, getting some\nof the records imply playing at a really high level and for several hours in clock time (Centipede\nhuman record took 12 hours). It can take days for a computer to play such a game so, even if\nseems to be theoretically feasible, we haven’t focused on that.\nOn the other hand, some games are faster and based on reaction time and spatial coordination.\nIn such games, Fractal AI can be on par with existing human absolute records.\nGame\nIce hockey\nBoxing\nCentipede\n\nAI record\n\nHuman record\n\nFractal AI\n\n0\n\n36\n\n64\n\n99.4\n\n99\n\n100\n\n8,704\n\n1,301,709\n\n1,222,000​ (*)\n\n(*) When this doc was petrified into a PDF, AI was still playing after 5 days with 1 extra life.\n\n5.1.3 - Implementation details\nThe Atari games experiment was implemented in python following the ideas in this document\nbut not the pseudo-code.\n\n5.1.3.1 - Auto-adjusting ‘Samples per step’\n“With four parameters I can fit an elephant, and with five I can\nmake him wiggle his trunk.”\nJohn von Neumann\nIn the Atari implementation we focused on auto-adjusting the main parameters on-the-fly, so\nwe could run the same code on a variety of Atari games.\nIn the code, instead of defining a fixed number of paths (walkers) and ticks (time depth) as in\nthe included pseudo-code, we limit the number of samples (simulations) per step to be below a\nmaximum, so the stop condition is just based on samples used so far.\nThe actual depth and number of walkers used at each step of the game is dynamically changed\ndepending on the difficulty of the situation, allowing high “samples per step” when needed\nwhile keeping the average very low.\n\n5.1.3.2 - Additional death condition\nSome games -like ‘Tennis’ and ‘Ice hockey’- build their scorings by adding +1 when the player\nwins a ball, and -1 when it loses, so on those cases, your score could eventually get smaller over\ntime.\n\n13 March 2018\n\n44\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nIn those cases, each ball played can be seen as a small game that ends when you gain or lose the\npoint, and it makes sense to consider losing the point as a local ‘death condition’ that will\ntriggered, in general, whenever your score get lower.\nAlthough the algorithm can play any game without this additional death condition, it greatly\nhelps improving the efficiency. In general, adding sensible death conditions is a powerful\nmethod to speed up fractal AI.\n\n5.1.4 - Github repository\nYou can find the full python code for the Atari experiment at\nhttps://github.com/FragileTheory/FractalAI\n\n5.2 - Continuous case: Flying rocket\nIn this experiment we control a 2D rocket flying inside a closed environment. The rocket has\ntwo continuous degrees of freedom corresponding to the trust levels for the main rocket and a\nsecondary one used for rotating.\n\nAt each step we define the force applied to each of the degrees of freedom, so our decision\nspace is a continuous 2D space. In these cases we will not be choosing an action from a list,\ninstead we will be deciding on a force as a 2D vector.\nThe rocket is a very interesting toy-system, it is very dynamic as equilibrium is never reached\nand making fast decisions is critic. When Fractal AI is used in a continuous decision system like\nthis, it performs even better than it did in the discrete case. Being the decision an average of\nmany decisions, it is more naturally defined in the continuous case than in the discrete one.\n\n5.2.1 - Flying a chaotic attractor\n“Chaos was the law of nature; Order was the dream of man.\nHenry Adams\n\n13 March 2018\n\n45\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nAs flying a rocket was not a big problem for fractal AI, we designed an special environment\nwhere the goals were almost impossible to get.\nFirst, a hock was attached to the rocket using a rubber band, forming a chaotic oscillator where\nthe final position of the hook is highly sensitive to small changes in the initial conditions,\nmaking it extremely difficult to sample the state space and find the low probability paths that\ndefine the right decision.\n\nSecondly, we will define a ridiculous difficult goal for the system: drive the rocket in such a way\nthat the chaotic hook picks a falling rock, take it into a distant deploy zone (crossed area),\nrelease it and wait until it leaves the dotted circle, and repeat it as many times as you can.\n\nTo define this ‘hook reward’ we just have to convert it into a reward function.\n1. For every walker, the hook defines its target, being it the nearest rock if the hook is\nempty, and the deploy area when it is holding a rock.\n2. For every walker, the hook calculates the distance D to the target.\n3. Now the walker compares it with the same distance calculated at the initial state (the\nagent position).\n4. If distance is 0, you did it!\nHook Reward = 100\n5. If distance is bigger:\nHook Reward = 10e-10\n6. If distance is 20% smaller:\nHook Reward = 0.2\nOnly this reward function was added, the rest of the code was just standard: the standard\nFractal AI code, and a homebrew physic simulator of the system.\n\n5.2.2 - Results\nFractal AI was able to solve this problem using only 300 walkers (paths) and 200 samples per\nwalker (a time horizon of 2 seconds at steps of 0.1 second) for a total of 60,000 samples per\ndecision.\n\n13 March 2018\n\n46\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nThe agent was able to chain several goals in a row, and also could recover the rock when it\nfalled down the ground, totally solving the task with extremely low computational resources.\nVideo 1: ​Solving the task​ (​https://youtu.be/HLbThk624jI​)\nThis experiment also allows us to watch the fractal paths generated in the process.\n\nVideo 2: ​Visualizing the decision process​ (https://youtu.be/cyibNzyU4ug )\n\n5.2.3 - Implementation details\nThis experiment used an early implementation of the algorithm that was 99% the same as in\nthe pseudo-code. It is coded in object-pascal (delphi 7) and includes a complete add-hoc\nphysical simulator.\nThe main differences with the general case came from the definition of distance between two\nstates and the reward function used.\n\n13 March 2018\n\n47\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n5.2.3.1 - Reward\nThe reward was the composition of two goals: keep alive -that correspond to the rocket health\nlevel (the simulator used the energy of the collisions to take health from the agent)- and the\nalready commented ‘hook reward’, so the actual reward was defined as:\nReward = Health_Level * Hook_Reward\n\n5.2.3.2 - Distance\nAny informative distance would have made the trick, but as this was a very physical example,\nwe decided to focus only on the position and momentum of the rocket to define its position,\nthus the distance used was:\nDist(A, B) = Sqrt( (A.x-B.x)^2 + (A.vx-B.vx)^2 + (A.y-B.y)^2 + (A.vy-B.vy)^2 )\nAdding the rest of the coordinates to the distance formula resulted in a lower performance. In\ngeneral, using a distance that makes sense in the problem helps. For the general case, using an\nembedding of the state can reduce its dimensionality and, as in any other method, helps to\nimprove efficiency.\n\n13 March 2018\n\n48\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n6 - Research topics\nWe will briefly comment on some of the research topic we find worth exploring.\n\n6.1 - Distributed computing\nThe algorithm time complexity is O(n) where n = num. walkers x num. ticks, but walkers work\nalmost independently -except for some inter-walker communication- and even\nasynchronously, so a parallel implementation of the algorithm, assigning one core per walker\ncan, in principle, lower the time complexity near to O(num. ticks).\nThus, adding more CPU can scale up the algorithm almost linearly but, eventually, the\ninter-processes communication overhead of sending system states from one walker to another\nwill impose a practical limit dependent, in practical terms, on the size of the system state.\nReached this point, a second distributed strategy is launching several fractal AI processes\n-workers- in a distributed environment, each one using a smaller number of walkers to output a\ndecision vector that will be averaged by the agent in order to make its decision. This ‘clustered’\ndecision is almost as reliable as using the sum of all walkers in a single fractal AI.\nBy adding the capability to reshuffle the states of all the walkers among the cluster of workers\nevery m steps, you can continuously change from totally isolated workers (m = number of total\nticks, no communication overhead) or totally connected workers (m = 1, overhead depending\non state size and simulation time).\nPlease note that the implementation included in the ​github repository​ at the e\n​ xperiment\nsection​ includes this parallel capabilities as an extra parameter.\n\n6.2 - Adding learning capabilities\n“One remembers the past to imagine the future’’\nDaniel L. Schacter\nAs we noted before, one of the limitations of the algorithm was dealing only with the\nforward-thinking process, so one natural research topic is mixing forward and\nbackward-thinking in a single process.\nThe presented algorithm scans all available actions at any given state with an uniform\nprobability distribution, it doesn’t have any ‘a priori’ preference, so the walks produced are\ntruly random.\n13 March 2018\n\n49\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nFractal AI algorithm could be used to feed examples of correct decisions -rollouts- to a neural\nnetwork that, in turn, would train itself to predict the intelligent decision -a probability\ndistribution over the actions- as a function of the state.\nWe can then use this as the ‘a priori’ distribution: when a walkers needs to randomly choose an\naction before simulating a delta of time, instead of choosing a random action, we can now\nsample it from this distribution.\nA mechanism like this could give the walkers a natural tendency to repeat actions that worked\nwell in the past on similar situations. Usually it means that, with the same number of walkers,\nyou can get better decisions or, inversely, that you can safely lower the number of walkers\nneeded to decide on situations that are familiar to the agent.\nIn the extreme case where the neural network can be considered well trained, you can\ncompletely disable walkers and decide by choosing the most probable action in the NN output.\nBy comparing the decision suggested by such a memory system with the one generated by the\nfractal AI algorithm -for the same initial state- we can estimate how accurate our a priori\ndistribution is, enabling us to dynamically adjust the ‘credibility’ of this distribution.\nTo get a simplified sketch of the idea we could:\n1) Define a function of the state that outputs a distribution over the actions: N(State) =\n(N​i​).\n2) When the algorithm ends, we were already getting a distribution (P​i​) over the available\nactions (the proportion of walkers associated with each action).\n3) We can know how similar they are: Credibility = D​H​(P​i​, N​i​) / D​H​(P​i​, Uniform).\n4) In the next iteration we can reduce the number of walkers to: Max_Walkers *\n(1-Credibility)\n5) In this next iteration, when walkers are building the random walks, they first get the ‘a\npriori’ distribution (N​i​) associated to its actual state, and mix it with the uniform\ndistribution (U​i​)=(1/N): (X​i​) = (N​i​)*Credibility + (U​i​)*(1-Credibility).\nThis mechanism opens the possibility of mixing fractal AI with any general learning method\n-like neural networks- in such a way that it can detect when the memory-based\nbackward-thinking “fast” decisions are good enough to replace the more expensive -in terms of\nCPU usage- forward-thinking decisions, allowing us to:\n1. Dynamically reduce the number of walkers used as the credibility of the distribution\ngets higher to speed up the process.\n2. Get better results over time using the same number of walkers.\n3. Generate a stand-alone fast policy (a standard neural network) to make decisions in\nabsence of walkers (backward-thinking only).\n\n13 March 2018\n\n50\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n6.2.1 - Using a DQN for learning\nDQN is a model of deep learning designed to learn the probability of the actions -expressed as\nreward expectation- as a function of the system state and as such it is a perfect match for\nFractal AI.\nIn one hand, Fractal AI is able to generate good quality game rollouts -sequences of pairs\nstate-action from previous games- without the need of a priori density of probabilities for\nactions, so it is able to feed the learning process of the DQN with meaningful game sequences\ninstead of random played ones, boosting the learning performance to some degree.\nIn the other hand, once the DQN has learned from a dataset of initial rollouts, Fractal AI can\nuse it output as a priori for randomly choosing an action at each walker step, making the\nfractal AI to scan more deeply those actions suggested by the DQN and thus, making fractal AI\nmore efficient and capable as the DQN learns to make better predictions.\nThis kind of combination is not new in the literature [​7​] but replacing UCT (a state-of-the-art\nimplementation of MCTS) with Fractal AI could improve the efficiency of the combo. A fair\ncomparison between both methods is presented in the ​experiments section​ showing that\nfractal AI can outperform UCT using about 0.01% to 0.1% of the samples per step.\n\n6.3 - Common Sense Assisted Control\nImagine a drone driven with Fractal AI, following the only goal of not crashing into anything.\nNow add a remote control that, when pushed forward, send an a priori probability over the\nactions where going forward is much more probable that all the other actions, in the same way\nthe DQN would be doing.\nThe Fractal AI will try to follow this direction, but only if this doesn’t go against its first goal of\nnot crashing into anything. The resulting drone will follow the control orders without crashing,\nallowing to fly it on difficult scenarios with easy and safety.\n\n6.4 - Consciousness\n“In any decision for action, when you have to make up your\nmind what to do, there is always a 'should' involved, and this\ncannot be worked out from, 'If I do this, what will happen?'\nalone.”\nRichard P. Feynman\n\n13 March 2018\n\n51\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nWhen the reward function is a composition of several goals {G​i​} we can assign a relative\nimportance {K​i​} for of each goal, having K​i​ ≥ 0 and Σ(K​i​)=1, so our reward function would looks\nlike this:\nReward(X) = 𝚷(G​i​(X)​Ki​)\nWe can consider the vector {K​i​} as being the “mental state” -as opposed to the physical state- of\nthe agent. Any mechanism that could automatically adjust those coefficients in order to make\nbetter decisions can be considered as a conscious mechanism.\nIf we consider those {K​i​} as being a second-level agent state, we can use them as both state\ncomponent and degrees of freedom, and apply the same Fractal AI algorithm to intelligently\nadjust them, as far as we can define a sensible reward associated with a mental state {K​i​}.\n\n6.5 - Real-time decision-making\n“Life is the continuous adjustment of internal relations to\nexternal relations.”\nHerbert Spencer\nThe need in the present implementation of resetting all the walkers to the new agent position\nafter a step is made, force us to erase valuable information, making the samples per step to be\nhigher than it could be.\nA slightly different implementation could lead to a continuous decision algorithm where a new\ndecision is generated for each tick of the algorithm -as opposed to each step of the agent- in a\ntotally continuous process, allowing to sample the decision at any time the agent needs it.\nIn this new implementation, each continuous decision would come with a measure of the\naverage delay between the agent time when the walkers started its path and the actual agent\ntime when the decision is used. A faster CPU would allow the algorithm to have a smaller delay,\nuse more walkers and paths, or think at a longer time horizon. A new parameter would be\nneeded to limit this delay below a desired value.\n\n6.6 - Universality pattern\n“Find beauty not only in the thing itself, but also in the pattern\nof the shadows, the light and dark which that thing provides”\nJunichiro Tanizaki\n\n13 March 2018\n\n52\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nIt would be interesting to connect the distances between walkers at any moment with the\n‘Universality pattern” found in the eigenvalues of random matrices. This pattern seems to be\nuniversal to any system where the parts are heavily correlated. In the pool of walkers it is the\ncase, so if this algorithm is some form of universal complex system solver, it makes sense to try\nto connect both ideas.\n\n13 March 2018\n\n53\n\n\fFractal AI: A Fragile Theory of Intelligence\n\n7 - Conclusions\nThe theory of intelligence introduced allowed us to build a very efficient agent that, in the\ndiscrete decision case, not only outperforms actual implementations of MTCS in at least three\norders of magnitude, but can also beat state-of-the-art learning based algorithms, like DQN or\nA3C neural networks, without the need of any previous learning or understanding of the\nsystem, by just inspecting the tree of decisions using entropy-based principles that boost\nexploration while producing a exploitation-exploration balanced decision in the process.\nThe algorithm can also be directly applied to continuous decision spaces, where it proved to be\nhighly efficiently, introducing Monte Carlo methods into a new spectrum of possible uses like\ndriving vehicles or controlling robots.\nThe algorithm naturally allows working with neural network in a close simbiosis where the NN\nlearns from the actions taken by the intelligence to produce a better a priori distribution over\nthe actions, that is then used by the intelligence to get better over time, that are learned by the\nNN closing a virtuous cycle. By doing so, actual reinforced learning methods could be reshaped\ninto a simpler and more efficient form of supervised learning.\n\n13 March 2018\n\n54\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nBibliography\n[1] Wissner-Gross, A. D., and C. E. Freer. “​Causal Entropic Forces​”. Physical Review Letters\n110.16 (2013). © 2013 American Physical Society.\n[2] Gottfredson, Linda S. (1997). \"​Mainstream Science on Intelligence: An Editorial With 52\nSignatories, History, and Bibliography​\". Intelligence. 24: 13–23. ISSN 0160-2896.\ndoi:10.1016/s0160-2896(97)90011-8.\n[3] Shane Legg, Marcus Hutter. “A Collection of Definitions of Intelligence”. ​Frontiers in\nArtificial Intelligence and Applications, Vol.157 (2007) 17-24, ​arXiv:0706.3639​ [cs.AI].\n[4] Cameron Browne, Edward Powley, Daniel Whitehouse, Simon Lucas, Peter I. Cowling,\nPhilipp Rohlfshagen, Stephen Tavener, Diego Perez, Spyridon Samothrakis and Simon Colton.\n“​A Survey of Monte Carlo Tree Search Methods​”. IEEE Transactions on computational\nintelligence and AI in games, Vol. 4, No. 1, March 2012.\n[5] Timothy Yee, Viliam Lisý, Michael Bowling, “​Monte Carlo Tree Search in Continuous Action\nSpaces with Execution Uncertainty​”. Proceedings of the Twenty-Fifth International Joint\nConference on Artificial Intelligence (IJCAI-16).\n[6] Christoph Salge, Cornelius Glackin, Daniel Polani (2013) “Empowerment -- an\nIntroduction”, ​arXiv:1310.1863​ [cs.AI].\n[7] Xiaoxiao Guo, Satinder Singh, Honglak Lee, Richard Lewis, Xiaoshi Wang, “​Deep learning for\nreal-time Atari game play using offline Monte-Carlo tree search planning​”, Advances in Neural\nInformation Processing Systems 27 (NIPS 2014).\n[8]Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A. Rusu, Joel Veness, Marc G.\nBellemare, Alex Graves, Martin Riedmiller, Andreas K. Fidjeland, Georg Ostrovski, Stig\nPetersen, Charles Beattie, Amir Sadik, Ioannis Antonoglou, Helen King, Dharshan Kumaran\n, Daan Wierstra, Shane Legg & Demis Hassabis (DeepMind Technologies), “​Human-level\ncontrol through deep reinforcement learning​”, Nature volume 518, pages 529–533 (26\nFebruary 2015), doi:10.1038/nature14236.\n[9] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou,\nDaan Wierstra, Martin Riedmiller (DeepMind Technologies), “Playing Atari with Deep\nReinforcement Learning”, ​arXiv:1312.5602​ [cs.LG].\n[10] “​Atari compendium​” (human world record list).\n\n13 March 2018\n\n55\n\n\fFractal AI: A Fragile Theory of Intelligence\n\nATARI experiment references\n●\n\n●\n\n●\n●\n\n●\n●\n\n●\n\n[A1]​ Guo, Xiaoxiao and Singh, Satinder and Lee, Honglak and Lewis, Richard L and\nWang, Xiaoshi. ​Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo\nTree Search Planning​.​ ​NIPS2014_5421​, 2014.\n[A2]​ Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and\nJohn Schulman and Jie Tang and Wojciech Zaremba. ​OpenAI Gym​ .​ ​arXiv:1606.01540​,\n2016.\n[A3]​ Marc G. Bellemare, Will Dabney Rémi Munos. ​A Distributional Perspective on\nReinforcement Learning​.​ ​arXiv:1707.06887​, 2017.\n[A4]​ Meire Fortunato, Mohammad Gheshlaghi Azar, Bilal Piot, Jacob Menick, Matteo\nHessel, Ian Osband, Alex Graves, Vlad Mnih, Remi Munos, Demis Hassabis, Olivier\nPietquin, Charles Blundell, Shane Legg. ​Noisy networks for exploration​.\narXiv:1706.10295​, 2018.\n[A5]​ Volodymyr Mnih & others. ​Human-level control through deep reinforcement\nlearning​.​ ​doi:10.1038/nature14236​, 2015.\n[A6]​ Matthias Plappert, Rein Houthooft, Prafulla Dhariwal, Szymon Sidor, Richard Y.\nChen, Xi Chen, Tamim Asfour, Pieter Abbeel, Marcin Andrychowicz. ​Parameter Space\nNoise for Exploration​.​ ​arXiv:1706.01905​, 2017.\n[A7]​ Tim Salimans, Jonathan Ho, Xi Chen, Szymon Sidor, Ilya Sutskever. ​Evolution\nStrategies as a Scalable Alternative to Reinforcement Learning​.​ ​arXiv:1703.03864​, 2017.\n\n13 March 2018\n\n56\n\n\f",
         "train",
         "81559",
         "13658"
        ],
        [
         "47",
         "20101",
         "cs.AI",
         "Artificial Intelligence",
         "1803.01252v1.pdf",
         "A Swift Heuristic Method for Work Order Scheduling under the\nSkilled-Workforce Constraint\nNima Safaeia, Corey Kiassatb\na Data\n\nScience and Analytics Lab, Global Banking and Marketing, Scotia Bank, Toronto, ON, Canada\n\nnima.safaei@scotiabank.com\nb Assistant\n\nProfessor of Industrial Engineering, Department of Engineering, Quinnipiac University,\n275 Mt. Carmel Avenue, Hamden, CT 06518, USA\ncorey.kiassat@qu.edu\n\nABSTRACT: The considered problem is how to optimally allocate a set of jobs to technicians of different\nskills such that the number of technicians of each skill does not exceed the number of persons with that\nskill designation. The key motivation is the quick sensitivity analysis in terms of the workforce size which\nis quite necessary in many industries in the presence of unexpected work orders. A time-indexed\nmathematical model is proposed to minimize the total weighted completion time of the jobs. The proposed\nmodel is decomposed into a number of single-skill sub-problems so that each one is a combination of a\nseries of nested binary Knapsack problems. A heuristic procedure is proposed to solve the problem. Our\nexperimental results, based on a real-world case study, reveal that the proposed method quickly produces\na schedule statistically close to the optimal one while the classical optimal procedure is very timeconsuming.\nKeywords: Scheduling Theory, Skilled-workforce, Knapsack problem, Heuristic method, Linear\nprogramming\n\nINTRODUCTION\nOrganizations frequently aim to optimally manage their available resources to minimize\noperations costs and maximize resource utilization and asset availability. The authors’\nexperiences from several research projects in the operations scheduling field show that\nmaintenance scheduling, given limited resources over a short planning horizon, is an important\nchallenge at the operational level; this agrees with a review paper by Mendez et al. (2006). In\nthese research projects, one of the most important maintenance resources is skilled workforce.\nMaintenance jobs are labour intensive, and the workforce performing these jobs is highly-paid as\na result of being extremely skilled in the respective areas.\nThe execution of the scheduling process has been a tedious and time-consuming job, and is\noften a highly intricate job when it deals with employees who have specific skills, job grade, and\nworking on different shift patterns. The Scheduling Problem under the Skilled-workforce\n\n1\n\n\fConstraint (SPSC) has wide applications in various industries to manage maintenance jobs and\nworkload. Scheduling of maintenance jobs associated with steel production machinery (Safaei et\nal., 2011a), military aircraft fleet (Safaei et al., 2011b), commercial aircraft (De Bruecker et al.,\n2015b) or power transmission equipment (Safaei et al. 2012b) are prominent examples where\nlimited labour resource and skilled-workforce availability is of great importance. Moreover,\nmultiple skills have gained a lot of attention in recent studies related to other fields (Heimerl and\nKolisch, 2010; De Bruecker et al., 2015a; De Bruecker et al., 2015b).\nOne difficulty with SPSC is how to handle the uncertainty due to unpredictable events such as\nunexpected equipment shutdown, power interruption or aircraft breakdown. These situations do\nnot commonly occur with a known pattern. Therefore, such uncertainty leads maintenance\nschedulers to seek a list of alternative schedules and various what-if scenarios under different\nworkforce sizes. This is especially true when a part of labour requirements may be satisfied\nthrough external resources. A further complication is the frequent usage of a built-in buffer of\nlabour for catastrophic failures or emergency situations. Therefore, there is a serious need in\nsome industries for a quick and efficient method to solve an SPSC and especially for a sensitivity\nanalysis on the skilled workforce availability (Keysan et al., 2010). For example, in military jets\nwhere we encounter daily missions and high frequency of unexpected faults, especially during\nwartime, sufficient labour resource should be available simultaneously in both flight line and\nrepair shop (Safaei et al. 2012b). Thus, the maintenance scheduler needs to know the possible\nwhat-if scenarios to exchange the labour between flight line and shop in the presence of\nunexpected failures. Likewise, the maintenance department in a steel production has to reprioritize the maintenance jobs, arriving from different manufacturing areas, and re-distribute\nthe technicians among different areas when a critical failure is reported (Safaei et al., 2011a). This\nresearch work is motivated by several research projects which have a strong reliance on having\nan efficient tool to quickly solve an SPSC with the aim of generating what-if scenarios and\nperforming the sensitivity analysis on the skilled-workforce availability. The reason for this\nreliance is frequent stochastic events in the form of unscheduled repair jobs.\nSPSC aims to match a series of jobs with a set of skills. Each job has certain requirements that\nare to be completed by various skills. The requirements consist of the processing time and the\nnumber of required technicians, assumed to be known in advance. The available number of\ntechnicians of each skill is also known and will remain fixed over the planning horizon. As pointed\nout earlier, the main constraint is the workforce availability per unit time. That is, the number of\ntechnicians of each skill required per unit time cannot exceed the number of persons available for\nthat skill, whilst all jobs must be completed by the end of the considered horizon. The jobs are\nassumed to have different weight/priority and the objective is to minimize the Total Weighted\nCompletion Time (TWCT) of all jobs. The problem is essentially NP-hard and, based on the\n\n2\n\n\fprevious experimental results, the computational efforts will progressively increase when the\navailable workforce size decreases, while the set of tasks remains the same (Safaei et al., 2011a).\nA comprehensive literature review on SPSC with a focus on the maintenance field can be\nfound in (Safaei et al., 2011a) and (Safaei et al., 2011b). In the former study, the authors consider\na bi-objective SPSC, associated with a steel production company, and formulate it using the flow\nnetwork with integral constraints. This is done to trace the workforce flow through the jobs. As\nsuch, Safaei et al. (2012a) propose a simulated annealing algorithm, with parallel architecture, to\nsolve their previous formulation (Safaei et al., 2012a). The aim is to generate the Pareto set of the\nalternative solutions. Their approach is able to produce near-optimal Pareto solutions in a\nreasonable time compared to the optimal Pareto set. However, this approach is not quick enough\nto be used as a robust post-optimization tool in the presence of unexpected events.\nCONTRIBUTION\nIn this paper, a heuristic approach is proposed to solve an SPSC within a very short period of time\nwhile the quality of solutions is significantly close to the optimal solution obtained by the classical\nmethods. To this end, we have a new perspective on SPSC in which the planning horizon is divided\ninto a number of nested subintervals so that each subinterval is thought of as a two-dimensional\nknapsack. The subintervals are arranged in such a way that the inner-most knapsack represents\nthe first time unit and the outer-most one represents the entire horizon. The capacity of each\nknapsack is equivalent to the available man-hours during the specific subinterval. As such, the\njobs are interpreted as bi-dimensional items comprising of labour requirement (human) and\nprocessing time (hour) as the two dimensions.\nIn our strategy, the minimization of TWCT imposes that items with higher priority be included\nin the inner-most knapsacks. Note that the above strategy differs from the classical\ndecomposition of Lagrangian relaxation problem (Fisher, 1981) in which each time period is\nconsidered as a separate 0-1 knapsack problem. Instead, the ‘nested’ concept is used to consider\nboth time and labour dimensions at the same time. Consequently, SPSC can be considered as a\ncrossover between the multi-dimensional and the multi-period knapsack problems, which makes\nthe proposed strategy quite a novel idea. This is due to the consideration of multiple skills as well\nas having each subinterval as a single period. SPSC might be converted to a specific kind of the\nKnapsack Problem (KP), such as multi-period KP (Faaland, 1981), multi-dimensional KP\n(Weingartner and Ness, 1967; Hill and Reilly, 2000); T-Constraint KP (Shih, 1979; Pirkul, 1987),\nor multiple KP with assignment restrictions (Dawande et al., 2000). In doing so, the applied\nsolution approaches cannot be directly used for the SPSC considered in this study because of its\nparticular structure that will be discussed in detail in the next section. SPSC can also be\nconsidered as a specific case of Resource-Constrained Project Scheduling Problem (RCPSP) with\n\n3\n\n\f‘Labour’ as a constant and renewable resource (Hartmann, 2000). However, the concept of ‘skill’\nas well as ‘TWCT’ as an objective makes it impossible to apply the solution methods of RCPSP to\nSPSC. Most methods have been developed to solve RCPSP considering the minimal Makespan\n(project duration) as the objective function. Moreover, some classical methods, such as Metra\npotential or critical path method, do not explicitly take into account the resource constraints\n(Sprecher et al., 1997). Others have been focused on specific characteristics of RCPSP such as\nmultiple modes, non-renewable resources, time-dependent resources and activity time-windows\n(Brucker et al., 1999; Brucker and Kunst, 2008). Therefore, it can be concluded that, due to the\nspecific characteristics of the SPSC considered in this study, the approaches introduced in the\nliterature to solve different kinds of KPs and different versions of RCPSP either cannot be\ncustomized to solve an SPSC or are not sufficiently quick and efficient to be used as a postoptimization tool.\nThe key idea behind the proposed heuristic method consists of two phases: at first, the SPSC\nis decomposed into a number of single-skill sub-problems such that each sub-problem is a\ncombination of a series of nested binary KPs. As a next step, a procedure, inspired by the Dantzig\nmethod (Dantzig, 1957), is developed to solve the sub-problems separately. The decision to use\nthe Dantzig method is due to the capability of representing the capacity constraints in KPs as a\nnested form. Using some propositions, we show how Danzig’s strategy can be simply applied to\nsolve the SPSC. The findings reveal that the combination of the partial solutions associated with\nthe sub-problems results in a high quality solution to the SPSC in a very short period of time.\nThe remainder of the paper is organized as follows. In Section 2, a time-indexed mathematical\nformulation for the SPSC is introduced. The knapsack formulation, as well as the extension of the\nDantzig method, is discussed in Section 3. The proposed solution approach is described in Section\n4. Finally, Section 5 verifies the performance of the proposed approach using a set of real data\nand also covers the related analysis.\nMATHEMATICAL FORMULATION\nIn this section, SPSC is formulated as a time-indexed 0-1 mathematical programming model to\nminimize TWCT. The following assumptions are adopted from a real life case study associated\nwith a steel company in Ontario, Canada (Safaei et al., 2011a). The company has a plant-wide\nscheduling approach through a central department to respond to maintenance work orders/jobs\nof various Manufacturing Areas (MAs) in the plant. The aim of this department is to minimize\nworkforce costs and to avoid long-term disruptions and shutdowns of the equipment within MAs.\nThe maintenance jobs are prioritized based on equipment criticality, order due date, and the\nseverity of failure, resulting in a normalized weight assigned to each job (Safaei et al., 2011a).\n\n4\n\n\fAssumptions\n1. Planning Horizon is assumed to be a countable finite set of T time units [t-1, t) where t = 1,\n2, ..., T. The jobs can only start at the beginning of time units, i.e., instances of time s = 0, 1,...,\nT-1. In our case, a weekly planning horizon consisting of five working days is considered.\nEach day has two consecutive 8-hour work shifts with an hour-long break between them.\n2. All submitted maintenance jobs are first prioritized to be scheduled over the upcoming day.\nThe goal is to complete all jobs by the end of the day. Jobs which cannot be scheduled over\nthe upcoming day are postponed to the following day as high priority jobs.\n3. Due to the high setup/preparation times, job pre-emption is not allowed.\n4. Setup time is built into job duration\n5. The number of available technicians of each skill designation is determined in advance and\nremains fixed over the upcoming day. Each technician may have different skills; however,\nhe/she is assigned to work within only one skill designation over the upcoming day.\n6. There is no precedence relationship among the skills to perform the jobs.\nInput parameters\nT\n\nlength of planning horizon in terms of a known time unit t, where t = 0,1,2,…,T\n\nM\n\nnumber of jobs, where m = 1,2,…,M\n\nK\n\nnumber of skills, where k = 1, 2,…,K\n\npmk\n\nprocessing time required for skill k to perform job m, where 0  pmk T\n\nmk\n\nrequired number of technicians of skill k to perform job m\n\nbk\n\navailable number of technicians of skill k over the planning horizon\n\nwm\n\nweight or priority of job m, where 0 < wm  1 and\n\n\n\nM\nm1\n\nwm  1\n\nDecision Variables\n\nymkt =1 if processing of job m is started at time instant t (or equivalently at the beginning of time\nunit t+1) by skill k; and equals zero otherwise.\n\nm\n\noverall completion time of job m by all associated skills, i.e., m  max cmk  , where\n1 k K\n\ncmk  pmk  t 0 tymkt represents the completion time of job m by skill k.\nT 1\n\nMathematical Model\nA Mixed-Integer Programming (MIP) formulation for the SPSC is:\n:\nM\n\nmin Z   wmm\n\n(1)\n\nm 1\n\n5\n\n\fs.t:\nT 1\n\nm  pmk   tymkt\nt 0\n\nT 1\n\ny\nt 0\n\nmkt\n\n \nM\n\nm1\n\n1\nt 1\ns  max0 ,t  pmk \n\n\n\nymks mk  bk\n\nm, k ; pmk  0\n\n(2)\n\nm , k ; pmk  0\n\n(3)\n\nk , 1  t  T\n\n(4)\n\nymkt  {0, 1}\n\nm, k , t\n\nThe objective function presented in (1) is to minimize TWCT of the jobs so that the overall\ncompletion time of each job by all associated skills is determined by (2). TWCT is used to minimize\nthe downtime of equipment due to maintenance or repair jobs (Safaei et al., 2011a). The term\n\n\n\nT 1\nt 0\n\ntymkt in (2) represents the start time of job m by skill k. Assignment constraint (3) imposes\n\nthe processing of job m by skill k must be started during the planning horizon. Inequality (4),\ninspired by the classical resource constraint in RCPSP, guarantees that the required number of\ntechnicians of skill k in each time-unit cannot exceed the total available number of technicians of\nthat skill, i.e., bk. The term\nt\n mk\n\n\n\n\nt 1\ns  max0,t  pmk \n\nymks\n\n\n\nt\nin (4) shows whether job m is being processed by skill k at time-unit t. That is,  mk\n 1 if job m is\n\nstarted within interval [max{0, t-pmk}, t). Assumption 2 imposes the following necessary feasibility\ncondition for ()\nM\n\nWk   pmk mk  T  bk ,\n\n(5)\n\nm1\n\nwhich means the total man-hours of skill k required to perform all jobs, Wk, cannot exceed the\navailable man-hours over the horizon, T×bk. Without loss of generality, we assume the input\ndatasets satisfy the condition above.\nFrom a practical point of view, Model  cannot be solved optimally in a reasonable amount of\ntime for real-sized instances. First of all,  is NP-hard since it is an MIP model (Garey and Johnson,\n1979). Moreover, P is an equality-constrained MIP (Eq. 3) and therefore  can also be categorized\nas an NP-complete problem due to the non-negativity requirement on y𝑚𝑘𝑡 (Aardal et al., 2000;\nAardal and Lenstra, 2002). It is worth mentioning that P is essentially a nonlinear integer\nprogramming problem when constraint (2) is removed and m  max cmk  directly embedded in\n1 k K\n\n(1) as 𝑍 = ∑𝑀\n𝑚=1 𝑤𝑚 max {𝑐𝑚𝑘 } . Consequently, the MIP formulation may be an alternative to\n1≤𝑘≤𝐾\n\nslightly reduce the problem complexity and to guarantee the optimal solution; however,\ncomputational time still remains a challenging issue for real size instances. One common\n\n6\n\n\falternative to achieve a lower bound on (1) is to decompose P into K subproblems in terms of\ndifferent skills. By applying the primary inequality\n\n max a   max  a  ; a\ni\n\nj\n\nij\n\ni\n\nj\n\nij\n\nij\n\n 0 on the\n\noriginal non-linear objective function, we get the following:\nM\nM\nM\n\nZ   wm max cmk    max wmcmk   max  wmcmk   max Zk  ,\n1 k K\n1 k K\n1 k K\nm 1\nm 1\nm  1\n 1k K\n\n(6)\n\nwhere Zk represents the weighted completion time of jobs by skill k so that maxk Zk  is an\nexplicit lower bound on Z. To calculate the components Zk,  can be decomposed into K singleskill sub-problems by relaxing (2), as follows:\n k:\n𝑇−1\nmin 𝑍𝑘 = ∑𝑀\n𝑚=1 𝑤𝑛 (𝑝𝑚𝑘 + ∑𝑡=0 𝑡𝑦𝑚𝑘𝑡 ),\n\n(7)\n\ns.t:\nT 1\n\ny\nt 0\n\nmkt\n\n \nM\n\nm1\n\nm ; pmk  0 ,\n\n1\nt 1\ns  max0 ,t  pmk \n\nymkt  {0, 1}\n\n\n\ny mks mk  bk\n\n(8)\n(9)\n\n1t T\n\nm, t .\n\n(Pk) is in fact a Generalized Assignment Problem (GAP) in which ik   m1 sgn( pmk )  M items\nM\n\nmust be assigned to T bins with respect to the capacity constraint (9). The sign function ‘sgn’\nequals 1 if pmk>0 and equals 0 otherwise. By dualizing constraint (8), (Pk) reduces to T 0-1 classical\nknapsack problem and the resulting Lagrangian relaxation problem can thus be solved in time\nproportional to T  ik  bk (Fisher, 1981). Hence, a lower bound on (1) can be obtained using an\nexact approach in time proportional to T\n\n ib\n\nk k k\n\n. Let xˆ k be the solution of (k) obtained by any\n\nˆ   xˆ , xˆ ,..., xˆ  is a feasible solution for (). According to (6), we have the\napproach so that X\n1\n2\nK\nfollowing:\nZ( Xˆ )  Z(X * )  max Zk  xˆ k  ,\n1 k K\n\nwhere X * is the global optimal solution for primary model . As a specific case, if xˆ k is the optimal\nsolution of k, we will get X *  Xˆ , when each job needs just one skill, i.e., for each m there is only\none k, where 𝑝𝑚𝑘 > 0.\nThe heuristic method proposed in this paper is aimed at obtaining the partial solutions\nxˆ k ; k  1, 2,..., K , so that the lower and upper bounds in the above inequality are tight enough\n\nwhere Z(Xˆ ) will be a good approximation on Z( X * ) . This benefit is due to “nested knapsacks’, the\n\n7\n\n\fkey idea behind the proposed method. Since the Dantzig method is a fast and near-optimal\nmethod for the classical KPs, the proposed nested strategy ensures the generated solution has the\nleast volatility to the problem characteristics such as size, variability of processing times, and skill\nrequirements. Thus, the lower and upper bounds in the above inequality are not affected by the\nproblem characteristics, as statistically verified through the computational experiences. Our\nfindings show that the computation effort of the proposed heuristic method is much less than the\ntime proportion T\n\n ib\n\nk k k\n\nwhile the optimality gap is not statistically significant. Thus, the\n\nproposed method can be used as a post-optimization tool to generate the list of what-if scenarios\nwith respect to the different levels of the workforce availability in a very short period of time.\nNESTED KNAPSACK FORMULATION FOR (k)\nBy extracting the constant part of Eq. (7), Q, we have:\nM\nT 1\nM T 1\nT 1 M\n\n M\nZk   wm  pmk   tymkt    wm pmk    wmt  ymkt  Q    wmt  ymkt .\nm1\nt 0\nm1 t 0\nt 0 m1\n\n m1\n\nHereafter, (7) is replaced by the reduced form\n\n  w t y\nT 1\n\nM\n\nt 0\n\nm1\n\nm\n\nmkt\n\n. In this reduced form, the\n\ncoefficient (wmt) is interpreted as the processing cost of job m, if it is started at time t. This\ncoefficient dictates that jobs with higher priorities should be scheduled in earlier time units to\nminimize Zk. Recalling the necessary feasibility condition (5), we can express (9) in another way.\nThat is, inequality (5) must hold for each subinterval [0, t), where 1tT, as follows:\nt 1 M\n\n  min p\ns 0 m1\n\nmk\n\n, t  s mk y mks  t  bk t\n\n(10)\n\nThis inequality, representing the nested form of capacity constraint (9), states that the total manhours required to handle the workload allocated to subinterval [0, t) cannot exceed the available\nlabour resource tbk, in which t is the length of the subinterval. According to the left side of (10),\nif job m is started somewhere within [0, t), i.e.,\n\n\n\nt 1\ns 0\n\nymks =1 , a part of its process with length\n\nmin{pmk, t-s+1} lies within [0, t). Inequality (10) is a special case of (5) in the extreme case of t=T,\nconsidering (8), and knowing that the allowable interval to start job m is [0, T-pmk]. Similar to (9),\ninequality (10) also considers job processing continuity and guarantees the required man-hours\nnot exceeding the available resources per unit time. Hence, (10) can replace (9) in Pk.\nInequality (10) in fact represents a series of capacity constraints for T Binary KPs (BKPs)\nassociated with the nested subinterval [0, t); 1tT. Subinterval [0, t) represents the tth knapsack\nwith capacity Ct = tbk (man-hour). In this case, job m occupies ams = min{pmk, t-s}mk units of\ncapacity of knapsack t, if it is started at time instant s[0, t). The objective of the tth KP is to place\n\n8\n\n\fthe most valuable workload in knapsack t, or equivalently to schedule the most important jobs\nwithin subinterval [0, t). The BKP associated with subinterval [0, t) is as follows:\nBKk(t):\nt 1 M\n\nmax v(t )    wm y mks ,\n\n(11)\n\ns 0 m1\n\ns.t:\nt 1 M\n\na\ns 0 m1\n\nms\n\ny mks  t  bk .\nm, s; s  0,..., t  1 .\n\nymks  {0, 1}\n\nUsing the following propositions, we show that subproblems BKk(t) can be simply solved\nthrough the Dantzig method.\nProposition 1: when t approaches T, ams becomes independent of index s, that is\nt  T  ams  pmkmk.\nProof: In general, the processing times of the jobs is supposed to be significantly smaller than the\nlength of the planning horizon, i.e, pmk T m,k. Hence, as t approaches T, ams gradually becomes\nindependent of index s and can be estimated by pmkmk \nProposition 2: According to Proposition 1, when t approaches T, BKk(t) can be rewritten\nindependently of index s, as follows:\nM\n\nBKPk (t ) : max  wm xmkt |s.t :\nm1\n\n\nM\n\np\n\nm1\n\n\n\nmk mk\n\n\n\n xmkt  t  bk ; xmkt  {0,1} \n\n\n\n(12)\n\nwhere xmkt  s0 ymks  1 if the processing of job m is started somewhere within [0, t). It equals 0\nt 1\n\notherwise.\nProposition 3: Dantzig method states that the optimal fractional solution to LP relaxation of\nProblem (12), LP-BKk(t), where the indices of xmkt (0≤ xmkt ≤1; ptmk>0 m) are arranged in nonincreasing order of the efficacy ratios wm  pmk mk  , is given by\nxmkt  1, if m  m0t\n\n(13)\n\nxmkt  0, if m  m0t\n\n\nxmkt   Ct   pnk nk \n\n\nn  m0h\n\n\nt\n\n pmk mk  , if m  m0t ,\n\nwhere m0 is the smallest integer 1  m0t  M for which\n\n\n\nmm0t\n\npmk mk  Ct , where Ct = tbk. If no\n\nm0t exists, then xmkt = 1 m. This indicates there is sufficient workforce capacity (of skill k) so that\n\n9\n\n\fthe whole workload can be included in knapsack t. If xmt kt  0 , then the resulting integer solution\n0\n\nis optimal for LP-BKk(t) and BKk(t), regardless of the non-assigned jobs m0t , m0t  1,..., M .\nProposition 3 reflects the idea of nested knapsacks, the key support behind the proposed solution\nprocedure.\nSOLUTION PROCEDURE\nIn this section, a fast heuristic method is proposed through Proposition (3) so that at each\niteration t, Problem (12) is solved using (13) for the jobs which have not been assigned in inner\nknapsack t – 1. Note that Proposition 3 is not always in line with objective TWCT. To minimize\nTWCT, by relaxing the resource constraints, i.e., 𝑏𝑘 → ∞, the jobs should be arranged in nonincreasing order of the efficacy ratios 𝑤𝑚 ⁄𝑝𝑚𝑘 so that 𝑤[1]⁄𝑝[1]𝑘 ≥ 𝑤[2]⁄𝑝[2]𝑘 ≥ ⋯ ≥ 𝑤[𝑀] ⁄𝑝[𝑀]𝑘 .\nIn this case, Proposition 3 will support TWCT if and only if 𝜆[1]𝑘 ≤ 𝜆[2]𝑘 ≤ ⋯ ≤ 𝜆[𝑀]𝑘 . Proposition\n3 simply states that, under the scenario 𝑤[1]⁄𝑝[1]𝑘 ≈ 𝑤[2]⁄𝑝[2]𝑘 ≈ ⋯, more resource-consuming\njobs should be scheduled later. This is intuitive as high resource-consuming jobs act as a\nbottleneck. To illustrate the issue, consider two typical jobs to be done by a given skill k where\n𝑝1𝑘 = 1, 𝜆1𝑘 = 5, 𝑤1 = 1; 𝑝2𝑘 = 2, 𝜆2𝑘 = 1, 𝑤2 = 1 and 𝑏𝑘 = 5. Considering Proposition 3, the\noptimal sequence is 2 ≻ 1 with 𝑇𝑊𝐹𝑇 = 1 × 2 + 1 × 3 = 5. However, using the efficacy ratios\n𝑤𝑚 ⁄𝑝𝑚𝑘 , the optimal sequence is 1 ≻ 2\n\nwith 𝑇𝑊𝐹𝑇 = 1 × 1 + 1 × 3 = 4. Therefore,\n\nproposition 3 produces a worse TWCT. By inserting a new job 𝑝3𝑘 = 2, 𝜆3𝑘 = 2, 𝑤3 = 1,\nproposition 3 produces the optimal sequence 1 ≻ 3 ≻ 2 with a much better TWCT rather than\nefficacy ratios 𝑤𝑚 ⁄𝑝𝑚𝑘 because jobs 1 and 3 can be scheduled simultaneously. Even though this\nstrategy may not be in line with TWCT; as our computational analysis reveals, the gap between\nthe optimal solution and our procedure remains relatively constant even if the problem size\nincreases and/or the workforce resource are tightened. This is the main advantage of our\nprocedure and is statistically inferred in Section 5.\nTo develop our procedure, we first revise (13) to cope with LP constraint xmkt {0, 1} . The\nfollowing is the result:\nt\n\nxmkt  1, if m  m0 ,\n\nt\n\nxmkt  0, if m  m0\n\nt\n\nwhere m0 is the largest integer 1  m0t  M for which\n\n(14)\n\n\n\nmm0t\n\npmk mk  Ct . Recall the reduced form\n\nof (7), coefficient (wmt) imposes that items with higher priorities should be scheduled in the\nearlier time units, resulting in the inner knapsacks having a higher priority to be packed.\nHowever, these inner knapsacks are practically interrelated due to (8), the nested nature of the\nsubintervals, and also the non-pre-emptive assumption. More precisely, each item m started at\n\n10\n\n\fthe beginning of time-unit s represents a workload equivalent to pmkmk man-hours. In this case,\nthe proportions {(r-s)/pmk} of the workload are included in the consecutively nested knapsacks\nr= s, s+1,..., and s+pmk-1 respectively. This is demonstrated in Figure 1 where job [3] is included in\nknapsacks 2, 3, and 4. Thus, a feasible strategy to solve (k) is to sequentially solve BKk(t); 1tT,\nstarting from the first time-unit. That is, at each iteration, the most valuable workload is placed\nin knapsack t, counting the workload already placed within inner knapsacks 1 to t-1. Note this\nstrategy dictates that if m  t and xmkt  1 , we have ymk ( t 1)  1 . This is because of the reasoning\nbehind coefficient (wmt) which enforces jobs to start at the earliest possible time. In Figure 1, Job\n[3] is scheduled at the earliest possible time t=2, since it cannot be included in the first knapsack.\nHence, without loss of generality, variable ‘y’ is substituted by ‘x’ in (12) and accordingly in (13)\nand (14) hereafter.\nWe have developed an extension of the Dantzig Method to implement the aforementioned\nstrategy. We have called this procedure the Extended Dantzig Method, or EDM for short. At each\niteration of EDM, BKk(t) is solved using (14). The feasible job indices at each iteration are those\n\n\n\n\n\nwhich have not been started yet. This is shown by the set  t  m| t 1 ymks  0 . Moreover, the\ns 0\ncapacity of the tth knapsack is updated as below with respect to the workload already assigned to\nthe inner knapsacks 1 to t-1.\nCt  t  bk  s0 m1 min pmk , t  s mk ymks\nt 1\n\nM\n\nt .\n\nThe main body of the procedure is as follows:\nPROCEDURE EDM:\nInitialize Ct = 0,  t   t ;\nFOR t = 1 TO T\na.\n\nCt  t  bk  s0 m1 min pmk , t  s mk ymks\nt 1\n\n\n\nM\n\n\n\nb. Set  t  m| t 1 ymks  0 and then sort the elements of  t in order of non-increasing\ns 0\nratios wm  pmk mk  . If t =  Then stop, Else go to step (c);\nc. According to (14), set ymkt values;\nNEXT t\nEND PROCEDURE\nIn Figure 1, five jobs numbered in a non-increasing order of ratios wm  pmk mk  have been\nscheduled sequentially using EDM procedure. It is assumed that bk = 6 people are available over\nthe planning horizon. The number within the boxes represents mk and the length of each box\n\n11\n\n\frepresents pmk. The grey dashed rectangles indicate the nested knapsacks t = 1, 2, 3, and 4 where\ntth knapsack has a capacity equal to 𝐶𝑡 = 𝑡 × 6.\n\nFigure 1. Schematic scheduling of five jobs using EDM\n\nThere is still a possibility to improve EDM by better utilizing the remaining capacity of the\nknapsacks due to the integrity property of ymks in (14). In other words, at each iteration of EDM,\nthe remaining capacity of the knapsack may still be used by a subset of jobs not selected by (14)\ndue to low efficacy. For example, in Figure 1, even though job (5) has the lowest efficacy, it can be\nselected at the first iteration to be placed in the first knapsack for improving (11). This will also\nlead to an improvement of (7). To consider this improvement in the EDM procedure, we conduct\na two-level strategy in which, at the first level, the jobs are selected in terms of their efficacy\nthrough (14). At the second level, some non-selected items might be picked with the aim of\nmaximizing the capacity utilization and accordingly improving (7). To consider this\nimprovement, (14) is changed to the following:\n ymkt  1, if  m  m0t    m t  \n\n\n,\n\nt\ny  0, if  m  m0    m t  \n\n mkt\n\n(15)\n\nwhere  t represents an optimal subset of Rt  m0t  1,..., M such that m pmk mk  t . Rt\nt\n\nrepresents the set of non-selected jobs and t represents the remaining capacity of knapsack t\nafter applying (14), where t  Ct  mmt pmk mk . Assuming t  min pmk  , there may be the\n1m M\n\n0\n\npossibility to fill the remaining capacity using the jobs belonging to  t .  t is obtained by solving\nthe following 0-1 KP with the objective of maximizing the capacity utilization.\n\nmax \n\nmRt\n\n\n\n\n\numk s.t: mR pmk mk umk  t ; umk  {0,1}\nt\n\numk =1 means mth element of Rt is assigned to the remaining capacity and 0 otherwise. Yet again\napplying (14) to solve the above sub-problem, the jobs belonging to Rt must be forced into\nknapsack t in non-decreasing order of values (pmkmk,) inasmuch as\n\n\n\nmRt\n\npmk mk  t . The\n\nimproved version of EDM procedure will be obtained by simply substituting (15) instead of (14)\nin Step (c). To solve (P), the EDM procedure is solved separately for each skill. The integration of\n\n12\n\n\fthe obtained partial schedules yields a near-optimal solution for (P) as will be demonstrated in\nthe next section.\nCOMPUTATIONAL EXPERIMENTS\nThe applicability and performance of the proposed solution procedure, EDM, is verified by 212\nbenchmark problems extracted from 35 original datasets associated with the case study\ndescribed in Section 2. The original datasets are randomly selected from a pool of historical\ndatasets, each of which represents the maintenance and repair jobs of different equipment in\nvarious MAs, submitted to the maintenance department during one week. Each benchmark\nproblem is obtained by perturbing an original dataset in terms of the workforce availability. The\nnumber of jobs and skills for original datasets ranges between [10, 229] jobs and [7, 34] skills.\nThe maintenance department is responsible for providing the labour resources with the required\nskills. These may come from internal and external sources and will perform the jobs while\nminimizing equipment downtime or equivalently minimizing TWCT of the jobs [1]. We use the\ntotal number of operations, OP   k 1  m1 sgn( pmk ) , as an indicator to measure the size of each\nK\n\nM\n\ndataset. Under the specific case, OP = M, each job needs just one skill and thereby () is simply\ndecomposed into K single-skill SPSC, as pointed out earlier.\nTo extract different benchmark problems, various levels of workforce availability are\nconsidered. That is, given a dataset consisting of M jobs and requiring K skills, (M, K), the possible\nminimum and maximum workforce requirements to perform all jobs by all skills are obtained as\nmax\n  k 1  m1 mk respectively. The benchmark scenarios are\nW min   k 1 max mk  and W\nK\n\nK\n\nM\n\n1 m  M\n\ngenerated assuming different levels of workforce availability for a given dataset as follows:\n\nA  (1   )W min  W max  ,\nwhere  = 0.01, 0.05, 0.1, 0,2, 0.3, 0.4, 0.5 . In fact, A represents a Sensitivity Analysis (SA) factor\nso that the smaller the value of , the smaller the workforce size available and therefore, more\ncomplicated scenario from a computational perspective due to the resource scarcity. More\nprecisely, considering 𝛼 ≤ 0.5, we focus on harder scenarios in order to better evaluate the\nperformance of the EDM.\nThrough this previously explained pre-processing, we try to keep the diversity of problems\nhigh enough in terms of workforce size, number of work orders, processing times and skill\nrequirements. The benchmark problems are optimally solved using the Branch-and-Bound (B&B)\nmethod embedded in LINGO 10.0 software on an x64-based DELL workstation with 8 Intel Xenon\nprocessors 2.0 GHz and 2 GB memory. The comparison between the B&B and EDM results are\nsummarized in Table 1 in which the optimal objective function value, Z*, is reported if it can be\n\n13\n\n\fachieved within 3 hours; otherwise, the best and lower bound values obtained in three hours, i.e.,\nZBEST and ZLB, will be reported. The CPU time of EDM is ignored since it is practically negligible\ncompared to the exact method, about 5 seconds in the worst case. In contrary, for medium and\nlarge size instances, B&B takes about several minutes to access the feasible space, especially when\nthe labour resource is reduced. The findings show that the percentage gap between Z* (ZBEST) and\nthe objective function value resulted from EDM, ZEDM, follows a Weibull distribution with shape\nparameter =0.83 and scale parameter =0.24, as graphically shown in Figure 2. This means the\n\n\n\n\n\naverage gap between the optimal solution and EDM is about  1  1   = 0.26% with a\n\n\n\nstandard deviation of about  2  1   2     2 1  1   \n\n\n\n\n\n1\n\n2\n\n=0.29. This is quite a satisfactory\n\noutcome, making EDM an efficient method to solve (). However, in very few cases, 3 out of 212,\nEDM failed to access the feasible space. That is, the completion time of some jobs exceed the\nplanning horizon length. While such a situation is common in practice, we theoretically consider\nit as an infeasible situation as long as B&B can produce a schedule bounded by the horizon length.\nThis assumption provides a fair comparison between our methodology and B&B. These three\ncases can be found as scenario numbers 164, 177, and 212 in Table 1.\n\nFigure 2. Relative frequency of gap between Z* (ZBEST) and ZEDM\n\nTo illustrate whether or not the size of the scenario affects the quality of the EDM, we arrange\nthe scenarios in a non-decreasing order of ratios  OP  K  A 0.1  (horizontal axis - Figure 3).\nThis ad-hoc ratio is used to achieve the maximum number of unique scale indices assigned to the\nscenarios. The correlation between the scenario scale and the relative gap is calculated to be\naround +0.21, indicating that there is no significant correlation between problem size and\nsolution quality of the EDM. In other words, increasing the problem size does not significantly\naffect the relative gap, as evident in Figure 3.\n\n14\n\n\fFigure 3. Correlation between the scenario size and the relative gap\n\nHowever, considering each individual dataset, decreasing the workforce size negatively\ninfluences both B&B CPU time and the relative gap, e.g., scenarios [110 to 115] or [137 to 143] in\nTable 1. Based on the empirical evidence, when the workforce size decreases, the computational\neffort for bound computations in B&B progressively increases. In fact, the smaller the workforce\nsize, the lesser the nodes in the decision tree of B&B are fathomed due to the existence of a weak\nbind. An important point here is that by reducing the workforce size, the feasible region is\ntightening intensively. As a consequence, finding a strong bind becomes more difficult especially\nwhen the penalization strategy is used to generate the bind. However, this behaviour is not always\ntrue, e.g., scenarios [148 to 150] or [195 to 197] in Table 1.\nThe workforce size reduction also has a negative effect on EDM; however, this is not always\nthe case, e.g., scenarios [173 to 176] in Table 1. The main reason is that skills are considered\nseparately in EDM. Hence, the negative effect of reducing the size of a given skill will not be\nrectified by other skills. To cope with this drawback, we need to consider a kind of interaction\nbetween single-skilled sub-problems, such as in Benders decomposition method. However, any\nimprovement in EDM significantly increases its computational effort that results in its inefficiency\nas a sensitivity analysis tool. This is not a major concern as we seldom encounter the worst case\nscenarios of the workforce unavailability in the real world.\nEven though the instances are coming from a single plant, they are actually related to\ncompletely different equipment types with various maintenance programs and failure modes.\nHaving this, in addition to enough permutations on workforce size generated using 𝐴𝛼 factor, the\ninstances are fairly distributed in terms of input parameters. Hence, our statistical analysis on the\nproposed EDM method can be extended to other similar industries with high confidence.\n\n15\n\n\fTable 1. Comparison between B&B and EDM\nProblem Info.\nNo.\nM\n1\n10\n2\n10\n3\n10\n4\n10\n5\n12\n6\n12\n7\n12\n8\n12\n9\n12\n10\n12\n11\n12\n12\n12\n13\n15\n14\n15\n15\n15\n16\n15\n17\n14\n18\n14\n19\n14\n20\n13\n21\n13\n22\n13\n23\n13\n24\n13\n25\n13\n26\n13\n27\n13\n28\n16\n29\n16\n30\n16\n31\n16\n32\n11\n33\n11\n34\n11\n35\n11\n36\n11\n37\n11\n38\n23\n39\n23\n40\n23\n41\n23\n42\n23\n43\n23\n44\n23\n45\n23\n46\n23\n47\n23\n48\n23\n49\n23\n50\n23\n51\n23\n52\n24\n53\n24\n54\n24\n55\n24\n56\n24\n57\n24\n58\n22\n59\n22\n60\n22\n61\n22\n62\n22\n63\n22\n64\n26\n65\n26\n66\n26\n67\n26\n68\n26\n69\n26\n70\n25\n71\n25\n72\n25\n73\n25\n74\n25\n75\n25\n76\n26\n77\n26\n78\n26\n79\n26\n\nOP\n11\n11\n11\n11\n12\n12\n12\n12\n14\n14\n14\n14\n15\n15\n15\n15\n16\n16\n16\n17\n17\n17\n17\n17\n17\n17\n17\n18\n18\n18\n18\n21\n21\n21\n21\n21\n21\n26\n26\n26\n26\n26\n26\n26\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n31\n31\n31\n31\n31\n31\n33\n33\n33\n33\n33\n33\n34\n34\n34\n34\n34\n34\n34\n34\n34\n34\n\nK\n7\n7\n7\n7\n6\n6\n6\n6\n8\n8\n8\n8\n7\n7\n7\n7\n13\n13\n13\n8\n8\n8\n8\n13\n13\n13\n13\n11\n11\n11\n11\n10\n10\n10\n10\n10\n10\n8\n8\n8\n8\n8\n8\n8\n12\n12\n12\n12\n12\n12\n12\n14\n14\n14\n14\n14\n14\n14\n14\n14\n14\n14\n14\n13\n13\n13\n13\n13\n13\n11\n11\n11\n11\n11\n11\n11\n11\n11\n11\n\nA (SA Factor)\n18\n16\n15\n14\n17\n16\n14\n13\n19\n18\n17\n16\n25\n22\n20\n16\n30\n29\n28\n25\n24\n22\n18\n32\n31\n29\n28\n27\n24\n23\n22\n23\n18\n17\n16\n14\n13\n28\n26\n23\n19\n16\n15\n14\n38\n33\n31\n27\n22\n21\n20\n38\n34\n33\n29\n27\n25\n36\n33\n31\n29\n24\n23\n32\n28\n26\n25\n21\n20\n35\n31\n28\n26\n24\n20\n38\n35\n32\n27\n\nBranch & Bound\nZLB\nZ* (ZBEST)\n78.4614\n78.5714\n78.5714\n79.3924\n36.8807\n37.0067\n37.0067\n40.0167\n61.9664\n61.9898\n62.0288\n62.2448\n57.8768\n57.9406\n60.176\n60.2163\n48.0565\n48.2815\n48.2815\n79.5361\n79.5859\n79.644\n79.7606\n63.9561\n64.0041\n64.0041\n64.0041\n30.5924\n30.9713\n31.1043\n31.4977\n41.935\n42.0535\n42.1604\n42.4125\n42.8782\n44.3441\n71.4546\n71.8932\n71.9103\n72.10845\n72.16155\n72.6108\n72.6925\n48.2528\n49.7256\n49.9312\n51.47185\n52.89388\n54.1766\n55.673\n68.6681\n68.6889\n68.7433\n69.0969\n69.2105\n69.4537\n43.6782\n43.8609\n43.9602\n44.4136\n45.3223\n46.64565\n33.7077\n33.8009\n33.8939\n34.0034\n34.5891\n35.2433\n64.1962\n64.2804\n64.7903\n65.7066\n66.7924\n67.6161\n51.3759\n52.427\n52.4861\n54.8165\n\nCPU (sec.)\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n4\n30\n3\n2\n1\n1\n1\n1\n1\n1\n1\n1\n1\n6\n13\n1\n1\n1\n1\n1\n5\n74\n1\n1\n1\n6\n1\n5\n1\n26\n1\n1\n\nEDM\nZEDM\n78.461403\n78.571404\n78.571404\n79.392403\n36.880699\n37.006699\n37.006699\n40.016701\n61.9664\n61.989799\n62.125198\n62.244801\n57.917198\n57.980999\n60.175999\n60.216301\n48.056499\n48.281502\n48.281502\n79.544403\n79.594193\n79.693787\n79.802094\n63.956089\n64.0041\n64.0041\n64.0041\n30.6084\n30.9713\n31.1043\n31.7451\n42.04591\n42.1299\n42.217701\n42.412498\n43.126202\n44.420502\n71.701103\n71.893204\n71.910301\n72.805\n72.8713\n72.878899\n72.941597\n48.287399\n49.866199\n50.066391\n52.059799\n53.072601\n54.252201\n55.982399\n68.671303\n68.708099\n68.772102\n69.096901\n69.447304\n69.6073\n43.738701\n43.866199\n43.982899\n44.4711\n45.3223\n46.646999\n33.835602\n33.954102\n34.111198\n34.167099\n34.801201\n35.373299\n64.285301\n64.429314\n64.914787\n65.731194\n67.005997\n67.713997\n51.376801\n52.426998\n52.486099\n54.817101\n\nGap (%)\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.16\n0.00\n0.07\n0.07\n0.00\n0.00\n0.00\n0.00\n0.00\n0.01\n0.01\n0.06\n0.05\n0.00\n0.00\n0.00\n0.00\n0.05\n0.00\n0.00\n0.79\n0.26\n0.18\n0.14\n0.00\n0.58\n0.17\n0.34\n0.00\n0.00\n0.97\n0.98\n0.37\n0.34\n0.07\n0.28\n0.27\n1.14\n0.34\n0.14\n0.56\n0.00\n0.03\n0.04\n0.00\n0.34\n0.22\n0.14\n0.01\n0.05\n0.13\n0.00\n0.00\n0.38\n0.45\n0.64\n0.48\n0.61\n0.37\n0.14\n0.23\n0.19\n0.04\n0.32\n0.14\n0.00\n0.00\n0.00\n0.00\n\n16\n\n\f80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n\n26\n26\n26\n31\n31\n31\n31\n31\n31\n31\n25\n25\n25\n25\n25\n25\n33\n33\n33\n33\n33\n33\n33\n34\n34\n34\n34\n34\n34\n34\n33\n33\n33\n33\n33\n33\n37\n37\n37\n37\n37\n37\n37\n28\n28\n28\n28\n28\n28\n28\n57\n57\n57\n57\n57\n57\n57\n61\n61\n61\n61\n61\n61\n61\n79\n79\n79\n79\n79\n79\n79\n101\n101\n101\n101\n101\n101\n101\n135\n135\n135\n135\n135\n135\n\n34\n34\n34\n34\n34\n34\n34\n34\n34\n34\n36\n36\n36\n36\n36\n36\n37\n37\n37\n37\n37\n37\n37\n38\n38\n38\n38\n38\n38\n38\n39\n39\n39\n39\n39\n39\n43\n43\n43\n43\n43\n43\n43\n48\n48\n48\n48\n48\n48\n48\n63\n63\n63\n63\n63\n63\n63\n71\n71\n71\n71\n71\n71\n71\n88\n88\n88\n88\n88\n88\n88\n105\n105\n105\n105\n105\n105\n105\n144\n144\n144\n144\n144\n144\n\n11\n11\n11\n8\n8\n8\n8\n8\n8\n8\n14\n14\n14\n14\n14\n14\n13\n13\n13\n13\n13\n13\n13\n10\n10\n10\n10\n10\n10\n10\n17\n17\n17\n17\n17\n17\n15\n15\n15\n15\n15\n15\n15\n13\n13\n13\n13\n13\n13\n13\n18\n18\n18\n18\n18\n18\n18\n15\n15\n15\n15\n15\n15\n15\n20\n20\n20\n20\n20\n20\n20\n17\n17\n17\n17\n17\n17\n17\n21\n21\n21\n21\n21\n21\n\n24\n22\n21\n38\n34\n30\n24\n20\n18\n16\n38\n32\n30\n26\n22\n19\n45\n42\n39\n33\n27\n26\n25\n38\n34\n30\n25\n21\n19\n17\n46\n41\n39\n36\n34\n32\n60\n57\n53\n45\n41\n38\n37\n45\n39\n36\n30\n27\n26\n23\n75\n66\n61\n52\n44\n42\n39\n61\n54\n46\n35\n28\n24\n21\n89\n76\n65\n52\n43\n35\n31\n114\n100\n85\n69\n55\n46\n40\n122\n107\n89\n73\n55\n45\n\n39.54251\n\n56.685\n58.472\n64.8353\n10.4042\n10.4362\n10.4614\n10.5136\n10.6225\n10.77937\n11.069\n31.0453\n32.1786\n32.6185\n32.724\n34.2363\n34.2898\n44.9073\n44.9935\n45.2286\n45.6858\n47.041\n47.6374\n48.0298\n62.63855\n62.71377\n62.9434\n63.4971\n64.1119\n64.6039\n65.5329\n63.6819\n65.3223\n65.3328\n65.371\n65.41\n65.5285\n49.50492\n49.7467\n50.4195\n51.6892\n52.87972\n53.9686\n54.28123\n38.8189\n38.8839\n38.9804\n39.2481\n39.6097\n39.6905\n40.6617\n51.4336\n52.08743\n52.51772\n53.91232\n55.7953\n56.8174\n59.723\n61.2602\n61.3916\n61.5675\n61.8864\n62.7714\n63.9092\n65.0649\n100.3176\n100.5283\n100.7591\n101.2413\n102.3672\n103.9585\n107.8838\n58.4826\n58.6375\n58.9591\n59.5387\n60.6508\n62.02551\n64.2455\n34.9864\n35.1233\n35.4633\n36.1151\n37.7061\n39.565\n\n1\n1\n1\n1\n1\n1\n1\n83\n2\n19\n1\n1\n1\n1\n1\n1\n1\n1\n2\n2\n3\n10\n23\n1\n1\n1\n1\n1\n2\n2\n1\n1\n1\n1\n1\n2\n1\n1\n7\n2\n2\n8\n107\n1\n1\n7\n142\n140\n644\n6176\n1\n1\n1\n1\n990\n681\n8140\n2\n45\n3\n6\n123\n173\n191\n4\n8\n3\n11\n1032\n44\n15579\n4\n6\n3\n43\n241\n699\n467\n5\n13\n22\n50\n140\n> 3 hrs\n\n58.4436\n58.4949\n70.191513\n10.4139\n10.4407\n10.4677\n10.5431\n10.6705\n10.785\n11.1622\n31.131201\n32.318001\n32.779301\n32.8848\n34.289799\n34.3433\n45.0257\n45.0257\n45.3088\n45.688\n47.335011\n47.7766\n48.141411\n62.644508\n62.779709\n62.976009\n63.4981\n64.140511\n64.603897\n65.859123\n63.686897\n65.352303\n65.365311\n65.419006\n65.448013\n65.6605\n49.865799\n49.978588\n50.47739\n51.689201\n53.077789\n53.97459\n54.478588\n38.909302\n39.056801\n39.200401\n39.450199\n39.880699\n40.0378\n40.940399\n51.532799\n52.223709\n52.769211\n54.728512\n56.460209\n57.70369\n60.132309\n61.288109\n61.432812\n61.5937\n61.89909\n63.021389\n64.010689\n65.444878\n100.34721\n100.56611\n100.83481\n101.38219\n102.56953\n104.04023\n108.45473\n58.612591\n58.762081\n59.10508\n59.67799\n60.92329\n62.484581\n65.363487\n35.025101\n35.208511\n35.54921\n36.2258\n37.847488\n39.820202\n\n3.10\n0.04\n8.26\n0.09\n0.04\n0.06\n0.28\n0.45\n0.05\n0.84\n0.28\n0.43\n0.49\n0.49\n0.16\n0.16\n0.26\n0.07\n0.18\n0.00\n0.63\n0.29\n0.23\n0.01\n0.11\n0.05\n0.00\n0.04\n0.00\n0.50\n0.01\n0.05\n0.05\n0.07\n0.06\n0.20\n0.73\n0.47\n0.11\n0.00\n0.37\n0.01\n0.36\n0.23\n0.44\n0.56\n0.51\n0.68\n0.88\n0.69\n0.19\n0.26\n0.48\n1.51\n1.19\n1.56\n0.69\n0.05\n0.07\n0.04\n0.02\n0.40\n0.16\n0.58\n0.03\n0.04\n0.08\n0.14\n0.20\n0.08\n0.53\n0.22\n0.21\n0.25\n0.23\n0.45\n0.74\n1.74\n0.11\n0.24\n0.24\n0.31\n0.37\n0.65\n\n17\n\n\f164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\n200\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n\n135\n132\n132\n132\n132\n132\n132\n141\n141\n141\n141\n141\n141\n141\n145\n145\n145\n145\n145\n145\n145\n152\n152\n152\n152\n152\n152\n152\n169\n169\n169\n169\n169\n169\n169\n201\n201\n201\n201\n201\n201\n201\n229\n229\n229\n229\n229\n229\n229\n\n144\n145\n145\n145\n145\n145\n145\n159\n159\n159\n159\n159\n159\n159\n160\n160\n160\n160\n160\n160\n160\n163\n163\n163\n163\n163\n163\n163\n181\n181\n181\n181\n181\n181\n181\n217\n217\n217\n217\n217\n217\n217\n248\n248\n248\n248\n248\n248\n248\n\n21\n25\n25\n25\n25\n25\n25\n29\n29\n29\n29\n29\n29\n29\n20\n20\n20\n20\n20\n20\n20\n23\n23\n23\n23\n23\n23\n23\n22\n22\n22\n22\n22\n22\n22\n28\n28\n28\n28\n28\n28\n28\n34\n34\n34\n34\n34\n34\n34\n\n38\n137\n114\n97\n79\n63\n46\n147\n126\n106\n87\n68\n56\n49\n147\n123\n102\n82\n60\n50\n39\n156\n134\n114\n92\n68\n58\n47\n164\n139\n116\n93\n68\n56\n46\n205\n174\n146\n115\n89\n74\n61\n254\n215\n179\n137\n104\n83\n66\n\n45.84522\n67.47359\n53.01927\n57.95624\n75.53397\n69.77254\n75.98684\n70.20005\n53.33973\n54.26741\n56.16489\n58.86389\n63.9224\n\n45.8867\n58.6599\n58.8208\n58.6599\n58.8208\n59.1084\n61.0297\n61.47041\n61.5696\n61.88495\n62.37121\n63.6624\n65.1911\n67.4839\n48.6565\n48.8381\n49.1908\n49.8687\n51.4081\n53.0252\n58.0672\n68.8081\n68.9753\n69.2349\n69.7629\n71.0437\n72.3003\n75.5825\n67.5518\n67.728\n67.9832\n68.4199\n69.7765\n71.2558\n76.0041\n65.8969\n66.0796\n66.38143\n67.30126\n68.5811\n70.2061\n73.8265\n52.6115\n52.8597\n53.3436\n54.2793\n56.16781\n58.8848\n64.0133\n\n> 3 hrs\n7\n9\n8\n9\n37\n68\n6\n119\n12\n15\n701\n> 3 hrs\n> 3 hrs\n11\n52\n437\n9863\n25371\n> 3 hrs\n> 3 hrs\n13\n156\n2942\n3480\n4933\n1573\n> 3 hrs\n11\n299\n1570\n2662\n> 3 hrs\n62792\n> 3 hrs\n136\n207\n12\n20\n23619\n> 3 hrs\n11130\n73\n21\n> 3 hrs\n> 3 hrs\n> 3 hrs\n> 3 hrs\n> 3 hrs\n\nN/A\n58.67989\n58.856499\n58.67989\n58.856499\n59.1745\n61.075489\n61.51598\n61.615971\n62.187\n62.76041\n63.788502\n65.272812\nN/A\n48.68819\n48.941078\n49.34079\n50.035702\n51.570789\n53.262699\n58.797199\n68.861481\n68.995491\n69.284691\n69.87291\n71.228104\n72.528023\n76.090736\n67.601112\n67.797791\n68.093102\n68.62178\n70.04612\n71.628502\n76.549423\n65.969887\n66.117493\n66.632683\n67.526192\n68.753708\n70.405617\n74.255943\n52.68362\n52.984501\n53.487801\n54.463711\n56.45932\n59.278702\nN/A\n\n0.03\n0.06\n0.03\n0.06\n0.11\n0.08\n0.07\n0.08\n0.49\n0.62\n0.20\n0.13\n0.07\n0.21\n0.30\n0.33\n0.32\n0.45\n1.26\n0.08\n0.03\n0.07\n0.16\n0.26\n0.31\n0.67\n0.07\n0.10\n0.16\n0.30\n0.39\n0.52\n0.72\n0.11\n0.06\n0.38\n0.33\n0.25\n0.28\n0.58\n0.14\n0.24\n0.27\n0.34\n0.52\n0.67\n-\n\nCONCLUSION\nIn this paper, we present a quick and efficient solution approach to solving the scheduling\nproblem under the skilled-workforce constraint. In this problem, a set of jobs must be performed\nby a set of skills, under the workforce size constraint. The proposed approach is an efficient postoptimization tool to conduct the sensitivity analysis as a critical requirement in many industries\nin which the availability of equipment and maintenance labour resource is a major concern in the\npresence of unexpected events.. A time-indexed 0-1 mathematical formulation is proposed along\nwith a heuristic solution approach to solve the model. The idea behind the heuristic approach\ncomes from the well-known Dantzig method proposed to solve the Knapsack problem (KP). At\nfirst, the proposed model is decomposed into a number of single-skill sub-problems where each\none can be presented as a series of nested Binary KP. Then, the Dantzig method is extended to\nsolve the sub-problems. A solution to the primary model is obtained by the integration of the\npartial schedules associated with these sub-problems. The findings reveal that the proposed\n\n18\n\n\fapproach is able to generate high-quality solutions very close to the optimal ones, in a short\namount of time, regardless of the problem size.\nThe performance of the approach is validated by a number of real datasets from a steel\nproduction company. The proposed approach can be used as a quick and efficient tool to conduct\nthe sensitivity analysis in terms of the workforce size as a necessity in maintenance department\nof many industries. Our heuristic can be developed as an add-in module for assisting maintenance\nsupervisors to quickly re-assign the workforce in the presence of unexpected work orders. Even\nthough there is no theoretical evidence to show that the heuristic method based on the skill\ndecomposition is an -approximation algorithm to the considered problem, we statistically show\nthat our proposed method is a -approximation algorithm.\nFurther developments of our approach will address the possibility of considering other\nfactors such as job pre-emption and inter-skill precedence relations. Job pre-emption most likely\nreduces the complexity of the problem since we no longer need to consider the nested strategy\nwhile each period of our planning horizon can be considered as an individual knapsack. The\nproposed model may be also extended within the framework of Robust Optimization so that the\ntasks’ processing times represent a disturbance quantity varying within a structured uncertainty\nset with an unknown pattern.\nREFERENCES\nAardal K., C. A. J. Hurkens, A. K. Lenstra. (2000) Solving a system of diophantine equations with\nlower and upper bounds on the variables. Math. Operations Research, 25, 427–442.\nAardal, K. and Lenstra, A.K. (2002) Hard Equality Constrained Integer Knapsacks, Lecture Notes\nin Computer Science (Integer Programming and Combinatorial Optimization), 2337, 350-366.\nBrucker, P., Drexl, A., Mohring, R., Neumann, K., and Pesch, E. (1999) Resource-constrained\nproject scheduling - Notation, classification, models and methods, European Journal of\nOperational Research, 112, 3-41.\nBrucker, P., and Knust, S., Complex Scheduling, New York: Springer, 2008.\nDantzig, G.B. (1957) Discrete Variable Extremum Problems, Operations Research, 5, 266-277.\nDawande, M., Kalagnanam, J., Keskinocak, P., Salman, F.S., and Ravi, R. (2000) Approximation\nAlgorithms for the Multiple Knapsack Problem with Assignment Restrictions, Journal of\nCombinatorial Optimization, 4 , 171-186.\nDe Bruecker, P., Van den Bergh, J., Beliën, J., and Demeulemeester, E. (2015a) Workforce planning\nincorporating skills: state of the art. European Journal of Operational Research, 243(1), 1-16.\nDe Bruecker, P., Van den Bergh, J., Belien, J., and Demeulemeester, E. (2015b). A two-stage mixed\ninteger programming approach for optimizing the skill mix and training schedules for aircraft\nmaintenance. Available at SSRN 2697491.\n\n19\n\n\fFaaland, B.H. (1981) The Multiperiod Knapsack Problem, Operations Research 29, 612-616.\nFisher, M. (1981) The Lagrangian Relaxation Method for Solving Integer Programming Problems.\nManagement Science, 27, 1-18.\nGarey, M. R. and Johnson, D. S. (1979) Computers and Intractability: A Guide to the Theory of NPCompleteness, W. H. Freeman and Company, New York.\nHartman, S. (2000) Packing Problems and Project Scheduling Models - An Integrating Perspective,\nJournal of Operational Research Society, 51, 1083-1092.\nHeimerl, C., and Kolisch, R. (2010). Scheduling and staffing multiple projects with a multi-skilled\nworkforce. OR spectrum, 32(2), 343-368.\nHill, R.R., and Reilly, C.H. (2000) The Effects of Coefficient Correlation Structure in TwoDimensional Knapsack Problems on Solution Procedure Performance, Management Science, 46,\n302-317.\nKeysan, G., Nemhauser, G.L. and Savelsbergh, M.W.P. (2010) Tactical and Operational Planning of\nScheduled Maintenance for Per-Seat, On-Demand Air Transportation, Transportation Science, 44,\n291-306.\nMendez, C.A., Cerda, J., Grossmann, I.E., Harjunkoski, I, Fahl, M. (2006). State-of-the-art Review of\nOptimization Methods for Short-term Scheduling of Batch Processes. Computers and Chemical\nEngineering, 30, 913-946.\nPirkul, H. (1987) A Heuristic Solution Procedure for the Multiconstraint Zero-One Knapsack\nProblem, Naval Research Logistics, 34, 161-172.\nSafaei, N., Banjevic, D., and Jardine, A.K.S. (2011a) Bi-objective Workforce-constrained\nMaintenance Scheduling: A Case Study, Journal of Operational Research Society, 62, 1005–1018.\nSafaei, N., Banjevic, D., and Jardine, A.K.S. (2011b) Workforce-constrained Maintenance\nScheduling for Military Aircraft Fleet: A Case Study, Annals of Operations Research, 186, 295-316.\nSafaei, N., Banjevic, D., and Jardine, A.K.S. (2012a) Multi-Threaded Simulated Annealing for a Biobjective Workforce-constrained Maintenance Scheduling Problem, International Journal of\nProduction Research, 50, 1-18.\nSafaei, N., Banjevic, D., and Jardine, A.K.S. (2012b) Workforce Planning for Power Restoration in\nElectricity Delivery Industry: an Integrated Simulation-Optimization Approach, IEEE\nTransactions on Power Systems, 27, 442-449.\nShih, W. (1979) A Branch and Bound Method for the Multiconstraint Zero-One Knapsack Problem,\nJournal of the Operational Research Society, 30, 369-378.\nSprecher, A., Hartman, S., and Drexl, A. (1997) An exact algorithm for project scheduling with\nmultiple modes, OR Spektrum, 19, 195-203.\nWeingartner, H.M., and Ness, D.N. (1967) Methods for the Solution of the Multidimensional 0/1\nKnapsack Problem, Operations Research, 15, 83-103.\n\n20\n\n\f",
         "train",
         "53337",
         "9590"
        ],
        [
         "48",
         "18082",
         "cs.AI",
         "Artificial Intelligence",
         "1711.05509v1.pdf",
         "Note on Representing attribute reduction and\nconcepts in concepts lattice using graphs\n\narXiv:1711.05509v1 [cs.AI] 15 Nov 2017\n\nJan Konecny\nDept. Computer Science, Palacky University, Olomouc\n17. listopadu 12, CZ-77146 Olomouc, Czech Republic\n\nAbstract. Mao H. (2017, Representing attribute reduction and concepts in concept lattice using graphs. Soft Computing 21(24):7293–7311)\nclaims to make contributions to the study of reduction of attributes in\nconcept lattices by using graph theory. We show that her results are either trivial or already well-known and all three algorithms proposed in\nthe paper are incorrect.\n\nKeywords: Clarification; Reduction; Formal Context; Graph; Formal concept\nenumeration\n\n1\n\nIntroduction\n\nMao (2017) claims that she studies attribute reduction and formal concept enumeration in Formal Concept Analysis (FCA) with the aid of Graph Theory.\nWe show, that the use of the Graph Theory is trivial. Specifically, Mao simply\nreplaces the notion of formal context by an equivalent notion of pre-weighted\nrelevant graph and presents well-known and trivial facts as novel and interesting. Additionally, Mao provides a method of enumeration of formal concepts in\na reduced formal context. The method is represented by three algorithms; we\ndemonstrate, using examples, that they are incorrect.\n\n2\n\nPreliminaries\n\nWe use the same notions and the same notations as Mao (2017); however we\nneed to also recall a few notions from (Ganter and Wille, 1999) to explain our\ncase. Thus, for the reader’s convenience, we provide full preliminaries.\nAn input to FCA is a triplet (O, P, I), called a formal context, where O, P are\nfinite non-empty sets of objects and attributes, respectively, and I is a binary\nrelation between O and P ; (o, a) ∈ I means that the object o has the attribute\na. Finite formal contexts are usually depicted as tables, in which rows represent\nobjects, columns represent attributes, and each entry contains a cross if the\ncorresponding object has the corresponding attribute, and is otherwise left blank\n(see top parts of Figures 3–5 for examples).\nThe formal context induces the following operators:\n\n\f↑ : 2O → 2P assigns to a set X of objects the set X ↑ of all attributes shared\nby all the objects in X.\n↓ : 2P → 2O assigns to a set B of attributes the set B ↓ of all objects which\nshare all the attributes in B.\nFor singletons we use shortened notation and write o↑ , a↓ instead of {o}↑ , {a}↓ ,\nrespectively.\nFormal concept is a pair (X, B) of sets X ⊆ O, B ⊆ P , s.t. X ↑ = B and\n↓\nB = X. The first component of a formal concept is called extent, the second\none is called intent. A collection of all formal concepts in (O, P, I) is denoted\nB(O, P, I). The collection B(O, P, I) with order ≤ defined by (X1 , B1 ) ≤ (X2 , B2 )\nif X1 ⊆ X2 for all formal concepts (X1 , B1 ), (X2 , B2 ) ∈ B(O, P, I), forms a\ncomplete lattice called a concept lattice.\nWe call a computation of B(O, P, I) a formal concept enumeration.\nWe consider the following two binary relations on P induced by a formal\ncontext:\n– dependency ⊑, defined by a ⊑ b if a↓ ⊆ b↓ for all a, b ∈ P ,\n– equivalence ≡, defined by a ≡ b if a↓ = b↓ for all a, b ∈ P .\nFormal context (O, P, I) is called clarified if a1 ≡ a2 implies a1 = a2 for any\na1 , a2 ∈ P ; i.e. if it does not contain duplicate columns. Removal of duplicate\ncolumns (keeping one representative of each ≡-class) is called a clarification.\nAn attribute a is called reducible in formal context (O, P, I) if there is Z ⊆\nP \\{a} such that a↓ = Z ↓ (equivalently, if B(O, P, I) and B(O, P \\{a}, I ∩(O×P \\\n{a})) are isomorphic). Formal context is reduced if it has no reducible attributes.\nRemoval of reducible attributes is called a reduction. Ganter and Wille (1999)\nprovide efficient method for clarification and reduction.\nOriginally for Rough Set Theory, Pawlak (1982) proposed three types of attributes. These types were introduced into FCA by Zhang et al (2005). We omit\ntheir definitions and just explain their relationship to the reducible and irreducible attributes: absolutely necessary (core) attributes are exactly irreducible\nattributes; relatively necessary attributes are those reducible attributes that become irreducible when their duplicates are removed; and absolutely unnecessary\nattributes are those which are neither absolutely nor relatively necessary.\n\n3\n\nThe use of Graph Theory is trivial and the results are\nnot novel\n\nMao (2017) claims to propose a method of attribute reduction which utilizes\nGraph Theory and is based on removing vertices from a particular graph; this\nshould distinguish her method from other known approaches (Ganter and Wille,\n1999; Zhang et al, 2005) which are based on the removal of attributes.\nSpecifically, she introduces a so-called pre-weighted relevant graph G(O, P, I)\n(derived from a formal context (O, P, I)) as a graph with vertices being the\nattributes in P and edges being given as follows: for a, b ∈ P and a 6= b,\n\n\f– if x↓ = y ↓ there is a bi-arc joining x and y, i.e. x ⇔ y,\n– if x↓ ⊂ y ↓ there is an arc joining y to x, i.e. x → y.\nThus, G(O, P, I) is basically (O, P, I) with the relations ⊑ and ≡ (specifically,\nthe arcs → correspond to pairs in ⊑ \\ ≡ and the bi-arcs ⇔ correspond to non\nreflexive pairs in ≡). This represents the entire utilization of Graph Theory in\nMao’s work.\nMao describes the attribute reduction in three steps (see Fig. 1):\n(1) For an input formal context (O0 , P0 , I0 ) satisfying\no↑ 6= ∅ and a↓ 6= ∅ for all o ∈ O, a ∈ P\nthe formal context (O1 , P1 , I1 ) is found by removing full-row objects and\nfull-column attributes from (O0 , P0 , I0 ).\n(2) For (O1 , P1 , I1 ) find context (O2 , P2 , I2 ) by clarification.\n(3) For (O2 , P2 , I2 ) find context (O3 , P3 , I3 ) by reduction.\n\n(O0 , P0 , I0 )\n(1) remove full-column attributes\nand full-row columns\n(O1 , P1 , I1 )\n(2) remove duplicate attributes\n(clarification)\n(O2 , P2 , I2 )\n(3) remove reducible attributes\n(reduction)\n(O3 , P3 , I3 )\nFig. 1. Three phase process of attribute reduction in Mao (2017).\n\nAt best, Mao’s results could be considered to show how to use precomputed\nrelations ⊑ and ≡ to achieve better time complexity. However there are two\nproblems with it.\n– First, the relations are used the same way as in (Ganter and Wille, 1999)\n(where they are not precomputed), or they present a trivial improvement.\nAs an example of the latter, Theorem 3.1 characterizes objects with full\nrow. The theorem states that we need not check whether the object has all\nattributes, instead we can just check those that are minimal w.r.t. ⊑.\n– Second, if the complexity is taken into account, it should be said that the\ncomputation of ≡ and ⊑ for (O, P, I) requires the same time as entire clarification and reduction using classic methods described in basic literature\n\n\f(Ganter and Wille, 1999). Mao does not mention the complexity of the computation of ≡ and ⊑ neither does she refer to the classic methods.\nSubstitution of the basic notions with the equivalent newly introduced notions is Mao’s main resource for results. Instead of removal attributes from\n(O, P, I) she removes the corresponding vertices from G(O, P, I). Rephrased,\nusing basic notions of FCA, the results become trivial or are already well-known.\nSpecifically, Theorem 3.2 states that duplicate attributes are reducible, which\nis obvious. Theorem 3.3 states that in the clarified context (O2 , P2 , I2 ) no attributes are relatively necessary, which is obvious because (O2 , P2 , I2 ) is obtained\nby clarification of the context (O1 , P1 , I1 ). Theorem 3.4 is an overcomplicated\ncharacterization of reducible attributes, which after a straightforward simplification becomes the one by Ganter and Wille (1999). Theorem 3.5 states, that\nin the reduced context (O3 , P3 , I3 ) all attributes are irreducible, which again is\nobvious, because (O3 , P3 , I3 ) is obtained by reduction of (O2 , P2 , I2 ). Finally,\nTheorems 3.6 and 3.7 explain trivial relationships between Pawlak’s types of\nattributes in P0 , P1 , P2 , and P3 .\n\n4\n\nThe proposed algorithms are incorrect\n\nMao Mao (2017) proposes a method of computing formal concepts in (O, P, I);\nmore specifically, a subset A containing all formal concepts excluding the top\nand the bottom concepts of B(O, P, I) and the attribute concepts.\nHer method consists of three algorithms which each compute different portions of A with the aid of a pre-weighted relevant graph; their input is a preweighted relevant graph and a maximal attribute c1 .\n1. The algorithm 1 computes a set F containing those concepts (A, B) ∈ A\n+\n(c1 ) (see Fig. 2 (top)).\nwhich satisfy c1 ∈ B and b ∈\n/ B for all b ∈ NG(O,P,I)\n2. The algorithm 2 computes a set S containing those concepts (A, B) ∈ A\n+\nwhich satisfy c1 ∈ B and b ∈ B for some b ∈ NG(O,P,I)\n(c1 ) (see Fig. 2 (middle)).\n3. The algorithm 3 computes a set T containing those concepts (A, B) ∈ A\nwhich satisfy c1 ∈\n/ B (see Fig. 2 (bottom)).\n+\nNG(O,P,I)\n(c1 ) in items 1. and 2. denotes the lower cone of attribute c1 w.r.t. ⊑,\nexcluding c1 itself.\nAll three algorithms are described in a very complicated way which makes\nthem almost unreadable. More importantly, they are incorrect. In what follows,\nwe present the examples in which the algorithms fail to deliver correct outputs.\nWe need to recall some additional notation from (Mao, 2017):\n\n– V →a denotes the upper cone of attribute c w.r.t. ⊑, excluding a itself;\n– ω(a) denotes the pre-weight of a, i.e. ω(a) = a↓ .\n\n\fc1\n•\n\nb1\n•\n\nb2\n•\n\nc1\n•\n\nb1\n•\n\nb2\n•\n\nc1\n•\n\nb1\n•\n\nb2\n•\n\nFig. 2. Portions of concept lattice computed by the algorithm 1 (top), algorithm 2 (middle), and algorithm 3 (bottom)\n\n\fc1 c2 b n\n1×\n2× ×\n3 × ××\n4\n×\n\nc1 {1, 2, 3}\n\nc2 {3, 4}\n\nb\n\nn ∅\n\n{1, 3}\n\nFig. 3. A formal context (top) and its pre-weighted relevant graph (bottom) as an\nexample for algorithm 1\n\n4.1\n\nExample for algorithm 1\n\nConsider the formal context depicted in Fig. 3 (top).\nWe demonstrate that the algorithm 1 fails to deliver correct output for its preweighted relevant graph (Fig. 3 (bottom)) and attribute c1 . We have C = {c1 , c2 }\n+\nand NG(O,P,I)(c\n= {b, n}. The following represents how the algorithm runs\n1)\nwhen we exactly follow the steps in Mao (2017).\n(step 1)\n+\nH1 = {x ∈ P \\ {c1 } |x ∈\n/ NG(O,P,I)\n(c1 )\n\nand ω(c1 ) ∩ ω(x) 6= ∅} = {c2 }.\nAs H1 6= ∅ is the case, we select h1 ∈ H1 . There is only one option, thus we set\nh1 := c2 . We compute extent A1 and B1 as\nA1 = ω(c1 ) ∩ ω(c2 ) = {3} and B1 = {c1 , c2 }.\nAs H1 \\B1 = ∅, the condition of non-existence of h ∈ H1 \\B1 with ω(c1 )∩ω(c2 ) ⊂\nω(h) is trivially satisfied, and (A1 , B1 ) is outputted.\n(step 2) As |H1 | = 1 we stop the computation.\nWe obtained a pair ({3}, {c1, c2 }) as an output, but this pair is not a formal\nconcept. If we close it, we obtain ({3}, {c1 , c2 , b}) which should not be in F , since\nit contains b.\n\n\f1\n2\n3\n4\n5\n6\n\nc1 c2 c3 b\n×\n× ×\n× × ×\n×\n××\n×\n×\n×\n\nc1 {2, 3, 4, 5}\n\nc2 {1, 2, 3}\n\n{3, 4}\n\nc3 {4, 5, 6}\n\nb\n\nFig. 4. A formal context (top) and its pre-weighted relevant graph (bottom) as an\nexample for algorithm 2\n\n4.2\n\nExample for algorithm 2\n\nConsider the formal context depicted in Fig. 4 (top).\nWe demonstrate that algorithm 2 fails to deliver the correct output for its\npre-weighted relevant graph (Fig. 4 (bottom)) and attribute c1 . We have that\n+\nC = {c1 , c2 , c3 } and NG(O,P,I)\n(c1 ) = {b}.\n(step 6) We set b1 := b as it is the only option; and we compute\nHb1 = {c2 , c3 }.\n(step 7) We have Hb1 6= ∅. We select d1 := c2 . We compute\nAb1 : = ω(b1 ) ∩ ω(d1 ) = ω(b) ∩ ω(c2 ) = {3},\nBb1 : = {b1 , d1 } ∪ V3→b1 ∪ V3→d1 = {b, c2 } ∪ {c1 } ∪ ∅\n= {b, c1 , c2 }.\nWe continue with Case 2 because c3 , the only element in Hb1 \\ Bb1 , does not\n+\n(b) = ∅;\nsatisfy Ab1 ⊂ ω(c3 ). The rest of this step is trivial since NG(O,P,I)\n(Ab1 , Bb1 ) is outputted.\n(step 8) We set d11 = c2 , d12 = c3 . And compute\nA1d1 = ω(b1 ) ∩ ω(d11 ) ∩ ω(d12 ) = ω(b) ∩ ω(c2 ) ∩ ω(c3 ) = ∅.\nSince A1d1 is empty the algorithm stops.\nThe algorithm terminated without outputting a formal concept ({4}, {c1, c3 , b}),\nwhich belongs to S.\n\n\f4.3\n\nExample for algorithm 3\n\nThe third algorithm uses the previous two algorithms. Even if algorithm 1 and\nalgorithm 2 were correct, algorithm 3 would be still incorrect, and this is shown\nfor the formal context depicted in Fig. 5 (top), its pre-weighted relevant graph is\nin Fig. 5 (bottom), and its attribute c1 .\n\nc1 c2 c3 b\n1\n×\n2× × ×\n3× × ×\n4×\n×\n5\n×\n\nc1 {2, 3, 4}\n\nc2 {1, 2, 3}\n\n{2}\n\nc3 {3, 4, 5}\n\nb\n\nFig. 5. A formal context (top) and its pre-weighted relevant graph (bottom) as an\nexample for algorithm 3\n\n(step 15) C := C \\ {c1 } = {c2 , c3 };\n+\nG(O, P, I) := G(O, P, I) \\ (c1 ∪ NG(O,P,I)\n(c1 ));\n\n(1)\n\ni.e. G(O, P, I) now contains only vertices c2 and c3 .\n(step 16) We use algorithms 1 and 2 for updated graph G(O, P, I) and c2 . It is\nnot clear whether (1) includes removal of c1 from P :\n– If yes, we get ({3}, {c2 , c3 }) as one of the outputs of algorithm 1 and 2, but\nit is not a formal concept\n– If no, we get ({3}, {c1 , c2 , c3 }) as one of the outputs of algorithm 1 and 2,\nbut it does not belong to T .\nEither way, we obtain a wrong output.\n4.4\n\nBogus complexity analysis\n\nAs the method of formal concept enumeration is incorrect, we could simply\ndisregard its complexity analysis, however, even then there is a problem which\nneeds mentioning.\n\n\fIn the description of both, attribute reduction and formal concept enumeration, Mao uses steps which perform intersections and/or comparisons of preweights, i.e. subsets of the set O. In the accompanied complexity analysis, she\nclaims complexity of these steps to be O(|P |2 ) or O(|P |3 ); i.e independent of\nthe size of the subsets or the size of O. This could be actually achieved if all the\nintersections of pre-weights were precomputed, however, a collection of all the\nintersections is, in fact, the collection of all extents. As each extent uniquely determines its formal concept, this assumption means that Mao’s method of formal\nconcept enumeration requires all formal concepts to be precomputed.\nTo sum up, either the claimed complexities are incorrect, or Mao works from\nan assumption that makes the actual computation superfluous.\n\n5\n\nConclusion\n\nIn (Mao, 2014), Mao substituted the concept-forming operators with seemingly\ndifferent operators which produced simple matroids instead of ordinary sets.\nConsequently, she presented well-known facts and trivial facts in a complicated\nway to make them look novel and interesting. This was exposed by Konecny\n(2015).\nWe have shown that she does the same in (Mao, 2017). Mao provides nothing\nnew. Her theoretical results are either trivial or well-known and the proposed\nalgorithms are incorrect.\n\nAcknowledgments\nSupported by grant No. 15-17899S, “Decompositions of Matrices with Boolean\nand Ordinal Data: Theory and Algorithms”, of the Czech Science Foundation.\n\n\fBibliography\n\nGanter B, Wille R (1999) Formal Concept Analysis – Mathematical Foundations.\nSpringer\nKonecny J (2015) Note on the characterization and reduction of concept lattices\nthrough matroid theory. Inf Sci 307:110–112, DOI 10.1016/j.ins.2015.02.007\nMao H (2014) Characterization and reduction of concept lattices through matroid theory. Inf Sci 281:338–354, DOI 10.1016/j.ins.2014.05.044\nMao H (2017) Representing attribute reduction and concepts in concept lattice using graphs. Soft Computing 21(24):7293–7311, DOI https://doi.org/10.\n1007/s00500-016-2441-2\nPawlak Z (1982) Rough sets. International Journal of Computer & Information\nSciences 11(5):341–356\nZhang W, Wei L, Qi J (2005) Attribute reduction theory and approach to concept\nlattice. Science in China Series F-Information Sciences 48(6):713, DOI https:\n//doi.org/10.1360/122004-104\n\n\f",
         "train",
         "15653",
         "2915"
        ],
        [
         "49",
         "18601",
         "cs.AI",
         "Artificial Intelligence",
         "1802.00048v2.pdf",
         "Deceptive Games\nDamien Anderson1 , Matthew Stephenson2 , Julian Togelius3 , Christoph Salge3 ,\nJohn Levine1 , and Jochen Renz2\n\narXiv:1802.00048v2 [cs.AI] 4 Feb 2018\n\n1\n\n2\n\n3\n\nComputer and Information Science Department, University of Strathclyde,\nGlasgow, UK,\nDamien.Anderson@strath.ac.uk\nResearch School of Computer Science, Australian National University, Canberra,\nAustralia\nNYU Game Innovation Lab, Tandon School of Engineering, New York University,\nNew York, USA\n\nAbstract. Deceptive games are games where the reward structure or\nother aspects of the game are designed to lead the agent away from a\nglobally optimal policy. While many games are already deceptive to some\nextent, we designed a series of games in the Video Game Description\nLanguage (VGDL) implementing specific types of deception, classified\nby the cognitive biases they exploit. VGDL games can be run in the\nGeneral Video Game Artificial Intelligence (GVGAI) Framework, making\nit possible to test a variety of existing AI agents that have been submitted\nto the GVGAI Competition on these deceptive games. Our results show\nthat all tested agents are vulnerable to several kinds of deception, but\nthat different agents have different weaknesses. This suggests that we can\nuse deception to understand the capabilities of a game-playing algorithm,\nand game-playing algorithms to characterize the deception displayed by\na game.\nKeywords: Games, Tree Search, Reinforcement Learning, Deception\n\n1\n1.1\n\nIntroduction\nMotivation\n\nWhat makes a game difficult for an Artificial Intelligence (AI) agent? Or, more\nprecisely, how can we design a game that is difficult for an agent, and what can\nwe learn from doing so?\nEarly AI and games research focused on games with known rules and full\ninformation, such as Chess [1] or Go. The game-theoretic approaches [2] to these\ngames, such as min-max, are constrained by high branching factors and large\ncomputational complexity. When Deep Blue surpassed the top humans in Chess\n[3], the game Go was still considered very hard, partly due to its much larger\nbranching factor. Also, the design of Arimaa [4], built to be deliberately difficult\nfor AI agents, relies heavily on an even higher branching factor than Go.\nBut increasing the game complexity is not the only way to make games more\ndifficult. To demonstrate this we will here focus on old arcade games, such as\n\n\fSokoban, Dig Dug or Space invaders, which can be implemented in VGDL. Part\nof the motivation for the development of VGDL and GVGAI was the desire\nto create a generic interface that would allow the same AIs to play a range\nof different games. GVGAI competitions have been held annually since 2013,\nresulting in an openly accessible corpus of games and AI agents that can play\nthem (with varying proficiency).\nVGDL games have relatively similar game complexity: the branching factor\nis identical (there are six possible actions) and the game state space is not too\ndifferent between games because of the similar-sized levels. Yet, if we look at\nhow well different agents do on different games we can see that complexity is\nnot the only factor for game difficulty. Certain games seem to be very easy,\nwhile others are nearly impossible to master for all existing agents. These effects\nare still present if the agents are given considerably more time which could\ncompensate for complexity [5]. Further analyses also shows that games cannot\neasily be ordered by difficulty, as agents based on different types of algorithms\nseem to have problems with different games—there is a distinct non-transitivity\nin performance rankings [6]. This raises the question of what makes a game\ndifficult for a specific agent but not for others?\nOne way to explain this is to consider that there are several methods for constructing agents to play games. One can train a function approximator to map\nfrom a state observation to an action using reinforcement learning algorithms\nbased on approximate dynamic programming (the temporal difference family of\nmethods), policy gradients or artificial evolution; alternatively, and complementary, if you have a forward model of the game you can use tree search or evolution\nto search for action sequences that maximize some utility [7]. Additionally, there\nare hybrid algorithms combining elements from several of these methods, such\nas the very successful AlphaGo[8] system which combines supervised learning,\napproximate dynamic programming and Monte Carlo Tree Search.\nA commonality between these game-playing methods is that they rely on\nrewards to guide their search and/or learning. Policies are learned to maximize\nthe expected reward, and when a model is available, action sequences are selected\nfor the same criterion. Fortunately, rewards are typically well-defined in games:\ngaining score is good, losing lives or getting hurt is bad. Indeed, one of the\nreasons for the popularity of games as AI testbeds is that many of them have\nwell-defined rewards (they can also be simulated cheaply, safely and speedily).\nBut it’s not enough for there to be rewards; the rewards can be structured in\ndifferent ways. For example, one of the key problems in reinforcement learning\nresearch, credit allocation, is how to assign reward to the correct action given\nthat the reward frequently occurs long after the action was taken.\nRecently, much work has gone into devising reinforcement learning algorithms\nthat can learn to play simple arcade games, and they generally have good performance on games that have short time lags between actions and rewards. For\ncomparison, a game such as Montezuma’s Revenge on the Atari 2600, where\nthere is a long time lag between actions and rewards, provides a very hard challenge for all known reinforcement learning algorithms.\n\n\fIt is not only a matter of the time elapsed between action and reward; rewards\ncan be more or less helpful. The reward structure of a game can be such that\ntaking the actions the lead to the highest rewards in the short-to-medium term\nleads to lower overall rewards, i.e. playing badly. For example, if you spend all\nyour time collecting coins in Super Mario Bros, you will likely run out of time.\nThis is not too unlike the situation in real life where if you optimize your eating\npolicy for fat and sugar you are likely to achieve suboptimal global nutritional\nreward. Designing a reward structure that leads an AI away from the optimal\npolicy can be seen as a form of deception, one that makes the game harder,\nregardless of the underlying game complexity. If we see the reward function as a\nheuristic function approximating the (inverse) distance from a globally optimal\npolicy, a deceptive reward function is an inadmissible heuristic.\n1.2\n\nBiases, deception and optimization\n\nIn order to understand why certain types or agents are weak against certain\nkinds of deceptions it is helpful to consider different types of deception through\nthe lens of cognitive biases. Deceptive games can be seen as exploiting a specific cognitive bias4 of the (human or AI) player to trick them into making a\nsuboptimal decision. Withholding or providing false information is a form of\ndeception, and can be very effective at sabotaging a player’s performance. In\nthis paper though, we want to focus on games where the player or AI has full\naccess to both the current game state and the rules (forward model). Is it still\npossible to design a game with these constraints that tricks an artificial agent?\nIf we were facing an agent with unlimited resources, the answer would be no, as\nunbounded computational resources makes deception impossible: an exhaustive\nsearch that considers all possible action sequences and rates them by their fully\nmodeled probabilistic expected outcome will find the optimal strategy. Writing\ndown what a unbounded rational agent should do is not difficult. In reality, both\nhumans and AI agents have bounded rationality in that they are limited in terms\nof computational resources, time, memory, etc.\nTo compensate for this, artificial intelligence techniques rely on approximations or heuristics that are easier to compute and still return a better answer\nthan random. In a naive interpretation, this seems to violate the free lunch theorem. This is still a viable approach though if one only deals with a subset of all\npossible problems. These assumptions about the problems one encounters can\nbe turned into helpful cognitive biases. In general, and in the right context, this\nis a viable cognitive strategy - one that has been shown to be effective for both\nhumans and AI agents [9,10]. But reasoning based on these assumptions also\nmakes one susceptible to deceptions - problems that violate this assumption and\nare designed in a way so that the, now mistaken, assumption leads the player\nto a suboptimal answer. Counter-intuitively, this means that the more sophisticated an AI agent becomes, the better it is at exploiting typical properties of\n4\n\nTo simplify the text we talk about the game as if it has agency and intentions; in\ntruth the intentions and agency lies with the game’s designer, and all text should be\nunderstood in this regard.\n\n\fthe environment, the more susceptible it becomes to specific deceptions based\non those cognitive biases.\nThis phenomenon can be related to the No Free Lunch theorem for search\nand optimization, which implies that, given limited time, making an agent perform better on a particular class of search problems will make it perform worse\non others (because over all possible search problems, all agents will perform the\nsame) [11]. Of course, some search algorithms are in practice better than others,\nbecause many “naturally occurring” problems tend to fall in a relatively restricted class where deception is limited. Within evolutionary computation, the\nphenomenon of deceptive optimization problems is well-defined and relatively\nwell-studied, and it has been claimed that the only hard optimization problems\nare the deceptive ones [12,13].\nFor humans, the list of cognitive biases is quite extensive, and subsequently,\nthere are many different deception strategies for tricking humans. Here we focus\non agent which have their own specific sets of biases. Identifying those cognitive\nbiases via deceptive games can help us to both categorize those agents, and help\nus to figure out what they are good at, and on what problem they should be\nused. Making the link to human biases could also help us to understand the\nunderlying assumptions humans use, enabling us to learn from human mistakes\nwhat shortcuts humans take to be more efficient than AIs.\n1.3\n\nOverview\n\nThe rest of this paper is structured as follows. We first outline some AI-specific\ndeceptions based on our understanding of current game-playing algorithms. We\npresent a non-exhaustive list of those, based on their assumptions and vulnerabilities. We then introduce several new VGDL games, designed to specifically\ndeceive the existing AI algorithms. We test a range of existing agents from the\nGVGAI framework on our new deceptive games and discuss the results.\n\n2\n2.1\n\nBackground\nCategories of Deception\n\nBy linking specific cognitive biases to types of deception we can categorize different deceptive games and try to predict which agents would perform well on them.\nWe can also construct deceptive games aimed at exploiting a specific weakness.\nThe following is a non-exhaustive list of possible AI biases and their associated\ntraps, exemplified with some of the games we present here.\nGreed Trap: A common problem simplification is to only consider the effect\nof our actions for a limited future. These greedy algorithms usually aim to maximize some immediate reward and rely on the assumption that the local reward\ngradient will guide them to a global maximum. One way to specifically exploit\nthis bias (a greedy trap) is to design a game with an accumulated reward and\n\n\fthen use some initial small reward to trick the player into an action that will\nmake a later, larger reward unattainable. The later mentioned DeceptiCoins and\nSister Saviour are examples of this. Delayed rewards, such as seen in Invest and\nFlower, are a subtype. In that case, an action has a positive reward that is only\nawarded much later. This can be used to construct a greedy trap by combining\nit with a smaller, more immediate reward. This also challenges algorithms that\nwant to attach specific rewards to actions, such as reinforcement learning.\nSmoothness Trap: Several AI techniques also rely on the assumption that\ngood solutions are “close” to other good solutions. Genetic Algorithms, for example, assume a certain smoothness of the fitness landscape and MCTS algorithms\noutperform uninformed random tree search because they bias their exploration\ntowards branches with more promising results. This assumption can be exploited\nby deliberately hiding the optimal solutions close to a many really bad solutions.\nIn the example of DeceptiZelda the player has two paths to the goal. One is a\ndirect, safe, low reward route to the exit which can be easily found. The other is\na long route, passing by several deadly hazards but incurring a high reward if the\nsuccessful route is found. Since many of the solutions along the dangerous part\nlead to losses, an agent operating with the smoothness bias might be disinclined\nto investigate this direction further, and would therefore not find the much better solution. This trap is different from the greedy trap, as it aims at agents that\nlimit their evaluation not by a temporal horizon, but by only sampling a subset\nof all possible futures.\nGenerality Trap: Another way to make decision-making in games more manageable, both for humans and AI agents, is to generalize from particular situations. Rather than learning or determining how to interact with a certain object\nin every possible context, an AI can be more efficient by developing a generalized\nrule. For example, if there is a sprite that kills the avatar, avoiding that sprite as\na general rule might be sensible. A generality trap can exploit this by providing\na game environment in which such a rule is sensible, but for few critical exceptions. WafterThinMints aims to realize this, as eating mints gives the AI points\nunless too many are eaten. So the agent has to figure out that it should eat a\nlot of them, but then stop, and change its behavior towards the mints. Agents\nthat would evaluate the gain in reward greedily might not have a problem here,\nbut agents that try to develop sophisticated behavioral rules should be weak to\nthis deception.\n2.2\n\nOther deceptions\n\nAs pointed out, this list is non-exhaustive. We deliberately excluded games with\nhidden or noisy information. Earlier GVGAI studies have looked at the question\nof robustness [14], where the forward model sometimes gives false information.\nBut this random noise is still different from a deliberate withholding of game\n\n\finformation, or even from adding noise in a way to maximize the problems for\nthe AI.\nWe should also note that most of the deceptions implemented here are focused on exploiting the reward structure given by the game to trick AIs that\nare optimized for actual rewards. Consider though, that recent developments in\nintrinsically motivated AIs have introduced ideas such as curiosity-driven AIs to\nplay games such as Montezuma’s Revenge [15] or Super Mario [16]. The internal\ncuriosity reward enhances the AI’s gameplay, by providing a gradient in a flat\nextrinsic reward landscape, but in itself makes the AI susceptible to deception.\nOne could design a game that specifically punished players for exploration.\n\n3\n3.1\n\nExperimental Setup\nThe GVGAI Framework\n\nThe General Video Game AI competition is a competition focused on developing AI agents that can play real-time video games; agents are tested on unseen\ngames, to make sure that the developer of the agent cannot tailor it to a particular game [17]. All current GVGAI games are created in VGDL, which was\ndeveloped particularly to make rapid and even automated game development\npossible [18]. The competition began with a single planning track which provided\nagents with a forward model to simulate future states but has since expanded\nto include other areas, such as a learning track, a rule generation track, and a\nlevel generation track [19].\nIn order to analyze the effects of game deception on GVGAI agent performance, a number of games were created (in VGDL) that implemented various\ntypes of deception in a relatively “pure” form. This section briefly explains the\ngoal of each game and the reasons for its inclusion. In order to determine whether\nan agent had selected the rational path or not, requirements were set based on\nthe agent’s performance, which is detailed in this section also.\n3.2\n\nDeceptiCoins (DC)\n\nThe idea behind DeceptiCoins is to offer agents two options for which path to\ntake. The first path has some immediate rewards and leads to a win condition.\nThe second path similarly leads to a win condition but has a higher cumulative\nreward along its path, which is not immediately visible to a short-sighted agent.\nOnce a path is selected by the agent, a wall closes behind them and they are no\nlonger able to choose the alternative path.\nIn order for the performance of an agent to be considered rational in this\ngame, the agent must choose the path with the greatest overall reward. In figure\n1, this rational path is achieved by taking the path to the right of the agent, as\nit will lead to the highest amount of score.\nTwo alternative levels were created for this game. These levels are similar in\nhow the rules of the game work, but attempt to model situations where an agent\n\n\fFig. 1. The first level of De- Fig. 2. The second level Fig. 3. The third level of DeceptiCoins\nof DeceptiCoins\nceptiCoins\n\nmay get stuck on a suboptimal path by not planning correctly. Level 2, shown in\nfigure 2, adds some enemies to the game which will chase the agent. The agents\nneed to carefully plan out their moves in order to avoid being trapped and losing\nthe game. Level 3, shown in figure 3 has a simple path which leads to the win\ncondition, and a risky path that leads to large rewards. Should the agent be too\ngreedy and take too much reward, the enemies in the level will close off the path\nto the win condition and the agent will lose.\nThe sprites used are as follows:\n–\n–\n–\n–\n\nAvatar - Represents the player/agent in the game.\nGold Coin - Awards a point if collected.\nG Square - Leads to winning the game when interacted with.\nPiranha - Enemies, if the avatar interacts with these, the game is lost.\n\nThe rational paths for level 2 and 3 are defined as reaching the win condition\nof the level, while also collecting a minimum amount of reward (5 for level 2 and\n10 for level 3).\n3.3\n\nDeceptiZelda (DZ)\n\nDeceptiZelda looks at the risk vs reward behavior of the GVGAI agents. As in\nDeceptiCoins, two paths are presented to the agent, with one leading to a quick\nvictory and the other leading to a large reward, if the hazards are overcome.\nThe hazards in this game are represented as moving enemies which must either\nbe defeated or avoided.\nTwo levels for this game were created as shown in figure 5 and figure 4. The\nfirst level presents the agent with a choice of going to the right, collecting the\nkey and exiting the level immediately without tackling any of the enemies. The\nsecond path leading up takes the agent through a hazardous corridor where they\nmust pass the enemies to reach the alternative goal. The second level uses the\nsame layout but instead of offering a win condition, a lot of collectible rewards\nare offered to the agent, who must collect these and then return to the exit.\n\n\fFig. 4. The first level of Deceptizelda\n\nFig. 5. The second level of Deceptizelda\n\nThe sprites used are as follows:\n–\n\nAvatar: Represents the player/agent in the game.\n\n–\n\nSpider: The enemies to overcome. If defeated awards 2 points.\n\n–\n\nKey: Used to unlock the first exit. Awards a point if collected.\n\n–\n\nGold Coin: Awards a point to the agent if collected.\n\n–\n\nClosed Door: The low value exit. Awards a point if moved into.\n\n–\n\nOpen Door: The high value exit. Awards 10 points if moved into.\n\nThe rational path for this game is defined as successfully completing the\npath with the most risk. In the first level, this is defined as achieving at least 10\npoints and winning the game. This can be done by taking the path leading up\nand reaching the exit beyond the enemies. The second level of DeceptiZelda is\nplayed on the same map, but instead of offering a higher reward win condition,\na large amount of reward is available, and the agent has to then backtrack to\nthe single exit in the level. This level can be seen in figure 5.\n3.4\n\nButterflies (BF)\n\nButterflies is one of the original games for the GVGAI that prompted the beginning of this work. This game presents a situation where if the agent aims for\nthe win condition too quickly, they will lower their maximum potential score for\nthe level. The goal of the game is simple; collect all of the butterflies before they\nreach their cocoons, which in turn creates more butterflies. To solve the game\nall that is required is that every butterfly is collected. Each collected butterfly\ngrants a small reward to the agent. If the agent is able to defend a single cocoon\nand wait until all other cocoons have been spawned, there will be the maximum\nnumber of butterflies available to gain reward from. So long as the last cocoon\n\n\fFig. 6. The first level of Butterflies\n\nis not touched by a butterfly, the game can still be won, but now a significantly\nhigher score is possible. The level used is shown in figure 6.\nThe sprites used are as follows:\n–\n\nAvatar: Represents the player/agent in the game.\n\n–\n\nButterfly: Awards 2 points if collected.\n\n–\n\nCocoon: If a butterfly interacts with these, more butterflies are created.\n\nThe rational path for Butterflies is defined as any win condition with a final\nscore over 30. This is achieved by allowing more than half of the cocoons to be\nspawned and then winning the level.\n3.5\n\nSisterSaviour (SS)\n\nThe concept of SisterSaviour was to present a moral choice to the agent. There\nare 3 hostages to rescue in each level, and a number of enemies guarding them,\nas shown in figure 7. It is not possible for the agent to defeat these enemies\nimmediately. The agent is given a choice of either rescuing the hostages or killing\nthem. If the agent chooses to rescue the hostages they receive a small reward\nand will be able to defeat the enemies, which grants a large point reward. On the\nother hand, if the agent chooses to kill the hostages, they are granted a larger\nreward immediately, but now lack the power to defeat the enemies and will lose\nthe game.\nThe sprites used are as follows:\n–\n–\n\nAvatar: Represents the player/agent in the game.\n\nScorpion: An enemy which chases the avatar. Immune to attacks from\nthe avatar, unless all of the hostages have been rescued. Awards 14 points if\ndefeated.\nHostage: Can be either killed, by attacking them or rescued by moving\n–\ninto their space. Awards 2 points if killed, and 1 point if rescued. If all are\nrescued then the avatar can kill the enemy.\n\n\fFig. 7. The first level of SisterSaviour\n\nFig. 8. The first level of Invest\n\nThe rational path for SisterSaviour is defined as reaching a score of 20. This\ninvolves rescuing all of the hostages, by moving the avatar onto their space, and\nthen defeating the enemy.\n\n3.6\n\nInvest (Inv)\n\nInvest looks at the ability of a GVGAI agent to spend their accumulated reward,\nwith the possibility of receiving a larger reward in the future. This game is\nshown in figure 8. The agent begins with a set number of points which need\nto be collected from the level, which can then be spent on investment options.\nThis is done by moving onto one of the 3 human characters to the north of the\nlevel. Investing will deduct an amount from their current score, acting as an\nimmediate penalty, and will trigger an event to occur at a random point in the\nfuture where the agent will receive a large score reward. Should the agent invest\ntoo much, and go into a negative score, then the game is lost, otherwise, they\nwill eventually win. The interesting point of this game was how much reward\nthey accumulate over the time period that they have, and would they overcome\nany loss adversity in order to gain higher overall rewards?\nThe sprites used are as follows:\n–\n\nAvatar: Represents the player/agent in the game.\n\n–\n\nGold Coin: Awards a point when collected.\n\n–\n\nGreen Investment: Takes 3 points when moved onto, returns 8.\n\n–\n\nRed Investment: Takes 7 points when moved onto, returns 15.\n\n–\n\nBlue Investment: Takes 5 points when moved onto, returns 10.\n\nThe rational path in Invest is defined as investing any amount of score successfully without suffering a loss.\n\n\f3.7\n\nFlower (Flow)\n\nFlower is a game which was designed to offer small immediate rewards, and\nprogressively larger rewards if some time is allowed to pass for the reward to\ngrow. As shown in figure 9, a single seed is available for the agent to collect,\nwhich is worth 0 points. As time passes the value of the seed increases as it\ngrows into a full flower, from 0 up to 10. Once collected, the seed will begin to\nregrow, starting from 0 again. The rational solution for this game is to wait for\na seed to grow into a full flower, worth 10 points, and then collecting it.\nThe sprites used are as follows:\n–\n\nAvatar: Represents the player/agent in the game.\n\n–\n\nSeed: Awards 0 points initially, but this increases up to 10.\n\nThe rational path in Flower is defined as achieving a score of at least 30.\nThis can only be done by allowing the flower to grow to at least the second stage\nand consistently collecting at that level.\n3.8\n\nWaferThinMints (Mints)\n\nWaferThinMints introduces the idea that gathering too much reward can lead\nto a loss condition. The agent has to gather resources in order to increase their\nreward, but if they collect too many they will die and lose the game.\nTwo variants of this game were created. One which includes an exit from\nthe level, shown in figure 11, and one that does not, shown in figure 10. These\nvariants were created in order to provide a comparison of the effect that the\ndeception in the level has on overall agent performance.\nThe sprites used are as follows:\n–\n\nAvatar: Represents the player/agent in the game.\n\nCheese: Awards a point when collected. If 9 have been collected already,\nthen the 10th will kill the avatar causing a loss.\n–\nExit: Leads to a win condition when moved into.\n–\n\nThe rational path for both versions of the game is defined as collecting a score\nof 9, and then either waiting for the timeout, in level 1 or exiting the game, in\nlevel 2.\n\n4\n\nExperiments and Results\n\nThe agents used were collected from the GVGAI competitions. Criteria for selection were the uniqueness of the algorithm used and competition ranking in the\npast. The hardware used for all of the experiments was a Ubuntu 14.04 desktop\nPC with an i7-4790 CPU and 16GB Ram.\nEach agent was run 10 times on each level of the deceptive games outlined\nin section 3. If an agent was disqualified for any reason it was given another\n\n\fFig. 9. The first level of Fig. 10. The first level of Fig. 11. The second level of\nFlower\nWaferThinMints\nWaferThinMints\n\nrun to collect 10 successful results for each game and agent. In addition to\ncomparing these performance statistics, observations were made on the choices\nthat the agents made when faced with potentially deceptive choices. Each game’s\nrational path is defined in section 3. The results of these experiments are shown\nin table 12. Each game was played a total of 360 times. The totals at the bottom\nof the table show how many of those games were completed using the defined\nrational path. The results are ranked in descending order by their number of\nrational trials, and then the number of games where they managed to play with\n100% rationality.\nNoticeably from the initial results is that no single algorithm was able to solve\nall the games, with DeceptiZelda and SisterSaviour being particularly challenging. Furthermore, no single algorithm dominated all others in all games. For\nExample, IceLab, the top agent in overall results, only has 2 rational trials in\nButterflies, compared to 9 for Greedy Search, which is in the 33rd place. In\ngeneral, the results for Butterflies are interesting, as top agents perform poorly\ncompared to some of the lower ranking agents.\nButterflies also has a good spread of results, with all but 4 of the algorithms\nbeing able to find the rational path at least once. While many of the algorithms\nare able to make some progress with the game, only 2 are able to achieve 100%\nrationality.\nThere is an interesting difference in the performance of agents between DeceptiCoins level 1 and 2. The agents that performed well in Decepticoins 1 seemed\nto perform significantly worse in level 2. The requirements of the levels are quite\ndifferent which appears to have a significant effect on the agents. If a ranking\nwas done with only the performance of DeceptiCoins level 2 then IceLab, the\n1st ranked in this experiment, would be in the bottom half of the results table.\nThe hardest games for the agents to solve were DeceptiZelda levels 1 and 2,\nand SisterSaviour. DeceptiZeldas levels had only 4 and 13 runs solved respectively, and SisterSaviour having 14. These games present interesting challenges\nto the agents, with the rational solution requiring a combination of long-range\nplanning and sacrificing apparent reward for the superior, long-range goal.\nAnother interesting case here is Mints, the only game in our set with a\ngeneralization trap. Most algorithms do well in Mints, suggesting that they do\n\n\fnot generalize. This is to be expected, as a tree search algorithm does not in\nitself generalize from one state to another. But bladerunner, AtheneAI, and\nSJA86 completely fail at these games, even though they perform reasonably well\notherwise. This suggests that they perform some kind of surrogate modeling\nof game states, relying on a generality assumption that this game breaks. The\ninclusion of an accessible win condition in Mints 2 also dramatically reduced\nthe number of algorithms that achieved the maximum amount of score, from\n26 to 8. This seems to be due to also introducing a specific greed trap that\nmost algorithms seem to be susceptible too - namely preferring to win the game\noutright, over accumulating more score.\nNote that, the final rankings of this experiment differ quite significantly from\nthe official rankings on the GVGAI competition. It is important to note that a\ndifferent ranking algorithm is used in the competition, which may account for\nsome of the differences observed. Many of the agents have a vastly different level\nof performance in these results compared to the official rankings. First of all,\nIceLab and MH2015 have historically appeared low in the official rankings, with\ntheir highest ranks being 10th place. The typical high ranking algorithms in the\nofficial competition seem to have been hit a bit harder by the new set of games.\nYolobot, Return42, maastCTS2, YBCriber, adrienctx and number27 tend to\nfeature in the top 5 positions of the official rankings, and have now finished in\npositions 2, 4, 15, 8, 9, and 7. For them to lose their positions in this new set of\ngames could show how the games can be constructed to alter the performance\nof agents [17,19].\nIn order to look at the effect of deception on specific types of algorithms,\nsuch as genetic algorithms (GA) or Tree Search techniques, a second set of\nexperiments were performed. A selection of algorithms were ran an additional\n10 times on each of the games, and each algorithm was investigated to identify\nthe core component of its operation. It should be noted that these classifications\nare simple, and an in-depth analysis of the specifics used by the algorithms\nmight reveal some further insights. The results for these experiments are shown\nin figure 13.\nThese results show a number of interesting observations. First of all, for DeceptiZelda1 and 2 it appears that agents using a genetic algorithm perform better\nthan most other approaches, but do poorly compared to tree search techniques\nat SisterSaviour. Portfolio search agents, which employ different algorithms for\ndifferent games or situations, take the top two positions of the table and place\nquite highly overall compared to single algorithm solutions.\n\n5\n\nDiscussion and Future Work\n\nThe results suggest that the types of deception presented in the games have\ndiffering effects on the performance of different algorithms. The fact that algorithms, that are more sophisticated and usually perform well in the regular\ncompetition are not on top of the rankings is also in line with our argument,\nthat they employ sophisticated assumptions and heuristics, and are subsequently\n\n\fAgent Name\nDC1 DC 2 DC 3 DZ 1 DZ 2\n1. IceLab\n10\n2\n10\n0\n0\n2. Return42\n10\n1\n7\n0\n0\n3. MH2015\n2\n4\n5\n1\n3\n4. YoloBot\n10\n3\n10\n0\n0\n5. jaydee\n9\n6\n9\n0\n0\n6. NovTea\n3\n4\n10\n0\n0\n7. number27\n0\n5\n4\n0\n1\n8. YBCriber\n10\n5\n10\n0\n0\n9. adrienctx\n0\n3\n4\n0\n0\n10. TeamTopBug\n9\n5\n10\n0\n0\n11. Catlinux\n0\n7\n10\n0\n4\n12. muzzle\n6\n2\n1\n0\n0\n13. novelTS\n1\n4\n10\n0\n0\n14. bladerunner\n10\n4\n8\n0\n3\n15. maastCTS2\n0\n2\n0\n2\n0\n16. SJA86\n1\n1\n0\n0\n1\n17. Catlinux3\n0\n3\n10\n0\n0\n18. aStar\n2\n1\n0\n0\n0\n19. AtheneAI\n10\n6\n0\n1\n0\n20. Rooot\n0\n1\n7\n0\n0\n21. SJA862\n3\n0\n7\n0\n0\n22. roskvist\n0\n2\n0\n0\n0\n23. EvolutionStrategies\n0\n1\n1\n0\n0\n24. AIJim\n0\n1\n0\n0\n0\n25. HillClimber\n2\n0\n0\n0\n0\n26. MnMCTS\n0\n1\n0\n0\n1\n27. mrtndwrd\n0\n0\n0\n0\n0\n28. simulatedAnnealing 4\n0\n0\n0\n0\n29. TomVodo\n3\n0\n0\n0\n0\n30. ToVo1\n1\n0\n0\n0\n0\n31. Thorbjrn\n0\n4\n5\n0\n0\n32. BFS\n0\n1\n0\n0\n0\n33. Greedy Search\n10\n0\n0\n0\n0\n34. IterativeDeepening\n0\n0\n0\n0\n0\n35. Catlinux4\n0\n0\n0\n0\n0\n36. DFS\n0\n0\n0\n0\n0\nTotals\n116 79 138\n4\n13\n\nSS\n0\n2\n0\n0\n0\n6\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n4\n0\n0\n0\n0\n0\n0\n2\n0\n0\n14\n\nBF Flow Inv Mints 1 Mints 2 Rational\n2\n10 10\n10\n10\n8\n1\n10 10\n10\n0\n8\n5\n0\n1\n10\n0\n8\n6\n6\n0\n10\n10\n7\n1\n10\n0\n10\n3\n7\n3\n2\n0\n10\n0\n7\n4\n6\n3\n10\n0\n7\n0\n0\n10\n10\n10\n6\n1\n10\n0\n10\n10\n6\n1\n10\n0\n10\n0\n6\n6\n7\n0\n10\n0\n6\n3\n0\n10\n10\n0\n6\n3\n0\n4\n10\n0\n6\n1\n0\n10\n0\n0\n6\n3\n3\n1\n10\n0\n6\n9\n6\n0\n1\n0\n6\n10\n8\n0\n10\n0\n5\n0\n10 10\n10\n0\n5\n10\n0\n10\n0\n0\n5\n7\n10\n0\n10\n0\n5\n3\n0\n10\n10\n0\n5\n5\n2\n0\n10\n3\n5\n3\n5\n0\n10\n0\n5\n9\n1\n5\n5\n0\n5\n7\n3\n1\n0\n1\n5\n6\n0\n8\n6\n0\n5\n3\n4\n0\n10\n0\n4\n8\n4\n0\n0\n1\n4\n5\n5\n0\n4\n0\n4\n9\n1\n0\n9\n0\n4\n9\n0\n1\n0\n0\n4\n5\n0\n10\n0\n0\n3\n9\n0\n0\n0\n0\n2\n1\n0\n0\n0\n0\n2\n0\n0\n10\n0\n0\n1\n0\n0\n0\n0\n0\n0\n158 133 124 235\n48\n\nFig. 12. The results of the first experiment\n\nsusceptible to deception. Based on the data we have now it would be possible\nto build a game to defeat any of the agents on the list, and it seems possible to\ndesign a specific set of games that would put any specific AI at the bottom of\nthe table. The difficulty of a game is, therefore, a property that is, at least in\npart, only well defined in regards to a specific AI.\nIn regards to categorization, it seems there is a certain degree of similarity\nbetween groups of games and groups of AIs that perform similarly, but a more\nin-depth analysis would be needed to determine what exact weakness each AI\nhas. The games in this corpus already contain, like Mints 2, a mixture of different\ndeceptions. Similarly, the more sophisticated agents also employ hybrid strategies\n\n\fAgent Name\n1. IceLab\n2. Return42\n3. MH2015\n4. SJA86\n5. YBCriber\n6. YoloBot\n7. Catlinux\n8. muzzle\n9. NovTea\n10. SJA862\n11. number27\n12. adrienctx\n13. TeamTopBug\n14. bladerunner\n15. EvolutionStrategies\n16. HillClimber\n17. aStar\n18. novelTS\n19. TomVodo\n20. mrtndwrd\n21. simulatedAnnealing\n22. Greedy Search\n23. BFS\n24. IterativeDeepening\n25. DFS\nTotal Clever\n\nAlgorithm DC 1 DC 2 DC 3 DZ 1 DZ 2\nPortfolio\n20\n3\n19\n0\n0\nPortfolio\n20\n3\n13\n0\n0\nGA\n2\n10\n10\n2\n3\nMCTS\n1\n2\n0\n2\n1\nPortfolio\n20\n9\n20\n0\n0\nPortfolio\n20\n8\n20\n0\n0\nGA\n0\n10\n20\n2\n4\nGA\n12\n3\n2\n0\n0\nTree\n8\n7\n20\n0\n0\nMinMax\n8\n3\n13\n0\n0\nPortfolio\n0\n9\n6\n0\n1\nMCTS\n0\n5\n10\n0\n0\nGA\n19\n9\n20\n0\n0\nPortfolio\n20\n6\n12\n4\n5\nGA\n0\n1\n1\n0\n0\nHill\n3\n0\n0\n0\n0\nA*\n4\n1\n0\n0\n0\nTree\n2\n5\n20\n0\n0\nMCTS\n5\n0\n0\n0\n0\nMCTS/A*\n0\n0\n0\n0\n0\nSA\n8\n0\n0\n0\n0\nTree\n20\n0\n0\n0\n0\nBest First\n0\n1\n0\n0\n0\nID\n0\n0\n0\n0\n0\nDepth\n0\n0\n0\n0\n0\n192 95 206 10\n14\n\nSS BF Flow Inv Mints Mints 2 Rational\n0\n9\n20\n2\n20\n20\n8\n4\n5\n20\n20\n20\n0\n8\n0 11\n0\n6\n20\n0\n8\n0 17\n10\n16\n8\n0\n8\n0\n2\n0\n20\n20\n20\n7\n0 12\n13\n0\n20\n20\n7\n0 15\n15\n0\n20\n0\n7\n1 10\n0\n20\n20\n0\n7\n12 9\n3\n0\n20\n0\n7\n0\n8\n2\n20\n20\n0\n7\n0 11\n12\n5\n20\n0\n7\n0\n7\n20\n0\n20\n20\n6\n0\n3\n20\n0\n20\n0\n6\n0\n3\n0\n0\n0\n0\n6\n0\n3\n8\n0\n20\n1\n6\n0 13\n6\n8\n1\n1\n6\n0\n0\n20\n20\n20\n0\n5\n0\n8\n0\n0\n20\n0\n5\n0 14\n8\n3\n8\n0\n5\n9\n9\n7\n0\n20\n0\n4\n0 14\n10\n0\n0\n1\n4\n0 10\n0\n0\n0\n0\n2\n0\n8\n0\n0\n0\n0\n2\n3\n1\n0\n0\n0\n0\n2\n3\n0\n0\n0\n0\n0\n1\n32 202 194 140 337\n83\n\nFig. 13. The results of the second experiment.\n\nand some, like YoloBot, switch between different AI approaches based on the\nkind of game they detect [20]. One way to explore this further would be to use a\ngenetic algorithm to create new VGDL games, with a fitness function rewarding\na set of games that can maximally discriminate between the existing algorithms.\nThere are also further possibilities for deception that we did not explore here.\nLimiting access to the game state, or even requiring agents to actually learn how\nthe game mechanics work open up a whole new range of deception possibilities.\nThis would also allow us to extend this approach to other games, which might\nnot provide the agent with a forward model, or might require the agent to deal\nwith incomplete or noisy sensor information about the world.\nAnother way to deepen this approach would be to extend the metaphor\nabout human cognitive biases. Humans have a long list of cognitive biases most of them connected to some reasonable assumption about the world, or\nmore specifically, typical games. By analyzing what biases humans have in this\nkind of games we could try to develop agents that use similar simplification\nassumptions to humans and thereby make better agents.\n\n6\n\nAcknowledgements\n\nDamien Anderson is funded by the Carnegie Trust for the Universities of Scotland as a PhD Scholar. Christoph Salge is funded by the EU Horizon 2020\nprogramme under the Marie Sklodowska-Curie grant 705643.\n\n\fReferences\n1. Turing, A.M.: Chess. In: Bowden, B.V. (ed.) Fasther than Thought, pp. 286–295.\nPitnam, London (1953)\n2. Von Neumann, J., Morgenstern, O.: Theory of games and economic behavior.\nPrinceton University Press Princeton, NJ (1945)\n3. Campbell, M., Hoane, A.J., Hsu, F.h.: Deep blue. Artificial intelligence 134(1-2),\n57–83 (2002)\n4. Syed, O., Syed, A.: Arimaa-a new game designed to be difficult for computers.\nICGA JOURNAL 26(2), 138–139 (2003)\n5. Nelson, M.J.: Investigating vanilla mcts scaling on the gvg-ai game corpus. In:\nComputational Intelligence and Games (CIG), 2016 IEEE Conference on. pp. 1–7.\nIEEE (2016)\n6. Bontrager, P., Khalifa, A., Mendes, A., Togelius, J.: Matching games and algorithms for general video game playing. In: Twelfth Artificial Intelligence and Interactive Digital Entertainment Conference. pp. 122–128 (2016)\n7. Yannakakis, G.N., Togelius, J.: Artificial Intelligence and Games. Springer (2018),\nhttp://gameaibook.org\n8. Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Driessche, G.V.D.,\nSchrittwieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M., Dieleman,\nS., Grewe, D., Nham, J., Kalchbrenner, N., Sutskever, I., Lillicrap, T., Leach,\nM., Kavukcuoglu, K.: Mastering the game of Go with deep neural networks\nand tree search. Nature 529(7585), 484–489 (2016), http://dx.doi.org/10.1038/\nnature16961\n9. Tversky, A., Kahneman, D.: Judgment under uncertainty: Heuristics and biases.\nScience 185(4157), 1124–1131 (1974)\n10. Gigerenzer, G., Goldstein, D.G.: Reasoning the fast and frugal way: models of\nbounded rationality. Psychological review 103(4), 650 (1996)\n11. Wolpert, D.H., Macready, W.G.: No free lunch theorems for optimization. IEEE\ntransactions on evolutionary computation 1(1), 67–82 (1997)\n12. Whitley, L.D.: Fundamental principles of deception in genetic search. In: Foundations of Genetic Algorithms (1991)\n13. Deb, K., Goldberg, D.E.: Analyzing deception in trap functions\n14. Pérez-Liébana, D., Samothrakis, S., Togelius, J., Schaul, T., Lucas, S.M.: Analyzing\nthe robustness of general video game playing agents. In: Computational Intelligence\nand Games (CIG), 2016 IEEE Conference on. pp. 1–8. IEEE (2016)\n15. Bellemare, M., Srinivasan, S., Ostrovski, G., Schaul, T., Saxton, D., Munos, R.:\nUnifying count-based exploration and intrinsic motivation. In: Advances in Neural\nInformation Processing Systems. pp. 1471–1479 (2016)\n16. Pathak, D., Agrawal, P., Efros, A.A., Darrell, T.: Curiosity-driven exploration by\nself-supervised prediction. arXiv preprint arXiv:1705.05363 (2017)\n17. Perez-Liebana, D., Samothrakis, S., Togelius, J., Schaul, T., Lucas, S.M.,\nCouëtoux, A., Lee, J., Lim, C.U., Thompson, T.: The 2014 general video game\nplaying competition. IEEE Transactions on Computational Intelligence and AI in\nGames 8(3), 229–243 (2016)\n18. Ebner, M., Levine, J., Lucas, S.M., Schaul, T., Thompson, T., Togelius, J.: Towards a video game description language. In: Dagstuhl Follow-Ups. vol. 6. Schloss\nDagstuhl-Leibniz-Zentrum fuer Informatik (2013)\n19. Perez-Liebana, D., Samothrakis, S., Togelius, J., Lucas, S.M., Schaul, T.: General\nvideo game ai: Competition, challenges and opportunities. In: Thirtieth AAAI\nConference on Artificial Intelligence (2016)\n\n\f20. Mendes, A., Togelius, J., Nealen, A.: Hyper-heuristic general video game playing.\nIn: Computational Intelligence and Games (CIG), 2016 IEEE Conference on. pp.\n1–8. IEEE (2016)\n\n\f",
         "train",
         "41398",
         "7332"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 18982
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cls_label</th>\n",
       "      <th>description</th>\n",
       "      <th>file_id</th>\n",
       "      <th>content</th>\n",
       "      <th>split</th>\n",
       "      <th>content_length</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18843</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>1711.04569v2.pdf</td>\n",
       "      <td>MULTILINGUAL ADAPTATION OF RNN BASED ASR SYSTE...</td>\n",
       "      <td>train</td>\n",
       "      <td>22376</td>\n",
       "      <td>3393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19680</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>0311016v1.pdf</td>\n",
       "      <td>Generic Program Monitoring\\nby Trace Analysis⋆...</td>\n",
       "      <td>train</td>\n",
       "      <td>85521</td>\n",
       "      <td>14093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>1801.00388v1.pdf</td>\n",
       "      <td>Beyond Word Embeddings: Learning Entity and Co...</td>\n",
       "      <td>train</td>\n",
       "      <td>43918</td>\n",
       "      <td>6876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18561</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>1802.06821v1.pdf</td>\n",
       "      <td>336\\n\\nInternational Journal \"Information Mode...</td>\n",
       "      <td>train</td>\n",
       "      <td>60978</td>\n",
       "      <td>7055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17628</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>1712.04415v1.pdf</td>\n",
       "      <td>Deception Detection in Videos\\nZhe Wu1\\n\\nBhar...</td>\n",
       "      <td>train</td>\n",
       "      <td>37887</td>\n",
       "      <td>5704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18977</th>\n",
       "      <td>9101</td>\n",
       "      <td>math.ST</td>\n",
       "      <td>Statistics Theory</td>\n",
       "      <td>1804.01619v1.pdf</td>\n",
       "      <td>Stability and Convergence Trade-off of Iterati...</td>\n",
       "      <td>validation</td>\n",
       "      <td>92482</td>\n",
       "      <td>17450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18978</th>\n",
       "      <td>10123</td>\n",
       "      <td>math.ST</td>\n",
       "      <td>Statistics Theory</td>\n",
       "      <td>1501.03694v3.pdf</td>\n",
       "      <td>FRACTIONALLY INTEGRATED COGARCH PROCESSES\\nSTE...</td>\n",
       "      <td>validation</td>\n",
       "      <td>71247</td>\n",
       "      <td>13869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18979</th>\n",
       "      <td>8619</td>\n",
       "      <td>math.ST</td>\n",
       "      <td>Statistics Theory</td>\n",
       "      <td>1602.07586v3.pdf</td>\n",
       "      <td>arXiv:1602.07586v3 [math.ST] 3 Mar 2018\\n\\nA P...</td>\n",
       "      <td>validation</td>\n",
       "      <td>85316</td>\n",
       "      <td>16126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18980</th>\n",
       "      <td>9337</td>\n",
       "      <td>math.ST</td>\n",
       "      <td>Statistics Theory</td>\n",
       "      <td>1512.07621v3.pdf</td>\n",
       "      <td>Submitted to Bernoulli\\n\\nSingle-index copulae...</td>\n",
       "      <td>validation</td>\n",
       "      <td>180065</td>\n",
       "      <td>39494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18981</th>\n",
       "      <td>8533</td>\n",
       "      <td>math.ST</td>\n",
       "      <td>Statistics Theory</td>\n",
       "      <td>1605.07679v1.pdf</td>\n",
       "      <td>1\\n\\nA Fundamental Limitation on Maximum Param...</td>\n",
       "      <td>validation</td>\n",
       "      <td>67337</td>\n",
       "      <td>12771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18982 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index cls_label              description           file_id  \\\n",
       "0      18843     cs.AI  Artificial Intelligence  1711.04569v2.pdf   \n",
       "1      19680     cs.AI  Artificial Intelligence     0311016v1.pdf   \n",
       "2      20001     cs.AI  Artificial Intelligence  1801.00388v1.pdf   \n",
       "3      18561     cs.AI  Artificial Intelligence  1802.06821v1.pdf   \n",
       "4      17628     cs.AI  Artificial Intelligence  1712.04415v1.pdf   \n",
       "...      ...       ...                      ...               ...   \n",
       "18977   9101   math.ST        Statistics Theory  1804.01619v1.pdf   \n",
       "18978  10123   math.ST        Statistics Theory  1501.03694v3.pdf   \n",
       "18979   8619   math.ST        Statistics Theory  1602.07586v3.pdf   \n",
       "18980   9337   math.ST        Statistics Theory  1512.07621v3.pdf   \n",
       "18981   8533   math.ST        Statistics Theory  1605.07679v1.pdf   \n",
       "\n",
       "                                                 content       split  \\\n",
       "0      MULTILINGUAL ADAPTATION OF RNN BASED ASR SYSTE...       train   \n",
       "1      Generic Program Monitoring\\nby Trace Analysis⋆...       train   \n",
       "2      Beyond Word Embeddings: Learning Entity and Co...       train   \n",
       "3      336\\n\\nInternational Journal \"Information Mode...       train   \n",
       "4      Deception Detection in Videos\\nZhe Wu1\\n\\nBhar...       train   \n",
       "...                                                  ...         ...   \n",
       "18977  Stability and Convergence Trade-off of Iterati...  validation   \n",
       "18978  FRACTIONALLY INTEGRATED COGARCH PROCESSES\\nSTE...  validation   \n",
       "18979  arXiv:1602.07586v3 [math.ST] 3 Mar 2018\\n\\nA P...  validation   \n",
       "18980  Submitted to Bernoulli\\n\\nSingle-index copulae...  validation   \n",
       "18981  1\\n\\nA Fundamental Limitation on Maximum Param...  validation   \n",
       "\n",
       "       content_length    len  \n",
       "0               22376   3393  \n",
       "1               85521  14093  \n",
       "2               43918   6876  \n",
       "3               60978   7055  \n",
       "4               37887   5704  \n",
       "...               ...    ...  \n",
       "18977           92482  17450  \n",
       "18978           71247  13869  \n",
       "18979           85316  16126  \n",
       "18980          180065  39494  \n",
       "18981           67337  12771  \n",
       "\n",
       "[18982 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
