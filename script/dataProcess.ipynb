{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess for CLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ag_news_classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset keys: dict_keys(['train', 'test'])\n",
      "Sample data: {'answer_choices': ['World politics', 'Sports', 'Business', 'Science and technology'], 'inputs': [3556, 472, 5, 9034, 7, 205, 4207, 3195, 3, 27201, 8, 1589, 41, 18844, 61, 3, 18844, 3, 18, 7110, 18, 7, 9670, 7, 6, 3556, 1887, 31, 7, 3, 26, 5165, 697, 2, 3348, 13, 6173, 18, 75, 63, 2532, 7, 6, 33, 2492, 1442, 541, 5, 363, 3783, 200, 8788, 48, 1506, 1108, 58], 'inputs_pretokenized': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again. \\nWhat label best describes this news article? \", 'targets': [1769, 1], 'targets_pretokenized': ' \\nBusiness'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bigscience/P3\", \"ag_news_classify\")\n",
    "\n",
    "print(\"Dataset keys:\", dataset.keys())\n",
    "\n",
    "print(\"Sample data:\", dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rotten_tomatoes_Movie_Expressed_Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset keys: dict_keys(['train', 'validation', 'test'])\n",
      "Sample data: {'answer_choices': ['negative', 'positive'], 'inputs': [8, 2480, 19, 3, 26677, 12, 36, 8, 1401, 7, 17, 2646, 31, 7, 126, 96, 975, 152, 96, 11, 24, 3, 88, 31, 7, 352, 12, 143, 3, 9, 16500, 237, 2123, 145, 1584, 29, 1490, 3, 12291, 35, 15, 6938, 3, 6, 3, 26459, 18, 75, 12513, 4049, 10157, 526, 42, 3, 849, 1926, 142, 6191, 3, 5, 37, 6493, 7103, 21, 8, 1974, 19], 'inputs_pretokenized': 'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . The sentiment expressed for the movie is ', 'targets': [1465, 1], 'targets_pretokenized': ' positive'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bigscience/P3\", \"rotten_tomatoes_Movie_Expressed_Sentiment\")\n",
    "\n",
    "print(\"Dataset keys:\", dataset.keys())\n",
    "\n",
    "print(\"Sample data:\", dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### qasc_is_correct_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 8134/8134 [00:00<00:00, 328557.92 examples/s]\n",
      "Generating validation split: 100%|██████████| 926/926 [00:00<00:00, 120063.23 examples/s]\n",
      "Generating test split: 100%|██████████| 920/920 [00:00<00:00, 132649.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset keys: dict_keys(['train', 'validation', 'test'])\n",
      "Sample data: {'answer_choices': ['Yes', 'No'], 'inputs': [156, 27, 817, 25, 24, 493, 9, 26, 7, 13, 387, 54, 36, 5147, 57, 15328, 6, 11, 987, 25, 8, 822, 96, 9170, 686, 13, 387, 3239, 19, 5147, 57, 15328, 4609, 6, 19, 8, 2024, 1525, 96, 855, 291, 40, 7, 121, 58], 'inputs_pretokenized': 'If I tell you that Beads of water can be formed by clouds, and ask you the question \"what type of water formation is formed by clouds?\", is the correct answer \"pearls\"? \\n\\n', 'targets': [465, 1], 'targets_pretokenized': ' \\n\\n No '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"bigscience/P3\", \"qasc_is_correct_1\")\n",
    "print(\"Dataset keys:\", dataset.keys())\n",
    "print(\"Sample data:\", dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WOS11967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_level_2\n",
      "2    2543\n",
      "4    2512\n",
      "0    2428\n",
      "3    2264\n",
      "1    2220\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('web_of_science', 'WOS11967')\n",
    "\n",
    "subcategory_counts = dataset['train'].to_pandas()['label_level_2'].value_counts()\n",
    "print(subcategory_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Parent Categories: 7\n",
      "Unique Parent-Child Category Combinations: 34\n",
      "Top 5 Parent-Child Combinations: [((4, 4), 449), ((4, 3), 441), ((1, 4), 426), ((4, 1), 423), ((3, 3), 420)]\n",
      "\n",
      "Parent-Child Count:\n",
      "(4, 4): 449\n",
      "(4, 3): 441\n",
      "(1, 4): 426\n",
      "(4, 1): 423\n",
      "(3, 3): 420\n",
      "(4, 0): 410\n",
      "(3, 1): 402\n",
      "(6, 2): 401\n",
      "(2, 1): 397\n",
      "(2, 3): 394\n",
      "(2, 2): 391\n",
      "(2, 0): 389\n",
      "(2, 4): 388\n",
      "(3, 4): 386\n",
      "(4, 2): 384\n",
      "(3, 0): 371\n",
      "(5, 2): 368\n",
      "(5, 1): 357\n",
      "(1, 2): 353\n",
      "(6, 0): 351\n",
      "(3, 2): 346\n",
      "(6, 1): 340\n",
      "(6, 3): 335\n",
      "(5, 3): 321\n",
      "(5, 0): 309\n",
      "(0, 1): 301\n",
      "(6, 4): 301\n",
      "(0, 3): 300\n",
      "(0, 2): 300\n",
      "(1, 0): 300\n",
      "(0, 4): 300\n",
      "(0, 0): 298\n",
      "(5, 4): 262\n",
      "(1, 3): 53\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the WOS-11967 dataset\n",
    "dataset = load_dataset(\"web_of_science\", \"WOS11967\")\n",
    "\n",
    "train_data = dataset[\"train\"]\n",
    "\n",
    "parent_count = defaultdict(int)\n",
    "parent_child_count = defaultdict(int)\n",
    "\n",
    "for example in train_data:\n",
    "    parent_label = example[\"label_level_1\"]\n",
    "    child_label = example[\"label_level_2\"]\n",
    "    \n",
    "    parent_count[parent_label] += 1\n",
    "    parent_child_count[(parent_label, child_label)] += 1 \n",
    "\n",
    "num_parents = len(parent_count)\n",
    "num_parent_child = len(parent_child_count)\n",
    "\n",
    "print(f\"Unique Parent Categories: {num_parents}\")\n",
    "print(f\"Unique Parent-Child Category Combinations: {num_parent_child}\")\n",
    "\n",
    "sorted_parent_child = sorted(parent_child_count.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Top 5 Parent-Child Combinations:\", sorted_parent_child[:5])\n",
    "\n",
    "print(\"\\nParent-Child Count:\")\n",
    "for (parent, child), count in sorted(parent_child_count.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"({parent}, {child}): {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAXI 1500 \n",
    "\n",
    "To be done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Spliting For Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n"
     ]
    }
   ],
   "source": [
    "unique_labels = list(set(train_data[\"label\"]))\n",
    "print(unique_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
